<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NEUCOM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="neucom---1204">NEUCOM - 1204</h2>
<ul>
<li><details>
<summary>
(2024). A comprehensive survey on contrastive learning.
<em>NEUCOM</em>, <em>610</em>, 128645. (<a
href="https://doi.org/10.1016/j.neucom.2024.128645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive Learning is self-supervised representation learning by training a model to differentiate between similar and dissimilar samples. It has been shown to be effective and has gained significant attention in various computer vision and natural language processing tasks. In this paper, we comprehensively and systematically sort out the main ideas, recent developments and application areas of contrastive learning. Specifically, we firstly provide an overview of the research activity of contrastive learning in recent years. Secondly, we describe the basic principles and summarize a universal framework of contrastive learning. Thirdly, we further introduce and discuss the latest advances of each functional component in detail, including data augmentation, positive/negative samples,network structure, and loss function. Finally, we summarize contrastive learning and discuss the challenges, future research trends and development directions in the area of contrastive learning.},
  archive      = {J_NEUCOM},
  author       = {Haigen Hu and Xiaoyuan Wang and Yan Zhang and Qi Chen and Qiu Guan},
  doi          = {10.1016/j.neucom.2024.128645},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128645},
  shortjournal = {Neurocomputing},
  title        = {A comprehensive survey on contrastive learning},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EEG-based epileptic seizure detection using deep learning
techniques: A survey. <em>NEUCOM</em>, <em>610</em>, 128644. (<a
href="https://doi.org/10.1016/j.neucom.2024.128644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is a complex neurological disorder marked by recurrent seizures, often stemming from abnormal discharge of the brain. Electroencephalogram (EEG) captures temporal and spatial shifts in cerebral electrical activity, holding pivotal diagnostic and therapeutic value for epilepsy. Deep learning techniques have made remarkable progress in EEG-based seizure detection over recent years. This review is dedicated to exploring seizure detection approaches based on deep learning, focusing on three distinct avenues. Primarily, we delve into the application of canonical deep learning methods in epilepsy detection. Subsequently, a more in-depth study was conducted on the hybrid models of deep learning. Next, the third is the integration of deep learning and traditional machine learning strategies. Finally, the challenges and future prospects related to this topic are put forward. The uniqueness of this review lies in its novel and comprehensive perspective on the latest research on deep learning-based epilepsy detection by systematically classifying methods, visualizing research progress, and addressing challenges and gaps in current research. It can provide valuable guidance for researchers who want to delve into the field of epileptic seizure detection based on EEG signals.},
  archive      = {J_NEUCOM},
  author       = {Jie Xu and Kuiting Yan and Zengqian Deng and Yankai Yang and Jin-Xing Liu and Juan Wang and Shasha Yuan},
  doi          = {10.1016/j.neucom.2024.128644},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128644},
  shortjournal = {Neurocomputing},
  title        = {EEG-based epileptic seizure detection using deep learning techniques: A survey},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-biased contrastive learning for answer selection with
dual-tower structure. <em>NEUCOM</em>, <em>610</em>, 128641. (<a
href="https://doi.org/10.1016/j.neucom.2024.128641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large number of unanswered products-related questions appear in the E-commerce platforms, necessitating the deployment of question-answering models to automatically provide precise responses for the user. However, the substantial absence of ground truth presents challenges for implementing supervised learning, and existing unsupervised contrastive learning methods have not addressed this issue fundamentally, with limitations in integrating multi-level features. This paper presents a dual-tower cross-biased contrastive learning model for answer selection, named CCLM-AS. By taking questions and augmented product reviews as positive pairs for unsupervised contrastive learning and employing a dual-tower structure encoder, CCLM-AS learns sentence representations from unlabeled data effectively. Furthermore, the designed training objective realizes multi-level feature integration, including character, sentence and dialogue levels, which enhances the model&#39;s inference ability. The experimental results on AmazonQA dataset indicate that our proposed model outperforms existing contrastive learning-based sentence representation models and also achieves comparable performance to supervised answer selection models. This demonstrates that CCLM-AS can not only alleviate the data sparsity problem effectively but also retain the excellent performance.},
  archive      = {J_NEUCOM},
  author       = {Xingnan Jin and Yongping Du and Binrui Wang and Qi Zhang},
  doi          = {10.1016/j.neucom.2024.128641},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128641},
  shortjournal = {Neurocomputing},
  title        = {Cross-biased contrastive learning for answer selection with dual-tower structure},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Structured orthogonal random features based on DCT for
kernel approximation. <em>NEUCOM</em>, <em>610</em>, 128640. (<a
href="https://doi.org/10.1016/j.neucom.2024.128640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random Fourier features are a popular technique used to improve nonlinear kernel methods in large-scale problems. Recent studies have shown that replacing random Gaussian matrices of random feature maps with appropriately scaled random orthogonal matrices, such as SORF, can significantly improve kernel approximation performance. However, the SORF method theoretically requires zero-padding for datasets whose input feature dimension does not meet d = 2 p for some p ∈ N + , resulting in increased memory and computation time. To address this limitation, we propose a new structured orthogonal random features method based on discrete cosine transform (SORF-DCT) to approximate Gaussian kernel functions. The SORF-DCT method does not require the input feature dimension to be d = 2 p . The key to SORF-DCT is that we combine the DCT matrix with diagonal ”sign-flipping” matrices and scale them appropriately using a diagonal matrix whose diagonal elements follow the chi distribution, resulting in a structured orthogonal matrix whose elements follow the standard Gaussian distribution instead of a random Gaussian matrix. SORF-DCT generates D -dimensional structured orthogonal random features in O ( D log d ) time and O ( D ) memory by employing fast discrete cosine transform, where d and D represent the input feature dimension and expansion dimension, respectively. We prove that SORF-DCT is an unbiased estimator of the Gaussian kernel function and analyze the concentration error bounds. Experimental results on eleven benchmark datasets show that SORF-DCT achieves lower kernel approximation errors, requires less time, and has comparable nonlinear learning capabilities.},
  archive      = {J_NEUCOM},
  author       = {Junna Zhang and Shuisheng Zhou},
  doi          = {10.1016/j.neucom.2024.128640},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128640},
  shortjournal = {Neurocomputing},
  title        = {Structured orthogonal random features based on DCT for kernel approximation},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Event-triggered adaptive neural inverse optimal
output-feedback control of steer-by-wire vehicle systems with prescribed
performance. <em>NEUCOM</em>, <em>610</em>, 128635. (<a
href="https://doi.org/10.1016/j.neucom.2024.128635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, an event-triggered adaptive neural network (NN) output-feedback inverse optimal control issue is investigated for the steer-by-wire vehicle (SBWV) systems. Firstly, NNs are utilized to approximate the unknown nonlinear dynamics and the auxiliary system of SBWV systems is established. Then, a NN state observer is constructed to estimate the unmeasured states. To obtain better tracking performance, the prescribed performance technique is introduced to constrain the tracking error. An event-triggered mechanism (ETM) is established to decrease the numbers of controller execution times. Subsequently, an event-triggered adaptive NN inverse optimal output-feedback control algorithm is proposed by employing the backstepping control theory. It is proved that the developed control method can not only ensure the stability of the SBWV systems, but also guarantee the tracking error does not exceed the prescribed performance bound and converges to a small neighborhood of zero. Finally, simulation results are given to verify the validity of the proposed control method.},
  archive      = {J_NEUCOM},
  author       = {Jiaming Zhang and Wenjun Zhang and Shaocheng Tong},
  doi          = {10.1016/j.neucom.2024.128635},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128635},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered adaptive neural inverse optimal output-feedback control of steer-by-wire vehicle systems with prescribed performance},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep neural networks-prescribed performance optimal control
for stochastic nonlinear strict-feedback systems. <em>NEUCOM</em>,
<em>610</em>, 128633. (<a
href="https://doi.org/10.1016/j.neucom.2024.128633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article explores the application of deep neural networks (DNNs) for optimized backstepping control design in a category of stochastic nonlinear strict-feedback systems with unknown dynamics, focusing on prescribed performance. DNNs, distinguished by their ability to handle high-complexity functions and enhance function approximation, are employed to estimate unknown nonlinear functions. The weight updating strategy for each layer of DNNs is determined through a Lyapunov function analysis. Tomitigate potential issues such as the tracking error exploding at uncertain moments, prescribed performance control (PPC) is introduced to constrain the tracking error within a predetermined range. Subsequently, a novel optimal tracking control scheme, integrating the backstepping method and Hamilton–Jacobi–Bellman (HJB) equation, is presented. The results indicate that all signals in the closed-loop system are bounded in probability, and the tracking error is maintained within a set of predefined arbitrarily small residuals. Simulation outcomes affirm the efficacy of the proposed control scheme.},
  archive      = {J_NEUCOM},
  author       = {Jinhui Chen and Jun Mei and Junhao Hu and Zhanying Yang},
  doi          = {10.1016/j.neucom.2024.128633},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128633},
  shortjournal = {Neurocomputing},
  title        = {Deep neural networks-prescribed performance optimal control for stochastic nonlinear strict-feedback systems},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic review on deep learning based methods for
cervical cell image analysis. <em>NEUCOM</em>, <em>610</em>, 128630. (<a
href="https://doi.org/10.1016/j.neucom.2024.128630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cervical cytology image analysis is indispensable for the detection of abnormal cervical cells. Traditionally, manual screening is time-consuming and labor-intensive. Therefore, a lot of deep learning (DL)-based automatic detection methods have been employed in this field to provide timely, accurate and objective results. In this study, we systematically review the current developments in cervical cell image analysis with DL methods. Specifically, we first present the most popular DL models that are widely applied in cervical cell analysis. Second, we describe the methodology for conducting this review. Third, we provide all publicly available datasets related to cervical cell images to the best of our knowledge. Then, we introduce relevant evaluation metrics and loss functions. Next, we summarize and assort the applications for cervical cell classification and segmentation. Afterwards, we discuss about current challenges and future research directions in this field. Finally, we draw the conclusion of this review. According to the analysis, we conclude that the studies based on DL models have maintained an increasing trend in recent years, which indicates the potential of DL in cervical cell image analysis. In cervical cell image classification, CNN is the most commonly used DL model. Among CNN models, we can find that VGGNet and ResNet are the most popular network architectures for the classification of cervical cells. Transformer is the second commonly used DL model. Moreover, Herlev and SIPaKMeD are the most popular public datasets used for cervical cell classification. In cervical cell segmentation, U-Net and FCN are the two most popular DL architectures. In addition, ISBI2014 and Herlev datasets are the most frequently used among the existing publicly available segmentation datasets. However, there are some issues in this field, such as poor cervical cell classification performance as a result of similar pathological properties between different cell categories. Therefore, it is necessary to develop more effective methods with DL models to improve these issues in the future research.},
  archive      = {J_NEUCOM},
  author       = {Ming Fang and Bo Liao and Xiujuan Lei and Fang-Xiang Wu},
  doi          = {10.1016/j.neucom.2024.128630},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128630},
  shortjournal = {Neurocomputing},
  title        = {A systematic review on deep learning based methods for cervical cell image analysis},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A parallel neural networks for emotion recognition based on
EEG signals. <em>NEUCOM</em>, <em>610</em>, 128624. (<a
href="https://doi.org/10.1016/j.neucom.2024.128624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our study proposes a novel Parallel Temporal–Spatial-Frequency Neural Network (PTSFNN) for emotion recognition. The network processes EEG signals in the time, frequency, and spatial domains simultaneously to extract discriminative features. Despite its relatively simple architecture, the proposed model achieves superior performance. Specifically, PTSFNN first applies wavelet transform to the raw EEG signals and then reconstructs the coefficients based on frequency hierarchy, thereby achieving frequency decomposition. Subsequently, the core part of the network performs three independent parallel convolution operations on the decomposed signals, including a novel graph convolutional network. Finally, an attention mechanism-based post-processing operation is designed to effectively enhance feature representation. The features obtained from the three modules are concatenated for classification, with the cross-entropy loss function being adopted. To evaluate the model’s performance, extensive experiments are conducted on the SEED and SEED-IV public datasets. The experimental results demonstrate that PTSFNN achieves excellent performance in emotion recognition tasks, with classification accuracies of 87.63% and 74.96%, respectively. Comparative experiments with previous state-of-the-art methods confirm the superiority of our proposed model, which can efficiently extract emotion information from EEG signals.},
  archive      = {J_NEUCOM},
  author       = {Ruijie He and Yuwen Jie and Wei Tong and Miaomiao Zhang and Guangyu Zhu and Edmond Q. Wu},
  doi          = {10.1016/j.neucom.2024.128624},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128624},
  shortjournal = {Neurocomputing},
  title        = {A parallel neural networks for emotion recognition based on EEG signals},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DMMGNet: A discrimination mapping and memory bank mean
guidance-based network for high-performance few-shot industrial anomaly
detection. <em>NEUCOM</em>, <em>610</em>, 128622. (<a
href="https://doi.org/10.1016/j.neucom.2024.128622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For deep learning-based industrial anomaly detection, it is still challenging to get adequate images for model training and achieve cold start for cross-product migration, restricting their practical application in real industrial production. Herein, an innovative few-shot anomaly detection network DMMGNet based on discrimination mapping and memory bank mean guidance strategies are demonstrated, which is trained by a new two-branch data augmentation technique. By separating the features stored in memory bank from the features used for training, the two-branch data augmentation method can significantly improve the robustness of few-shot model training and reduce the redundance of memory bank. In the elaborately designed discrimination mapping module, new negative samples are generated by adding dynamic Gaussian noise to normal samples along the channel dimension in feature space to solve the problem of sample imbalance. Meanwhile, the discrimination mapping module also helps to map the feature distribution of positive samples to the target domain more efficiently and reduce the deviation of feature domain, conducive to a more precise separation of positive and negative samples. In addition, a novel mean guidance approach with an optimized loss function is developed to guide the positive sample feature mapping by specifying the local feature space center to form a clear feature domain contour and enhance the detection accuracy. The multiple experimental results validate that our DMMGNet outperforms the most advanced anomaly detection counterparts on image-level AUROC, showing an increase by 0.3–3 % on both MVTec AD and MPDD benchmarks under several few-shot scenarios.},
  archive      = {J_NEUCOM},
  author       = {Aoshuang Luo and Guojun Wen and Yahui Cheng and Shuang Mei and Hongbo Dong and Xingyue Liu},
  doi          = {10.1016/j.neucom.2024.128622},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128622},
  shortjournal = {Neurocomputing},
  title        = {DMMGNet: A discrimination mapping and memory bank mean guidance-based network for high-performance few-shot industrial anomaly detection},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Zero-shot visual grounding via coarse-to-fine representation
learning. <em>NEUCOM</em>, <em>610</em>, 128621. (<a
href="https://doi.org/10.1016/j.neucom.2024.128621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual grounding (VG) locates target objects in visual scenes by understanding given natural language queries. Current methods for VG mainly focus on grounding referring expressions or noun phrases covered in the labeled training samples. Despite their grounding prowess, these approaches struggle in grounding novel query–image pairs excluded from the training data. This shortage is usually caused by the deficiency of discriminative representation learning both in images and queries. To address these issues, we propose a one-stage coarse-to-fine framework for zero-shot VG to ground novel query-image samples. Specifically, in the coarse stage, we mine the global context information in the visual features and query embeddings by employing a multi-head self-attention block, strengthening the intra-modality relations in the visual and textual features. In the fine stage, we first learn the query-aware visual representations based on the acquired global context information via a multi-modal relation-enhanced transformer block, which explores the informative information by modeling the cross-modal interaction among visual and textual domains. We further excavate target-oriented discriminative representations from the acquired query-aware visual representations by a noun phrase-guided multi-modal interaction network, which augments the interaction between target-related phrases and the obtained query-aware visual representations to enhance the distinction of target regions, enhancing the subsequent referred target grounding and generalizing. In order to validate the proposed approach, we implement extensive experiments and ablation studies on public benchmark datasets, including RefCOCO, RefCOCO+, RefCOCOg, Flickr30K Entity, Flickr-Split-0 and Flickr-Split-1. Experimental results demonstrate that our approach substantially improves the grounding accuracy and achieves new state-of-the-art performance under single-stage training and testing.},
  archive      = {J_NEUCOM},
  author       = {Jinpeng Mi and Shaofei Jin and Zhiqian Chen and Dan Liu and Xian Wei and Jianwei Zhang},
  doi          = {10.1016/j.neucom.2024.128621},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128621},
  shortjournal = {Neurocomputing},
  title        = {Zero-shot visual grounding via coarse-to-fine representation learning},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring transferable and robust adversarial perturbation
generation across network hierarchy. <em>NEUCOM</em>, <em>610</em>,
128620. (<a href="https://doi.org/10.1016/j.neucom.2024.128620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transferability and robustness of adversarial examples are two practical and important properties for black-box adversarial attacks. In this paper, we explore effective mechanisms to boost both of them across network hierarchy. In general, a typical network can be hierarchically divided into output stage, intermediate stage and input stage. Due to the over-specialization of the substitute model, we can hardly improve the transferability and robustness of the adversarial perturbations in the output stage. Therefore, we focus on manipulating the intermediate and input stages in this paper, and propose a Transferable and Robust Adversarial Perturbation generation (TRAP) method. Specifically, we propose the dynamically guided mechanism to continuously calculate accurate directional guidances for perturbation generation in the intermediate stage. In the input stage, instead of employing the single-form transformation augmentations adopted in the existing methods, we leverage multi-form affine transformation augmentations to enrich the input diversity and simultaneously boost the robustness and transferability of the adversarial perturbations. Extensive evaluations on ImageNet validation set demonstrate that our TRAP achieves superior transferability when attacking convolution neural networks (CNNs) and vision transformers (ViTs) compared to closely related state-of-the-art methods. For instance, based on the ResNet-101 model, we achieve an average attack success rate of 97.5% on black-box CNN models and 70.1% on ViT models, respectively. Moreover, TRAP exhibits robust performance against various physical-world interferences, such as Gaussian blurring, Gaussian noise, JPEG compression, color distortions, image erosion and image dilation. Additionally, we also show the potential application of our TRAP method for proactive defense against deepfake.},
  archive      = {J_NEUCOM},
  author       = {Ruikui Wang and Yuanfang Guo and Ruijie Yang and Yunhong Wang},
  doi          = {10.1016/j.neucom.2024.128620},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128620},
  shortjournal = {Neurocomputing},
  title        = {Exploring transferable and robust adversarial perturbation generation across network hierarchy},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cascading graph contrastive learning for multi-behavior
recommendation. <em>NEUCOM</em>, <em>610</em>, 128618. (<a
href="https://doi.org/10.1016/j.neucom.2024.128618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recommendation techniques often prioritize target behavior in practical recommendation scenarios(e.g., follow, play and buy). However, these approaches suffer from data sparsity issues and may not fully capture user’s personal preferences. To address this deficiency, multi-behavior recommendation technology has emerged, leveraging users’ multi-behavioral interactions for recommendation. Nevertheless, certain multi-behavior recommendation methods learning behavioral information from each behavior separately and then aggregate them before making recommendation, which inadvertently neglects the intrinsic connections between different behaviors. In some scenarios, user behavior often occurs in a fixed order, such as view - &gt; cart - &gt; buy in e-commerce platforms. In this work, we propose a novel C ascading G raph C onstrastive L earning (CGCL) framework for Multi-Behavior recommendation. Specifically, we devise a graph contrastive learning block to learn distinctive user behavioral representations for each type of interaction. Leveraging the recommendation task, we aim to capture user preferences, while the contrastive learning provides supplementary supervisory signals to refine the user and item representation. By acknowledging the sequential order of behaviors, we utilize the cascading structure within our model to iteratively propagate and purify the personalized preferences of users. Extensive experimental results and ablation studies on three real-world datasets have shown that our CGCL framework outperforms various state-of-the-art recommendation methods and validated the effectiveness of our approach.},
  archive      = {J_NEUCOM},
  author       = {Jiangquan Yang and Xiangxia Li and Bin Li and Lianfang Tian and Bo Xu and Yanhong Chen},
  doi          = {10.1016/j.neucom.2024.128618},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128618},
  shortjournal = {Neurocomputing},
  title        = {Cascading graph contrastive learning for multi-behavior recommendation},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weakly supervised text classification framework for
noisy-labeled imbalanced samples. <em>NEUCOM</em>, <em>610</em>, 128617.
(<a href="https://doi.org/10.1016/j.neucom.2024.128617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this study is to solve the combined issue of noise labels and imbalanced samples for text classification. Current studies generally adopt data sampling or cleaning in model learning, leading to a part of information loss. To this end, this paper introduces a weakly supervised text classification framework, dubbed WeStcoin, which aims to learn a clear hierarchical attention network directly from the given noisy-labeled imbalanced samples. Specifically, WeStcoin first vectorizes the given texts to generate a contextualized corpus on which the pseudo-label vector is calculated by extracting seed words from each class and the predicted label vector is obtained by a hierarchical attention network. Based on the pseudo and predicted label vectors, we learn a cost-sensitive matrix to project the concatenated label vectors into the given label space. WeStcoin is trained iteratively to reduce the difference between the output labels and the given noisy labels by updating the network parameters, the set of seed words, and the cost-sensitive matrix, respectively. Finally, extended experiments on short-text classification shows that WeStcoin achieves a significant improvement than the state-of-the-art models in imbalanced samples with noisy labels. Besides, WeStcoin acts more robustly than compared methods and provides potential explanations for noisy labels.},
  archive      = {J_NEUCOM},
  author       = {Wenxin Zhang and Yaya Zhou and Shuhui Liu and Yupei Zhang and Xuequn Shang},
  doi          = {10.1016/j.neucom.2024.128617},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128617},
  shortjournal = {Neurocomputing},
  title        = {Weakly supervised text classification framework for noisy-labeled imbalanced samples},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). JARViS: Detecting actions in video using unified actor-scene
context relation modeling. <em>NEUCOM</em>, <em>610</em>, 128616. (<a
href="https://doi.org/10.1016/j.neucom.2024.128616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video action detection (VAD) is a formidable vision task that involves the localization and classification of actions within the spatial and temporal dimensions of a video clip. Among the myriad VAD architectures, two-stage VAD methods utilize a pre-trained person detector to extract the region of interest features, subsequently employing these features for action detection. However, the performance of two-stage VAD methods has been limited as they depend solely on localized actor features to infer action semantics. In this study, we propose a new two-stage VAD framework called Joint Actor-scene context Relation modeling based on Visual Semantics (JARViS), which effectively consolidates cross-modal action semantics distributed globally across spatial and temporal dimensions using Transformer attention. JARViS employs a person detector to produce densely sampled actor features from a keyframe. Concurrently, it uses a video backbone to create spatio-temporal scene features from a video clip. Finally, the fine-grained interactions between actors and scenes are modeled through a Unified Action-Scene Context Transformer to directly output the final set of actions in parallel. Our experimental results demonstrate that JARViS outperforms existing methods by significant margins and achieves state-of-the-art performance on three popular VAD datasets, including AVA, UCF101-24, and JHMDB51-21.},
  archive      = {J_NEUCOM},
  author       = {Seok Hwan Lee and Taein Son and Soo Won Seo and Jisong Kim and Jun Won Choi},
  doi          = {10.1016/j.neucom.2024.128616},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128616},
  shortjournal = {Neurocomputing},
  title        = {JARViS: Detecting actions in video using unified actor-scene context relation modeling},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). K-order echo-type spiking neural p systems for time series
forecasting. <em>NEUCOM</em>, <em>610</em>, 128613. (<a
href="https://doi.org/10.1016/j.neucom.2024.128613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear spiking neural P (NSNP) systems are variants of neural-like membrane computing models, abstracted by nonlinear spiking mechanisms of biological neurons. NSNP systems can show rich nonlinear dynamics. This study proposes a new variant of NSNP systems, called k -order NSNP systems, and derives their mathematical models. The k -order NSNP systems are able to remember the states of the previous k moments. Based on the k -order NSNP systems, we propose a new recurrent-like model, called k -order echo-type spiking neural P systems or termed kESNP model. Structurally, the k ESNP model is a k -order NSNP system equipped with an input layer and an output layer. Inspired by echo state networks (ESN), this k ESNP model is trained by ridge regression algorithm. Six time series are used as benchmark data sets to evaluate the k ESNP model and it is compared with 33 baseline prediction methods. The experimental results demonstrate that the proposed k ESNP model is sufficient for the task of time series forecasting.},
  archive      = {J_NEUCOM},
  author       = {Juan He and Hong Peng and Jun Wang and Qian Yang and Antonio Ramírez-de-Arellano},
  doi          = {10.1016/j.neucom.2024.128613},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128613},
  shortjournal = {Neurocomputing},
  title        = {K-order echo-type spiking neural p systems for time series forecasting},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time synchronization of proportional delay memristive
competitive neural networks. <em>NEUCOM</em>, <em>610</em>, 128612. (<a
href="https://doi.org/10.1016/j.neucom.2024.128612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The finite-time synchronization (FTS) is considered for proportional delay memristive competitive neural networks (PDMCNNs). By utilizing Lyapunov functional method and differential inclusion theory, two new criteria ensuring the FTS of PDMCNNs are established. These criteria with algebraic inequality forms are less complicated and easier to verify than the matrix inequality forms. In addition, the corresponding settling times have been estimated. Eventually, the effectiveness of the presented criteria and controllers is confirmed through two numerical examples, and one application about image encryption is provided.},
  archive      = {J_NEUCOM},
  author       = {Jiapeng Han and Liqun Zhou},
  doi          = {10.1016/j.neucom.2024.128612},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128612},
  shortjournal = {Neurocomputing},
  title        = {Finite-time synchronization of proportional delay memristive competitive neural networks},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Localizing discriminative regions for fine-grained visual
recognition: One could be better than many. <em>NEUCOM</em>,
<em>610</em>, 128611. (<a
href="https://doi.org/10.1016/j.neucom.2024.128611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained visual recognition (FGVR) involves distinguishing between highly similar subcategories. To capture subtle differences among closely related subcategories, prevalent methodologies first localize the discriminative region in the image and then classify it. However, previous detection-based and attention-based methods for discriminative region localization possess inherent limitations, thus limiting the performance. Deep reinforcement learning (DRL) is a good choice as it can autonomously determine optimal actions to achieve a given objective, e.g. , localizing the discriminative region. Nevertheless, existing DRL-based approaches learn to simultaneously localize an uncertain number of discriminative regions, which may pose challenges for the DRL agent. Additionally, the optimization of DRL relies on recognition feedback from an FGVR classifier, whereas existing approaches just employ standard networks as the classifier. To address these challenges, we propose a Reinforced Most-Discriminative Region Localization (RMDRL) module to adaptively localize a single, most discriminative region in the image. To provide precise feedback for training the RMDRL module, we propose a Discriminative Knowledge Self-Distillation (DKSD) module to cultivate a robust FGVR classifier. Our extensive experimentation across nine benchmarks validates the efficacy of our approach for FGVR. Our findings also support that one discriminative region localized by DRL could be better than multiple discriminative regions.},
  archive      = {J_NEUCOM},
  author       = {Fen Fang and Yun Liu and Qianli Xu},
  doi          = {10.1016/j.neucom.2024.128611},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128611},
  shortjournal = {Neurocomputing},
  title        = {Localizing discriminative regions for fine-grained visual recognition: One could be better than many},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards sharper excess risk bounds for differentially
private pairwise learning. <em>NEUCOM</em>, <em>610</em>, 128610. (<a
href="https://doi.org/10.1016/j.neucom.2024.128610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pairwise learning is a vital part of machine learning. It depends on pairs of training instances, and is naturally fit for modeling relationships between samples. However, as a data driven paradigm, it faces huge privacy issues. Differential privacy (DP) is a useful tool to protect the privacy of machine learning, but corresponding excess population risk bounds are loose in existing DP pairwise learning analysis. In this paper, we propose a gradient perturbation algorithm for pairwise learning to get better risk bounds under Polyak–Łojasiewicz condition, including both convex and non-convex cases. Specifically, for the theoretical risk bound in expectation, previous best results are of rates O ( p n 2 ϵ 2 + 1 n ) and O ( p n ϵ + 1 n ) under strongly convex condition and convex conditions, respectively. In this paper, we use the on-average stability and achieve an O ( min { p n 1 . 5 ϵ + p 1 . 5 n 2 . 5 ϵ 3 , p n 2 ϵ 2 + 1 n } ) bound, significantly improving previous bounds. For the high probability risk bound, previous best results are analyzed by the uniform stability, and O ( β n U + p n ϵ ) excess population risk bounds are achieved under strongly convex or convex conditions, where β n U is the traditional pairwise uniform stability parameter, it is large since it considers the worst case of the loss sensitivity. In this paper, we propose the pairwise locally elastic stability and improve the high probability bound to O ( β E n + p n ϵ ) , in which the pairwise locally elastic stability parameter β E ≪ β n U because it considers the average sensitivity of the pairwise loss function.},
  archive      = {J_NEUCOM},
  author       = {Yilin Kang and Jian Li and Yong Liu and Weiping Wang},
  doi          = {10.1016/j.neucom.2024.128610},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128610},
  shortjournal = {Neurocomputing},
  title        = {Towards sharper excess risk bounds for differentially private pairwise learning},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Task scheduling for control system based on deep
reinforcement learning. <em>NEUCOM</em>, <em>610</em>, 128609. (<a
href="https://doi.org/10.1016/j.neucom.2024.128609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the control system’s computational task scheduling problem within limited time and with limited CPU cores in the cloud server. We employ a neural network model to estimate the runtime consumption of linear quadratic regulators (LQR) under varying numbers of CPU cores. Building upon this, we model the task scheduling problem as a two-dimensional bin packing problem (2D BPP) and formulate the BPP as a Markov Decision Process (MDP). By studying the characteristics of the MDP, we simplify the action space, design an efficient reward function, and propose a Double DQN-based algorithm with a simplified action space. Experimental results demonstrate that the proposed approach has improved training efficiency and learning performance compared to other packing algorithms, effectively addressing the challenges of task scheduling in the context of the control system.},
  archive      = {J_NEUCOM},
  author       = {Yuhao Liu and Yuqing Ni and Chang Dong and Jun Chen and Fei Liu},
  doi          = {10.1016/j.neucom.2024.128609},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128609},
  shortjournal = {Neurocomputing},
  title        = {Task scheduling for control system based on deep reinforcement learning},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Beyond supervision: Harnessing self-supervised learning in
unseen plant disease recognition. <em>NEUCOM</em>, <em>610</em>, 128608.
(<a href="https://doi.org/10.1016/j.neucom.2024.128608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models have demonstrated great promise in plant disease identification. However, existing approaches often face challenges when dealing with unseen crop-disease pairs, limiting their practicality in real-world settings. This research addresses the gap between known and unknown (unseen) plant disease identification. Our study pioneers the exploration of the zero-shot setting within this domain, offering a new perspective to conceptualizing plant disease identification. Specifically, we introduce the novel Cross Learning Vision Transformer (CL-ViT) model, incorporating self-supervised learning, in contrast to the previous state-of-the-art, FF-ViT, which emphasizes conceptual feature disentanglement with a synthetic feature generation framework. Through comprehensive analyses, we demonstrate that our novel model outperforms state-of-the-art models in both accuracy performance and visualization analysis. This study establishes a new benchmark and marks a significant advancement in the field of plant disease identification, paving the way for more robust and efficient plant disease identification systems. The code is available at https://github.com/abelchai/Cross-Learning-Vision-Transformer-CL-ViT .},
  archive      = {J_NEUCOM},
  author       = {Abel Yu Hao Chai and Sue Han Lee and Fei Siang Tay and Pierre Bonnet and Alexis Joly},
  doi          = {10.1016/j.neucom.2024.128608},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128608},
  shortjournal = {Neurocomputing},
  title        = {Beyond supervision: Harnessing self-supervised learning in unseen plant disease recognition},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Image manipulation localization via dynamic cross-modality
fusion and progressive integration. <em>NEUCOM</em>, <em>610</em>,
128607. (<a href="https://doi.org/10.1016/j.neucom.2024.128607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image manipulation localization aims at distinguishing forged regions from the whole test image. Though many outstanding prior arts have been proposed for this task, there are still two issues that need to be further studied: (1) how to fuse diverse types of features with forgery clues; (2) how to progressively integrate multistage features for better localization performance. In this paper, we propose a tripartite progressive integration network (TriPINet) for end-to-end image manipulation localization. First, we extract both visual perception information, e.g., RGB input images, and visual imperceptible features, e.g., frequency and noise traces for forensic feature learning. Second, we develop a guided cross-modality dual-attention (gCMDA) module to fuse different types of forged clues. Third, we design a set of progressive integration squeeze-and-excitation (PI-SE) modules to improve localization performance by appropriately incorporating multiscale features in the decoder. Extensive experiments are conducted to compare our method with state-of-the-art image forensics approaches. The proposed TriPINet obtains competitive results on several benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Xiao Jin and Wen Yu and Wei Shi},
  doi          = {10.1016/j.neucom.2024.128607},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128607},
  shortjournal = {Neurocomputing},
  title        = {Image manipulation localization via dynamic cross-modality fusion and progressive integration},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MFFGD: An adaptive caputo fractional-order gradient
algorithm for DNN. <em>NEUCOM</em>, <em>610</em>, 128606. (<a
href="https://doi.org/10.1016/j.neucom.2024.128606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a primary optimization method for neural networks, gradient descent algorithm has received significant attention in the recent development of deep neural networks. However, current gradient descent algorithms still suffer from drawbacks such as an excess of hyperparameters, getting stuck in local optima, and poor generalization. This paper introduces a novel Caputo fractional-order gradient descent (MFFGD) algorithm to address these limitations. It provides fractional-order gradient derivation and error analysis for different activation functions and loss functions within the network, simplifying the computation of traditional fractional order gradients. Additionally, by introducing a memory factor to record past gradient variations, MFFGD achieves adaptive adjustment capabilities. Comparative experiments were conducted on multiple sets of datasets with different modalities, and the results, along with theoretical analysis, demonstrate the superiority of MFFGD over other optimizers.},
  archive      = {J_NEUCOM},
  author       = {Zhuo Huang and Shuhua Mao and Yingjie Yang},
  doi          = {10.1016/j.neucom.2024.128606},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128606},
  shortjournal = {Neurocomputing},
  title        = {MFFGD: An adaptive caputo fractional-order gradient algorithm for DNN},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cycle-consistent adversarial chest x-rays domain adaptation
for pneumonia diagnosis. <em>NEUCOM</em>, <em>610</em>, 128604. (<a
href="https://doi.org/10.1016/j.neucom.2024.128604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To deal with the challenge of limited annotated data for training target domain pneumonia classifier, domain adaptation methods leverage publicly available source dataset to enhance performance on the target domain. However, the existing methods lack effective feature representation to ensure a significant similarity between the source domain and the target domain. To address this problem, we propose a novel method, called C ycle- C onsistent A dversarial chest X-rays D omain A daptation (C2ADA) to diagnose pneumonia from Chest X-rays automatically, which can transfer knowledge from a publicly available large-scale source dataset to the small-scale target dataset and achieve high performance with fewer target domain samples. Specifically, C2ADA introduces the cycle-consistent adversarial module to enforce the feature extractor to learn domain-invariant features. Furthermore, unlike most existing domain adaptation methods that deal with the same tasks in the source domain and target domain, our perspective is that heterogeneous tasks can assist the target domain in learning more effectively. Therefore, C2ADA includes two subnetworks, one is for the source domain, which contains a multilabel classification task, and the other is for the target domain, which focuses on the binary classification task. To assess the effectiveness of our method, we conduct a comparative analysis with other domain adaptation approaches. The experimental results show that the proposed method can achieve 96.86% accuracy on the ChestXRay2017 dataset utilizing just 50 images.},
  archive      = {J_NEUCOM},
  author       = {Yue Zhou and Xiaoqiang Li and Yuanchen Wu},
  doi          = {10.1016/j.neucom.2024.128604},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128604},
  shortjournal = {Neurocomputing},
  title        = {Cycle-consistent adversarial chest X-rays domain adaptation for pneumonia diagnosis},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Formation control and lag formation control for
human–machine interaction second-order multiagent systems.
<em>NEUCOM</em>, <em>610</em>, 128603. (<a
href="https://doi.org/10.1016/j.neucom.2024.128603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the formation control and lag formation control problems for second-order multiagent systems (MASs) with and without nonlinear intrinsic dynamics are discussed, in which a fraction of agents are controlled by humans and the others are free from human intervention. By selecting suitable control protocol and Lyapunov functional, a formation criterion for the second-order nonlinear MAS is derived. Furthermore, considering that time delay always exists between agent and virtual leader due to finite transmission speed, a lag formation criterion for the second-order nonlinear MAS is also obtained by selecting appropriate control strategy. In addition, the above obtained results are further extend to the double-integrator MAS. Finally, the devised control strategies are verified by exploiting two numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Kun Ling and Jin-Liang Wang and Xiao Han and Xueming Dong},
  doi          = {10.1016/j.neucom.2024.128603},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128603},
  shortjournal = {Neurocomputing},
  title        = {Formation control and lag formation control for human–machine interaction second-order multiagent systems},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identification of hamiltonian systems using neural networks
and first integrals approaches. <em>NEUCOM</em>, <em>610</em>, 128602.
(<a href="https://doi.org/10.1016/j.neucom.2024.128602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research introduces a class of non-parametric identifiers based on differential neural networks represented by Hamiltonian dynamics. The structure of the identifier corresponds to the form of a canonical Hamiltonian system that uses the evolution of generalized coordinates and momentums. The learning laws of the identifier come from applying the first integrals approach, which justifies the design of an exact identifier considering the time invariance of the Hamiltonian, with a finite number of activation functions in the identifier structure. The first integrals approach derives several learning laws for the proposed class of identifiers. The learning laws design uses the estimated derivative of the generalized momentum assessed via a super-twisting differentiator with multiple inputs and outputs. All proposed laws require the solution of differential continuous-time Riccati equations and nonlinear differential equations for the learning laws, which depend on the identification error and state constraints. The developed identifier was evaluated compared to an identifier that did not consider the Hamiltonian constraint using first integrals. This comparison included a numerical evaluation of the identifier considering its application to a classical Hamiltonian system associated with the Kepler dynamics representing satellite orbital evolution. This evaluation confirmed that the identification results were improved with the proposed learning laws regarding the class of Hamiltonian structures, and the quality indicators based on the mean square error were several times lower.},
  archive      = {J_NEUCOM},
  author       = {Ilya Nachevsky and Isaac Chairez and Olga Andrianova},
  doi          = {10.1016/j.neucom.2024.128602},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128602},
  shortjournal = {Neurocomputing},
  title        = {Identification of hamiltonian systems using neural networks and first integrals approaches},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Security containment control for nonlinear MASs under DOS
attacks: An improved adaptive method. <em>NEUCOM</em>, <em>610</em>,
128601. (<a href="https://doi.org/10.1016/j.neucom.2024.128601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the security containment control problem of nonlinear multi-agent systems (NMASs) subjected to denial of service (DOS) attacks based on an improved adaptive control protocol. During the attack, communication between the agents is completely disrupted. To compensate the control signals during attacks and mitigate the damage to the system caused by the attack, an attack compensation system for each follower is devised based on the last successful received neighbor information. According to the estimated information of neighbors, a novel adaptive control protocol with exponential term is proposed for both attack periods and normal communication periods, respectively, and the sufficient condition achieving consensus of NMASs under DOS attack is derived. Compared to some related works in this field, the designed adaptive control protocol not only improves the dynamic performance of system during long-time attack, but also greatly reduces the conservatism of the convergence bound for error system. Finally, the theoretical results are confirmed through a numerical example.},
  archive      = {J_NEUCOM},
  author       = {Yapeng Yang and Zhanshan Wang and Wanli Jin},
  doi          = {10.1016/j.neucom.2024.128601},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128601},
  shortjournal = {Neurocomputing},
  title        = {Security containment control for nonlinear MASs under DOS attacks: An improved adaptive method},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time contractive stability for fractional-order
nonlinear systems with delayed impulses: Applications to neural
networks. <em>NEUCOM</em>, <em>610</em>, 128599. (<a
href="https://doi.org/10.1016/j.neucom.2024.128599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with finite-time stability (FTS) and finite-time contractive stability (FTCS) criteria of fractional-order nonlinear systems (FONSs), where the state of the systems consists of a finite number of delayed impulsive instants. To achieve these results, we have extended the theories on FTS and FTCS criteria from integer-order NSs to fractional-order systems. Employing the fractional-order Lyapunov stability theory, the sufficient conditions of the above-mentioned stability criteria are derived for a class of FONSs with state-dependent delayed impulses. Then, to ensure the applicability of the proposed results, we have analyzed the desired performances for several neural network (NN) models, such as non-autonomous NNs (NANNs), Cohen–Grossberg NNs (CGNNs), switched NNs (SNNs) and bidirectional associative memory NNs (BAMNNs). Finally, four representative numerical examples are illustrated to demonstrate the assurance of the obtained stability conditions of the respective state-dependent impulsive fractional-order NNs (FONNs).},
  archive      = {J_NEUCOM},
  author       = {P. Gokul and G. Soundararajan and Ardak Kashkynbayev and R. Rakkiyappan},
  doi          = {10.1016/j.neucom.2024.128599},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128599},
  shortjournal = {Neurocomputing},
  title        = {Finite-time contractive stability for fractional-order nonlinear systems with delayed impulses: Applications to neural networks},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing the utilization of uncertain pixels in
semi-supervised semantic segmentation. <em>NEUCOM</em>, <em>610</em>,
128598. (<a href="https://doi.org/10.1016/j.neucom.2024.128598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In semi-supervised semantic segmentation, determining the correct label for uncertain pixels is crucial yet challenging. The recently proposed virtual category (VC) learning achieves excellent performance by creating a potential category (PC) set to exploit the valuable part of the uncertain pixels effectively. However, the potential category set in the existing method is not accurate enough at the beginning of iterations, which could lead to less accurate segmentation results. To better utilize uncertain pixels, we propose to improve the strategy of constructing the potential category set. Specifically, we adjust the threshold based on the model’s optimization status and split the pseudo-labels into low/high-confidence areas to create a more appropriate PC set. At the same time, due to uncertainty in boundary pixels, it is challenging to achieve precise object segmentation, and there is currently no method available to optimize these areas in semi-supervised segmentation tasks. Therefore, we propose a entropy-based method to identify boundary areas and design a novel boundary refinement network to process labeled and unlabeled data separately to optimize segmentation. The experimental results demonstrate that our proposed method excels in accurately segmenting the boundary areas of the targets. Furthermore, it achieves state-of-the-art semi-supervised segmentation on the Pascal VOC and Cityscapes datasets.},
  archive      = {J_NEUCOM},
  author       = {Xingfang Chang and Changrui Chen and Caifeng Shan},
  doi          = {10.1016/j.neucom.2024.128598},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128598},
  shortjournal = {Neurocomputing},
  title        = {Enhancing the utilization of uncertain pixels in semi-supervised semantic segmentation},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A thermophysical mechanism exploration of the brain: Motor
cortex modeling with canonical ensemble theory. <em>NEUCOM</em>,
<em>610</em>, 128597. (<a
href="https://doi.org/10.1016/j.neucom.2024.128597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The brain, recognized as one of the most intricate systems globally, has been a focal point for scientific exploration. Researchers have made efforts to construct models of the brain based on neural dynamics and complex networks to gain insights into its workings. It is crucial to investigate the brain&#39;s working principles from various perspectives. This study presents a novel thermophysical model of the motor cortex and examines its potential thermodynamic properties. Utilizing canonical ensemble theory, we constructed the thermophysical model using spike and local field potential (LFP) signals obtained from intracortical brain-machine-interfaces (iBMIs) in two monkeys. The parameters derived from this model—namely internal energy, free energy, and entropy—were employed to assess the thermodynamic properties and observe alterations in these properties during reaching and grasping movements. Furthermore, this proposed model was applied to movement pattern decoding, highlighting its potential in neural decoding tasks. In both LFP- and spike-based thermodynamic models, there was an increase in internal energy and free energy, coupled with a decrease in entropy when the motor cortex was activated across various movement tasks. This suggests that the neural system adheres to the principles of a thermophysical system. Notably, the thermodynamic features demonstrated superior performance in decoding movement intentions compared to traditional LFP and spike features. This study represents the first construction of a comprehensive thermodynamic model of the motor cortex based on LFP and spike signals. The model exhibits remarkable stationarity and holds promise for long-term and stable evaluations of motor cortex functions.},
  archive      = {J_NEUCOM},
  author       = {Wei Li and Chenxi Zhou and Xi Chen and Haodong Mao and Jiping He and Qiang Li and Peng Zhang},
  doi          = {10.1016/j.neucom.2024.128597},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128597},
  shortjournal = {Neurocomputing},
  title        = {A thermophysical mechanism exploration of the brain: Motor cortex modeling with canonical ensemble theory},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Group-feature (sensor) selection with controlled redundancy
using neural networks. <em>NEUCOM</em>, <em>610</em>, 128596. (<a
href="https://doi.org/10.1016/j.neucom.2024.128596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a novel embedded feature selection method based on a Multi-layer Perceptron (MLP) network and generalize it for group-feature or sensor selection problems, which can control the level of redundancy among the selected features or groups and it is computationally more efficient than the existing ones in the literature. Additionally, we have generalized the group lasso penalty for feature selection to encompass a mechanism for selecting valuable groups of features while simultaneously maintaining control over redundancy. We establish the monotonicity and convergence of the proposed algorithm, with a smoothed version of the penalty terms, under suitable assumptions. The effectiveness of the proposed method for both feature selection and group feature selection is validated through experimental results on various benchmark datasets. The performance of the proposed methods is compared with some state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Aytijhya Saha and Nikhil R. Pal},
  doi          = {10.1016/j.neucom.2024.128596},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128596},
  shortjournal = {Neurocomputing},
  title        = {Group-feature (Sensor) selection with controlled redundancy using neural networks},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive denoising graph contrastive learning with memory
graph attention for recommendation. <em>NEUCOM</em>, <em>610</em>,
128595. (<a href="https://doi.org/10.1016/j.neucom.2024.128595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning has emerged as a powerful technique for dealing with graph noise and mining latent information in networks, that has been widely applied in GNN-based collaborative filtering. Traditional graph contrastive learning methods commonly generate multiple augmented views, and then learn node representations by maximizing the consistency between these views. However, on one hand, manual view construction methods necessitate expert knowledge and a trial-and-error process. On the other hand, adaptive view construction methods require decoders which results in increased training costs. To address the aforementioned limitations, in this paper, we propose the Adaptive Denoising Graph Contrastive Learning with Memory Graph Attention for Recommendation (ADGA) framework. Firstly, we introduce the memory graph attention mechanism to capture node attention during multi-hop information aggregation. Then, unlike previous methods that required additional node representations to generate views, ADGA proposes, for the first time, directly using attention to adaptively generate structure-aware contrastive learning views. It reduces the training cost of the model and improves the cross-view consistency of node representations, that offers a new paradigm for adaptive graph contrastive learning. Experimental results on three real-world datasets demonstrate that ADGA achieves state-of-the-art performance in recommendation tasks. The code is available at https://github.com/Andrewsama/ADGA .},
  archive      = {J_NEUCOM},
  author       = {Gang-Feng Ma and Xu-Hua Yang and Liang-Yu Gao and Ling-Hang Lian},
  doi          = {10.1016/j.neucom.2024.128595},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128595},
  shortjournal = {Neurocomputing},
  title        = {Adaptive denoising graph contrastive learning with memory graph attention for recommendation},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive sliding mode control using a novel fully feedback
recurrent neural network for quad-rotor UAVs. <em>NEUCOM</em>,
<em>610</em>, 128592. (<a
href="https://doi.org/10.1016/j.neucom.2024.128592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel full feedback recurrent neural network (FFRNN) based integral sliding mode control (SMC) strategy is proposed for the altitude and attitude control problem of quad-rotor unmanned aerial vehicles (UAVs). The proposed method ensures fast convergence of the sliding surface as well as asymptotic convergence of the system state. Due to the high degree of the uncertainties of parameters for the quad-rotor UAV, it is very difficult to establish its accurate dynamic model. Therefore, the novel FFRNN structure is used to approximate the model uncertainty. The FFRNN has two hidden layers, and every hidden layer receives feedback signals from the next layer, which enhances its approximation power. Since this new structure combines the advantages of the inner/outer feedback neural network, more information can be saved inside the neural network, and the newly designed FFRNN has better approximation capacity, higher accuracy and faster network training speed than the neural networks without feedback loop and the single feedback loop neural network. Lyapunov stability theory is used to ensure the stability of the whole system, and then the real-time adaptive laws of FFRNN weights are derived. To validate the efficacy of the proposed approach, a comparative analysis is conducted between FFRNN and two other neural network models, namely radial basis function (RBF) neural network and double loop recurrent neural network (DLRNN), during the experiment. Simulation results indicate that the proposed integral sliding mode controller based on FFRNN has a better control performance, approximation performance and stability compared to sliding mode controller based on RBF and DLRNN.},
  archive      = {J_NEUCOM},
  author       = {Jixun Li and Zhanshan Zhao and Xinghao Qin},
  doi          = {10.1016/j.neucom.2024.128592},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128592},
  shortjournal = {Neurocomputing},
  title        = {Adaptive sliding mode control using a novel fully feedback recurrent neural network for quad-rotor UAVs},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the influence of input triggering on the dynamics of the
jansen–rit oscillators network. <em>NEUCOM</em>, <em>610</em>, 128590.
(<a href="https://doi.org/10.1016/j.neucom.2024.128590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our investigation delves into the intricate dynamical properties of a network of coupled neural oscillators, each comprising identical Jansen–Rit masses. The connections between these nodes follow the renowned Watts–Strogatz topology. Every node receives inputs from two primary sources: external and internal inputs derived from its neighboring nodes’ outputs. In this paper, we aim to explore the consequences of changing these two inputs and analyze the results generated. To begin with, we analyzed the model using the mean-field approximation, assuming identical outputs across all nodes due to identical internal and external inputs. Subsequently, we relaxed this assumption, and a more detailed analysis of both states is discussed. As a result of the mean-field approach, we observed that there was no phase transition, despite apparent changes in behavior. However, the relaxation of the mean-field assumption led to the occurrence of the first (discontinuous) and second (continuous) phase transitions. Moreover, our findings indicate that by relaxing the mean-field assumption in our analysis of the single Jansen–Rit neural mass model, theta waves can be generated. Our study provides a comprehensive examination of various observed behaviors by the model, including transitions between synchrony and asynchrony. Additionally, our work highlights the potential contribution of external and internal inputs in studying phase transition and synchronization of neural mass models. Overall, our investigation sheds light on the intricate dynamics of coupled neural oscillators and their sensitivity to varying inputs.},
  archive      = {J_NEUCOM},
  author       = {Sheida Kazemi and Yousef Jamali},
  doi          = {10.1016/j.neucom.2024.128590},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128590},
  shortjournal = {Neurocomputing},
  title        = {On the influence of input triggering on the dynamics of the Jansen–Rit oscillators network},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consistency-constrained unsupervised video anomaly detection
framework based on co-teaching. <em>NEUCOM</em>, <em>610</em>, 128589.
(<a href="https://doi.org/10.1016/j.neucom.2024.128589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent video surveillance continues to be a vibrant research domain within the field of computer vision. However, existing representation learning frameworks primarily focus on static information extraction frame by frame such as appearance features, they often overlook the valuable dynamic information like optical flow feature inherent in the video data, which is most essential characteristics of sequence data. To mining dynamic features and bridge this gap, our paper introduces a novel anomaly detection framework that balance dynamic information with static information and construct a relationship between appearance features and corresponding optical flow features, where we sets strong consistency constraints, which reduce the loss between dynamic information and corresponding static information, and we leverages collaborative teaching network to ensure a consistent representation of both static and dynamic information for predict. The proposed framework consists of two sets of encoder–decoder pairs complemented by a memory storage module. Operating in parallel with the dual encoder network is a Co-teaching network, with the shared memory module serving as the cornerstone for collaborative training. The Consistency constrained condition guarantees the strong consistency of dynamic and static information in the learned representations. In our experimental phase, we present compelling results that showcase the superior performance of our algorithm across three publicly available datasets.},
  archive      = {J_NEUCOM},
  author       = {Wenhao shao and Praboda Rajapaksha and Noel Crespi and Xuechen Zhao and Mengzhu Wang and Nan Yin and Xinwang Liu and Zhigang Luo},
  doi          = {10.1016/j.neucom.2024.128589},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128589},
  shortjournal = {Neurocomputing},
  title        = {Consistency-constrained unsupervised video anomaly detection framework based on co-teaching},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). MeST-former: Motion-enhanced spatiotemporal transformer for
generalizable deepfake detection. <em>NEUCOM</em>, <em>610</em>, 128588.
(<a href="https://doi.org/10.1016/j.neucom.2024.128588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of Deepfake technology has sparked significant concerns due to its potential for misuse and malicious manipulation of multimedia content. Various detection approaches aimed at detecting Deepfake videos have been proposed, mostly relying on the identification of spatial and temporal artifacts. However, due to the different contexts of source images and the variety of generation techniques, current Deepfake detection methods usually perform well on training datasets, and yet generalize poorly to those unseen identities in new datasets. This issue is widely known as the generalization challenge of Deepfake detection. To address this challenge, this paper proposes an advanced spatiotemporal Deepfake video detector, named M otion- e nhanced S patiotemporal T ransformer (MeST-Former). MeST-Former is based on the spatiotemporal modeling capacity of the video Swin Transformer. The spatial and temporal features are obtained from the RGB and motion images, respectively. To enhance the generalization ability of MeST-Former to unseen identities in unseen datasets, the ID-related components in the spatial and temporal features are detached. Specifically, MeST-Former adopts the newly proposed Identity-Decoupling Attention (IDC-Att) module to disentangle the ID-related and ID-unrelated components. Only the ID-unrelated components are used to construct more generalizable spatiotemporal representations. This process makes the constructed spatiotemporal features identity-agnostic and more generalizable to unseen identities. We conducted extensive experiments to evaluate the performance of the MeST-Former. Our results indicate that MeST-Former achieves accurate and generalizable Deepfake detection performance. Notably, MeST-Former also demonstrates high efficacy in detecting AI-animated talking-head videos.},
  archive      = {J_NEUCOM},
  author       = {Baoping Liu and Bo Liu and Ming Ding and Tianqing Zhu},
  doi          = {10.1016/j.neucom.2024.128588},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128588},
  shortjournal = {Neurocomputing},
  title        = {MeST-former: Motion-enhanced spatiotemporal transformer for generalizable deepfake detection},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust filter pruning guided by deep frequency-features for
edge intelligence. <em>NEUCOM</em>, <em>610</em>, 128586. (<a
href="https://doi.org/10.1016/j.neucom.2024.128586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularity of mobile applications, smart terminals require the deployment of lightweight deep neural networks (DNNs). However, those lightweight DNNs deployed on resource-constrained edge devices, have serious security vulnerabilities to adversarial examples. Pruning methods have been widely used to obtain lightweight DNNs, which mainly focus on improving classification accuracy, but ignore robustness. To this end, we present a Fourier space-based robust pruning algorithm (FSRP). We find that a robust network pays more attention to the low-frequency region of the adversarial examples’ feature maps, but ignores the high-frequency region. According to this finding, we design a filter robust indicator, a ratio of low-frequency components to high-frequency components of the feature map, to guide the pruning process. With this new robust pruning criterion, we adopt a strategy of local pruning that removes the filters with low robustness layer by layer in the model. Extensive experiments on CIFAR10/CIFAR100 and ImageNet show that the robust pruning accuracy is significantly improved under the FSRP robust pruning criterion. On CIFAR10, a pruning ratio of 90% on the VGG16 network still shows a 14.1% improvement in robust accuracy under auto attacks (AA).},
  archive      = {J_NEUCOM},
  author       = {Yaguan Qian and Wenzhuo Huang and Qinqin Yu and Tengteng Yao and Xiang Ling and Bin Wang and Zhaoquan Gu and Yanchun Zhang},
  doi          = {10.1016/j.neucom.2024.128586},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128586},
  shortjournal = {Neurocomputing},
  title        = {Robust filter pruning guided by deep frequency-features for edge intelligence},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BRAVE: A cascaded generative model with sample attention for
robust few shot image classification. <em>NEUCOM</em>, <em>610</em>,
128585. (<a href="https://doi.org/10.1016/j.neucom.2024.128585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning (FSL) confronts notable challenges due to the disparity between training and testing categories, leading to channel bias in neural networks and hindering accurate feature discernment. To address this, we introduce Biased-Reduction Attentive Network (BRAVE), an innovative model that incorporates a refined Vector Quantized Variational Autoencoder (VQ-VAE) backbone, enhanced with our Diverse Quantization (DQ) Module, for unbiased, fine-grained feature creation. Alongside, our Sample Attention (SA) Module is utilized for extracting discriminative features from these unbiased, fine-grained features. The DQ Module in BRAVE strategically integrates prior distribution regularization and stochastic masking with Gumbel sampling for balanced and diverse codebook engagement, while the SA Module leverages inter-sample dynamics for identifying critical features. This synergy effectively counters channel bias and boosts classification accuracy in FSL setups, surpassing current leading methods. Our approach represents a practical balance between preserving detailed features through the decoder and ensuring classification effectiveness, marking a significant advance in FSL. BRAVE’s implementation is accessible for community use and further exploration. Code and models available at https://github.com/ApocalypsezZ/BRAVE .},
  archive      = {J_NEUCOM},
  author       = {Huayi Ji and Linkai Luo and Hong Peng},
  doi          = {10.1016/j.neucom.2024.128585},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128585},
  shortjournal = {Neurocomputing},
  title        = {BRAVE: A cascaded generative model with sample attention for robust few shot image classification},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive qualitative and quantitative survey on image
dehazing based on deep neural networks. <em>NEUCOM</em>, <em>610</em>,
128582. (<a href="https://doi.org/10.1016/j.neucom.2024.128582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image dehazing has become a necessary area of research with the increasing popularity and demand of computer vision systems. Image dehazing is a method to remove haze from an image to improve its visual quality. Dehazing techniques are widely employed in a variety of computer vision applications to enhance their overall performance. Many techniques have been proposed by researchers in recent years to eliminate the haze from an image. However, there is a lack of available literature that provides a summary of deep learning-based state-of-the-art image dehazing methods. In this study, we provide a detailed review of recently proposed image dehazing techniques based on deep neural networks such as CNN, GAN, RNN, RCNN, and Transformer. A concise review of significant applications of image dehazing, benchmark datasets, and various performance metrics are also presented. We compare the state-of-the-art methods quantitatively using performance evaluation metrics such as SSIM and PSNR. Finally, this study discusses the fundamental difficulties associated with image dehazing approaches that need to be further explored.},
  archive      = {J_NEUCOM},
  author       = {Pulkit Dwivedi and Soumendu Chakraborty},
  doi          = {10.1016/j.neucom.2024.128582},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128582},
  shortjournal = {Neurocomputing},
  title        = {A comprehensive qualitative and quantitative survey on image dehazing based on deep neural networks},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time passivity of multi-weighted coupled neural
networks with directed topologies and time-varying delay.
<em>NEUCOM</em>, <em>610</em>, 128581. (<a
href="https://doi.org/10.1016/j.neucom.2024.128581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the finite-time passivity (FTP) problem for multi-weighted coupled neural networks (MWCNNs) with directed topologies and time-varying delay is discussed. Firstly, by designing a new state feedback controller, several FTP criteria are given for the considered network. Then, some finite-time synchronization (FTS) criteria are established by employing the FTP results. Secondly, a hybrid impulsive and state feedback controller is first designed, under which different FTP and FTS criteria are presented and the synchronization time is successfully shortened compared to the non-hybrid controller without impulses. Finally, numerical simulations are given to show the effectiveness and superiority of the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Huining Nie and Yu Zhang and Jitao Sun},
  doi          = {10.1016/j.neucom.2024.128581},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128581},
  shortjournal = {Neurocomputing},
  title        = {Finite-time passivity of multi-weighted coupled neural networks with directed topologies and time-varying delay},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Zero-shot text classification with knowledge resources under
label-fully-unseen setting. <em>NEUCOM</em>, <em>610</em>, 128580. (<a
href="https://doi.org/10.1016/j.neucom.2024.128580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification techniques are at the heart of many real-world applications, e.g. sentiment analysis, recommender systems and automatic text annotation, to process and analyse large-scale textual data in multiple fields. However, the effectiveness of natural language processing models can only be confirmed when a large amount of up-to-date training data is available. An unprecedented amount of data is continuously created, and new topics are introduced, making it less likely or even infeasible to collect labelled samples covering all topics for training models. We attempt to study the extreme case: there is no labelled data for model training, and the model, without being adapted to any specific dataset, will be directly applied to the testing samples. We propose a transformer-based framework to encode sentences in a contextualised way and leverage the existing knowledge resources, i.e. ConceptNet and WordNet, to integrate both descriptive and structural knowledge for better performance. To enhance the robustness of the model, we design an adversarial example generator based on relations from external knowledge bases. The framework is evaluated on both general and specific domain text classification datasets. Results show that the proposed framework can outperform the existing competitive state-of-the-art baselines, delivering new benchmark results.},
  archive      = {J_NEUCOM},
  author       = {Yuqi Wang and Wei Wang and Qi Chen and Kaizhu Huang and Anh Nguyen and Suparna De},
  doi          = {10.1016/j.neucom.2024.128580},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128580},
  shortjournal = {Neurocomputing},
  title        = {Zero-shot text classification with knowledge resources under label-fully-unseen setting},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bipartite consensus of concatenated opinion dynamics for two
antagonistic groups: A game theoretical perspective. <em>NEUCOM</em>,
<em>610</em>, 128578. (<a
href="https://doi.org/10.1016/j.neucom.2024.128578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent decades have witnessed a significant surge in scholarly attention towards formulating dynamic models for opinion formation on social networks. This paper considers the bipartite consensus problem over a series of issues for two antagonistic groups wherein two graphs are employed to model the interaction within groups and a noncooperative game to describe the interaction between groups. Firstly, we prove that the noncooperative game admits the unique Nash equilibrium. Secondly, we give sufficient conditions for achieving a bipartite consensus that both graphs are strongly connected. Additionally, we obtain that the game’s mechanism decides the convergence rate of bipartite consensus from one issue to the next. It is important to highlight that confrontation is key in elevating the most influential individuals to leadership positions within their groups. Thirdly, we construct the bipartite consensus state for a particular case where the networks of two groups are balanced. Finally, we present two examples to demonstrate the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Jiamei Li and Yilun Shang and Wenshuai Wang and Jingying Ma},
  doi          = {10.1016/j.neucom.2024.128578},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128578},
  shortjournal = {Neurocomputing},
  title        = {Bipartite consensus of concatenated opinion dynamics for two antagonistic groups: A game theoretical perspective},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning in motor imagery EEG signal decoding: A
systematic review. <em>NEUCOM</em>, <em>610</em>, 128577. (<a
href="https://doi.org/10.1016/j.neucom.2024.128577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to the fast evolution of electroencephalography (EEG)-based brain–computer interfaces (BCIs) and computing technologies, as well as the availability of large EEG datasets, decoding motor imagery (MI) EEG signals is rapidly shifting from traditional machine learning (ML) to deep learning (DL) approaches. Furthermore, real-world MI-EEG BCI applications are progressively requiring higher generalization capabilities, which can be achieved by leveraging publicly available MI-EEG datasets and high-performance decoding models. Within this context, this paper provides a systematic review of DL approaches for MI-EEG decoding, focusing on studies that work on publicly available EEG-MI datasets. This review paper firstly provides a clear overview of these datasets that can be used for DL model training and testing. Afterwards, considering each dataset, related DL studies are discussed with respect to the four decoding paradigms identified in the literature, i.e., subject-dependent, subject-independent, transfer learning, and global decoding paradigms. Having analyzed the reviewed studies, the current trends and strategies, popular architectures, baseline models that are used for comprehensive analysis, and techniques to ensure reproducibility of the results in DL-based MI-EEG decoding are also identified and discussed. The selection and screening of the studies included in this review follow the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, leading to a comprehensive analysis of 394 papers published between January 1, 2017, and January 23, 2023.},
  archive      = {J_NEUCOM},
  author       = {Aurora Saibene and Hafez Ghaemi and Eda Dagdevir},
  doi          = {10.1016/j.neucom.2024.128577},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128577},
  shortjournal = {Neurocomputing},
  title        = {Deep learning in motor imagery EEG signal decoding: A systematic review},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mask-guided BERT for few-shot text classification.
<em>NEUCOM</em>, <em>610</em>, 128576. (<a
href="https://doi.org/10.1016/j.neucom.2024.128576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based language models have achieved significant success in various domains. However, the data-intensive nature of the transformer architecture requires much labeled data, which is challenging in low-resource scenarios (i.e., few-shot learning (FSL)). The main challenge of FSL is the difficulty of training robust models on small amounts of samples, which frequently leads to overfitting. Here we present Mask-BERT, a simple and modular framework to help BERT-based architectures tackle FSL. The proposed approach fundamentally differs from existing FSL strategies such as prompt tuning and meta-learning. The core idea is to selectively apply masks on text inputs and filter out irrelevant information, which guides the model to focus on discriminative tokens that influence prediction results. In addition, to make the text representations from different categories more separable and the text representations from the same category more compact, we introduce a contrastive learning loss function. Experimental results on open-domain and medical-domain datasets demonstrate the effectiveness of Mask-BERT. Code and data are available at: github.com/WenxiongLiao/mask-bert},
  archive      = {J_NEUCOM},
  author       = {Wenxiong Liao and Zhengliang Liu and Haixing Dai and Zihao Wu and Yiyang Zhang and Xiaoke Huang and Yuzhong Chen and Xi Jiang and David Liu and Dajiang Zhu and Sheng Li and Wei Liu and Tianming Liu and Quanzheng Li and Hongmin Cai and Xiang Li},
  doi          = {10.1016/j.neucom.2024.128576},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128576},
  shortjournal = {Neurocomputing},
  title        = {Mask-guided BERT for few-shot text classification},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SDD-net: Soldering defect detection network for printed
circuit boards. <em>NEUCOM</em>, <em>610</em>, 128575. (<a
href="https://doi.org/10.1016/j.neucom.2024.128575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid detection of soldering defects in printed circuit boards (PCBs) is crucial and a challenge for quality control. Thus, a novel soldering defect detection network (SDD-Net) is proposed based on improvements in YOLOv7-tiny. A fast spatial pyramid pooling block integrating a cross-stage partial network is designed to expand the receptive field and feature extraction ability of the model. A hybrid combination attention mechanism is proposed to boost feature representation. A residual feature pyramid network is subsequently presented to reinforce the capability of multilevel feature fusion to overcome the scale variance issue in PCB soldering defects. Finally, efficient intersection over union loss is applied for bounding box regression to accelerate model convergence while improving localisation precision. SDD-Net achieves a stunning mean average precision of 99.1% on the dataset, producing a 1.8% increase compared with the baseline. The detection speed is boosted to 102 frames/s for input images of 640 × 640 pixels using a mediocre processor. In addition, SDD-Net exhibits outstanding generalisation ability in two public surface defect datasets.},
  archive      = {J_NEUCOM},
  author       = {Qin Ling and Nor Ashidi Mat Isa and Mohd Shahrimie Mohd Asaari},
  doi          = {10.1016/j.neucom.2024.128575},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128575},
  shortjournal = {Neurocomputing},
  title        = {SDD-net: Soldering defect detection network for printed circuit boards},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). No-reference quality evaluation of realistic hazy images via
singular value decomposition. <em>NEUCOM</em>, <em>610</em>, 128574. (<a
href="https://doi.org/10.1016/j.neucom.2024.128574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Haze is one of the atmospheric image degradations that causes severe distortions to outdoor images such as low contrast, color shift, and structure damage. Due to the unique physical characteristics of haze, the quality of hazy images is not accurately assessed using general-purpose image quality assessment (IQA) approaches. Therefore, several haze-aware IQA approaches have been proposed to provide more efficient dehazing quality evaluation. These approaches extract several haze-aware features to be either combined to form a single IQA metric or fed to a regression model that predicts the dehazing quality. However, these haze-relevant features are extracted using pixel intensity, in which luminance and structure information are inseparable, leading to less correlation between such features and the type of degradation they are supposed to represent. To address this issue, we propose a singular value decomposition (SVD) based IQA metric that can effectively separate the luminance component of an image from structure. This separation offers the ability to accurately evaluate the degradation at two different levels i.e. luminance and structure. The experimental results show that our proposed SVD-based dehazing quality evaluator (SDQE) outperforms the existing state-of-the-art non-reference IQA metrics in terms of accuracy and processing time.},
  archive      = {J_NEUCOM},
  author       = {Ibrahim Kajo and Abderrazak Chahi and Mohamed Kas and Yassine Ruichek},
  doi          = {10.1016/j.neucom.2024.128574},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128574},
  shortjournal = {Neurocomputing},
  title        = {No-reference quality evaluation of realistic hazy images via singular value decomposition},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging denoising diffusion probabilistic model to
improve the multi-thickness CT segmentation. <em>NEUCOM</em>,
<em>610</em>, 128573. (<a
href="https://doi.org/10.1016/j.neucom.2024.128573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organs-at-risk (OARs) segmentation in computed tomography (CT) is a fundamental step in the radiotherapy workflow, which has been prone as a time-consuming and labor-intensive task. Deep neural networks (DNNs) have gained significant popularity in the field of OAR segmentation tasks, achieving remarkable progress in clinical practice. Typically, OARs are distributed throughout different areas of the body and require varying thicknesses of CT scans for better diagnosis and segmentation in clinical. Most DNN-based segmentation focuses on single-thickness CT scans, limiting their applicability to varying thicknesses due to a lack of diverse thickness-related feature learning. While pre-training with the denoising diffusion probabilistic model (DDPM) offers an effective solution for dense feature learning, current works are constrained in addressing feature diversity, as exemplified by scenarios such as multi-thickness CT. To address the above challenges, this paper introduces a novel pre-training approach called DiffMT. This approach leverages the DDPM to extract valuable features from multi-thickness CT images. By transferring the pre-trained DDPM to the downstream segmentation for fine-tuning, the model gains proficiency in learning diverse multi-thickness CT features, leading to precise segmentation across varied thicknesses. We explore DiffMT’s feature learning capacity through experiments involving pre-trained models of varying sizes and different denoising thicknesses. Subsequently, thorough experiments comparing DDPM-based segmentation with other state-of-the-art (SOTA) CT segmentation methods, along with assessments on diverse OARs and modalities, empirically demonstrate that the proposed DiffMT method outperforms the control methods. The codes are available at https://github.com/ychengrong/DiffMT .},
  archive      = {J_NEUCOM},
  author       = {Chengrong Yu and Ying Song and Qiang Wang and Shengqian Zhu and Zhang Yi and Junjie Hu},
  doi          = {10.1016/j.neucom.2024.128573},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128573},
  shortjournal = {Neurocomputing},
  title        = {Leveraging denoising diffusion probabilistic model to improve the multi-thickness CT segmentation},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hyperspectral anomaly detection based on weighted low-rank
sparse dictionary learning. <em>NEUCOM</em>, <em>610</em>, 128572. (<a
href="https://doi.org/10.1016/j.neucom.2024.128572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The geometric model-based hyperspectral anomaly detection techniques have garnered a lot of interest recently. These methods are predicated on the assumption that the background can be represented by a dictionary of spectral vectors, but the anomaly cannot. Building an objective model with high representational capabilities and obtaining precise background modeling are therefore key aspects of this type of method. The background dictionary is also readily tainted by anomalies due to the limitations of the current approaches, making the detection findings less reliable. To address the above problems, this paper proposes a weighted low-rank sparse dictionary learning method (WLSDL). This model organically combines sparse representation with low-rank representation in order to effectively depict the intricate background distribution. The weights relating to the eigenvalues of the image are designed by mining the physical characteristics of the HSI. This can enhance the nuclear norm’s capacity for representation, resulting in a background dictionary with more representativeness. Furthermore, the capped norm constraint is incorporated in the objective function to decrease the effect of anomalies and noises on background modeling, hence minimizing anomaly pollution on the background dictionary. The residual image effectively increases the accuracy of anomaly identification since it makes it easier to distinguish between anomalies and background. We use three hyperspectral datasets to evaluate the proposed method. The experimental findings demonstrate the effectiveness and superiority of the proposed method over state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xin Li and Yuan Yuan},
  doi          = {10.1016/j.neucom.2024.128572},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128572},
  shortjournal = {Neurocomputing},
  title        = {Hyperspectral anomaly detection based on weighted low-rank sparse dictionary learning},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decoupling foreground and background with siamese ViT
networks for weakly-supervised semantic segmentation. <em>NEUCOM</em>,
<em>610</em>, 128540. (<a
href="https://doi.org/10.1016/j.neucom.2024.128540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the coarse granularity of information extraction in image-level annotation-based weakly supervised semantic segmentation algorithms, there exists a significant gap between the generated pseudo-labels and the real pixel-level labels. In this paper, we propose the DeFB-SV framework, which consists of a dual-branch Siamese network structure. This framework separates the foreground and background of images by generating unified resolution and mixed resolution class activation maps, which are then fused to obtain pseudo-labels. The mixed-resolution class activation maps are produced by a new mixed-resolution patch partition method, where we introduce a semantically heuristic patch scorer to divide the image into patches of different sizes based on semantics. Additionally, a novel multi-confidence region division mechanism is proposed to enable the adaptive extraction of the effective parts of pseudo-labels, further enhancing the accuracy of weakly supervised semantic segmentation algorithms. The proposed semantic segmentation framework, DeFB-SV, is evaluated on the PASCAL VOC 2012 and MS COCO 2014 datasets, demonstrating comparable segmentation performance with state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Meiling Lin and Gongyan Li and Shaoyun Xu and Yuexing Hao and Shu Zhang},
  doi          = {10.1016/j.neucom.2024.128540},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128540},
  shortjournal = {Neurocomputing},
  title        = {Decoupling foreground and background with siamese ViT networks for weakly-supervised semantic segmentation},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Purity skeleton dynamic hypergraph neural network.
<em>NEUCOM</em>, <em>610</em>, 128539. (<a
href="https://doi.org/10.1016/j.neucom.2024.128539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, in the field of Hypergraph Neural Networks (HGNNs), the effectiveness of dynamic hypergraph construction has been validated, which aims to reduce structural noise within the hypergraph through embeddings. However, the existing dynamic construction methods fail to notice the reduction of information contained in the hypergraphs during dynamic updates. This limitation undermines the quality of hypergraphs. Moreover, dynamic hypergraphs are constructed from graphs. Several key nodes play a crucial role in graph, but they are overlooked in hypergraphs. In this paper, we propose a P urity S keleton D ynamic H ypergraph N eural N etwork (PS-DHGNN) to address the above issues. Firstly, we leverage purity skeleton method to dynamically construct hypergraphs via the fusion embeddings of features and topology simultaneously. This method effectively reduces structural noise and prevents the loss of information. Secondly, we employ an incremental training strategy, which implements a batch training strategy based on the importance of nodes. The key nodes, as the skeleton of hypergraph, are still highly valued. In addition, we utilize a novel loss function for learning structure information between hypergraph and graph. We conduct extensive experiments on node classification and clustering tasks, which demonstrate that our PS-DHGNN outperforms state-of-the-art methods. Note on real-world traffic flow datasets, PS-DHGNN demonstrates excellent performance, which is highly meaningful in practice.},
  archive      = {J_NEUCOM},
  author       = {Yuge Wang and Xibei Yang and Qiguo Sun and Yuhua Qian and Qihang Guo},
  doi          = {10.1016/j.neucom.2024.128539},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128539},
  shortjournal = {Neurocomputing},
  title        = {Purity skeleton dynamic hypergraph neural network},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NCLWO: Newton’s cooling law-based weighted oversampling
algorithm for imbalanced datasets with feature noise. <em>NEUCOM</em>,
<em>610</em>, 128538. (<a
href="https://doi.org/10.1016/j.neucom.2024.128538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced datasets pose challenges to standard classification algorithms. Although oversampling techniques can balance the number of samples across different classes, the difficulties of imbalanced classification is not solely imbalanced data itself but other factors, such as small disjuncts and overlapping regions, especially in the presence of noise. Traditional oversampling techniques are not effectively address these intricacies. To this end, we propose a novel oversampling method called Newton’s Cooling Law-Based Weighted Oversampling (NCLWO). The proposed method initially calculates the weight of the minority class based on density and closeness factors to identify hard-to-learn samples, assigning them higher heat. Subsequently, Newton’s Cooling Law is applied to each minority class sample by using it as the center and expanding the sampling region outward, gradually decreasing the heat until reaching a balanced state. Finally, majority class samples within the sampling region are translated to eliminate overlapping areas, and a weighted oversampling approach is employed to synthesize informative minority class samples. The experimental study, carried out on a set of benchmark datasets, confirm that the proposed method not only outperforms state-of-the-art oversampling approaches but also shows greater robustness in the presence of feature noise.},
  archive      = {J_NEUCOM},
  author       = {Liangliang Tao and Qingya Wang and Zhicheng Zhu and Fen Yu and Xia Yin},
  doi          = {10.1016/j.neucom.2024.128538},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128538},
  shortjournal = {Neurocomputing},
  title        = {NCLWO: Newton’s cooling law-based weighted oversampling algorithm for imbalanced datasets with feature noise},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploration on the spiking response of a single compartment
neuron with multiple active properties under electrical stimuli.
<em>NEUCOM</em>, <em>610</em>, 128537. (<a
href="https://doi.org/10.1016/j.neucom.2024.128537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of modulating the neuronal signals by electrical stimuli is important to intervene the abnormal neuronal firing and bring them to a normal state. Spike trains, which are the highest quality of brain signals, have been deficiently explored and analyzed owing to the challenges of obtaining them in reality. In this regard, this paper aims to investigate and analyze the effect of electrical stimuli on the spiking response of neurons, and the following work is to be carried out. The relationships between the spiking response and three parameters (namely, the amplitude of the electrode current (EC), the angular velocity of the electric field current (EFC), and the signal-noise ratio (SNR)) are examined on a neuronal model with spatial length and multiple active properties. When specific currents with different SNRs are imposed on the neurons, their influence on the spiking response is further explored. With regard to the spiking response, the main focus is on three characteristics, i.e., the spiking pattern, the spike count (SC), and the spiking arrangement. An algorithm, called the return map distance (RMD) algorithm, is proposed in this paper, and gives the classification of spiking patterns a quantitative criterion. Based on it, the spiking patterns are classified in this paper as busting spike train, regular spike train (RST), and meager spike train (MST). Simulation results indicate that both the amplitude of the EC and the angular velocity of the EFC change the neuronal spiking patterns. As the amplitude (angular velocity) of the EC (EFC) increases, the spiking pattern of the Soldado-Magraner model (SMM) eventually tends to RST (MST). In addition, the SC increases with the amplitude of the EC, while it does not hold for the SC with respect to the angular velocity of the EFC. Furthermore, the spiking arrangement and the SC are severely destroyed for the EC with low SNRs, while three spiking features of the SMM under EFC are all robust to the different SNRs, which implies that compared with the EC, the spiking responses of the SMM under EFC are more stable. The findings in this paper may provide some theoretical guidance to the fields related to neuronal firing, such as brain-computer interfaces and electrotherapy. The RMD algorithm proposed here can be applied to more individual neurons, and the spiking arrangement discussed here could be regarded as an effective encoding way for spike trains.},
  archive      = {J_NEUCOM},
  author       = {Ruyue Wang and Jinling Liang},
  doi          = {10.1016/j.neucom.2024.128537},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128537},
  shortjournal = {Neurocomputing},
  title        = {Exploration on the spiking response of a single compartment neuron with multiple active properties under electrical stimuli},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Emotion knowledge-based fine-grained facial expression
recognition. <em>NEUCOM</em>, <em>610</em>, 128536. (<a
href="https://doi.org/10.1016/j.neucom.2024.128536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing facial expression recognition (FER) techniques rely primarily on seven coarse-grained emotions as emotional labels, which are insufficient to cover the subtle changes in human emotions in the real world. We use 135 fine-grained emotions as emotional benchmarks to address the problem of highly semantically similar fine-grained emotion recognition. In this work, we propose a robust emotion knowledge-based fine-grained (EK-FG) emotion recognition network that captures inter-class relationships and discriminative representations of fine-grained emotions through two prior-based losses: coarse-grained hierarchical loss and fine-grained semantic loss. Specifically, the coarse-grained hierarchical loss obtains a structured semantic representation of fine-grained emotions based on prior knowledge, and captures inter-class relationships through effective category-level push-pull to obtain discriminative representations. The fine-grained semantic loss provides more accurate measurement information for semantic features based on prior knowledge, and enhances the model’s discriminative ability for subtle facial expression differences through regression constraints. Extensive experimental results on the Emo135 dataset demonstrate that EK-FG can effectively overcome the class ambiguity of fine-grained emotion.},
  archive      = {J_NEUCOM},
  author       = {Jiacheng Zhu and Yu Ding and Hanwei Liu and Keyu Chen and Zhanpeng Lin and Wenxing Hong},
  doi          = {10.1016/j.neucom.2024.128536},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128536},
  shortjournal = {Neurocomputing},
  title        = {Emotion knowledge-based fine-grained facial expression recognition},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maximum entropy intrinsic learning for spiking networks
towards embodied neuromorphic vision. <em>NEUCOM</em>, <em>610</em>,
128535. (<a href="https://doi.org/10.1016/j.neucom.2024.128535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural network (SNN), as a brain-inspired model, possesses outstanding low power consumption and the ability to mimic biological neuron mechanisms. Embodied vision is a promising field, which requires the low-power advantage of SNNs. However, SNN faces difficulties in achieving real-time, high generalization ability, and robustness in the implementation of embodied vision due to the limitations of existing training methods. In this paper, to prevent model overfitting to noise and unknown environment in embodied neuromorphic visual intelligence, we present a new and efficient learning strategy designed to enhance the training performance of deep SNNs, called Spiking Maximum Entropy Intrinsic Learning (SMEIL). The learning algorithm essentially promotes the perturbation of the underlying source distribution, which in turn enlarges the predictive uncertainty of the current model. This approach enhances the model&#39;s robustness and improves its ability to generalize during the training process. Superior performance across a variety of data sets is achieved, and different types of noise are added to SMEIL algorithm for testing its robustness. Experiments show that SMEIL can consistently improve the learning robustness over each noise disturbance, and can cut down the power consumption during training significantly. Hence, it is a powerful method for advancing direct training of deep SNNs, and opens a novel point of view for developing novel spike-based learning algorithm towards embodied neuromorphic intelligence.},
  archive      = {J_NEUCOM},
  author       = {Shuangming Yang and Qing He and Yao Lu and Badong Chen},
  doi          = {10.1016/j.neucom.2024.128535},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128535},
  shortjournal = {Neurocomputing},
  title        = {Maximum entropy intrinsic learning for spiking networks towards embodied neuromorphic vision},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shape-intensity-guided u-net for medical image segmentation.
<em>NEUCOM</em>, <em>610</em>, 128534. (<a
href="https://doi.org/10.1016/j.neucom.2024.128534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation has achieved impressive results thanks to U-Net or its alternatives. Yet, most existing methods perform segmentation by classifying individual pixels, tending to ignore the shape-intensity prior information. This may yield implausible segmentation results. Besides, the segmentation performance often drops greatly on unseen datasets. One possible reason is that the model is biased towards texture information, which varies more than shape information across different datasets. In this paper, we introduce a novel Shape-Intensity-Guided U-Net (SIG-UNet) for improving the generalization ability of variants of U-Net in segmenting medical images. Specifically, we adopt the U-Net architecture to reconstruct class-wisely averaged images that only contain the shape-intensity information. We then add an extra similar decoder branch with the reconstruction decoder for segmentation, and apply skip fusion between them. Since the class-wisely averaged image has no any texture information, the reconstruction decoder focuses more on shape and intensity features than the encoder on the original image. Therefore, the final segmentation decoder has less texture bias. Extensive experiments on three segmentation tasks of medical images with different modalities demonstrate that the proposed SIG-UNet achieves promising intra-dataset results while significantly improving the cross-dataset segmentation performance. The source code will be publicly available after acceptance.},
  archive      = {J_NEUCOM},
  author       = {Wenhui Dong and Bo Du and Yongchao Xu},
  doi          = {10.1016/j.neucom.2024.128534},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128534},
  shortjournal = {Neurocomputing},
  title        = {Shape-intensity-guided U-net for medical image segmentation},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Double-kernel based bayesian approximation broad learning
system with dropout. <em>NEUCOM</em>, <em>610</em>, 128533. (<a
href="https://doi.org/10.1016/j.neucom.2024.128533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broad learning system (BLS) is an efficient incremental learning machine algorithm. However, there are some disadvantages in such an algorithm. For example, the number of hidden layer nodes needs to be manually adjusted during the training process, meanwhile the large uncertainty will be caused by two random mappings. To solve these problems, based on the optimization ability of the kernel function, a double-kernel broad learning system (DKBLS) is proposed to eliminate the uncertainty of random mapping by using additive kernel strategy. Meanwhile, to reduce the computing costs and training time of DKBLS, a double-kernel based bayesian approximation broad learning system with dropout (Dropout-DKBLS) is further proposed. Ablation experiments show that the output accuracy of Dropout-DKBLS does not decrease even if the node is dropped. In addition, function approximation experiments show that DKBLS and Dropout-DKBLS have good robustness and can accurately predict noise data. The regression and classification experiments on multiple datasets are compared with the latest kernel-based learning methods. The comparison results show that both DKBLS and Dropout-DKBLS have good regression and classification performance. By further comparing the training time of these kernel-based learning methods, we prove that the Dropout-DKBLS can reduce the computational cost while ensuring the output accuracy.},
  archive      = {J_NEUCOM},
  author       = {Tao Chen and Lijie Wang and Yang Liu and C.L. Philip Chen},
  doi          = {10.1016/j.neucom.2024.128533},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128533},
  shortjournal = {Neurocomputing},
  title        = {Double-kernel based bayesian approximation broad learning system with dropout},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Semi-supervised segmentation of medical images focused on
the pixels with unreliable predictions. <em>NEUCOM</em>, <em>610</em>,
128532. (<a href="https://doi.org/10.1016/j.neucom.2024.128532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pseudo-labeling is a well-studied approach in semi-supervised learning. However, unreliable or potentially incorrect pseudo-labels can accumulate training errors during iterative self-training steps, leading to unstable performance. Addressing this challenge typically involves either discarding unreliable pseudo-labels, resulting in the loss of important data, or attempting to refine them, risking the possibility of worsening the pseudo-labels in some cases/pixels. In this paper, we propose a novel method based on pseudo-labeling for semi-supervised segmentation of medical images. Unlike existing approaches, our method neither discards any data nor worsens reliable pseudo-labels. Our approach generates uncertainty masks for the predictions, utilizing reliable pixels without any modification as ground truths and modifying the unreliable ones rather than discarding them. Furthermore, we introduce a novel loss function that incorporates both mentioned parts by multiplying each term by its corresponding uncertainty mask, encompassing reliable and unreliable pixels. The reliable pixels are addressed using a masked cross-entropy loss function, while the modification of the unreliable pixels is performed through a deep-learning-based adaptation of active contours. The entire process is solved within a single loss function without the need to solve traditional active contour equations. We evaluated our approach on three publicly available datasets, including MRI and CT images from cardiac structures and lung tissue. Our proposed method outperforms the state-of-the-art semi-supervised learning methods on all three datasets. Implementation of our work is available at https://github.com/behnam-rahmati/Semi-supervised-medical .},
  archive      = {J_NEUCOM},
  author       = {Behnam Rahmati and Shahram Shirani and Zahra Keshavarz-Motamed},
  doi          = {10.1016/j.neucom.2024.128532},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128532},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised segmentation of medical images focused on the pixels with unreliable predictions},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic delineation and prognostic assessment of head and
neck tumor lesion in multi-modality positron emission tomography /
computed tomography images based on deep learning: A survey.
<em>NEUCOM</em>, <em>610</em>, 128531. (<a
href="https://doi.org/10.1016/j.neucom.2024.128531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately segmenting and staging tumor lesions in cancer patients presents a significant challenge for radiologists, but it is essential for devising effective treatment plans including radiation therapy, personalized medicine, and surgical options. The integration of artificial intelligence (AI), particularly deep learning (DL), has become a useful tool for radiologists, enhancing their ability to understand tumor biology and deliver personalized care to patients with H&amp;N tumors. Segmenting H&amp;N tumor lesions using Positron Emission Tomography/Computed Tomography (PET/CT) images has gained significant attention. However, the diverse shapes and sizes of tumors, along with indistinct boundaries between malignant and normal tissues, present significant challenges in effectively fusing PET and CT images. To overcome these challenges, various DL-based models have been developed for segmenting tumor lesions in PET/CT images. This article reviews multimodality (PET/CT) based H&amp;N tumor lesions segmentation methods. We firstly discuss the strengths and limitations of PET/CT imaging and the importance of DL-based models in H&amp;N tumor lesion segmentation. Second, we examine the current state-of-the-art DL models for H&amp;N tumor segmentation, categorizing them into UNet, VNet, Vision Transformer, and miscellaneous models based on their architectures. Third, we explore the annotation and evaluation processes, addressing challenges in segmentation annotation and discussing the metrics used to assess model performance. Finally, we discuss several open challenges and provide some avenues for future research in H&amp;N tumor lesion segmentation.},
  archive      = {J_NEUCOM},
  author       = {Zain Ul Abidin and Rizwan Ali Naqvi and Muhammad Zubair Islam and Abbas Jafar and Seung-Won Lee and Hyung Seok Kim},
  doi          = {10.1016/j.neucom.2024.128531},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128531},
  shortjournal = {Neurocomputing},
  title        = {Automatic delineation and prognostic assessment of head and neck tumor lesion in multi-modality positron emission tomography / computed tomography images based on deep learning: A survey},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature balanced re-enhanced network with multi-factor
margin loss for long-tailed visual recognition. <em>NEUCOM</em>,
<em>610</em>, 128530. (<a
href="https://doi.org/10.1016/j.neucom.2024.128530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world data often exhibits a long-tailed distribution, where the number of training samples for head classes far exceeds that of tail classes. This class imbalance phenomenon poses significant challenges for training deep neural networks. Existing class-aware loss methods typically focus only on the numerical relationship between class samples, blindly favoring the optimization of tail classes during the process, while neglecting the difficulty of samples and the similarity between the current class and other classes. To this end, relying only on the number relationship can easily lead to over-fitting of tail classes, thereby failing to fully utilize the potential information in the data. Therefore, we propose the Multi-Factor Margin Loss (MFMLoss), which consists of positive margin loss and negative margin loss. MFMLoss comprehensively considers three factors at three levels: overall, class, and sample: (1) quantitative relationships, (2) inter-class similarity relationships, and (3) sample recognition difficulty. The combined consideration of these three factors enables the model to pay more attention to confusing classes and difficult samples during the training process, rather than solely on tail classes, thus achieving optimization from coarse-grained to fine-grained. To further mitigate the negative impact of the imbalance between head and tail classes on feature learning, we design a new network architecture, called F-BREN. F-BREN consists of two components: the feature balancing network and the feature re-enhancement network. The former is trained with negative margin loss, which reduces the recognizability of easy samples. The latter is trained with positive margin loss, using positive margin to give more attention to hard samples, thus balancing the model’s attention to all samples. We conducted extensive experiments on four long-tailed benchmark datasets: CIFAR10-LT, CIFAR100-LT, ImageNet-LT and iNaturalist 2018, comparing the recognition accuracy of our method with eight state-of-the-art methods. The experimental results demonstrate that our proposed method outperforms the eight compared methods.},
  archive      = {J_NEUCOM},
  author       = {Yaoyao Wang and Junhai Zhai},
  doi          = {10.1016/j.neucom.2024.128530},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128530},
  shortjournal = {Neurocomputing},
  title        = {Feature balanced re-enhanced network with multi-factor margin loss for long-tailed visual recognition},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging discriminative data: A pathway to
high-performance, stable one-shot network pruning at initialization.
<em>NEUCOM</em>, <em>610</em>, 128529. (<a
href="https://doi.org/10.1016/j.neucom.2024.128529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-shot Network Pruning at Initialization (OPaI) is acknowledged as a highly cost-effective strategy for network pruning. However, it has been observed that OPaI models tend to suffer from reduced accuracy stability as target sparsity increases. This study introduces a novel approach by incorporating Discriminative Data (DD) into OPaI, significantly improving performance at higher sparsity levels while maintaining the “one-shot” nature. Our approach achieves state-of-the-art (SOTA) performance, challenging the previously held belief of OPaI’s data independence. Through detailed ablation studies, we thoroughly investigate the influence of data on OPaI, particularly focusing on how DD addresses a common failure in OPaI known as “layer collapse”. Furthermore, our experiments demonstrate that leveraging DD from various pre-trained models can markedly boost pruning performance across different models without requiring changes to the existing model architectures or pruning methodologies. These significant improvements highlight our method’s high generalizability and stability, paving new paths for advancing pruning strategies. Our code is publicly available at: https://github.com/Nonac/DDOPaI .},
  archive      = {J_NEUCOM},
  author       = {Yinan Yang and Ying Ji and Jien Kato},
  doi          = {10.1016/j.neucom.2024.128529},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128529},
  shortjournal = {Neurocomputing},
  title        = {Leveraging discriminative data: A pathway to high-performance, stable one-shot network pruning at initialization},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Clustering-based hyper-heuristic algorithm for multi-region
coverage path planning of heterogeneous UAVs. <em>NEUCOM</em>,
<em>610</em>, 128528. (<a
href="https://doi.org/10.1016/j.neucom.2024.128528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of multi-heterogeneous UAV coverage path planning, an effective solution method has been proposed. Firstly, regions are set up as fully connected graphs which are cut into multiple subgraphs by spectral clustering method to assign tasks to multi-heterogeneous UAVs. Additionally, an RL-based hyper-heuristic algorithm is proposed. Heuristic space is parameterized by GNN which is trained with the reward provided by the optimization goal to automate design and enhance the heuristic metrics, avoiding the inefficiency and suboptimality of expert design and manual parameter tuning. Compared with existing methods, the proposed algorithm has a better performance in task completion time, execution time and deviation rate, which shows its potential application in the coverage path planning problem of multi-heterogeneous UAVs.},
  archive      = {J_NEUCOM},
  author       = {Bocheng Zhao and Mingying Huo and Zheng Li and Ze Yu and Naiming Qi},
  doi          = {10.1016/j.neucom.2024.128528},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128528},
  shortjournal = {Neurocomputing},
  title        = {Clustering-based hyper-heuristic algorithm for multi-region coverage path planning of heterogeneous UAVs},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AFGN: Attention feature guided network for object detection
in optical remote sensing image. <em>NEUCOM</em>, <em>610</em>, 128527.
(<a href="https://doi.org/10.1016/j.neucom.2024.128527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in optical remote sensing (RS) images is crucial for both military and civilian applications. However, a major challenge in RS object detection lies in the complexity of texture details within the images, which makes it difficult to accurately identify the objects. Currently, many object detection methods based on deep learning focus primarily on network architecture and label assignment design. These methods often employ an end-to-end training approach, where the loss function only directly constraints the final output layer. However, this approach gives each module within the network a significant amount of freedom during the optimization process, which can hinder the network’s ability to effectively focus on the object and limit detection accuracy. To address these limitations, this paper proposes a novel approach called the Attention Feature Guided Network (AFGN). In this approach, a Attention Feature Guided Branch (AFGB) is introduced during the training phase of the CNN-based end-to-end detection network. The AFGB provides additional shallow supervision outside the detector’s output layer, guiding the backbone to effectively focus on the object amidst complex backgrounds. Additionally, a new operation called Background Blur Mask (BBM) is proposed, which is embedded in the AFGB to achieve image-level attention. Experiments conducted on the DIOR dataset demonstrate the effectiveness and efficiency of the proposed method. Our method achieves an mAP (mean average precision) of 0.777, surpassing many state-of-the-art object detection methods.},
  archive      = {J_NEUCOM},
  author       = {Ruiqing Zhang and Yinjie Lei},
  doi          = {10.1016/j.neucom.2024.128527},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128527},
  shortjournal = {Neurocomputing},
  title        = {AFGN: Attention feature guided network for object detection in optical remote sensing image},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel capsule network based on multi-order descartes
extension transformation. <em>NEUCOM</em>, <em>610</em>, 128526. (<a
href="https://doi.org/10.1016/j.neucom.2024.128526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the capsule network has significantly impacted deep learning with its unique structure that robustly handles spatial relationships and image deformations like rotation and scaling. While previous research has primarily focused on enhancing the structural network of capsule networks to process complex images, little attention has been given to the rich semantic information contained within the capsules themselves. We recognize this gap and propose the Multi-Order Descartes Expansion Capsule Network (MODE-CapsNet). By introducing the Multi-Order Descartes Expansion Transformation (MODET), this innovative architecture enhances the expressiveness of a single capsule by enabling its projection into a higher-dimensional space. As far as we know, this is the first significant enhancement at the single-capsule granularity level, providing a new perspective for improving capsule networks. Additionally, we proposed a hierarchical routing algorithm designed explicitly for the MODE capsules, significantly optimizing computational efficiency and performance. Experimental results on datasets (MNIST, Fashion-MNIST, SVHN, CIFAR-10, tiny-ImageNet) showed that MODE capsules exhibited improved separability and expressiveness, contributing to overall network accuracy, robustness, and computational efficiency.},
  archive      = {J_NEUCOM},
  author       = {Hongjia Zhu and Cong Xu and Lin Ma and Haifeng Li},
  doi          = {10.1016/j.neucom.2024.128526},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128526},
  shortjournal = {Neurocomputing},
  title        = {A novel capsule network based on multi-order descartes extension transformation},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A slimmable framework for practical neural video
compression. <em>NEUCOM</em>, <em>610</em>, 128525. (<a
href="https://doi.org/10.1016/j.neucom.2024.128525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is being increasingly applied to image and video compression in a new paradigm known as neural video compression. While achieving impressive rate–distortion (RD) performance, neural video codecs (NVC) require heavy neural networks, which in turn have large memory and computational costs and often lack important functionalities such as variable rate. These are significant limitations to their practical application. Addressing these problems, recent slimmable image codecs can dynamically adjust their model capacity to elegantly reduce the memory and computation requirements, without harming RD performance. However, the extension to video is not straightforward due to the non-trivial interplay with complex motion estimation and compensation modules in most NVC architectures. In this paper we propose the slimmable video codec framework (SlimVC) that integrates an slimmable autoencoder and a motion-free conditional entropy model. We show that the slimming mechanism is also applicable to the more complex case of video architectures, providing SlimVC with simultaneous control of the computational cost, memory and rate, which are all important requirements in practice. We further provide detailed experimental analysis, and describe application scenarios that can benefit from slimmable video codecs.},
  archive      = {J_NEUCOM},
  author       = {Zhaocheng Liu and Fei Yang and Defa Wang and Marc Górriz Blanch and Luka Murn and Shuai Wan and Saiping Zhang and Marta Mrak and Luis Herranz},
  doi          = {10.1016/j.neucom.2024.128525},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128525},
  shortjournal = {Neurocomputing},
  title        = {A slimmable framework for practical neural video compression},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vision transformers inference acceleration based on adaptive
layer normalization. <em>NEUCOM</em>, <em>610</em>, 128524. (<a
href="https://doi.org/10.1016/j.neucom.2024.128524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, deep neural networks (DNNs) have been widely used due to their remarkable accuracy in real-world applications. However, this increase in accuracy often results in computationally expensive models and high memory usage, leading to longer prediction latencies and exorbitant release costs. In this paper, we propose a new adaptive layer normalization (ALN) algorithm for transformer models, which tackles the computational, and memory problems encountered by traditional layer normalization (LN) techniques. The proposed method computes and stores statistical moments during the training and uses them directly during the inference phase, allowing the normalization layer to be merged with the nearest linear layer. The result is a significant acceleration in inference time, by up to 29%. In classification tasks, our evaluations on the ImageNet dataset show an improvement in accuracy of 0.1%, while maintaining comparable accuracy in object detection tasks on the COCO reference dataset. The proposed ALN algorithm is a simple and effective solution for improving the inference time of pre-trained transformer models, making it a valuable tool for natural language processing and computer vision tasks.},
  archive      = {J_NEUCOM},
  author       = {Fekhr Eddine Keddous and Arcadi Llanza and Nadiya Shvai and Amir Nakib},
  doi          = {10.1016/j.neucom.2024.128524},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128524},
  shortjournal = {Neurocomputing},
  title        = {Vision transformers inference acceleration based on adaptive layer normalization},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-agent, human–agent and beyond: A survey on cooperation
in social dilemmas. <em>NEUCOM</em>, <em>610</em>, 128514. (<a
href="https://doi.org/10.1016/j.neucom.2024.128514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of cooperation within social dilemmas has long been a fundamental topic across various disciplines, including computer science and social science. Recent advancements in Artificial Intelligence (AI) have significantly reshaped this field, offering fresh insights into understanding and enhancing cooperation. This survey examines three key areas at the intersection of AI and cooperation in social dilemmas. First, focusing on multi-agent cooperation, we review the intrinsic and external motivations that support cooperation among rational agents, and the methods employed to develop effective strategies against diverse opponents. Second, looking into human–agent cooperation, we discuss the current AI algorithms for cooperating with humans and the human biases towards AI agents. Third, we review the emergent field of leveraging AI agents to enhance cooperation among humans. We conclude by discussing future research avenues, such as using large language models, establishing unified theoretical frameworks, revisiting existing theories of human cooperation, and exploring multiple real-world applications.},
  archive      = {J_NEUCOM},
  author       = {Chunjiang Mu and Hao Guo and Yang Chen and Chen Shen and Die Hu and Shuyue Hu and Zhen Wang},
  doi          = {10.1016/j.neucom.2024.128514},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128514},
  shortjournal = {Neurocomputing},
  title        = {Multi-agent, human–agent and beyond: A survey on cooperation in social dilemmas},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of black-box adversarial attacks on image
classification. <em>NEUCOM</em>, <em>610</em>, 128512. (<a
href="https://doi.org/10.1016/j.neucom.2024.128512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning-based image classification models have been extensively studied in academia and widely applied in industry. However, deep learning is inherently vulnerable to adversarial attacks, posing security threats to image classification models in security sensitive field, such as face recognition, medical image diagnosis and traffic sign recognition. Especially for black-box adversarial attacks, which can be carried out even without remote model information, the security issues facing deep learning are even more serious. Despite more and more attentions on this issue, existing reviews always analyze black-box adversarial attack only from one perspective, focus on only a certain application field. This paper systematically reviews and discusses existing progress, demonstrating black-box adversarial attacks from multiple perspectives and systematically classifying existing methods. Besides, we also sort out and categorize the application of current black-box adversarial attacks and identify several promising directions for future research.},
  archive      = {J_NEUCOM},
  author       = {Yanfei Zhu and Yaochi Zhao and Zhuhua Hu and Tan Luo and Like He},
  doi          = {10.1016/j.neucom.2024.128512},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128512},
  shortjournal = {Neurocomputing},
  title        = {A review of black-box adversarial attacks on image classification},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Review of neural network model acceleration techniques based
on FPGA platforms. <em>NEUCOM</em>, <em>610</em>, 128511. (<a
href="https://doi.org/10.1016/j.neucom.2024.128511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network models, celebrated for their outstanding scalability and computational capabilities, have demonstrated remarkable performance across various fields such as vision, language, and multimodality. The rapid advancements in neural networks, fueled by the deep development of Internet technology and the increasing demand for intelligent edge devices, introduce new challenges, including significant model parameter sizes and increased storage pressures. In this context, Field-Programmable Gate Arrays (FPGA) emerge as a preferred platform for accelerating neural network models, thanks to their exceptional performance, energy efficiency, and the flexibility and scalability of the system. Building FPGA-based neural network systems necessitates bridging significant differences in objectives, methods, and design spaces between model design and hardware design. This review article adopts a comprehensive analytical framework to thoroughly explore multidimensional technological implementation strategies, encompassing optimizations at the algorithmic and hardware levels, as well as compiler optimization techniques. It focuses on methods for collaborative optimization between algorithms and hardware, identifies challenges in the collaborative design process, and proposes corresponding implementation strategies and key steps. Addressing various technological dimensions, the article provides in-depth technical analysis and discussion, aiming to offer valuable insights for research on optimizing and accelerating neural network models in edge computing environments.},
  archive      = {J_NEUCOM},
  author       = {Fang Liu and Heyuan Li and Wei Hu and Yanxiang He},
  doi          = {10.1016/j.neucom.2024.128511},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128511},
  shortjournal = {Neurocomputing},
  title        = {Review of neural network model acceleration techniques based on FPGA platforms},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fast strategy-solving method for adversarial team games
utilizing warm starting. <em>NEUCOM</em>, <em>610</em>, 128509. (<a
href="https://doi.org/10.1016/j.neucom.2024.128509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial team games (ATGs) have garnered significant attention in recent years, leading to the emergence of various solutions such as linear programming algorithms, multi-agent reinforcement learning, and game tree transformation. The ATGs involve large-scale game trees, resulting in higher time costs for computation. In this paper, we focus on expediting the solution of team-maxmin equilibrium with correlation (TMECor), which can be considered the equilibrium that maximizes the team’s payoff. To address this, we propose a transformation with seed strategies (TSS). TSS leverages reinforcement learning to calculate player strategies. We initialize the strategies of all players, referred to as seed strategies, and incorporate them into the multi-agent game tree during the transformation process. These seed strategies serve as the starting strategies for counterfactual regret minimization (CFR). CFR initializes the strategies and cumulative regret of all players based on the seed strategy. By warm starting the whole process, our method accelerates the solving of TMECor. We conducted nine experiments using Kuhn poker and Leduc Hold’em poker. The results demonstrated that TSS improved the solving speed of TMECor.},
  archive      = {J_NEUCOM},
  author       = {Botao Liu and Chen Qiu and Weixin Huang and Jiajia Zhang and Xuan Wang},
  doi          = {10.1016/j.neucom.2024.128509},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128509},
  shortjournal = {Neurocomputing},
  title        = {A fast strategy-solving method for adversarial team games utilizing warm starting},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-loss nonlinear independent component estimation for
augmenting explainable vibration samples of rotating machinery faults.
<em>NEUCOM</em>, <em>610</em>, 128508. (<a
href="https://doi.org/10.1016/j.neucom.2024.128508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obtaining fault samples for diagnosing faults in rotating machinery for engineering applications can be costly. To address this challenge, fault sample augmentation methods are used to train fault diagnosis models. However, existing techniques mainly focus on comparing augmented signal loss with real ones, overlooking the underlying vibration mechanism of rotating machinery faults. Addressing this limitation, a novel approach, called dual-loss nonlinear independent component estimation (DLNICE), is proposed to enhance understanding of fault features in vibration signals. This integrates augmentation losses in both time and frequency domains to enrich fault vibration samples. DLNICE effectively utilizes limited fault samples for augmentation by estimating nonlinear independent components, capturing key fault characteristics like impulsiveness and cyclo-stationarity. Therefore, augmented fault samples become more explainable for analyzing rotating machinery faults. Experimental evaluations on bearing and gearbox vibration samples confirm the effectiveness of DLNICE. Utilizing the augmented samples leads to an average accuracy of 86.27 % in bearing fault diagnosis, and that of 81.60 % in gearbox fault diagnosis. The results demonstrate that DLNICE excels in augmenting high-quality vibration samples of rotating machinery faults.},
  archive      = {J_NEUCOM},
  author       = {Xiaoyun Gong and Mengxuan Hao and Chuan Li and Wenliao Du and Ziqiang Pu},
  doi          = {10.1016/j.neucom.2024.128508},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128508},
  shortjournal = {Neurocomputing},
  title        = {Dual-loss nonlinear independent component estimation for augmenting explainable vibration samples of rotating machinery faults},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Text-to-text generative approach for enhanced complex word
identification. <em>NEUCOM</em>, <em>610</em>, 128501. (<a
href="https://doi.org/10.1016/j.neucom.2024.128501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach for solving the Complex Word Identification (CWI) task using the text-to-text generative model. The CWI task involves identifying complex words in text, which is a challenging Natural Language Processing task. To our knowledge, it is a first attempt to address CWI problem into text-to-text context. In this work, we propose a new methodology that leverages the power of the Transformer model to evaluate complexity of words in binary and probabilistic settings. We also propose a novel CWI dataset, which consists of 62,200 phrases, both complex and simple. We train and fine-tune our proposed model on our CWI dataset. We also evaluate its performance on separate test sets across three different domains. Our experimental results demonstrate the effectiveness of our proposed approach compared to state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Patrycja Śliwiak and Syed Afaq Ali Shah},
  doi          = {10.1016/j.neucom.2024.128501},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128501},
  shortjournal = {Neurocomputing},
  title        = {Text-to-text generative approach for enhanced complex word identification},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Distributed nonlinear fusion filtering for multi-sensor
networked systems with random varying parameter matrix and missing
measurements. <em>NEUCOM</em>, <em>610</em>, 128491. (<a
href="https://doi.org/10.1016/j.neucom.2024.128491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the distributed fusion filtering algorithm design problem for multi-sensor nonlinear networked systems (MSNNSs) subject to multiplicative noises, random varying parameter matrix and missing measurements (MMs). In particular, we utilize the Bernoulli random variable with certain statistical features to describe and characterize the MMs phenomenon. By introduce a fictitious noise, the effects from process noise as well as random varying parameter matrix are addressed and a new nonlinear stochastic networked system is obtained. The primary purpose of this paper is to develop a novel fusion filtering scheme of the distributed way and provide the corresponding boundedness evaluation criterion. Firstly, specific upper bounds of filtering error covariance (FEC) are identified and locally minimized at each sampling instant. Subsequently, based on the obtained local filters, a distributed fusion filtering algorithm is designed via adopting the inverse covariance intersection (ICI) fusion idea. Furthermore, the analysis with respect to the upper bound of local FEC is discussed and examined by proposing a sufficient condition under certain constraints regarding the related parameters. Eventually, with the help of the simulation experiments, the usefulness of the proposed fusion filtering algorithm is illustrated.},
  archive      = {J_NEUCOM},
  author       = {Lin Zhao and Lifeng Sun and Jun Hu},
  doi          = {10.1016/j.neucom.2024.128491},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128491},
  shortjournal = {Neurocomputing},
  title        = {Distributed nonlinear fusion filtering for multi-sensor networked systems with random varying parameter matrix and missing measurements},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural architecture search for image super-resolution: A
review on the emerging state-of-the-art. <em>NEUCOM</em>, <em>610</em>,
128481. (<a href="https://doi.org/10.1016/j.neucom.2024.128481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, complex and expensive neural architectures are seen by many as a way to improve the performance of existing models in image recognition, voice recognition, translation, and other tasks. Such a perspective caused an increased interest in expert architecture engineering within Deep Learning. Fueled by this interest, neural architecture search originated as a promising way to automate the tedious process of constructing a deep neural network by hand. Over the last five years, we have seen an increasing number of works focusing all efforts on studying the impact of automating deep neural network design. The spotlight has recently turned from automatically discovering classification models to other more complex tasks. Motivated by a desire for high-resolution images in real-world user-centered and expert computer vision applications, architecture search for super-resolution image restoration centers in approaches capable of automatically finding efficient and well-performing models. Here, we present a survey that, beyond delving into an overview of modern approaches to automatic neural network design, focuses on the recollection and study of neural architecture search approaches that have directed their efforts at the super-resolution image restoration tasks and future lines of research found within this emerging area of study.},
  archive      = {J_NEUCOM},
  author       = {Jesús L. Llano García and Raúl Monroy and Víctor Adrián Sosa Hernández},
  doi          = {10.1016/j.neucom.2024.128481},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128481},
  shortjournal = {Neurocomputing},
  title        = {Neural architecture search for image super-resolution: A review on the emerging state-of-the-art},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online imbalance learning with unpredictable feature
evolution and label scarcity. <em>NEUCOM</em>, <em>610</em>, 128476. (<a
href="https://doi.org/10.1016/j.neucom.2024.128476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, online learning with imbalanced data streams has aroused wide concern, which reflects an uneven distribution of different classes in data streams. Existing approaches have conventionally been conducted on stationary feature space and they assume that we can obtain the entire labels of data streams in the case of supervised learning. However, in many real scenarios, e.g., the environment monitoring task, new features flood in, and old features are partially lost during the changing environment as the different lifespans of different sensors. Besides, each instance needs to be labeled by experts, resulting in expensive costs and scarcity of labels. To address the above problems, this paper proposes a novel Online Imbalance learning with unpredictable Feature evolution and Label scarcity (OIFL) algorithm. First, we utilize margin-based online active learning to selectively label valuable instances. After obtaining the labels, we handle imbalanced class distribution by optimizing F-measure and transforming F-measure optimization into a weighted surrogate loss minimization. When data streams arrive with augmented features, we combine the online passive-aggressive algorithm and structural risk minimization to update the classifier in the divided feature space. When data streams arrive with incomplete features, we leverage variance to identify the most informative features following the empirical risk minimization principle and continue to update the existing classifier as before. Finally, we obtain a sparse but reliable learner by the strategy of projecting truncation. We derive theoretical analyses of OIFL. Also, experiments on the synthetic datasets and real-world data streams to validate the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Jiahang Tu and Shilin Gu and Chenping Hou},
  doi          = {10.1016/j.neucom.2024.128476},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128476},
  shortjournal = {Neurocomputing},
  title        = {Online imbalance learning with unpredictable feature evolution and label scarcity},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Understanding activation patterns in artificial neural
networks by exploring stochastic processes: Discriminating
generalization from memorization. <em>NEUCOM</em>, <em>610</em>, 128473.
(<a href="https://doi.org/10.1016/j.neucom.2024.128473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To gain a deeper understanding of the behavior and learning dynamics of artificial neural networks, mathematical abstractions and models are valuable. They provide a simplified perspective and facilitate systematic investigations. In this paper, we propose to analyze dynamics of artificial neural activation using stochastic processes, which have not been utilized for this purpose thus far. Our approach involves modeling the activation patterns of nodes in artificial neural networks as stochastic processes. By focusing on the activation frequency, we can leverage techniques used in neuroscience to study neural spike trains. Specifically, we extract the activity of individual artificial neurons during a classification task and model their activation frequency. The underlying process model is an arrival process following a Poisson distribution. We examine the theoretical fit of the observed data generated by various artificial neural networks in image recognition tasks to the proposed model’s key assumptions. Through the stochastic process model, we derive measures describing activation patterns of each network. We analyze randomly initialized, generalizing, and memorizing networks, allowing us to identify consistent differences in learning methods across multiple architectures and training sets. We calculate features describing the distribution of Activation Rate and Fano Factor, which prove to be stable indicators of memorization during learning. These calculated features offer valuable insights into network behavior. The proposed model demonstrates promising results in describing activation patterns and could serve as a general framework for future investigations. It has potential applications in theoretical simulation studies as well as practical areas such as pruning or transfer learning.},
  archive      = {J_NEUCOM},
  author       = {Stephan Johann Lehmler and Muhammad Saif-ur-Rehman and Tobias Glasmachers and Ioannis Iossifidis},
  doi          = {10.1016/j.neucom.2024.128473},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128473},
  shortjournal = {Neurocomputing},
  title        = {Understanding activation patterns in artificial neural networks by exploring stochastic processes: Discriminating generalization from memorization},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive structure generation and neuronal differentiation
for memory encoding in SNNs. <em>NEUCOM</em>, <em>610</em>, 128470. (<a
href="https://doi.org/10.1016/j.neucom.2024.128470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memory is the core of cognition. The exploration of the memory encoding mechanism or the representation mechanism of information in the Spiking Neural Network (SNN) is the basis for the in-depth study of memory. In this paper, we study the memory encoding mechanism of multilayer SNN models from a biomimetic perspective and explore a method using the high biological likelihood of SNN to enable the network to effectively simulate memory effects. We proposed a series of heuristic neuron-growing connection algorithms and supervised network weight learning algorithms, which were applied to the unsupervised and supervised training process of the presentation layer. These methods optimized the structure of the representation layer, achieved functional differentiation of neurons, and enabled the network to generate differentiated representations for different data modes. Under our algorithm, the proposed model achieves stable convergence with identical pattern inputs, demonstrating distinct representations and sensitivities to different visual modalities. To achieve stable information expression within the network, we conducted various comparative experiments to determine diverse parameters of the complex network. This paper contributes to the development of Brain-inspired Intelligence by bridging the gap between computer science and neuroscience by using simulations to validate biological hypotheses and guide machine learning.},
  archive      = {J_NEUCOM},
  author       = {Zihui Jin and Jian Cai and Yingze Di and Yunlin Lei and Yu Fu and Yuhan Liu and Xu Yang},
  doi          = {10.1016/j.neucom.2024.128470},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128470},
  shortjournal = {Neurocomputing},
  title        = {Adaptive structure generation and neuronal differentiation for memory encoding in SNNs},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning restricted boltzmann machines with pattern induced
weights. <em>NEUCOM</em>, <em>610</em>, 128469. (<a
href="https://doi.org/10.1016/j.neucom.2024.128469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Restricted Boltzmann Machines are energy-based models capable of learning probability distributions. In practice, though, it is seriously limited by the fact that the computational cost associated with the exact evaluation of the gradients, required during learning, is prohibitively high. The standard approach to mitigate this problem is to use the Contrastive Divergence algorithm, but it leads to a rough approximation that presents issues on its own. As a completely different alternative, a model called RAPID (Pozas-Kerstjen et al., 2021) recently appeared, where unit weights are constructed from high-probability patterns that allow for an effective evaluation of the update rules along learning. In this work we analyze RAPID to find that it also presents some drawbacks that constrain its performance. We identify the problematic sources in RAPID and modify them accordingly to build a similar but more flexible alternative, called PIW (Pattern Induced Weights). Experiments show that PIW performs better than the original RAPID implementation, bringing it to a competitive level when compared to a standard RBM with CDk, with a substantial reduction in the number of training parameters.},
  archive      = {J_NEUCOM},
  author       = {J. Garí and E. Romero and F. Mazzanti},
  doi          = {10.1016/j.neucom.2024.128469},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128469},
  shortjournal = {Neurocomputing},
  title        = {Learning restricted boltzmann machines with pattern induced weights},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot image classification using graph neural network
with fine-grained feature descriptors. <em>NEUCOM</em>, <em>610</em>,
128448. (<a href="https://doi.org/10.1016/j.neucom.2024.128448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph computation via Graph Neural Networks (GNNs) is emerging as a pivotal approach for addressing the challenges in image classification tasks. This paper introduces a novel strategy for image classification using minimal labeled data from the mini-ImageNet database. The primary contributions include the development of an innovative Fine-Grained Feature Descriptor (FGFD) module. Following this, the GNN is employed at a more granular level to enhance image classification efficiency. Additionally, ablation studies were conducted in conjunction with existing state-of-the-art systems for few-shot image classification. Comparative analyses were performed, and the simulation results demonstrate that the proposed method significantly improves classification accuracy over traditional few-shot image classification methods.},
  archive      = {J_NEUCOM},
  author       = {Priyanka Ganesan and Senthil Kumar Jagatheesaperumal and Mohammad Mehedi Hassan and Francesco Pupo and Giancarlo Fortino},
  doi          = {10.1016/j.neucom.2024.128448},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128448},
  shortjournal = {Neurocomputing},
  title        = {Few-shot image classification using graph neural network with fine-grained feature descriptors},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Memory-efficient DRASiW models. <em>NEUCOM</em>,
<em>610</em>, 128443. (<a
href="https://doi.org/10.1016/j.neucom.2024.128443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weightless Neural Networks (WNN) are ideal for Federated Learning due to their robustness and computational efficiency. These scenarios require models with a small memory footprint and the ability to aggregate knowledge from multiple models. In this work, we demonstrate the effectiveness of using Bloom filter variations to implement DRASiW models—an adaptation of WNN that records both the presence and frequency of patterns—with minimized memory usage. Across various datasets, DRASiW models show competitive performance compared to models like Random Forest, k k -Nearest Neighbors, Multi-layer Perceptron, and Support Vector Machines, with an acceptable space trade-off. Furthermore, our findings indicate that Bloom filter variations, such as Count Min Sketch, can reduce the memory footprint of DRASiW models by up to 27% while maintaining performance and enabling distributed and federated learning strategies.},
  archive      = {J_NEUCOM},
  author       = {Otávio Oliveira Napoli and Ana Maria de Almeida and Edson Borin and Mauricio Breternitz Jr.},
  doi          = {10.1016/j.neucom.2024.128443},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128443},
  shortjournal = {Neurocomputing},
  title        = {Memory-efficient DRASiW models},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph neural network based intelligent tutoring system: A
survey. <em>NEUCOM</em>, <em>610</em>, 128442. (<a
href="https://doi.org/10.1016/j.neucom.2024.128442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online education is developing rapidly driven by artificial intelligence technology. The massive learning resources lead to information overload and low resource utilization. Intelligent tutoring system (ITS) plays a vital role in the education platform, providing personalized learning services for students. The data obtained from the online education platform has complex correlations, which can be potentially transformed into multi-level graph structures. In recent years, graph neural networks (GNNs) have been tried to be introduced into intelligent learning services due to their superior performance in processing graph-structured data. This paper aims to provide researchers and engineers with a general overview of modeling processes and techniques for intelligent learning services based on GNNs. Through a careful review of the advanced models published between 2019 and 2023, existing research primarily focuses on four detailed areas within the smart services scenario. The GNN models involved are systematically classified, and the principles, pioneers and variants of various models are summarized in detail. Simultaneously, this paper analyzes the applications, the specific problems to be solved, and the technologies and innovations of graph-based models in the four key areas. In addition, we examine the commonly used datasets and evaluation metrics in the field of education. Finally, the current challenges and future development trends are summarized to provide comprehensive and in-depth guidance for research in related fields.},
  archive      = {J_NEUCOM},
  author       = {Juhua Pu and Shufei Li and Meng Guo and Xi Chen and Zhang Xiong},
  doi          = {10.1016/j.neucom.2024.128442},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128442},
  shortjournal = {Neurocomputing},
  title        = {Graph neural network based intelligent tutoring system: A survey},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From text to mask: Localizing entities using the attention
of text-to-image diffusion models. <em>NEUCOM</em>, <em>610</em>,
128437. (<a href="https://doi.org/10.1016/j.neucom.2024.128437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have revolted the field of text-to-image generation recently. The unique way of fusing text and image information contributes to their remarkable capability of generating highly text-related images. From another perspective, these generative models imply clues about the precise correlation between words and pixels. This work proposes a simple but effective method to utilize the attention mechanism in the denoising network of text-to-image diffusion models. Without additional training time nor inference-time optimization, the semantic grounding of phrases can be attained directly. We evaluate our method on Pascal VOC 2012 and Microsoft COCO 2014 under weakly-supervised semantic segmentation setting and our method achieves superior performance to prior methods. In addition, the acquired word-pixel correlation is generalizable for the learned text embedding of customized generation methods, requiring only a few modifications. To validate our discovery, we introduce a new practical task called “personalized referring image segmentation” with a new dataset. Experiments in various situations demonstrate the advantages of our method compared to strong baselines on this task. In summary, our work reveals a novel way to extract the rich multi-modal knowledge hidden in diffusion models for segmentation.},
  archive      = {J_NEUCOM},
  author       = {Changming Xiao and Qi Yang and Feng Zhou and Changshui Zhang},
  doi          = {10.1016/j.neucom.2024.128437},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128437},
  shortjournal = {Neurocomputing},
  title        = {From text to mask: Localizing entities using the attention of text-to-image diffusion models},
  volume       = {610},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive review of deep neural network interpretation
using topological data analysis. <em>NEUCOM</em>, <em>609</em>, 128513.
(<a href="https://doi.org/10.1016/j.neucom.2024.128513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have achieved significant success across various fields, but their intrinsic black-box nature hinders the further development. Addressing the interpretability challenges, topological data analysis has emerged as a promising tool to reveal these complex models. In this work, we present a review of the emerging field of interpreting deep neural networks using topological data analysis. We organize the existing body of work into distinct analytical categories, highlighting interpretations based on the topology of data, network structural characteristics, network functional characteristics, and techniques derived from Mapper. The objective of this paper is to extract the research pattern of this area, and point out the future research direction.},
  archive      = {J_NEUCOM},
  author       = {Ben Zhang and Zitong He and Hongwei Lin},
  doi          = {10.1016/j.neucom.2024.128513},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128513},
  shortjournal = {Neurocomputing},
  title        = {A comprehensive review of deep neural network interpretation using topological data analysis},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Periodic update rule with q-learning promotes evolution of
cooperation in game transition with punishment mechanism.
<em>NEUCOM</em>, <em>609</em>, 128510. (<a
href="https://doi.org/10.1016/j.neucom.2024.128510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative behavior assumes a critical role in resolving conflicts arising between collective and individual interests, while punishment measures serve as a robust deterrent against opportunistic free-riding. Within this context, evolutionary game theory (EGT) emerges as an indispensable paradigm for addressing this multifaceted issue. When it comes to introspection behaviors, reinforcement learning (RL) methods exhibit remarkable capabilities to capture agents’ cognitive processes. Nonetheless, previous research has often focused on a static and time-invariant update rule, neglecting the dynamic nature of real-world scenarios where individuals can flexibly transit between strategies in periodic time-dependent patterns. Here, we propose periodic update rules with Q-learning algorithm and game transition model with a punishment mechanism that grants cooperative agents the autonomy to exercise discretion in deciding whether to initiate punishment actions. The agents display dynamic rules periodically through game model transitions, thus ensuring EGT’s inherent adaptability. By employing Monte Carlo (MC) simulations, we analyze the emergence of cooperation that underscores the substantial enhancement of cooperative behavior through the proposed periodic update rules with Q-learning algorithm and game transitions in the presence of punishment. Our study highlights the indispensable significance of appropriate periodic intervals for updating rules and determining optimal punishment costs in the game transition model as critical elements for fostering the evolution of cooperation in real-world scenarios.},
  archive      = {J_NEUCOM},
  author       = {Zeyuan Yan and Li Li and Jun Shang and Hui Zhao},
  doi          = {10.1016/j.neucom.2024.128510},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128510},
  shortjournal = {Neurocomputing},
  title        = {Periodic update rule with Q-learning promotes evolution of cooperation in game transition with punishment mechanism},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rainforest: A three-stage distribution adaptation framework
for unsupervised time series domain adaptation. <em>NEUCOM</em>,
<em>609</em>, 128507. (<a
href="https://doi.org/10.1016/j.neucom.2024.128507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving the unsupervised domain adaptation (UDA) task in time series is of great significance for practical applications, such as human activity recognition and machine fault diagnosis. Compared to UDA for computer vision, UDA in time series is more challenging due to the dynamics of time series data and the complex dependencies among different time steps. Existing UDA methods for time series fail to adequately capture the temporal dependencies, limiting their ability to learn domain-invariant temporal patterns. Furthermore, most UDA methods only focus on distribution adaptation on the backbone network without considering how the classifier adapts to the data distribution of the target domain. In this paper, we propose Rainforest, a three-stage UDA framework for time series. We first pre-train the backbone network through a self-supervised method called bidirectional autoregression, so that the model can comprehensively learn the temporal dependencies in time series. Next, we propose a novel meta-learning-based distribution adaptation method to achieve the joint alignment of the global and local distributions while encouraging the model to adaptively reduce the temporal dynamic differences among different domains. Finally, we design a pseudo-label-guided fine-tuning strategy to help the classifier estimate the data distribution of the target domain more accurately. Extensive experiments on four real-world time series datasets show that our Rainforest outperforms state-of-the-art methods, with an average improvement of 2.19% in accuracy and 2.41% in MF1-score.},
  archive      = {J_NEUCOM},
  author       = {Yingyi Zhong and Wen’an Zhou},
  doi          = {10.1016/j.neucom.2024.128507},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128507},
  shortjournal = {Neurocomputing},
  title        = {Rainforest: A three-stage distribution adaptation framework for unsupervised time series domain adaptation},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heterogeneous-branch integration framework: Introducing
first-order predicate logic in logical reasoning question answering.
<em>NEUCOM</em>, <em>609</em>, 128504. (<a
href="https://doi.org/10.1016/j.neucom.2024.128504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The logical reasoning question-answering is a critical task in natural language processing, as it equips models with human-like logical reasoning intelligence. Existing approaches focus on extracting and leveraging the hidden logical structures within text. However, previous works explore partial logical relationships and neglect the holistic extraction within the text. Moreover, they struggle to fully model logical connections, including long-distance dependencies and local topology information. To address these issues, we propose a novel heterogeneous-branch integration framework. Our framework is based on first-order predicate logic theory and consists of three primary components. First, we construct two heterogeneous logical graphs to model logical relationships within and between propositions. Second, we propose a novel Graph-Masked Transformer with a novel graph-masked multi-head attention mechanism to enable distant node interactions and local sparse relationship modeling. Third, we propose a novel multi-branch fusion module to integrate information from multiple sources and generate answer predictions. The proposed heterogeneous-branch integration framework outperforms the VDGN method by 2.73% in accuracy on the ReClor dataset and 2.15% on the LogiQA dataset. Our code and models will be made available at https://github.com/starry-y/HBI .},
  archive      = {J_NEUCOM},
  author       = {Jianyu Yue and Xiaojun Bi and Zheng Chen},
  doi          = {10.1016/j.neucom.2024.128504},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128504},
  shortjournal = {Neurocomputing},
  title        = {Heterogeneous-branch integration framework: Introducing first-order predicate logic in logical reasoning question answering},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inductive relation prediction with information bottleneck.
<em>NEUCOM</em>, <em>609</em>, 128503. (<a
href="https://doi.org/10.1016/j.neucom.2024.128503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inductive relation prediction is an important learning task for knowledge graph completion that aims to infer new facts from existing ones. Previous works that focus on path-based are naturally limited in expressive. The methods based on graph neural network framework consider all paths thus improving the performance. However, fusing all paths information may extract features that are spuriously correlated with the prediction. By analogy to the human reasoning process, we observe that only a small subset of the critical paths determine the prediction. In this work, we propose a novel framework that extracts such critical paths to make inductive relation prediction on K nowledge G raph with G raph I nformation B ottleneck ( KG-GIB ). KG-GIB is the first attempt to advance the Graph Information Bottleneck (GIB) for inductive relation prediction. Derived from the GIB principle, KG-GIB extracts critical paths which preserves task-relevant paths and blocks information from task-irrelevant paths. The extracted critical paths are expected to be more generalizable and interpretable. Extensive experiments on both synthetic and real-world datasets demonstrate the effectiveness of KG-GIB.},
  archive      = {J_NEUCOM},
  author       = {Han Yu and Kai Chen and Ziniu Liu and Hongkui Tu and Aiping Li},
  doi          = {10.1016/j.neucom.2024.128503},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128503},
  shortjournal = {Neurocomputing},
  title        = {Inductive relation prediction with information bottleneck},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bipartite consensus for multi-agent systems over signed
networks: A novel dynamic event-triggered mechanism. <em>NEUCOM</em>,
<em>609</em>, 128502. (<a
href="https://doi.org/10.1016/j.neucom.2024.128502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the problem of dynamic event-triggered bipartite consensus control for nonlinear multi-agent systems based on signed networks. A new dynamic event-triggered control mechanism is proposed, whereby an adjustment variable is introduced to dynamically schedule the triggering frequency, enabling the minimization of the triggering times while ensuring system performance. Based on the designed event-triggered control algorithm, sufficient conditions are derived to guarantee that bipartite consensus can be reached by the considered nonlinear multi-agent system. Furthermore, it is proved that Zeno behavior will not occur. Numerical examples are provided in this paper to verify the effectiveness of the proposed control algorithm. The simulation results reveal that, compared with the static event-triggered mechanism and the traditional dynamic event-triggered mechanism, the proposed event-triggered algorithm can further reduce the triggering times and enhance the flexibility of the event-triggered mechanism.},
  archive      = {J_NEUCOM},
  author       = {Jie Ren and Liang Hua and Min Zhao and Guoping Lu},
  doi          = {10.1016/j.neucom.2024.128502},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128502},
  shortjournal = {Neurocomputing},
  title        = {Bipartite consensus for multi-agent systems over signed networks: A novel dynamic event-triggered mechanism},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meta-adaptable-adapter: Efficient adaptation of
self-supervised models for low-resource speech recognition.
<em>NEUCOM</em>, <em>609</em>, 128493. (<a
href="https://doi.org/10.1016/j.neucom.2024.128493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised models have demonstrated remarkable performance in speech processing by learning latent representations from large amounts of unlabeled data. Adapting these models to low-resource languages yields promising results, but the computational cost of fine-tuning all model parameters is prohibitively high. Adapters offer a solution by introducing lightweight bottleneck structures into pre-trained models for downstream tasks, enabling efficient parameter adaptation. However, randomly initialized adapters often underperform in extremely low-resource scenarios. To address this issue, we explore the Meta-Adapter for self-supervised models and analyzed some limitations of Meta-Adapter including poor learning in language-specific knowledge and meta-overfitting problems. To relieve these problems, we propose the Meta-Adaptable-Adapter (MAA), a new meta leaning algorithm that adapts to low-resource languages quickly and effectively. MAA learns task-specific adapters for feature extraction, and task-independent adapters for feature combination. The experiments on three datasets show superior performance on 31 low-resource languages across seven different language families compared to other adapters, showing better generalization and extensibility.},
  archive      = {J_NEUCOM},
  author       = {Yaqi Chen and Hao Zhang and Xukui Yang and Wenlin Zhang and Dan Qu},
  doi          = {10.1016/j.neucom.2024.128493},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128493},
  shortjournal = {Neurocomputing},
  title        = {Meta-adaptable-adapter: Efficient adaptation of self-supervised models for low-resource speech recognition},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nearest neighbors and density-based undersampling for
imbalanced data classification with class overlap. <em>NEUCOM</em>,
<em>609</em>, 128492. (<a
href="https://doi.org/10.1016/j.neucom.2024.128492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While addressing the problem of imbalanced data classification, most existing resampling methods primarily focus on balancing class distribution. However, they often overlook class overlap and fail to adequately consider the feature distributions of different classes. Consequently, when resampling is performed under such conditions, samples within areas of overlap remain susceptible to misclassification, failing to substantially improve overall performance. To address these shortcomings, we propose a novel data resampling technique, Nearest Neighbors and Density-based Undersampling (NDU). This method employs within-class k-nearest neighbors and between-class probability densities to design a weight assignment strategy. Leveraging this strategy, we establish an exclusive metric, the F_factor, to evaluate the importance of majority class samples in overlap areas. Subsequently, NDU promotes a gradient-based segmented undersampling strategy, which applies varying degrees of undersampling to majority class samples across segmented regions. Through experiments on binary imbalanced datasets with class overlap, we evaluate the efficiency of diverse resampling methods concerning classification performance. The results demonstrate that our proposed method effectively addresses class overlap challenges.},
  archive      = {J_NEUCOM},
  author       = {Peiqi Sun and Yanhui Du and Siyun Xiong},
  doi          = {10.1016/j.neucom.2024.128492},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128492},
  shortjournal = {Neurocomputing},
  title        = {Nearest neighbors and density-based undersampling for imbalanced data classification with class overlap},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of graph neural networks and pretrained language
models for knowledge graph reasoning. <em>NEUCOM</em>, <em>609</em>,
128490. (<a href="https://doi.org/10.1016/j.neucom.2024.128490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph (KG) stores human knowledge facts in an intuitive graphical structure but faces challenges such as incomplete construction or inability to handle new knowledge. Knowledge Graph Reasoning (KGR) can make KGs more accurate, complete, and trustworthy to support various artificial intelligence applications better. Currently, the popular KGR methods are based on graph neural networks (GNNs). Recent studies have shown that hybrid logic rules and synergized pre-trained language models (PLMs) can enhance the GNN-based KGR methods. These methods mainly focus on data sparsity, insufficient knowledge evolution patterns, multi-modal fusion, and few-shot reasoning. Although many studies have been conducted, there are still few review papers that comprehensively summarize and explore KGR methods related to GNNs, logic rules, and PLMs. Therefore, this paper provides a comprehensive review of GNNs and PLMs for KGR based on a large number of high-quality papers. To present a clear overview of KGR, we propose a general framework. Specifically, we first introduce the KG preparation. Then we provide an overview of KGR methods, in which we categorize KGR methods into GNNs-based, logic rules-enhanced, and pre-trained language models-enhanced KGR methods. Furthermore, we also compare and analyze the GNN-based KGR methods in two scenarios. Moreover, we also present the application of KGR in different fields. Finally, we discuss the current challenges and future research directions for KGR.},
  archive      = {J_NEUCOM},
  author       = {Jiangtao Ma and Bo Liu and Kunlin Li and Chenliang Li and Fan Zhang and Xiangyang Luo and Yaqiong Qiao},
  doi          = {10.1016/j.neucom.2024.128490},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128490},
  shortjournal = {Neurocomputing},
  title        = {A review of graph neural networks and pretrained language models for knowledge graph reasoning},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-timescale neurodynamic approach to robust distributed
model predictive control for nonlinear systems. <em>NEUCOM</em>,
<em>609</em>, 128489. (<a
href="https://doi.org/10.1016/j.neucom.2024.128489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a robust distributed model predictive control strategy is proposed for nonlinear dynamical systems affected by bounded disturbances. Grounded on sequential quadratic programming, a two-timescale recurrent neural network paradigm is deployed for solving minimax optimization problems. Sufficient criteria for the two-timescale recurrent neural network are delineated, which specifically guarantee its stability and optimality. Under these conditions, it is demonstrated that the recurrent neural network converges to optimal solutions, thereby enhancing the robustness of the control strategy. The simulation results exhibit significantly enhanced convergence in comparison to the mono-timescale recurrent neural network.},
  archive      = {J_NEUCOM},
  author       = {Wenbo Qi and Jie Zhong and Wenying Xu and Yan Wang},
  doi          = {10.1016/j.neucom.2024.128489},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128489},
  shortjournal = {Neurocomputing},
  title        = {A two-timescale neurodynamic approach to robust distributed model predictive control for nonlinear systems},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GAP: A group-based automatic pruning algorithm via
convolution kernel fusion. <em>NEUCOM</em>, <em>609</em>, 128488. (<a
href="https://doi.org/10.1016/j.neucom.2024.128488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the deployment and operation of convolution neural networks on edge devices with limited computing capabilities have become increasingly challenging due to the large network structure and computational cost. Currently, the mainstream structured pruning algorithms mainly compress the network at the filter or layer level. However, these methods introduce too much human intervention with large granularities, which may lead to unpredictable performance after compression. In this paper, we propose a group-based automatic pruning algorithm(GAP) via kernel fusion to automatically search for the optimal pruning structure in a more fine-grained manner. Specifically, we first adopt a novel nonlinear dimensionality reduction clustering algorithm to divide the filters of each convolution layer into groups of equal size. Afterwards, we encode the mutual distribution similarity of the kernels within each group, and its KL divergence is employed as an importance indicator to determine the retained kernel groups through weighted fusion. Subsequently, we introduce an intelligent searching module that automatically explore and optimize the pruned structure of each layer. Finally, the pruned filters are permutated to form a dense group convolution and fine-tuned. Sufficient experiments show that, on two image classification datasets, for five advanced CNN models, our GAP algorithm outperforms most extant SOTA schemes, reduces artificial intervention, and enables efficient end-to-end training of compact models.},
  archive      = {J_NEUCOM},
  author       = {Dingfu Chen and Kangwei Lin and Qingxu Deng},
  doi          = {10.1016/j.neucom.2024.128488},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128488},
  shortjournal = {Neurocomputing},
  title        = {GAP: A group-based automatic pruning algorithm via convolution kernel fusion},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MaskRecon: High-quality human reconstruction via masked
autoencoders using a single RGB-d image. <em>NEUCOM</em>, <em>609</em>,
128487. (<a href="https://doi.org/10.1016/j.neucom.2024.128487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we explore reconstructing high-quality clothed 3D humans from a single RGB-D image, assuming that virtual humans can be represented by front-view and back-view depths. Due to the scarcity of captured real RGB-D human images, we employ rendered images to train our method. However, rendered images lack background with significant depth variation in silhouettes, leading to shape prediction inaccuracies and noise. To mitigate this issue, we introduce a pseudo-multi-task framework, which incorporates a Conditional Generative Adversarial Network (CGAN) to infer back-view RGB-D images and a self-supervised Masked Autoencoder (MAE) to capture latent structural information of the human body. Additionally, we propose a Multi-scale Feature Fusion (MFF) module to effectively merge structural information and conditional features at various scales. Our method surpasses many existing techniques, as demonstrated through evaluations on the Thuman, RenderPeople, and BUFF datasets. Notably, our approach excels in reconstructing high-quality human models, even under challenging conditions such as complex poses and loose clothing, both on rendered and real-world images. Codes are available at https://github.com/Archaic-Atom/MaskRecon .},
  archive      = {J_NEUCOM},
  author       = {Xing Li and Yangyu Fan and Zhe Guo and Zhibo Rao and Yu Duan and Shiya Liu},
  doi          = {10.1016/j.neucom.2024.128487},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128487},
  shortjournal = {Neurocomputing},
  title        = {MaskRecon: High-quality human reconstruction via masked autoencoders using a single RGB-D image},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-free aperiodic tracking for discrete-time systems
using hierarchical reinforcement learning. <em>NEUCOM</em>,
<em>609</em>, 128486. (<a
href="https://doi.org/10.1016/j.neucom.2024.128486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the operation of practical systems, it is often a challenging task to deal with limited knowledge of the system dynamics, therefore, it is needed to obtain a framework for the simultaneous learning and control of dynamic systems, able to cope with uncertain dynamics. This paper proposes a model-free aperiodic tracking control method based on MAXQ hierarchical reinforcement learning for unknown dynamics in discrete-time systems. Firstly, a MAXQ hierarchical framework is developed for aperiodic tracking control that decomposes the task into pre-control and accurate control subtasks. The former achieves sub-optimal tracking which prompts the implementation of accurate control. The latter implements aperiodic tracking based on the pre-control result to reduce resource occupation. The structure of the MAXQ framework simplifies the complexity of the tracking task, and the incorporation of pre-control accelerates the learning process in the formal control stage. Secondly, considering the disparities between the control inputs and the control update instants, pre-control is decomposed to learn the triggering strategy and control policy, respectively. Meanwhile, the control policy learns optimal control inputs by minimizing the cost function. Similarly, the triggering strategy and control policy are also separately learned in accurate control. In contrast to traditional aperiodic triggering mechanisms, in accurate control stage, the triggering strategy is developed based on the cumulative error of the pre-control result, thus avoiding the influence of accidental factors and the cumulative effects of errors, enhancing system robustness. Thirdly, the proposed tracking control is derived by using only the input, output, and reference signal data from the system, without relying on system dynamics. It is applicable to both linear and nonlinear systems, demonstrating strong generalizability. Finally, simulation examples are provided to validate the effectiveness and superiority of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yingqiang Tian and Haiying Wan and Hamid Reza Karimi and Xiaoli Luan and Fei Liu},
  doi          = {10.1016/j.neucom.2024.128486},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128486},
  shortjournal = {Neurocomputing},
  title        = {Model-free aperiodic tracking for discrete-time systems using hierarchical reinforcement learning},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving AI-assisted video editing: Optimized footage
analysis through multi-task learning. <em>NEUCOM</em>, <em>609</em>,
128485. (<a href="https://doi.org/10.1016/j.neucom.2024.128485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, AI-assisted video editing has shown promising applications. Understanding and analyzing camera language accurately is fundamental in video editing, guiding subsequent editing and production processes. However, many existing methods for camera language analysis overlook computational efficiency and deployment requirements in favor of improving classification accuracy. Consequently, they often fail to meet the demands of scenarios with limited computing power, such as mobile devices. To address this challenge, this paper proposes an efficient multi-task camera language analysis pipeline based on shared representations. This approach employs a multi-task learning architecture with hard parameter sharing, enabling different camera language classification tasks to utilize the same low-level feature extraction network, thereby implicitly learning feature representations of the footage. Subsequently, each classification sub-task independently learns the high-level semantic information corresponding to the camera language type. This method significantly reduces computational complexity and memory usage while facilitating efficient deployment on devices with limited computing power. Furthermore, to enhance performance, we introduce a dynamic task priority strategy and a conditional dataset downsampling strategy. The experimental results demonstrate that achieved a comprehensive accuracy surpassing all previous methods. Moreover, training time was reduced by 66.33%, inference cost decreased by 59.85%, and memory usage decreased by 31.95% on the 2-task dataset MovieShots; on the 4-task dataset AVE, training time was reduced by 95.34%, inference cost decreased by 97.23%, and memory usage decreased by 61.21%.},
  archive      = {J_NEUCOM},
  author       = {Yuzhi Li and Haojun Xu and Feifan Cai and Feng Tian},
  doi          = {10.1016/j.neucom.2024.128485},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128485},
  shortjournal = {Neurocomputing},
  title        = {Improving AI-assisted video editing: Optimized footage analysis through multi-task learning},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fully-inductive link prediction with path-based graph neural
network: A comparative analysis. <em>NEUCOM</em>, <em>609</em>, 128484.
(<a href="https://doi.org/10.1016/j.neucom.2024.128484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, fully-inductive link prediction in knowledge graphs (KGs) has aimed to predict missing links between unseen–unseen entities, independently completing evolving KGs. The latest literature emphasizes path-based graph neural network (GNN) methods, which combine traditional path-based methods with popular GNN methods, possessing generalization capability, interpretability, scalability, and high model capacity under the inductive setting. This paper presents the first comparative analysis of fully-inductive link prediction using path-based GNNs. First, we comprehensively review and summarize the research of six relevant models, divided into relational digraph-based models and Bellman–Ford algorithm-based models. Based on this, we conduct a comprehensive analysis of these models in terms of effectiveness and efficiency (including runtime, memory, and learning curves), and compared them with two subgraph-based models. Furthermore, we delve into the impact of factors such as message functions, aggregation functions, and negative sampling in the loss function on path-based GNNs. Finally, we provide an outlook on future research directions.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Liang and Guannan Si and Jianxin Li and Zhaoliang An and Pengxin Tian and Fengyu Zhou},
  doi          = {10.1016/j.neucom.2024.128484},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128484},
  shortjournal = {Neurocomputing},
  title        = {Fully-inductive link prediction with path-based graph neural network: A comparative analysis},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parallel hyperparameter optimization of spiking neural
networks. <em>NEUCOM</em>, <em>609</em>, 128483. (<a
href="https://doi.org/10.1016/j.neucom.2024.128483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperparameter optimization of spiking neural networks (SNNs) is a difficult task which has not yet been deeply investigated in the literature. In this work, we designed a scalable constrained Bayesian based optimization algorithm that prevents sampling in non-spiking areas of an efficient high dimensional search space. These search spaces contain infeasible solutions that output no or only a few spikes during the training or testing phases, we call such a mode a “silent network”. Finding them is difficult, as many hyperparameters are highly correlated to the architecture and to the dataset. We leverage silent networks by designing a spike-based early stopping criterion to accelerate the optimization process of SNNs trained by spike timing dependent plasticity and surrogate gradient. We parallelized the optimization algorithm asynchronously, and ran large-scale experiments on heterogeneous multi-GPU Petascale architecture. Results show that by considering silent networks, we can design more flexible high-dimensional search spaces while maintaining a good efficacy. The optimization algorithm was able to focus on networks with high performances by preventing costly and worthless computation of silent networks.},
  archive      = {J_NEUCOM},
  author       = {Thomas Firmin and Pierre Boulet and El-Ghazali Talbi},
  doi          = {10.1016/j.neucom.2024.128483},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128483},
  shortjournal = {Neurocomputing},
  title        = {Parallel hyperparameter optimization of spiking neural networks},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved hierarchical deep reinforcement learning
algorithm for multi-intelligent vehicle lane change. <em>NEUCOM</em>,
<em>609</em>, 128482. (<a
href="https://doi.org/10.1016/j.neucom.2024.128482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lane change is a pivotal technology in autonomous driving, playing a significant role in improving traffic conditions. The control task of lane change becomes exceptionally complex for coordination of multiple intelligent vehicles, especially in unpredictable situations. To address this issue, the paper proposes a novel multi-intelligent vehicle lane change method (MVLC) based on Deep Reinforcement Learning (DRL). The MVLC features a hierarchical framework that includes a lower-layer lane change controller and an upper-layer reinforcement learning decision-making method. In the lower layer, a lane change controller is designed to execute motion control for a single vehicle, consisting of a lateral controller utilizing dueling double deep Q-network to make lane change decision and a longitudinal controller that employs Intelligent Driver Model (IDM) to follow the preceding vehicle. In the upper layer, a model-free DRL method is used for simultaneous control of multiple intelligent vehicles. To learn the optimal policy, a comprehensive reward function is designed. Finally, experiments are conducted in mixed traffic to valid the effectiveness of the proposed method. Results show that MVLC achieves secure and timely lane changes for multiple vehicles. Therefore, the method is expected to have significant potential for improving overall traffic efficiency and mitigating traffic congestion.},
  archive      = {J_NEUCOM},
  author       = {Hongbo Gao and Ming Zhao and Xiao Zheng and Chengbo Wang and Lin Zhou and Yafei Wang and Lei Ma and Bo Cheng and Zhenyu Wu and Yuansheng Li},
  doi          = {10.1016/j.neucom.2024.128482},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128482},
  shortjournal = {Neurocomputing},
  title        = {An improved hierarchical deep reinforcement learning algorithm for multi-intelligent vehicle lane change},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unidirectional and hierarchical on-chip interconnected
architecture for large-scale hardware spiking neural networks.
<em>NEUCOM</em>, <em>609</em>, 128480. (<a
href="https://doi.org/10.1016/j.neucom.2024.128480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) exhibit the strong capability to address spatiotemporal dynamic problems. Recent research has explored the hardware SNN systems to solve the spatiotemporal problems in real-time. The Network-on-Chip (NoC) is an effective scheme for building large-scale hardware SNNs. However, for the existing NoC-based hardware SNNs, large area overhead and hardware power are consumed by their interconnections, because of complex topologies and router structures. Therefore, in this work a novel Unidirectional and Hierarchical on-Chip Interconnected Architecture (UHCIA) is proposed to address this problem. The proposed UHCIA mainly combines the novel hybrid topology of unidirectional multiple loops and rings, and uses a deflection router technique. Experimental results show that compared to other works, the UHCIA achieves ∼ ∼ 23.6X of area reduction and ∼ ∼ 6.4X of power reduction, with high system throughput and biological real-time computations.},
  archive      = {J_NEUCOM},
  author       = {Junxiu Liu and Dong Jiang and Qiang Fu and Yuling Luo and Yaohua Deng and Sheng Qin and Shunsheng Zhang},
  doi          = {10.1016/j.neucom.2024.128480},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128480},
  shortjournal = {Neurocomputing},
  title        = {Unidirectional and hierarchical on-chip interconnected architecture for large-scale hardware spiking neural networks},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review on video person re-identification based on deep
learning. <em>NEUCOM</em>, <em>609</em>, 128479. (<a
href="https://doi.org/10.1016/j.neucom.2024.128479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person Re-Identification (ReID) is an essential technology for matching a person across non-overlapping cameras. It has attracted increasing attention in recent years due to its wide range of applications in various real-world scenarios such as security surveillance and criminal investigation. Different from other person ReID tasks, video-based ReID uses a video clip as the retrieval input, which can provide more promising ReID performance because that the video has rich information on appearance, motion cues and pose variations on temporal pipeline. Over the last few years, many deep learning-based video person ReID have been proposed to address various challenges, such as illumination variation, complex background, occlusion, etc. To provide a more comprehensive and readable review on existing video-based person ReID methods, we propose a novel taxonomy method that observes existing methods from four perspectives: data, algorithms, computing power, and applications. Specifically, we first introduce some popular datasets and evaluation criterion used for video-based person ReID. Next, from limited data and little annotation view, we introduce data augmentation and unsupervised learning ReID. From algorithm view, we focus on reviewing supervised methods including spatial feature learning, temporal feature learning and spatio-temporal feature learning, and further discuss and conduct a systematic comparison among these approaches. From complex open-world application view, we mainly summarized domain adaption and multimodal ReID. From insufficient GPU computing power view, we mainly discuss modality-agnostic unified large-scale ReID and their lightweighting. Finally, we provide a discussion of open problems and potential research directions for the community.},
  archive      = {J_NEUCOM},
  author       = {Haifei Ma and Canlong Zhang and Yifeng Zhang and Zhixin Li and Zhiwen Wang and Chunrong Wei},
  doi          = {10.1016/j.neucom.2024.128479},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128479},
  shortjournal = {Neurocomputing},
  title        = {A review on video person re-identification based on deep learning},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An open chest x-ray dataset with benchmarks for automatic
radiology report generation in french. <em>NEUCOM</em>, <em>609</em>,
128478. (<a href="https://doi.org/10.1016/j.neucom.2024.128478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical report generation (MRG), which aims to automatically generate a textual description of a specific medical image (e.g., a chest X-ray), has recently received increasing research interest. Building on the success of image captioning, MRG has become achievable. However, generating language-specific radiology reports poses a challenge for data-driven models due to their reliance on paired image-report chest X-ray datasets, which are labor-intensive, time-consuming, and costly. In this paper, we introduce a chest X-ray benchmark dataset, namely CASIA-CXR , consisting of high-resolution chest radiographs accompanied by narrative reports originally written in French. To the best of our knowledge, this is the first public chest radiograph dataset with medical reports in this particular language. Importantly, we propose a simple yet effective multimodal encoder–decoder contextually-guided framework for medical report generation in French. We validated our framework through intra-language and cross-language contextual analysis, supplemented by expert evaluation performed by radiologists. The dataset is freely available at: https://www.casia-cxr.net/ .},
  archive      = {J_NEUCOM},
  author       = {Hichem Metmer and Xiaoshan Yang},
  doi          = {10.1016/j.neucom.2024.128478},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128478},
  shortjournal = {Neurocomputing},
  title        = {An open chest X-ray dataset with benchmarks for automatic radiology report generation in french},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Gated parametric neuron for spike-based audio recognition.
<em>NEUCOM</em>, <em>609</em>, 128477. (<a
href="https://doi.org/10.1016/j.neucom.2024.128477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) aim to simulate real neural networks in the human brain with biologically plausible neurons. The leaky integrate-and-fire (LIF) neuron is one of the most widely studied SNN architectures. However, it has the vanishing gradient problem when trained with backpropagation. Additionally, its neuronal parameters are often manually specified and fixed, in contrast to the heterogeneity of real neurons in the human brain. This paper proposes a gated parametric neuron (GPN) to process spatio-temporal information effectively with the gating mechanism. Compared with the LIF neuron, the GPN has two distinguishing advantages: (1) it copes well with the vanishing gradients by improving the flow of gradient propagation; and, (2) it learns spatio-temporal heterogeneous neuronal parameters automatically. Additionally, we use the same gate structure to eliminate initial neuronal parameter selection and design a hybrid recurrent neural network-SNN structure. Experiments on two spike-based audio datasets demonstrated that the GPN network outperformed several state-of-the-art SNNs, could mitigate vanishing gradients, and had spatio-temporal heterogeneous parameters. Our work shows the ability of SNNs to handle long-term dependencies and achieve high performance simultaneously.},
  archive      = {J_NEUCOM},
  author       = {Haoran Wang and Herui Zhang and Siyang Li and Dongrui Wu},
  doi          = {10.1016/j.neucom.2024.128477},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128477},
  shortjournal = {Neurocomputing},
  title        = {Gated parametric neuron for spike-based audio recognition},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Polycentric intuitionistic fuzzy weighted least squares
twin SVMs. <em>NEUCOM</em>, <em>609</em>, 128475. (<a
href="https://doi.org/10.1016/j.neucom.2024.128475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of data with outliers and noise has always been one of the principal challenges within machine learning. The previous unicentric-based fuzzy twin support vector machines (SVMs) typically allot the membership through proximity to the center of the samples, which neglects the global structural information and the local neighborhood information and potentially causes confusion between fringe support vectors and outliers. In this paper, a polycentric intuitionistic fuzzy weighted least squares twin SVMs (PIFW-LSTSVM) is presented to alleviate the above issue. Concretely, the PIFW-LSTSVM model simultaneously assigns membership and nonmembership to each sample, where the membership is determined by the sample proximity to the corresponding nearest center, and nonmembership is identified by neighborhood entropy. Benefiting from the novel polycentric weighting strategy, the PIFW-LSTSVM model mitigates the impact of outliers and noise and reduces the confusion between fringe support vectors and outliers or noise, thereby boosting the generalization ability. The experiments, conducted on both artificial and real-world benchmark datasets, comprehensively demonstrate the effectiveness and superiority of the PIFW-LSTSVM model compared to other state-of-the-art models.},
  archive      = {J_NEUCOM},
  author       = {Liang Liu and Shuaiyong Li and Xu Zhang and Zhengxu Dai and Yongqiang Zhu},
  doi          = {10.1016/j.neucom.2024.128475},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128475},
  shortjournal = {Neurocomputing},
  title        = {Polycentric intuitionistic fuzzy weighted least squares twin SVMs},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Introducing new node prediction in graph mining: Predicting
all links from isolated nodes with graph neural networks.
<em>NEUCOM</em>, <em>609</em>, 128474. (<a
href="https://doi.org/10.1016/j.neucom.2024.128474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces new node prediction , a fresh problem in the field of graph mining and social network analysis. This task can be categorized as zero-shot out-of-graph all-links prediction , and aims to predict all links coming from or going to a new, isolated, and unobserved node that was previously disconnected from the graph. In comparison with classic approaches to link prediction (including few-shot out-of-graph link prediction), this problem bears two key differences: (1) the new node has no existing links from which to extract patterns for new predictions; and (2) the goal is to predict not just one, but all the links of this new node, or, at least, a significant part of them. Experiments used an architecture based on Deep Graph Neural Networks, and were carried out on two datasets: a bibliographic citation graph and a drug–drug interaction graph. Results demonstrate that this challenging problem can be solved satisfactorily by using state-of-the-art Deep Learning techniques.},
  archive      = {J_NEUCOM},
  author       = {Damiano Zanardini and Emilio Serrano},
  doi          = {10.1016/j.neucom.2024.128474},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128474},
  shortjournal = {Neurocomputing},
  title        = {Introducing new node prediction in graph mining: Predicting all links from isolated nodes with graph neural networks},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised accuracy predictor-based multi-objective
neural architecture search. <em>NEUCOM</em>, <em>609</em>, 128472. (<a
href="https://doi.org/10.1016/j.neucom.2024.128472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of neural architecture search (NAS) demonstrates the deep exploration between the neural network architecture and its performance (e.g., accuracy). Many NAS methods are inefficient because they train all candidates from scratch to obtain their accuracies. Although predictor-based NAS algorithms have been vigorously developed to efficiently and accurately evaluate the performance of candidate architectures, the training of accuracy predictors still require hundreds of architectures with ground truth. To overcome this shortcoming, this paper investigates an evolutionary-based NAS method, which constructs a semi-supervised accuracy predictor to efficiently and accurately evaluate candidate architectures. A one-time extractor and strong regressors are implemented to further enhance the prediction performance of the semi-supervised accuracy predictor. Furthermore, a multi-objective approach is developed to find architectures with high ground truth in a tradeoff between high prediction accuracy and prediction confidence. Experimental results demonstrate the strong competitiveness of the proposed approach on NAS benchmarks. The code is available at https://github.com/outofstyle/SAPMNAS .},
  archive      = {J_NEUCOM},
  author       = {Songyi Xiao and Bo Zhao and Derong Liu},
  doi          = {10.1016/j.neucom.2024.128472},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128472},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised accuracy predictor-based multi-objective neural architecture search},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reward shaping via expectation maximization method.
<em>NEUCOM</em>, <em>609</em>, 128471. (<a
href="https://doi.org/10.1016/j.neucom.2024.128471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement Learning (RL) has found widespread applications in various decision making tasks. However, it still faces challenges such as the deadly triad, slow convergence, and rewards drop, which limit its practical scope. This paper primarily addresses the issues of slow convergence and rewards drop observed during RL training. Our proposed solution involves a reward shaping method composed of two distinct components, each serving a specific purpose: speeding up training and enhancing stability. These two components are interconnected through hyper-parameters, and it has been observed that the choice of hyper-parameters plays a critical role in determining the final performance of the RL algorithm. To optimize these hyper-parameters effectively, we employ a discrete sampling technique to cover the value ranges of these parameters. This discrete sampling creates a sparse set of data points within the reward matrix. Subsequently, we introduce a fitting approach based on the Expectation Maximization (EM) algorithm to estimate the global maximum of the reward matrix along with the corresponding hyper-parameters combination. This EM method significantly reduces computational complexity. Our extensive experimental results across various RL environments have demonstrated the effectiveness of our proposed method. It successfully mitigates the issue of rewards drop while simultaneously accelerating the convergence speed of the RL algorithm.},
  archive      = {J_NEUCOM},
  author       = {Zelin Deng and Xing Liu and Yunlong Dong},
  doi          = {10.1016/j.neucom.2024.128471},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128471},
  shortjournal = {Neurocomputing},
  title        = {Reward shaping via expectation maximization method},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Building efficient CNNs using depthwise convolutional
eigen-filters (DeCEF). <em>NEUCOM</em>, <em>609</em>, 128461. (<a
href="https://doi.org/10.1016/j.neucom.2024.128461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Convolutional Neural Networks (CNNs) have been widely used in various domains due to their impressive capabilities. These models are typically composed of a large number of 2D convolutional (Conv2D) layers with numerous trainable parameters. To manage the complexity of such networks, compression techniques can be applied, which typically rely on the analysis of trained deep learning models. However, in certain situations, training a new CNN from scratch may be infeasible due to resource limitations. In this paper, we propose an alternative parameterization to Conv2D filters with significantly fewer parameters without relying on compressing a pre-trained CNN. Our analysis reveals that the effective rank of the vectorized Conv2D filters decreases with respect to the increasing depth in the network. This leads to the development of the Depthwise Convolutional Eigen-Filter (DeCEF) layer, which is a low rank version of the Conv2D layer with significantly fewer trainable parameters and floating point operations (FLOPs). The way we define the effective rank is different from previous work, and it is easy to implement and interpret. Applying this technique is straightforward – one can simply replace any standard convolutional layer with a DeCEF layer in a CNN. To evaluate the effectiveness of DeCEF layers, experiments are conducted on the benchmark datasets CIFAR-10 and ImageNet for various network architectures. The results have shown a similar or higher accuracy using about 2/3 of the original parameters and reducing the number of FLOPs to 2/3 of the base network. Additionally, analyzing the patterns in the effective rank provides insights into the inner workings of CNNs and highlights opportunities for future research.},
  archive      = {J_NEUCOM},
  author       = {Yinan Yu and Samuel Scheidegger and Tomas McKelvey},
  doi          = {10.1016/j.neucom.2024.128461},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128461},
  shortjournal = {Neurocomputing},
  title        = {Building efficient CNNs using depthwise convolutional eigen-filters (DeCEF)},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on personalized document-level sentiment analysis.
<em>NEUCOM</em>, <em>609</em>, 128449. (<a
href="https://doi.org/10.1016/j.neucom.2024.128449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized document-level sentiment analysis (PDSA) plays an important role in many real-world applications. So far, various deep learning models for PDSA have been proposed. However, there has been no systematic survey in this area. To address this issue, in this paper, we overview the existing methods of PDSA, and propose a novel two-dimensional PDSA taxonomy. Specifically, in the dimension of attribute usage type , PDSA works are divided into two groups: (1) user-based and (2) user and product-based models. In the dimension of attribute processing method , PDSA works are divided into two groups: (1) feature-based and (2) relation-based models. To fill in the research blank indicated by the taxonomy, we further propose an architecture named User Correlation Mining (UCM) for PDSA. Specifically, UCM contains two components, namely Similar User Cluster Module (SUCM) and Triple Attributes BERT Model (TABM). SUCM is responsible for user clustering, and TABM aims to classify the user’s sentiment based on the information of users, products, user clusters and user reviews. To evaluate the performances of the existing works as well as UCM, we conduct extensive experiments on three real-world datasets. The experiment results show that our proposed architecture UCM outperforms the other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Wenhao Zhu and Jiayue Qiu and Ziyue Yu and Wuman Luo},
  doi          = {10.1016/j.neucom.2024.128449},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128449},
  shortjournal = {Neurocomputing},
  title        = {A survey on personalized document-level sentiment analysis},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A prediction method of diabetes comorbidity based on
non-negative latent features. <em>NEUCOM</em>, <em>609</em>, 128447. (<a
href="https://doi.org/10.1016/j.neucom.2024.128447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a novel network-based approach, namely Inherently Non-negative Latent Feature Analysis for Diabetes Mellitus Comorbidity Detection (INDM), to enhance the detection and analysis of comorbidities associated with diabetes mellitus. Different from existing methods, INDM is the first computational approach that integrates comorbidity networks of the chronic disease spectrum with patient clinical characteristics. To perform the analytical tasks, the proposed INDM adopts the following core components. First, comorbidity networks representing patients diagnosed solely with hypertension and those with hypertension and diabetes are constructed, following the case-control design that establishes a 1:1 matching in age and gender between two cohorts. Subsequently, the disease set is modeled in the comorbidity network according to the relative risk methodology. This enables nodes and edges in the comorbidity network to represent disease interactions that are derived from the patient-disease bipartite graph. Second, a nonlinear loss function with the capability of inherently non-negative latent feature analysis followed by a comorbidity classifier is adopted to uncover the patterns indicating the diabetes comorbidity in the comorbidity network. The proposed INDM has been rigorously tested on actual diabetes comorbidity datasets. The notable results demonstrate that INDM exhibits superior detection accuracy. Furthermore, the topological structure discovered by the proposed INDM can provide a profound insight into hypertension comorbidity in both the case and control groups.},
  archive      = {J_NEUCOM},
  author       = {Leming Zhou and Kechen Liu and Yonghong Wang and Hanshu Qin and Tiantian He},
  doi          = {10.1016/j.neucom.2024.128447},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128447},
  shortjournal = {Neurocomputing},
  title        = {A prediction method of diabetes comorbidity based on non-negative latent features},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GNN-based multi-source domain prototype representation for
cross-subject EEG emotion recognition. <em>NEUCOM</em>, <em>609</em>,
128445. (<a href="https://doi.org/10.1016/j.neucom.2024.128445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition based on electroencephalography (EEG) signals is a major area of affective computing. However, the existence of distributional differences between subjects has greatly hindered the large-scale application of EEG emotion recognition techniques. Most of the existing cross-subject methods primarily concentrate on treating multiple subjects as a single source domain. These methods lead to significant distributional differences within the source domain, which hinder the model’s ability to generalise effectively to target subjects. In this paper, we propose a new method that combines graph neural network-based prototype representation of multiple source domains with clustering similarity loss. It consists of three parts: multi-source domain prototype representation, graph neural network and loss. Multi-source domain prototype representation treats different subjects in the source domain as sub-source domains and extracts prototype features, which learns a more fine-grained feature representation. Graph neural network can better model the association properties between prototypes and samples. In addition, we propose a similarity loss based on clustering idea. The loss makes maximum use of similarity between samples in the target domain while ensuring that the classification performance does not degrade. We conduct extensive experiments on two benchmark datasets, SEED and SEED IV. The experimental results validate the effectiveness of the proposed multi-source domain fusion approach and indicate its superiority over existing methods in cross-subject classification tasks.},
  archive      = {J_NEUCOM},
  author       = {Yi Guo and Chao Tang and Hao Wu and Badong Chen},
  doi          = {10.1016/j.neucom.2024.128445},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128445},
  shortjournal = {Neurocomputing},
  title        = {GNN-based multi-source domain prototype representation for cross-subject EEG emotion recognition},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatial exchanging fusion network for RGB-t crowd counting.
<em>NEUCOM</em>, <em>609</em>, 128433. (<a
href="https://doi.org/10.1016/j.neucom.2024.128433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-T crowd counting (RGB-T CC) aims to estimate the crowd population size utilizing the complementary information from visible and thermal images. Current deep models for RGB-T CC typically adopt a three-tier architecture, featuring a middle fusion layer that aggregates both RGB and thermal streams. However, we find that this dedicated fusion layer dominates the training process, causing under-optimization of both modal branches, which becomes the performance bottleneck in mainstream multi-modal counting models. To address this challenge, we propose a simple-yet-effective counting architecture, the Spatial Exchanging Fusion Network (SEFNet). It is built on a Dual Attention Guided Spatial Exchanging (DASE) mechanism, enabling direct extraction and exchange of modality-complementary features between modalities without the extra fusion branch employed in most existing works. This design ensures a more balanced gradient back-propagation over networks, attaining optimized representations in multi-modality fusion over prior models. Besides, the Modality Gradient Enhancement Module (MGEM) in SEFNet can effectively learn modality-specific crowd representations with two counting sub-tasks, dynamically achieving better gradient distribution and further enhancing optimization in both modalities. Extensive experiments demonstrate that SEFNet significantly outperforms state-of-the-art methods on mainstream benchmark datasets, and also exhibits promising generalization ability across various counting backbones and losses.},
  archive      = {J_NEUCOM},
  author       = {Chaoqun Rao and Lin Wan},
  doi          = {10.1016/j.neucom.2024.128433},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128433},
  shortjournal = {Neurocomputing},
  title        = {Spatial exchanging fusion network for RGB-T crowd counting},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A simple multi-constraint fusion based semi-supervised
non-negative matrix decomposition for image clustering. <em>NEUCOM</em>,
<em>609</em>, 128432. (<a
href="https://doi.org/10.1016/j.neucom.2024.128432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised non-negative matrix decomposition (SNMF) is a highly interpretable image clustering algorithm. We typically incorporate graph learning to enhance the model’s representation ability, while adding positive and negative labeling information and pairwise constraints to prevent overfitting and improve the discriminative performance. However, embedding positive and negative labels and pairwise constraints simultaneously in the SNMF model is challenging due to their dimension mismatch. Thus We propose a method named multi-constraint fusion based semi-supervised non-negative matrix decomposition (MCFSNMF), which effectively solves the above problem by constructing symmetric labeling matrices embedded with positive and negative labeling information and fusing them with pairwise constraint matrices. In addition, SNMF is essentially a feature extraction method, which cannot obtain clustering results directly. Therefore, we combine the label propagation algorithm to achieve feature learning and label assignment interaction, which not only avoids the impact of clustering post-processing operations but also enhances the representation of labeled data relative to unlabeled data. We compare multiple SNMF algorithms on six image datasets and show that the proposed algorithm can effectively enhance the clustering performance and validate the algorithm’s convergence.},
  archive      = {J_NEUCOM},
  author       = {Zeping Ge and Youlong Yang},
  doi          = {10.1016/j.neucom.2024.128432},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128432},
  shortjournal = {Neurocomputing},
  title        = {A simple multi-constraint fusion based semi-supervised non-negative matrix decomposition for image clustering},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Skip-patching spatial–temporal discrepancy-based anomaly
detection on multivariate time series. <em>NEUCOM</em>, <em>609</em>,
128428. (<a href="https://doi.org/10.1016/j.neucom.2024.128428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection in the Industrial Internet of Things (IIoT) is a challenging task that relies heavily on the efficient learning of multivariate time series representations. We introduce Skip-patching and Spatial–Temporal discrepancy mechanisms to improve the efficiency of detecting anomalies. Traditional feature extraction is hindered by redundant information in limited datasets. The situation is that feature generation from stable operational processes results in low-quality representations. To address this challenge, we propose the Skip-Patching mechanism. This approach involves selectively extracting features from partial data patches, prompting the model to learn more meaningful knowledge through self-supervised learning. It also effectively doubles the training sample size by creating independent sub-groups of patches. Despite the complex spatial and temporal relationships in IIoT systems, existing methods mainly extracted features from a single domain, either temporal or spatial (sensor-wise), or simply cascaded two features, i.e., one after one, which limited anomaly detection capabilities. To address this, we introduce the Spatial–Temporal Association Discrepancy component, which leverages discrepancies between spatial and temporal features to enhance latent representation learning. Our Skip-Patching Spatial–Temporal Anomaly Detection (SSAD) framework combines these two components to provide a more diverse and comprehensive learning process. Tested across four multivariate time series anomaly detection benchmarks, SSAD demonstrates superior performance, confirming the efficacy of combining Skip-patching and Spatial–Temporal features to enhance anomaly detection in IIoT systems.},
  archive      = {J_NEUCOM},
  author       = {Yinsong Xu and Yulong Ding and Jie Jiang and Runmin Cong and Xuefeng Zhang and Shiqi Wang and Sam Kwong and Shuang-Hua Yang},
  doi          = {10.1016/j.neucom.2024.128428},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128428},
  shortjournal = {Neurocomputing},
  title        = {Skip-patching spatial–temporal discrepancy-based anomaly detection on multivariate time series},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Function-dependent neural-network-driven state feedback
control and self-verification stability for discrete-time nonlinear
system. <em>NEUCOM</em>, <em>609</em>, 128422. (<a
href="https://doi.org/10.1016/j.neucom.2024.128422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning significantly impacts neural network controller synthesis. Despite the higher efficiency of deep learning algorithms compared to traditional model-based controller design methods, the performance of these neural network controllers lacks theoretical guarantees. Initially, this paper proposes an architecture to synthesize the state feedback controller and Lyapunov function, called function-dependent neural-network-driven (NN-driven) architecture. The discrete-time nonlinear system dynamics, state feedback controller and Lyapunov function in this architecture are all designed using neural networks, which can improve the efficiency of stability verification and control performance. To realize self-verification of system stability by neural networks, three optimization problems are designed based on Lyapunov stability conditions and training speed constraints, solved using mixed-integer linear programming (MILP) solvers. Additionally, a MILP-based algorithm called Stability Counter-examples Updating Training Set (SCUTS) is proposed to simultaneously train the state feedback controller and Lyapunov function neural networks. Finally, experiments conducted on a second-order discrete-time nonlinear system, an inverted pendulum with NN-driven dynamics and an inverted pendulum with Lagrangian dynamics demonstrate the effectiveness of this work. Experimental results indicate that this work outperforms previous research on synthesizing neural network controllers in both the neural network training speed and the control system stabilization speed.},
  archive      = {J_NEUCOM},
  author       = {Jingya Wang and Xiao Feng and Yongbin Yu and Xiangxiang Wang and Xinyi Han and Kaibo Shi and Shouming Zhong and Jiarun Shen and Jingye Cai},
  doi          = {10.1016/j.neucom.2024.128422},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128422},
  shortjournal = {Neurocomputing},
  title        = {Function-dependent neural-network-driven state feedback control and self-verification stability for discrete-time nonlinear system},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Video text tracking with transformer-based local search.
<em>NEUCOM</em>, <em>609</em>, 128420. (<a
href="https://doi.org/10.1016/j.neucom.2024.128420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video text tracking is a highly significant branch in the field of multi-object tracking (MOT), aiming to detect all text instances in video frames and construct trajectories for each text. Conventional text tracking methods typically follow the Tracking-By-Detection (TbD) paradigm which involves two separate steps of detection and association. In complex scenarios, abundant detection omission of text instances is caused by exposure, occlusion, motion blur, and the like, leading to text trajectory breakpoints in the TbD methods. To this end, video text tracking with transformer-based local search (LSTrack) is proposed in this paper. We utilize historical trajectory information to estimate the approximate search areas where omitted texts are located. In this case, our local search tracker leverages the text images in historical trajectories as references to directly recall text instances in the search areas. In addition, our tracking framework can combine the explicit semantic information output from an OCR model to obtain the semantic version (SV) of LSTrack, which for the first time uses the text edit distance as the distance measurement in matching stages to achieve better text tracking results. Ultimately, our method achieves an advanced performance on several public benchmarks. In particular, LSTrack (SV) achieves state-of-the-art performance on the Minetto benchmark.},
  archive      = {J_NEUCOM},
  author       = {Xingsheng Zhou and Cheng Wang and Xinggang Wang and Wenyu Liu},
  doi          = {10.1016/j.neucom.2024.128420},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128420},
  shortjournal = {Neurocomputing},
  title        = {Video text tracking with transformer-based local search},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A varying-parameter complementary neural network for
multi-robot tracking and formation via model predictive control.
<em>NEUCOM</em>, <em>609</em>, 128384. (<a
href="https://doi.org/10.1016/j.neucom.2024.128384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a varying-parameter complementary neural network (VPCNN) is designed and combined with model predictive control (MPC) to solve the multi-robot tracking and formation problems via a leader–follower strategy. First, multi-robot tracking and formation problems are transformed into quadratic programming (QP) problems employing an MPC approach. Second, a nonlinear complementary function approach, i.e., the Fischer–Burmeister function, is used to map the Karush–Kuhn–Tucker conditions of the QP problem with double-ended inequality constraints to a system of nonlinear equations. Finally, the VPCNN is designed to solve the multi-robot tracking and formation problem. The effectiveness of the proposed method is demonstrated by numerical simulations, and the advantage of VPCNN in terms of solution speed is indicated by comparisons with a primal–dual neural network.},
  archive      = {J_NEUCOM},
  author       = {Xingru Li and Xiaohui Ren and Zhijun Zhang and Jinjia Guo and Yamei Luo and Jiajie Mai and Bolin Liao},
  doi          = {10.1016/j.neucom.2024.128384},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128384},
  shortjournal = {Neurocomputing},
  title        = {A varying-parameter complementary neural network for multi-robot tracking and formation via model predictive control},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CGAD: A novel contrastive learning-based framework for
anomaly detection in attributed networks. <em>NEUCOM</em>, <em>609</em>,
128379. (<a href="https://doi.org/10.1016/j.neucom.2024.128379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficient detection of anomalies in attributed networks is crucial for various applications. Although contrastive learning methods have shown potential in this domain, most existing studies still suffer from issues such as negative sampling bias and limited utilization of neighborhood information. Moreover, these methods often fail to account for the impact of systematic noise. In this paper, we introduce a purpose-built framework called C ontrastive learning-based G raph A nomaly D etection (CGAD) to address these specific challenges. In CGAD, we present a debiased negative sampling approach, which intelligently selects negative nodes based on community distribution to mitigate negative sampling bias. Additionally, our approach incorporates multiple masking strategies to construct multi-scale instance pairs and leverages the Robust InfoNCE (RINCE) technique to effectively filter out noise, thus enhancing the overall performance of the framework. We evaluate the performance of CGAD across four diverse datasets and conduct a comparative analysis against seven baseline models. The experimental results consistently demonstrate the superior performance of CGAD.},
  archive      = {J_NEUCOM},
  author       = {Yun Wan and Dapeng Zhang and Dong Liu and Feng Xiao},
  doi          = {10.1016/j.neucom.2024.128379},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128379},
  shortjournal = {Neurocomputing},
  title        = {CGAD: A novel contrastive learning-based framework for anomaly detection in attributed networks},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-paced contrastive learning for knowledge tracing.
<em>NEUCOM</em>, <em>609</em>, 128366. (<a
href="https://doi.org/10.1016/j.neucom.2024.128366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing presents a fundamental research challenge within personalized education, aiming to dynamically monitor students’ evolving mastery of individual skills through analysis of their online answer data. Noteworthy advancements have been achieved in knowledge tracing models, particularly with the integration of deep learning techniques. These models leverage long-short-term memory (LSTM) networks to process students’ answer sequences, discern latent skill states, and predict subsequent responses. Nevertheless, real-world scenarios introduce a substantial challenge, given the inherent sparsity of student interaction data, implying that each student interacts with only a limited number of skills. Deep knowledge tracing models, when confronted with sparse data, tend to exhibit a bias towards learning from students with large sample sizes, consequently resulting in compromised learning outcomes due to insufficient interaction data. Addressing these challenges, this paper introduces an innovative self-paced learning data augmentation approach designed to augment the number of student answer sequence samples. Additionally, the paper employs self-supervised contrastive learning to strike a balance between local and global information, thereby mitigating the model’s inclination to overly focus on local samples. To effectively address the aforementioned challenges, the paper proposes a deep knowledge tracing framework grounded in self-paced contrastive learning. The efficacy of the self-paced contrastive learning strategy is validated using real datasets, demonstrating superior prediction accuracy compared to alternative algorithms.},
  archive      = {J_NEUCOM},
  author       = {Huan Dai and Yue Yun and Yupei Zhang and Rui An and Wenxin Zhang and Xuequn Shang},
  doi          = {10.1016/j.neucom.2024.128366},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128366},
  shortjournal = {Neurocomputing},
  title        = {Self-paced contrastive learning for knowledge tracing},
  volume       = {609},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A lightweight transformer-based visual question answering
network with weight-sharing hybrid attention. <em>NEUCOM</em>,
<em>608</em>, 128460. (<a
href="https://doi.org/10.1016/j.neucom.2024.128460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances show that Transformer-based models and object detection-based models play an indispensable role in VQA. However, object detection-based models have significant limitations due to their redundant and complex detection box generation process. In contrast, Visual and Language Pre-training (VLP) models can achieve better performance, but require high computing power. To this end, we present Weight-Sharing Hybrid Attention Network (WHAN), a lightweight Transformer-based VQA model. In WHAN, we replace the object detection network with Transformer encoder and use LoRA to solve the problem that the language model cannot adapt to interrogative sentences. We propose Weight-Sharing Hybrid Attention (WHA) module with parallel residual adapters, which can significantly reduce the trainable parameters of the model and we design DWA and BVA modules that can allow the model to perform attention operations from different scales. Experiments on VQA-v2, COCO-QA, GQA, and CLEVR datasets show that WHAN achieves competitive performance with far fewer trainable parameters.},
  archive      = {J_NEUCOM},
  author       = {Yue Zhu and Dongyue Chen and Tong Jia and Shizhuo Deng},
  doi          = {10.1016/j.neucom.2024.128460},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128460},
  shortjournal = {Neurocomputing},
  title        = {A lightweight transformer-based visual question answering network with weight-sharing hybrid attention},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distance-reconstructed dependency enhanced aspect-based
sentiment analysis with sentiment strength. <em>NEUCOM</em>,
<em>608</em>, 128459. (<a
href="https://doi.org/10.1016/j.neucom.2024.128459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis task that requires the detection of sentiment polarity towards specific aspects. Dependency tree-based graph convolutional network models (GCN) have been widely applied in ABSA. These studies utilize syntactic analysis tools to derive syntactic dependency graphs, which are then inputted into GCN. It enables iterative learning of sentiment dependency information from contextual words to aspect terms. However, directly using syntactic dependency graphs can lead to two shortcomings. First, the long-distance sentiment information in long sentences will be weakened during GCN iterative computations. Second, the syntactic dependency graphs of short sentences lack sentiment strength information. To address these two shortcomings, we propose a Distance-Reconstructed Dependency Enhanced Sentiment analysis approach with Sentiment Strength based on GCN (DRD-SE-GCN) approach, in which the syntactic dependency graph of long sentences is reconstructed based on distance, thus narrowing the gap between sentiment words and target aspect words. It ensures that the sentiment dependency information carried by the long-distance sentiment words will not be weakened or lost during the GCN iteration. Additionally, the weights of the syntactic dependency graph for short sentences are reassigned so as to carry the strength information of sentiment words. Experimental results on four standard datasets show that our proposed model can effectively improve the accuracy of aspect-level sentiment analysis.},
  archive      = {J_NEUCOM},
  author       = {Mingming Kong and Le Feng and Chao Zhang and Fei Hao and Yumeng Yan},
  doi          = {10.1016/j.neucom.2024.128459},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128459},
  shortjournal = {Neurocomputing},
  title        = {Distance-reconstructed dependency enhanced aspect-based sentiment analysis with sentiment strength},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards explainable fake news detection and automated
content credibility assessment: Polish internet and digital media
use-case. <em>NEUCOM</em>, <em>608</em>, 128450. (<a
href="https://doi.org/10.1016/j.neucom.2024.128450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting fake news and disinformation is a challenging and complex task. With the proliferation of the transformer architectures, researchers and practitioners have started actively using them to combat this phenomenon. In that regard, different approaches have been proposed by the community. Unfortunately, a significant number of solutions have started to treat misinformation in a similar way as other natural language processing challenges (e.g., sentiment classification). However, the reality is more complex, and the fake news detection problem often require additional context that may be essential to provide a complete assessment. Another pitfall in combating fake news is treating it as a binary classification challenge (e.g., fake vs. legitimate news). Combining such a simplified response with a deep black-box neural system effectively impacts the interpretability and eventual trustworthiness of the detection system. In this paper, the phenomenon of fake news is approached from a multi-factor perspective. Therefore, the proposed innovative approach does not limit news content rating to a one-dimensional binary response. In particular, the authors utilize a vast spectrum of processing techniques, including text embedding, machine translation, and various users’ preferences to provide content assessment. The results are presented using a Polish digital media use-case.},
  archive      = {J_NEUCOM},
  author       = {Rafał Kozik and Gracjan Kątek and Marta Gackowska and Sebastian Kula and Joanna Komorniczak and Paweł Ksieniewicz and Aleksandra Pawlicka and Marek Pawlicki and Michał Choraś},
  doi          = {10.1016/j.neucom.2024.128450},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128450},
  shortjournal = {Neurocomputing},
  title        = {Towards explainable fake news detection and automated content credibility assessment: Polish internet and digital media use-case},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fixed-time synchronization of interconnected memristive
neural networks with energy consumption via switched control.
<em>NEUCOM</em>, <em>608</em>, 128438. (<a
href="https://doi.org/10.1016/j.neucom.2024.128438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fixed-time synchronization of time-delay interconnected memristive neural networks is probed in this article. Firstly, according to the conventional controller, a new type of switching controller is proposed, which can complement each other. By utilizing the theory of Lyapunov stability and differential inclusion, it is proved that interconnected memristive neural networks can achieve synchronization within a fixed time under the designed controller. In addition, to control engineering costs, the upper limit of energy consumption, which is produced by the controller from the initial time to the settling-time, is estimated. Finally, numerical examples are provided to verify the validity of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Xuan Wang and Dongbing Tong and Qiaoyu Chen and Wuneng Zhou},
  doi          = {10.1016/j.neucom.2024.128438},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128438},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time synchronization of interconnected memristive neural networks with energy consumption via switched control},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for 3D object recognition: A survey.
<em>NEUCOM</em>, <em>608</em>, 128436. (<a
href="https://doi.org/10.1016/j.neucom.2024.128436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing availability of extensive 3D datasets and the rapid progress in computational power, deep learning (DL) has emerged as a highly promising approach for learning from 3D data, addressing critical tasks like object detection, segmentation, and recognition. Despite the unique challenges in processing geometry data with deep neural networks, recent advancements in DL for 3D object recognition have shown remarkable success, with various methods proposed to tackle different issues. This paper aims to stimulate future research by providing a comprehensive review of recent progress in DL techniques for 3D object recognition, which are systematically categorized based on their learning behavior. We discuss the advantages, limitations, and application of each approach, highlighting their performance in 3D object classification on benchmark datasets such as ModelNet, ScanObjectNN, and Sydney Urban Object. The survey offers insightful observations and inspires future research directions.},
  archive      = {J_NEUCOM},
  author       = {A.A.M. Muzahid and Hua Han and Yujin Zhang and Dawei Li and Yuhe Zhang and Junaid Jamshid and Ferdous Sohel},
  doi          = {10.1016/j.neucom.2024.128436},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128436},
  shortjournal = {Neurocomputing},
  title        = {Deep learning for 3D object recognition: A survey},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Long-range attention classification for substation point
cloud. <em>NEUCOM</em>, <em>608</em>, 128435. (<a
href="https://doi.org/10.1016/j.neucom.2024.128435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud classification for substation is challenging due to the occluding layout as well as the complexity of methods. Most previous methods trade inference speed for precision by building complex extractors. To alleviate the paradox of performance and complexity trade-off, this paper proposes the lightweight long-range attention classification for substation point cloud, including shuffle channel attention(SCA) and dilated channel attention(DCA). First, SCA captures local cross-channel interaction via 1D convolution and global interaction via channel shuffling, shown promising performance. Second, to further reduce the amount of computation involved in shuffling, we propose a more elegant method DCA by resizing the 1D vector after pooling into 2D feature map. Note that proposed DCA are implemented by just 2D convolution, determining the coverage of cross-channel interaction, with a significantly higher inference speed. Furthermore, we develop a heuristic algorithm to adaptively determine parameters like kernel size, shuffle group and size of 2D feature map. Besides ModelNet40 and ScanObjectNN(PB_T50_RS), this paper also selects ten of main objects in substation for training and testing. Finally, experimental results suggest that proposed methods bring notable performance gain, nearly 1%. DCA reaches 93.801% and just increases 0.0003M parameters but 15.5% faster than SCA. We also make an attempt to simplify proposed methods via reducing the coding dimensions and coding blocks. And simplified DCA achieves 93.4% performance with almost quarter parameters and 112% faster, guaranteeing both efficiency and effectiveness. A simplified version is used to achieve the highest accuracy of 85.115% and 83.304% on ScanObjectNN, with the highest improvements of 1.735% and 2.391%. This paper also conducts robustness test where different proportions of points are missing. Results show that when 93.75% missing, the accuracy only decreases by 4.093%, and can still reach 89%, which is significantly ahead of other methods.},
  archive      = {J_NEUCOM},
  author       = {Da Li and Hui Zhao and Xingyu Yan and Liang Zhao and Hui Cao},
  doi          = {10.1016/j.neucom.2024.128435},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128435},
  shortjournal = {Neurocomputing},
  title        = {Long-range attention classification for substation point cloud},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A general framework for multi-step ahead adaptive conformal
heteroscedastic time series forecasting. <em>NEUCOM</em>, <em>608</em>,
128434. (<a href="https://doi.org/10.1016/j.neucom.2024.128434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel model-agnostic algorithm called adaptive ensemble batch multi-input multi-output conformalized quantile regression ( AEnbMIMOCQR ) that enables forecasters to generate multi-step ahead prediction intervals for a fixed pre-specified miscoverage rate α α in a distribution-free manner. Our method is grounded on conformal prediction principles, however, it does not require data splitting and provides close to exact coverage even when the data is not exchangeable. Moreover, the resulting prediction intervals, besides being empirically valid along the forecast horizon, do not neglect heteroscedasticity. AEnbMIMOCQR is designed to be robust to distribution shifts, which means that its prediction intervals remain reliable over an unlimited period of time, without entailing retraining or imposing unrealistic strict assumptions on the data-generating process. Through methodically experimentation, we demonstrate that our approach outperforms other competitive methods on both real-world and synthetic datasets. The code used in the experimental part and a tutorial on how to use AEnbMIMOCQR can be found at the following GitHub repository: https://github.com/Quilograma/AEnbMIMOCQR .},
  archive      = {J_NEUCOM},
  author       = {Martim Sousa and Ana Maria Tomé and José Moreira},
  doi          = {10.1016/j.neucom.2024.128434},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128434},
  shortjournal = {Neurocomputing},
  title        = {A general framework for multi-step ahead adaptive conformal heteroscedastic time series forecasting},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic dependency and local convolution for enhancing
naturalness and tone in text-to-speech synthesis. <em>NEUCOM</em>,
<em>608</em>, 128430. (<a
href="https://doi.org/10.1016/j.neucom.2024.128430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-attention-based networks have become increasingly popular due to their exceptional performance in parallel training and global context modeling. However, it may fall short of capturing local dependencies, particularly in datasets with strong local correlations. To address this challenge, we propose a novel method that utilizes semantic dependency to extract linguistic information from the original text. The semantic relationship between nodes serves as prior knowledge to refine the self-attention distribution. Additionally, to better fuse local contextual information, we introduce a one-dimensional convolution neural network to generate the query and value matrices in the self-attention mechanism, taking advantage of the strong correlation between input characters. We apply this variant of the self-attention network to text-to-speech tasks and propose a non-autoregressive neural text-to-speech model. To enhance pronunciation accuracy, we separate tones from phonemes as independent features in model training. Experimental results show that our model yields good performance in speech synthesis. Specifically, the proposed method significantly improves the processing of pause, stress, and intonation in speech.},
  archive      = {J_NEUCOM},
  author       = {Chenglong Jiang and Ying Gao and Wing W.Y. Ng and Jiyong Zhou and Jinghui Zhong and Hongzhong Zhen and Xiping Hu},
  doi          = {10.1016/j.neucom.2024.128430},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128430},
  shortjournal = {Neurocomputing},
  title        = {Semantic dependency and local convolution for enhancing naturalness and tone in text-to-speech synthesis},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Modeling the skeleton-language uncertainty for 3D action
recognition. <em>NEUCOM</em>, <em>608</em>, 128426. (<a
href="https://doi.org/10.1016/j.neucom.2024.128426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human 3D skeleton-based action recognition has received increasing interest in recent years. Inspired by the excellent ability of the multi-modal model, some pioneer attempts to employ diverse modalities, i.e., skeleton and language, to construct the skeleton-language model and have shown compelling results. Yet, these attempts model the data representation as deterministic point estimation, ignoring a key issue that descriptions of similar motions are uncertain and ambiguous, which brings about restricted comprehension of complex concept hierarchies and impoverished cross-modal alignment reliability. To tackle this challenge, this paper proposes a new Uncertain Skeleton-Language Learning Framework (USLLF) to capture the semantic ambiguity among diverse modalities in a probabilistic manner for the first time. USLLF consists of both inter- and intra-modal uncertainties. Specifically, first, we integrate the language (text) generated by ChatGPT with the generic skeleton-based network and develop a deterministic multi-modal baseline, which can be easily achieved via any off-the-shelf skeleton and text encoders. Then, based on this baseline, we explicitly model the intra-modal (skeleton/language) uncertainties as the Gaussian distributions using the new uncertainty networks capable of learning the distributional embeddings of modalities. Following this, these embeddings are aligned and formulated as inter-modal (skeleton-language) uncertainty using both the contrastive and negative log-likelihood objectives to alleviate the cross-modal alignment error. Experimental results on NTU RGB+D, NTU RGB+D 120, and NW-UCLA datasets show that our approach outperforms the proposed baseline and achieves comparable performance with a high inference efficiency compared to the state-of-the-art methods. Besides, we also deliver insightful analyses on how learned uncertainty reduces the impact of uncertain and ambiguous data on model performance.},
  archive      = {J_NEUCOM},
  author       = {Mingdao Wang and Xianlin Zhang and Siqi Chen and Xueming Li and Yue Zhang},
  doi          = {10.1016/j.neucom.2024.128426},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128426},
  shortjournal = {Neurocomputing},
  title        = {Modeling the skeleton-language uncertainty for 3D action recognition},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recent progress, challenges and future prospects of applied
deep reinforcement learning: A practical perspective in path planning.
<em>NEUCOM</em>, <em>608</em>, 128423. (<a
href="https://doi.org/10.1016/j.neucom.2024.128423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is one of the most crucial elements in the field of robotics, such as autonomous driving, minimally invasive surgery and logistics distribution. This review begins by summarizing the limitations of conventional path planning methods and recent work on DRL-based path planning methods. Subsequently, the paper systematically reviews the construction of key elements of DRL methods in recent work, with the aim of assisting readers in comprehending the foundation of DRL research, along with the underlying logic and considerations from a practical perspective. Facing issues of sparse rewards and the exploration–exploitation balance during the practical training process, the paper reviews enhancement methods for training efficiency and optimization results in DRL path planning. In the end, the paper summarizes the current research limitations and challenges in practical path planning applications, followed by future research directions.},
  archive      = {J_NEUCOM},
  author       = {Ye Zhang and Wang Zhao and Jingyu Wang and Yuan Yuan},
  doi          = {10.1016/j.neucom.2024.128423},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128423},
  shortjournal = {Neurocomputing},
  title        = {Recent progress, challenges and future prospects of applied deep reinforcement learning: A practical perspective in path planning},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Compositional kronecker context optimization for
vision–language models. <em>NEUCOM</em>, <em>608</em>, 128421. (<a
href="https://doi.org/10.1016/j.neucom.2024.128421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context Optimization (CoOp) has emerged as a simple yet effective technique for adapting CLIP-like vision–language models to downstream image recognition tasks. Nevertheless, learning context with satisfactory base-to-new, domain and cross-task generalization ability simultaneously while adapting to new tasks is a challenge. To tackle such a challenge, existing methods mainly exploit knowledge distillation with auxiliary text data written by human experts. However, we instead explore a new technique route by structuring the prompts without resorting to extra text data. As a result, we obtain a new lightweight yet generalizable approach termed Compositional Kronecker Context Optimization (CK-CoOp). Technically, the prompt’s context words in CK-CoOp are learnable vectors, which are crafted by linearly combining base vectors from a dictionary. These base vectors consist of a non-learnable component obtained by quantizing the weights in the token embedding layer, and a learnable component constructed by applying Kronecker product on several learnable tiny matrices. Intuitively, the compositional structure mitigates the risk of overfitting on training data and the Kronecker product breaks the non-learnable restrictions of the dictionary, thereby enhancing representation ability with minimal additional parameters. Extensive experiments confirm that, compared with existing methods, CK-CoOp can not only achieve comparable or even better performance under base-to-new, domain and cross-task generalization evaluation without the help of auxiliary text data, but also has the merits of fewer learnable parameters and efficient training and inference speed.},
  archive      = {J_NEUCOM},
  author       = {Kun Ding and Xiaohui Li and Qiang Yu and Ying Wang and Haojian Zhang and Shiming Xiang},
  doi          = {10.1016/j.neucom.2024.128421},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128421},
  shortjournal = {Neurocomputing},
  title        = {Compositional kronecker context optimization for vision–language models},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Overcoming language priors in visual question answering with
cumulative learning strategy. <em>NEUCOM</em>, <em>608</em>, 128419. (<a
href="https://doi.org/10.1016/j.neucom.2024.128419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of visual question answering(VQA) has witnessed great progress over the last few years. However, many current VQA models tend to rely on superficial linguistic correlations between questions and answers, often failing to sufficiently learn multi-modal knowledge from both vision and language, and thus suffering significant performance drops. To address this issue, the VQA-CP v2.0 dataset was developed to reduce language biases by greedily re-partitioning the distribution of VQA v2.0’s training and test sets. According to the fact that achieving high performance on real-world datasets requires effective learning from minor classes, in this paper we analyze the presence of skewed long-tail distributions in the VQA-CP v2.0 dataset and propose a new ensemble-based parameter-insensitive framework. This framework is built on two representation learning branches and a joint learning block, which are designed to reduce language biases in VQA tasks. Specifically, the representation learning branches can ensure the superior representative ability learned from the major and minor classes. The joint learning block forces the model to initially concentrate on major classes for robust representation and then gradually shifts its focus towards minor classes for classification during the training progress. Experimental results demonstrate that our approach outperforms the state-of-the-art works on the VQA-CP v2.0 dataset without requiring additional annotations. Notably, on the “num” type, our framework exceeds the second-best method (without extra annotations) by 8.64%. Meanwhile, our approach does not sacrifice accuracy performance on the VQA v2.0 dataset compared with the baseline model.},
  archive      = {J_NEUCOM},
  author       = {Aihua Mao and Feng Chen and Ziying Ma and Ken Lin},
  doi          = {10.1016/j.neucom.2024.128419},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128419},
  shortjournal = {Neurocomputing},
  title        = {Overcoming language priors in visual question answering with cumulative learning strategy},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel generalized policy iteration for efficient evolving
control of nonlinear systems. <em>NEUCOM</em>, <em>608</em>, 128418. (<a
href="https://doi.org/10.1016/j.neucom.2024.128418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we construct a novel generalized policy iteration framework to address optimal regulation problems for discrete-time nonlinear systems in a more efficient way. Relevant properties are investigated for the framework, including monotonicity and convergence of the iterative value function sequence as well as the admissibility of the iterative control policy. Additionally, an innovative approach is developed to seek an initial admissible control policy for the framework with an adjustable searching speed. Based on these, an evolving control algorithm is presented with stability guarantee. This algorithm employs iterative control policies for system control during the computation of the optimal control policy, as opposed to waiting for the generation of the optimal control policy before implementing control. Eventually, two simulation experiments are conducted with real-world physical backgrounds, in order to illustrate the performance of the proposed strategy.},
  archive      = {J_NEUCOM},
  author       = {Haiming Huang and Ding Wang and Hua Wang and Junlong Wu and Mingming Zhao},
  doi          = {10.1016/j.neucom.2024.128418},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128418},
  shortjournal = {Neurocomputing},
  title        = {Novel generalized policy iteration for efficient evolving control of nonlinear systems},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A lightweight multi-scale multi-angle dynamic interactive
transformer-CNN fusion model for 3D medical image segmentation.
<em>NEUCOM</em>, <em>608</em>, 128417. (<a
href="https://doi.org/10.1016/j.neucom.2024.128417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combining Convolutional Neural Network(CNN) and Transformer has become one of the mainstream methods for three-dimensional (3D) medical image segmentation. However, the complexity and diversity of target forms in 3D medical images require models to capture complex feature information for segmentation, resulting in an excessive number of parameters which are not conducive to training and deployment. Therefore, we have developed a lightweight 3D multi-target semantic segmentation model. In order to enhance contextual texture connections and reinforce the expression of detailed feature information, we designed a multi-scale and multi-angle feature interaction module to enhance feature representation by interacting multi-scale features from different perspectives. To address the issue of attention collapse in Transformers, leading to the neglect of other detailed feature learning, we utilized local features as dynamic parameters to interact with global features, dynamically grouping and learning critical features from global features, thereby enhancing the model&#39;s ability to learn detailed features. While ensuring the segmentation capability of the model, we aimed to keep the model lightweight, resulting in a total of 9.63 M parameters. Extensive experiments were conducted on public datasets ACDC and Brats2018, as well as a private dataset, Temporal Bone CT. The results indicate that our proposed model is more competitive compared to the latest techniques in 3D medical image segmentation.},
  archive      = {J_NEUCOM},
  author       = {Xin Hua and Zhijiang Du and Hongjian Yu and Jixin Ma and Fanjun Zheng and Chen Zhang and Qiaohui Lu and Hui Zhao},
  doi          = {10.1016/j.neucom.2024.128417},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128417},
  shortjournal = {Neurocomputing},
  title        = {A lightweight multi-scale multi-angle dynamic interactive transformer-CNN fusion model for 3D medical image segmentation},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Neural networks-based composite learning control for
robotic systems with predefined time error constraints. <em>NEUCOM</em>,
<em>608</em>, 128414. (<a
href="https://doi.org/10.1016/j.neucom.2024.128414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the neural networks-based control problem for robotic systems with error constraints. By embedding a new predefined time performance function into an asymmetric barrier function, a predefined time constraints method is proposed with the following features: (1) it is a general approach that can handle asymmetric error constraints and can be directly applied to the predefined performance control for other high-order nonlinear systems without any changing; (2) both settling time and convergent compact set can be preassigned by the user; (3) the results are global i.e., the robot can start arbitrarily within the physical domain. By extending the regression operators with online data memory, a prediction error is constructed, by using which, a new neural networks based composite learning law is constructed to handle unknown dynamics. Compared with the traditional method such as gradient descent algorithm, σ σ -modification and ϵ ϵ -modification which cannot guarantee the convergence of the neural networks weights or can only force the weights to stay around preselected values, the neural networks guarantees that the weights converge to the region around the true values, in particular under a weak interval excitation (IE) condition rather than the typically stringent persistent excitation (PE) condition. The benefits and effectiveness of the proposed control are theoretically authenticated and experimentally validated.},
  archive      = {J_NEUCOM},
  author       = {Yu Zhang and Zihan Xu and Jiannan Chen and Licui Zhao and Xinyu Wang and Changchun Hua},
  doi          = {10.1016/j.neucom.2024.128414},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128414},
  shortjournal = {Neurocomputing},
  title        = {Neural networks-based composite learning control for robotic systems with predefined time error constraints},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tensor product model transformation-based reinforcement
learning neural network controller with guaranteed stability.
<em>NEUCOM</em>, <em>608</em>, 128411. (<a
href="https://doi.org/10.1016/j.neucom.2024.128411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the success of neural network (NN) controllers, the stability of closed-loop NN control systems is still a major challenge. This paper proposes a constrained reinforcement learning (RL) algorithm to design optimal NN controllers for a class of nonlinear dynamical systems while guaranteeing the stability of the control systems. By representing a controlled system as a tensor product (TP) model, a sufficient stability condition for a closed-loop NN control system is derived, which is then employed as a training constraint for the NN controller throughout the training process to ensure the stability in each training step. By showing the existence of a Lyapunov function, which is also directly obtained during the training process, the stability can be theoretically confirmed. Simulation studies on various nonlinear dynamical systems illustrate that the NN controllers trained with the proposed constrained RL algorithm outperform linear–quadratic–regulator controllers and yield roughly the same performance index values as those trained with an unconstrained RL algorithm, indicating that the imposed constraint does not significantly affect the training performance. Most importantly, while simulation results show that all controllers provide closed-loop stability, only the NN controllers trained with the proposed constrained RL algorithm theoretically guarantee stability.},
  archive      = {J_NEUCOM},
  author       = {Kraisak Phothongkum and Suwat Kuntanapreeda},
  doi          = {10.1016/j.neucom.2024.128411},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128411},
  shortjournal = {Neurocomputing},
  title        = {Tensor product model transformation-based reinforcement learning neural network controller with guaranteed stability},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic differential privacy-based dataset condensation.
<em>NEUCOM</em>, <em>608</em>, 128394. (<a
href="https://doi.org/10.1016/j.neucom.2024.128394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous expansion of data scale, data condensation technology has emerged as a means to reduce costs related to storage, time, and energy consumption. Data condensation can generate a synthesized dataset of reduced size, enabling the training of models that exhibit high performance comparable to the original dataset. Nevertheless, data condensation has also exposed privacy issues. Although many approaches have been proposed to preserve privacy for data condensation, the privacy protection for data condensation has not been well explored. Furthermore, to the best of our knowledge, none of the existing approaches propose dynamic parameters-based differential privacy dataset condensation considering unnecessary noise introduced by the fixed privacy parameter strategy. Most approaches typically inject constant noise with the fixed variance into gradients across all layers using predefined privacy parameters, which can significantly impact model accuracy. In this paper, we investigate alternative approaches for data condensation with differential privacy (DP) that aim to ensure DP while minimizing the noise added to gradients and improving the model accuracy. First, we develop a dynamic threshold method to reduce the noise added to gradients in the later stages of training by using a clipping threshold that decreases with training rounds. Second, noise injection in our method is not arbitrary as in conventional approaches; instead, it is based on the maximum size of the gradient after clipping. This approach ensures that only minimal noise increments are introduced, thereby mitigating accuracy loss and parameter instability that may arise from excessive noise injection. Finally, our privacy analysis confirms that the proposed method provides a rigorous privacy guarantee. Extensive evaluations on different datasets demonstrate that our approach can improve accuracy compared to existing DP data condensation techniques while adhering to the same privacy budget and applying a specified clipping threshold.},
  archive      = {J_NEUCOM},
  author       = {Zhaoxuan Wu and Xiaojing Gao and Yongfeng Qian and Yixue Hao and Min Chen},
  doi          = {10.1016/j.neucom.2024.128394},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128394},
  shortjournal = {Neurocomputing},
  title        = {Dynamic differential privacy-based dataset condensation},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DCEnt‐PredictiveNet: A novel explainable hybrid model for
time series forecasting. <em>NEUCOM</em>, <em>608</em>, 128389. (<a
href="https://doi.org/10.1016/j.neucom.2024.128389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a novel hybrid framework called DCEnt-PredictiveNet (deep convolutional neural network (DCNN) + entropy + support vector regressor (SVR)) that concatenate both deep and handcrafted features for time series data analysis and forecasting. From the discrete wavelet transform coefficients of input time series data, computed four different handcrafted entropy features, which were then concatenated with deep features extracted using a modified DCNN. The concatenated deep and handcrafted feature vector was then fed to a SVR for prediction. The DCEnt-PredictiveNet framework was trained and tested on three time series datasets of real-world COVID-19, stock price and traffic information, and achieved mean absolute percentage errors of 0.03 %, 1.53 % and 11.41 % for daily cumulative COVID-19 positive cases, closing stock price, and hourly traffic (vehicle numbers) at one junction predictions, respectively. In addition, we incorporated local interpretable model-agnostic explanations and Shapley additive explanations methods into DCEnt-PredictiveNet to enable visualization of significant features that contributed to the model’s decision-making, thereby enhancing its explainability. Our DCEnt-PredictiveNet model yielded promising and interpretable forecasting results, which can facilitate advance resource planning in hospitals for incoming COVID-19 patients, stock market investment planning, and efficient traffic control management.},
  archive      = {J_NEUCOM},
  author       = {Vidya K. Sudarshan and Reshma A. Ramachandra and Smit Ojha and Ru-San Tan},
  doi          = {10.1016/j.neucom.2024.128389},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128389},
  shortjournal = {Neurocomputing},
  title        = {DCEnt‐PredictiveNet: A novel explainable hybrid model for time series forecasting},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural network-based distributed consensus tracking control
for uncertain euler–lagrange systems over directed topologies.
<em>NEUCOM</em>, <em>608</em>, 128383. (<a
href="https://doi.org/10.1016/j.neucom.2024.128383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a neural network-based robust control approach for driving disturbed Euler–Lagrange systems (e.g., robot manipulator) in a directed network to perform consensus tracking of a heterogeneous leader’s output signal. The parameter matrices and external disturbances in each follower’s Euler–Lagrange dynamics are unmeasurable, thus we unify them into one lumped uncertainty term. Neural networks are then employed to online estimate these uncertainties, with adaptive update laws ensuring the boundedness of the estimation errors. Subsequently, a set of distributed observers are developed to adaptively estimate the leader’s states as well as the unidentified parameter vector and output matrix in the leader’s model. With their help, the robust cooperative controller is designed. Its efficacy on directed networks is theoretically justified by designing a Lyapunov function with a special structure. This function produces symmetric positive definite matrices when its first derivative terms interact with the specified parameters in the observer and Laplacian matrices for directed graphs. Finally, numerical simulations based on two-link robot manipulators are carried out to verify that the tracking errors converge to zero when applying the neural network-based robust controller.},
  archive      = {J_NEUCOM},
  author       = {Chenglin Han and Kaiyu Qin and Boxian Lin and Mengji Shi and Zhiqiang Li and Qiang Liu},
  doi          = {10.1016/j.neucom.2024.128383},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128383},
  shortjournal = {Neurocomputing},
  title        = {Neural network-based distributed consensus tracking control for uncertain Euler–Lagrange systems over directed topologies},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Observer-based time-varying formation-containment tracking
of general linear multi-agent systems with input saturation.
<em>NEUCOM</em>, <em>608</em>, 128382. (<a
href="https://doi.org/10.1016/j.neucom.2024.128382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study the time-varying formation-containment (TVFC) tracking problem for linear multi-agent systems (MASs) and take the input saturation problem of the systems into account. An observer-based TVFC tracking protocol is proposed. It has been proven that the real leaders can realize the expected formation and track the virtual leader’s trajectory, and followers can get into the convex envelope spanned by the leaders. In addition, to avoid unexpected large chattering caused by nonzero input, we propose a continuous protocol. Under this protocol, each error is uniformly ultimately bounded and is able to converge to any small zero neighborhood. At the end, the feasibility of the TVFC theory is demonstrated by simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Zhang and Xisheng Zhan and Jie Wu and Tao Han},
  doi          = {10.1016/j.neucom.2024.128382},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128382},
  shortjournal = {Neurocomputing},
  title        = {Observer-based time-varying formation-containment tracking of general linear multi-agent systems with input saturation},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A binary particle swarm optimization-based pruning approach
for environmentally sustainable and robust CNNs. <em>NEUCOM</em>,
<em>608</em>, 128378. (<a
href="https://doi.org/10.1016/j.neucom.2024.128378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Convolutional Neural Networks (CNNs), continue to demonstrate remarkable performance across various tasks. However, their computational demands and energy consumption present significant drawbacks, restricting their practical deployment and contributing to a substantial carbon footprint. This paper addresses this challenge by proposing a novel method named Binary Particle Swarm Optimization Layer Pruner (BPSO-LPruner), aimed at achieving substantial computational reduction and mitigating environmental impact during CNN inference. BPSO-LPruner utilizes a constrained Binary Particle Swarm Optimization for CNN layer pruning, integrating a masked-bit strategy and a new population initialization strategy to enhance search performance. We illustrate the effectiveness of our method in reducing model computational costs and carbon footprint emissions while improving performance across multiple models (VGG16, VGG19, DenseNet-40, ResNet18, ResNet20, ResNet34, ResNet44, ResNet56, ResNet110, ResNet50, and MobileNetv2) and diverse datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet, COVID-19 X-ray dataset). Promising results underscore the performance of the proposed method. Additionally, we demonstrate that layer pruning yields benefits beyond enhanced computational performance. Our experimentation reveals that BPSO-LPruner enhances the model’s reliability and robustness by effectively addressing variations in input data, inherent ambiguity in model parameters, and adversarial images.},
  archive      = {J_NEUCOM},
  author       = {Jihene Tmamna and Rahma Fourati and Emna Ben Ayed and Leandro A. Passos and João P. Papa and Mounir Ben Ayed and Amir Hussain},
  doi          = {10.1016/j.neucom.2024.128378},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128378},
  shortjournal = {Neurocomputing},
  title        = {A binary particle swarm optimization-based pruning approach for environmentally sustainable and robust CNNs},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generative diffusion models: A survey of current theoretical
developments. <em>NEUCOM</em>, <em>608</em>, 128373. (<a
href="https://doi.org/10.1016/j.neucom.2024.128373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative diffusion models showed high success in many fields with a powerful theoretical background. They convert the data distribution to noise and remove the noise back to obtain a similar distribution. Many existing reviews focused on the specific application areas without concentrating on the developments about the algorithm. Unlike them we investigated the theoretical developments of the generative diffusion models. These approaches mainly divide into two: training-based and training-free. Awakening to this allowed us a clear and understandable categorization for the researchers who will make new developments in the future.},
  archive      = {J_NEUCOM},
  author       = {Melike Nur Yeğin and Mehmet Fatih Amasyalı},
  doi          = {10.1016/j.neucom.2024.128373},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128373},
  shortjournal = {Neurocomputing},
  title        = {Generative diffusion models: A survey of current theoretical developments},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LSMOTE: A link-based synthetic minority oversampling
technique for binary imbalanced datasets. <em>NEUCOM</em>, <em>608</em>,
128372. (<a href="https://doi.org/10.1016/j.neucom.2024.128372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Synthetic Minority Oversampling Technique (SMOTE) is a popular preprocessing method for handling the imbalance learning problem, which is one of the main challenges in the field of data mining. In this paper, we claim that the main issue exists in SMOTE and its variants is the tradeoff between overfitting and noise prevention. To overcome this issue, we propose a novel method named LSMOTE, in which synthetic minority examples are generated based on a link-based approach and noise filtering for binary imbalanced datasets. Firstly, a data smoothing method is used to find the outlier points from the majority class. Then, the linked regions are recognized where a Gaussian process is employed for generating synthetic examples. Finally, due to the adventurous interpolation strategy, a simple noise filtering method is employed to remove the potential noisy synthetic examples. The experimental results based on 55 imbalanced datasets selected from the KEEL dataset repository reveal the good behavior of our proposed LSMOTE, achieving the best classification performance with respect to classic SMOTE and several state-of-the-art SMOTE variants.},
  archive      = {J_NEUCOM},
  author       = {Qin-Nan Cai and Zhong-Liang Zhang and Yu-Heng Wu and Xiu-Ming Zhang},
  doi          = {10.1016/j.neucom.2024.128372},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128372},
  shortjournal = {Neurocomputing},
  title        = {LSMOTE: A link-based synthetic minority oversampling technique for binary imbalanced datasets},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attention-based fusion network for RGB-d semantic
segmentation. <em>NEUCOM</em>, <em>608</em>, 128371. (<a
href="https://doi.org/10.1016/j.neucom.2024.128371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D semantic segmentation can realize a profound comprehension of scenes, which is crucial in various computer vision tasks. However, due to the inherent modal variances and image noise, achieving superior segmentation using existing methods remains challenging. In this paper, we propose an attention-based fusion network for RGB-D semantic segmentation. Specifically, our network employs a forward multi-step propagation strategy and a backward progressive bootstrap fusion strategy based on the encoder–decoder architecture. By aggregating feature maps at different scales, we effectively diminish the uncertainty in the final prediction. Meanwhile, we introduce a Channel and Spatial Rectification Module (CSRM) to enable multi-dimensional interactions and noise removal. In order to achieve comprehensive integration between RGB and depth images, we put the rectified features into the Cross-Attention Fusion Module(CAFM). Extensive experiments show that our network can adeptly manage a diverse array of complex scenarios, demonstrating its innovative strength with superior performance and robust effectiveness across indoor NYU Depth V2 and SUN-RGBD datasets, and extending its capabilities to the outdoor Cityscapes dataset.},
  archive      = {J_NEUCOM},
  author       = {Li Zhong and Chi Guo and Jiao Zhan and JingYi Deng},
  doi          = {10.1016/j.neucom.2024.128371},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128371},
  shortjournal = {Neurocomputing},
  title        = {Attention-based fusion network for RGB-D semantic segmentation},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simulation-based evaluation of model-free reinforcement
learning algorithms for quadcopter attitude control and trajectory
tracking. <em>NEUCOM</em>, <em>608</em>, 128362. (<a
href="https://doi.org/10.1016/j.neucom.2024.128362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {General use quadcopters have been under development for over a decade but many of their potential applications are still under evaluation and have not yet been adopted in many of the areas that could benefit from their use. While the current generation of quadcopters use a mature set of control algorithms, the next steps, especially as autonomous features are developed, should involve a more complex learning capability to be able to adapt to unknown circumstances in a safe and reliable way. This paper provides baseline quadcopter control models learnt using eight general reinforcement learning (RL) algorithms in a simulated environment, with the object of establishing a reference performance, both in terms of precision and generation cost, for a simple set of trajectories. Each algorithm uses a tailored set of hyperparameters while, additionally, the influence of random seeds is also studied. While not all algorithms converge in the allocated computing budget, the more complex ones are able to provide stable and precise control models. This paper recommends the use of the TD3 algorithm as a reference for comparison with new RL algorithms. Additional guidance for future work is provided based on the weaknesses identified in the learning process, especially regarding the strong dependence of agent performance on random seeds.},
  archive      = {J_NEUCOM},
  author       = {Pablo Caffyn Yuste and José Antonio Iglesias Martínez and María Araceli Sanchis de Miguel},
  doi          = {10.1016/j.neucom.2024.128362},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128362},
  shortjournal = {Neurocomputing},
  title        = {Simulation-based evaluation of model-free reinforcement learning algorithms for quadcopter attitude control and trajectory tracking},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Asymptotic stability analysis of time delayed
fractional-order replicator dynamics with government’s intervention.
<em>NEUCOM</em>, <em>608</em>, 128359. (<a
href="https://doi.org/10.1016/j.neucom.2024.128359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the asymptotic stability of fractional-order replicator dynamics with government involvement. Firstly, we extend replicator dynamics incorporating government intervention into a fractional-order framework. Subsequently, we introduce a novel property for the vector Lyapunov function tailored to fractional-order replicator dynamics with government involvement. We then use this new property to elucidate the asymptotic stability of fractional-order replicator dynamics with government intervention. Additionally, we tackle the scenario of fractional-order replicator dynamics with time delay, analyzing the system&#39;s asymptotic stability in the presence of delay. Finally, we validate the correctness and practicality of these novel theoretical results through numerical simulations conducted under various conditions.},
  archive      = {J_NEUCOM},
  author       = {Zhang Zhe and Toshimitsu Ushio and Yaonan Wang and Jing Zhang and Xiaogang Zhang},
  doi          = {10.1016/j.neucom.2024.128359},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128359},
  shortjournal = {Neurocomputing},
  title        = {Asymptotic stability analysis of time delayed fractional-order replicator dynamics with government’s intervention},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Physical activation functions (PAFs): An approach for more
efficient induction of physics into physics-informed neural networks
(PINNs). <em>NEUCOM</em>, <em>608</em>, 128352. (<a
href="https://doi.org/10.1016/j.neucom.2024.128352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the evolution of Physics-Informed Neural Networks (PINNs) has reduced the gap between Deep Learning (DL) based methods and analytical/numerical approaches in scientific computing. However, there are still complications in training PINNs and the optimal interleaving of physical models. In this work, we introduce the concept of Physical Activation Functions (PAFs), in which one can use generic AFs with their mathematical expression inherited from the physical description of the evaluated system, instead of solely usage of standard activation functions (AFs) such as tanh , and sigmoid for all the neurons. The expression of PAFs could be selected based on individual terms appearing in the analytical solution, the initial or boundary conditions of the PDE system, or a component in the composition-of-functions type solutions. The PAFs could be applied in NNs, either in explicit, or self-adaptive forms. In the explicit approach, the main activation function of the network is replaced by PAF in some of the neurons of the network. In the self-adaptive implementation approach, the relative impact of PAFs (compared to the base AF) for each neuron was determined automatically. We tested the performance of PAFs in both forward and inverse problems for several PDEs, such as 1D and 2D wave equations, the Advection-Convection equation, the 1D heterogeneous, and 2D diffusion equations, and the Laplace equation. The main advantage of PAFs, compared to using standard AFs, was the more efficient constraining and interleaving of PINNs with the physical phenomena and their underlying mathematical models. The added PAFs significantly improved the predictions of PINNs for the testing data that were out-of-training distribution. Furthermore, applying PAFs reduced the size of the PINNs by up to 75 % in different cases while maintaining the same accuracy. Also, the training process was improved by reducing the value of the total loss term by one to two orders of magnitude. Furthermore, it improved the precision of the calculated properties in the examined inverse problems, for both clean and noisy observational data. It can be concluded that using PAFs helps in generating PINNs with less complexity and more validity for longer ranges of prediction.},
  archive      = {J_NEUCOM},
  author       = {Jassem Abbasi and Pål Østebø Andersen},
  doi          = {10.1016/j.neucom.2024.128352},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128352},
  shortjournal = {Neurocomputing},
  title        = {Physical activation functions (PAFs): An approach for more efficient induction of physics into physics-informed neural networks (PINNs)},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved gradient leakage attack against compressed
gradients in federated learning. <em>NEUCOM</em>, <em>608</em>, 128349.
(<a href="https://doi.org/10.1016/j.neucom.2024.128349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed machine learning, such as federated learning, protects privacy by collecting gradients instead of training data. Recent studies have shown that gradient leakage attacks are possible in distributed machine learning, that is, the training data can be reconstructed from the shared gradients. In practical applications, distributed machine learning typically uses gradient compression to prevent gradient leakage attacks. This approach not only significantly reduces communication overhead but also maintains model performance. In this paper, we propose a method to reconstruct images from compressed gradients, called Deep Leakage from Compressed Gradients (DLCG). Extensive experiments on LeNet and ResNet20-4 demonstrate that our proposed method is able to reconstruct recognizable images from compressed gradients with sparsity levels as high as 90% and 80%, respectively, outperforming other methods. Furthermore, we analyze the sensitivity of gradient leakage attack to gradients of from different layers and propose a corresponding defense strategy.},
  archive      = {J_NEUCOM},
  author       = {Xuyang Ding and Zhengqi Liu and Xintong You and Xiong Li and Athhanasios V. Vasilakos},
  doi          = {10.1016/j.neucom.2024.128349},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128349},
  shortjournal = {Neurocomputing},
  title        = {Improved gradient leakage attack against compressed gradients in federated learning},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Switching LPV approach for analysis and control of TCP-based
cyber-physical systems under DoS attack. <em>NEUCOM</em>, <em>608</em>,
128310. (<a href="https://doi.org/10.1016/j.neucom.2024.128310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical systems (CPSs) integrate controllers, sensors, actuators, and communication networks. Tight integration with communication networks makes CPSs vulnerable to cyberattacks. In this paper, the impact of denial of service (DoS) attacks on the stability of cyber physical systems is investigated, with a focus on the transmission control protocol (TCP). A sufficient stability condition is extracted in linear matrix inequality (LMI) form. The TCP-CPS under DoS attack is modeled as a switching linear parameter-varying (LPV) time-delay system using the Markov jump model. Subsequently, a parameter-dependent stabilizing controller is designed for CPSs under DoS attacks, taking into account network parameters. Finally, the efficiency and feasibility of the findings are demonstrated through a well-known case study in the networked control systems literature.},
  archive      = {J_NEUCOM},
  author       = {Soheila Barchinezhad and Vicenç Puig},
  doi          = {10.1016/j.neucom.2024.128310},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128310},
  shortjournal = {Neurocomputing},
  title        = {Switching LPV approach for analysis and control of TCP-based cyber-physical systems under DoS attack},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intuitionistic fuzzy generalized eigenvalue proximal support
vector machine. <em>NEUCOM</em>, <em>608</em>, 128258. (<a
href="https://doi.org/10.1016/j.neucom.2024.128258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized eigenvalue proximal support vector machine (GEPSVM) has attracted widespread attention due to its simple architecture, rapid execution, and commendable performance. GEPSVM gives equal significance to all samples, thereby diminishing its robustness and efficacy when confronted with real-world datasets containing noise and outliers. In order to reduce the impact of noises and outliers, we propose a novel intuitionistic fuzzy generalized eigenvalue proximal support vector machine (IF-GEPSVM). The proposed IF-GEPSVM assigns the intuitionistic fuzzy score to each training sample based on its location and surroundings in the high-dimensional feature space by using a kernel function. The solution of the IF-GEPSVM optimization problem is obtained by solving a generalized eigenvalue problem. Further, we propose an intuitionistic fuzzy improved generalized eigenvalue proximal support vector machine (IF-IGEPSVM) by solving standard eigenvalue decomposition resulting in simpler optimization problems with less computation cost which leads to an efficient intuitionistic fuzzy-based model. We conduct a comprehensive evaluation of the proposed IF-GEPSVM and IF-IGEPSVM models on UCI and KEEL benchmark datasets. Moreover, to evaluate the robustness of the proposed IF-GEPSVM and IF-IGEPSVM models, label noise is introduced into some UCI and KEEL datasets. The experimental findings showcase the superior generalization performance of the proposed IF-GEPSVM and IF-IGEPSVM models when compared to the existing baseline models, both with and without label noise. Our experimental results, supported by rigorous statistical analyses, confirm the superior generalization abilities of the proposed IF-GEPSVM and IF-IGEPSVM models over the baseline models. Furthermore, we implement the proposed IF-GEPSVM and IF-IGEPSVM models on the USPS recognition dataset, yielding promising results that underscore the models’ effectiveness in practical and real-world applications. The source code of the proposed IF-GEPSVM and IF-IGEPSVM models are available at https://github.com/mtanveer1/IF-GEPSVM .},
  archive      = {J_NEUCOM},
  author       = {A. Quadir and M.A. Ganaie and M. Tanveer},
  doi          = {10.1016/j.neucom.2024.128258},
  journal      = {Neurocomputing},
  month        = {12},
  pages        = {128258},
  shortjournal = {Neurocomputing},
  title        = {Intuitionistic fuzzy generalized eigenvalue proximal support vector machine},
  volume       = {608},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep top-down framework towards generalisable multi-view
pedestrian detection. <em>NEUCOM</em>, <em>607</em>, 128458. (<a
href="https://doi.org/10.1016/j.neucom.2024.128458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple cameras have been frequently used to detect heavily occluded pedestrians. The state-of-the-art methods, for deep multi-view pedestrian detection, usually project the feature maps, extracted from multiple views, to the ground plane through homographies for information fusion. However, this bottom-up approach can easily overfit the camera locations and orientations in a training dataset, which leads to a weak generalisation performance and compromises its real-world applications. To address this problem, a deep top-down framework TMVD is proposed, in which the feature maps within the rectangular boxes, sitting at each cell of the discretized ground plane and of the average pedestrians’ size, in the multiple views are weighted and embedded in a top view. They are used to infer the locations of pedestrians by using a convolutional neural network. The proposed method significantly improves the generalisation performance when compared with the benchmark methods for deep multi-view pedestrian detection. Meanwhile, it also significantly outperforms the other top-down methods.},
  archive      = {J_NEUCOM},
  author       = {Rui Qiu and Ming Xu and Yuchen Ling and Jeremy S. Smith and Yuyao Yan and Xinheng Wang},
  doi          = {10.1016/j.neucom.2024.128458},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128458},
  shortjournal = {Neurocomputing},
  title        = {A deep top-down framework towards generalisable multi-view pedestrian detection},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-driven paradigm shift in computerized cardiotocography
analysis: A systematic review and promising directions. <em>NEUCOM</em>,
<em>607</em>, 128446. (<a
href="https://doi.org/10.1016/j.neucom.2024.128446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement of deep neural networks (DNNs) has significantly transformed various sectors, demonstrating unparalleled proficiency in managing intricate tasks in multiple domains. This progress holds promising implications for fetal monitoring systems, particularly in leveraging artificial intelligence (AI) to enhance the detection of abnormalities through cardiotocography (CTG). Understanding the evolving role of AI in obstetrics and gynecology, and its potential to revolutionize clinical practices, is crucial. This paper provides a comprehensive review of the integration of computerized cardiotocography and its associated technologies, coupled with a detailed analysis of the latest developments in machine learning (ML) and deep learning (DL) within the realm of CTG research over recent years. It further explores additional tools for fetal heart monitoring, such as fetal cardiotocography, and delves into the implications of these advancements. Moreover, the study outlines prospective research avenues, discusses innovative AI approaches to overcome existing challenges, and envisages the transformative impact of AI on the future of antepartum and intrapartum care, paving the way for a new era of automated fetal monitoring.},
  archive      = {J_NEUCOM},
  author       = {Weifang Xie and Pufan Cai and Yating Hu and Yu Lu and Cang Chen and Zhiqi Cai and Xianghua Fu},
  doi          = {10.1016/j.neucom.2024.128446},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128446},
  shortjournal = {Neurocomputing},
  title        = {AI-driven paradigm shift in computerized cardiotocography analysis: A systematic review and promising directions},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic attention aggregated missing spatial–temporal data
imputation for traffic speed prediction. <em>NEUCOM</em>, <em>607</em>,
128441. (<a href="https://doi.org/10.1016/j.neucom.2024.128441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic speed forecasting is indispensable in Intelligent Traffic Systems (ITS). The missing traffic speed due to sensors’ failure may hamper the accurate prediction of traffic speed. Different kinds of imputation techniques were employed to replace the missing values considering the spatial and temporal information. However, previous techniques did not consider the dynamic contribution of the neighboring nodes and failed to capture the complex properties of traffic speed data precisely. The architecture of the previous imputation models was infeasible in real-time applications in terms of scalability. Therefore, a novel machine learning-based imputation technique is proposed to generate the missing traffic speed using the spatial–temporal information and dynamic contribution of neighboring nodes. A new dataset considering the characteristics of the traffic speed data is generated from the existing dataset by exploiting the non-missing traffic speed of neighboring nodes. The newly formed dataset helps in the estimation of the dynamic contribution of the neighboring nodes using the linear regression algorithm. The non-missing speeds and estimated dynamic contribution of neighboring nodes assist in calculating the missing speeds of a node. Furthermore, a novel deep learning-based prediction model is introduced to forecast traffic speed accurately. The prediction model contains graph structure learning, a deep graph neural network with skip connections, GRU, multi-head soft attention, and a fully connected neural network. Graph structure learning is proposed based on the distribution of the congestion to represent the graph in an efficient way. The deep graph neural network with skip connections and GRU help in capturing topological and temporal information, respectively. The multi-head soft attention is designed to focus on every relevant temporal information at each time step for capturing global traffic information. Finally, the extracted spatial–temporal features are fed into the fully connected neural network to predict the traffic speed. The proposed imputation and prediction models are evaluated on two real-time datasets, METR-LA and PeMSD7 datasets, under different missing rates of different missing patterns. The proposed framework generates possible spatial–temporal information for efficient traffic congestion management and evicts erroneous issues in real-time.},
  archive      = {J_NEUCOM},
  author       = {Pritam Bikram and Shubhajyoti Das and Arindam Biswas},
  doi          = {10.1016/j.neucom.2024.128441},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128441},
  shortjournal = {Neurocomputing},
  title        = {Dynamic attention aggregated missing spatial–temporal data imputation for traffic speed prediction},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Alternating nonnegative least squares-incorporated
regularized symmetric latent factor analysis for undirected weighted
networks. <em>NEUCOM</em>, <em>607</em>, 128440. (<a
href="https://doi.org/10.1016/j.neucom.2024.128440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An U ndirected W eighted N etwork (UWN) can be precisely quantified as an adjacency matrix whose inherent characteristics are fully considered in a S ymmetric N onnegative L atent F actor (SNLF) model for its good representation accuracy. However, an SNLF model uses a sole latent factor matrix to precisely describe the topological characteristic of a UWN, i.e., symmetry, thereby impairing its representation learning ability. Aiming at addressing this issue, this paper proposes an A lternating nonnegative least squares-incorporated Regularized S ymmetric L atent factor analysis (ARSL) model. First of all, equation constraints composed of multiple matrices are built in its learning objective for well describing the symmetry of a UWN. Note that it adopts an L 2 -norm-based regularization scheme to relax such constraints for making such a symmetry-aware learning objective solvable. Then, it designs an alternating nonnegative least squares-incorporated algorithm for optimizing its parameters efficiently. Empirical studies on four UWNs demonstrate that an ARSL model outperforms the state-of-the-art models in terms of representation accuracy, as well as achieves promising computational efficiency.},
  archive      = {J_NEUCOM},
  author       = {Yurong Zhong and Kechen Liu and Chen Jiqiu and Xie Zhe and Weiling Li},
  doi          = {10.1016/j.neucom.2024.128440},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128440},
  shortjournal = {Neurocomputing},
  title        = {Alternating nonnegative least squares-incorporated regularized symmetric latent factor analysis for undirected weighted networks},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Mixing prisoner’s dilemma games on higher-order networks.
<em>NEUCOM</em>, <em>607</em>, 128439. (<a
href="https://doi.org/10.1016/j.neucom.2024.128439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prisoner’s dilemma game is a paradigmatic example of a plight situation in which different individuals vie for maximal payoffs. And it has been shown that interaction networks that host such individuals have an immense impact on individual strategy choices. In this paper, we advance this subject by mixing the two-person prisoner’s dilemma and various multiplayer prisoner’s dilemma games and explore the role of 2-order simplicial complexes on the evolutionary dynamics. In the studied model, the fraction of multiplayer prisoner’s dilemma games on the network can be indirectly controlled by adjusting the ratio of 2-simplex complexes in the network. Through large-scale simulations, we show that by adjusting this ratio, the level of cooperation can be enhanced by a mechanism that is unique to higher-order networks. In particular, the strategic unity of the triangles in the network can foster the stability of cooperation and its spreading through enhanced network reciprocity. These results thus reveal benefits of higher-order interactions on cooperation that have thus far, on classical networks, been reserved only for games played in groups, such as the public goods game.},
  archive      = {J_NEUCOM},
  author       = {Juan Wang and Jindong Nie and Shiqiang Guo and Mahmut Özer and Chengyi Xia and Matjaž Perc},
  doi          = {10.1016/j.neucom.2024.128439},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128439},
  shortjournal = {Neurocomputing},
  title        = {Mixing prisoner’s dilemma games on higher-order networks},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MGFNet: Cross-scene crowd counting via multistage gated
fusion network. <em>NEUCOM</em>, <em>607</em>, 128431. (<a
href="https://doi.org/10.1016/j.neucom.2024.128431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing crowd counting methods are mainly trained and tested in similar scenarios. When the testing and training scenarios of the model are different, the counting accuracy of these methods will sharply decrease, which seriously limits their practical application. To address this problem, we propose a multistage gated fusion network (MGFNet) for cross-scene crowd counting. MGFNet is primarily composed of dynamic gated convolution units (DGCU) and multilevel scale attention blocks (MSAB) modules. Specifically, DGCU uses a dynamic gating path to supplement detailed information to reduce the loss of crowd information and overestimation of background in different scenarios. MSAB calibrates crowd information at different scales and perspectives in different scenes by generating attention maps with discriminative information. In addition, we used a new global local consistency loss to optimize the model to adapt to changes in crowd density and distribution. Extensive experiments on four different types of scene counting benchmarks show that the proposed MGFNet achieves superior cross-scene counting performance.},
  archive      = {J_NEUCOM},
  author       = {Yanbo Liu and Yingxiang Hu and Guo Cao and Yanfeng Shang},
  doi          = {10.1016/j.neucom.2024.128431},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128431},
  shortjournal = {Neurocomputing},
  title        = {MGFNet: Cross-scene crowd counting via multistage gated fusion network},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-organizing hypercomplex-valued adaptive network.
<em>NEUCOM</em>, <em>607</em>, 128429. (<a
href="https://doi.org/10.1016/j.neucom.2024.128429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel, unsupervised, artificial intelligence system is presented, whose input signals and trainable weights consist of complex or hypercomplex values. The system uses the effect given by the complex multiplication that the multiplicand is not only scaled but also rotated. The more similar an input signal and the reference signal are, the more likely the input signal belongs to the corresponding class. The data assigned to a class during training is stored on a generic layer as well as on a layer extracting special features of the signal. As a result, the same cluster can hold a general description and the details of the signal. This property is vital for assigning a signal to an existing or a new class. To ensure that only valid new classes are opened, the system determines the variances by comparing each input signal component with the weights and adaptively adjusts its activation and threshold functions for an optimal classification decision. The presented system knows at any time all boundaries of its clusters. Experimentally, it is demonstrated that the system is able to cluster the data of multiple classes autonomously, fast, and with high accuracy.},
  archive      = {J_NEUCOM},
  author       = {Simon Hazubski and Harald Hoppe},
  doi          = {10.1016/j.neucom.2024.128429},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128429},
  shortjournal = {Neurocomputing},
  title        = {Self-organizing hypercomplex-valued adaptive network},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Polar lights optimizer: Algorithm and applications in image
segmentation and feature selection. <em>NEUCOM</em>, <em>607</em>,
128427. (<a href="https://doi.org/10.1016/j.neucom.2024.128427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces Polar Lights Optimization (PLO), an algorithm based on the aurora phenomenon or polar lights. The aurora is a unique natural spectacle that occurs when energetic particles from the solar wind converge at the Earth&#39;s poles, influenced by the geomagnetic field and the Earth&#39;s atmosphere. By analyzing the motion of high-energy particles and delving into the underlying principles of physics, we propose a unique model for mimicking particle motion. This model integrates gyration motion and aurora oval walk, with the former facilitating local exploitation, while the latter enabling global exploration. By synergistically combining these two strategies, the proposed PLO achieves a balanced approach to local exploitation and global exploration. Additionally, a particle collision strategy is introduced to enhance the efficiency of escaping local optima. To evaluate the performance of PLO, a qualitative analysis experiment is designed to assess its ability to explore the problem space and search for solutions. PLO is compared against 9 classic algorithms and 8 high-performance algorithms using 30 benchmark functions from IEEE CEC2014. Furthermore, we compare and analyze PLO with the current state-of-the-art methods in the field, utilizing 12 benchmark functions from IEEE CEC2022. Subsequently, PLO is successfully applied to multi-threshold image segmentation and feature selection. Specifically, a PLO-based multi-threshold segmentation model and a binary PLO-based feature selection method are developed. The performance of PLO is also evaluated using 10 images from the Invasive Ductal Carcinoma (IDC) medical dataset, while the overall adaptability and accuracy of the feature selection model are tested using 8 medical datasets. These results affirm the emergence of PLO as an effective optimization tool ready for solving real-world problems, including those in the medical field. The source codes of PLO are available at https://aliasgharheidari.com/PLO.html and other websites.},
  archive      = {J_NEUCOM},
  author       = {Chong Yuan and Dong Zhao and Ali Asghar Heidari and Lei Liu and Yi Chen and Huiling Chen},
  doi          = {10.1016/j.neucom.2024.128427},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128427},
  shortjournal = {Neurocomputing},
  title        = {Polar lights optimizer: Algorithm and applications in image segmentation and feature selection},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differentially private and explainable boosting machine with
enhanced utility. <em>NEUCOM</em>, <em>607</em>, 128424. (<a
href="https://doi.org/10.1016/j.neucom.2024.128424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce DP-EBM*, an enhanced utility version of the Differentially Private Explainable Boosting Machine (DP-EBM). DP-EBM* offers predictions for both classification and regression tasks, providing inherent explanations for its predictions while ensuring the protection of sensitive individual information via Differential Privacy. DP-EBM* has two major improvements over DP-EBM. Firstly, we develop an error measure to assess the efficiency of using privacy budget, a crucial factor to accuracy, and optimize this measure. Secondly, we propose a feature pruning method, which eliminates less important features during the training process. Our experimental results demonstrate that DP-EBM* outperforms the state-of-the-art differentially private explainable models.},
  archive      = {J_NEUCOM},
  author       = {Incheol Baek and Yon Dohn Chung},
  doi          = {10.1016/j.neucom.2024.128424},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128424},
  shortjournal = {Neurocomputing},
  title        = {Differentially private and explainable boosting machine with enhanced utility},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An inverse-free getz-marsden dynamic system and its
eleven-instant discrete model for time-variant linear equations solving.
<em>NEUCOM</em>, <em>607</em>, 128416. (<a
href="https://doi.org/10.1016/j.neucom.2024.128416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-variant linear equations (TVLEs) are fundamental problems appeared in many practical applications. There is an increasing demand for algorithms that can solve TVLEs with high accuracy. This paper proposes an inverse-free continuous-time Getz–Marsden dynamic system (CTGMDS) for solving TVLEs. Additionally, a general eleven-instant finite-difference method (FDM) is proposed to discretize the CTGMDS, resulting in a general eleven-instant discrete-time GMDS (11-DTGMDS) model. Theoretically, the proposed 11-DTGMDS has truncation error of seven-order precision that delivers higher precision than the existing FDMs. This paper also compares five DTGMDS models using other FDMs to discretize the CTGMDS. The convergence of the CTGMDS and 11-DTGMDS is proven by theoretical analysis. Numerical validations are performed by comparing the 11-DTGMDS and other DTGMDSs, showing that the 11-DTGMDS provides higher solution accuracy. Finally, a path-tracking task is completed by applying the 11-DTGMDS model to a Franka Emika Panda robot, validating the practicality of the 11-DTGMDS.},
  archive      = {J_NEUCOM},
  author       = {Biao Song and Jiarong Guo and Weibing Li and Yongping Pan},
  doi          = {10.1016/j.neucom.2024.128416},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128416},
  shortjournal = {Neurocomputing},
  title        = {An inverse-free getz-marsden dynamic system and its eleven-instant discrete model for time-variant linear equations solving},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time stability of fractional-order quaternion-valued
memristive neural networks with time delay. <em>NEUCOM</em>,
<em>607</em>, 128410. (<a
href="https://doi.org/10.1016/j.neucom.2024.128410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the finite-time stability (FTS) problem of fractional-order quaternion-valued memristive neural networks (FQMNNs) with time delay. Firstly, by leveraging set-valued mapping, differential inclusion, and contracting mapping principle, the sufficient condition is provided to assure the existence and uniqueness of the equilibrium point. Secondly, given the fractional order differential inequality and Gronwall inequality, a finite-time stability (FTS) criterion is obtained for the delayed FQMNNs with the fractional order between 0 and 1. Additionally, a sufficient condition is proposed to guarantee the FTS of FQMNNs with the fractional order between 1 and 2. Compared with existing results, this study not only extends the fractional order between 0 and 2, but also incorporates quaternions, which significantly enhances the FTS theory. Finally, two numerical examples demonstrate the practicality of the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Jingjing Wang and Hongbing Xu and Song Zhu},
  doi          = {10.1016/j.neucom.2024.128410},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128410},
  shortjournal = {Neurocomputing},
  title        = {Finite-time stability of fractional-order quaternion-valued memristive neural networks with time delay},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-label feature selection based on minimizing feature
redundancy of mutual information. <em>NEUCOM</em>, <em>607</em>, 128392.
(<a href="https://doi.org/10.1016/j.neucom.2024.128392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection is an indispensable technology in the preprocessing of multi-label high-dimensional data. Approaches utilizing information theory and sparse models hold promise in this domain, demonstrating strong performance. Although there have been extensive literatures using l 1 l1 and l 2 , 1 l2,1 -norms to identify label-specific features and common features in the feature space, they all ignore the redundant information interference problem when different features are learned simultaneously. Considering that features and labels in multi-label data are rarely linearly correlated, the MFS-MFR approach is presented to generate a representation of the nonlinear correlation between features and labels using the mutual information estimator. Following that, MFS-MFR detects specific and common features in the feature-label mutual information space using two coefficient matrices constrained by the l 1 l1 and l 2 , 1 l2,1 -norms, respectively. In particular, we define a non-zero correlation constraint that effectively minimizes the redundant correlation between the two matrices. Moreover, a manifold regularization term is devised to preserve the local information of the mutual information space. To solve the optimization model with nonlinear binary regular term, we employ a novel solution approach called S-FISTA. Extensive experiments across 15 multi-label benchmark datasets, comparing against 11 top-performing multi-label feature selection methods, demonstrate the superior performance of MFS-MFR.},
  archive      = {J_NEUCOM},
  author       = {Gaozhi Zhou and Runxin Li and Zhenhong Shang and Xiaowu Li and Lianyin Jia},
  doi          = {10.1016/j.neucom.2024.128392},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128392},
  shortjournal = {Neurocomputing},
  title        = {Multi-label feature selection based on minimizing feature redundancy of mutual information},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed predefined-time economic dispatch based on
event-triggered strategy for microgrids under directed graphs.
<em>NEUCOM</em>, <em>607</em>, 128391. (<a
href="https://doi.org/10.1016/j.neucom.2024.128391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of new energy solutions and the enhanced accessibility of distributed power sources have significantly increased the complexity and variability of microgrid structures. Due to inherent limitations in its operational mode, the traditional centralized optimization method falls short in effectively addressing the economic dispatch problem in contemporary microgrids. In this paper, a distributed optimization method is devised to address the economic dispatch problem of microgrids under directed graphs by leveraging the consensus algorithm of multi-agent systems. We define the incremental cost of each microgrid unit as the consensus variable, achieving convergence through a pioneering combination of event-triggered strategy and predefined-time control theory. This approach not only optimizes resource use but also ensures timely and efficient solution convergence, addressing critical gaps in existing methodologies. This approach enables control over the upper bound of convergence time for optimal solutions by directly adjusting time parameters in the controller under the directed graph. Consequently, it achieves coordinated control of the power output in microgrids within a predefined time while reducing the communication resources between nodes with event-triggered mechanism. The effectiveness of the proposed algorithm is verified through simulation and analysis.},
  archive      = {J_NEUCOM},
  author       = {Shaoping Chang and Hao Wang and Xiaoyuan Luo and Xinping Guan},
  doi          = {10.1016/j.neucom.2024.128391},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128391},
  shortjournal = {Neurocomputing},
  title        = {Distributed predefined-time economic dispatch based on event-triggered strategy for microgrids under directed graphs},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Progressive discrepancy elimination for visible–infrared
person re-identification. <em>NEUCOM</em>, <em>607</em>, 128387. (<a
href="https://doi.org/10.1016/j.neucom.2024.128387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible–Infrared Person Re-Identification (VI-ReID) aims to retrieve the identities of persons from different modalities. The significant distribution discrepancy makes this task challenging. Recent methods usually generate an intermediate modality to bridge the modality gap. However, these methods may lead to spectral confusion, and ignore the negative impact of visible channel redundancy information on establishing cross-modal correspondence. In this paper, we propose a Progressive Discrepancy Elimination Model (PDEM) for VI-ReID. Specifically, we design a Single-Channel Stripe Aggregation (SCSA) module to synthesize high-quality transitional modality images by using only raw visible and infrared spectral stripes. Meanwhile, we propose a two-stage Spectral Information Filtering (SIF) strategy, consisting of our designed Semantic Consistency Loss (SCL) and Cascade Aggregation Loss (CAL). SCL and CAL are employed in different training stages to achieve visible task-related information filtering and visible–infrared multi-scale alignment, respectively. In this way, the most relevant semantics with infrared modality in visible features are retained, and spectral correspondence is subsequently learned in a small cross-modal gap. We conduct extensive experiments on two VI-ReID datasets and achieve superior performance compared to most state-of-the-art methods. The source code of this paper is available at https://github.com/wxz0530/PDEM .},
  archive      = {J_NEUCOM},
  author       = {Guoqing Zhang and Zhun Wang and Hairui Wang and Jieqiong Zhou and Yuhui Zheng},
  doi          = {10.1016/j.neucom.2024.128387},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128387},
  shortjournal = {Neurocomputing},
  title        = {Progressive discrepancy elimination for visible–infrared person re-identification},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An end-to-end image-text matching approach considering
semantic uncertainty. <em>NEUCOM</em>, <em>607</em>, 128386. (<a
href="https://doi.org/10.1016/j.neucom.2024.128386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel end-to-end image-text matching approach considering semantic uncertainty (SU-ITM), aiming to deal with the one-to-many semantic diversity involved in image-text matching in order to capture the associations between them more comprehensively and improve the robustness of the model. Traditional methods map images and texts as definite points in an embedding space to measure cross-modal similarity. However, the point-based embedding cannot capture the semantic uncertainty, leading to a large bias in the matching results. To address this problem, we model the one-to-many associations between image and text in a way that establishes a probability distribution, incorporating the uncertainty information into the final semantic representation of the text. In addition, we optimize the image-text matching loss so that the different text features approximate the image features in a distributed manner while maintaining the discriminative nature of the semantic representation, effectively reducing the matching uncertainty. Notably, our method achieves end-to-end training by not using pre-trained target detection branches throughout the training process. We fully demonstrate the excellent performance of our method in the image-text matching task through experimental validation on Flickr30k and MSCOCO. Excellent performance levels of 546.1 and 545.0 are achieved on the R@SUM metric for Flickr30k and MSCOCO 1k, respectively.},
  archive      = {J_NEUCOM},
  author       = {Gulanbaier Tuerhong and Xin Dai and Liwei Tian and Mairidan Wushouer},
  doi          = {10.1016/j.neucom.2024.128386},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128386},
  shortjournal = {Neurocomputing},
  title        = {An end-to-end image-text matching approach considering semantic uncertainty},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DarkMor: A framework for darknet traffic detection that
integrates local and spatial features. <em>NEUCOM</em>, <em>607</em>,
128377. (<a href="https://doi.org/10.1016/j.neucom.2024.128377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dark web, as an integral part of the multi-layered structure of the internet, provides anonymity and high levels of concealment absent on the surface web. Users can engage in various online activities without leaving any trace, making the dark web a hub for illicit activities, such as drug and weapon trafficking. Consequently, this poses a significant threat to social order and network security. However, due to the high concealment of the dark web, traditional detection methods suffer with insufficient extraction of characteristic information from darknet traffic and inadequate consideration of feature correlations. As a result, the accuracy of these conventional detection methods in detecting the dark web in real network environments is suboptimal. This paper proposes a darknet traffic detection framework called DarkMor to address these challenges. It integrates local and spatial features, automates feature mining and fusion, and models spatial relationship between features to fully exploit their potential. The core components of DarkMor consist of the feature fusion module and the traffic perception module. Using an improved feature tokenizer transformer architecture, the feature fusion module enhances the extraction of local features within high-dimensional feature clusters, effectively combining local feature information with global context. Additionally, the traffic perception module leverages a temporal model that incorporates self-attention mechanisms to learn the spatiotemporal characteristics of fused features, thereby further enhancing the model’s detection. Experimental results demonstrated that DarkMor achieved an accuracy of 97.78% on real network datasets, surpassing the latest cross-modal darknet traffic detection models. Furthermore, DarkMor maintained an accuracy of 97.57% even in network environments with reduced training samples, confirming the feasibility and robustness of the proposed detection framework.},
  archive      = {J_NEUCOM},
  author       = {Jin Yang and Weiheng Liang and Xin Wang and Siyu Li and Xinyun Jiang and Yufei Mu and Shunyang Zeng},
  doi          = {10.1016/j.neucom.2024.128377},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128377},
  shortjournal = {Neurocomputing},
  title        = {DarkMor: A framework for darknet traffic detection that integrates local and spatial features},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph classification using high-difference-frequency
subgraph embedding. <em>NEUCOM</em>, <em>607</em>, 128369. (<a
href="https://doi.org/10.1016/j.neucom.2024.128369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of big data analysis, graphs have become an important data structure in relationship extraction and learning. However, the complexity of graph structure increases the difficulty of downstream learning tasks, e.g., graph classification. For example, some traditional graph classification methods rely on the attributes of nodes and edges; the attributes may be incomplete or missing in large-scale graph datasets, e.g., online social networks and knowledge graphs. Focusing on the node-level features overlooks the global characteristics, leading to decreased classification accuracy. This paper proposes a novel graph classification method based on the subgraph-level feature the high-difference-frequency subgraph. We measure the difference in subgraph appearing frequency and use the high difference frequency subgraphs as features in graph learning and classification. The experiments demonstrate that the proposed method outperforms the state-of-the-art graph classification methods.},
  archive      = {J_NEUCOM},
  author       = {Tianchong Gao and Yixin Xu},
  doi          = {10.1016/j.neucom.2024.128369},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128369},
  shortjournal = {Neurocomputing},
  title        = {Graph classification using high-difference-frequency subgraph embedding},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FTMLP: MLP with feature-temporal block for multivariate time
series forecasting. <em>NEUCOM</em>, <em>607</em>, 128365. (<a
href="https://doi.org/10.1016/j.neucom.2024.128365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series (MTS) forecasting is extensively applied in real-world scenarios. Recent studies introduced the concept of channel independence, which has achieved significant results. However, this approach often misses the intricate interrelations among features and lacks physical interpretation. To address this problem, we propose a new framework, the Feature-Temporal block, designed to extract both temporal and feature information. Each block contains two modules: a feature module using a gating mechanism to understand competitive interactions among features, and a temporal module using learnable filters for frequency domain filtering. This innovative design allows FTMLP to combine information across feature and sequence dimensions, as well as time and frequency domains. The computational efficiency of FTMLP is enhanced due to its exclusive use of Multi-Layer Perceptron (MLP). Comprehensive experiments on several real-world datasets demonstrate that FTMLP achieves state-of-the-art results in terms of overall performance. Code is available at https://github.com/whxlearning/FTMLP .},
  archive      = {J_NEUCOM},
  author       = {Haoxin Wang and Yipeng Mo and Honghe Dai and Nan Yin and Songhai Fan and Bixiong Li and Site Mo},
  doi          = {10.1016/j.neucom.2024.128365},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128365},
  shortjournal = {Neurocomputing},
  title        = {FTMLP: MLP with feature-temporal block for multivariate time series forecasting},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). STCSNN: High energy efficiency spike-train level spiking
neural networks with spatio-temporal conversion. <em>NEUCOM</em>,
<em>607</em>, 128364. (<a
href="https://doi.org/10.1016/j.neucom.2024.128364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-inspired spiking neuron networks (SNNs) have attracted widespread research interest due to their low power features, high biological plausibility, and strong spatiotemporal information processing capability. Although adopting a surrogate gradient (SG) makes the non-differentiability SNN trainable, achieving comparable accuracy for ANNs and keeping low-power features simultaneously is still tricky. In this paper, we proposed an energy-efficient spike-train level spiking neural network with spatio-temporal conversion, which has low computational cost and high accuracy. In the STCSNN, spatio-temporal conversion blocks (STCBs) are proposed to keep the low power features of SNNs and improve accuracy. However, STCSNN cannot adopt backpropagation algorithms directly due to the non-differentiability nature of spike trains. We proposed a suitable learning rule for STCSNNs by deducing the equivalent gradient of STCB. We evaluate the proposed STCSNN on static and neuromorphic datasets, including Fashion-Mnist, Cifar10, Cifar100, TinyImageNet, and DVS-Cifar10. The experiment results show that our proposed STCSNN outperforms the state-of-the-art accuracy on nearly all datasets, using fewer time steps and being highly energy-efficient.},
  archive      = {J_NEUCOM},
  author       = {Changqing Xu and Yi Liu and Yintang Yang},
  doi          = {10.1016/j.neucom.2024.128364},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128364},
  shortjournal = {Neurocomputing},
  title        = {STCSNN: High energy efficiency spike-train level spiking neural networks with spatio-temporal conversion},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cluster synchronization of fractional-order coupled genetic
regulatory networks via pinning control. <em>NEUCOM</em>, <em>607</em>,
128363. (<a href="https://doi.org/10.1016/j.neucom.2024.128363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell-to-cell interaction and quorum sensing are universal in real life and have an extremely important biological significance. Besides, fractional-order calculus has tremendous advantages in describing the memory of neurons and the inheritance of genes. In this article, the cluster synchronization of fractional-order coupled genetic regulatory networks (GRNs) is explored by applying pinning control technique. First of all, a type of coupled fractional-order models about GRNs is proposed based on the quorum sensing and cluster expression characteristics of genes. Secondly, by designing pinning control strategies and fractional-order inequalities, several sufficient criteria are constructed to reach cluster synchronization. Furthermore, the selection rule of pining nodes is provided to conduct what nodes can be selected to be pinned and how many nodes are pinned to achieve cluster synchronization. In addition, the fractional-order adaptive control strategy is designed to regulate control gains. Several numerical results are provided lastly to confirm the theoretical analysis.},
  archive      = {J_NEUCOM},
  author       = {Juan Yu and Rui Yao and Cheng Hu},
  doi          = {10.1016/j.neucom.2024.128363},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128363},
  shortjournal = {Neurocomputing},
  title        = {Cluster synchronization of fractional-order coupled genetic regulatory networks via pinning control},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maximal cliques-based hybrid high-dimensional feature
selection with interaction screening for regression. <em>NEUCOM</em>,
<em>607</em>, 128361. (<a
href="https://doi.org/10.1016/j.neucom.2024.128361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies on feature selection have been extensively conducted in the literature, as it plays a significant role in both supervised and unsupervised machine learning tasks. Since the bulk of features in high-dimensional data sets might not be significant, feature selection plays a key role in removing unimportant variables and improving prediction and data analysis performance. Many of the current feature selection methods, meanwhile, become ineffective when used on contemporary datasets, which exhibit an escalating number of features in relation to sample size. This paper introduces a novel supervised feature selection method for regression problems. The proposed algorithm is called maximal Clique with Interaction Screening (ISClique). The ISClique algorithm’s overall structure can be described in two steps. Initially, a filter approach is used to select relevant features from an initial feature space and examine the different interactions between them. This is done using an innovative coefficient based on Kendall’s tau and partial Kendall’s tau. Secondly, the maximal clique strategy is applied as a wrapper to the selected set from the previous step to construct subsets of features. The most optimal subset that minimizes prediction error is selected. The proposed method integrates the advantages of graph theory with feature screening. Additionally, because the criteria employed in developing the ISClique method accommodate variable heterogeneity, this method is equally suitable for classification tasks. The proposed hybrid approach has been evaluated through applications involving various simulation scenarios and real datasets. Experimental findings demonstrate the advantages of ISClique over comparable methods.},
  archive      = {J_NEUCOM},
  author       = {Hasna Chamlal and Asmaa Benzmane and Tayeb Ouaderhman},
  doi          = {10.1016/j.neucom.2024.128361},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128361},
  shortjournal = {Neurocomputing},
  title        = {Maximal cliques-based hybrid high-dimensional feature selection with interaction screening for regression},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GraphixMatch: Improving semi-supervised learning for graph
classification with FixMatch. <em>NEUCOM</em>, <em>607</em>, 128356. (<a
href="https://doi.org/10.1016/j.neucom.2024.128356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph classification is a critical problem that predicts the properties of an entire graph representing complicated relationships. This problem has been extensively studied in a supervised manner in various industries via graph convolutional networks that required large numbers of labeled graphs. However, labeled graphs are typically expensive and time-consuming to obtain in the real-world. Training graph classification models is difficult because of the sparseness of labeled data. Therefore, semi-supervised learning (SSL) algorithms that make full use of unlabeled data and overcome the lack of labels have led to the expansion of graph classification studies. In this study, we propose GraphixMatch to learn the graph properties of both labeled and unlabeled graphs based on the use of FixMatch for graph classification. To effectively capture the characteristics of a graph, we newly define and apply weak and strong augmentation of the graph. We evaluate the proposed method on seven benchmarks from a public dataset. We show that compared with various SSL methods, the simplified proposed method with weak and strong augmentation is superior. Furthermore, we conduct extensive additional experiments to derive the important parameters of GraphixMatch.},
  archive      = {J_NEUCOM},
  author       = {Eunji Koh and Young Jae Lee and Seoung Bum Kim},
  doi          = {10.1016/j.neucom.2024.128356},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128356},
  shortjournal = {Neurocomputing},
  title        = {GraphixMatch: Improving semi-supervised learning for graph classification with FixMatch},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Output related fault detection and diagnosis based on multi
block modified orthogonal broyden-fletcher-goldfarb-shanno algorithm.
<em>NEUCOM</em>, <em>607</em>, 128350. (<a
href="https://doi.org/10.1016/j.neucom.2024.128350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, some progress has been made in fault diagnosis of multi-block regression model, but multi-block method uses the relationship between variables in Hilbert space to block, while the relationship between variables in complex industrial systems often exists in Banach space. In addition, Bayesian fusion method is used in fault monitoring, which can not accurately process the sub-block information and judge whether the fault information is related to the output. In this paper, a new multi-block method is proposed. Firstly, this method uses Ball Covariance (BCov) suitable for Banach space to describe the correlation between variables, and combines K-means clustering method to block variables to ensure that the blocking method is more reasonable. Secondly, an improved orthogonal decomposition Broyden-Fletcher -Goldfarb-Shanno (BFGS) algorithm is proposed. The MOBFGS algorithm performs orthogonal projection on potential structures, removing information orthogonal to the output from the input block. Furthermore, through complete orthogonal decomposition between the input block and the output block, information related to and unrelated to the output is completely separated, and used to detect output related and unrelated faults, respectively. Thirdly, at the block level, MOBFGS algorithm is used for fault detection and contribution graph method for fault diagnosis. Finally, numerical examples and Tennessee Eastman (TE) process simulation verify the effectiveness of this method.},
  archive      = {J_NEUCOM},
  author       = {Cuiping Xue and Tie Zhang and Dong Xiao},
  doi          = {10.1016/j.neucom.2024.128350},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128350},
  shortjournal = {Neurocomputing},
  title        = {Output related fault detection and diagnosis based on multi block modified orthogonal broyden-fletcher-goldfarb-shanno algorithm},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-modal data clustering using deep learning: A
systematic review. <em>NEUCOM</em>, <em>607</em>, 128348. (<a
href="https://doi.org/10.1016/j.neucom.2024.128348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal clustering represents a formidable challenge in the domain of unsupervised learning. The objective of multi-modal clustering is to categorize data collected from diverse modalities, such as audio, visual, and textual sources, into distinct clusters. These clustering techniques operate by extracting shared features across modalities in an unsupervised manner, where the identified common features exhibit high correlations within real-world objects. Recognizing the importance of perceiving the correlated nature of these features is vital for enhancing clustering accuracy in multi-modal settings. This survey explores Deep Learning (DL) techniques applied to multi-modal clustering, encompassing methodologies such as Convolutional Neural Networks (CNN), Autoencoders (AE), Recurrent Neural Networks (RNN), and Graph Convolutional Networks (GCN). Notably, this survey represents the first attempt to investigate DL techniques specifically for multi-modal clustering. The survey presents a novel taxonomy for DL-based multi-modal clustering, conducts a comparative analysis of various multi-modal clustering approaches, and deliberates on the datasets employed in the evaluation process. Additionally, the survey identifies research gaps within the realm of multi-modal clustering, offering insights into potential future avenues for research.},
  archive      = {J_NEUCOM},
  author       = {Sura Raya and Mariam Orabi and Imad Afyouni and Zaher Al Aghbari},
  doi          = {10.1016/j.neucom.2024.128348},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128348},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal data clustering using deep learning: A systematic review},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FATA: An efficient optimization method based on geophysics.
<em>NEUCOM</em>, <em>607</em>, 128289. (<a
href="https://doi.org/10.1016/j.neucom.2024.128289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient swarm intelligence algorithm is proposed to solve continuous multi-type optimization problems, named the fata morgana algorithm (FATA). By mimicking the process of mirage formation, FATA designs the mirage light filtering principle (MLF) and the light propagation strategy (LPS), respectively. The MLF strategy, combined with the definite integration principle, drives the algorithmic population to enhance FATA’s exploration capability. The LPS strategy, combined with the trigonometric principle, drives the algorithmic individual to improve the algorithm&#39;s convergence speed and exploitation capability. These two search strategies can better use FATA’s population and individual search capabilities. The FATA is compared with a broad array of competitive optimizers on 23 benchmark functions and IEEE CEC 2014 to verify the optimization capability. This work is designed separately for qualitative analysis, exploration and exploitation competence analysis, the analysis of avoiding locally optimal solutions, and comprehensive comparison experiments. The experimental results demonstrate the comprehensiveness and competitiveness of FATA for solving multi-type functions. Meanwhile, FATA is applied to three practical engineering optimization problems to evaluate its performance. Then, the algorithm obtains better results than its counterparts in engineering problems. According to the results, FATA has excellent potential to be used as an efficient computer-aided tool for dealing with practical optimization tasks. Source codes and related files are available at https://aliasgharheidari.com/FATA.html and other websites.},
  archive      = {J_NEUCOM},
  author       = {Ailiang Qi and Dong Zhao and Ali Asghar Heidari and Lei Liu and Yi Chen and Huiling Chen},
  doi          = {10.1016/j.neucom.2024.128289},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128289},
  shortjournal = {Neurocomputing},
  title        = {FATA: An efficient optimization method based on geophysics},
  volume       = {607},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rectifying self-training with neighborhood consistency and
proximity for source-free domain adaptation. <em>NEUCOM</em>,
<em>606</em>, 128425. (<a
href="https://doi.org/10.1016/j.neucom.2024.128425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-free domain adaptation (SFDA) seeks to transfer knowledge from the source domain to the target domain by leveraging only unlabeled target data and pre-trained source model, without accessing source data. Existing approaches for SFDA heavily depend on self-training, involving the generation of pseudo-labels on the target domain. However, these generated labels inevitably suffer from incorrect predictions due to distribution discrepancy, making the training process vulnerable to pseudo-label noise. To track this issue, in this paper, we propose neighborhood semantic consistency and neighborhood spatial proximity to distinguish sample importance and incorporate them to rectify self-training. Specifically, we refer to the sample relationship with nearby neighbors to evaluate the pseudo-label reliability of target samples, explicitly serving as regularization for the optimizing objective. The neighborhood consistency is calculated based on the similarity of sample-wise and data-structure predictions, describing local semantic uniformity, while the neighborhood proximity is calculated by considering the feature distances to nearby samples, which measures local spatial affinity. Furthermore, a regularized neighborhood alignment term is introduced, which adaptively integrates self-distillation with neighborhood supervision to boost representation learning. Comprehensive experiments across several different SFDA benchmarks demonstrate the efficacy of our approach. Further analyses substantiate that the proposed approach exhibits superior robustness against pseudo-label noise, which leads to notable enhancements when compared with conventional pseudo-label-based self-training. The codes of our method are available at https://github.com/xingbw/Rectified-Self-Training .},
  archive      = {J_NEUCOM},
  author       = {Bowei Xing and Xianghua Ying and Ruibin Wang},
  doi          = {10.1016/j.neucom.2024.128425},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128425},
  shortjournal = {Neurocomputing},
  title        = {Rectifying self-training with neighborhood consistency and proximity for source-free domain adaptation},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). MIMTracking: Masked image modeling enhanced vision
transformer for visual object tracking. <em>NEUCOM</em>, <em>606</em>,
128415. (<a href="https://doi.org/10.1016/j.neucom.2024.128415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, one-stage trackers achieve state-of-the-art tracking results due to more sufficient integration of search and template representations. These methods usually adopt an encoder for synchronous feature generation and interaction. Despite their high performance, the one-stage approaches tend to feed the encoder full input representations that are highly redundant and dense during training. With a focus on tackling this problem, a novel algorithm termed MIMTracking is developed for visual target tracking. MIMTracking exploits an encoder and a decoder for masked image modeling during training. Randomly sampled discrete search embeddings and template embeddings serve as input of the encoder. The lightweight decoder takes full representations as input and progressively highlights the target region. This design alleviates input redundancy and reduces the computational cost of the training process, thereby allowing for more efficient learning of useful representations. The proposed MIMTracking achieves state-of-the-art tracking results on numerous tracking datasets, e.g., 51.5 % area under curve (AUC) on LaSOT ext , outperforming the previous top tracker OSTrack by 2 %. Especially, our large model MIMTracking-L further improves the AUC to 53.4 % on LaSOT ext .},
  archive      = {J_NEUCOM},
  author       = {Shuo Zhang and Dan Zhang and Qi Zou},
  doi          = {10.1016/j.neucom.2024.128415},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128415},
  shortjournal = {Neurocomputing},
  title        = {MIMTracking: Masked image modeling enhanced vision transformer for visual object tracking},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). HQ-net: A heatmap-based query backbone for point cloud
understanding. <em>NEUCOM</em>, <em>606</em>, 128413. (<a
href="https://doi.org/10.1016/j.neucom.2024.128413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of sensor technology, including LiDAR and RGB-D cameras, tasks related to point cloud understanding have gained widespread application. The sampling and learning of feature points play a crucial role in point cloud understanding, representing a fundamental and essential aspect of 3D computer vision. In the realm of point cloud processing, traditional methods such as Farthest Point Sampling (FPS) are frequently employed to select feature points. These points are then used in conjunction with effective feature aggregation operators to facilitate reasoning. However, these traditional sampling methods primarily focus on the Euclidean distance between points, lacking a comprehensive consideration of point cloud features. To address this limitation, we introduce HQ-Net, a novel point cloud understanding model designed to optimize feature point sampling using a Heatmap-based Query Backbone. The Heatmap-based Query Backbone utilizes the Heatmap Module to select category-specific point features, effectively generating a heatmap tailored to the category features and automatically extracting features from the heatmap. Subsequently, the proposed Query Encoder is employed to facilitate the interaction between point features and query features, providing mutual guidance and enhancing the model’s ability to capture spatial structure and semantic information within point clouds. Additionally, we propose task-specific heads, such as classification and segmentation heads for different tasks, which can be seamlessly integrated with the backbone to achieve excellent performance. In various point cloud understanding tasks, including shape classification, part segmentation, and semantic segmentation, HQ-Net demonstrates excellent performance.},
  archive      = {J_NEUCOM},
  author       = {Jun Li and Shangwei Guo and Luhan Wang and Shaokun Han},
  doi          = {10.1016/j.neucom.2024.128413},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128413},
  shortjournal = {Neurocomputing},
  title        = {HQ-net: A heatmap-based query backbone for point cloud understanding},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning-based robust output tracking control for unknown
discrete-time nonlinear systems with dynamic uncertainty.
<em>NEUCOM</em>, <em>606</em>, 128412. (<a
href="https://doi.org/10.1016/j.neucom.2024.128412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although numerous approximate dynamic programming (ADP) methods have been proposed and applied to robust control problems, research on the use of ADP methods for robust tracking control in nonlinear systems remains limited, especially for discrete time (DT) nonlinear systems. In this paper, we propose an efficient robust learning-based output tracking control method, referred to as r-LTC, for a class of unknown DT nonlinear systems with dynamic uncertainty. The objectives are achieved by: 1) using a system identification technique based on network-type coefficients Auto-Regressive with eXogenous variables (ARX) model to identify completely unknown systems; 2) reformulating the identified model into a state space model in terms of deviations from the reference trajectory, such that the robust tracking problem can be converted into a robust regulation problem; 3) transforming the robust regulation problem into an equivalent optimal regulation problem for a nominal system with a modified utility function; 4) alternately implementing the performance evaluation and control policy update through two neural networks (NNs) to numerically solve DT Hamilton-Jacobi-Bellman (HJB) equation, such that the approximated optimal feedback control inputs for nominal system can be obtained, allowing for realization of all unknown bounded uncertainties. The proposed method does not require a state observer and any steady state knowledge, only the measurable system input and output data are utilized. The convergence of NNs’ approximate weights and stability of the closed-loop uncertain systems are rigorously proven using the Lyapunov method. Lastly, a case study is performed using real data collected from the Shenzhen Metro Line 12 tunneling project to examine the performance of the proposed r-LTC algorithm in terms of the set value tracking accuracy, control system stability, and robustness against different types of disturbances.},
  archive      = {J_NEUCOM},
  author       = {Fang Liu and Hui Peng},
  doi          = {10.1016/j.neucom.2024.128412},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128412},
  shortjournal = {Neurocomputing},
  title        = {Learning-based robust output tracking control for unknown discrete-time nonlinear systems with dynamic uncertainty},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Clusterwise independent component analysis (c-ICA): An r
package for clustering subjects based on ICA patterns underlying
three-way (brain) data. <em>NEUCOM</em>, <em>606</em>, 128396. (<a
href="https://doi.org/10.1016/j.neucom.2024.128396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many areas of science, like neuroscience, genomics and text mining, several important and challenging research questions imply the study of (subject) heterogeneity present in three-way data. In clinical neuroscience, for example, disclosing differences or heterogeneity between subjects in resting state networks (RSNs) underlying multi-subject fMRI data (i.e., time by voxel by subject three-way data) may advance the subtyping of psychiatric and mental diseases. Recently, the Clusterwise Independent Component Analysis (C-ICA) method was proposed that enables the disclosure of heterogeneity between subjects in RSNs that is present in multi-subject rs-fMRI data [1] . Up to now, however, no publicly available software exists that allows to fit C-ICA to empirical data at hand. The goal of this paper, therefore, is to present the CICA R package, which contains the necessary functions to estimate the C-ICA parameters and to interpret and visualize the analysis output. Further, the package also includes functions to select suitable initial values for the C-ICA model parameters and to determine the optimal number of clusters and components for a given empirical data set (i.e., model selection). The use of the main functions of the package is discussed and demonstrated with simulated data. Herewith, the necessary analytical choices that have to be made by the user (e.g., starting values) are explained and showed step by step. The rich functionality of the package is further illustrated by applying C-ICA to empirical rs-fMRI data from a group of Alzheimer patients and elderly control subjects and to multi-country stock market data. Finally, extensions regarding the C-ICA algorithm and procedures for model selection that could be implemented in future releases of the package are discussed.},
  archive      = {J_NEUCOM},
  author       = {Jeffrey Durieux and Serge Rombouts and Marisa Koini and Juan Claramunt Gonzalez and Tom Wilderjans},
  doi          = {10.1016/j.neucom.2024.128396},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128396},
  shortjournal = {Neurocomputing},
  title        = {Clusterwise independent component analysis (C-ICA): An r package for clustering subjects based on ICA patterns underlying three-way (brain) data},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale contrastive adaptor learning for segmenting
anything in underperformed scenes. <em>NEUCOM</em>, <em>606</em>,
128395. (<a href="https://doi.org/10.1016/j.neucom.2024.128395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundational vision models, such as the Segment Anything Model (SAM), have achieved significant breakthroughs through extensive pre-training on large-scale visual datasets. Despite their general success, these models may fall short in specialized tasks with limited data, and fine-tuning such large-scale models is often not feasible. Current strategies involve incorporating adaptors into the pre-trained SAM to facilitate downstream task performance with minimal model adjustment. However, these strategies can be hampered by suboptimal learning approaches for the adaptors. In this paper, we introduce a novel Multi-scale Contrastive Adaptor learning method named MCA-SAM, which enhances adaptor performance through a meticulously designed contrastive learning framework at both token and sample levels. Our Token-level Contrastive adaptor (TC-adaptor) focuses on refining local representations by improving the discriminability of patch tokens, while the Sample-level Contrastive adaptor (SC-adaptor) amplifies global understanding across different samples. Together, these adaptors synergistically enhance feature comparison within and across samples, bolstering the model’s representational strength and its ability to adapt to new tasks. Empirical results demonstrate that MCA-SAM sets new benchmarks, outperforming existing methods in three challenging domains: camouflage object detection, shadow segmentation, and polyp segmentation. Specifically, MCA-SAM exhibits substantial relative performance enhancements, achieving a 20.0% improvement in MAE on the COD10K dataset, a 6.0% improvement in MAE on the CAMO dataset, a 15.4% improvement in BER on the ISTD dataset, and a 7.9% improvement in mDice on the Kvasir-SEG dataset.},
  archive      = {J_NEUCOM},
  author       = {Ke Zhou and Zhongwei Qiu and Dongmei Fu},
  doi          = {10.1016/j.neucom.2024.128395},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128395},
  shortjournal = {Neurocomputing},
  title        = {Multi-scale contrastive adaptor learning for segmenting anything in underperformed scenes},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A general method for mode decomposition on additive mixture:
Generalized variational mode decomposition and its sequentialization.
<em>NEUCOM</em>, <em>606</em>, 128390. (<a
href="https://doi.org/10.1016/j.neucom.2024.128390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational Mode Decomposition(VMD) method was proposed to separate non-stationary signal mixture by solving a optimization problem. This method is powerful and can reconstruct the signal components precisely when they are orthogonal(or quasi-orthogonal) in frequency domain. The crucial problem for VMD is that it requires the information of modal number before the decomposition. Also its applications are limited in 1D and 2D signal processing fields, of narrow scope. In this paper, by inheriting and developing the core idea of VMD, we build a general form for this method and extend it to the modal decomposition for common additive mixture, not only limited in signal processing. To overcome the obstacle of modal number, we sequentialize the generalized VMD method, such that the modes can be extracted one by one, without knowing the modal number a priori. After the generalization and sequentialization for the VMD, we apply them in different fields of additive case, such as texture segmentation, Gaussian Mixture Model(GMM), clustering, etc. From the experiments, we conclude that the generalized and sequentialized VMD methods can solve variety classical problems from the view of modal decomposition, which implies that our methods have higher generality and wider applicability. A raw Matlab code for this algorithm is shown in https://github.com/changwangke/SGVMD_additive_Clustering/blob/main/SGVMD_clustering.m .},
  archive      = {J_NEUCOM},
  author       = {Wei Chen and Yong Zhang},
  doi          = {10.1016/j.neucom.2024.128390},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128390},
  shortjournal = {Neurocomputing},
  title        = {A general method for mode decomposition on additive mixture: Generalized variational mode decomposition and its sequentialization},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consistent representation joint adaptive adjustment for
incremental zero-shot learning. <em>NEUCOM</em>, <em>606</em>, 128385.
(<a href="https://doi.org/10.1016/j.neucom.2024.128385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning aims to recognize objects from novel concepts through the model trained on seen class data and assisted by the semantic descriptions. Though it breaks the serious reliance on training data, it still fails to deal with the sequential streaming data in the open world. In this paper, we focus on the incremental zero-shot learning (IZSL) where the seen data arrives in the form of task sequence. In each incremental task, we only have access to the seen data of current task. The IZSL methods aim to depict the characteristics of current seen classes and avoid forgetting the previous ones, in the meantime, learn to generalize to the unseen classes. We summarize the challenges in IZSL as semantic drift which is further divided into task-recency bias and seen-class bias. To solve these issues, we propose a novel IZSL method termed as CRAA. Specifically, CRAA constructs consistent representations with satisfactory discrimination and generalization for all the seen and unseen classes. Based on these representations, CRAA learns a prototype classifier with a novel adaptive adjustment strategy to alleviate the task-recency bias and seen-class bias. Note that CRAA only needs a limited memory footprint to store the fixed scale model, and meets the demands of both memory restriction and data security in industry. We have conducted extensive experiments to evaluate our method on three widely used datasets. The results prove our method is superior to all the compared methods with significant improvements. Code is available at: https://github.com/changniu54/CRAA-Master .},
  archive      = {J_NEUCOM},
  author       = {Chang Niu and Junyuan Shang and Zhiheng Zhou and Junmei Yang},
  doi          = {10.1016/j.neucom.2024.128385},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128385},
  shortjournal = {Neurocomputing},
  title        = {Consistent representation joint adaptive adjustment for incremental zero-shot learning},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Granformer: A granular transformer net with linear
complexity. <em>NEUCOM</em>, <em>606</em>, 128380. (<a
href="https://doi.org/10.1016/j.neucom.2024.128380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, transformer models have demonstrated excellent performance across various intelligent applications owing to their ability to understand global context through self-attention mechanism. However, the extensively investigated multiplicative-based attention mechanism is inadequate for capturing relationship-based feature representations, as the dot product cannot depict the intricate semantic information between objects. Moreover, it has a great computational burden with a complexity of O ( n 2 ) O(n2) , due to the global feature representation capability achieved by calculating the relationship between each token within the entire feature sequence. To solve the current problem, this paper proposes a granular transformer framework with linear complexity, wherein diverse granulation functions can be employed to supersede the prevailing multiplicative relationships, and an innovative linearization methodology in the form of matrix factorization is designed to reduce the computational burden. Relying on the intricate semantics information embedded within granular structures, the capacity for feature extraction is significantly more comprehensive. Then, a novel matrix factorization methodology is developed for the linearity of granulation-based attention, accomplished by implementing separate deformable convolution sampling and using an approximate iterative algorithm based on cubic equations to calculate the Moore–Penrose inverse. The mathematical proof that our method is approximate with the complete granulation-based attention matrix is investigated in detail. Finally, the performance of Granformer, an innovative reconfiguration of plug-and-play transformer block, is evaluated on representative intelligent applications, including 3D point cloud classification, emotion recognition and sentiment analysis, and object detection. The experimental results suggest that our methodologies outperform the state-of-the-art models.},
  archive      = {J_NEUCOM},
  author       = {Kaili Wang and Xinwei Sun and Tao Shen},
  doi          = {10.1016/j.neucom.2024.128380},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128380},
  shortjournal = {Neurocomputing},
  title        = {Granformer: A granular transformer net with linear complexity},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Difficulty level-based knowledge distillation.
<em>NEUCOM</em>, <em>606</em>, 128375. (<a
href="https://doi.org/10.1016/j.neucom.2024.128375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) enables a simple model (student model) to perform as a complex model (teacher model) by distilling the knowledge from a pre-trained teacher model. Existing soft-label distillation methods often use a fixed temperature value in the softmax function to prevent overconfidence in the distillation process. However, this approach can lead to the suppression of important ‘dark knowledge’ for non-target classes in difficult samples, while also over-smoothing the confidence values for easier samples. To address this issue, we propose a novel approach called difficulty level-based knowledge distillation (DLKD), which considers the difficulty level of each sample to distill refined knowledge with high or low confidence, depending on the sample’s complexity. Our method calculates the difficulty level based on the Euclidean distance between the teacher model’s predictions and the pruned teacher model’s predictions. Experimental results demonstrate that our DLKD method outperforms state-of-the-art methods on challenging samples, including those with noisy labels or augmented data, achieving superior results on CIFAR-100, FGVR, and ImageNet datasets for image classification.},
  archive      = {J_NEUCOM},
  author       = {Gyeongdo Ham and Yucheol Cho and Jae-Hyeok Lee and Minchan Kang and Gyuwon Choi and Daeshik Kim},
  doi          = {10.1016/j.neucom.2024.128375},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128375},
  shortjournal = {Neurocomputing},
  title        = {Difficulty level-based knowledge distillation},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convergence and stability analysis of value iteration
q-learning under non-discounted cost for discrete-time optimal control.
<em>NEUCOM</em>, <em>606</em>, 128370. (<a
href="https://doi.org/10.1016/j.neucom.2024.128370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a theoretical analysis of the value iteration Q-learning with non-discounted costs. The analysis focuses on two main aspects: the convergence of the iterative Q-function and the stability of the system under the final iterative control policy. Unlike previous theoretical results on Q-learning, our analysis takes into account the effect of approximation errors, leading to a more comprehensive investigation. We first discuss the effect of approximation errors on the iterative Q-function update. Then, considering the presence of approximation errors in each iteration, we analyze the convergence of the iterative Q-function. Furthermore, we establish a sufficient condition, also accounting for the approximation errors, to ensure the stability of the system under the final iterative control policy. Finally, two simulation cases are conducted to validate the presented convergence and stability results.},
  archive      = {J_NEUCOM},
  author       = {Shijie Song and Mingming Zhao and Dawei Gong and Minglei Zhu},
  doi          = {10.1016/j.neucom.2024.128370},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128370},
  shortjournal = {Neurocomputing},
  title        = {Convergence and stability analysis of value iteration Q-learning under non-discounted cost for discrete-time optimal control},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time series features and fuzzy memberships combination for
time series classification. <em>NEUCOM</em>, <em>606</em>, 128368. (<a
href="https://doi.org/10.1016/j.neucom.2024.128368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series classification is an increasingly attractive field with the appearance of new problems in an expanding digitalized world. Most of the proposals in the state-of-the-art have focused just on improving the results’ performance, leaving interpretability on a secondary level. The available interpretable proposals do not provide competitive results, which is an issue to be addressed. This paper introduces a new fuzzy feature-based time series classification method, which joins the ability of time series features to capture essential information about the time series with Fuzzy logic. This proposal allows the fuzzy-based approach to incorporate global information about the behavior of time series in the membership calculation with the aim of improving the performance and interpretability of the results by using an interpretable classifier. The proposed method has been evaluated over the 112 state-of-the-art time series classification datasets from the UCR repository, and the results obtained show a better performance. Furthermore, the combination of time series features and fuzzy memberships has also increased the interpretability of final models.},
  archive      = {J_NEUCOM},
  author       = {Francisco J. Baldán and Luis Martínez},
  doi          = {10.1016/j.neucom.2024.128368},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128368},
  shortjournal = {Neurocomputing},
  title        = {Time series features and fuzzy memberships combination for time series classification},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discriminative hamiltonian variational autoencoder for
accurate tumor segmentation in data-scarce regimes. <em>NEUCOM</em>,
<em>606</em>, 128360. (<a
href="https://doi.org/10.1016/j.neucom.2024.128360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has gained significant attention in medical image segmentation. However, the limited availability of annotated training data presents a challenge to achieving accurate results. In efforts to overcome this challenge, data augmentation techniques have been proposed. However, the majority of these approaches primarily focus on image generation. For segmentation tasks, providing both images and their corresponding target masks is crucial, and the generation of diverse and realistic samples remains a complex task, especially when working with limited training datasets. To this end, we propose a new end-to-end hybrid architecture based on Hamiltonian Variational Autoencoders (HVAE) and a discriminative regularization to improve the quality of generated images. Our method provides an accurate estimation of the joint distribution of the images and masks, resulting in the generation of realistic medical images with reduced artifacts and off-distribution instances. As generating 3D volumes requires substantial time and memory, our architecture operates on a slice-by-slice basis to segment 3D volumes, capitalizing on the richly augmented dataset. Experiments conducted on two public datasets, BRATS (MRI modality) and HECKTOR (PET modality), demonstrate the efficacy of our proposed method on different medical imaging modalities with limited data.},
  archive      = {J_NEUCOM},
  author       = {Aghiles Kebaili and Jérôme Lapuyade-Lahorgue and Pierre Vera and Su Ruan},
  doi          = {10.1016/j.neucom.2024.128360},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128360},
  shortjournal = {Neurocomputing},
  title        = {Discriminative hamiltonian variational autoencoder for accurate tumor segmentation in data-scarce regimes},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SW-YOLOX: A YOLOX-based real-time pedestrian detector with
shift window-mixed attention mechanism. <em>NEUCOM</em>, <em>606</em>,
128357. (<a href="https://doi.org/10.1016/j.neucom.2024.128357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian detection is a critical research area in computer vision with practical applications. This paper addresses this key topic by providing a novel lightweight model named Shift Window-YOLOX (SW-YOLOX). The purpose of SW-YOLOX is to significantly enhance the robustness and real-time performance of pedestrian detection under practical application requirements. The proposed method incorporates a novel Shift Window-Mixed Attention Mechanism (SW-MAM), which combines spatial and channel attention for effective feature extraction. In addition, we introduce a novel up-sampling layer, PatchExpandingv2, to enhance spatial feature representation while maintaining computational efficiency. Furthermore, we propose a novel Shift Window-Path Aggregation Feature Pyramid Network (SW-PAFPN) to integrate with the YOLOX detector, further enhancing feature extraction and the robustness of pedestrian detection. Experimental results validated on challenging datasets such as CrowdHuman, MOT17Det, and MOT20Det demonstrate the competitive performance of the proposed SW-YOLOX compared to state-of-the-art methods and its pedestrian detection performance in crowded and complex scenes.},
  archive      = {J_NEUCOM},
  author       = {Chi-Yi Tsai and Run-Yu Wang and Yu-Chen Chiu},
  doi          = {10.1016/j.neucom.2024.128357},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128357},
  shortjournal = {Neurocomputing},
  title        = {SW-YOLOX: A YOLOX-based real-time pedestrian detector with shift window-mixed attention mechanism},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Billion-scale pre-trained knowledge graph model for
conversational chatbot. <em>NEUCOM</em>, <em>606</em>, 128353. (<a
href="https://doi.org/10.1016/j.neucom.2024.128353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational Chatbot is a critical technology for managing customer service on E-commerce platforms. However, most Chatbots struggle with data scarcity and sparsity. To tackle these issues, a novel two-step (pretrain and fine-tune) click-through-rate prediction model called knowledge-enhanced deep cross network (K-DCN) is proposed. First, a billion-scale conversation knowledge graph is constructed, inspired by real-world application scenarios. Then, the conversation knowledge graph is pretrained to capture the semantic and structure information respectively. Our K-DCN leverages novel user-state and dialogue-interaction representations from the pre-trained conversation knowledge graph, integrating them with the conventional dense and sparse feature representations within the Deep Cross Network framework. This integration is designed to perform item ranking in recommendation. From the experiments, our proposed K-DCN significantly outperforms the baseline models, and the model has been deployed in real world application.},
  archive      = {J_NEUCOM},
  author       = {Chi-Man Wong and Fan Feng and Wen Zhang and Huajun Chen and Chi-Man Vong and Chuangquan Chen},
  doi          = {10.1016/j.neucom.2024.128353},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128353},
  shortjournal = {Neurocomputing},
  title        = {Billion-scale pre-trained knowledge graph model for conversational chatbot},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adversarial example denoising and detection based on the
consistency between fourier-transformed layers. <em>NEUCOM</em>,
<em>606</em>, 128351. (<a
href="https://doi.org/10.1016/j.neucom.2024.128351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have achieved considerable success in a variety of tasks, and this success has led to an increase in the importance of the security and robustness of algorithms where DNNs are applied. In fact, previous studies have identified that neural networks are vulnerable to adversarial examples that are generated by adding a small amount of noise to the input images. Detection-based methods that can detect adversarial examples among input images are a popular defense technique against adversarial examples. However, these methods reject the detected adversarial images, making it difficult to use the input image for further analysis. In this study, we propose a novel denoising-based detection method that simultaneously denoises and detects an input image when defending against adversarial examples. Our method primarily analyzes images in the feature maps of the target classifier layers based on the consistency between the Fourier domains. We first generate adversarial examples and train the denoising network by minimizing the similarity between the non-adversarial and denoised adversarial images in the feature maps of the Fourier-transformed layers. The predicted denoised images are then input to the adversarial example detector, which determines whether the images are adversarial by exploring the characteristics of the concatenated input and denoised images. There are three main contributions in this paper: (1) We propose a novel denoising-based detection method that simultaneously denoises and detects an input image when defending against adversarial examples. (2) We improve the denoising method for adversarial examples that reconstructs adversarial examples based on the Fourier-transformed feature maps. (3) We improve the detection method by using denoised images in addition to the input images. We tested our proposed method against the fast gradient sign method, basic iterative method, projected gradient descent, Deepfool, and Carlini and Wagner adversarial attack algorithms on two Canadian Institute for Advanced Research (CIFAR) datasets, i.e., CIFAR-10 and CIFAR-100. Our method, which employed a frequency-based denoising mechanism in combination with a detection mechanism, demonstrated significant accuracy improvements in the denoising and detection performances when compared to other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Seunghwan Jung and Heeyeon kim and Minyoung Chung and Yeong-Gil Shin},
  doi          = {10.1016/j.neucom.2024.128351},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128351},
  shortjournal = {Neurocomputing},
  title        = {Adversarial example denoising and detection based on the consistency between fourier-transformed layers},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assistive systems for visually impaired people: A survey on
current requirements and advancements. <em>NEUCOM</em>, <em>606</em>,
128284. (<a href="https://doi.org/10.1016/j.neucom.2024.128284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this survey, we provide a comprehensive study on the assistive technological devices which help visually impaired persons in their day-to-day lives. With various forms of disabilities such as visual, auditory, mobility, or cognitive impairment affecting a significant number of people worldwide, the aim of this study is to enable the blind persons to achieve independence. The primary objective of this work is to provide a concise description of assistive technologies for the visually impaired, along with an exploration of approaches for object detection, text detection, and text-to-speech synthesis. We present detailed discussion on these approaches using both traditional as well as deep learning based techniques. Finally, we conclude with some open opportunities where further research can be carried out.},
  archive      = {J_NEUCOM},
  author       = {Preeti Kathiria and Sapan H. Mankad and Jitali Patel and Mayank Kapadia and Neel Lakdawala},
  doi          = {10.1016/j.neucom.2024.128284},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128284},
  shortjournal = {Neurocomputing},
  title        = {Assistive systems for visually impaired people: A survey on current requirements and advancements},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Investigating over-parameterized randomized graph networks.
<em>NEUCOM</em>, <em>606</em>, 128281. (<a
href="https://doi.org/10.1016/j.neucom.2024.128281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate neural models based on graph random features for classification tasks. First, we aim to understand when over parameterization, namely generating more features than the ones necessary to interpolate, may be beneficial for the generalization abilities of the resulting models. We employ two measures: one from the algorithmic stability framework and another one based on information theory. We provide empirical evidence from several commonly adopted graph datasets showing that the considered measures, even without considering task labels, can be effective for this purpose. Additionally, we investigate whether these measures can aid in the process of hyperparameters selection. The results of our empirical analysis show that the considered measures have good correlations with the estimated generalization performance of the models with different hyperparameter configurations. Moreover, they can be used to identify good hyperparameters, achieving results comparable to the ones obtained with a classic grid search.},
  archive      = {J_NEUCOM},
  author       = {Giovanni Donghi and Luca Pasa and Luca Oneto and Claudio Gallicchio and Alessio Micheli and Davide Anguita and Alessandro Sperduti and Nicolò Navarin},
  doi          = {10.1016/j.neucom.2024.128281},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128281},
  shortjournal = {Neurocomputing},
  title        = {Investigating over-parameterized randomized graph networks},
  volume       = {606},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GeoExplainer: Interpreting graph convolutional networks with
geometric masking. <em>NEUCOM</em>, <em>605</em>, 128393. (<a
href="https://doi.org/10.1016/j.neucom.2024.128393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For Graph Convolutional Network (GCN), the inherent geometric topology and relationships within spatio-temporal graphs are critical to factors affect its predictive performance. Understanding the decision-making process of GCN remains a challenging task. Existing perturbation-based explanation methods are primarily tailored for Graph Neural Network (GNN) models and focus on how the information of nodes or subgraphs in static graphs impacts GNN predictions. Due to the geometric properties of spatio-temporal graphs, screw theory serves as crucial mathematical tools for describing the geometric relationships and patterns of motion within the geometric space of spatio-temporal graphs. Therefore,we propose GeoExplainer, which utilizes screw theory to geometric masking for spatio-temporal graphs with strong geometric correlations, generating explanations for GCN. Our method perturbs spatio-temporal graphs using geometric masking, and ultimately generating explanations in the form of geometric masks serve as importance mappings for model prediction results. Firstly, we design a screw motion vector model with geometric constraints to describe the spatio-temporal graph in screw system. Then, we design a geometric screw perturbation to generate smooth geometric masks. Finally, we propose a geometric masking approach to optimize and update the geometric mixture mask. We utilize pointwise mutual information (PMI) to maximize the correlation between the model predictions after geometric perturbation and the original predictions, obtaining the optimal geometric mask as an explanation for GCN. The interpretable experiments of ST-GCN, HD-GCN, GCN and GIN models on four datasets with geometric relationships demonstrate that GeoExplainer outperforms eight competitive interpretation methods in quantitative and visualization analysis.},
  archive      = {J_NEUCOM},
  author       = {Rui Yu and Yanshan Li and Huajie Liang and Zhiyuan Chen},
  doi          = {10.1016/j.neucom.2024.128393},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128393},
  shortjournal = {Neurocomputing},
  title        = {GeoExplainer: Interpreting graph convolutional networks with geometric masking},
  volume       = {605},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differentiable homotopy methods for gradually reinforcing
the training of fully connected neural networks. <em>NEUCOM</em>,
<em>605</em>, 128374. (<a
href="https://doi.org/10.1016/j.neucom.2024.128374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep fully connected neural networks (FCNNs) are the workhorses of deep learning and are broadly applicable due to their “agnostic” structure. Generally, the learning capability of FCNNs improves with the increase in the number of layers and the width of each layer, which, however, comes at an increased computational cost in training. To alleviate this difficulty, in this paper, we develop a gradually reinforced differentiable homotopy (GRDH) method to train the FCNNs. Explicitly speaking, by introducing an extra variable t t ranging between zero and one, we design a series of auxiliary functions, which are continuous and monotonically increasing in t t . With the above functions, we formulate an optimization problem for training an artificial FCNN, which progressively incorporates more layers and nodes into the neural network as t t changes from one to zero and eventually becomes an FCNN with a target number of layers or width of nodes. We prove that the set of solutions to the artificial problem contains an everywhere differentiable path, which starts from a uniquely given point at t = 1 t=1 and ends at the weights and biases of the target FCNN as t t goes to zero. The proposed GRDH method is a novel method that incorporates the differentiable homotopy methods into the training of deep learning methods, and retains the satisfactory theoretical convergence property the classical homotopy methods possess. To promote the application of the GRDH method, we implement it and another efficient method called HTA to train the same FCNNs and find that the GRDH method outperforms the HTA both in the computational time and number of iterations for obtaining a solution with similar (even higher) accuracy. Numerical results further confirm the effectiveness of the GRDH method to solve classification problems.},
  archive      = {J_NEUCOM},
  author       = {Peixuan Li and Yuanbo Li},
  doi          = {10.1016/j.neucom.2024.128374},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128374},
  shortjournal = {Neurocomputing},
  title        = {Differentiable homotopy methods for gradually reinforcing the training of fully connected neural networks},
  volume       = {605},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Auto-weighted multi-view clustering via hierarchical
bipartite graph. <em>NEUCOM</em>, <em>605</em>, 128367. (<a
href="https://doi.org/10.1016/j.neucom.2024.128367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expensive time consumption and hyper-parameters are two main drawbacks of most existing multi-view graph clustering methods. Especially in large-scale data clustering, these two defects are more serious. Aiming at these two problems, we propose a novel auto-weighted multi-view clustering method based on the hierarchical bipartite graph to effectively address these two limitations. Similar to the idea of an anchor graph, firstly, the bisecting k-means method is used instead of traditional method to generate a hierarchical anchor points set. And then, the hierarchical bipartite graph can be constructed between the original points and the anchor points of last layer. Since we only consider the anchor points on the last layer rather than using a larger number of anchors to obtain the bipartite graph, our proposed method will greatly reduce the time consumption. Moreover, the automatic learning strategy was adopted to select the appropriate weights for each view in our proposed approach, which remove the weight-related hyper-parameters and effectively avoid the vexing problem of hyper-parameters in multi-view graph clustering. Finally, experiments were carried out on synthetic data and different sizes benchmark data respectively to verify the validity of our method.},
  archive      = {J_NEUCOM},
  author       = {Jie Zhou and Xinglong Luo and Feiping Nie and Xingshi He},
  doi          = {10.1016/j.neucom.2024.128367},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128367},
  shortjournal = {Neurocomputing},
  title        = {Auto-weighted multi-view clustering via hierarchical bipartite graph},
  volume       = {605},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). TaylorNet: A novel approach for spectral filter learning on
graph data. <em>NEUCOM</em>, <em>605</em>, 128358. (<a
href="https://doi.org/10.1016/j.neucom.2024.128358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are indispensable data structures used to model interconnected nodes and their relationships. However, devising filters for graph data is challenging. Previous approaches, including BernNet, utilized Bernstein polynomials to approximate spectral graph convolutions but suffered from lengthy training times compared to alternatives. To address this, we propose TaylorNet, a novel graph neural network built upon rigorous mathematical principles and theoretical foundations. TaylorNet provides an efficient approach for learning arbitrary graph spectral filters. Our methodology revolves around utilizing K K th order Taylor polynomials to estimate filters on the normalized Laplacian operator of graphs. By carefully setting the coefficients of these polynomials, we achieve effective filter design. Additionally, TaylorNet personalizes filter learning for specific graphs by leveraging observed graph data and signals to determine these coefficients. Extensive experimentation demonstrates TaylorNet’s ability to learn arbitrary spectral filters, surpassing current state-of-the-art methods, particularly for handling large graphs. Its exceptional performance extends to real-world graph modeling tasks, highlighting its versatility and applicability. For interested researchers, the complete implementation of TaylorNet is available at https://github.com/12chen20/TaylorNet .},
  archive      = {J_NEUCOM},
  author       = {Liwen Xu and Jiali Chen and Zhonghua Han and Yongxia Zhang},
  doi          = {10.1016/j.neucom.2024.128358},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128358},
  shortjournal = {Neurocomputing},
  title        = {TaylorNet: A novel approach for spectral filter learning on graph data},
  volume       = {605},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonlinear RISE based integral reinforcement learning
algorithms for perturbed bilateral teleoperators with variable time
delay. <em>NEUCOM</em>, <em>605</em>, 128355. (<a
href="https://doi.org/10.1016/j.neucom.2024.128355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of unknown Bilateral Teleoperators, the simultaneous satisfaction of not only synchronous control problem between two sides, but also optimal control performance under time-varying delays and external disturbance is a difficult task. Initially, in order to address this challenge, we proposed two control approaches including On-Policy and Off-Policy strategies after employing the sliding variable to reduce the order of dynamic model. Additionally, since the development of the unification between synchronous control problem and optimal control performance, it requires the consideration of discount factor addition to guarantee the bound of the infinite horizon cost function. In order to handle the dynamic uncertainties and the exponential cost function, by fully considering data collection technique in model-free On-Policy and Off-Policy strategies, Reinforcement Learning control schemes are proposed to guarantee the optimality effectiveness. Consequently, the Robust Integral of the Sign of the Error term is integrated into two proposed optimal control frames to improve the synchronous control performance and estimation capability of dynamic uncertainties. Moreover, the convergence of control policies and synchronous control problem of two proposed control frames are rigorously analyzed by Lyapunov stability theory. Finally, simulation results and the comparisons with the existing controller demonstrate the effectiveness of two proposed control frameworks.},
  archive      = {J_NEUCOM},
  author       = {Phuong Nam Dao and Van Quang Nguyen and Hoang Anh Nguyen Duc},
  doi          = {10.1016/j.neucom.2024.128355},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128355},
  shortjournal = {Neurocomputing},
  title        = {Nonlinear RISE based integral reinforcement learning algorithms for perturbed bilateral teleoperators with variable time delay},
  volume       = {605},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SRPM-ST: Sequential retraining and pseudo-labeling in
mini-batches for self-training. <em>NEUCOM</em>, <em>605</em>, 128343.
(<a href="https://doi.org/10.1016/j.neucom.2024.128343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An impediment to training accurate classifiers in supervised learning is the scarcity of labeled data. In that respect, semi-supervised learning could help by using both labeled and unlabeled data. A specific form of semi-supervised learning is self-training (ST). In its basic form, ST trains an initial classifier using the labeled data to generate pseudo-labels for the unlabeled set. At this point, either the whole set of pseudo-labeled data or a subset of them with some high confidence scores about the generated pseudo-labels is selected. The selected pseudo-labeled data are then used to update the initial classifier. Although this process can be repeated to generate new pseudo-labels for the unlabeled data, it is typically a tacit assumption up to this point that the classifier is updated once all pseudo-labels are generated—a process to which we refer as the full-batch ST (F-ST) regardless of any confidence score-based subset selection. Here, we show that sequential retraining and pseudo-labeling in mini-batches (SRPM) could potentially improve the performance of the classifier with respect to F-ST. Our empirical results show the existence of a data-dependent mini-batch size for SRPM that is optimal in terms of possessing the least error rate. In practice, this parameter could be treated as a hyperparameter to tune.},
  archive      = {J_NEUCOM},
  author       = {Azamat Mukhamediya and Amin Zollanvari},
  doi          = {10.1016/j.neucom.2024.128343},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128343},
  shortjournal = {Neurocomputing},
  title        = {SRPM-ST: Sequential retraining and pseudo-labeling in mini-batches for self-training},
  volume       = {605},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pseudo-ISP: Learning pseudo in-camera signal processing
pipeline from a color image denoiser. <em>NEUCOM</em>, <em>605</em>,
128316. (<a href="https://doi.org/10.1016/j.neucom.2024.128316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep denoisers usually ignore the problem of noise discrepancy between training and test images caused by the different noise modeling of sensor and in-camera signal processing (ISP) pipeline, which inevitably degrades the denoising performance. In this paper, we present an unpaired learning scheme to adapt the color image denoisers for handling test images with noise discrepancy. To this end, we consider a practical training setting equipped with a pre-trained color denoiser, a set of test noisy sRGB images, and an unpaired set of clean sRGB images. Then, we propose to alternate between two modules, i.e. , Pseudo-ISP training for learning noise modeling of sensor and in-camera signal processing (ISP) pipeline and denoiser adaption . Instead of modeling the complex noise in sRGB images, we assume the signal-dependent and spatially independent noise in rawRGB space, and specifically design the Pseudo-ISP to learn the pseudo ISP pipeline and pseudo rawRGB noise model jointly. Applying the learned Pseudo-ISP to the unpaired set of clean sRGB images, the corresponding realistic noisy sRGB observations can be easily obtained. Conversely, using the generated paired data for model fine-tuning, the color denoiser can be well adapted for test images. Through iterating between Pseudo-ISP training and denoiser adaption, denoising performance of deep denoisers can be further improved. Experiments show that our Pseudo-ISP not only can boost simple Gaussian blurring-based denoiser to achieve competitive performance against CBDNet, but also is effective in improving state-of-the-art deep denoisers, e.g., CBDNet and RIDNet.},
  archive      = {J_NEUCOM},
  author       = {Yue Cao and Xiaohe Wu and Shuran Qi and Xiao Liu and Zhongqin Wu and Wangmeng Zuo},
  doi          = {10.1016/j.neucom.2024.128316},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128316},
  shortjournal = {Neurocomputing},
  title        = {Pseudo-ISP: Learning pseudo in-camera signal processing pipeline from a color image denoiser},
  volume       = {605},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A bidirectional siamese recurrent neural network for
accurate gait recognition using body landmarks. <em>NEUCOM</em>,
<em>605</em>, 128313. (<a
href="https://doi.org/10.1016/j.neucom.2024.128313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition is a significant biometric technique for person identification, particularly in scenarios where other physiological biometrics are impractical or ineffective. In this paper, we address the challenges associated with gait recognition and present a novel approach to improve its accuracy and reliability. The proposed method leverages advanced techniques, including sequential gait landmarks obtained through the Mediapipe pose estimation model, Procrustes analysis for alignment, and a Siamese biGRU-dualStack Neural Network architecture for capturing temporal dependencies. Extensive experiments were conducted on large-scale cross-view datasets to demonstrate the effectiveness of the approach, achieving high recognition accuracy compared to other state-of-the-art models. The model demonstrated accuracies of 95.7%, 94.44%, 87.71%, and 86.6% on CASIA-B, SZU RGB-D, OU-MVLP, and Gait3D datasets respectively. The results highlight the potential applications of the proposed method in various practical domains, indicating its significant contribution to the field of gait recognition.},
  archive      = {J_NEUCOM},
  author       = {Proma Hossain Progga and Md. Jobayer Rahman and Swapnil Biswas and Md. Shakil Ahmed and Arif Reza Anwary and Swakkhar Shatabda},
  doi          = {10.1016/j.neucom.2024.128313},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128313},
  shortjournal = {Neurocomputing},
  title        = {A bidirectional siamese recurrent neural network for accurate gait recognition using body landmarks},
  volume       = {605},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SITU: Stochastic input encoding and weight update
thresholding for efficient memristive neural network in-situ training.
<em>NEUCOM</em>, <em>605</em>, 128275. (<a
href="https://doi.org/10.1016/j.neucom.2024.128275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Analog-to-Digital Converter (ADC) sensing and conductance update are the most power-demanding processes in the in-situ training of memristive neural networks. In this work, we propose a new thresholded weight update method in conjunction with stochastic input encoding to reduce the ADC sensing requirement and weight updates. This leads to better power and area efficiency for simple neural network models developed in situ on memristive crossbars. For performance analysis, we train three different neural network architectures, i.e. two Convolutional Neural Networks (CNNs) and one Recurrent Neural Network (RNN) on our in-situ training simulation platform with the MNIST, CIFAR-10, and Sentimental Analysis datasets, using a passive crossbar array. Results show that as the network complexity increases, the performance of the in-situ trained network with our proposed update rules decreases, due to the reduction in the number of updates at the beginning of the training process and the problem of deciding the learning rate without prior knowledge of the gradient of the loss function. Compared to a baseline network, the proposed adaptive thresholding saves 52.0% and 59.1% of weight updates on CNN and RNN, by sacrificing 0.17% and 5.81% of classification accuracy, respectively. Moreover, the stochastic input encoding saves inference power by 4.97% and 3.48% on CNN and RNN, while also slightly reducing the layout area by around 5 × 1 0 − 3 5×10−3 mm 2 mm2 and 1 0 − 3 mm 2 10−3mm2 , respectively.},
  archive      = {J_NEUCOM},
  author       = {Xuening Dong and Brian Chen and Roman Genov and Mostafa Rahimi Azghadi and Amirali Amirsoleimani},
  doi          = {10.1016/j.neucom.2024.128275},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128275},
  shortjournal = {Neurocomputing},
  title        = {SITU: Stochastic input encoding and weight update thresholding for efficient memristive neural network in-situ training},
  volume       = {605},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GRA-net: Group response attention for deep learning.
<em>NEUCOM</em>, <em>605</em>, 128272. (<a
href="https://doi.org/10.1016/j.neucom.2024.128272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Activation function, one of the most critical components in deep learning, enables the artificial neural networks to learn complex patterns through nonlinearity. Currently, element-wise activation functions such as ReLU are widely utilized because of their simplicity and efficiency. However, these methods do not consider the interactions among neurons, which may produce redundant features and affect performance. Inspired by neuroscience, we propose Group Response Attention (GRA). It establishes connections among neurons, which means that the state of each member is determined by the entire group. Accordingly, GRA makes the features more diverse and reduces redundancy. In addition, we propose a pure attention network without any conventional activation function, termed as GRA-Net. Experiments conducted on typical computer vision tasks show that GRA-Net achieves state-of-the-art results. For the ImageNet-1K classification task, GRA-Net-T achieves 82.9% Top-1 accuracy. With comparable parameters and FLOPs, its performance improves by 1.6% and 0.8% over Swin-T and ConvNeXt-T. On the COCO detection task, as the backbone of Mask R-CNN, GRA-Net-T outperforms Swin-T and ConvNeXt-T by 2.1% and 2.0% on box AP. Meanwhile, the mIoU of GRA-Net-T on the ADE20K semantic segmentation task is higher than Swin-T and ConvNeXt-T by 1.9% and 1.0%.},
  archive      = {J_NEUCOM},
  author       = {Zhenyuan Wang and Xuemei Xie and Xiaodan Song and Jianxiu Yang},
  doi          = {10.1016/j.neucom.2024.128272},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128272},
  shortjournal = {Neurocomputing},
  title        = {GRA-net: Group response attention for deep learning},
  volume       = {605},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Mitigating data imbalance and noise: A divergence-based
approach with enhanced sample selection. <em>NEUCOM</em>, <em>605</em>,
128269. (<a href="https://doi.org/10.1016/j.neucom.2024.128269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label noise and distribution imbalance are common challenges in real-world datasets. To address noisy labels, sample selection methods are typically used. These methods identify small-loss data as correctly labeled and utilize only these clean samples for updating parameters during training. However, our thorough analysis shows that in scenarios with a long-tailed distribution, methods based on small-loss tend to favor samples from dominant classes, leading to a significant drop in performance. To tackle this issue, we introduce a divergence-based separation mechanism coupled with prototype distance for clean sample identification across each class, effectively mitigating the adverse effects of distribution imbalance on sample selection. Furthermore, drawing on recent theoretical insights that highlight the benefits of pseudo-labels in managing class imbalances, we enhance our approach by integrating semi-supervised and contrastive learning techniques. Comprehensive tests conducted on two synthetic noisy long-tailed datasets and one real-world dataset demonstrate the efficacy of our method in dealing with label noise and long-tailed distributions.},
  archive      = {J_NEUCOM},
  author       = {Xuan Chen and Likai Wang and Wenlong Li and Yuchen Yang and Erkun Yang and Cheng Deng},
  doi          = {10.1016/j.neucom.2024.128269},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128269},
  shortjournal = {Neurocomputing},
  title        = {Mitigating data imbalance and noise: A divergence-based approach with enhanced sample selection},
  volume       = {605},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Scalable, explainable, adaptive information extraction from
structure-aware nearest neighbor. <em>NEUCOM</em>, <em>605</em>, 128261.
(<a href="https://doi.org/10.1016/j.neucom.2024.128261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information extraction (IE) is a crucial task in natural language processing, focusing on classifying and structuring informative elements from textual data. Despite significant performance improvements in recent years, existing methods face challenges in terms of scalability, adaptability, and explainability when applied in real-world scenarios. This paper presents a pioneering approach, namely the KNN-IE framework, tailored to address this challenge in key IE tasks. Diverging from conventional KNN methods primarily employed in classification tasks based on point-to-point similarity, our framework introduce an instance-to-instance similarity, called structural similarity, where each instance can contain multiple points as its elements. To provide supervision signals during training and enable better prediction explanations, we define a text-based measurement between two instances which is reasonable and can be calculated before trainingIn the training phase, we leverage structure-aware contrastive learning to help model learn structural similarity between different instances, especially those with the same type. During inference, schema-constraint bipartite matching between target text and retrieved instances enables KNN-IE to concurrently tackle the classification and structuring of informative elements, in a single round of retrieval process. Every time after finishing extraction, those retrieved structurally similar instances can work as well comprehensible evidences to help user understand why KNN-IE makes such predictions. Experimental evaluations across four prevalent IE tasks and ten diverse datasets demonstrate that KNN-IE can compete with state-of-the-art IE methods in fully supervised settings. Other results further underscore its superior scalability, adaptability, and explainability, affirming its potential for effective deployment in practical applications.},
  archive      = {J_NEUCOM},
  author       = {Shudong Lu and Si Li and Jun Guo},
  doi          = {10.1016/j.neucom.2024.128261},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128261},
  shortjournal = {Neurocomputing},
  title        = {Scalable, explainable, adaptive information extraction from structure-aware nearest neighbor},
  volume       = {605},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EMRIL: Ensemble method based on ReInforcement learning for
binary classification in imbalanced drifting data streams.
<em>NEUCOM</em>, <em>605</em>, 128259. (<a
href="https://doi.org/10.1016/j.neucom.2024.128259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The co-occurrence of evolving concepts and imbalanced data deteriorates the learning performance of classifiers in data streams. Recent studies do not account for data difficulty factors associated with class imbalance, i.e. imbalance complexity, complicating the imbalance learning under a drifting data environment. This paper proposes EMRIL, a novel batch-based ensemble method, to deal with this challenge. As part of EMRIL, Imbalance Complexity Redressing Component ( EMRIL ICRC EMRILICRC ), a data-level balancing module, resolves the imbalance complexity to increase minority class visibility for the base classifiers of the ensemble. Additionally, a novel ensemble pool management ( EMRIL EPM EMRILEPM ) technique is designed using Reinforcement Learning (RL). EMRIL EPM EMRILEPM regularly updates the ensemble pool and constructs an optimal base classifier subset for predictions through effective training and evaluation policies. Handling imbalance complexity, and RL-based ensemble pool management helps EMRIL to effectively perform the binary classification task in imbalanced and evolving data streams. A comprehensive experimental evaluation is conducted with 104 data streams which contain a variety of concept drifts and imbalance ratios categorized by various data difficulty factors. The results are compared with 15 state-of-the-art methods showing the superiority of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Muhammad Usman and Huanhuan Chen},
  doi          = {10.1016/j.neucom.2024.128259},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128259},
  shortjournal = {Neurocomputing},
  title        = {EMRIL: Ensemble method based on ReInforcement learning for binary classification in imbalanced drifting data streams},
  volume       = {605},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-task framework based on decomposition for multimodal
named entity recognition. <em>NEUCOM</em>, <em>604</em>, 128388. (<a
href="https://doi.org/10.1016/j.neucom.2024.128388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a text-image pair, Multimodal Named Entity Recognition (MNER) is the task of identifying and categorizing entities in the text. Most existing work performs named entity labeling directly using final token representations derived by fusing image and text representations. Although they achieve promising results, these work may fail to effectively exploit text and image modalities. This is because they neglect the difference in the role of the two modalities: text modality can detect the boundary of an entity, while image modality is introduced to disambiguate the category of the entity. Based on these findings, in this paper, we construct two auxiliary tasks based on the decomposition strategy and propose a multi-task framework for MNER. Specifically, we first decompose MNER into two auxiliary tasks: entity boundary detection task and entity category classification task. Here, the former treats only the text modality as input and outputs the boundary labels, since it can achieve satisfactory boundary results by itself. The latter uses two modalities to yield category labels where image modality is dedicated to disambiguating categories. These two auxiliary tasks allow the effective exploitation of text and image modalities and put them back into their respective roles. Then, we vectorize their results to improve entity recognition using label clues from auxiliary tasks. Finally, we fuse features from text and image modalities and label embeddings from auxiliary tasks to fulfill MNER. Experimental results on two widely used MNER datasets show that our framework can yield new SOTA performance.},
  archive      = {J_NEUCOM},
  author       = {Chenran Cai and Qianlong Wang and Bing Qin and Ruifeng Xu},
  doi          = {10.1016/j.neucom.2024.128388},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128388},
  shortjournal = {Neurocomputing},
  title        = {A multi-task framework based on decomposition for multimodal named entity recognition},
  volume       = {604},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A consistency-aware deep capsule network for hierarchical
multi-label image classification. <em>NEUCOM</em>, <em>604</em>, 128376.
(<a href="https://doi.org/10.1016/j.neucom.2024.128376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical classification is a significant challenge in computer vision due to the logical order and interconnectedness of multiple labels. This paper presents HD-CapsNet, a novel neural network architecture based on deep capsule networks, specifically designed for hierarchical multi-label classification(HMC). By incorporating a tree-like hierarchical structure, HD-CapsNet is designed to leverage the inherent ontological order within the hierarchical label tree, thereby ensuring classification consistency across different levels. Additionally, we introduce a specialized loss function that promotes accurate hierarchical relationships while penalizing inconsistencies. This not only enhances classification performance but also strengthens the network’s robustness. We rigorously evaluate HD-CapsNet’s efficacy by benchmarking it against existing HMC methods across six diverse datasets: Fashion-MNIST, Marine-Tree, CIFAR-10, CIFAR-100, Caltech-UCSD Birds-200-2011, and Stanford Cars. Our results conclusively demonstrate that HD-CapsNet excels in learning hierarchical relationships and significantly outperforms the competition in various image classification tasks. Our implementation is available at https://github.com/tasrif-khondaker/HD-CapsNet .},
  archive      = {J_NEUCOM},
  author       = {Khondaker Tasrif Noor and Antonio Robles-Kelly and Leo Yu Zhang and Mohamed Reda Bouadjenek and Wei Luo},
  doi          = {10.1016/j.neucom.2024.128376},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128376},
  shortjournal = {Neurocomputing},
  title        = {A consistency-aware deep capsule network for hierarchical multi-label image classification},
  volume       = {604},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward cross-subject and cross-session generalization in
EEG-based emotion recognition: Systematic review, taxonomy, and methods.
<em>NEUCOM</em>, <em>604</em>, 128354. (<a
href="https://doi.org/10.1016/j.neucom.2024.128354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A systematic review on machine-learning strategies for improving generalization in electroencephalography-based emotion classification was realized. In particular, cross-subject and cross-session generalization was focused. In this context, the non-stationarity of electroencephalographic (EEG) signals is a critical issue and can lead to the Dataset Shift problem. Several architectures and methods have been proposed to address this issue, mainly based on transfer learning methods. In this review, 449 papers were retrieved from the Scopus , IEEE Xplore and PubMed databases through a search query focusing on modern machine learning techniques for generalization in EEG-based emotion assessment. Among these papers, 79 were found eligible based on their relevance to the problem. Studies lacking a specific cross-subject or cross-session validation strategy, or making use of other biosignals as support were excluded. On the basis of the selected papers’ analysis, a taxonomy of the studies employing Machine Learning (ML) methods was proposed, together with a brief discussion of the different ML approaches involved. The studies reporting the best results in terms of average classification accuracy were identified, supporting that transfer learning methods seem to perform better than other approaches. A discussion is proposed on the impact of (i) the emotion theoretical models and (ii) psychological screening of the experimental sample on the classifier performances.},
  archive      = {J_NEUCOM},
  author       = {Andrea Apicella and Pasquale Arpaia and Giovanni D’Errico and Davide Marocco and Giovanna Mastrati and Nicola Moccaldi and Roberto Prevete},
  doi          = {10.1016/j.neucom.2024.128354},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128354},
  shortjournal = {Neurocomputing},
  title        = {Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods},
  volume       = {604},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human pose estimation based on frequency domain and
attention module. <em>NEUCOM</em>, <em>604</em>, 128318. (<a
href="https://doi.org/10.1016/j.neucom.2024.128318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming to address the problems of high computing costs and limited local receptive fields in existing human pose estimation methods, this study proposes a novel framework for human pose estimation called ”Frequency Domain and Attention Pose Estimation” (FDAPose). By integrating high-resolution features, Fast Fourier Transform (FFT), and attention modules, FDAPose offers a new approach to human pose estimation. This framework improves the accuracy of human pose estimation while reducing computational costs. We introduce the Depthwise ECA Block (DEBlock) and the Residual ECA Block (REBlock) into our backbone network. These modules effectively reduce the number of model parameters and preserve the high-fidelity feature extraction necessary for accurately capturing the spatial relationships and details in human body postures. Additionally, the introduction of the Global Context Coordinate Attention(GCCA) module enhances the model’s utilization of contextual information, especially when dealing with occluded and complex backgrounds. Our unique contribution is the integration of spatial features extracted at various stages with the frequency domain information, facilitated by the FFT technique. This approach enhances the model’s ability to capture long-distance dependencies within the image, leading to improved accuracy in pose estimation. The model achieves an average precision of 78.0% and 89.6% on the COCO 2017 and MPII datasets, respectively. This study not only improves the accuracy of human pose estimation but also introduces new research avenues to the field by integrating frequency domain and spatial domain information.},
  archive      = {J_NEUCOM},
  author       = {Shuren Zhou and Xinlan Duan and Jiarui Zhou},
  doi          = {10.1016/j.neucom.2024.128318},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128318},
  shortjournal = {Neurocomputing},
  title        = {Human pose estimation based on frequency domain and attention module},
  volume       = {604},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Preventing harm to the rare in combating the malicious: A
filtering-and-voting framework with adaptive aggregation in federated
learning. <em>NEUCOM</em>, <em>604</em>, 128317. (<a
href="https://doi.org/10.1016/j.neucom.2024.128317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributed nature of Federated Learning (FL) introduces security vulnerabilities and issues related to the heterogeneous distribution of data. Traditional FL aggregation algorithms often mitigate security risks by excluding outliers, which compromises the diversity of shared information. In this paper, we introduce a novel filtering-and-voting framework that adeptly navigates the challenges posed by non-iid training data and malicious attacks on FL. The proposed framework integrates a filtering layer for defensive measures against the intrusion of malicious models and a voting layer to harness valuable contributions from diverse participants. Moreover, by employing Deep Reinforcement Learning (DRL) for dynamic aggregation weight adjustment, we ensure the optimized aggregation of participant data, enhancing the diversity of information used for aggregation and improving the performance of the global model. Experimental results demonstrate that the proposed framework presents superior accuracy over traditional and contemporary FL aggregation methods as diverse models are utilized. It also shows robust resistance against malicious poisoning attacks.},
  archive      = {J_NEUCOM},
  author       = {Yanna Jiang and Baihe Ma and Xu Wang and Guangsheng Yu and Caijun Sun and Wei Ni and Ren Ping Liu},
  doi          = {10.1016/j.neucom.2024.128317},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128317},
  shortjournal = {Neurocomputing},
  title        = {Preventing harm to the rare in combating the malicious: A filtering-and-voting framework with adaptive aggregation in federated learning},
  volume       = {604},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An radicals construction technique based on dual quaternions
and hierarchical transformers. <em>NEUCOM</em>, <em>604</em>, 128315.
(<a href="https://doi.org/10.1016/j.neucom.2024.128315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, the exploration of Knowledge Graph Embedding (KGE) mainly focuses on static KGE models. Due to the diversity and complexity of vertical domain data, it is difficult for existing KGE models to achieve excellent performance. Specific KGE models must be constructed for research on vertical domain knowledge graphs. This paper explores the relationships between the composition of Chinese characters and their sounds, meanings, and forms by constructing the Chinese Radical Knowledge Graph (CRKG). CRKG was constructed from a unique perspective according to the characteristics of Chinese radicals and knowledge graphs. The minor components of Chinese characters are separated and constructed into the fourth dimension of the knowledge graph. In this paper, we propose a new Chinese Radical Knowledge Graph Embedding (CRKGE) model, RotAL RotAL , which introduces dual quaternions and hierarchical transformers into KGE. RotAL performs a translation-rotation operation on the head entity with the relation as a parameter, then does a translation operation on the head entity with the minor component as a parameter to be close to the tail entity. Finally, we feed the trained quaternions into hierarchical transformers to jointly learn entity-related composition and relational contextualization based on a head entity’s neighborhood. We demonstrate that our method can model and infer various relational patterns of CRKG, such as symmetric/antisymmetric, reflexive, inversion, and multiple. The experimental results on four CRKG datasets demonstrate that the RotAL model achieves the highest Hit@1 score, outperforming existing KGE models in accurately identifying the target entity on the first attempt. Furthermore, the RotAL model consistently achieves superior performance across other evaluation metrics, substantiating its significant advantage over existing models.},
  archive      = {J_NEUCOM},
  author       = {Sensen Zhang and Xun Liang},
  doi          = {10.1016/j.neucom.2024.128315},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128315},
  shortjournal = {Neurocomputing},
  title        = {An radicals construction technique based on dual quaternions and hierarchical transformers},
  volume       = {604},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A debiased self-training framework with graph
self-supervised pre-training aided for semi-supervised rumor detection.
<em>NEUCOM</em>, <em>604</em>, 128314. (<a
href="https://doi.org/10.1016/j.neucom.2024.128314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing rumor detection models have achieved remarkable performance in fully-supervised settings. However, it is time-consuming and labor-intensive to obtain extensive labeled rumor data. To mitigate the reliance on labeled data, semi-supervised learning (SSL), jointly learning from labeled and unlabeled samples, achieves significant performance improvements at low costs. Commonly used self-training methods in SSL, despite their simplicity and efficiency, suffer from the notorious confirmation bias, which can be seen as the accumulation of noise arising from utilization of incorrect pseudo-labels. To deal with the problem, in this study, we propose a debiased self-training framework with graph self-supervised pre-training for semi-supervised rumor detection. First, to enhance the initial model for self-training and reduce the generation of incorrect pseudo-labels in early stages, we leverage the rumor propagation structures of massive unlabeled data for graph self-supervised pre-training. Second, we improve the quality of pseudo-labels by proposing a pseudo-labeling strategy with self-adaptive thresholds, which consists of self-paced global thresholds controlling the overall utilization process of pseudo-labels and local class-specific thresholds attending to the learning status of each class. Extensive experiments on four public benchmarks demonstrate that our method significantly outperforms previous rumor detection baselines in semi-supervised settings, especially when labeled samples are extremely scarce. Notably, we have achieved 96.3% accuracy on Weibo with 500 labels per class and 86.0% accuracy with just 5 labels per class.},
  archive      = {J_NEUCOM},
  author       = {Yuhan Qiao and Chaoqun Cui and Yiying Wang and Caiyan Jia},
  doi          = {10.1016/j.neucom.2024.128314},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128314},
  shortjournal = {Neurocomputing},
  title        = {A debiased self-training framework with graph self-supervised pre-training aided for semi-supervised rumor detection},
  volume       = {604},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Partial label learning via weighted centroid clustering
disambiguation. <em>NEUCOM</em>, <em>604</em>, 128312. (<a
href="https://doi.org/10.1016/j.neucom.2024.128312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial Label Learning (PLL) is a weakly supervised learning problem that induces a multi-class classifier from data with candidate labels, among which only one is the ground-truth label. The crucial challenge in PLL is to disambiguate the false-positive labels from the candidate labels. However, most existing PLL methods fail to simultaneously consider both the instance-level similarity and the class-level information during label disambiguation. In this paper, we propose a novel two-stage method based on weighted centroid clustering, which efficiently utilizes both the local similarity among instances and the per-class global information. In the first stage, we initialize the center of each class using label propagation based on the instance-level similarity, and obtain the disambiguated instances via weighted centroid clustering derived from the per-class global information. In the second stage, the disambiguated instances are used to train a multi-class classifier. Extensive experiments on both controlled UCI datasets and real-world datasets show the superiority of the proposed method in classification accuracy.},
  archive      = {J_NEUCOM},
  author       = {Yuhang Tian and Xin Niu and Jing Chai},
  doi          = {10.1016/j.neucom.2024.128312},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128312},
  shortjournal = {Neurocomputing},
  title        = {Partial label learning via weighted centroid clustering disambiguation},
  volume       = {604},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decentralized adaptive temporal-difference learning over
time-varying networks and its finite-time analysis. <em>NEUCOM</em>,
<em>604</em>, 128311. (<a
href="https://doi.org/10.1016/j.neucom.2024.128311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In reinforcement learning, centralized temporal-difference (TD) learning is commonly used to solve the policy evaluation problem. However, the decentralized adaptive variant of the TD learning algorithm has rarely been investigated in multi-agent reinforcement learning. To fill this gap, based on linear function approximation, we propose a decentralized adaptive TD learning algorithm over time-varying networks, referred to as D-AdaTD . We rigorously analyze the convergence performance of D-AdaTD , i.e., the explicit finite-time analysis is established under different step-sizes. Specifically, under constant step-sizes, the average estimated value function can converge to a neighborhood of the optimal value at rate O ( 1 / ( k + 1 ) ) O(1/(k+1)) and the estimated parameter of each agent can converge to a neighborhood of the optimal parameter at rate O ( ξ k ) O(ξk) , where k k is the number of iterations and ξ ∈ ( 0 , 1 ) ξ∈(0,1) . Under diminishing step-sizes, the average estimated value function can converge to the optimal value and the average estimated parameter can converge to the optimal parameter at rate O ( ( 1 + log ( k + 1 ) ) / k ) O((1+log(k+1))/k) and O ( ( 1 + log ( k + 1 ) ) / ( k + 1 ) ) O((1+log(k+1))/(k+1)) , respectively. In addition, we evaluate the performance of D-AdaTD via simulation experiments, which are commonly insufficient in the existing decentralized temporal-difference learning. The experimental results also validate the effectiveness of D-AdaTD .},
  archive      = {J_NEUCOM},
  author       = {Ping Xie and Xin Wang and Shan Yao and Muhua Liu and Xuhui Zhao and Ruijuan Zheng},
  doi          = {10.1016/j.neucom.2024.128311},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128311},
  shortjournal = {Neurocomputing},
  title        = {Decentralized adaptive temporal-difference learning over time-varying networks and its finite-time analysis},
  volume       = {604},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptable fuzzy reinforcement learning method for
non-stationary environments. <em>NEUCOM</em>, <em>604</em>, 128309. (<a
href="https://doi.org/10.1016/j.neucom.2024.128309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How do we know when a reinforcement learning policy needs to adapt? In non-stationary environments, agents must adapt and learn in environments that change dynamically. We propose a finite-horizon model-free solution using a hierarchical learning structure with fuzzy systems. The higher-level learning policy advises the lower-level policy when to start and stop learning based on the temporal differences calculated within the lower-level. Major differences in the temporal difference of each action produced by an agent may indicate environment change. This structure is tested with multi-agent differential games in both the cooperative and competitive aspect. Results show that this method is quick to notice and adapt the policy within relatively few learning episodes.},
  archive      = {J_NEUCOM},
  author       = {Rachel Haighton and Amirhossein Asgharnia and Howard Schwartz and Sidney Givigi},
  doi          = {10.1016/j.neucom.2024.128309},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128309},
  shortjournal = {Neurocomputing},
  title        = {An adaptable fuzzy reinforcement learning method for non-stationary environments},
  volume       = {604},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring heterophily in calibration of graph neural
networks. <em>NEUCOM</em>, <em>604</em>, 128294. (<a
href="https://doi.org/10.1016/j.neucom.2024.128294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With growing applications in safety-critical domains such as autonomous vehicles and healthcare systems, graph neural networks (GNNs) are expected to provide predictions that are not only accurate but also reliable. Confidence calibration is a crucial task closely related to improve the reliability of machine learning models. Current GNN calibration methods primarily address challenges arising from the non-Euclidean topology structure of graph data and a general trend of under-confidence. However, our empirical studies have shown that these methods struggle with local miscalibrations when community homophily differs from the global trend, such as high-homophily nodes in heterophilous graphs. To tackle this issue, we introduce Adaptive Spectral Temperature Scaling (ASTS), a novel spectral-based calibration method tailored for graphs with varying levels of homophily. On top of the node-wise temperature scaling framework, ASTS incorporates two components: (1) dual-channel graph filters that adaptively integrate similar and dissimilar information from neighborhood, (2) an innovative adaptive edge dropout module that alleviates issues induced by low-degree nodes. These designs ensure that ASTS is local structure-aware, global trend-aware and well-adapted to different graph structures. Our extensive empirical studies confirm ASTS’s superior calibration performance over existing methods across graphs of diverse homophily ratios.},
  archive      = {J_NEUCOM},
  author       = {Xiaotian Xie and Biao Luo and Yingjie Li and Chunhua Yang and Weihua Gui},
  doi          = {10.1016/j.neucom.2024.128294},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128294},
  shortjournal = {Neurocomputing},
  title        = {Exploring heterophily in calibration of graph neural networks},
  volume       = {604},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A stochastic primal–dual algorithm for composite constrained
optimization. <em>NEUCOM</em>, <em>604</em>, 128285. (<a
href="https://doi.org/10.1016/j.neucom.2024.128285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the decentralized stochastic optimization problem over an undirected network, where each agent owns its local private functions made up of two non-smooth functions and an expectation-valued function. A decentralized stochastic primal–dual algorithm is proposed, by combining the variance-reduced method and the stochastic approximation method. The local gradients are estimated by using the mean of a variable number of sample gradients and the stochastic error decreases with the number of samples in the stochastic approximation process. The highlight of this paper is the extension of the primal–dual algorithm to the stochastic optimization problems. The effectiveness of the proposed algorithm and the correctness of the theory are verified by numerical experiments.},
  archive      = {J_NEUCOM},
  author       = {Enbing Su and Zhihuan Hu and Wei Xie and Li Li and Weidong Zhang},
  doi          = {10.1016/j.neucom.2024.128285},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128285},
  shortjournal = {Neurocomputing},
  title        = {A stochastic primal–dual algorithm for composite constrained optimization},
  volume       = {604},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Exponential synchronization of stochastic coupled neural
networks with stochastic delayed impulsive effect. <em>NEUCOM</em>,
<em>604</em>, 128262. (<a
href="https://doi.org/10.1016/j.neucom.2024.128262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the synchronization of stochastic coupled neural networks (SCNNs) with stochastic delayed impulses, which are more realistic and complex than the deterministic ones. Unlike previous works, we incorporate two distinct types of stochastic factors into the model: random noise affecting the systems continuous dynamics, and stochastic impulsive intensity applied at discrete impulsive instances. We extend the differential inequality with stochastic delayed impulses to stochastic systems without requiring that impulsive delay to be smaller than impulsive interval. We also model the impulsive intensity as a discrete-time Markov chain. By using the generalized inequality, graph theory, and stochastic analysis techniques, we derive a synchronization criterion for SCNNs with stochastic delayed impulses. We present numerical examples to demonstrate the effectiveness of our results.},
  archive      = {J_NEUCOM},
  author       = {Lvqin Wang and Lulu Li and Qian Cui and Zhen Wang},
  doi          = {10.1016/j.neucom.2024.128262},
  journal      = {Neurocomputing},
  month        = {11},
  pages        = {128262},
  shortjournal = {Neurocomputing},
  title        = {Exponential synchronization of stochastic coupled neural networks with stochastic delayed impulsive effect},
  volume       = {604},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CAISFormer: Channel-wise attention transformer for image
steganography. <em>NEUCOM</em>, <em>603</em>, 128295. (<a
href="https://doi.org/10.1016/j.neucom.2024.128295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current Transformer-based image steganography cannot embed data properly without considering the correlation of the cover image and the secret image. In addition, to save computational complexity, spatial-wise Transformer is often used to apply in small spatial windows, which limits the extraction of the global feature. To solve those limitations, we present a channel-wise attention Transformer model for image steganography (CAISFormer), which aims to construct long-range dependencies for identifying inconspicuous positions to embed data. A channel self-attention module (CSAM) is deployed to focus the feature channels suitable for data hiding by establishing channel relationships. Meanwhile, a non-linear enhancement (NLE) layer is employed to enhance the beneficial features while weaken the irrelevant ones. For building feature coupling between the cover image and the secret image, a channel-wise cross attention module (CCAM) is designed to fine-tune cover image features by capturing their cross-dependencies. In addition, for concealing data properly, a global–local aggregation module (GLAM) is deployed to adjust fused features by combining global and local attention, which can focus on inconspicuous and texture regions, respectively. The experimental results demonstrate that CAISFormer obtains PSNR gains of more than 0.36 dB and 0.90 dB for the cover/stego image pair and the secret/recovery image pair, respectively, and the detection ratio is decreased by 3.43%, in single image hiding compared to the state-of-the-art. Moreover, the generalization ability is also proved across a variety of datasets. The code will be made publicly available at https://github.com/YuhangZhouCJY/CAISFormer .},
  archive      = {J_NEUCOM},
  author       = {Yuhang Zhou and Ting Luo and Zhouyan He and Gangyi Jiang and Haiyong Xu and Chin-Chen Chang},
  doi          = {10.1016/j.neucom.2024.128295},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128295},
  shortjournal = {Neurocomputing},
  title        = {CAISFormer: Channel-wise attention transformer for image steganography},
  volume       = {603},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Specific event detection for video surveillance using
variational bayesian inference. <em>NEUCOM</em>, <em>603</em>, 128291.
(<a href="https://doi.org/10.1016/j.neucom.2024.128291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although in recent years there has been a trend to incorporate data-driven models to automate the task of video surveillance, there remains a shortage of learning-based solutions for the detection of specific events that do not require examples of such events during training. Current research largely focuses on abnormal event detection, a learning-based approach that allows for the detection of events as anomalies. Unfortunately, such an approach does not provide any details about the types of events detected as the training data only includes normal events. This paper proposes an approach to detect specific events in surveillance videos under an anomaly detection framework by constraining the input space of the detection model, and hence, allowing to determine the type of event detected as an anomaly. Specifically, the proposed approach exploits the benefits of variational Bayesian inference to build probabilistic models for the detection of specific events as anomalies. Such a novel strategy leverages the benefits of the learning mechanism used by abnormal event detection frameworks to detect specific events. The proposed approach achieves a very competitive performance for the detection of several events within the context of video surveillance in public transport stations. It outperforms the state-of-the-art for the detection of pieces of abandoned luggage.},
  archive      = {J_NEUCOM},
  author       = {Roberto Leyva and Victor Sanchez and Chang-Tsun Li and Carsten Maple},
  doi          = {10.1016/j.neucom.2024.128291},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128291},
  shortjournal = {Neurocomputing},
  title        = {Specific event detection for video surveillance using variational bayesian inference},
  volume       = {603},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-task prompt tuning with soft context sharing for
vision–language models. <em>NEUCOM</em>, <em>603</em>, 128290. (<a
href="https://doi.org/10.1016/j.neucom.2024.128290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision–language models have recently shown great potential on many tasks in computer vision. Meanwhile, prior work demonstrates prompt tuning designed for vision–language models could acquire superior performance on few-shot image recognition compared to linear probe, a strong baseline. In practice, many few-shot tasks are inherently correlated, particularly within specialized domains. However, such information is overlooked previously. Inspired by the fact that modeling task relationship by multi-task learning can usually boost performance, we propose a novel method SoftCPT (Soft Context Sharing for Prompt Tuning) to tune pre-trained vision–language models on multiple target few-shot tasks jointly. Specifically, we design a task-shared meta network to generate prompt context for each task using task name together with a learnable task context as input. The parameters of this meta network as well as the task context are tuned on the joint training set of all tasks. As such, the prompt context of all tasks will be shared in a soft manner. Extensive experiments across four multi-task few-shot datasets covering 44 tasks and 1593 categories demonstrate that SoftCPT significantly outperforms single-task prompt tuning methods, highlighting the effectiveness of multi-task learning for vision–language prompt tuning.},
  archive      = {J_NEUCOM},
  author       = {Kun Ding and Ying Wang and Pengzhang Liu and Qiang Yu and Haojian Zhang and Shiming Xiang and Chunhong Pan},
  doi          = {10.1016/j.neucom.2024.128290},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128290},
  shortjournal = {Neurocomputing},
  title        = {Multi-task prompt tuning with soft context sharing for vision–language models},
  volume       = {603},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of recent advances in spatially resolved
transcriptomics data analysis. <em>NEUCOM</em>, <em>603</em>, 128283.
(<a href="https://doi.org/10.1016/j.neucom.2024.128283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing significance of spatial organization and our understanding of molecular characteristics have greatly contributed to technological advancements in spatially resolved transcriptomics (SRT). Its development provides a new perspective to explore the spatial specificity of gene expression, which assists in revealing the interactions between tissues and cells, along with abnormal gene expression patterns in disease development, further enhancing our comprehension of gene regulation mechanisms in organisms. The main purpose of this review is to introduce some of the latest developments in the analysis and development of spatial transcriptomics data, and emphasize their current research approaches in spatial clustering, spatial trajectory inference, identification of spatially variable genes, cell–cell/gene–gene interaction, batch effect correction and gene expression denoising.},
  archive      = {J_NEUCOM},
  author       = {Yue Gao and Ying-Lian Gao and Jing Jing and Feng Li and Chun-Hou Zheng and Jin-Xing Liu},
  doi          = {10.1016/j.neucom.2024.128283},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128283},
  shortjournal = {Neurocomputing},
  title        = {A review of recent advances in spatially resolved transcriptomics data analysis},
  volume       = {603},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey for automatic text summarization:
Techniques, approaches and perspectives. <em>NEUCOM</em>, <em>603</em>,
128280. (<a href="https://doi.org/10.1016/j.neucom.2024.128280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The enormous quantity of text makes it challenging for users to obtain the key information and knowledge. Automatic text summarization can alleviate this problem by providing reliable summaries for massive text documents. During the last decade, significant achievements have been made in text summarization. We conduct this survey to explore what research community is focused on, the application scenarios of summarization, the state-of-the-art techniques and methods, and to analyze the challenges and future direction. We summarize that incorporating with natural language processing, previous text summarization research applied knowledge-based methods, graph-based methods, statistical learning methods, and deep learning methods. Applying large language model to text summarization is still in its early stages. By analyzing current research progress, we conclude that understand semantic information and specific domain knowledge is required for text summarization, and the conciseness and readability of the summary should be ensured. The future research opportunity is automatic knowledge summarization, and more research effort is urgently needed to explore.},
  archive      = {J_NEUCOM},
  author       = {Mengqi Luo and Bowen Xue and Ben Niu},
  doi          = {10.1016/j.neucom.2024.128280},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128280},
  shortjournal = {Neurocomputing},
  title        = {A comprehensive survey for automatic text summarization: Techniques, approaches and perspectives},
  volume       = {603},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MixRGBX: Universal multi-modal tracking with symmetric mixed
attention. <em>NEUCOM</em>, <em>603</em>, 128274. (<a
href="https://doi.org/10.1016/j.neucom.2024.128274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-modal tracker realizes robust tracking by complementing the unique information between modalities. However, there is still a serious data deficiency problem in multi-modal tracking, which leads to inadequate learning of fusion modules designed for specific modality. In this research, we introduce MixRGBX, a universal multi-modal tracking framework with RGB as the primary modality. MixRGBX leverages the flexibility of attention operations, introducing a symmetric complementary fusion module to unify feature extraction and deep fusion processes between different modalities. The symmetric complementary fusion module progressively introduce fused features into the backbone of the RGB tracker, allowing MixRGBX to deeply incorporate auxiliary information to enhance target information in the original RGB features. Additionally, a target position search module is employed for target localization based on the enhanced RGB features. Therefore, MixRGBX only relies on a small amount of multi-modal data for model fine-tuning to achieve robust multi-modal tracking. Extensive experiments on five benchmark datasets validate the effectiveness of the proposed MixRGBX.},
  archive      = {J_NEUCOM},
  author       = {Meng Sun and Xiaotao Liu and Hongyu Wang and Jing Liu},
  doi          = {10.1016/j.neucom.2024.128274},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128274},
  shortjournal = {Neurocomputing},
  title        = {MixRGBX: Universal multi-modal tracking with symmetric mixed attention},
  volume       = {603},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal summarization with modality features alignment
and features filtering. <em>NEUCOM</em>, <em>603</em>, 128270. (<a
href="https://doi.org/10.1016/j.neucom.2024.128270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous studies about M ulti M odal S ummarization (MMS) mainly focus on effective selection and filtering of visual features to assist in cross-modal fusion and text-based generation. However, there exists a natural disparity between the distributions of features from different modalities which limits a more comprehensive cross-modal fusion for MMS models. In this paper, we propose to utilize M aximum M ean D iscrepancy (MMD) to align the features from two modalities, design a filter to further denoise the visual features, and conduct cross-modal fusion based on generative pre-trained language models for better cross-modal fusion and text generation. Moreover, we notice the presence of some special tokens in the MMS dataset which are introduced in prior data preprocessing. This phenomenon could limit the performance of contemporary generative models. Thus we adopt the powerful L arge L anguage M odel (LLM) to preprocess the dataset to enhance MMS models. Experimental results on the original MMS dataset demonstrate that our proposed method is effective and outperforms previous strong baselines. Experimental results on the preprocessed MMS dataset also demonstrate the feasibility of incorporating LLM in the data preprocessing to enhance MMS models.},
  archive      = {J_NEUCOM},
  author       = {Binghao Tang and Boda Lin and Zheng Chang and Si Li},
  doi          = {10.1016/j.neucom.2024.128270},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128270},
  shortjournal = {Neurocomputing},
  title        = {Multimodal summarization with modality features alignment and features filtering},
  volume       = {603},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view clustering with semantic fusion and contrastive
learning. <em>NEUCOM</em>, <em>603</em>, 128264. (<a
href="https://doi.org/10.1016/j.neucom.2024.128264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view data obtained from different sources provides a comprehensive way to model the real world. As one of the fundamental analyses, clustering for multi-view data has attracted increasing attention from researchers in different fields. Although existing multi-view clustering methods have achieved promising results, how to fully utilize the consensus and differences among different views and how to integrate their features to learn a unified representation is still challenging. To overcome the limitations, we put forward a Semantic fusion and Contrastive learning model for Multi-View Clustering (SCMVC) in this paper. SCMVC employs the view-specific encoders to extract embeddings from each view, and reconstructs the topological and attribute information by using the corresponding decoders. Simultaneously, a cross-view contrastive learning module is introduced in SCMVC to assimilate the consensus information across different views. In addition, to distinguish the differences in semantic information across different views, we incorporate an attention mechanism to determine the relative importance of each view in the semantic information fusion. The proposed model is jointly optimized by training and clustering to mutually reinforce each other, gradually improving its performance and robustness. Experiments on three real-world multi-view datasets demonstrate the effectiveness of our SCMVC framework. Source codes are freely available at https://github.com/HexonBang/SCMVC .},
  archive      = {J_NEUCOM},
  author       = {Hui Yu and Hui-Xiang Bian and Zi-Ling Chong and Zun Liu and Jian-Yu Shi},
  doi          = {10.1016/j.neucom.2024.128264},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128264},
  shortjournal = {Neurocomputing},
  title        = {Multi-view clustering with semantic fusion and contrastive learning},
  volume       = {603},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linguistic steganalysis via multi-task with crossing
generative-natural domain. <em>NEUCOM</em>, <em>603</em>, 128260. (<a
href="https://doi.org/10.1016/j.neucom.2024.128260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real world, the sources of text often transcend the boundaries of generative and natural domains, which introduces challenges for existing linguistic steganalysis methods. The typical problem arises from the sample selection bias caused by training solely on a single-source domain, rendering the model incapable of inferencing across the entire generative-natural (GN) space. Moreover, there exists the problem of overlooking the sensitive discrepancies between generative text and natural text, which hampers model fitting. In this paper, we model steganalysis in a brand-new perspective by employing multi-task learning to build the main task and auxiliary tasks in the cross GN domain. The proposed Cross Generative-Natural Domain Multi-task Model (CG-NDMM) can concurrently address the two aforementioned issues through i) modeling steganalysis across the entire GN space, incorporating two auxiliary tasks alongside a main task, and ii) utilizing a feature representation transfer learning strategy to harmonize two sub-networks. Furthermore, we employ diverse steganography algorithms to construct the datasets, which comprise four types of texts (generative-cover, generative-steganographic, natural-cover, and natural-steganographic) derived from two public datasets, Movie and Twitter. The experiments on these datasets demonstrate the effectiveness of the proposed approach, showcasing its substantially superior performance over the comparative baseline methods.},
  archive      = {J_NEUCOM},
  author       = {Huiqing You and Lingyun Xiang and Chunfang Yang and Xiaobo Shen},
  doi          = {10.1016/j.neucom.2024.128260},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128260},
  shortjournal = {Neurocomputing},
  title        = {Linguistic steganalysis via multi-task with crossing generative-natural domain},
  volume       = {603},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Systematic comparison of deep-learning based fusion
strategies for multi-modal ultrasound in diagnosis of liver cancer.
<em>NEUCOM</em>, <em>603</em>, 128257. (<a
href="https://doi.org/10.1016/j.neucom.2024.128257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the diagnosis of liver cancer, conventional brightness mode (B-mode) can only provide morphological information. Multi-modal ultrasound, including shear-wave elastography (SWE) and contrast enhanced ultrasound (CEUS), can provide comprehensive diagnostic information on tumor microenvironment and tissue perfusion. The challenge is to effectively explore the multi-modal features of ultrasound. Besides, there are many fusion strategies currently available, but there is a lack of systematic comparative research on the various fusion strategies. In this study, we designed &#39;Lesions Pairing&#39; to construct the dataset, addressing the challenge of small sample sizes in multi-modal learning. We then compared the effectiveness of different strategies and proposed hybrid-fusion strategies based on the combination of conventional layer-level fusion (i.e. early-fusion, mid-fusion and late-fusion), which can efficiently extract intra-/inter- modal information. Specifically, we first systematically compared different deep-learning-based fusion strategies for multi-modal ultrasound in the diagnosis of liver cancer. Secondly, based on the comparison results of a multimodal framework that integrates B-mode, SWE, CEUS ultrasound data, and clinical data simultaneously, we propose a hybrid-fusion strategies for the diagnosis of hepatocellular carcinoma and intrahepatic cholangiocarcinoma. The experimental results showed that the area under the curve of the early-late fusion strategy combined with clinical data was 0.9854, which was superior to other single mode and other fusion strategies, increasing by 13.8–25.88 % and 2.22 %-9.79 %, respectively.},
  archive      = {J_NEUCOM},
  author       = {Ming-De Li and Wei Li and Man-Xia Lin and Xin-Xin Lin and Hang-Tong Hu and Ying-Chen Wang and Si-Min Ruan and Ze-Rong Huang and Rui-Fang Lu and Lv Li and Ming Kuang and Ming-De Lu and Li-Da Chen and Wei Wang and Qing-hua Huang},
  doi          = {10.1016/j.neucom.2024.128257},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128257},
  shortjournal = {Neurocomputing},
  title        = {Systematic comparison of deep-learning based fusion strategies for multi-modal ultrasound in diagnosis of liver cancer},
  volume       = {603},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CAG-NSPDE: Continuous adaptive graph neural stochastic
partial differential equations for traffic flow forecasting.
<em>NEUCOM</em>, <em>603</em>, 128256. (<a
href="https://doi.org/10.1016/j.neucom.2024.128256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow forecasting, which aims to predict future traffic flow given historical data, is crucial for the planning and construction of urban transportation infrastructure. Existing methods based on discrete dynamic graphs are unable to model the smooth evolution of spatial relationships and usually have high computational cost. In addition, they ignore the effect of stochastic noise on the modeling of temporal dependencies, which lead to poor predictive performance on complex intelligent transportation systems. To address these issues, we propose continuous adaptive graph neural stochastic partial differential equation (CAG-NSPDE). A continuous graph is constructed based on learnable continuous adaptive node embeddings for the modeling of evolution of spatial dependencies. To explicitly model the effect of noise, a novel architecture based on stochastic partial differential equation (SPDE) is proposed. It can simultaneously extract features from the temporal and frequency domains by reducing SPDEs to a system of ODEs in Fourier space. We perform extensive experiments on four real-world datasets and the results demonstrate the superiority of CAG-NSPDE compared with state-of-the-arts.},
  archive      = {J_NEUCOM},
  author       = {Tijin Yan and Hengheng Gong and Yufeng Zhan and Yuanqing Xia},
  doi          = {10.1016/j.neucom.2024.128256},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128256},
  shortjournal = {Neurocomputing},
  title        = {CAG-NSPDE: Continuous adaptive graph neural stochastic partial differential equations for traffic flow forecasting},
  volume       = {603},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Abstractive text summarization: State of the art,
challenges, and improvements. <em>NEUCOM</em>, <em>603</em>, 128255. (<a
href="https://doi.org/10.1016/j.neucom.2024.128255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Specifically focusing on the landscape of abstractive text summarization, as opposed to extractive techniques, this survey presents a comprehensive overview, delving into state-of-the-art techniques, prevailing challenges, and prospective research directions. We categorize the techniques into traditional sequence-to-sequence models, pre-trained large language models, reinforcement learning, hierarchical methods, and multi-modal summarization. Unlike prior works that did not examine complexities, scalability and comparisons of techniques in detail, this review takes a comprehensive approach encompassing state-of-the-art methods, challenges, solutions, comparisons, limitations and charts out future improvements — providing researchers an extensive overview to advance abstractive summarization research. We provide vital comparison tables across techniques categorized — offering insights into model complexity, scalability and appropriate applications. The paper highlights challenges such as inadequate meaning representation, factual consistency, controllable text summarization, cross-lingual summarization, and evaluation metrics, among others. Solutions leveraging knowledge incorporation and other innovative strategies are proposed to address these challenges. The paper concludes by highlighting emerging research areas like factual inconsistency, domain-specific, cross-lingual, multilingual, and long-document summarization, as well as handling noisy data. Our objective is to provide researchers and practitioners with a structured overview of the domain, enabling them to better understand the current landscape and identify potential areas for further research and improvement.},
  archive      = {J_NEUCOM},
  author       = {Hassan Shakil and Ahmad Farooq and Jugal Kalita},
  doi          = {10.1016/j.neucom.2024.128255},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128255},
  shortjournal = {Neurocomputing},
  title        = {Abstractive text summarization: State of the art, challenges, and improvements},
  volume       = {603},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluation of synthetic electronic health records: A
systematic review and experimental assessment. <em>NEUCOM</em>,
<em>603</em>, 128253. (<a
href="https://doi.org/10.1016/j.neucom.2024.128253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have shown how synthetic data generation methods can be applied to electronic health records (EHRs) to obtain synthetic versions that do not violate privacy rules. This growing body of research has resulted in the emergence of numerous methods for evaluating the quality of generated data, with new publications often introducing novel evaluation methods. This work presents a detailed review of synthetic EHRs, focusing on the various evaluation methods used to assess the quality of the generated EHRs. We discuss the existing evaluation methods, offering insights into their use as well as providing an interpretation of the evaluation metrics from the perspectives of achieving fidelity , utility and privacy . Furthermore, we highlight the key factors influencing the selection of evaluation methods, such as the type of data (e.g., categorical, continuous, or discrete) and the mode of application (e.g., patient level, cohort level, and feature level). To assess the effectiveness of current evaluation measures, we conduct a series of experiments to shed light on the potential limitations of these measures. The findings from these experiments reveal notable shortcomings, including the need for meticulous application of methods to the data to reduce inconsistent evaluations, the qualitative nature of some assessments subject to individual judgment, the need for clinical validations, and the absence of techniques to evaluate temporal dependencies within the data. This highlights the need to place greater emphasis on evaluation measures, their application, and the development of comprehensive evaluation frameworks as it is crucial for advancing progress in this field.},
  archive      = {J_NEUCOM},
  author       = {Emmanuella Budu and Kobra Etminani and Amira Soliman and Thorsteinn Rögnvaldsson},
  doi          = {10.1016/j.neucom.2024.128253},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128253},
  shortjournal = {Neurocomputing},
  title        = {Evaluation of synthetic electronic health records: A systematic review and experimental assessment},
  volume       = {603},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning based interval type-2 fuzzy approach for
image retrieval systems. <em>NEUCOM</em>, <em>603</em>, 128251. (<a
href="https://doi.org/10.1016/j.neucom.2024.128251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning, that one of its key benefits is automated feature extraction, has become a principal solution for computer vision. This paper presents a Deep Type-2 Beta Fuzzy (DT2F) approach for Content-Based Image Retrieval (CBIR) systems. Firstly, the suggested architecture uses InceptionResNetv2 a pre-trained deep learning model on Image-Net data as a feature extractor. Secondly, the obtained feature space is fuzzified to handle the uncertainties associated with the extracted values of deep features. Thirdly, the reduction dimensionality step is efficiently applied using a Multi-Variational Auto-Encoder (MVAE) to reduce computational complexity and achieve better performance. Ultimately, we retrieve images using the nearest neighbors rule based on type-2 fuzzy similarity to having higher proximity sensitivity. Extensive experimentations were accomplished on various image-retrieving datasets of different scales the proposed system achieved an average precision of 97.15% exceeding other state-of-the-art methods over many systems on Corel datasets, which can open the door for several hybridization breakthroughs in the area of image retrieval.},
  archive      = {J_NEUCOM},
  author       = {Yosr Ghozzi and Tarek M. Hamdani and Hani Hagras and Khmaies Ouahada and Habib Chabchoub and Adel M. Alimi},
  doi          = {10.1016/j.neucom.2024.128251},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128251},
  shortjournal = {Neurocomputing},
  title        = {A deep learning based interval type-2 fuzzy approach for image retrieval systems},
  volume       = {603},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed learning for online multi-cluster games over
directed graphs. <em>NEUCOM</em>, <em>603</em>, 128213. (<a
href="https://doi.org/10.1016/j.neucom.2024.128213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the distributed Nash equilibrium seeking problem of multi-cluster games with time-varying local cost functions and local strategy set constraints is considered. Agents are divided into different clusters, and each cluster can be viewed as a virtual noncooperative player competing with others through a directed graph with a row-stochastic adjacency matrix. Agents in a cluster are the actual decision makers whose goal is to cooperatively minimize the cluster’s time-varying cost function through a directed graph with a column-stochastic adjacency matrix. In this scenario, a distributed learning algorithm based on the consensus method and the gradient-tracking technique is proposed to seek the Nash equilibrium of the considered online multi-cluster game. Moreover, it can be theoretically proved that sublinearly bounded dynamic regrets can be guaranteed by properly choosing decreasing stepsizes when the path length accumulation and the gradient length accumulation increase sublinearly. Finally, theoretical results are verified by numerical simulations.},
  archive      = {J_NEUCOM},
  author       = {Rui Yu and Min Meng and Li Li and Qingyun Yu},
  doi          = {10.1016/j.neucom.2024.128213},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128213},
  shortjournal = {Neurocomputing},
  title        = {Distributed learning for online multi-cluster games over directed graphs},
  volume       = {603},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-modal hashing retrieval with compatible triplet
representation. <em>NEUCOM</em>, <em>602</em>, 128293. (<a
href="https://doi.org/10.1016/j.neucom.2024.128293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal hashing retrieval has emerged as a promising approach due to its advantages in storage efficiency and query speed for handling diverse multimodal data. However, existing cross-modal hashing retrieval methods often oversimplify similarity by solely considering identical labels across modalities and are sensitive to noise in the original multimodal data. To tackle this challenge, we propose a cross-modal hashing retrieval approach with compatible triplet representation. In the proposed approach, we integrate the essential feature representations and semantic information from text and images into their corresponding multi-label feature representations, and introduce a fusion attention module to extract text and image modalities with channel and spatial attention features, respectively, thereby enhancing compatible triplet-based semantic information in cross-modal hashing learning. Comprehensive experiments demonstrate the superiority of the proposed approach in retrieval accuracy compared to state-of-the-art methods on three public datasets.},
  archive      = {J_NEUCOM},
  author       = {Zhifeng Hao and Yaochu Jin and Xueming Yan and Chuyue Wang and Shangshang Yang and Hong Ge},
  doi          = {10.1016/j.neucom.2024.128293},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128293},
  shortjournal = {Neurocomputing},
  title        = {Cross-modal hashing retrieval with compatible triplet representation},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RAD-IQMRI: A benchmark for MRI image quality assessment.
<em>NEUCOM</em>, <em>602</em>, 128292. (<a
href="https://doi.org/10.1016/j.neucom.2024.128292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI) is susceptible to visual artifacts that can degrade the perceptual image quality, potentially leading to inaccurate or inefficient diagnoses in clinical practice. It is critical to evaluate the perceptual image quality and build this technique into clinical solutions. In a previous study, an MRI database was created for image quality assessment (IQA), where various types of MRI artifacts with different degrees of degradation were simulated. Application specialists assessed the image quality; however, radiologists’ perception of MRI image quality remains unknown. To make IQA clinically relevant, in this paper we conduct a new subjective experiment where 13 radiologists rated the quality of images contained in the MRI database. Based on this subjective IQA benchmark named RAD-IQMRI, we evaluate the performance of state-of-the-art objective IQA models, providing insights into their application for MRI image quality assessment in clinical settings.},
  archive      = {J_NEUCOM},
  author       = {Yueran Ma and Jianxun Lou and Jean-Yves Tanguy and Padraig Corcoran and Hantao Liu},
  doi          = {10.1016/j.neucom.2024.128292},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128292},
  shortjournal = {Neurocomputing},
  title        = {RAD-IQMRI: A benchmark for MRI image quality assessment},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HGOD: Outlier detection based on a hybrid graph.
<em>NEUCOM</em>, <em>602</em>, 128288. (<a
href="https://doi.org/10.1016/j.neucom.2024.128288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection is one of the core problems in the field of data mining. Graph-based approaches are widely acknowledged for their robust performance in outlier detection, yet constructing a comprehensive graph to represent the original data remains challenging. Some methods rely solely on the global distribution of the data, leading to low detection accuracy; in addition, when incorporating the local information of the data, the problem of dangling links may arise. To improve the graph construction process, this paper proposes an outlier detection algorithm based on a hybrid graph (HGOD). First, the neighbors of each object are obtained in an adaptive manner, and a neighborhood graph is created. Subsequently, a global connectivity graph is constructed using a minimum spanning tree. Then, these two graphs are merged into a hybrid graph, and Markov random walks are conducted on it. Finally, outliers are identified based on the converged stationary distribution. The performance of HGOD is evaluated on both real-world and synthetic datasets. The precision and AUC of HGOD algorithm surpasses that of the other seven algorithms. Ablation and analysis experiments further demonstrate that the HGOD algorithm is effective and has outstanding performance in outlier detection.},
  archive      = {J_NEUCOM},
  author       = {Zhongping Zhang and Yuehan Hou and Daoheng Liu and Ruibo Zhang and Xin Guo},
  doi          = {10.1016/j.neucom.2024.128288},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128288},
  shortjournal = {Neurocomputing},
  title        = {HGOD: Outlier detection based on a hybrid graph},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GraphFusion: Integrating multi-level semantic information
with graph computing for enhanced 3D instance segmentation.
<em>NEUCOM</em>, <em>602</em>, 128287. (<a
href="https://doi.org/10.1016/j.neucom.2024.128287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph computing has emerged as a focal point in recent research across various fields, including the realm of 3D instance segmentation, where it aids in detecting and segmenting objects within volumetric data. Our study introduces GraphFusion, a state-of-the-art network that harnesses the power of graph computing to enhance the segmentation of 3D point clouds. GraphFusion is equipped with a Multi-Level Semantic Aggregation Module, architectured akin to a graph, to capture comprehensive features from 3D point clouds. Utilizing graph-based methodologies, this module proficiently aggregates multi-scale semantic information, illuminating insights from both global and local contexts. Additionally, our Parallel Feature Fusion Transformer Module leverages graph-transformer techniques to intricately process complex spatial relationships within point clouds, culminating in a more cohesive feature representation. Rigorous experiments on the ScanNetv2 dataset affirm the dominance of GraphFusion, which eclipses current methods by 2.2% in mean Average Precision (mAP) on the hidden test set. The model’s code is accessible at https://github.com/3171228612/GraphFusion .},
  archive      = {J_NEUCOM},
  author       = {Lei Pan and Wuyang Luan and Yuan Zheng and Junhui Li and Linwei Tao and Chang Xu},
  doi          = {10.1016/j.neucom.2024.128287},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128287},
  shortjournal = {Neurocomputing},
  title        = {GraphFusion: Integrating multi-level semantic information with graph computing for enhanced 3D instance segmentation},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LUIE: Learnable physical model-guided underwater image
enhancement with bi-directional unsupervised domain adaptation.
<em>NEUCOM</em>, <em>602</em>, 128286. (<a
href="https://doi.org/10.1016/j.neucom.2024.128286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, learning-based underwater enhancement (UIE) methods have made considerable progress, significantly benefiting downstream tasks such as underwater semantic segmentation and underwater depth estimation. Most existing unsupervised UIE methods utilize the atmospheric image formation model to decompose underwater images into background color, transmission map, and scene radiance. However, they rely on simplified physical models for estimating the transmission map, over-simplifying its complex formation, which results in imprecise modeling of underwater scattering effects. Additionally, supervised UIE methods heavily depend on synthetic data or ground truth, leading to limited generalization capabilities due to the substantial domain gap presented in different underwater scenarios. To tackle these challenges, we propose a L earnable physical model-guided unsupervised domain adaptation framework for U nderwater I mage E nhancement, dubbed LUIE . LUIE learns to predict background light, depth, and scene radiance from an underwater image. We incorporate a learnable network to estimate the transmission map based on the predicted depth map. To minimize the inter-domain gap between synthetic and real underwater images, we introduce a bi-directional domain adaptation method that alternates the background light from each domain. Experimental results demonstrate the effectiveness of our proposed method compared to existing approaches, and high-level experiment results validate that our enhanced underwater results. Experiments in real-world settings on underwater ROVs platform with NVIDIA Jetson AGX Xavier further confirm the effectiveness and efficiency of our work.},
  archive      = {J_NEUCOM},
  author       = {Jingyi Pan and Zeyu Duan and Jianghua Duan and Zhe Wang},
  doi          = {10.1016/j.neucom.2024.128286},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128286},
  shortjournal = {Neurocomputing},
  title        = {LUIE: Learnable physical model-guided underwater image enhancement with bi-directional unsupervised domain adaptation},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluating the necessity of the multiple metrics for
assessing explainable AI: A critical examination. <em>NEUCOM</em>,
<em>602</em>, 128282. (<a
href="https://doi.org/10.1016/j.neucom.2024.128282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the specific properties of Explainable Artificial Intelligence (xAI), particularly when implemented in AI/ML models across high-stakes sectors, in this case cybersecurity. The authors execute a comprehensive systematic review of xAI properties, various evaluation metrics, and existing frameworks to assess their utility and relevance. Subsequently, the experimental sections evaluate selected xAI techniques against these metrics, delivering key insights into their practical utility and effectiveness. The findings highlight that the proliferation of metrics enhances the understanding of xAI systems but simultaneously exposes challenges such as metric duplication, inefficacy, and confusion. These issues underscore the pressing need for standardized evaluation frameworks to streamline their application and strengthen their effectiveness, thereby improving the overall utility of xAI in critical domains.},
  archive      = {J_NEUCOM},
  author       = {Marek Pawlicki and Aleksandra Pawlicka and Federica Uccello and Sebastian Szelest and Salvatore D’Antonio and Rafał Kozik and Michał Choraś},
  doi          = {10.1016/j.neucom.2024.128282},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128282},
  shortjournal = {Neurocomputing},
  title        = {Evaluating the necessity of the multiple metrics for assessing explainable AI: A critical examination},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). WSSGCN: Wide sub-stage graph convolutional networks.
<em>NEUCOM</em>, <em>602</em>, 128273. (<a
href="https://doi.org/10.1016/j.neucom.2024.128273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Networks (GCNs) have emerged as a potent tool for learning graph representations, finding applications in a plethora of real-world scenarios. Nevertheless, a significant portion of deep learning research has predominantly concentrated on enhancing model performance via the construction of deeper GCNs. Regrettably, the efficacy of training deep GCNs is marred by two fundamental weaknesses: the inadequacy of conventional methodologies in handling heterogeneous networks, and the exponential surge in model complexity as network depth increases. This, in turn, imposes constraints on their practical utility. To surmount these inherent limitations, we propose an innovative approach named the Wide Sub-stage Graph Convolutional Network (WSSGCN). Our method is an outcome of meticulous observations drawn from classical and graph convolutional networks, aimed at rectifying the constraints associated with traditional GCNs. Our strategy involves the conception of a staged convolutional network framework that mirrors the fundamental tenets of the step-by-step learning process akin to human cognition. This framework prioritizes three distinct forms of consistency: response-based, feature-based, and relationship-based. Our approach involves three tailored convolutional networks capturing node/edge, subgraph, and global features. Additionally, we introduce a novel method to expand graph width for efficient GCN training. Empirical validation on benchmarks highlights WSSGCN’s superior accuracy and faster training versus conventional GCNs. WSSGCN triumphs over traditional GCN constraints, significantly enhancing graph representation learning.},
  archive      = {J_NEUCOM},
  author       = {Chao Wang and Zheng Tang and Hailu Xu},
  doi          = {10.1016/j.neucom.2024.128273},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128273},
  shortjournal = {Neurocomputing},
  title        = {WSSGCN: Wide sub-stage graph convolutional networks},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global-local manifold embedding broad graph convolutional
network for hyperspectral image classification. <em>NEUCOM</em>,
<em>602</em>, 128271. (<a
href="https://doi.org/10.1016/j.neucom.2024.128271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional neural networks (GCNs) with domain-specific feature aggregation capabilities have unique advantages in hyperspectral image (HSI) classification. However, current GCN-based approaches frequently encounter the issue of node characteristics being over-smoothed while aggregating in higher-order domains. Furthermore, GCN linear classifiers focus solely on sample separability and ignore the potential manifold information of graph features, resulting in a failure to fully investigate extracted features. To address these problems, we propose a global-local manifold embedding broad graph convolutional network (GLMBG) for HSI classification. In GLMBG, we designed two modules from feature extraction and classification perspectives: The graph convolutional edge feature fusion extractor (GEFF) and the broad classifier of global-local manifold embedding (BGLME). GEFF is designed to learn graph node and local edge features from HSI through GCN and recursive filtering, combining them in a weighted manner to construct fused graph features. BGLME is designed to replace traditional linear classifiers with broad learning classifiers through manifold regularized embedding, fully utilizing the global and local manifold discriminant information of graph node features. The combination of GEFF and BGLME effectively reduces over-smoothing of graph node features while maximizing the utilization of manifold discriminant information, hence improving model feature discriminative ability. Experimental evaluations of three commonly used hyperspectral datasets show that our method surpasses state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Heling Cao and Jun Cao and Yonghe Chu and Yun Wang and Guangen Liu and Peng Li},
  doi          = {10.1016/j.neucom.2024.128271},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128271},
  shortjournal = {Neurocomputing},
  title        = {Global-local manifold embedding broad graph convolutional network for hyperspectral image classification},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TE-spikformer: Temporal-enhanced spiking neural network with
transformer. <em>NEUCOM</em>, <em>602</em>, 128268. (<a
href="https://doi.org/10.1016/j.neucom.2024.128268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of Spiking Neural Networks (Maass, 1997) and Transformers (Vaswani et al., 2017) has significantly enhanced performance in the field, achieving substantial improvements while ensuring energy efficiency. This amalgamation bears significant exploratory significance. This paper aims to enhance the network’s capacity for extracting temporal information from neuromorphic datasets. By leveraging the Spikformer (Zhou et al., 2023b) architecture, we introduce a novel network named TE-Spikformer. Through thorough analysis, we identified an imbalance in the Average Firing Rates(AFR) of neurons in the layer preceding the classification head across temporal steps. We thoroughly investigate the root cause of this issue, attributing it to the limitations of the network’s use of Batch Normalization (BN) (Ioffe and Szegedy, 2015) layer. To address these challenges, we propose a Batch Group Normalization (BGN) layer. While maintaining the stability of temporal characteristics in the data, we also introduce the Spike Spatio-Temporal Attention(SSTA) module to enhance the network’s ability to capture temporal information. To validate the effectiveness of our approach, we conducted multiple experiments using neuromorphic datasets, including DVS-CIFAR10, DVS128 Gesture, and N-Caltech101. The experimental results demonstrate that our algorithm consistently outperforms baseline methods, achieving accuracy rates of 99.30%, 89.60%, and 87.42%, respectively, thereby attaining state-of-the-art performance in the field.},
  archive      = {J_NEUCOM},
  author       = {ShouWei Gao and XiangYu Fan and XingYang Deng and ZiChao Hong and Hao Zhou and ZiHao Zhu},
  doi          = {10.1016/j.neucom.2024.128268},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128268},
  shortjournal = {Neurocomputing},
  title        = {TE-spikformer: Temporal-enhanced spiking neural network with transformer},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed sparsity constrained optimization over the
stiefel manifold. <em>NEUCOM</em>, <em>602</em>, 128267. (<a
href="https://doi.org/10.1016/j.neucom.2024.128267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed optimization aims to effectively complete specified tasks through cooperation among multi-agent systems, which has achieved great success in large-scale optimization problems. However, it remains a challenging task to develop an effective distributed algorithm with theoretical guarantees, especially when dealing with nonconvex constraints. More importantly, high-dimensional data often exhibits inherent structures such as sparsity, which if exploited accurately, can significantly enhance the capture of its intrinsic characteristics. In this paper, we introduce a novel d ist r ibut e d sp a rsity constrained optimization framework over the Stiefel m anifold, abbreviated as DREAM. DREAM innovatively integrates the ℓ 2 , 0 ℓ2,0 -norm constraint and Stiefel manifold constraint within a distributed optimization setting, which has not been investigated in existing literature. Unlike the existing distributed methods, the proposed DREAM not only can extract the similarity information among samples, but also more flexibly determine the number of features to be extracted. Then, we develop an efficient Newton augmented Lagrangian-based algorithm. In theory, we delve into the relationship between the minimizer, the Karush–Kuhn–Tucker point, and the stationary point, and rigorously demonstrate that the sequence generated by our algorithm converges to a stationary point. Extensive numerical experiments verify its superiority over state-of-the-art distributed methods.},
  archive      = {J_NEUCOM},
  author       = {Wentao Qu and Huangyue Chen and Xianchao Xiu and Wanquan Liu},
  doi          = {10.1016/j.neucom.2024.128267},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128267},
  shortjournal = {Neurocomputing},
  title        = {Distributed sparsity constrained optimization over the stiefel manifold},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large-scale multi-view subspace clustering via embedding
space and partition matrix. <em>NEUCOM</em>, <em>602</em>, 128266. (<a
href="https://doi.org/10.1016/j.neucom.2024.128266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering (MVSC) has attracted increasing attention because it can extract information from multiple views and explore the underlying structure. In general, most of the existing anchor strategies solve the problem of excessive complexity, but there is a loss of information in the process of affinity graph passing to spectral clustering. In addition, the noise in the original data leads to the learned anchor graph not representing the data features adequately. To solve the above problems, this paper proposes a Large-Scale Multi-View Subspace Clustering via Embedding Space and Partition Matrix(LMVSC-EPM) algorithm that preserves the distribution of the original data by embedding matrix mapping. The algorithm utilizes the centroid matrix and the clustering assignment matrix to derive the clustering results directly. Specifically, LMVSC-EPM employs embedding matrices to map the raw data into the embedding space and adaptively learns anchors using a view-sharing anchor strategy. Moreover, the non-negative orthogonal matrix is adopted to assign the results to the clustering assignment matrix, which avoids the loss of the affinity matrix in the passing process. Furthermore, an alternating minimization optimization method is designed in this paper to solve the optimization problem. Experimental results on seven underlying datasets demonstrate the efficiency and superiority of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Tianhang Cheng and Jinjia Peng and Hui Li and Huibing Wang},
  doi          = {10.1016/j.neucom.2024.128266},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128266},
  shortjournal = {Neurocomputing},
  title        = {Large-scale multi-view subspace clustering via embedding space and partition matrix},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fixed-time event-triggered adaptive control of manipulator
system with input deadzone and model uncertainty. <em>NEUCOM</em>,
<em>602</em>, 128265. (<a
href="https://doi.org/10.1016/j.neucom.2024.128265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There exist universal model uncertainty and input deadzone in mechatronic motion plant due to unknown model parameters and actuator physical feature, which will degrade the motion performance and stability. In this study, a fixed-time event-triggered adaptive control is proposed in n n -DOF manipulator system to address these problems. Firstly, the dynamic model of n n -DOF manipulator with joint friction and input deadzone is constructed by Lagrange technique. Then a radial basis function neural network (RBFNN) is designed to approximate uncertain dynamics. Meanwhile, an event-triggered mechanism (ETM) is used to reduce the control update frequency and to save the communication resource. Furthermore, an adaptive estimation law is adopted to compensate unknown input deadzone parameters. Based on backstepping iteration technique, a fixed-time convergent controller is presented to guarantee the system state errors convergence to zero neighborhood in finite time irrelevant to arbitrary initial state. Finally, the effectiveness of the proposed control scheme is verified by sufficient comparative simulation and experimental results.},
  archive      = {J_NEUCOM},
  author       = {Haoran Zhan and Chen Wang and Qing Guo and Xinglong Wu and Tieshan Li},
  doi          = {10.1016/j.neucom.2024.128265},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128265},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time event-triggered adaptive control of manipulator system with input deadzone and model uncertainty},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel approaches for fake news detection based on
attention-based deep multiple-instance learning using contextualized
neural language models. <em>NEUCOM</em>, <em>602</em>, 128263. (<a
href="https://doi.org/10.1016/j.neucom.2024.128263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of social media and online news sources, the spread of fake news (FN) has become a significant concern. Classifying FN requires sophisticated approaches to discern nuances, patterns of misinformation, and evolving strategies of disinformation spreaders. Furthermore, contextualizing news texts enables a more in-depth understanding of the nature of the news beyond surface analyses and, thus, more accurate classifications. This study proposes approaches based on Attention-based Deep Multiple Instance Learning (ADMIL) for Fake News Detection (FND), which treats texts through contextual embedding. The proposed approaches leverage the learning capabilities of the MIL model by using an integrated attention mechanism that adaptively focuses on significant instances and dynamically adjusts attention weights. Embeddings provided by state-of-the-art contextual Neural Language Models (cNLMs) such as DeBERTa, SGPT, Flair, and GPT-3.5-based ADA-002 contribute to developing ADMIL-based detection models. These embeddings support the learning process by enabling the model to extract deeper meaning from the data. This study also presents novel approaches that integrate the feature extraction layers of CNNs, called C o n v − A D M I L Conv−ADMIL , to improve classification ability by improving extraction resolution. Experimental studies were conducted on two comprehensive FN datasets, LIAR and McIntire, to evaluate the effectiveness of the proposed approaches. In McIntire’s dataset, the C o n v − A D M I L Conv−ADMIL classifier, utilizing the DeBERTa, achieved an F 1 − s c o r e F1−score of 97%, while in the LIAR dataset, employing the ADA-002, it attained a performance of over 93%. These findings demonstrate that integrating the C o n v − A D M I L Conv−ADMIL model with DeBERTa and ADA-002 cNLMs yields superior performance across various metrics. As a pioneering research towards new models for this domain, this study lays a foundation for future research and confirms that the proposed approaches are practical for FND tasks.},
  archive      = {J_NEUCOM},
  author       = {Kürşat Mustafa Karaoğlan},
  doi          = {10.1016/j.neucom.2024.128263},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128263},
  shortjournal = {Neurocomputing},
  title        = {Novel approaches for fake news detection based on attention-based deep multiple-instance learning using contextualized neural language models},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Physics-informed convolution gated recurrent unit network
for solving an inverse problem. <em>NEUCOM</em>, <em>602</em>, 128254.
(<a href="https://doi.org/10.1016/j.neucom.2024.128254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has gained considerable attention in recent years for solving partial differential equations (PDEs) and inverse problems. In this paper a novel framework called physics-informed convolution gated recurrent unit Resnet (PhyCGRUR) is introduced. It is designed to address PDEs and their associated inverse problems. To investigate our model, first we apply the PhyCGRUR for solving PDEs without any labeled data. Then, we adapt the proposed methodology for identifying some parameters in PDEs from the final observation. Finally, we illustrate the capabilities and robustness of our proposed architecture (PhyCGRUR) compared with some competitive learned models using relative error, complexity, memory requirements and Running Time.},
  archive      = {J_NEUCOM},
  author       = {M. Srati and A. Hadri and L. Afraites},
  doi          = {10.1016/j.neucom.2024.128254},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128254},
  shortjournal = {Neurocomputing},
  title        = {Physics-informed convolution gated recurrent unit network for solving an inverse problem},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consensus local graph for multiple kernel clustering.
<em>NEUCOM</em>, <em>602</em>, 128252. (<a
href="https://doi.org/10.1016/j.neucom.2024.128252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the ability to represent the relationship among data, graph has received extensive attention in clustering field. As illustrated by existing studies, learning graph in kernel space is an effective way to capture the structure of data. Among kernel-based methods, multiple kernel learning (MKL) is increasingly popular since it can automatically utilize the complementary information contained in base kernels. Although many existing MKL-based graph learning algorithms have promising learning abilities, we observe that they (1) put too much attention on learning the consensus kernel which probably contains lots of redundant information and loses the diversity of base kernels; (2) ignore the local structure of the representations in multiple kernel spaces. To eliminate the bad effect of these issues, we propose a novel graph learning method, termed consensus local graph based on MKL (CLGMKL), for clustering. In CLGMKL, a low-rank kernel matrix is used to extract the discriminative information of each base kernel and a local graph is constructed to capture the local structure contained in each new kernel. Then CLGMKL combines these local graphs in a self-weighed way. Since the above processes are associated with each other, we jointly optimize them to obtain the overall optimality. An effective learning scheme with proved convergence is developed to optimize the combined objective function. Finally, extensive experiments on some popular datasets are conducted to test the effectiveness of the presented method. As illustrated, CLGMKL is more competitive than the state-of-the-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Zheng Liu and Shiluo Huang and Wei Jin and Ying Mu},
  doi          = {10.1016/j.neucom.2024.128252},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128252},
  shortjournal = {Neurocomputing},
  title        = {Consensus local graph for multiple kernel clustering},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised reconstructed graph learning for link
prediction in bipartite graphs. <em>NEUCOM</em>, <em>602</em>, 128250.
(<a href="https://doi.org/10.1016/j.neucom.2024.128250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Network(GNN) has achieved remarkable performance in classification tasks due to its strong distinctive power of different graph topologies. However, traditional GNNs face great limitations in link prediction tasks since they learn vertex embeddings from fixed input graphs thus the learned embeddings cannot reflect unobserved graph structures. Graph-learning based GNNs have shown better performance by collaborative learning of graph structures and vertex embeddings, but most of them rely on available initial features to refine graphs and almost perform graph learning at once. Recently, some methods utilizes contrastive learning to facilitate link prediction, but their graph augmentation strategies are predefined only on original graphs, and do not introduce unobserved edges into augmented graphs. To this end, a self-supervised reconstructed graph learning (SRGL) method is proposed. The key points of SRGL lie in two folds: Firstly, it generates augmented graphs for contrasting by learning reconstructed graphs and vertex embeddings from each other, which brings unobserved edges into augmented graphs. Secondly, it maximizes the mutual information between edge-level embeddings of reconstructed graphs and the graph-level embedding of an original graph, which guarantees learned reconstructed graphs to be relevant to the original graph.},
  archive      = {J_NEUCOM},
  author       = {Xu Jin and Desheng Kong and Maoqiang Xie and Yalou Huang and Mingming Liu and Weiwei Yang and Hao Shi and Yue Liu},
  doi          = {10.1016/j.neucom.2024.128250},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128250},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised reconstructed graph learning for link prediction in bipartite graphs},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contrastive optimized graph convolution network for traffic
forecasting. <em>NEUCOM</em>, <em>602</em>, 128249. (<a
href="https://doi.org/10.1016/j.neucom.2024.128249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting is an increasingly important research topic in the field of Intelligent Transportation Systems (ITS). In this field, prediction models based on Graph Convolution Networks (GCN) have become very popular. Most GCN-based models focus on constructing various optimized or dynamic road network graphs to represent the spatio-temporal correlation hidden in traffic data. However, these methods currently only consider the construction of a single improved road network graph and ignore the relationship of these existing optimized road network graphs. Therefore, in this paper, we propose a Contrastive Optimized Graph Convolution Network (COGCN) to connect two kinds of optimized road network graphs and maintain their global–local feature consistency through contrastive learning. The proposed COGCN model is evaluated in detail using four real traffic datasets: two traffic speed datasets and two traffic flow datasets. Experimental results show that COGCN improves forecasting accuracy by at least 2% on the two speed datasets and 9% on the two flow datasets compared to the existing state-of-the-art GCN-based methods.},
  archive      = {J_NEUCOM},
  author       = {Kan Guo and Daxin Tian and Yongli Hu and Yanfeng Sun and Zhen (Sean) Qian and Jianshan Zhou and Junbin Gao and Baocai Yin},
  doi          = {10.1016/j.neucom.2024.128249},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128249},
  shortjournal = {Neurocomputing},
  title        = {Contrastive optimized graph convolution network for traffic forecasting},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LSTM network in bilateral teleoperation of a skid-steering
robot. <em>NEUCOM</em>, <em>602</em>, 128248. (<a
href="https://doi.org/10.1016/j.neucom.2024.128248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper analyses a control scheme aided by LSTM networks for the delayed bilateral teleoperation system of a skid-steering wheeled mobile robot. The strategy implemented at the local and remote sites combines a virtual force based on nonlinear impedance, nonlinear Proportional–Integral (PI) gains, spring-damper, and robust neural dynamics compensation, including a gradient-based adjustment law or critic-actor RL trained offline using the ADAM algorithm. To analyse the stated strategy, stability analysis is performed. A Lyapunov–Krasovskii functional is proposed for evaluation along the system trajectories to analyse the evolution of control errors and network errors. Human-in-the-loop simulations are conducted and evaluated as a case study to observe the responses of velocities and yaw rate errors, lateral velocity, and network parameters in the presence of time-varying delays, variable load, and different terrain frictions.},
  archive      = {J_NEUCOM},
  author       = {Emanuel Slawiñski and Francisco Rossomando and Fernando A. Chicaiza and Javier Moreno-Valenzuela and Vicente Mut},
  doi          = {10.1016/j.neucom.2024.128248},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128248},
  shortjournal = {Neurocomputing},
  title        = {LSTM network in bilateral teleoperation of a skid-steering robot},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot open-set recognition via pairwise discriminant
aggregation. <em>NEUCOM</em>, <em>602</em>, 128214. (<a
href="https://doi.org/10.1016/j.neucom.2024.128214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot open-set recognition (FSOR) aims to develop models capable of generalizing to new tasks for both unknown detection and known classification with limited labeled data. Previous FSOR methods lack a comprehensive definition of the open space in the few-shot scenario, making models susceptible to overgeneralization. In this paper, we propose a novel method called Pairwise Discriminant Aggregation (PDAgg), addressing FSOR within a two-level recognition framework. PDAgg unifies the diverse optimization goals of FSOR at the pair level and provides a reasonable aggregate-level representation for unknown samples, thereby greatly enhancing model generalization to open space in the few-shot context. Specifically, PDAgg treats support-query pairs as the basic recognition units, which are adapted to a pair-specific feature space by enhancing pairwise representative features and incorporating a global knowledge context. Binary discriminant analyses are performed on adapted pair embeddings to estimate pair-level discriminant scores, which are then jointly aggregated to achieve both unknown detection and few-shot classification. Extensive experiments demonstrate that our method delivers comparable and even better performance with less extra information compared to the existing FSOR methods.},
  archive      = {J_NEUCOM},
  author       = {Jian Jin and Yang Shen and Zhenyong Fu and Jian Yang},
  doi          = {10.1016/j.neucom.2024.128214},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128214},
  shortjournal = {Neurocomputing},
  title        = {Few-shot open-set recognition via pairwise discriminant aggregation},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). APPN: An attention-based pseudo-label propagation network
for few-shot learning with noisy labels. <em>NEUCOM</em>, <em>602</em>,
128212. (<a href="https://doi.org/10.1016/j.neucom.2024.128212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning has garnered significant attention in deep learning as an effective approach for addressing the issue of data scarcity. Conventionally, training datasets in few-shot learning are clean. However, due to the occurrence of sensor malfunctions, data transmission anomalies, or inaccuracies in manual annotation, the accuracy of sample annotations cannot be guaranteed. Therefore, dealing with few-shot learning with noisy label becomes an urgent problem. To solve the above problem, we propose an Attention-based Pseudo-label Propagation Network (APPN). We make some technical contributions: (1) We propose an attention-based feature extraction method that can effectively capture the distinctions between clean and noisy samples. (2) We propose an improved graph-based pseudo-label propagation method that utilizes pseudo-labels with latent class information as initial labels, thereby enhancing the accuracy of label propagation. (3) We describe a comprehensive multi-step noise detection method which can accurately detect noisy samples from clean samples and effectively distinguish between out-of-domain (OOD) noise and in-domain (ID) noise. (4) Finally, the solid experiments verify the better performance on FC100, CIFAR-FS, mini ImageNet, and tiered ImageNet datasets. The results show that our method has high robustness and superiority in the few-shot learning with noisy labels. Code and models at: https://github.com/Typistchen/APPN .},
  archive      = {J_NEUCOM},
  author       = {Jiaqi Chen and Shizhuo Deng and Da Teng and Dongyue Chen and Tong Jia and Hao Wang},
  doi          = {10.1016/j.neucom.2024.128212},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128212},
  shortjournal = {Neurocomputing},
  title        = {APPN: An attention-based pseudo-label propagation network for few-shot learning with noisy labels},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). HTNet for micro-expression recognition. <em>NEUCOM</em>,
<em>602</em>, 128196. (<a
href="https://doi.org/10.1016/j.neucom.2024.128196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression is related to facial muscle contractions and different muscle movements correspond to different emotional states. For micro-expression recognition, the muscle movements are usually subtle, which has a negative impact on the performance of current facial emotion recognition algorithms. Most existing methods use self-attention mechanisms to capture relationships between tokens in a sequence, but they do not take into account the inherent spatial relationships between facial landmarks. This can result in sub-optimal performance on micro-expression recognition tasks. Therefore, learning to recognize facial muscle movements is a key challenge in the area of micro-expression recognition. In this paper, we propose a Hierarchical Transformer Network (HTNet) to identify critical areas of facial muscle movement. HTNet includes two major components: a transformer layer that leverages the local temporal features and an aggregation layer that extracts local and global semantical facial features. Specifically, HTNet divides the face into four different facial areas: left lip area, left eye area, right eye area and right lip area. The transformer layer is used to focus on representing local minor muscle movement with local self-attention in each area. The aggregation layer is used to learn the interactions between eye areas and lip areas. The experiments on four publicly available micro-expression datasets show that the proposed approach outperforms previous methods by a large margin. The codes and models are available at: https://github.com/wangzhifengharrison/HTNet .},
  archive      = {J_NEUCOM},
  author       = {Zhifeng Wang and Kaihao Zhang and Wenhan Luo and Ramesh Sankaranarayana},
  doi          = {10.1016/j.neucom.2024.128196},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128196},
  shortjournal = {Neurocomputing},
  title        = {HTNet for micro-expression recognition},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy preservation network with global-aware focal loss
for interactive personal visual privacy preservation. <em>NEUCOM</em>,
<em>602</em>, 128193. (<a
href="https://doi.org/10.1016/j.neucom.2024.128193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing visual privacy preservation methods often encounter the challenge of over-protection, which usually fails to accurately protect a specified person in an image. This paper introduces a novel task called “Interactive Personal Visual Privacy Preservation (IPVPP)”, with the objective of safeguarding a desired individual in an image based on user-click prompts. We propose a new framework, Privacy Preservation Network (PPNet) with Global-aware Focal Loss, tailored for IPVPP task. To address the sample imbalance issue in IPVPP, we present a Global-aware Focal Loss (GFL), which introduces global and local difficulty balance weights to dynamically adjust the overall decision boundary, thereby mitigating the sample imbalance problem for better optimization of models. Furthermore, to tackle the insufficient fusion between click and visual features, we propose a Click-Image Fusion (CIF) module, which effectively emphasizes the interaction between click and image features, providing robust query inputs to the model. We finally employ generative adversarial networks to ensure the reusability of privacy images, striking a balance between privacy preservation and image value. Experimental results on the DAVIS dataset demonstrate the effectiveness of PPNet, achieving improvements measured in NoC 90, IS, SSIM, F-1, and DIR, with 0.22, 0.19, 0.009, 4.23, and 2.15 improvements, respectively.},
  archive      = {J_NEUCOM},
  author       = {Zhiqiang Xiao and Jiacheng Lin and Jiajun Chen and Haolong Fu and Yifan Li and Jin Yuan and Zhiyong Li},
  doi          = {10.1016/j.neucom.2024.128193},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128193},
  shortjournal = {Neurocomputing},
  title        = {Privacy preservation network with global-aware focal loss for interactive personal visual privacy preservation},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meta-learning on dynamic node clustering knowledge graph for
cold-start recommendation. <em>NEUCOM</em>, <em>602</em>, 128192. (<a
href="https://doi.org/10.1016/j.neucom.2024.128192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-learning has been introduced in the recommendation domain, and a possible direction to extend graph-based meta-learning is how to exploit higher-order information between nodes. The current studies primarily rely on pre-embedding methods to utilize user attributes, inadvertently overlooking the crucial co-occurrence patterns among users’ features. This oversight hinders the discovery of implicit connections between users. Furthermore, in scenarios of infrequent interactions, the reliance on initial edge information constrains connections between nodes in the same category. This constraint compromises the update capability of node embeddings, leading to reduced recommendation accuracy. In this paper, a meta-learning recommendation method with a dynamic node clustering knowledge graph (DCKG) is proposed. By introducing user attribute nodes and a triple-gated attention networks, this approach facilitates connections between users based on attribute relationships and enables the balancing of information across various pathways. Additionally, the integration of a dynamic aggregation module frees nodes of the same category from initial connection constraints, fostering more direct connections and further augmenting the propagation capability of higher-order information. The experimental results show that DCKG achieves the excellent results in the cold-start recommendation. DCKG can extend the use of higher-order features in the graph by direct connection.},
  archive      = {J_NEUCOM},
  author       = {Hui Pan and Senlin Luo and Xinshuai Li and Limin Pan and Zhouting Wu},
  doi          = {10.1016/j.neucom.2024.128192},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128192},
  shortjournal = {Neurocomputing},
  title        = {Meta-learning on dynamic node clustering knowledge graph for cold-start recommendation},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating instance-level knowledge to see the unseen: A
two-stream network for video object segmentation. <em>NEUCOM</em>,
<em>602</em>, 127878. (<a
href="https://doi.org/10.1016/j.neucom.2024.127878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing matching-based video object segmentation (VOS) approaches carry inherent limitations in segmenting pixels that have never appeared in the previous frames ( i.e. , unseen pixels). In this paper, we introduce a T wo- S tream N etwork (TSN), which addresses this issue by distinguishing between seen and unseen pixels softly and processes them with two streams. Particularly, a pixel division module is devised to generate a routing map, distinguishing between seen and unseen pixels. Guided by the routing map, TSN integrates instance-level knowledge from an instance stream and pixel-level information from a pixel stream explicitly, generating the final segmentation result. The soft partitioning strategy allows for flexibility and adaptability in the fusion process. Additionally, the compact instance stream encodes and leverages instance-level knowledge, resulting in improved segmentation accuracy of the unseen pixels. Extensive experiments demonstrate the effectiveness of our proposed TSN, and we also report state-of-the-art performance on public VOS benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Hannan Lu and Zhi Tian and Pengxu Wei and Haibing Ren and Wangmeng Zuo},
  doi          = {10.1016/j.neucom.2024.127878},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {127878},
  shortjournal = {Neurocomputing},
  title        = {Integrating instance-level knowledge to see the unseen: A two-stream network for video object segmentation},
  volume       = {602},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event-triggered impulsive tracking control for uncertain
strict-feedback nonlinear systems via the neural-network-based
backstepping technique. <em>NEUCOM</em>, <em>601</em>, 128240. (<a
href="https://doi.org/10.1016/j.neucom.2024.128240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of event-triggered impulsive tracking control (ETITC) for uncertain strict-feedback nonlinear systems (USFNSs). In contrast to existing impulsive control schemes, this paper incorporates the neural-network (NN)-based backstepping technique into impulsive control design, such that stronger nonlinearities and uncertainties are allowed to be included in the concerned systems. The proposed state-feedback ETITC scheme guarantees that all the signals of the closed-loop system are bounded and the tracking error ultimately converges to an adjustable bounded region, while also avoiding the Zeno behavior. In addition, by constructing a NN-based observer, this paper further develops an output-feedback ETITC scheme to extend its investigation to the scenario where full states are not available for impulsive control design. Finally, an illustrative example involving a chemical reactor system is presented to demonstrate the effectiveness of our control schemes.},
  archive      = {J_NEUCOM},
  author       = {Weihao Pan and Debao Fan and Hanfeng Li and Xianfu Zhang},
  doi          = {10.1016/j.neucom.2024.128240},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128240},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered impulsive tracking control for uncertain strict-feedback nonlinear systems via the neural-network-based backstepping technique},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prototypical contrastive learning based oriented detector
for kitchen waste. <em>NEUCOM</em>, <em>601</em>, 128239. (<a
href="https://doi.org/10.1016/j.neucom.2024.128239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic detection of kitchen waste enables the identification and quantification of non-degradable materials, such as plastics, metals, and other substances that cannot be easily decomposed. This approach increases the efficiency of the waste disposal process with significant time and cost savings compared to manual sorting. However, detecting non-degradable waste automatically presents a great challenge due to the deformability and directional uncertainty of the objects in kitchen waste images. Object deformation leads to a lack of structural features, making it more difficult to distinguish objects. Direction uncertainty leads to redundant backgrounds when detecting with the horizontal box detector. To address these issues, we propose a kitchen waste detector (KWDet) for the automatic detection of non-degradable waste in kitchen waste. First, the KWDet introduces the oriented bounding box representation and rotated region of interest (RRoI) learner, which enables the oriented detection of non-degradable waste in kitchen waste. Second, the KWDet constructs a prototypical contrastive learning (PCL) based detection head to improve the classification performance by learning discriminative features of different non-degradable waste in kitchen waste. In the PCL based detection head, the prototype-sample contrastive loss is proposed to pull samples and prototypes from the same classes together while pushing samples and prototypes from the different classes apart. After that, we design the inter-prototype contrastive loss to learn the discriminative prototypes of different non-degradable waste. Finally, to evaluate the proposed KWDet, we construct a large kitchen waste detection dataset (KWDD), containing 13,873 kitchen waste images and 213,565 instances collected from Zhengzhou China with 5 classes. To validate the effectiveness of our proposed method, we performed ablation experiments and comparison experiments on the KWDD dataset. The experiments demonstrate that KWDet achieves a state-of-the-art (SOTA) m A P 50 mAP50 of 71.5%, surpassing other object detection methods by more than 1.6% m A P 50 mAP50 . Furthermore, our approach’s Macro-F1 score outperforms the SOTA method by 4.0%. Extensive experiments on the KWDD demonstrate that the prototypical contrastive learning-based oriented detector is able to extract more robust features and better characterize the target location, suggesting that the KWDet is a powerful support for intelligent kitchen waste sorting.},
  archive      = {J_NEUCOM},
  author       = {Lihan Ouyang and Leyuan Fang and Qi Tang and Shuaiyu Ding and Junwu Yu and Jiaxing Lin and Lin Tang},
  doi          = {10.1016/j.neucom.2024.128239},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128239},
  shortjournal = {Neurocomputing},
  title        = {Prototypical contrastive learning based oriented detector for kitchen waste},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-stage image enhancement and dynamic feature
aggregation framework for gastroscopy image segmentation.
<em>NEUCOM</em>, <em>601</em>, 128228. (<a
href="https://doi.org/10.1016/j.neucom.2024.128228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable automatic segmentation of lesion areas in gastroscopy images can assist endoscopists in making diagnoses and reduce the possibility of missed or incorrect diagnoses. This paper presents a two-stage framework for segmenting gastroscopy images, which aims to improve the accuracy of medical image segmentation tasks using limited datasets. The proposed framework consists of two stages: the Image Enhancement Stage and the Lesion Segmentation Stage. First, in the Image Enhancement Stage, an image enhancement solution called TDC-Enhance is proposed to enrich the original small-scale gastroscopy image dataset. This solution performs Texture Enhancement, Detail Enhancement, and Color Enhancement on the original images. Then, in the Lesion Segmentation Stage, a multi-path automatic segmentation network for gastroscopy images, named DynaSiam, is introduced. DynaSiam comprises a Dependent Encoder, a Shared Encoder, and a Fusion Decoder. It learns feature information related to the lesion region by encoding the different enhanced images obtained in the Image Enhancement Stage as inputs to the multi-path network. Additionally, a Dynamic Feature Interaction (DFI) block is designed to capture and learn deeper image information, thereby improving the segmentation performance of the model. The experimental results show that the proposed method achieves a 90.80% mIoU, 92.71% Dice coefficient and 96.31% Accuracy. Other performance metrics also indicate the best performance, suggesting that the proposed model has significant potential for clinical analysis and diagnosis. Code and implementation details can be found on GitHub: https://github.com/kyasulee/DynaSiam .},
  archive      = {J_NEUCOM},
  author       = {Dongzhi He and Yunyu Li and Liule Chen and Yu Liang and Yongle Xue and Xingmei Xiao and Yunqi Li},
  doi          = {10.1016/j.neucom.2024.128228},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128228},
  shortjournal = {Neurocomputing},
  title        = {A two-stage image enhancement and dynamic feature aggregation framework for gastroscopy image segmentation},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual path features interaction network for efficient image
super-resolution. <em>NEUCOM</em>, <em>601</em>, 128226. (<a
href="https://doi.org/10.1016/j.neucom.2024.128226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image super-resolution (SR) is a crucial task in computer vision that involves reconstructing a low-resolution (LR) image into its high-resolution (HR) counterpart. Transformer-based methods excel at establishing long-range dependency but face challenges with high-complexity computations and capturing fine-grained features. Conversely, CNN-based methods are advantageous in capturing fine-grained features but are limited by fixed receptive fields. Additionally, most SR methods suffer from channel redundancy, leading to higher computational overhead. In this paper, we propose a Dual Path Features Interaction Network (DPFINet) to achieve efficient image SR, which consists of two components: a) To alleviate the issue of feature channel redundancy, a Local–Global Features Modeling (LGFM) method is newly proposed, which concurrently models global and local features by splitting features along different channels. In LGFM, a Shift Window Linear Attention (SWLA) layer is adopted to effectively capture global information through a large shift window based on the split features. Meanwhile, a Multi-Scale Detail Enhancement (MSDE) layer is designed, where the split other features are encoded to facilitate detail reconstruction through an interactive fusion of semantic and local information, thereby addressing the limitations of SWLA in capturing fine-grained features. b) A Cross-Level Features Interaction (CLFI) method is proposed to fuse global and local features modeled by different network structures (SWLA and MSDE), where a novel residual fusion mechanism is designed to preserve both global and local information while complementing each other. Extensive experiments demonstrate that our method outperforms most state-of-the-art SR methods on five benchmark datasets. Notably, during inference, our approach improves performance by 0.41 dB and reduces memory consumption by approximately 79% compared to DiVANet (Behjati et al., 2023) on the Manga109 ( × × 4) dataset.},
  archive      = {J_NEUCOM},
  author       = {Huimin Yang and Jingzhong Xiao and Ji Zhang and Yu Tian and Xuchuan Zhou},
  doi          = {10.1016/j.neucom.2024.128226},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128226},
  shortjournal = {Neurocomputing},
  title        = {Dual path features interaction network for efficient image super-resolution},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HHGNN: Hyperbolic hypergraph convolutional neural network
based on variational autoencoder. <em>NEUCOM</em>, <em>601</em>, 128225.
(<a href="https://doi.org/10.1016/j.neucom.2024.128225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a growing interest in the widespread application of graph neural networks (GNNs). However, existing GNN frameworks are predominantly designed for simple graphs in Euclidean space, limiting their effectiveness in handling scale-free graph-structured data that is multimodal and multiscale. Recently, there has been a surge in approaches using hyperbolic spaces to better model scale-free graphs and overcome the limitations of Euclidean space. Nevertheless, these methods face challenges in effectively handling hierarchical multimodal data. To address this gap and leverage multilevel aggregation for capturing high-order hidden information in local representations, we propose the Hyperbolic Hypergraph Convolutional Neural Network (HHGNN). This deep graph representation learning framework, based on Variational Autoencoder (VAE), maps scale-free graphs from Euclidean space to hyperbolic space. In HHGNN, we define the hypergraph convolutional neural networks in hyperbolic space. Furthermore, considering the multimodal nature of data representations, our model demonstrates strong scalability, currently supporting over ten data formats and capable of constructing hypergraph inputs for HHGNN training. Extensive benchmark experiments demonstrate the outstanding performance of HHGNN in node classification tasks, particularly on datasets with hierarchical structures, outperforming current methods. The experimental results also illustrate that our model effectively captures data distribution characteristics and enhances data representation capabilities. Additionally, we conduct an in-depth analysis of a diabetes dataset, aiming to support early diabetes diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Zhangyu Mei and Xiao Bi and Yating Wen and Xianchun Kong and Hao Wu},
  doi          = {10.1016/j.neucom.2024.128225},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128225},
  shortjournal = {Neurocomputing},
  title        = {HHGNN: Hyperbolic hypergraph convolutional neural network based on variational autoencoder},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Context-aware relational reasoning for video chunks and
frames overlapping in language-based moment localization.
<em>NEUCOM</em>, <em>601</em>, 128224. (<a
href="https://doi.org/10.1016/j.neucom.2024.128224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The language-based moment localization (LBML) goal is to locate the moment that corresponds to the input query, and output is the moment that matches with the input query. Due to erroneous correlations between various modalities, currently available methods for LBML frequently fail to distinguish between similar but perplexing overlap moments in an untrimmed video. In addition, long videos are incomprehensible, where the visual overlap during localization is challenging to interpret. In order to localize the correct moment, this paper attempts to identify critical video chunks and frames overlaps that cause network errors. We provide context-aware relational reasoning for video chunks and frames overlapping in language-based moment localization in untrimmed videos. We call our network Useful Overlap Moments Rectifier Network (UOMR-Net). Our UOMR-Net consists of three significant modules: prior to extracting the adjacent frames, we call it video chunks, the Query-Based Filtration module first identifies the useful and useless overlap video chunks and frames. It then refines the video chunk by combining it with the query global feature representation to get the semantics of the query that matches with the video chunk. Second, the Scene Context Overlap Distinguisher module it identifies which frame and video chunk has greater association with the input query, and further consist of two modules: (1) a video chunk overlapping separator and (2) frame overlapping separator. Third, Moment Localization and Contrastive Learning module that explains the context-aware relational reasoning behind the overlapping of the moments, and give us moment starting and ending boundaries as well. The Charades-STA, TaCos, and Activity-Net caption datasets demonstrate that our framework outperforms cutting-edge methods.},
  archive      = {J_NEUCOM},
  author       = {Hafiza Sadia Nawaz and Daming Shi and Munaza Nawaz},
  doi          = {10.1016/j.neucom.2024.128224},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128224},
  shortjournal = {Neurocomputing},
  title        = {Context-aware relational reasoning for video chunks and frames overlapping in language-based moment localization},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature boosting with efficient attention for scene parsing.
<em>NEUCOM</em>, <em>601</em>, 128222. (<a
href="https://doi.org/10.1016/j.neucom.2024.128222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity of scene parsing grows with the number of object and scene classes, which is higher in unrestricted open scenes. The biggest challenge is to model the spatial relation between scene elements while succeeding in identifying objects at smaller scales. This paper presents a novel feature-boosting network that gathers spatial context from multiple levels of feature extraction and computes the attention weights for each level of representation to generate the final class labels. A novel ‘channel attention module’ is designed to compute the attention weights, ensuring that features from the relevant extraction stages are boosted while the others are attenuated. The model also learns spatial context information at low resolution to preserve the abstract spatial relationships among scene elements and reduce computational cost. Spatial attention is subsequently concatenated into a final feature set before applying feature boosting. Low-resolution spatial attention features are trained using an auxiliary task that help to learn a coarse global scene structure. The proposed model outperforms all state-of-the-art models on both the ADE20K and the Cityscapes datasets.},
  archive      = {J_NEUCOM},
  author       = {Vivek Singh and Shailza Sharma and Fabio Cuzzolin},
  doi          = {10.1016/j.neucom.2024.128222},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128222},
  shortjournal = {Neurocomputing},
  title        = {Feature boosting with efficient attention for scene parsing},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fixed-time stability analysis of general impulsive systems
and application to synchronization of complex networks with hybrid
impulses. <em>NEUCOM</em>, <em>601</em>, 128218. (<a
href="https://doi.org/10.1016/j.neucom.2024.128218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the fixed-time stability of general impulsive systems and the fixed-time synchronization issue of impulsive complex networks are investigated. First, the fixed-time stability of a class of nonlinear systems with general impulsive effects is analyzed by means of inequality method and using some special functions. Then, the developed fixed-time stability results are used to study the fixed-time synchronization of impulsive complex networks under the saturation controller. Compared with some early published works, in this paper, the estimation accuracy of settling time is improved by calculating the value of improper integral more precisely, and the saturation controller effectively suppresses chattering phenomenon caused by discontinuous signum function. Lastly, some numerical examples are given to verify the feasibility of our theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Qihang Wang and Abdujelil Abdurahman},
  doi          = {10.1016/j.neucom.2024.128218},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128218},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time stability analysis of general impulsive systems and application to synchronization of complex networks with hybrid impulses},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synergistic insights: Exploring continuous learning and
explainable AI in handwritten digit recognition. <em>NEUCOM</em>,
<em>601</em>, 128217. (<a
href="https://doi.org/10.1016/j.neucom.2024.128217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks achieve outstanding results; however, their reliance on a static environment with fixed data poses challenges in dynamic scenarios where data continuously evolves. Being capable of learning, adapting, and generalizing continually in a scalable, successful, and efficient manner is crucial for the sustainable development of AI systems. The classical solution of retraining the model using both old and new data is time-consuming and expensive. Continual Learning tackles the problem of learning new data distributions without the need for retraining from scratch. Furthermore, the task of recognizing unlabeled images using previously acquired knowledge becomes challenging, particularly when the new data needs to be incrementally annotated without starting the training process from scratch. To gain a deeper understanding of how “Black Box” neural networks make decisions, it is important to visualize components inside the model that affect the error rate throughout the decision-making process. The Continual Self-Learning model on label-less historical digits yields increasingly perceptive interpretations. This paper aims to establish a literature review of the latest advances in continual learning for computer vision tasks, to articulate catastrophic forgetting using Explainable Artificial Intelligence on both split MNIST and the historical digit dataset DIDA, and to shed light on important but still understudied topics.},
  archive      = {J_NEUCOM},
  author       = {Asma Kharrat and Fadoua Drira and Franck Lebourgeois and Bertrand kerautret},
  doi          = {10.1016/j.neucom.2024.128217},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128217},
  shortjournal = {Neurocomputing},
  title        = {Synergistic insights: Exploring continuous learning and explainable AI in handwritten digit recognition},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trainable pruned ternary quantization for medical signal
classification models. <em>NEUCOM</em>, <em>601</em>, 128216. (<a
href="https://doi.org/10.1016/j.neucom.2024.128216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of deep learning is renowned for its resource-intensive nature, hence improving its environmental impact is crucial. In this paper, we propose a novel model compression method to mitigate the energy demands of deep learning for a greener, and more sustainable AI landscape. Our approach relies on an asymmetric weakly-differentiable pruning function that leverages weight statistics to directly incorporate adaptable pruning into the quantization mechanism. This enables us to achieve higher compression rates globally while simultaneously reducing energy consumption and minimizing classification performance degradation. The efficacy of our approach was evaluated using three distinct models on three distinct datasets: cerebral emboli (HITS), epileptic seizure recognition (ESR), and MNIST. Our method demonstrated a superior balance between compression, energy consumption, and classification performance compared to other state-of-the-art extreme quantization methods, across all models and datasets. In fact, on the HITS dataset with a two-dimensional convolutional neural network, we achieved strong gains of 50.6%, 54.9%, 52.1% in compression rates (of the global model and the quantized layers only, respectively) and energy consumption, respectively, while improving the Matthews correlation coefficient by 2.5% compared to other approaches. The code is available at: https://github.com/yamilvindas/pTTQ .},
  archive      = {J_NEUCOM},
  author       = {Yamil Vindas and Blaise Kévin Guépié and Marilys Almar and Emmanuel Roux and Philippe Delachartre},
  doi          = {10.1016/j.neucom.2024.128216},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128216},
  shortjournal = {Neurocomputing},
  title        = {Trainable pruned ternary quantization for medical signal classification models},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CrowdUNet: Segmentation assisted u-shaped crowd counting
network. <em>NEUCOM</em>, <em>601</em>, 128215. (<a
href="https://doi.org/10.1016/j.neucom.2024.128215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the end of the COVID-19 pandemic, the number of pedestrians in various public places has increased dramatically. Estimating the size and density distribution of crowds accurately from images is essential for public safety. At present, there are still many factors that limit the accuracy of dense crowd counting, such as perspective distortion, background clutter and heavy occlusion. To be capable of accurately estimating the crowd size in RGB images, we propose a crowd counting network called CrowdUNet, which is assisted by a segmentation task. It applies the segmentation results to the crowd counts, making the network more focused on the prediction of foreground regions. We combine Swin Transformer Block and CNN to build a Swin Transformer Convolution(STC) module to extract deep semantic features. We analyze the characteristics of crowd images and propose a novel decoder structure called Coordinate Decoder(CD), which better aggregates low and high level features and improve the robustness of the network. In order to obtain accurate regression results, we also propose a regression head with multi-scale receptive fields, which is called Spatial Pyramid Convolution (SPC). Extensive experiments on four challenging crowd counting datasets namely ShanghaiTech A, ShanghaiTech B, UCF p=CC 50, and UCF-QNRF have validated the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Zhou Cao and Lei Lyu and Ran Qi and Jihua Wang},
  doi          = {10.1016/j.neucom.2024.128215},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128215},
  shortjournal = {Neurocomputing},
  title        = {CrowdUNet: Segmentation assisted U-shaped crowd counting network},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incipient fault detection based on dense feature ensemble
net. <em>NEUCOM</em>, <em>601</em>, 128211. (<a
href="https://doi.org/10.1016/j.neucom.2024.128211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With modern industrial processes becoming more and more complex, the occurrence of faults may cause unmitigated disaster. Therefore, incipient fault detection is very important and has attracted increasing attention Recently, a feature ensemble net (FENet) has been proposed based on a deep feature ensemble framework, which can detect partial notorious faults (such as faults 3, 9 and 15 in the Tennessee Eastman process (TEP)). However, the feature transformer layers in FENet can only mine the process information from the upper layer’s output rather than all features from previous layers. Therefore, a novel dense feature ensemble net (DenseFENet) is proposed to deeply extract the features of data for incipient fault detection in industrial process. DenseFENet firstly constructs base detectors with capabilities for extracting nonlinear features, such as one-class support vector machine, isolation forest, one-class back propagation neural network, one-class long short term memory network and one-class temporal convolutional network, etc. Then, a dense net structure with short paths between non-adjacent feature transformer layers is developed, improving the reutilization capability for shallow knowledge. In addition, a numerical simulation and TEP are adopted to demonstrate the performance of the proposed method. The fault detection rate of DenseFENet has improved by 5.05% and 3.27% correspondingly, revealing the superiority of this approach.},
  archive      = {J_NEUCOM},
  author       = {Min Wang and Feiyang Cheng and Kai Chen and Gen Qiu and Yuhua Cheng and Maoyin Chen},
  doi          = {10.1016/j.neucom.2024.128211},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128211},
  shortjournal = {Neurocomputing},
  title        = {Incipient fault detection based on dense feature ensemble net},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dual laplacian framework with effective graph learning for
unified fair spectral clustering. <em>NEUCOM</em>, <em>601</em>, 128210.
(<a href="https://doi.org/10.1016/j.neucom.2024.128210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of spectral clustering under group fairness constraints, where samples from each sensitive group are approximately proportionally represented in each cluster. Traditional fair spectral clustering (FSC) methods consist of two consecutive stages, i.e., performing fair spectral embedding on a given graph and conducting k k means to obtain discrete cluster labels. However, in practice, the graph is usually unknown, and we need to construct the underlying graph from potentially noisy data, the quality of which inevitably affects subsequent fair clustering performance. Furthermore, performing FSC through separate steps breaks the connections among these steps, leading to suboptimal results. To this end, we first theoretically analyze the effect of the constructed graph on FSC. Motivated by the analysis, we propose a novel graph construction method with a node-adaptive graph filter to learn graphs from noisy data. Then, all independent stages are integrated into a single objective function via a dual Laplacian framework, forming an end-to-end model that inputs raw data and outputs discrete cluster labels. An algorithm is developed to jointly and alternately update the variables in each stage. Finally, we conduct extensive experiments on synthetic, benchmark, and real data, which show that our model is superior to state-of-the-art fair clustering methods.},
  archive      = {J_NEUCOM},
  author       = {Xiang Zhang and Qiao Wang},
  doi          = {10.1016/j.neucom.2024.128210},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128210},
  shortjournal = {Neurocomputing},
  title        = {A dual laplacian framework with effective graph learning for unified fair spectral clustering},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attention-based acoustic feature fusion network for
depression detection. <em>NEUCOM</em>, <em>601</em>, 128209. (<a
href="https://doi.org/10.1016/j.neucom.2024.128209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression, a common mental disorder, significantly influences individuals and imposes considerable societal impacts. The complexity and heterogeneity of the disorder necessitate prompt and effective detection, which nonetheless, poses a difficult challenge. This situation highlights an urgent requirement for improved detection methods. Exploiting auditory data through advanced machine learning paradigms presents promising research directions. Yet, existing techniques mainly rely on single-dimensional feature models, potentially neglecting the abundance of information hidden in various speech features. To rectify this, we present the novel Attention-Based Acoustic Feature Fusion Network (ABAFnet) for depression detection. ABAFnet combines four different acoustic features into a comprehensive deep neural network, thereby effectively integrating and blending multi-tiered features. We present a novel Type-Adaptive CNN for feature process, a LSTM-Attention Mechanism for features’ temporal–spatial computation, and a Dynamic Weight Adjustment module for Linear Late Fusion Network that boosts performance by efficaciously synthesizing these features. The effectiveness of our approach is confirmed via extensive validation on two novel speech databases, CNRAC and CS-NRAC, thereby outperforming previous methods in depression detection and subtype classification. Further in-depth analysis confirms the key role of each feature and highlights the importance of MFCC-related features in speech-based depression detection (SDD).},
  archive      = {J_NEUCOM},
  author       = {Xiao Xu and Yang Wang and Xinru Wei and Fei Wang and Xizhe Zhang},
  doi          = {10.1016/j.neucom.2024.128209},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128209},
  shortjournal = {Neurocomputing},
  title        = {Attention-based acoustic feature fusion network for depression detection},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Targeted context attack for object detection.
<em>NEUCOM</em>, <em>601</em>, 128208. (<a
href="https://doi.org/10.1016/j.neucom.2024.128208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to the untargeted attack, the targeted attack is a more challenging task in the field of adversarial attacks for object detection, because it aims to mislead the detectors to predict certain specific wrong labels rather than arbitrary labels. The existing targeted attack methods are primarily implemented by maximizing the classification score of the target object, resulting in poor attack performance, especially in the case of a large gap between the correct label and the specified wrong label of the victim object. Considering the significant impact of contextual information on object detection, it is difficult to mislabel the victim object to a designated object which has low association with the original context. Therefore, we design a classification network to model the contextual information and propose a Targeted Context Attack method which changes not only the classification score of the victim object itself, but also the score of its context. The extensive experiments on MS COCO and VOC datasets using YOLOv3 and Faster RCNN show that the targeted context attack largely improves the fooling rate of targeted attack for object detection in terms of both white-box and black-box cases, even if the target object is totally dissimilar with the victim object. Specifically, the proposed attack method at most achieves a 21.8% improvement in the fooling rate for attacking YOLOv3.},
  archive      = {J_NEUCOM},
  author       = {Changfeng Sun and Xuchong Zhang and Haoliang Han and Hongbin Sun},
  doi          = {10.1016/j.neucom.2024.128208},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128208},
  shortjournal = {Neurocomputing},
  title        = {Targeted context attack for object detection},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predictive resilience assessment of road networks based on
dynamic multi-granularity graph neural network. <em>NEUCOM</em>,
<em>601</em>, 128207. (<a
href="https://doi.org/10.1016/j.neucom.2024.128207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the influence of global climate anomalies, abnormal weather conditions such as heavy rainfall have become more frequent in recent years, posing a significant threat to the operation of transportation systems. An effective assessment of the resilience of the transportation system before and during heavy rain can alert the transportation department to take necessary emergency actions. However, existing methods for assessing the rainfall resilience of transportation networks mostly suffer from the following problems: (1) Simulation methods for modeling rainfall impacts lack realism; (2) After-the-fact evaluations of resilience cannot offer advance warning prior to or during a heavy rain event. To address above problems, we present a novel resilience assessment methodology for evaluating the resilience of road networks in real-time during heavy rainfall scenarios. In this methodology, we propose the temporal decomposition-based dynamic multi-granularity graph neural network (TD2MG2NN) for long-term traffic speed forecasting, providing a perspective on the future evolution of traffic states for accurate resilience assessment. In addition, we construct a composite traffic resilience indicator, designed to comprehensively reflect changes in the spatial–temporal resilience of the transportation system during heavy rain. Experimental results on four publicly real datasets indicate that the prediction performance of TD2MG2NN outperforms state-of-the-art models. The assessment results for the transportation road network in California demonstrate that the comprehensive resilience indicator is superior to single functional resilience indicator and the real-time methodology for evaluating resilience can accurately depict and predict the operation of the road network system under heavy rainfall scenarios.},
  archive      = {J_NEUCOM},
  author       = {Di Zang and Yongjie Ding and Jiayi Zhao and Keshuang Tang and Hong Zhu},
  doi          = {10.1016/j.neucom.2024.128207},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128207},
  shortjournal = {Neurocomputing},
  title        = {Predictive resilience assessment of road networks based on dynamic multi-granularity graph neural network},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explicit 3D reconstruction from images with dynamic graph
learning and rendering-guided diffusion. <em>NEUCOM</em>, <em>601</em>,
128206. (<a href="https://doi.org/10.1016/j.neucom.2024.128206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-quality 3D reconstruction is becoming increasingly important in a variety of fields. Recently, implicit representation methods have made significant progress in image-based 3D reconstruction. However, these methods tend to yield entangled neural representations which lack support for standard 3D pipelines, and their reconstruction results usually experience a sharp drop in quality when input views are reduced. To obtain high-quality 3D content, we propose an explicit 3D reconstruction method that directly extracts textured meshes from images and remains robust using reduced input views. Our central components include a dynamic graph convolutional network (GCN) and a rendering-guided diffusion model. The dynamic GCN aims to improve mesh reconstruction quality by effectively aggregating features from vertex neighborhoods. The aggregation is accelerated through sampling geometric-related neighbors with different SDF signs, which gradually converges in quantity during training. The rendering-guided diffusion model learns prior distributions for unseen regions to improve reconstruction performance using sparse-view inputs. It uses the rendered image under an interpolated camera pose as conditioned input and its diffusion strength can be controlled with the rendering loss of explicit reconstruction. In addition, the rendering-guided diffusion model can be jointly trained to generate plausible novel views with 3D consistency. Experiments demonstrate that our method can produce high-quality explicit reconstruction results and maintain realistic reconstruction using sparse-view inputs.},
  archive      = {J_NEUCOM},
  author       = {Di Wu and Linli Zhou and JinCheng Li and Jianqiao Xiong and Liangtu Song},
  doi          = {10.1016/j.neucom.2024.128206},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128206},
  shortjournal = {Neurocomputing},
  title        = {Explicit 3D reconstruction from images with dynamic graph learning and rendering-guided diffusion},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adversarially deep interative-fused embedding clustering via
joint self-supervised networks. <em>NEUCOM</em>, <em>601</em>, 128205.
(<a href="https://doi.org/10.1016/j.neucom.2024.128205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of deep convolutional networks, attributed graph clustering has become an increasingly important and challenging research area. In the field of graph clustering, more and more researchers have recognized the role of content information and structural information in the clustering process. However, existing methods often overlook potential issues that may arise during the fusion of content and structural information, such as incomplete structural information or missing content information. These issues have led to bottlenecks in clustering performance, making improvements challenging. Furthermore, most of the methods focus on minimizing the reconstruction error of the graph structure, ignoring the embedding distribution of deep representations, which may result in inferior representations. To address these challenges, in this paper, we innovatively introduce an adversarial regularized deep embedding clustering method based on dual interative-fusion and joint self-supervised networks, called AIJSS. Specifically, we utilize interative fusion techniques to deeply integrate structural and content information across network layers. Moreover, a triple self-supervised module is introduced for joint optimization to achieve consistent and superior embedding representations. We also design an adversarial graph embedding module to learn effective embedding representation to enhance the robustness of clustering. Extensive experiments on six benchmark datasets demonstrate that our proposed AIJSS method achieves significant improvements over current state-of-the-art methods, highlighting its innovation and forward-looking nature in the field of deep graph clustering. Our code is publicly available at https://github.com/sliboo/AIJSS .},
  archive      = {J_NEUCOM},
  author       = {Yafang Li and Xiumin Lin and Caiyan Jia and Baokai Zu and Shaotao Zhu},
  doi          = {10.1016/j.neucom.2024.128205},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128205},
  shortjournal = {Neurocomputing},
  title        = {Adversarially deep interative-fused embedding clustering via joint self-supervised networks},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interpretability of deep neural networks: A review of
methods, classification and hardware. <em>NEUCOM</em>, <em>601</em>,
128204. (<a href="https://doi.org/10.1016/j.neucom.2024.128204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence, and especially deep neural networks, have evolved substantially in the recent years, infiltrating numerous domains of applications, often greatly impactful to society’s well-being. As a result, the need to understand how these models operate in depth and to access explanations of their decisions has become more vital than ever. Tending to this demand, the following paper aims to provide a thorough overview of the methods that have so far been developed to explain deep neural networks. Key aspects of explainability are defined and a straightforward classification of existing approaches is introduced, along with numerous examples. The task of realizing these methods on hardware is also discussed to complete the understanding of their application.},
  archive      = {J_NEUCOM},
  author       = {Thanasis Antamis and Anastasis Drosou and Thanasis Vafeiadis and Alexandros Nizamis and Dimosthenis Ioannidis and Dimitrios Tzovaras},
  doi          = {10.1016/j.neucom.2024.128204},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128204},
  shortjournal = {Neurocomputing},
  title        = {Interpretability of deep neural networks: A review of methods, classification and hardware},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A swarm exploring neural dynamics method for solving convex
multi-objective optimization problem. <em>NEUCOM</em>, <em>601</em>,
128203. (<a href="https://doi.org/10.1016/j.neucom.2024.128203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective optimization problem (MOP) plays an increasingly important role in finance and engineering. In order to obtain more accurate and evenly distributed target solution set to a multi-objective programming, a novel swarm exploring neural dynamics (SEND) method is proposed, analyzed and applied in this paper. Specifically, a scalarization approach is firstly applied to transform the MOP into a group of subproblems. Secondly, each subproblem is solved by a varying parameter recurrent neural network (VP-RNN). By solving these problems, a group of Pareto optimal solutions are obtained. Thirdly, a population evolution weight optimization algorithm is used to diversify the solution set to obtain evenly distributed solutions. Simulation results demonstrate that the proposed SEND method can obtain a more accurate and evenly distributed solution set than some previous methods and the convergence rate is faster than the state-of-art methods, such as collaborative neurodynamic approach (CNA).},
  archive      = {J_NEUCOM},
  author       = {Zhijun Zhang and Haomin Yu and Xiaohui Ren and Yamei Luo},
  doi          = {10.1016/j.neucom.2024.128203},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128203},
  shortjournal = {Neurocomputing},
  title        = {A swarm exploring neural dynamics method for solving convex multi-objective optimization problem},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differentiable gated autoencoders for unsupervised feature
selection. <em>NEUCOM</em>, <em>601</em>, 128202. (<a
href="https://doi.org/10.1016/j.neucom.2024.128202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature selection (UFS) aims to identify a subset of the most informative features from high-dimensional data without labels. However, most existing UFS methods cannot adequately capture the intricate nonlinear relationships present in high-dimensional data, limiting their ability to obtain meaningful features. In this letter, we propose a novel UFS model that leverages the autoencoder with a differentiable gating function to address this limitation. Our model optimizes a bi-level loss function to automatically select a subset of informative and stable features by capturing the nonlinear interactions between features. Furthermore, we leverage the continuous relaxation of the Bernoulli distribution to parameterize stochastic gates, thereby enabling the learning of a relaxed model through a low-variance gradient estimator. The proposed model does not necessitate prior knowledge or domain-specific tuning, making it a versatile and widely applicable method. Extensive experiments on 13 benchmark datasets demonstrate the effectiveness and superiority of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Zebin Chen and Jintang Bian and Bo Qiao and Xiaohua Xie},
  doi          = {10.1016/j.neucom.2024.128202},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128202},
  shortjournal = {Neurocomputing},
  title        = {Differentiable gated autoencoders for unsupervised feature selection},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Robust iterative learning control for discrete-time systems
with random initial state shifts. <em>NEUCOM</em>, <em>601</em>, 128201.
(<a href="https://doi.org/10.1016/j.neucom.2024.128201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the sufficient conditions of the stability for discrete-time systems with random initial state shifts when applying iterative learning control. Different sufficient conditions have been developed for systems with different characteristics to ensure boundedness of tracking errors and convergence of the learning process under random initial condition. First, the relationship between the initial shifts of two adjacent iterations is addressed with the help of the transition matrix. And the different analysis models are established for each type of systems: one-dimensional matrix analysis model and 2-D Roesser model. Second, the new and sufficient conditions are established for the proposed learning control law to ensure systems convergence by matrix theory and two-dimensional system theory. Third, solving the linear matrix inequality (LMI) yields the control gains. Finally, digital simulations illustrate the effectiveness and sufficiency of the presented conditions.},
  archive      = {J_NEUCOM},
  author       = {Guojun Li and Tiantian Lu and Yingsheng Fan and Dongjie Chen},
  doi          = {10.1016/j.neucom.2024.128201},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128201},
  shortjournal = {Neurocomputing},
  title        = {Robust iterative learning control for discrete-time systems with random initial state shifts},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Understanding mobile GUI: From pixel-words to
screen-sentences. <em>NEUCOM</em>, <em>601</em>, 128200. (<a
href="https://doi.org/10.1016/j.neucom.2024.128200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ubiquity of mobile phones makes mobile GUI understanding an important task. Most previous works in this domain require human-created metadata of screens (e.g. View Hierarchy) during inference, which unfortunately is often not available or reliable enough for GUI understanding. Inspired by the impressive success of Transformers in NLP tasks, targeting for purely vision-based GUI understanding, we extend the concepts of Words / Sentence to Pixel-Words / Screen-Sentence , and propose a mobile GUI understanding architecture: Pixel-Words to Screen-Sentence (PW2SS). In analogy to the individual Words , we define the Pixel-Words as atomic visual components (text and graphic components), which are visually consistent and semantically clear across screenshots of a large variety of design styles. The Pixel-Words extracted from a screenshot are aggregated into Screen-Sentence with a Screen Transformer proposed to model their relations. Since the Pixel-Words are defined as atomic visual components, the ambiguity between their visual appearance and semantics is dramatically reduced. We are able to make use of metadata available in training data to auto-generate high-quality annotations for Pixel-Words . A dataset, RICO-PW, of screenshots with Pixel-Words annotations is built based on the public RICO dataset, which will be released to help to address the lack of high-quality training data in this area. We train a detector to extract Pixel-Words from screenshots on this dataset and achieve metadata-free GUI understanding during inference. We conduct experiments and show that Pixel-Words can be well extracted on RICO-PW and well generalized to a new dataset, P2S-UI, collected by ourselves. The effectiveness of PW2SS is further verified in the GUI understanding tasks including relation prediction, clickability prediction, screen retrieval, and app type classification.},
  archive      = {J_NEUCOM},
  author       = {Jingwen Fu and Xiaoyi Zhang and Yuwang Wang and Wenjun Zeng and Nanning Zheng},
  doi          = {10.1016/j.neucom.2024.128200},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128200},
  shortjournal = {Neurocomputing},
  title        = {Understanding mobile GUI: From pixel-words to screen-sentences},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive neural event-dependent intermittent fault-tolerant
control of reaction–diffusion multi-agent systems. <em>NEUCOM</em>,
<em>601</em>, 128199. (<a
href="https://doi.org/10.1016/j.neucom.2024.128199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article employs an event-dependent intermittent fault-tolerant control approach to address the adaptive consensus of reaction–diffusion multi-agent systems under directed topologies in both leaderless and leader-following networks. Initially, an event-dependent intermittent control mechanism is proposed to determine the work/rest time, relying on three partitions of the non-negative real region and the formulated Lyapunov function. Subsequently, under the introduced control mechanism, an adaptive consensus protocol is established, incorporating the updating law for adaptive coupling strength and adaptive weight estimation. Utilizing the neural network estimation theorem for fault estimation, the article presents explicit criteria to ensure the attainment of leaderless or leader-following consensus in reaction–diffusion multi-agent systems. Finally, two numerical simulation experiments are conducted to validate the robustness and effectiveness of the derived theorem.},
  archive      = {J_NEUCOM},
  author       = {Renlong Hu and Jianwen Feng and Jingyi Wang and Xiaoli Ruan and Jiayi Cai},
  doi          = {10.1016/j.neucom.2024.128199},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128199},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural event-dependent intermittent fault-tolerant control of reaction–diffusion multi-agent systems},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From a-to-z review of clustering validation indices.
<em>NEUCOM</em>, <em>601</em>, 128198. (<a
href="https://doi.org/10.1016/j.neucom.2024.128198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data clustering involves identifying latent similarities within a dataset and organizing them into clusters or groups. The outcomes of various clustering algorithms differ as they are susceptible to the intrinsic characteristics of the original dataset, including noise and dimensionality. The effectiveness of such clustering procedures directly impacts the homogeneity of clusters, underscoring the significance of evaluating algorithmic outcomes. Consequently, the assessment of clustering quality presents a significant and complex endeavor. A pivotal aspect affecting clustering validation is the cluster validity metric, which aids in determining the optimal number of clusters. The main goal of this study is to comprehensively review and explain the mathematical operation of internal and external cluster validity indices, but not all, to categorize these indices and to brainstorm suggestions for future advancement of clustering validation research. In addition, we review and evaluate the performance of internal and external clustering validation indices on the most common clustering algorithms, such as the evolutionary clustering algorithm star (ECA*). Finally, we suggest a classification framework for examining the functionality of both internal and external clustering validation measures regarding their ideal values, user-friendliness, responsiveness to input data, and appropriateness across various fields. This classification aids researchers in selecting the appropriate clustering validation measure to suit their specific requirements.},
  archive      = {J_NEUCOM},
  author       = {Bryar A. Hassan and Noor Bahjat Tayfor and Alla A. Hassan and Aram M. Ahmed and Tarik A. Rashid and Naz N. Abdalla},
  doi          = {10.1016/j.neucom.2024.128198},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128198},
  shortjournal = {Neurocomputing},
  title        = {From A-to-Z review of clustering validation indices},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Cross-region feature fusion with geometrical relationship
for OCR-based image captioning. <em>NEUCOM</em>, <em>601</em>, 128197.
(<a href="https://doi.org/10.1016/j.neucom.2024.128197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatically generating a readable sentence that describes the text-contained image is a challenging task. Compared to traditional image captioning algorithms, OCR-based image captioning focuses on reading OCR tokens in images and understanding them with the image content to generate descriptions. However, existing research mainly concentrate on improving the quantity and quality of obtaining OCR tokens and exploring their spatial relationships while lacking investigation into how to effectively join OCR tokens with image content. This paper proposes a cross-region feature fusion with a geometrical relationship Transformer(CFGR-Transformer) for OCR-based image captioning. The network first establishes the associations between the OCR and object regions of the image by constructing relative geometric relationships, including width/height difference, distance, IOU(Intersection over Union), inclusion relationships, and angles offset, and then incorporates intra-region and cross-region features to aggregate entities from different modalities by a multi-head attention mechanism based on relative relationships. Benefiting from the guidance of the relative relationship, visual entities like OCR tokens and object regions can consider multiple relative relationships as the attention weight for feature fusion within each subspace. Extensive experiments conducted on the TextCaps dataset demonstrate the effectiveness of the proposed CFGR-Transformer method. In particular, our results on the online testing of TextCaps achieve an improvement in CIDEr score from 93.0% to 98.2%.},
  archive      = {J_NEUCOM},
  author       = {Jinfei Zhou and Cheng Yang and Yaping Zhu and Yana Zhang},
  doi          = {10.1016/j.neucom.2024.128197},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128197},
  shortjournal = {Neurocomputing},
  title        = {Cross-region feature fusion with geometrical relationship for OCR-based image captioning},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revisiting 3D visual grounding with context-aware feature
aggregation. <em>NEUCOM</em>, <em>601</em>, 128195. (<a
href="https://doi.org/10.1016/j.neucom.2024.128195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D visual grounding is the task of accurately locating objects in a three-dimensional scene based on textual descriptions. Current approaches mainly depend on downsampling and extracting the point features for fusion with text features. However, the main challenges of these methods are the poor point feature resolution and limited local context during multi-modal fusion, causing visual-linguistic misalignment, particularly for small objects described in the text. The intuitive solution is to get additional object-related point features, gathering more contextual information to augment the representation capability of multimodal features, thereby promoting the representation capabilities of multimodal features. Based on this, we introduce a novel 3D visual grounding framework named Context-aware Feature Aggregation (CFA). The CFA framework includes two key modules: (1) Point Augmented Aggregation Module (PAM), designed to compensate for downsampling-induced information loss by augmenting sampled points with neighboring context for more discriminative features; and (2) Dual Contextual Grouping Attention Module (DCGAM), which iteratively refines features and geometry coordinates from PAM, capturing more global context. We assess the performance of our CFA framework on two point-based datasets: ScanRefer and Nr3D/Sr3D. The CFA framework exhibits efficiency in 3D visual grounding, surpassing the performance of previous methods by experimental results.},
  archive      = {J_NEUCOM},
  author       = {Peng Guo and Hongyuan Zhu and Hancheng Ye and Taihao Li and Tao Chen},
  doi          = {10.1016/j.neucom.2024.128195},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128195},
  shortjournal = {Neurocomputing},
  title        = {Revisiting 3D visual grounding with context-aware feature aggregation},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Concept accumulation and gradient-guided adaption for
continual learning in evolving streaming. <em>NEUCOM</em>, <em>601</em>,
128194. (<a href="https://doi.org/10.1016/j.neucom.2024.128194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning algorithms in modern information systems often operate in dynamic environments where data is collected as transient data streams. Processing data streams imposes new computational requirements on algorithms compared to static data mining, as they need to incrementally process incoming examples within limited memory and time constraints. Existing methods based on deep neural networks and ensemble learning suffer from catastrophic forgetting when concepts drift and struggle to rapidly learn from infinite data without increasing computational resources. To address these problems, we propose a two-level hybrid framework, called Concept Accumulation and Gradient-Guided Adaption learning (CAGGA), which ensembles individual classifiers with neural networks for evolving streaming classification. In base-level, this approach utilizes a chunk-mode detector to detect drift and reusable base classifiers to alleviate memory growth and catastrophic forgetting. The meta-level neural network acquires cross-task and cross-classifier knowledge to learn meta-knowledge from previous tasks. By preserving gradient changes and meta-knowledge during learning, the network can quickly converge, requiring fewer instances to recover from concept drift. The experiments were conducted to compare our method with eight well-known streaming classifiers on various types of data streams, showcasing its competitive predictive performance and its efficiency in terms of runtime and memory usage.},
  archive      = {J_NEUCOM},
  author       = {Lin Xiong and Shanxiong Chen and Hao Zhou and Hailing Xiong},
  doi          = {10.1016/j.neucom.2024.128194},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128194},
  shortjournal = {Neurocomputing},
  title        = {Concept accumulation and gradient-guided adaption for continual learning in evolving streaming},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new adaptive elastic loss for robust unsupervised feature
selection. <em>NEUCOM</em>, <em>601</em>, 128191. (<a
href="https://doi.org/10.1016/j.neucom.2024.128191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sparse-based unsupervised dimension reduction technique has been demonstrated to be an effective tool for dealing with high-dimensional data. Among them, the sparse regularization technique is used to introduce the prior knowledge of the model and helps unsupervised dimension reduction algorithms to complete the feature selection. However, the sparse regularization only considers the sparsity of representation. It ignores the group effect of variables among which the pairwise correlations are very high. To solve these issues, we present a novel regularization approach based on adaptive elastic loss in this study. Then, utilizing the regularization method, an efficient unsupervised feature selection methodology is given. Additionally, we devise an efficient alternative optimization algorithm to resolve the complex optimization issue of our proposed method and conduct a theoretical analysis of its computational complexity and convergence. Eventually, we conduct comprehensive experiments to test the validity of our proposed method, and real-world data and a simulation study demonstrate that our proposed method outperforms many state-of-the-art unsupervised feature selection methods in terms of clustering and classification.},
  archive      = {J_NEUCOM},
  author       = {Jinyan Pan and Youwei Xie and Xinjing Wang and Haifeng Zhang and Chao Cao and Yunlong Gao},
  doi          = {10.1016/j.neucom.2024.128191},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128191},
  shortjournal = {Neurocomputing},
  title        = {A new adaptive elastic loss for robust unsupervised feature selection},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spiking neural networks in the alexiewicz topology: A new
perspective on analysis and error bounds. <em>NEUCOM</em>, <em>601</em>,
128190. (<a href="https://doi.org/10.1016/j.neucom.2024.128190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to ease the analysis of error propagation in neuromorphic computing and to get a better understanding of spiking neural networks (SNN), we address the problem of mathematical analysis of SNNs as endomorphisms that map spike trains to spike trains. A central question is the adequate structure for a space of spike trains and its implication for the design of error measurements of SNNs including time delay, threshold deviations, and the design of the reinitialization mode of the leaky-integrate-and-fire (LIF) neuron model. First, we identify the underlying topology by analyzing the closure of all sub-threshold signals of a LIF model. For zero leakage this approach yields the Alexiewicz topology, which we adopt to LIF neurons with arbitrary positive leakage. As a result, LIF can be understood as spike train quantization in the corresponding norm. This way we obtain various error bounds and inequalities such as a quasi-isometry relation between incoming and outgoing spike trains. Another result is a Lipschitz-style global upper bound for the error propagation and a related resonance-type phenomenon.},
  archive      = {J_NEUCOM},
  author       = {Bernhard A. Moser and Michael Lunglmayr},
  doi          = {10.1016/j.neucom.2024.128190},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128190},
  shortjournal = {Neurocomputing},
  title        = {Spiking neural networks in the alexiewicz topology: A new perspective on analysis and error bounds},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Corrigendum to “max–min robust principal component
analysis” [neurocomputing 521 (2023) 89–98]. <em>NEUCOM</em>,
<em>601</em>, 128189. (<a
href="https://doi.org/10.1016/j.neucom.2024.128189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Sisi Wang and Feiping Nie and Zheng Wang and Rong Wang and Xuelong Li},
  doi          = {10.1016/j.neucom.2024.128189},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128189},
  shortjournal = {Neurocomputing},
  title        = {Corrigendum to “Max–min robust principal component analysis” [Neurocomputing 521 (2023) 89–98]},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Output feedback adaptive neural network control for
uncertain nonsmooth systems with application. <em>NEUCOM</em>,
<em>601</em>, 128185. (<a
href="https://doi.org/10.1016/j.neucom.2024.128185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The output feedback adaptive neural network control problem is addressed for uncertain nonsmooth systems with network communication constraints. First, a funnel function is provided to ensure that the tracking error restrains the pre-specified performance and improves the transient and steady-state performance simultaneously. Second, an event-triggered controller including the control input, a fixed threshold and the tracking error is designed to alleviate the communication burden. It is rigorously mathematically proved that there exists a positive lower bound to avoid the Zeno behavior. With the designed observer, the control algorithm assures that all the signals are semi-globally uniformly ultimately bounded. Finally, the validity of the proposed scheme is demonstrated through an application example.},
  archive      = {J_NEUCOM},
  author       = {Qian Xu and Guangdeng Zong and Xudong Zhao and Yang Yi and Jianwei Xia},
  doi          = {10.1016/j.neucom.2024.128185},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128185},
  shortjournal = {Neurocomputing},
  title        = {Output feedback adaptive neural network control for uncertain nonsmooth systems with application},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RCI-seg: Robust click-based interactive segmentation
framework with deep reinforcement learning for biomedical images.
<em>NEUCOM</em>, <em>601</em>, 128184. (<a
href="https://doi.org/10.1016/j.neucom.2024.128184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, interactive segmentation models have achieved remarkable success in the field of biomedical images. However, these models rely on the accurate and high-quality interaction information provided by users, otherwise the segmentation performance will be seriously affected. This problem is more severe in multi-target biomedical images, which means that an image contains multiple targets of interest. It is extremely challenging for users to always maintain high-quality interactions. In this paper, we propose a novel two-stage segmentation model with robust interaction points for biomedical images. In the first stage, we implement robust interaction points based on user initial interaction points and the deep reinforcement learning (DRL) model. Specifically, we build a reinforcement learning environment to simulate the movement of interaction points with agents, and obtain improved interaction points (clue points) that are beneficial for segmentation. In the second stage, we use a convolutional neural network (CNN) model to achieve segmentation by combining clue points and biomedical image. We validate the performance of our approach on five public biomedical image datasets. The experimental results show that the proposed approach outperforms several SOTA methods in multiple metrics.},
  archive      = {J_NEUCOM},
  author       = {Zhiqiang Tian and Yueming He and Lei Sun and Yang Li and Shaoyi Du},
  doi          = {10.1016/j.neucom.2024.128184},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128184},
  shortjournal = {Neurocomputing},
  title        = {RCI-seg: Robust click-based interactive segmentation framework with deep reinforcement learning for biomedical images},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differentiable architecture search with multi-dimensional
attention for spiking neural networks. <em>NEUCOM</em>, <em>601</em>,
128181. (<a href="https://doi.org/10.1016/j.neucom.2024.128181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) have gained enormous popularity in the field of artificial intelligence due to their low power consumption. However, the majority of SNN methods directly inherit the structure of Artificial Neural Networks (ANN), usually leading to sub-optimal model performance in SNNs. To alleviate this problem, we integrate Neural Architecture Search (NAS) method and propose Multi-Attention Differentiable Architecture Search (MA-DARTS) to directly automate the search for the optimal network structure of SNNs. Initially, we defined a differentiable two-level search space and conducted experiments within micro architecture under a fixed layer. Then, we incorporated a multi-dimensional attention mechanism and implemented the MA-DARTS algorithm in this search space. Comprehensive experiments demonstrate our model achieves state-of-the-art performance on classification compared to other methods under the same parameters with 94.40% accuracy on CIFAR10 dataset and 76.52% accuracy on CIFAR100 dataset. Additionally, we monitored and assessed the number of spikes (NoS) in each cell during the whole experiment. Notably, the number of spikes of the whole model stabilized at approximately 110K in validation and 100k in training on datasets.},
  archive      = {J_NEUCOM},
  author       = {Yilei Man and Linhai Xie and Shushan Qiao and Yumei Zhou and Delong Shang},
  doi          = {10.1016/j.neucom.2024.128181},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128181},
  shortjournal = {Neurocomputing},
  title        = {Differentiable architecture search with multi-dimensional attention for spiking neural networks},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Speech emotion recognition based on multi-feature speed rate
and LSTM. <em>NEUCOM</em>, <em>601</em>, 128177. (<a
href="https://doi.org/10.1016/j.neucom.2024.128177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correctly recognizing speech emotions is of significant importance in various fields, such as healthcare and human–computer interaction (HCI). However, the complexity of speech signal features poses challenges for speech emotion recognition. This study introduces a novel multi-feature method for speech emotion recognition that combines short-and rhythmic features. Utilizing short-time energy, zero-crossing rate, and average amplitude difference, the proposed approach effectively addressed overfitting concerns by reducing feature dimensionality. Employing an (LSTM) network, the experiment achieved notable accuracy across diverse datasets. Specifically, the proposed method achieved an impressive accuracy of up to 98.47% on the CASIA dataset, 100% on the Emo-DB dataset, and 98.87% on the EMOVO dataset, demonstrating its capability to accurately discern speaker emotions across different languages and emotion classes. These findings underscore the significance of incorporating speech rate for emotional content recognition, which holds promise for application in HCI and auxiliary medical diagnostics.},
  archive      = {J_NEUCOM},
  author       = {Zijun Yang and Zhen Li and Shi Zhou and Lifeng Zhang and Seiichi Serikawa},
  doi          = {10.1016/j.neucom.2024.128177},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128177},
  shortjournal = {Neurocomputing},
  title        = {Speech emotion recognition based on multi-feature speed rate and LSTM},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven-based sliding-mode dynamic event-triggered
control of unknown nonlinear systems via reinforcement learning.
<em>NEUCOM</em>, <em>601</em>, 128176. (<a
href="https://doi.org/10.1016/j.neucom.2024.128176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a data-driven-based dynamic event-triggered control problem for continuous-time unknown nonlinear systems using the reinforcement learning method and the sliding-mode surface technique. Initially, by constructing a cost function associated with sliding-mode surface variables for the nominal system, the original control problem is equivalently transformed into a problem of designing a dynamic event-triggered optimal control policy. To handle the unknown issue of system dynamics, a data-driven model is established to reconstruct the system dynamics. Then, under the framework of reinforcement learning, a critic network is employed to solve the event-triggered Hamilton–Jacobi–Bellman equation. The weight vector in the critic network is updated through the current data and historical data, such that the persistence of excitation condition is no longer needed. After that, it is strictly proven via Lyapunov stability theory that all the signals of the considered system are bounded in the sense of uniformly ultimately boundedness. Finally, the effectiveness of the developed control method is demonstrated by two simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Tengda Wang and Guangdeng Zong and Xudong Zhao and Ning Xu},
  doi          = {10.1016/j.neucom.2024.128176},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128176},
  shortjournal = {Neurocomputing},
  title        = {Data-driven-based sliding-mode dynamic event-triggered control of unknown nonlinear systems via reinforcement learning},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ST-DAGCN: A spatiotemporal dual adaptive graph convolutional
network model for traffic prediction. <em>NEUCOM</em>, <em>601</em>,
128175. (<a href="https://doi.org/10.1016/j.neucom.2024.128175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting traffic flow characteristics is crucial for effective urban transportation management. Emergence of artificial intelligence has led to the surge of deep learning methods for short-term traffic forecast. Notably, Graph Convolutional Neural Networks (GCN) have demonstrated remarkable prediction accuracy by incorporating road network topology into deep neural networks. However, many existing GCN-based models are based on the premise that the graph network is static, which may fail to do justice in replicating the situations in the real World. On one hand, real road networks are dynamic and undergo changes such as road maintenance and traffic control, leading to altered network structures over time. On the other hand, relationships between road sections can fluctuate due to factors like traffic accidents, weather conditions, and other events, which can significantly impact traffic patterns and result in inaccurate predictions if a static network and static relationships between nodes are assumed. To address these challenges, we propose the spatiotemporal dual adaptive graph convolutional network (ST-DAGCN) model for spatiotemporal traffic prediction, which utilizes a dual-adaptive adjacency matrix comprising both a static and a dynamic graph structure learning matrix. The dual-adaptive mechanism can adaptively learn the global features and the local dynamic features of the traffic states by updating the correlations of nodes at each prediction step, while the gated recurrent unit (GRU), which is also a component of the model, extracts the temporal dependencies of traffic data. Through a comprehensive comparison analysis on two real-world traffic datasets, our model has achieved the highest prediction accuracy when compared to other advanced models.},
  archive      = {J_NEUCOM},
  author       = {Yutian Liu and Tao Feng and Soora Rasouli and Melvin Wong},
  doi          = {10.1016/j.neucom.2024.128175},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128175},
  shortjournal = {Neurocomputing},
  title        = {ST-DAGCN: A spatiotemporal dual adaptive graph convolutional network model for traffic prediction},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SDNet: Spatial adversarial perturbation local descriptor
learned with the dynamic probabilistic weighting loss. <em>NEUCOM</em>,
<em>601</em>, 128160. (<a
href="https://doi.org/10.1016/j.neucom.2024.128160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local descriptor is an important upstream component in computer vision tasks. Despite considerable advances with deep learning-based descriptors, recent descriptors are not robust enough to handle widespread viewpoint changes in image matching tasks such as localization and 3D reconstruction. In this study, SDNet, a robust descriptor utilizing spatial adversarial perturbations, trained with a novel dynamic probabilistic weighting loss to enhance performance under such challenges. First, to increase the robustness and generalization ability of the network across spatially transformed instances, a innovative module for generating hard negative samples via spatial adversarial perturbations is designed. By maximizing adversarial loss, this module generates more complex patches, significantly enhancing the geometric robustness of the descriptor. Importantly, this module integrates seamlessly with existing patch-based descriptors without necessitating extra training data. Second, to mitigate the imbalance in the matching relationship between generated positive and negative pairs, the label weighted triplet loss is proposed, which markedly improves descriptor performance. Third, a comprehensive theoretical analysis of preceding studies is carried out from a gradient perspective, and a probabilistic dynamic weighting approach that adaptively emphasizes weighting functions with higher likelihoods is proposed to improve training performance of the descriptor. Extensive experiments are carried out on mainstream datasets. These comprehensive experiments demonstrate the effectiveness of SDNet, and the proposed method achieves significant improvements on the UBC, HPatches and ETH datasets, outperforming current state-of-the-art methods. The code is available at https://github.com/webd111/sdnet .},
  archive      = {J_NEUCOM},
  author       = {Kaiji Huang and Hua Yang and Yuyang Jiang and Zhouping Yin},
  doi          = {10.1016/j.neucom.2024.128160},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128160},
  shortjournal = {Neurocomputing},
  title        = {SDNet: Spatial adversarial perturbation local descriptor learned with the dynamic probabilistic weighting loss},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Secure state estimation of memristive neural networks with
dynamic self-triggered strategy subject to deception attacks.
<em>NEUCOM</em>, <em>601</em>, 128142. (<a
href="https://doi.org/10.1016/j.neucom.2024.128142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is dedicated to addressing state estimation for memristive neural networks (MNNs) featuring dynamic self-triggered mechanisms (DSTM) subject to deception attacks (DA). Taking into account the constrained channel bandwidth, the data sampling controller by dynamic self-triggering is proposed for measurement output. The network transmission of data among sensor and estimator is susceptible to deception attacks, and a corresponding state estimator is developed. Utilizing Lyapunov stability theory, it is demonstrated that the state error system is exponentially ultimately bounded in the mean square, and the dynamic self-triggered strategy avoids Zeno behavior. Furthermore, the estimation gains are obtained using a linear matrix inequality (LMI) approach. Lastly, simulated examples are provided to demonstrate the efficacy of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Bingrui Xu and Xiaofang Hu and Shenglin Li},
  doi          = {10.1016/j.neucom.2024.128142},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128142},
  shortjournal = {Neurocomputing},
  title        = {Secure state estimation of memristive neural networks with dynamic self-triggered strategy subject to deception attacks},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view clustering algorithm based on feature learning
and structure learning. <em>NEUCOM</em>, <em>601</em>, 128138. (<a
href="https://doi.org/10.1016/j.neucom.2024.128138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-clustering aims to cluster heterogeneous information from different perspectives, which is an important research direction in Multi-view learning. Many clustering algorithms based on multi-view data usually have the following two problems: (1) high-dimensional data leads to high computing cost, and data noise leads to poor clustering performance. (2) It cannot effectively carry out structure learning and integrate heterogeneous information of each view. In order to address these issues, this work suggests a multi-view clustering algorithm (FS-MVC) based on feature learning and structure learning. For each view, feature learning comes first. The data after dimensionality reduction is used for clustering. The projection matrix is introduced to reduce the dimensionality of each view of the original data. Second, a brand-new structure learning technique is developed that may efficiently utilize the diverse information present in each view and produce the best clustering outcomes. The clustering results on eight multi-view data are compared with those of nine advanced multi-view clustering methods in order to confirm the performance of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Guoping Kong and Yingcang Ma and Zhiwei Xing and Xiaolong Xin},
  doi          = {10.1016/j.neucom.2024.128138},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128138},
  shortjournal = {Neurocomputing},
  title        = {Multi-view clustering algorithm based on feature learning and structure learning},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A novel gradient boosting approach for imbalanced
regression. <em>NEUCOM</em>, <em>601</em>, 128091. (<a
href="https://doi.org/10.1016/j.neucom.2024.128091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data imbalance is prevalent in the real world and has received significant attention in classification tasks, both theoretically and practically. However, imbalanced regression remains underexplored. It involves continuous labels, which is laborious and technically difficult due to the absence of distinct boundaries between different targets. To address this issue, we leverage the balanced mean square error (Balanced MSE) from a statistical perspective into the gradient boosting algorithm framework to present the imbalanced regression gradient boosting algorithm (IMr-GB). This algorithm could adapt to imbalanced prior distributions and achieve tradeoffs between frequent and rare labels, thus delivering balanced estimation and effectively reducing adverse effects on underrepresented datasets. In addition, we devise a Bayes variant of IMr-GB, denoted as IMr-bay-GB, to eliminate the complexity of the number of Gaussian mixture components and acquire robustness and optimal performance. Our strategies are extensively tested on ten real-world data sets to demonstrate their superior performance.},
  archive      = {J_NEUCOM},
  author       = {Wenchao Zhang and Peixin Shi and Pengjiao Jia and Xiaoqi Zhou},
  doi          = {10.1016/j.neucom.2024.128091},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128091},
  shortjournal = {Neurocomputing},
  title        = {A novel gradient boosting approach for imbalanced regression},
  volume       = {601},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fixed-time formation tracking for unmanned surface vehicles:
A multi-layer neural networks approach. <em>NEUCOM</em>, <em>600</em>,
128220. (<a href="https://doi.org/10.1016/j.neucom.2024.128220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the distributed fixed-time formation problem of unmanned surface vehicles (USVs) in the presence of external disturbances, model uncertainties, input saturation and quantization constraints. To deal with the problem, a fixed-time sliding-mode control algorithm is proposed, where multi-layer neural networks (MNNs) are designed to approximate the unknown dynamics and composite disturbances of the system. The proposed MNNs combine the advantages of fuzzy neural networks (FNNs) and radial basis function neural networks (RBFNNs), exhibiting robust dynamic characteristics. Furthermore, the non-singular fast terminal sliding mode (NFTSM) is integrated into the fixed-time control framework to improve the robustness and speed of convergence for uncertain USV systems. Comparative simulations conducted with USVs demonstrate the superiority and effectiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Ze-Jiang Chang and Xiang-Yu Yao and Ju H. Park},
  doi          = {10.1016/j.neucom.2024.128220},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128220},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time formation tracking for unmanned surface vehicles: A multi-layer neural networks approach},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised spatial–temporal feature enhancement for
one-shot video object detection. <em>NEUCOM</em>, <em>600</em>, 128219.
(<a href="https://doi.org/10.1016/j.neucom.2024.128219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-shot video object detection is a task that aims to locate and identify objects in video sequences given only a single video sample for each class. Exploration in this field is still in its infancy and previous few-shot video object detection methods have limitation in this task. In this paper, we propose the Self-supervised Feature Enhancement (SFE) framework to address one-shot video object detection task. SFE includes two important modules: Hybrid Spatial Self-supervised Feature Enhancement (HSSFE) and Dynamic Temporal Self-supervised Feature Enhancement (DTSFE). HSSFE enhances features from a spatial perspective with spatial self-supervised auxiliary tasks at frame and instance levels. DTSFE on the other hand enhances features from a temporal perspective with memory-based self-supervised constraint for the same object across different frames. We have conducted experiments on multiple benchmarks, and the results demonstrate that our method achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Xudong Yao and Xiaoshan Yang},
  doi          = {10.1016/j.neucom.2024.128219},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128219},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised spatial–temporal feature enhancement for one-shot video object detection},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). State estimation based on measurement from a part of nodes
for a delayed itô type of complex network with markovian mode-dependent
parameters. <em>NEUCOM</em>, <em>600</em>, 128188. (<a
href="https://doi.org/10.1016/j.neucom.2024.128188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is devoted to coping with the state estimate problem for a class of Itô stochastic complex network. The target network under consideration is a hybrid system involving Markovian jumping parameters and mode-dependent distributed time-delays, and the system noise is characterized by the Brownian Motion. The problem addressed is to design a state estimator to track the states of target network under the assumption that the network outputs are from only a portion of network nodes. By utilizing the Lyapunov stability method and the Itô stochastic differential equation theory, sufficient conditions are educed so that the state estimation error of the estimator is mean-square exponentially ultimately bounded. In particular, in the case that the system is noise-free, the derived conditions can ensure the state estimation error is mean-square exponentially stable. Furthermore, the estimator design can be made by solving a set of matrix inequalities. Lastly, a numerical example is exploited to indicates the validity of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Tao Xue and Yurong Liu},
  doi          = {10.1016/j.neucom.2024.128188},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128188},
  shortjournal = {Neurocomputing},
  title        = {State estimation based on measurement from a part of nodes for a delayed itô type of complex network with markovian mode-dependent parameters},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient abnormal behavior detection with adaptive weight
distribution. <em>NEUCOM</em>, <em>600</em>, 128187. (<a
href="https://doi.org/10.1016/j.neucom.2024.128187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been notable progress of recognizing and detecting human abnormal behavior in the field of computer vision. However, it remains an exceptionally difficult task due to serious background interference in surveillance videos, multi-scale variations, inter-target occlusions, and constraints on real-time performance. To address these problems, this paper proposes a new framework called efficient abnormal behavior detection (EABD) that simultaneously integrates spatio-temporal feature modeling and long-term dependency modeling. Then we introduce a new block for adaptive weight distribution to avoid noise interference. Meanwhile, we incorporate the detection head with attention and the SIoU loss function to improve network performance for detecting targets at various scales. Finally, the SoftNMS strategy is employed to enhance the prediction effect for overlapping objects of specific video frames in the inference stage. We conduct extensive experiments on four benchmark datasets, i.e., UCSD Ped1, UCSD Ped2, ShanghaiTech, and CUHK Avenue datasets. Our proposed EABD achieves AUC of 97.8%, 98.7%, 86.7%, and 95.4%, respectively. The experimental results show superiority over other related methods and demonstrate the effectiveness of our proposed method. Additionally, it achieves a maximum inference speed of 71.9 fps.},
  archive      = {J_NEUCOM},
  author       = {Yutong He and Yefeng Qin and Lei Chen and Peng Zhang and Xianye Ben},
  doi          = {10.1016/j.neucom.2024.128187},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128187},
  shortjournal = {Neurocomputing},
  title        = {Efficient abnormal behavior detection with adaptive weight distribution},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Neuroadaptive event-triggered tracking control for
nonlinear systems with dynamic fault feedback and prescribed time
convergence. <em>NEUCOM</em>, <em>600</em>, 128186. (<a
href="https://doi.org/10.1016/j.neucom.2024.128186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of event-triggered adaptive prescribed time tracking control for nonlinear systems with combining multiplicative and additive dynamic sensor fault. A simple state observer is designed by fusing fault output and reference signal to estimate unmeasurable states, where the unknown unmeasurable uncertain functions are approximated by neural network technology. Then, the prescribed time performance function is constructed based on the time scale function, and a suitable function transformation is introduced so that the tracking error can reach the desired residual set in the prescribed time, where the initial value of the error can be arbitrarily selected regardless of the prescribed time performance function. Moreover, the desired accuracy and the prescribed time can be specified on request. The designed adaptive event-triggered controller can effectively compensate for the sensor fault in the output feedback control and reduce the communication burden, and the feasibility of the proposed method is verified by the simulation result.},
  archive      = {J_NEUCOM},
  author       = {Le Wang and Huaguang Zhang and Juan Zhang and Jiawei Ma},
  doi          = {10.1016/j.neucom.2024.128186},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128186},
  shortjournal = {Neurocomputing},
  title        = {Neuroadaptive event-triggered tracking control for nonlinear systems with dynamic fault feedback and prescribed time convergence},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Multi-level modality-specific and modality-common features
fusion network for RGB-IR person re-identification. <em>NEUCOM</em>,
<em>600</em>, 128183. (<a
href="https://doi.org/10.1016/j.neucom.2024.128183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current approaches in RGB-Infrared Person Re-Identification (RGB-IR ReID) often utilize two parameter-specific subnetworks to extract modality-specific features from RGB and IR images, followed by a shared-parameter subnetwork that identifies common features across modalities to facilitate the matching of individuals. Nevertheless, the aforementioned methods ignore the complementary relationships between modality-specific and modality-common features. The exploration of discriminative person-related modality-common features may not be comprehensive, leading to sub-optimal results. To address the above issue, we design a novel multi-level modality-specific and modality-common features fusion network (3MFFNet). Specifically, in 3MFFNet, we design a multi-granularity feature fusion module (MGFFM) to explore those complementary person-related information between modality-specific features and modality-common features. Meanwhile, we combine a multi-granularity feature extraction strategy with an attention mechanism for selecting those discriminative person-related modality-specific features and facilitating the fusion process. This method can make the RGB-IR network obtain a more robust and discriminative person representation. Through extensive experiments conducted on two public datasets, our approach demonstrates superior performance compared to existing state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Jianan Liu and Qiang Zhang},
  doi          = {10.1016/j.neucom.2024.128183},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128183},
  shortjournal = {Neurocomputing},
  title        = {Multi-level modality-specific and modality-common features fusion network for RGB-IR person re-identification},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards test time domain adaptation via negative label
smoothing. <em>NEUCOM</em>, <em>600</em>, 128182. (<a
href="https://doi.org/10.1016/j.neucom.2024.128182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label Smoothing (LS) is a widely-used training technique that adjusts hard labels towards a softer distribution, which prevents model being over-confidence and enhances model generalization ability. However, its effectiveness diminishes during test time domain adaptation (TTA), which optimizes source-pretrained model parameter during inference with only unlabeled noisy data. In this paper, we show this limitation stems from the increased entropy of noisy data, where LS may excessively smooth the posterior. Our investigation reveals that Negative Label Smoothing (NLS), the opposite of LS that negatively weights the combination of hard and soft labels, is more apt for the common TTA scenarios. Moreover, we delve into the intricacies of both LS and NLS in the context of TTA learning, demonstrating theoretically that NLS is preferable for TTA optimization. Extensive experiments conducted on the CIFAR10-C, CIFAR100-C, and ImageNet-C datasets demonstrate that the proposed method achieves an average improvement of 1%, 1.85% and 2.7%, respectively, compared to existing state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Hao Yang and Hao Zuo and Rui Zhou and Min Wang and Yun Zhou},
  doi          = {10.1016/j.neucom.2024.128182},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128182},
  shortjournal = {Neurocomputing},
  title        = {Towards test time domain adaptation via negative label smoothing},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Infrastructure-assisted 3D detection networks based on
camera-lidar early fusion strategy. <em>NEUCOM</em>, <em>600</em>,
128180. (<a href="https://doi.org/10.1016/j.neucom.2024.128180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target detection in autonomous driving is a pivotal domain of the current research focus. The process fundamentally relies on on-board sensors tasked to identify proximate objects. However, long-range perception instability and the partial obstruction by traffic participants further complicate the challenge. These factors collectively affected the effectiveness of targeted detection from the cooperative vehicle-infrastructure system (CVIS) and urgently need to be addressed. Starting from infrastructure-side assisted detection, we propose a 3D detection network based on multi-sensor sensing. Our approach consists of three sub-networks: Diversity Balanced Feature Fusion Network (MRBNeXt), Early Multimodal Fusion Network (VBRFusion), and TwoStage Lightweight Detection Network (TSL). MRBNeXt focuses on extracting raw images fused into multilevel semantic representations to address the drawbacks of needing a rich feature-level representation; VBRFusion proposes a two-branch structure that acts on the point cloud voxelization to aggregate high-dimensional features. The point features are mapped to the sampled graphical semantic features via the coordinate features to complete the early fusion and thus improve the feature quality of a single modality. In the proposed area network, TSL enhances the sensory field processing of multidimensional features using the context-aware module in a two-stage approach to achieve fast target recognition at different scale levels. Finally, we perform comparative ablation experiments on the DAIR-V2X vehicle-infrastructure dataset. The results validated our approach and demonstrated its effectiveness and enhancement in detection accuracy at the infrastructure end compared to current state-of-the-art methods. This improvement significantly boosted the performance of 3D target detection tasks in complex traffic scenarios and provided a more robust justification for the subsequent development of vehicle-side-infrastructure-side collaborative 3D target detection.},
  archive      = {J_NEUCOM},
  author       = {Jingchao Yao and Jian Zhou and Yuhui Wang and Zhibao Gao and Wenqiang Hu},
  doi          = {10.1016/j.neucom.2024.128180},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128180},
  shortjournal = {Neurocomputing},
  title        = {Infrastructure-assisted 3D detection networks based on camera-lidar early fusion strategy},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Position-aware interactive attention network for
multi-intent spoken language understanding. <em>NEUCOM</em>,
<em>600</em>, 128178. (<a
href="https://doi.org/10.1016/j.neucom.2024.128178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spoken Language Understanding (SLU) is a crucial component of task-oriented dialog systems. In recent years, there has been increasing attention on multi-intent SLU due to its relevance to complex real-world applications. Most existing joint models only utilize multi-intent information to guide the slot filling, with only a small number of models achieving bidirectional interaction. Additionally, unlike traditional single-intent SLU, multi-intent SLU is scope-dependent, where each intent in a sentence has its specific dependency range. However, current bidirectional joint models often employ a pipeline approach to implement interaction between the two sub-tasks, which fails to fully leverage the semantic information between them and can lead to error propagation. Moreover, attention-based multi-intent joint models do not adequately model the positional relationships between words, resulting in suboptimal overall performance. In this paper, we propose a novel multi-intent SLU model called Position-aware Interactive Attention Network (PIAN), which consists of interactive attention and rotary position embedding. The aim of PIAN is to fully exploit the correlation between the two sub-tasks and capturing the positional dependencies between words. This facilitates mutual guidance and enhancement between the two sub-tasks. Additionally, to address the issue of uncoordinated slot problem generated by traditional slot filling decoders, we employ an MCRF slot filling decoder to constrain the slot labels. We evaluate our model on two public multi-intent SLU datasets, and the experimental results demonstrate that our model achieves state-of-the-art performance on key metrics. Code for this paper is publicly available at https://github.com/puhahahahahaha/SLU_with_Co_PRoE .},
  archive      = {J_NEUCOM},
  author       = {Pengfei Sun and Han Cao and Hongli Yu and Yachao Cui and Lei Wang},
  doi          = {10.1016/j.neucom.2024.128178},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128178},
  shortjournal = {Neurocomputing},
  title        = {Position-aware interactive attention network for multi-intent spoken language understanding},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New fixed-time/preassigned-time stability results of
impulsive systems and its application to synchronization of delayed
octonion-valued neural networks. <em>NEUCOM</em>, <em>600</em>, 128174.
(<a href="https://doi.org/10.1016/j.neucom.2024.128174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, in order to obtain more accurate settling time estimation and overcome the complexity of the theoretical analysis caused by using decomposition method, the problem of fixed-time (F-T) and preassigned-time (P-T) synchronization of delayed octonion-valued neural networks with impulsive effects is explored by utilizing direct octonion approach. First, a new fixed-time stability theorem for impulsive system is presented by using the comparison principle, average impulsive interval and Bernoulli differential equation theory. Second, to solve the problems of non associative and non commutative laws of octonion, some novel lemmas are introduced, which are the basis of the direct octonion approach. Third, under the improved F-T stability result, a new P-T stability theorem is derived and the settling time is preassigned according to realistic need and is irrelevant with any initial values and any parameters. Then, based on newly established theorems and developed controller strategies, some sufficient conditions are deduced to guarantee F-T and P-T synchronization of the discussed systems. Finally, a numerical simulation is provided to verify the effectiveness of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Ningning Zhao and Yuanhua Qiao and Jun Miao and Lijuan Duan},
  doi          = {10.1016/j.neucom.2024.128174},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128174},
  shortjournal = {Neurocomputing},
  title        = {New fixed-time/preassigned-time stability results of impulsive systems and its application to synchronization of delayed octonion-valued neural networks},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meta-learning in spiking neural networks with
reward-modulated STDP. <em>NEUCOM</em>, <em>600</em>, 128173. (<a
href="https://doi.org/10.1016/j.neucom.2024.128173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human brain constantly learns and rapidly adapts to new situations by integrating acquired knowledge and experiences into memory. Developing this capability in machine learning models is considered an important goal of AI research since deep neural networks perform poorly when there is limited data or when they need to adapt quickly to new unseen tasks. Meta-learning models are proposed to facilitate quick learning in low-data regimes by employing absorbed information from the past. Although some models have recently been introduced that reached high-performance levels, they are not biologically plausible. In our research, we have proposed a bio-plausible meta-learning model inspired by the hippocampus and the prefrontal cortex using spiking neural networks with a reward-based learning system. The major contribution of our work lies in the design of a bio-plausible meta-learning framework that incorporates learning rules such as Spike-Timing-Dependent Plasticity (STDP) and Reward-Modulated STDP (R-STDP). This framework not only reflects biological learning mechanisms more accurately but also attains competitive results comparable to those achieved by traditional gradient descent-based approaches in meta-learning. Our proposed model includes a memory designed to prevent catastrophic forgetting, a phenomenon that occurs when meta-learning models forget what they have learned so far as learning the new task begins. Furthermore, our new model can easily be applied to spike-based neuromorphic devices and enables fast learning in neuromorphic hardware. The implications and predictions of various models for solving few-shot classification tasks are extensively analyzed. Base on the results, our model has demonstrated the ability to compete with the existing state-of-the-art meta-learning techniques, representing a significant step towards creating AI systems that emulate the human brain’s ability to learn quickly and efficiently from limited data.},
  archive      = {J_NEUCOM},
  author       = {Arsham Gholamzadeh Khoee and Alireza Javaheri and Saeed Reza Kheradpisheh and Mohammad Ganjtabesh},
  doi          = {10.1016/j.neucom.2024.128173},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128173},
  shortjournal = {Neurocomputing},
  title        = {Meta-learning in spiking neural networks with reward-modulated STDP},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On representation learning-based methods for effective,
efficient, and scalable code retrieval. <em>NEUCOM</em>, <em>600</em>,
128172. (<a href="https://doi.org/10.1016/j.neucom.2024.128172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code retrieval consists of finding relevant code snippets regarding a programmer’s query — an increasingly important task due to software ubiquity. Although significant progress has been made, there is still a need for refinement and improvement in current code retrieval solutions. Besides effective , we argue that solutions for the code retrieval task should be efficient and scalable to ever-increasing large code repositories. This paper introduces xCoFormer , the first representation learning-based model for the code retrieval task in the literature, which meets all these requirements. Our contributions include: (i) an interactive tag-training method that efficiently places a query closer to its relevant codes in the embedding space and (ii) use of a specialized loss function ( N N -pair) better suited to the code retrieval task. To evaluate our proposal, we conducted experiments with different versions of xCoFormer against several state-of-the-art deep learning models in datasets with different properties. In our experiments, xCoFormer produced the best cost-effectiveness tradeoff — it is as effective as our closest competitor while being thousands of times faster at search time. xCoFormer’s attention mechanism also (partially) meets the desirable requirement of explainability by exposing the “reasoning” of the model’s predictions. Finally, when used as a “proxy” method, fine-tuned with domain-specific code language models, such as Unixcoder and CodeBERT, our proposal achieves gains of more than 33% in effectiveness when compared to the use of general purpose language models such as BERT and RoBERTa.},
  archive      = {J_NEUCOM},
  author       = {Celso França and Rennan C. Lima and Claudio Andrade and Washington Cunha and Pedro O.S. Vaz de Melo and Berthier Ribeiro-Neto and Leonardo Rocha and Rodrygo L.T. Santos and Adriana Silvina Pagano and Marcos André Gonçalves},
  doi          = {10.1016/j.neucom.2024.128172},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128172},
  shortjournal = {Neurocomputing},
  title        = {On representation learning-based methods for effective, efficient, and scalable code retrieval},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Action-dependent heuristic dynamic programming for
hybrid-order systems based on dynamic event-triggered mechanism.
<em>NEUCOM</em>, <em>600</em>, 128171. (<a
href="https://doi.org/10.1016/j.neucom.2024.128171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the distributed optimal consensus control problem based on action-dependent heuristic dynamic programming (ADHDP). In order to strike a stable balance between the learning cost of reinforcement learning and the resource utilization efficiency of the hybrid-order multi-agent systems (MASs), we propose an improved dynamic event-triggered ADHDP (dET-ADHDP) method. This approach can non-periodically explore the control policy distribution using the online action-dependent actor–critic (ADAC) learning framework. Meanwhile, it can dynamically adjust the trigger lower bound by exploiting the designed trigger threshold function, and adaptively decide the signal trigger moment during the ADAC learning process. In addition, we demonstrate the boundedness of the ADAC network weights and show that under the designed dynamic event-triggering rules, the MASs can asymptotically achieve optimal tracking control without Zeno phenomenon. Finally, compared with the traditional static counterparts, simulation experiments demonstrate that the proposed dynamic event-triggered ADAC (dET-ADAC) algorithm has more efficient resource utilization while maintaining satisfactory learning performance.},
  archive      = {J_NEUCOM},
  author       = {Jun Li and Huaqing Li and Lifeng Zheng and Liang Ran and Lianghao Ji},
  doi          = {10.1016/j.neucom.2024.128171},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128171},
  shortjournal = {Neurocomputing},
  title        = {Action-dependent heuristic dynamic programming for hybrid-order systems based on dynamic event-triggered mechanism},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive review of community detection in graphs.
<em>NEUCOM</em>, <em>600</em>, 128169. (<a
href="https://doi.org/10.1016/j.neucom.2024.128169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of complex networks has significantly advanced our understanding of community structures which serves as a crucial feature of real-world graphs. Detecting communities in graphs is a challenging problem with applications in sociology, biology, and computer science. Despite the efforts of an interdisciplinary community of scientists, a satisfactory solution to this problem has not yet been achieved. This review article delves into the topic of community detection in graphs, which serves as a thorough exposition of various community detection methods from perspectives of modularity-based methods, spectral clustering, probabilistic modeling, and deep learning. Along with the methods, a new community detection method designed by us is also presented. Additionally, the performance of these methods on the datasets with and without ground truth is compared. In conclusion, this comprehensive review provides a deep understanding of community detection in graphs.},
  archive      = {J_NEUCOM},
  author       = {Jiakang Li and Songning Lai and Zhihao Shuai and Yuan Tan and Yifan Jia and Mianyang Yu and Zichen Song and Xiaokang Peng and Ziyang Xu and Yongxin Ni and Haifeng Qiu and Jiayu Yang and Yutong Liu and Yonggang Lu},
  doi          = {10.1016/j.neucom.2024.128169},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128169},
  shortjournal = {Neurocomputing},
  title        = {A comprehensive review of community detection in graphs},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey for generative data augmentation.
<em>NEUCOM</em>, <em>600</em>, 128167. (<a
href="https://doi.org/10.1016/j.neucom.2024.128167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative data augmentation (GDA) has emerged as a promising technique to alleviate data scarcity in machine learning applications. This thesis presents a comprehensive survey and unified framework of the GDA landscape. We first provide an overview of GDA, discussing its motivation, taxonomy, and key distinctions from synthetic data generation. We then systematically analyze the critical aspects of GDA—selection of generative models, techniques to utilize them, data selection methodologies, validation approaches, and diverse applications. Our proposed unified framework categorizes the extensive GDA literature, revealing gaps such as the lack of universal benchmarks. The thesis summarizes promising research directions, including , effective data selection, theoretical development for large-scale models’ application in GDA and establishing a benchmark for GDA. By laying a structured foundation, this thesis aims to nurture more cohesive development and accelerate progress in the vital arena of generative data augmentation.},
  archive      = {J_NEUCOM},
  author       = {Yunhao Chen and Zihui Yan and Yunjie Zhu},
  doi          = {10.1016/j.neucom.2024.128167},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128167},
  shortjournal = {Neurocomputing},
  title        = {A comprehensive survey for generative data augmentation},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of privacy-preserving research on federated graph
neural networks. <em>NEUCOM</em>, <em>600</em>, 128166. (<a
href="https://doi.org/10.1016/j.neucom.2024.128166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks are widely employed in diverse domains; however, they confront the peril of privacy infringement. To address this concern, federated learning emerges as a privacy-preserving approach that avoids sharing data for model training, effectively resolving the issue of privacy leakage in graph neural networks. The rapid advancement of federated neural networks has spurred the demand for more potent tools to enhance model performance owing to the concealed correlation information amongst federated learning participants. However, the structural attributes of federated graph neural networks render them vulnerable to inference attacks, reconstruction attacks, inversion attacks, and the like, potentially endangering privacy. This study delves into the intricacies of privacy-preserving within federated graph neural networks. Firstly, it introduces the architecture and variants of federated graph neural networks, analyzes the privacy risks encountered by these networks from four perspectives, and elucidates three primary attack methods. In accordance with the privacy-preserving mechanism of federated graph neural networks, it summarizes the privacy-preserving techniques and synthesizes the existing strategies from four perspectives: encryption methods, perturbation methods, anonymization, and hybrid methods. Furthermore, it summarily presents the prevailing framework for preserving privacy in neural networks. Ultimately, this paper examines the challenges and outlines future research directions pertaining to federated graph neural network technology.},
  archive      = {J_NEUCOM},
  author       = {Lina Ge and YanKun Li and Haiao Li and Lei Tian and Zhe Wang},
  doi          = {10.1016/j.neucom.2024.128166},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128166},
  shortjournal = {Neurocomputing},
  title        = {A review of privacy-preserving research on federated graph neural networks},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TSUDepth: Exploring temporal symmetry-based uncertainty for
unsupervised monocular depth estimation. <em>NEUCOM</em>, <em>600</em>,
128165. (<a href="https://doi.org/10.1016/j.neucom.2024.128165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When faced with occlusions and non-rigid motions, machines often struggle with depth estimation, a task effortlessly performed by humans with just one eye. Continuous RGB images embody rich temporal features, such as symmetry and optical flow, which current deep-learning models fail to effectively leverage. In response to this limitation, we introduce an innovative framework known as Temporal Symmetry-based Uncertainty (TSU)-Depth, aimed at enhancing the accuracy of unsupervised monocular depth estimation. The Temporal Symmetry-based Occlusion Optimization (TSOO) component plays a pivotal role in robustly identifying occluded regions and comparable optimization across adjacent frames. Simultaneously, we propose Temporal Optical Flow Masking (TOFM) to effectively identify and exclude static pixels (such as out-of-range depths and non-rigid objects) between adjacent frames. Additionally, we introduce Cross-Resolution Distillation (CRED) to enhance depth estimation accuracy across various resolutions, especially in low input resolution scenarios. Furthermore, we designed a new depth estimation structure utilizing the DPT structure and incorporating a GRU module to enhance performance details. Through extensive experiments on benchmark datasets, including KITTI, Cityscapes, and Make3D, our TSUDepth framework has consistently demonstrated state-of-the-art performance. Code is available at https://github.com/BlueEg/TSUDepth/ .},
  archive      = {J_NEUCOM},
  author       = {Yufan Zhu and Rui Ren and Weisheng Dong and Xin Li and Guangming Shi},
  doi          = {10.1016/j.neucom.2024.128165},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128165},
  shortjournal = {Neurocomputing},
  title        = {TSUDepth: Exploring temporal symmetry-based uncertainty for unsupervised monocular depth estimation},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive fixed-time neural consensus control for a class of
uncertain nonlinear multi-agent systems with full state constraints.
<em>NEUCOM</em>, <em>600</em>, 128164. (<a
href="https://doi.org/10.1016/j.neucom.2024.128164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the fixed-time consensus control problem for non-strict feedback multi-agent systems with asymmetric output constraints and full state constraints. Considering the feasibility of controlling execution, a novel practical virtual control signal is developed utilizing both saturation function and hyperbolic tangent function to ensure that this signal can remain within the same restricted range as the corresponding state variable throughout entire operation process. In backstepping steps, the design of ideal virtual control signal also adopts a different form of piecewise function than before, introducing high-order polynomial functions to avoid singularity problems in the derivation process. In addition, function approximation ability of radial basis function neural networks technique is applied to estimate uncertainties derived from the system functions and controller design procedure. Moreover, universal barrier Lyapunov function approach is improved for constructing an adaptive constrained synchronization control scheme. By fixed-time stability theory, it is shown that the tracking errors of the MAS converge to an adjustable region around the origin in a fixed time and the state variables always obey their constraints. And the upper bound of the settling time is merely dependent on design parameters, which is not affected by the initial states of MAS. The effectiveness of the proposed control strategy is shown by a numerical simulation example at last. Two scenarios are provided to demonstrate the advantages of the control protocol proposed in this paper.},
  archive      = {J_NEUCOM},
  author       = {Yun Shang and Zunshui Cheng and Youming Xin and Xue Lin},
  doi          = {10.1016/j.neucom.2024.128164},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128164},
  shortjournal = {Neurocomputing},
  title        = {Adaptive fixed-time neural consensus control for a class of uncertain nonlinear multi-agent systems with full state constraints},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TCKGCN: Graph convolutional network for aspect-based
sentiment analysis with three-channel knowledge fusion. <em>NEUCOM</em>,
<em>600</em>, 128163. (<a
href="https://doi.org/10.1016/j.neucom.2024.128163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, most aspect-based sentiment analysis studies addresses the syntactic dependency problem of review statements by building syntactic dependency graphs. However, this approach is insensitive to syntactic structural information and susceptible to noise interference. Existing fusion methods are unable to effectively capture the complementary relationships between information, leading to large and less efficient model structures. To tackle these issues, we introduce a unique and original scheme that fuses semantic information, ConceptNet conceptual knowledge, and SenticNet affective knowledge, intending to improve the capability of the model to capture sentence features. Specifically, the process involves four steps: first, a semantic attention mechanism is constructed as the first channel to parse the semantic relationship within the context; second, the expressive meaning of the aspects is enhanced with concept mapping as the second channel, with concepts injected into aspectual words; third, the representation ability of sentence dependency graphs is strengthened through adding the affective knowledge of SenticNet as a third channel. Subsequently, the sensitivity of the model to affective information is increased, and finally, the optimization of aspect and context coordination is strengthened by integrating an interactive attention mechanism. The overall findings underscore the efficacy of the model, showing accuracy improvements of 1.05 % and 2.80 % on the Twitter and Lap14 datasets, respectively, compared to state-of-the-art models. Moreover the macro-F1 scores showed significant improvements of 1.99 % and 1.61 %, respectively, enabling more effective capturing of aspect-specific sentiment expressions.},
  archive      = {J_NEUCOM},
  author       = {Jun Hao and Lili Pei and Yongxi He and Zhenzhen Xing and Yuhan Weng},
  doi          = {10.1016/j.neucom.2024.128163},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128163},
  shortjournal = {Neurocomputing},
  title        = {TCKGCN: Graph convolutional network for aspect-based sentiment analysis with three-channel knowledge fusion},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing end-to-end control in autonomous driving through
kinematic-infused and visual memory imitation learning. <em>NEUCOM</em>,
<em>600</em>, 128161. (<a
href="https://doi.org/10.1016/j.neucom.2024.128161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an exploration, study, and comparison of various alternatives to enhance the capabilities of an end-to-end control system for autonomous driving based on imitation learning by adding visual memory and kinematic input data to the deep learning architectures that govern the vehicle. The experimental comparison relies on fundamental error metrics (MAE, MSE) during the offline assessment, supplemented by several external complementary fine-grain metrics based on the behavior of the ego vehicle at several urban test scenarios in the CARLA reference simulator in the online evaluation. Our study focuses on a lane-following application using different urban scenario layouts and visual bird-eye-view input. The memory addition involves architectural modifications and different sensory input types. The kinematic data integration is managed with a modified input. The experiments encompass both typical driving scenarios and extreme never-seen conditions. Additionally, we conduct an ablation study examining various memory lengths and densities. We prove experimentally that incorporating visual memory capabilities and kinematic input data makes the driving system more robust and able to handle a wider range of challenging situations, including those not encountered during training, in terms of reduction of collisions and speed self-regulation, resulting in a 75% enhancement. All the work we present here, including model architectures, trained model weights, comparison tool, and the dataset, is open-source, facilitating replication and extension of our findings.},
  archive      = {J_NEUCOM},
  author       = {Sergio Paniego and Roberto Calvo-Palomino and JoséMaría Cañas},
  doi          = {10.1016/j.neucom.2024.128161},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128161},
  shortjournal = {Neurocomputing},
  title        = {Enhancing end-to-end control in autonomous driving through kinematic-infused and visual memory imitation learning},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Security control for cyber–physical systems under aperiodic
denial-of-service attacks: A memory-event-triggered active approach.
<em>NEUCOM</em>, <em>600</em>, 128159. (<a
href="https://doi.org/10.1016/j.neucom.2024.128159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the security control problem for cyber–physical systems (CPSs) subjected to aperiodic denial-of-service (DoS) attacks. In order to mitigate the adverse impacts of DoS attacks, buffers are installed at both the event-generator and controller ends, allowing for the storage of pertinent historical information. A novel memory-event-triggered mechanism (METM) that incorporates dynamic parameter terms is introduced by taking into account previously transmitted state signals, with the aim of minimizing real-time data exchanges within CPS components. An active security control strategy is then formulated, leveraging the data from successful triggers to ensure timely updates of control signals, even in instances where the communication channel is compromised. The time-delayed closed-loop CPS, influenced by DoS attacks and network delays, is established using the interval decomposition method. A sufficient condition is derived, through the employment of an appropriate Lyapunov-Krasovskii functional, for achieving asymptotic stability along with an H ∞ H∞ performance index for the closed-loop system. The advantages and effectiveness of the theoretical results are showcased by two illustrative examples.},
  archive      = {J_NEUCOM},
  author       = {Min Zhao and Wenzhi Qin and Jing Yang and Guoping Lu},
  doi          = {10.1016/j.neucom.2024.128159},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128159},
  shortjournal = {Neurocomputing},
  title        = {Security control for cyber–physical systems under aperiodic denial-of-service attacks: A memory-event-triggered active approach},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual residual and large receptive field network for
lightweight image super-resolution. <em>NEUCOM</em>, <em>600</em>,
128158. (<a href="https://doi.org/10.1016/j.neucom.2024.128158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been rapid progress in single-image super-resolution (SISR) reconstruction technology based on deep learning, but many methods face challenges in practical application due to their excessive computational requirements. To address this issue, numerous lightweight super-resolution (SR) methods have been proposed. Convolutional neural networks (CNNs) have demonstrated outstanding performance in lightweight SR reconstruction tasks. However, existing CNN-based lightweight SR networks still suffer from redundancy due to the use of small convolutional kernels and deeper network architectures for feature extraction. To solve these problems, we propose a novel network called Dual Residual and Large Receptive Field Network (DRLN), which includes two main designs. Firstly, a Large Receptive Field Feature Extraction Block (LRFEB) is proposed, which concatenates large kernel depth separable convolutions and large kernel depth separable dilated convolutions, effectively capturing spatial contextual information without increasing the number of parameters or computational burden, and enhancing the overall performance of the model. Secondly, in the Efficient Feature Distillation Block (EFDB), we innovatively propose a dual residual structure, which greatly improve the learning ability and feature expression richness of the network, and significantly improve the reconstruction performance. Extensive experiments demonstrate that DRLN surpasses BSRN which is the champion of the model complexity track of the NTIRE 2022 Efficient SR Challenge on all benchmark datasets, with fewer parameters and less computation.},
  archive      = {J_NEUCOM},
  author       = {Lulu Pan and Guo Li and Ke Xu and Yanheng Lv and Wenbo Zhang and Lingxiao Li and Le Lei},
  doi          = {10.1016/j.neucom.2024.128158},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128158},
  shortjournal = {Neurocomputing},
  title        = {Dual residual and large receptive field network for lightweight image super-resolution},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UniverDetect: Universal landmark detection method for
multidomain x-ray images. <em>NEUCOM</em>, <em>600</em>, 128157. (<a
href="https://doi.org/10.1016/j.neucom.2024.128157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Landmark detection using X-ray imaging is vital for disease screening, treatment, and prognosis. It provides a framework for subsequent tasks, including segmentation, classification, and target detection. Existing landmark detection methods exhibit limits with the increasing number of X-ray examiners. Not only they serve specific data types, but also their ability to learn the complete semantic information from this dataset is limited, potentially affecting their widespread adoption. We address these challenges by proposing a universal landmark detection model for multidomain X-ray imaging, UniverDetect. By progressively acquiring local semantic information, global semantic insights, and anatomical structure knowledge at various levels, the model ensured that the detected landmarks were closely aligned with the ground-truth labels. UniverDetect consists of three key components. The landmark detection module (LDM) utilizes a U-net network equipped with our innovative pyramid depthwise separable (PDS) convolution module for initial landmark detection. The landmark refinement module (LRM) integrates a fine-tuning module comprising continuously extended convolution blocks. Finally, the landmark correction module (LCM) incorporates a graph convolutional network (GCN) to rectify offset errors during partial landmark detection. An inherent feature of this model is its domain- generalization capability, which enables continuous learning across diverse domains. This model can concurrently learn from eight domains, covering 118 landmarks within a diverse dataset of 5969 images. Extensive experiments on multiple datasets demonstrate that this method consistently outperforms state-of-the-art approaches. This study presents a versatile and effective solution to reduce doctors’ workload while providing precise quantitative analysis.},
  archive      = {J_NEUCOM},
  author       = {Chenyang Lu and Guangtong Yang and Xu Qiao and Wei Chen and Qingyun Zeng},
  doi          = {10.1016/j.neucom.2024.128157},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128157},
  shortjournal = {Neurocomputing},
  title        = {UniverDetect: Universal landmark detection method for multidomain X-ray images},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Instruct pix-to-3D: Instructional 3D object generation from
a single image. <em>NEUCOM</em>, <em>600</em>, 128156. (<a
href="https://doi.org/10.1016/j.neucom.2024.128156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a challenging task, creating the instructional 3D object based on a single image and human instruction. Although existing methods utilize pre-trained text-to-image diffusion models to optimize Neural Radiance Fields (NeRF) and achieve remarkable results, they are inherently challenged in addressing this task due to two inherent obstacles. First, the written instruction is mismatched or uncorrelated with target images in the distribution of pre-trained text-to-image diffusion models, which leads to insufficient supervision. Another is editing 3D content starting from a single image, which is an ill-posed problem as the image only provides partial information. To tackle the difficulties, we propose an Instruct Pixel-to-3D framework, which exploits the supervisory signals from the given instructions and integrates the domain-specific knowledge drawn from 2D and 3D diffusion models. Specifically, to address the first challenge, we propose instruction guidance to facilitate meticulous image editing using fine-grained instructions and regulate the novel views of 3D objects using positional prompts. To tackle the second difficulty, we propose diffusion guidance for 3D generation, which optimizes the NeRF employing dual guidances: a 2D diffusion guidance derived from the score distillation sampling (SDS) loss and a 3D diffusion guidance embodied by the Zero-1-to-3 loss. Moreover, Instruct Pix-to-3D adopts a coarse-to-fine training strategy aimed at mitigating the complexities inherent in reconstructing scenes from sparse viewpoints. Qualitative and quantitative experiments on the DTU dataset and in-the-wild images demonstrate that our approach could synthesize high-quality and high-fidelity 3D content based on a single image and human instruction.},
  archive      = {J_NEUCOM},
  author       = {Weiwei Cai and Wen Liu and Wanzhang Li and Zibo Zhao and Fukun Yin and Xin Chen and Lei Zhao and Tao Chen},
  doi          = {10.1016/j.neucom.2024.128156},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128156},
  shortjournal = {Neurocomputing},
  title        = {Instruct pix-to-3D: Instructional 3D object generation from a single image},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TranSalNet+: Distortion-aware saliency prediction.
<em>NEUCOM</em>, <em>600</em>, 128155. (<a
href="https://doi.org/10.1016/j.neucom.2024.128155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the saliency of images affected by distortion is a challenging but emerging research problem. Given a distorted image, we wish to accurately predict saliency as perceived by humans. A recent distortion-aware saliency benchmark – the CUDAS database – reveals the inadequacy of existing saliency models in handling distorted images. In this paper, we devise a deep learning Distortion-Aware Saliency Module (DASM) that enables capturing saliency features related to image distortions, and integrates this module into a saliency prediction architecture. To achieve the high expressive capability of DASM using supervised learning, we create a dedicated dataset that draws upon a large-scale saliency dataset and machine-generated image quality assessments. Experimental results demonstrate the superior performance of the proposed model in predicting the saliency of distorted images.},
  archive      = {J_NEUCOM},
  author       = {Jianxun Lou and Xinbo Wu and Padraig Corcoran and Paul L. Rosin and Hantao Liu},
  doi          = {10.1016/j.neucom.2024.128155},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128155},
  shortjournal = {Neurocomputing},
  title        = {TranSalNet+: Distortion-aware saliency prediction},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A survey for table recognition based on deep learning.
<em>NEUCOM</em>, <em>600</em>, 128154. (<a
href="https://doi.org/10.1016/j.neucom.2024.128154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tables, as an important information interaction media containing much structured information, are popularly adopted in our life. There are a lot of table recognition methods for understanding and applying these information. Among them, table recognition based on deep learning is the mainstream. Therefore, we conducted this survey to summarize the latest research on table recognition based on deep learning in recent years. Table recognition can be divided into three sub-tasks, namely table detection, table structure recognition and table content recognition, so we firstly introduce the importance and significance of table recognition research and analyze the current challenges faced by each sub-task. Then, we list the existing public table recognition datasets and introduce commonly used evaluation metrics. Furthermore, we review deep learning-based solutions proposed in recent years for three different sub-tasks and reclassify them. Especially for table structure recognition, we reclassify them according to their annotation schemes. Finally, we report the performance of some excellent methods, such as CascadeTabNet, TSRFormer, SEM, etc, on public datasets, and describe the future research directions, including table recognition in natural scenes, question and answer about tables, visual information extraction, domain adaptation etc. In summary, this survey reviews the data, evaluations, methods, and development directions of table recognition. Table understanding and domain adaptation need as well to be focused on. The former can predict the relationships between two table elements, which helps us to understand the table. The latter can enhance the generalization ability of table recognition methods, thereby obtaining more robust recognition performance. Both are important development directions for table recognition in the future.},
  archive      = {J_NEUCOM},
  author       = {Chenglong Yu and Weibin Li and Wei Li and Zixuan Zhu and Ruochen Liu and Biao Hou and Licheng Jiao},
  doi          = {10.1016/j.neucom.2024.128154},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128154},
  shortjournal = {Neurocomputing},
  title        = {A survey for table recognition based on deep learning},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Utilizing motion segmentation for optimizing the temporal
adjacency matrix in 3D human pose estimation. <em>NEUCOM</em>,
<em>600</em>, 128153. (<a
href="https://doi.org/10.1016/j.neucom.2024.128153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In monocular 3D human pose estimation, modeling the temporal relation of human joints is crucial for prediction accuracy. Currently, most methods utilize transformer to model the temporal relation among joints. However, existing transformer-based methods have limitations. The temporal adjacency matrix utilized within the self-attention of the temporal transformer inaccurately models the temporal relationships between frames, particularly in cases where distinct motions exhibit significant correlation despite having different physical interpretations and large temporal spans. To address this issue, we construct an artificial temporal adjacency matrix based on input data and introduce a temporal adjacency matrix hybrid module to blend this matrix with the model’s inherent temporal adjacency matrix, resulting in a novel composite temporal adjacency matrix. Through extensive experiments on Human3.6M and MPI-INF-3DHP datasets using state-of-the-art methods as benchmarks, our proposed method demonstrates a maximum improvement of up to 5.6% compared to the original approach.},
  archive      = {J_NEUCOM},
  author       = {Yingfeng Wang and Muyu Li and Hong Yan},
  doi          = {10.1016/j.neucom.2024.128153},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128153},
  shortjournal = {Neurocomputing},
  title        = {Utilizing motion segmentation for optimizing the temporal adjacency matrix in 3D human pose estimation},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blind image quality index with high-level semantic guidance
and low-level fine-grained representation. <em>NEUCOM</em>,
<em>600</em>, 128151. (<a
href="https://doi.org/10.1016/j.neucom.2024.128151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image Quality Assessment (IQA) has received unprecedented attention due to the extensive applications in benchmarking image processing algorithms and systems. Despite great progress in IQA, most previous frameworks either utilized only high-level semantic features or simply stacked multi-level features to account for the distortions, resulting in limited performance. The initial visual perception is formed after that the information is processed by the primary visual cortex and the advanced visual cortex. However, the information transmission of the cerebral cortex is not unidirectional, that is, the higher brain area can affect the primary brain area in turn, regulate its sensitivity and preference, so as to help the brain to understand the external world more finely. Inspired by this, we propose a novel blind image quality index with high-level Semantic Guidance and low-level fine-grained Representation (SGRNet). First, the versatile backbone, called pyramid vision Transformer, is used to simulate the multilevel information processing in the brain, generating multilevel feature representation. Second, we propose a novel high-level semantic guidance module to simulate the feedback mechanism between levels of the visual cortex. Third, a simple but effective fine-grained feature extraction module is proposed for high-level information compensation and lower-level content perception. After this, an attention mechanism-based enhancement module is proposed to further learn the above two features respectively. Finally, a bilinear pooling-based regression module is proposed to integrate the enhanced features of the two parts and map them to the quality score. Extensive experiments on six challenging public datasets show that the proposed SGRNet can deal well with both the simulated and authentic distortions and achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Bo Hu and Jia Zheng and Leida Li and Ke Gu and Shuaijian Wang and Weisheng Li and Xinbo Gao},
  doi          = {10.1016/j.neucom.2024.128151},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128151},
  shortjournal = {Neurocomputing},
  title        = {Blind image quality index with high-level semantic guidance and low-level fine-grained representation},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Safe dynamic sparse training of modified RBF networks for
joint feature selection and classification. <em>NEUCOM</em>,
<em>600</em>, 128150. (<a
href="https://doi.org/10.1016/j.neucom.2024.128150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing an efficient embedded feature selection method for both binary and multiclass classification problems is a fundamental topic to be further studied. In this paper, the conventional radial basis function (RBF) network is modified for joint feature selection and classification. By utilizing the anisotropic Gaussian basis function, an individual weight parameter is assigned to each feature for feature weighting. The L 1 L1 -regularized loss function is designed by combining the softmax cross entropy loss with L 1 L1 regularization terms imposing on feature and output weights. A specialized active-set limited-memory projected Quasi-Newton (SAL-PQN) algorithm is proposed to minimize the L 1 L1 -regularized loss function, which can optimize all the adjustable parameters and zero out the redundant feature and output weights simultaneously. Furthermore, a safe dynamic pruning strategy is integrated into the SAL-PQN algorithm for dynamic sparse training of the modified RBF network, which continuously excludes the dynamically zeroed-out feature weights from the training process. It is theoretically assured of yielding the same gradient updates as SAL-PQN, thus the relevant computation of the zeroed-out feature weights in the forward and backward propagations can be safely eliminated. The experimental results demonstrate the effectiveness and efficiency of the proposed methods for joint feature selection and classification, and illustrate the practical utility of the inherent feature weighting capability.},
  archive      = {J_NEUCOM},
  author       = {Xusheng Qian and Jisu Hu and Yi Zheng and He Huang and Zhiyong Zhou and Yakang Dai},
  doi          = {10.1016/j.neucom.2024.128150},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128150},
  shortjournal = {Neurocomputing},
  title        = {Safe dynamic sparse training of modified RBF networks for joint feature selection and classification},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transformer-based cross-modality interaction guidance
network for RGB-t salient object detection. <em>NEUCOM</em>,
<em>600</em>, 128149. (<a
href="https://doi.org/10.1016/j.neucom.2024.128149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring more effective multimodal fusion strategies is still challenging for RGB-T salient object detection (SOD). Most RGB-T SOD methods tend to focus on the strategy of acquiring modal complementary features by utilizing foreground information while ignoring the importance of background information for salient object localization. In addition, feature fusion without information filtering may introduce more noise. To solve these problems, this paper proposes a new cross-modal interaction guidance network (CIGNet) for RGB-T saliency object detection. Specifically, we construct a transformer-based dual-stream encoder to extract multimodal features. In the decoder, we propose an attention mechanism-based modal information complementary module (MICM) for capturing cross-modal complementary information for global comparison and salient object localization. Based on the MICM features, we design a multi-scale adaptive fusion module (MAFM) to find the optimal salient region of the multi-scale fusion process and reduce redundant features. In order to enhance the completeness of salient features after multi-scale feature fusion, this paper proposes the saliency region mining module (SRMM), which corrects the features in the boundary neighborhood by exploiting the differences between foreground and background pixels and the boundary. Comparisons with other state-of-the-art methods on three RGB-T datasets and five RGB-D datasets, the experimental results demonstrate the superiority and extensiveness of the proposed CIGNet.},
  archive      = {J_NEUCOM},
  author       = {Jincheng Luo and Yongjun Li and Bo Li and Xinru Zhang and Chaoyue Li and Zhimin Chenjin and Jingyi He and Yifei Liang},
  doi          = {10.1016/j.neucom.2024.128149},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128149},
  shortjournal = {Neurocomputing},
  title        = {Transformer-based cross-modality interaction guidance network for RGB-T salient object detection},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Min–max consensus of multi-agent systems in random
networks. <em>NEUCOM</em>, <em>600</em>, 128148. (<a
href="https://doi.org/10.1016/j.neucom.2024.128148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the study of the min–max consensus problem for multi-agent systems in random networks. A min–max consensus algorithm is proposed, which incorporates the weighted average of the agent’s state, the maximum value of its neighbors’ states, and the minimum value of its neighbors’ states. The interaction network is composed of a directed random network where edges exist with probability and are independent of each other. Then, the convergence of the min–max consensus algorithm is investigated utilizing max-plus algebra, min-plus algebra, and stochastic analysis theory. Sufficient and necessary conditions are given to ensure that the multi-agent systems achieve min–max consensus almost surely and in mean-square, respectively. Finally, some numerical simulations are conducted to confirm the effectiveness of the proposed consensus algorithm.},
  archive      = {J_NEUCOM},
  author       = {Hailong Li and Jianing Yang and Zhongjie Yin and Liqi Zhou and Jianxiang Xi and Yuanshi Zheng},
  doi          = {10.1016/j.neucom.2024.128148},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128148},
  shortjournal = {Neurocomputing},
  title        = {Min–max consensus of multi-agent systems in random networks},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FETR: Feature transformer for vehicle-infrastructure
cooperative 3D object detection. <em>NEUCOM</em>, <em>600</em>, 128147.
(<a href="https://doi.org/10.1016/j.neucom.2024.128147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D object detection plays a crucial role in the perception system of autonomous vehicles, however, the vehicle’s field of view is restricted due to obstructions from nearby vehicles and buildings. Vehicle-infrastructure cooperation can compensate for the issue of visibility, but due to discrepancies in timestamps between vehicle and infrastructure sensors as well as data transmission delays, there is typically a time asynchrony between vehicle and infrastructure data. Therefore, Feature Transformer (FETR) has been introduced, which is a vehicle-infrastructure cooperative 3D object detection model utilizing Transformer as a Feature Predictor. The Transformer Predictor is capable of predicting features of future frame based on the current frame features, efficiently addressing the problem of time asynchrony. Additionally, to enhance the precision of 3D object detection, we have introduced a plug-and-play module named Mask Feature Enhancement (MFE), MFE employs a mask to amplify the features in the object region while simultaneously diminishing the features of the surrounding environment, enlarging the difference between object features and environmental features, thereby improving the detection effect. Experimental results show that FETR attains a 68.15 BEV-mAP (IoU=0.5) on the DAIR-V2X dataset, with a 200ms latency, and the data transmission is merely 6 . 0 × 1 0 4 6.0×104 bytes, constituting just 4.2% of the original point cloud data, outperforming current vehicle-infrastructure cooperative models in terms of both precision and data transmission.},
  archive      = {J_NEUCOM},
  author       = {Wenchao Yan and Hua Cao and Jiazhong Chen and Tao Wu},
  doi          = {10.1016/j.neucom.2024.128147},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128147},
  shortjournal = {Neurocomputing},
  title        = {FETR: Feature transformer for vehicle-infrastructure cooperative 3D object detection},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel positive–negative graph convolutional network-based
fault diagnosis method with application to complex systems.
<em>NEUCOM</em>, <em>600</em>, 128145. (<a
href="https://doi.org/10.1016/j.neucom.2024.128145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis plays a crucial role in ensuring the safe and stable operation of complex industrial systems. Among various existing methods, graph convolutional network (GCN)-based methods can handle graph-structured data commonly found in industrial systems, due to their capability to capture complex relationships within datasets through association graphs. However, conventional GCN models exclusively consider positive association relationship between data, but do not account for the negative one, resulting in embedding vectors that exhibit clustering tendencies and the over-smoothing issue. To address these challenges, a positive–negative GCN-based fault diagnosis method is proposed in this paper. In the method, the conventional association graph is treated as a positive graph, and a corresponding negative one is constructed to capture negative relationships within the dataset. Furthermore, a graph-level data aggregation strategy is introduced to aggregate the information from both association graphs, and incorporate them into the forward propagation process. Fault diagnosis is achieved using a iteratively trained GCN model. Experimental results on two cases demonstrate that the proposed method outperforms existing fault diagnosis methods in terms of diagnostic performance.},
  archive      = {J_NEUCOM},
  author       = {Jiamin Xu and Siwen Mo and Zhaohui Jiang and Zhiwen Chen and Weihua Gui and Hongwei Wang},
  doi          = {10.1016/j.neucom.2024.128145},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128145},
  shortjournal = {Neurocomputing},
  title        = {A novel positive–negative graph convolutional network-based fault diagnosis method with application to complex systems},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning from NN-based extended PID control for a class of
high-order uncertain nonlinear systems. <em>NEUCOM</em>, <em>600</em>,
128144. (<a href="https://doi.org/10.1016/j.neucom.2024.128144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As is well known, traditional PID controllers are the most widely used type of controllers in industrial control due to their simplicity and other advantages. However, the existing research results on PID controllers lack a general theory for addressing the nonlinearity and uncertainty present in practical systems. In the era of intelligent control, it is highly valuable to design an intelligent PID controller with learning capability for complex unknown nonlinear systems. In this paper, we consider an extended form of PID controller based on deterministic learning (DL) for high-order nonlinear systems with unknown dynamics. The introduction of neural networks (NNs) provides an effective tool to compensate for the composite unknown nonlinearities in controlled systems, overcoming the limitations of traditional PID controllers relying solely on feedback mechanisms to combat unknown nonlinearities. Based on the Lyapunov theory, it not only ensures the stability and tracking control of the system but also simplifies the selection of controller parameters. Furthermore, based on the DL theory, the composite unknown nonlinear dynamics can be accurately compensated and approximated, and the acquired knowledge can be stored in a constant-value neural network. When encountering similar control tasks, the acquired knowledge can be quickly accessed to construct a knowledge-based extended PID controller, thereby improving the overall control performance. Simulation results demonstrate the effectiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Qinchen Yang and Fukai Zhang and Cong Wang},
  doi          = {10.1016/j.neucom.2024.128144},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128144},
  shortjournal = {Neurocomputing},
  title        = {Learning from NN-based extended PID control for a class of high-order uncertain nonlinear systems},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). FDE-net: A memory-efficiency densely connected network
inspired from fractional-order differential equations for single image
super-resolution. <em>NEUCOM</em>, <em>600</em>, 128143. (<a
href="https://doi.org/10.1016/j.neucom.2024.128143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense connection has proved an effective way to take full advantage of hierarchical features extracted from low-resolution images using deep neural networks (DNNs) for single image super-resolution (SISR). However, existing densely connected networks are often manually designed and overly depended on practical experience, thus leading to suboptimal performance. Moreover, due to their complicated connections, they are memory-consuming and lack of interpretability. To address all these problems with one stone, we propose to construct a new densely connected network for SISR from a dynamic system perspective. Following this idea, we cast the hierarchical transformation of DNNs into the state evolution of a fractional-order dynamic system, which empowers us to automatically construct two interdependent densely connected modules based on the system solution rather manual design. They are a prediction module that controls the system to iteratively predict the next state, and a correction module that iteratively refines the predicted state to improve the prediction accuracy. With these two modules as backbone, we establish a Fractional-order Differential Equations-based network (FDE-Net) for SISR. Since the iterative computational manner requires both densely connected modules to be of the recurrent structure, FDE-Net is memory-efficiency and good interpretability. In addition, we analyze the existence and uniqueness of the solution for FDE to theoretically guarantee the feasibility of FDE-Net. Experiments on four SISR benchmark datasets demonstrate the superiority of FDE-Net over existing densely connected networks and other baselines in terms of generalization capacity, especially with limited memory.},
  archive      = {J_NEUCOM},
  author       = {Xiao Zhang and Lei Zhang and Wei Wei and Yuxuan Sun and Chunna Tian and Yanning Zhang},
  doi          = {10.1016/j.neucom.2024.128143},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128143},
  shortjournal = {Neurocomputing},
  title        = {FDE-net: A memory-efficiency densely connected network inspired from fractional-order differential equations for single image super-resolution},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Design of consensus and cluster consensus controller for
first-order nonlinear multi-agent systems based on subgroup structure.
<em>NEUCOM</em>, <em>600</em>, 128141. (<a
href="https://doi.org/10.1016/j.neucom.2024.128141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that nonlinear multi-agent systems (MASs) with a directed topology can reach a consensus if the global coupling coefficient is strong enough. In this paper, we propose a novel distributed protocol based on the subgroup structure. Our results demonstrate that the MAS design can follow a part-to-whole approach, starting with subgroups and gradually building up to a more complex system. We firstly consider two cases for the MASs: one with a single leader and one with a leader group, where agents within the leader group can communicate with each other, but cannot receive the information of other group. We show that followers can track the leader or group leaders if intra-coupling within the subgroup and information strength received by the root node are above a certain threshold. Next, we investigate cluster consensus and practical cluster consensus for the Laplacian matrix with unequal row sum, equal row sum, and mixing of partitioned matrices. Our results reveal that row sum and community structure of the partitioned matrix are crucial in determining the final state of each agent. Our proposed control protocol is highly flexible and relies only on the cluster structure and information received by the root node, rather than global information. Moreover, our method is not limited to tracking problems, cooperative control, or multi-objective control, and can accommodate new group agents joining the system, making it highly adaptable. We provide illustrative examples to demonstrate the effectiveness of our approach.},
  archive      = {J_NEUCOM},
  author       = {Yi Wang and Zhongjun Ma and Guoyuan Chen and Jinde Cao},
  doi          = {10.1016/j.neucom.2024.128141},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128141},
  shortjournal = {Neurocomputing},
  title        = {Design of consensus and cluster consensus controller for first-order nonlinear multi-agent systems based on subgroup structure},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lifelong reinforcement learning tracking control of
nonlinear strict-feedback systems using multilayer neural networks with
constraints. <em>NEUCOM</em>, <em>600</em>, 128139. (<a
href="https://doi.org/10.1016/j.neucom.2024.128139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel safe integral reinforcement learning (IRL)-based optimal trajectory tracking scheme for nonlinear systems with uncertain dynamics that is subject to constraints. We leverage multilayer neural networks (MNNs) for actor-critic MNNs along with an NN identifier in the backstepping process for minimizing a discounted value function. A time-varying barrier Lyapunov function (TVBLF) is utilized for handling constraints and to provide safety assurances. Online weight update laws for the actor and critic MNNs are derived that are driven by Bellman error and control input error. We introduce an online lifelong learning (LL) method in the critic NN, utilizing the Bellman error in MNNs to address catastrophic forgetting. The method’s effectiveness is demonstrated through simulations on mobile robot multitask tracking. The paper concludes with a stability analysis of the closed-loop system.},
  archive      = {J_NEUCOM},
  author       = {Irfan Ganie and S. Jagannathan},
  doi          = {10.1016/j.neucom.2024.128139},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128139},
  shortjournal = {Neurocomputing},
  title        = {Lifelong reinforcement learning tracking control of nonlinear strict-feedback systems using multilayer neural networks with constraints},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unveiling SAR target recognition networks: Adaptive
perturbation interpretation for enhanced understanding. <em>NEUCOM</em>,
<em>600</em>, 128137. (<a
href="https://doi.org/10.1016/j.neucom.2024.128137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have obtained remarkable achievements in various vision tasks. However, DNNs’ mechanism remains obscure, especially in synthetic aperture radar (SAR) target recognition. To clearly understand DNNs’ mechanism, some interpretation algorithms are proposed to provide a saliency map to visualize DNN’s decisions, which can be categorized into (1) propagation-based methods, (2) activation-based methods, and (3) perturbation-based methods. Unfortunately, each of them has some imperfection in producing saliency maps. The saliency maps produced by propagation-based methods are sensitive to SAR speckles. Activation-based methods have difficulty producing a saliency map where the highlighted region covers the entire feature. Perturbation-based methods tend to forfeit intricate details of the target in saliency map during optimization. To mitigate the above limitations, this paper proposed Adaptive Perturbation Interpretation (API), with two aims: (1) to improve the interpretability of SAR recognition networks and (2) to recover the fine-grained lost during the optimization procedures of perturbation-based methods. Specifically, we first introduce a Multi-information Perturbation Optimization Module (MPOM) to retain the target’s local characteristics while constraining saliency map’s sparsity by configuring regularization terms. Additionally, we further introduce a Feature Compensation Module (FCM) to recover the fine-grained feature lost during the optimization process in MPOM. Extensive experiments are implemented on SAR interpretation benchmark datasets, MSTAR and SARAIRcraft1.0, the results demonstrate the superiority of API to other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Mingzhe Zhu and Xuran Hu and Zhenpeng Feng and Ljubiša Stanković},
  doi          = {10.1016/j.neucom.2024.128137},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128137},
  shortjournal = {Neurocomputing},
  title        = {Unveiling SAR target recognition networks: Adaptive perturbation interpretation for enhanced understanding},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fully distributed observer-based scaled consensus of
multi-agent systems with actuator saturation and edge-based
event-triggered communication. <em>NEUCOM</em>, <em>600</em>, 128134.
(<a href="https://doi.org/10.1016/j.neucom.2024.128134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work uses an edge-based event-triggered technique to study the adaptive scaled consensus of general linear multi-agent systems with actuator saturation and unmeasurable internal states. By proposing an edge-based event-triggered scaled algorithm, constructing an improved Lyapunov function, and introducing a low-gain feedback technique, the difficulties generated by actuator saturation and scaling property are overcome, and a triggering condition based on the triggering function is obtained, under which the scaled consensus is achieved, and the Zeno behavior is excluded. This work’s results are more flexible than existing results; in other words, triggering numbers and convergence rates are adjusted in this work. Finally, several examples are proposed to verify the results and their interesting characteristics.},
  archive      = {J_NEUCOM},
  author       = {Yaping Sun and Xinsong Yang and Housheng Su},
  doi          = {10.1016/j.neucom.2024.128134},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128134},
  shortjournal = {Neurocomputing},
  title        = {Fully distributed observer-based scaled consensus of multi-agent systems with actuator saturation and edge-based event-triggered communication},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A semantic backdoor attack against graph convolutional
networks. <em>NEUCOM</em>, <em>600</em>, 128133. (<a
href="https://doi.org/10.1016/j.neucom.2024.128133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) have been very effective in addressing the issue of various graph-structured related tasks, such as node classification and graph classification. However, recent research has shown that GCNs are vulnerable to a new type of threat called a backdoor attack, where the adversary can inject a hidden backdoor into GCNs so that the attacked model performs well on benign samples, but its prediction will be maliciously changed to the attacker-specified target class if the hidden backdoor is activated by the attacker-defined trigger. A semantic backdoor attack is a new type of backdoor attack on deep neural networks (DNNs), where a naturally occurring semantic feature of samples can serve as a backdoor trigger such that the infected DNNs models will misclassify testing samples containing the predefined semantic feature even without the requirement of modifying the testing samples. Since the backdoor trigger is a naturally occurring semantic feature of the samples, semantic backdoor attacks are more imperceptible and pose a new and serious threat. Existing research on semantic backdoor attacks focuses on the tasks of CNNs-based (Convolutional Neural Networks) image classification and LSTM-based (Long Short-Term Memory) text classification or word prediction. Little attention has been given to semantic backdoor attacks on GCNs models. In this paper, we investigate whether such semantic backdoor attacks are possible for GCNs and propose a s emantic b ackdoor a ttack against G CNs ( SBAG ) under the context of graph classification to reveal the existence of this security vulnerability in GCNs. SBAG uses a certain type of nodes in the samples as a backdoor trigger and injects a hidden backdoor into GCNs models by poisoning training data. The backdoor will be activated, and the GCNs models will give malicious classification results specified by the attacker even on unmodified samples as long as the samples contain enough trigger nodes. We evaluate SBAG on five graph datasets. The experimental results indicate that SBAG can achieve attack success rates of approximately 99.9% on unmodified testing samples that naturally contain the trigger and attack success rates over 82% on testing samples modified to inject the trigger, respectively, both under poisoning rates of less than 5%. 1},
  archive      = {J_NEUCOM},
  author       = {Jiazhu Dai and Zhipeng Xiong and Chenhong Cao},
  doi          = {10.1016/j.neucom.2024.128133},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128133},
  shortjournal = {Neurocomputing},
  title        = {A semantic backdoor attack against graph convolutional networks},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Generalizing event-based HDR imaging to various exposures.
<em>NEUCOM</em>, <em>600</em>, 128132. (<a
href="https://doi.org/10.1016/j.neucom.2024.128132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-exposure High Dynamic Range Imaging (HDRI), as a typical ill-posed problem, has attracted extensive attention from researchers. However, restoration in real-world scenarios has always been an intractable task due to various exposures and noise artifacts. This work proposes an event-based HDRI framework that generalizes to scenes under various exposures by exploiting the high dynamic range of events. To address the challenge of processing diverse exposures, we propose an exposure-aware network incorporating the exposure attention fusion module, which facilitates the adaptive fusion of SDR image and event features. Moreover, the problem of noise in extremely under-exposed regions and events is effectively alleviated by introducing a self-supervised loss, namely EDDN, which effectively enhances the details of saturated areas while simultaneously decreasing noise. We conduct novel event-based HDRI datasets to evaluate our proposed method for benchmarking with diverse exposed images. Comprehensive experiments have demonstrated that our method outperforms the state-of-the-art.},
  archive      = {J_NEUCOM},
  author       = {Xiaopeng Li and Qingyang Lu and Cien Fan and Chen Zhao and Lian Zou and Lei Yu},
  doi          = {10.1016/j.neucom.2024.128132},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128132},
  shortjournal = {Neurocomputing},
  title        = {Generalizing event-based HDR imaging to various exposures},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ethics-aware face recognition aided by synthetic face
images. <em>NEUCOM</em>, <em>600</em>, 128129. (<a
href="https://doi.org/10.1016/j.neucom.2024.128129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current face recognition models trained on large-scale face datasets have achieved promising performance. However, using face images to train a face recognition model without consent would lead to severe privacy and ethical issues. Moreover, existing face recognition models also exhibit uneven performance on different races, thus perplexing vulnerable populations. To address the aforementioned two issues, this work investigates an ethics-aware face recognition method and examines whether we can leverage synthesized faces to achieve a high-accuracy racial balanced recognition model. In a nutshell, we introduce a race-controllable and identity-innumerable face synthesis approach to generate synthetic face images, and then employ the synthesized images to improve face recognition accuracy and mitigate recognition imbalance among different races despite the scarcity of consenting images (less than 100 individuals). More importantly, the synthetic data enable us to analyze the potential impacts of races on face recognition models quantitatively and facilitate the eradication of racial imbalance in face recognition. Extensive experiments demonstrate that employing our synthetic face data improves face recognition accuracy by a large margin while mitigating the recognition imbalance across different race groups.},
  archive      = {J_NEUCOM},
  author       = {Xiaobiao Du and Xin Yu and Jinhui Liu and Beifen Dai and Feng Xu},
  doi          = {10.1016/j.neucom.2024.128129},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128129},
  shortjournal = {Neurocomputing},
  title        = {Ethics-aware face recognition aided by synthetic face images},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Granular transfer learning. <em>NEUCOM</em>, <em>600</em>,
128126. (<a href="https://doi.org/10.1016/j.neucom.2024.128126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning is aimed at supporting the design of machine learning models in the target domain D t , given that the knowledge (model) has already been constructed in the source domain D s . The domains D t and D s (as well as the corresponding tasks T s and T t ) are similar, yet not identical. As a result, the model transferred from D s to D t in this new environment exhibits its relevance (credibility) only to some limited extent. In this study, we develop an original approach, where we advocate that the knowledge transfer (model transfer) gives rise to a granular model where the level of information granularity associated with the produced results quantifies the relevance (quality or credibility) of the transferred model. In other words, we stress that the quality of knowledge transferred to D t becomes captured through a granular generalization of the original numeric model. The overall systematic design process is elaborated on by focusing on the development process of granular neural networks carried out on a basis of the numeric neural networks coming from D s . The key aspect of the design is to elevate the existing numeric neural network to its granular counterpart by admitting that the connections of the developed model come in the form of information granules, in particular intervals and fuzzy sets. The optimization process is guided by adjusting (optimizing) the level of information granularity being regarded as an essential design asset. The optimized performance index builds upon the descriptors of information granules commonly encountered in Granular Computing. In particular, coverage and specificity measures are treated as sound performance indicators of the quality of knowledge transfer (viz. the performance of the granular neural network expressed in the target domain). Several illustrative examples are provided to visualize the performance of the established design environment.},
  archive      = {J_NEUCOM},
  author       = {Rami Al-Hmouz and Witold Pedrycz and Medhat Awadallah and Ahmed Ammari},
  doi          = {10.1016/j.neucom.2024.128126},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128126},
  shortjournal = {Neurocomputing},
  title        = {Granular transfer learning},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A learning-based framework for topology-preserving
segmentation using quasiconformal mappings. <em>NEUCOM</em>,
<em>600</em>, 128124. (<a
href="https://doi.org/10.1016/j.neucom.2024.128124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose the Topology-Preserving Segmentation Network, a deformation-based model that can extract objects in an image while maintaining their topological properties. This network generates segmentation masks that have the same topology as the template mask, even when trained with limited data. The network consists of two components: the Deformation Estimation Network, which produces a deformation map that warps the template mask to enclose the region of interest, and the Beltrami Adjustment Module, which ensures the bijectivity of the deformation map by truncating the associated Beltrami coefficient based on Quasiconformal theories. The proposed network can also be trained in an unsupervised manner, eliminating the need for labeled training data. This is achieved by incorporating an unsupervised segmentation loss. Our experimental results on various image datasets show that TPSN achieves better segmentation accuracy than state-of-the-art models with correct topology. Furthermore, we demonstrate TPSN’s ability to handle multiple object segmentation.},
  archive      = {J_NEUCOM},
  author       = {Han Zhang and Lok Ming Lui},
  doi          = {10.1016/j.neucom.2024.128124},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128124},
  shortjournal = {Neurocomputing},
  title        = {A learning-based framework for topology-preserving segmentation using quasiconformal mappings},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data augmentation for gram-stain images based on vector
quantized variational AutoEncoder. <em>NEUCOM</em>, <em>600</em>,
128123. (<a href="https://doi.org/10.1016/j.neucom.2024.128123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Availability of large-scale datasets plays a significant role in segmentation and classification tasks using deep learning. However, domains such as healthcare inherently suffer from unavailability and inaccessibility of data. This leads to challenges in deploying CNN-based models for computer-aided diagnosis. This challenge extends to Gram-stain image analysis for detecting bacterial infections, which is a crucial task. The lack of datasets containing Gram-stained direct and culture smear images exacerbates the significant challenges in deep learning tasks. In this regard, we investigate a novel application of the Variational AutoEncoder. Specifically, the Vector Quantized Variational AutoEncoder model is trained to generate the Gram-stain images. Incorporating a novel loss function, where the quality loss ( L q u Lqu ) is derived by integrating the L o s s S S I M LossSSIM , L 1 L1 , and L 2 L2 losses with the VQ-VAE loss ( L o s s v q Lossvq ) for proposed approach for Gram-stained direct and culture smear images. This modification facilitates the creation of images closely resembling the original input, leading to notable SSIM scores of 0.92 for Gram-stained culture images and 0.88 for Gram-stained direct smear images. The current study compares the proposed method with state-of-the-art machine learning based and CNN based transformations. This work also demonstrates the classification process with and without image augmentation. It shows that the area under the curve in the case of augmentation is higher by an average of 20%.},
  archive      = {J_NEUCOM},
  author       = {Shwetha V and Keerthana Prasad and Chiranjay Mukhopadhyay and Barnini Banerjee},
  doi          = {10.1016/j.neucom.2024.128123},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128123},
  shortjournal = {Neurocomputing},
  title        = {Data augmentation for gram-stain images based on vector quantized variational AutoEncoder},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving radiology report generation with multi-grained
abnormality prediction. <em>NEUCOM</em>, <em>600</em>, 128122. (<a
href="https://doi.org/10.1016/j.neucom.2024.128122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional data-driven approaches for radiology report generation face a problem that the descriptions of the normal regions in the real data are much more than the that for abnormal ones, which potentially leads to the bias of losing focus on abnormalities. Previous work showed promising results owing to the fact that most of the content in reports are described within normal range, which, although fluent, has the limitation of tending to favor the evaluation metrics rather than produce useful hints for human judgment and model learning. To this end, we propose to explicitly predict abnormalities for radiology report generation, following a multi-task learning scheme to drive the model paying more attention on the abnormal regions with multi-grained information, including abnormalities in different granularities, so as to tackle the aforementioned limitation for report generation. In doing so, we propose a disease detector (DD) to identify coarse-grained abnormality, and a medical concept detector (MCD) to associate the predicted disease with the predefined fine-grained pathological concepts. To integrate the information from the proposed abnormality prediction, we design a dual-stream adaptive decoder that takes such information into account with a gate unit controls the integration at each generation step. Extensive experiment results on two widely used benchmark datasets indicate that our method achieves 29.8% and 34.2% performance improvement over the baseline on the natural language generation (NLG) metrics and clinical efficacy (CE) metrics respectively, demonstrate the superiority of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Yuda Jin and Weidong Chen and Yuanhe Tian and Yan Song and Chenggang Yan},
  doi          = {10.1016/j.neucom.2024.128122},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128122},
  shortjournal = {Neurocomputing},
  title        = {Improving radiology report generation with multi-grained abnormality prediction},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unified deep semantic expansion framework for
domain-generalized person re-identification. <em>NEUCOM</em>,
<em>600</em>, 128120. (<a
href="https://doi.org/10.1016/j.neucom.2024.128120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised Person Re-identification (Person ReID) methods have achieved excellent performance when training and testing within one camera network. However, they usually suffer from considerable performance degradation when applied to different camera systems. In recent years, many Domain Adaptation Person ReID methods have been proposed, achieving impressive performance without requiring labeled data from the target domain. However, these approaches still need the unlabeled data of the target domain during the training process, making them impractical in many real-world scenarios. Our work focuses on the more practical Domain Generalized Person Re-identification (DG-ReID) problem. Given one or more source domains, it aims to learn a generalized model that can be applied to unseen target domains. One promising research direction in DG-ReID is the use of implicit deep semantic feature expansion, and our previous method, Domain Embedding Expansion (DEX), is one such example that achieves powerful results in DG-ReID. However, in this work we show that DEX and other similar implicit deep semantic feature expansion methods, due to limitations in their proposed loss function, fail to reach their full potential on large evaluation benchmarks as they have a tendency to saturate too early. Leveraging on this analysis, we propose Unified Deep Semantic Expansion, our novel framework that unifies implicit and explicit semantic feature expansion techniques in a single framework to mitigate this early over-fitting and achieve a new state-of-the-art (SOTA) in all DG-ReID benchmarks. Further, we apply our method on more general image retrieval tasks, also surpassing the current SOTA in all of these benchmarks by wide margins.},
  archive      = {J_NEUCOM},
  author       = {Eugene P.W. Ang and Shan Lin and Alex C. Kot},
  doi          = {10.1016/j.neucom.2024.128120},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128120},
  shortjournal = {Neurocomputing},
  title        = {A unified deep semantic expansion framework for domain-generalized person re-identification},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A cognition-driven framework for few-shot class-incremental
learning. <em>NEUCOM</em>, <em>600</em>, 128118. (<a
href="https://doi.org/10.1016/j.neucom.2024.128118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-Shot Class-Incremental Learning (FSCIL) aims at integrating new concepts from a minimal set of instances while preserving previously acquired knowledge. This study explores the potential of Vision Transformers (ViTs) in addressing the challenges inherent in the FSCIL paradigm, such as catastrophic forgetting and overfitting problems. Drawing insights from cognitive neuroscience, we propose a Cognition-Driven Framework (CoDF) for FSCIL, leveraging Vision Transformers to emulate human cognitive processes from the aspects of Intuitive Acquisition and Structured Cognition. On the one hand, we employ self-supervised learning techniques to imbue the representations with richer information, thereby facilitating a more intuitive acquisition of essential information to solve FSCIL tasks. On the other hand, we propose to structure the learned representations by introducing biases into the prior distribution of the latent factors, which involves a multivariate Gaussian Mixture Model (GMM) and an intra-class distribution assumption. Furthermore, we apply an innovative extended warm-up strategy to effectively harness the acquired representations for downstream tasks. Comprehensive experiments on three public datasets substantiate the efficacy of our proposed framework.},
  archive      = {J_NEUCOM},
  author       = {Xuan Wang and Zhong Ji and Yanwei Pang and Yunlong Yu},
  doi          = {10.1016/j.neucom.2024.128118},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128118},
  shortjournal = {Neurocomputing},
  title        = {A cognition-driven framework for few-shot class-incremental learning},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-scale information integration framework for infrared
and visible image fusion. <em>NEUCOM</em>, <em>600</em>, 128116. (<a
href="https://doi.org/10.1016/j.neucom.2024.128116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion aims at generating a fused image containing the intensity and detail information of source images, and the key issue is effectively measuring and integrating the complementary information of multi-modality images from the same scene. Existing methods mostly adopt a simple weight in the loss function to decide the information retention of each modality rather than adaptively measuring complementary information for different image pairs. In this study, we propose a multi-scale dual attention (MDA) framework for infrared and visible image fusion, which is designed to measure and integrate multi-scale complementary information in both structure and loss function at the image and patch level. In our method, the residual downsample block decomposes source images into three scales first. Then, dual attention fusion block integrates complementary information and generates a spatial and channel attention map at the same and adjacent scale for feature fusion. Finally, the output image is reconstructed by the residual reconstruction block. Loss function consists of image-level, feature-level and patch-level three parts, of which the calculation of the image-level and patch-level two parts are based on the weights generated by the complementary information measurement. Indeed, to constrain the pixel intensity distribution between the output and infrared image, a style loss is added. Our fusion results perform robust and informative across different scenarios. Qualitative and quantitative results on three datasets illustrate that our method is able to preserve both thermal radiation and detailed information from two modalities and achieve comparable results compared with the other state-of-the-art methods. Ablation experiments show the effectiveness of our information integration architecture and adaptively measure complementary information retention in the loss function. Our code is available at https://github.com/SSyangguang/MDA .},
  archive      = {J_NEUCOM},
  author       = {Guang Yang and Jie Li and Hanxiao Lei and Xinbo Gao},
  doi          = {10.1016/j.neucom.2024.128116},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128116},
  shortjournal = {Neurocomputing},
  title        = {A multi-scale information integration framework for infrared and visible image fusion},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PatchSkip: A lightweight technique for effectively
alleviating over-smoothing in vision transformers. <em>NEUCOM</em>,
<em>600</em>, 128112. (<a
href="https://doi.org/10.1016/j.neucom.2024.128112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently vision transformers (ViTs) have encountered the over-smoothing problem, which reduces their capacity by mapping input patches into a similar latent representation. Existing methods introduce regularization terms to alleviate over-smoothing but often increase computational costs. To address this, this paper proposes PatchSkip, a novel and flexible dropout variant, alleviating the over-smoothing problem of ViTs in a lightweight manner. Specifically, PatchSkip draws inspiration from the fact that a similar over-smoothing problem in GNNs is primarily caused by static adjacent matrices leading to solitary message passing mode between nodes. PatchSkip constructs graphs with patch embeddings and analyzes the adjacent matrices in ViTs. By randomly selecting specific patch embeddings to bypass transformer blocks, PatchSkip is proved to generate various adjacent matrices and acts as a multi-mode message passing engine, providing diverse modes of message passing between patches. The effectiveness of PatchSkip in preventing over-smoothing is demonstrated through theoretical proofs and empirical visualizations. Furthermore, PatchSkip is evaluated on various datasets and backbones, showing significant performance improvements while reducing computational costs. For example, when trained on Tiny-ImageNet from scratch, PatchSkip improves the performance of the vanilla CrossViT by 3.85% while reducing computational costs by over 20%.},
  archive      = {J_NEUCOM},
  author       = {Jiafeng Zhao and Xiang Ye and Bohan Li and Yong Li},
  doi          = {10.1016/j.neucom.2024.128112},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128112},
  shortjournal = {Neurocomputing},
  title        = {PatchSkip: A lightweight technique for effectively alleviating over-smoothing in vision transformers},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neighborhood repartition-based oversampling algorithm for
multiclass imbalanced data with label noise. <em>NEUCOM</em>,
<em>600</em>, 128090. (<a
href="https://doi.org/10.1016/j.neucom.2024.128090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of imbalanced data remains one of the most significant topics in contemporary data analysis. Existing classification algorithms tend to favor majority classes, leading to false predictions and difficulties in addressing class overlap or label noise. These challenges are particularly evident in multiclass settings, where the mutual imbalance relationships among classes become more complex. Despite this, the vast majority of research in this field has concentrated on binary problems, while the more difficult multiclass problems are relatively underexplored. In this paper, we propose a novel data-sampling technique, a Multiclass Neighborhood Repartition-based Oversampling (MC-NRO) algorithm. The innovation of this method lies in it considers local data characteristics of each class to constrain the oversampled neighborhood. MC-NRO calculates the mutual potential of different classes to precisely optimize the subregions for generating new instances. By selecting different repartition neighborhoods to meet the needs of specific domain, it can detect outliers and label noise, expand the decision boundary of minority class, and avoid class overlap through data cleaning. The experimental results demonstrate that MC-NRO outperforms other advanced oversampling strategies, ranking first on average across the three evaluation metrics, and exhibits robustness, especially in datasets with high noise levels. More importantly, MC-NRO is highly versatile and can be flexibly applied to various classifiers, and is particularly suitable for processing naturally complex (i.e., not affected by noise) datasets.},
  archive      = {J_NEUCOM},
  author       = {Shiyi Shen and Zhixin Li and Zhan Huan and Fanqi Shang and Yongsong Wang and Ying Chen},
  doi          = {10.1016/j.neucom.2024.128090},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128090},
  shortjournal = {Neurocomputing},
  title        = {Neighborhood repartition-based oversampling algorithm for multiclass imbalanced data with label noise},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). FeatSync: 3D point cloud multiview registration with
attention feature-based refinement. <em>NEUCOM</em>, <em>600</em>,
128088. (<a href="https://doi.org/10.1016/j.neucom.2024.128088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current studies often decompose multiview registration into several individual tasks, ignoring the correlation between each stage and making certain assumptions on noise distribution without knowledge from previous stages. These issues bring difficulties in generalization to real cases. In this paper, we propose an end-to-end feature-based multiview registration model that takes a set of raw 3D point cloud fragments as input and outputs the global transformation. Unlike previous works, our method allows the exchange of information between stages. We firstly estimate pairwise registration by a attention-based model to assist feature learning. In the next stage, we utilize iteratively reweighted least squares (IRLS) algorithm to refine and obtain the global transformation. In each iteration, instead of making assumptions on noises, we directly construct a model to infer the outliers from pairwise registration so that such an inference can help synchronization produce more reliable results. To follow the process in IRLS algorithm, we propose a simple yet effective refinement module to boost feature-based pairwise estimations in an iterative manner, which can be seamlessly integrated into the IRLS procedure. Extensive experiments conducted on benchmark datasets show that the results of our proposed method outperformed existing methods.},
  archive      = {J_NEUCOM},
  author       = {Yiheng Hu and Binghao Li and Chengpei Xu and Sarp Saydam and Wenjie Zhang},
  doi          = {10.1016/j.neucom.2024.128088},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128088},
  shortjournal = {Neurocomputing},
  title        = {FeatSync: 3D point cloud multiview registration with attention feature-based refinement},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Local residual preserving non-negative matrix factorization
for multi-view clustering. <em>NEUCOM</em>, <em>600</em>, 128054. (<a
href="https://doi.org/10.1016/j.neucom.2024.128054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering precisely represents the intrinsic attributes of data from different perspectives. However, most existing multi-view clustering methods mainly focus on important properties, i.e. consistency and complementarity, embedded in the multi-view data, ignoring the particular statistical property of each individual view. In this paper, we propose a novel local residual-preserving non-negative matrix factorization (LRPNMF) approach for multi-view clustering. The particular statistical properties of each view are identified via graph embedding, ensuring similar data points yield similar reconstruction residuals. As a result, each basis matrix captures the local residual structure of each view through graph embedding. We further centralize these basis matrices, compelling them to centralize with their mean. Additionally, we impose a sparse constraint to each basis matrix, ensuring each view provides a subset associated with the coefficient matrix to reconstruct the initial data. Consequently, LRPNMF captures more flexible and robust patterns in multi-view features. Experiments on different datasets demonstrated that LRPNMF outperforms the correlation method.},
  archive      = {J_NEUCOM},
  author       = {Jiaqing Li and Peipei Kang and Weijun Sun and Zhikun Jiang},
  doi          = {10.1016/j.neucom.2024.128054},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128054},
  shortjournal = {Neurocomputing},
  title        = {Local residual preserving non-negative matrix factorization for multi-view clustering},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event representation via contrastive learning with prototype
based hard negative sampling. <em>NEUCOM</em>, <em>600</em>, 128047. (<a
href="https://doi.org/10.1016/j.neucom.2024.128047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event representing methods usually use external knowledge to construct potentially more useful positive or negative samples, while neglecting the importance of sampling them during the training process. In this paper, we propose a prototype based negative sampling method to sample useful negatives and better learn the semantic classes. This sampling method has theoretical generalization guarantees and handles false negatives in a natural way. Furthermore, we apply a parametric augmentation strategy to generate positive pairs, which can alleviate BERT embedding bias and decouple the interrelation of augmented positive pairs. Experimental results show that our unsupervised approach has a 0.8%–5.1% improvement over state-of-the-art methods on hard similarity dataset, and a 2.62% improvement on the MCNC dataset. Our proposed method provides a novel insight into negative sampling and augmentation for event representation.},
  archive      = {J_NEUCOM},
  author       = {Jing Kong and Zhouwang Yang},
  doi          = {10.1016/j.neucom.2024.128047},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {128047},
  shortjournal = {Neurocomputing},
  title        = {Event representation via contrastive learning with prototype based hard negative sampling},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature-based analyses of concept drift. <em>NEUCOM</em>,
<em>600</em>, 127968. (<a
href="https://doi.org/10.1016/j.neucom.2024.127968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is one of the most relevant preprocessing and analysis techniques in machine learning. It can dramatically increase the performance of learning algorithms and at the same time provide relevant information on the data. In the scenario of online and stream learning, concept drift, i.e., changes in the underlying distribution over time, can cause significant problems for learning models and data analysis. While there do exist feature selection methods for online learning, none of the methods targets feature selection for drift detection, i.e., the challenge to increase the performance of drift detectors by analyzing the drift rather than increasing model accuracy. However, this challenge is particularly relevant for common unsupervised scenarios. In this work, we study feature selection for drift detection and drift monitoring. We develop a formal definition for a feature-wise notion of drift that allows semantic interpretation. Besides, we derive an efficient algorithm by reducing the problem to classical feature selection and analyze the applicability of our approach to feature selection for drift detection on a theoretical level. Finally, we empirically show the relevance of our considerations on several benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Fabian Hinder and Valerie Vaquet and Barbara Hammer},
  doi          = {10.1016/j.neucom.2024.127968},
  journal      = {Neurocomputing},
  month        = {10},
  pages        = {127968},
  shortjournal = {Neurocomputing},
  title        = {Feature-based analyses of concept drift},
  volume       = {600},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Clustering-based mask recovery for image captioning.
<em>NEUCOM</em>, <em>599</em>, 128127. (<a
href="https://doi.org/10.1016/j.neucom.2024.128127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Region features play a huge role in image captioning. However, obtaining region features requires pre-training an object detector by using a large number of object detection datasets. It may be impossible for the end-to-end training. And if there is a large distribution difference between the object detection datasets and the image captioning datasets, the object detector may not be able to extract accurate region features. This makes it limited in application. In this paper, we propose a clustering-based mask recovery for image captioning. In the encoder, the pseudo-region features are obtained by clustering the grid features, which are extracted using Swin Transformer. Then we input the grid features together with the pseudo-region features into the decoder, and make the model to dynamically learns the weights of the two features in the decoding process to minimize the effect of errors caused by clustering. By using a clustering method to generate pseudo-region features for images, not only does the training process become end-to-end, but there is no need to introduce additional object detection datasets to train the object detector. In addition, the Transformer decoder has a misplaced problem in the decoding process. This means that the positional information used by the model when generating a word is not the same as the positional information used when it continues to use the word to reason. This may have some negative impact on the position encoding of the model. Therefore, we changed the original decoding method to mask recovery. Furthermore, a masked multi-head attention module with relative position is proposed in the decoder to integrate the information in the fusion features, and reconstruct the relative position relationship between words. We conduct experiments on MSCOCO 2014 dataset. The experiment results show that our model obtains 144.3% (single model) and 147.0% (ensemble of 4 models) CIDEr scores on ‘Karpathy’ offline test split, and 143.2% (c40) CIDEr scores on the official online test server.},
  archive      = {J_NEUCOM},
  author       = {Xu Liang and Chen Li and Lihua Tian},
  doi          = {10.1016/j.neucom.2024.128127},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128127},
  shortjournal = {Neurocomputing},
  title        = {Clustering-based mask recovery for image captioning},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BSANet: Boundary-aware and scale-aggregation networks for
CMR image segmentation. <em>NEUCOM</em>, <em>599</em>, 128125. (<a
href="https://doi.org/10.1016/j.neucom.2024.128125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate segmentation of distinct cardiac regions from cardiac magnetic resonance (CMR) images is pivotal for enhancing the diagnosis and prognosis of heart diseases. However, the complex structure of the heart and the low contrast in CMR images pose significant challenges to achieving precise segmentation. In response to these difficulties, we propose a novel approach named BSANet, which integrates the inherent local characteristics of convolution with the global feature extraction of the Transformer through an elaborately designed multi-scale Boundary-Aware (MBA) module and a Scale-Aggregation TransFormer (SAT) module. The MBA module is specifically tailored to address the issue of blurry boundaries in CMR images. It enhances the edge extraction ability within low-level feature maps. On the other hand, the SAT module is designed to tackle the complexity and diversity of heart structures. This module retains crucial scale information to enhance segmentation performance while efficiently leveraging the computational capabilities of the Transformer via spatial reduction. Experimental results performed on three datasets show the superior performance of BSANet compared to the state-of-the-art methods. Notably, on the ACDC dataset, the proposed BSANet achieves the highest Dice score of 92.39%, while maintaining the lowest parameters. Furthermore, BSANet demonstrates optimal generalization performance on the RVSC and Sunnybrook datasets, underscoring its potential as a valuable tool for radiologists in clinical diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Dan Zhang and Chenggang Lu and Tao Tan and Behdad Dashtbozorg and Xi Long and Xiayu Xu and Jiong Zhang and Caifeng Shan},
  doi          = {10.1016/j.neucom.2024.128125},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128125},
  shortjournal = {Neurocomputing},
  title        = {BSANet: Boundary-aware and scale-aggregation networks for CMR image segmentation},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RDProtoFusion: Refined discriminative prototype-based
multi-task fusion for cross-domain few-shot learning. <em>NEUCOM</em>,
<em>599</em>, 128117. (<a
href="https://doi.org/10.1016/j.neucom.2024.128117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning and meta-learning have been widely studied for their ability to reduce the burden of data annotation. However, real-world applications often involve training and target tasks from different source and target domains, leading to poor generalization of existing methods. To address this issue, we propose a novel method called RDProtoFusion, which leverages refined discriminative class prototypes to achieve task augmentation and bridge the domain shift. Firstly, we refine naive prototypes with query samples to avoid computation bias caused by the limited support size. Secondly, we perform multi-task fusion through class-representative prototypes, resulting in flexible task-augmentation with low complexity that effectively alleviates overfitting. Thirdly, we propose a prototype contrastive loss to obtain robust and accurate prototypes, by enhancing the discrimination between class prototypes. The proposed prototype refinement, fusion and contrast can improve generalization of the model effectively. We conduct extensive experiments on multiple cross-domain few-shot learning benchmarks, demonstrating that RDProtoFusion achieves state-of-the-art performance. Overall, our proposed method shows great potential for addressing the challenge of domain shift in few-shot learning, offering a promising avenue for real-world applications.},
  archive      = {J_NEUCOM},
  author       = {Shuzhen Rao and Jun Huang and Zengming Tang},
  doi          = {10.1016/j.neucom.2024.128117},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128117},
  shortjournal = {Neurocomputing},
  title        = {RDProtoFusion: Refined discriminative prototype-based multi-task fusion for cross-domain few-shot learning},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain composition and attention network trained with
synthesized unlabeled images for generalizable medical image
segmentation. <em>NEUCOM</em>, <em>599</em>, 128115. (<a
href="https://doi.org/10.1016/j.neucom.2024.128115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite that deep learning models have achieved remarkable performance in medical image segmentation, their performance is often limited on testing images from new centers with a domain shift. To achieve Domain Generalization (DG) for medical image segmentation, we propose a Domain Composition and Attention-based Network (DCA-Net) combined with structure- and style-based data augmentation that generates unlabeled synthetic images for training. First, DCA-Net represents features in one certain domain by a linear combination of a set of basis representations that are learned by parallel domain preceptors with a divergence constraint. The linear combination is used to calibrate the feature maps of an input image, which enables the model to generalize to unseen domains. Second, considering the number of domains and images for training is limited, we employ generative models to synthesize images with a higher structure diversity, and to leverage the unlabeled synthetic images, we introduce a consistency constraint for their predictions under style augmentation based on frequency amplitude mixture. Additionally, a Test-Time Frequency Augmentation (TTFA) is proposed to neutralize the domain shift from the target to source domains. Experimental results on two multi-domain datasets for fundus structure and nasopharyngeal carcinoma segmentation showed that: (1) our method significantly outperformed several existing DG methods, and (2) the model’s generalizability was largely improved by domain composition and attention modules; (3) by leveraging the unlabeled synthetic images and the TTFA, the model could better deal with images from unseen domains.},
  archive      = {J_NEUCOM},
  author       = {Jiangshan Lu and Ran Gu and Wenjun Liao and Shichuan Zhang and Huijun Yu and Shaoting Zhang and Guotai Wang},
  doi          = {10.1016/j.neucom.2024.128115},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128115},
  shortjournal = {Neurocomputing},
  title        = {Domain composition and attention network trained with synthesized unlabeled images for generalizable medical image segmentation},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable artificial intelligence: A survey of needs,
techniques, applications, and future direction. <em>NEUCOM</em>,
<em>599</em>, 128111. (<a
href="https://doi.org/10.1016/j.neucom.2024.128111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence models encounter significant challenges due to their black-box nature, particularly in safety-critical domains such as healthcare, finance, and autonomous vehicles. Explainable Artificial Intelligence (XAI) addresses these challenges by providing explanations for how these models make decisions and predictions, ensuring transparency, accountability, and fairness. Existing studies have examined the fundamental concepts of XAI, its general principles, and the scope of XAI techniques. However, there remains a gap in the literature as there are no comprehensive reviews that delve into the detailed mathematical representations, design methodologies of XAI models, and other associated aspects. This paper provides a comprehensive literature review encompassing common terminologies and definitions, the need for XAI, beneficiaries of XAI, a taxonomy of XAI methods, and the application of XAI methods in different application areas. The survey is aimed at XAI researchers, XAI practitioners, AI model developers, and XAI beneficiaries who are interested in enhancing the trustworthiness, transparency, accountability, and fairness of their AI models.},
  archive      = {J_NEUCOM},
  author       = {Melkamu Mersha and Khang Lam and Joseph Wood and Ali K. AlShami and Jugal Kalita},
  doi          = {10.1016/j.neucom.2024.128111},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128111},
  shortjournal = {Neurocomputing},
  title        = {Explainable artificial intelligence: A survey of needs, techniques, applications, and future direction},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient primal simplex method for solving large-scale
support vector machines. <em>NEUCOM</em>, <em>599</em>, 128109. (<a
href="https://doi.org/10.1016/j.neucom.2024.128109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last two decades, active set methods for training support vector machines (SVMs) have received a lot of attention due to their robustness and have shown excellent results for training large-scale problems. In this paper, we propose the primal simplex method to solve the quadratic programming problem encountered during the training phase of an SVM classification problem. Our novel approach, named PSM-SVM, generates iteratively a decreasing sequence of feasible points that converges to the optimal solution. Contrary to existing active set algorithms, PSM-SVM has the particularity to avoid using the null-space matrix and also the reduced Hessian matrix when the descent direction is calculated at each iteration. In addition, it starts with a working-set having only one support vector and also guarantees the nonsingularity of the basic matrix during all the iterations process. We have theoretically proven its global convergence and calculated its computational complexity. Numerical experiments on several data sets show the effectiveness of our approach compared to the popular active-set and decomposition methods.},
  archive      = {J_NEUCOM},
  author       = {Belkacem Brahmi},
  doi          = {10.1016/j.neucom.2024.128109},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128109},
  shortjournal = {Neurocomputing},
  title        = {An efficient primal simplex method for solving large-scale support vector machines},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Efficient filter pruning: Reducing model complexity through
redundancy graph decomposition. <em>NEUCOM</em>, <em>599</em>, 128108.
(<a href="https://doi.org/10.1016/j.neucom.2024.128108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Filter pruning has emerged as a crucial technique facilitating the efficient deployment of Convolutional Neural Networks (CNNs) on edge devices. The resultant lightweight models often present a challenging trade-off between performance and compression rate. Moreover, the excessive granularity of filter selection, coupled with intricate fine-tuning procedures, hampers the practical applicability of numerous pruning methodologies. To tackle these limitations, our paper introduces a novel pruning approach that initially constructs an undirected graph, effectively capturing convolutional layer redundancy by quantifying the similarity among output feature maps. Subsequently, our method iteratively eliminates highly redundant and low-value filters, employing both k k -core decomposition and importance ranking criteria. In practical implementation, we adopt a one-shot pruning strategy, thereby minimizing the requirement for extensive fine-tuning. Comprehensive comparative experiments demonstrate the efficacy of our proposed approach in achieving remarkable improvements in model compression without compromising performance. For instance, with CIFAR-10, our method achieves state-of-the-art results on DenseNet-40 with a mere 70 fine-tuning epochs, while effectively removing 49.39% of FLOPs, resulting in a mere 0.01% accuracy loss. Furthermore, in the context of ImageNet, our approach excels by removing 48.81% of FLOPs and 23.71% of parameters from ResNet-50, exhibiting only 1.47% and 0.83% decline in Top-1 and Top-5 Accuracy respectively. The code is publicly available at https://github.com/lijiang99/redundancy-graph-decomposition .},
  archive      = {J_NEUCOM},
  author       = {Jiang Li and Haijian Shao and Xing Deng and Yingtao Jiang},
  doi          = {10.1016/j.neucom.2024.128108},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128108},
  shortjournal = {Neurocomputing},
  title        = {Efficient filter pruning: Reducing model complexity through redundancy graph decomposition},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Accurate learning of graph representation with the
consideration of fuzzy overlapping community. <em>NEUCOM</em>,
<em>599</em>, 128107. (<a
href="https://doi.org/10.1016/j.neucom.2024.128107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph classification task plays a crucial role in many practical applications, for which the model is required to be capable of learning an accurate representation with discriminative characteristics, but existing methods typically fail to exploit the most authentic substructures for better representation. Aiming at this limitation, a fuzzy overlapping community guided subgraph neural network is proposed in this paper to make the best use of graph latent topologies for fine-grained representation learning and discriminative feature extraction, namely FS-GRAL. Taking multi-functional elements and their preferences fully into consideration, FS-GRAL allows the nodes to appear in more than one subgraph with different contributions for message passing, so that the model is powerful enough in capturing those natural aggregations inherent in complex networks to achieve accurate representation learning. Meanwhile, on the basis of learned accurate representations, a two-level pooling strategy dominated by intra-subgraph node discarding is presented for feature extraction, which enables graph latent topology can be integrated into extracted discriminative features, and thus the coarsened graph is more representative for graph classification. Extensive experiments on real-world benchmarks demonstrate that our fuzzy overlapping community guided subgraph neural network is highly competitive in learning the accurate graph representation and its intra-subgraph dominated two-level pooling strategy promotes a more promising classification performance.},
  archive      = {J_NEUCOM},
  author       = {Xin Liu and Yan Zhang and Zuping Zhang},
  doi          = {10.1016/j.neucom.2024.128107},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128107},
  shortjournal = {Neurocomputing},
  title        = {Accurate learning of graph representation with the consideration of fuzzy overlapping community},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual separated attention-based graph neural network.
<em>NEUCOM</em>, <em>599</em>, 128106. (<a
href="https://doi.org/10.1016/j.neucom.2024.128106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) offer a viable solution to model the inter-dependencies among labeled and unlabeled samples in a semi-supervised manner. However, their performances can degrade dramatically when the number of labels is extremely limited, which is due to the limitations of typical graph convolutional network design in most existing GNNs, including over-smoothing, difficulty in extending the propagation step, and failure to preserve the distinctiveness of each node. To address the issues, we propose a dual separated attention-based graph neural network (DSA-GNN) to deal with label scarcity in semi-supervised node classification. Firstly, DSA-GNN decouples feature propagation from representation transformation to alleviate the problems of over-smoothing and overfitting. Secondly, DSA-GNN separates self-representation learning from neighbor-representation learning by two feature extractors with different learnable parameters. As a result, the commonality between connected nodes and the distinctiveness of each node can be both preserved. Thirdly, DSA-GNN incorporates an attention-based label propagation mechanism to refine the label prediction of each node, by aggregating label prediction among the neighborhood based on adaptive edge coefficients. The extensive experimental results on the real-world datasets demonstrate the superiority of DSA-GNN for semi-supervised node classification, especially when the observed labels are extremely limited.},
  archive      = {J_NEUCOM},
  author       = {Xiao Shen and Kup-Sze Choi and Xi Zhou},
  doi          = {10.1016/j.neucom.2024.128106},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128106},
  shortjournal = {Neurocomputing},
  title        = {Dual separated attention-based graph neural network},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VIFNet: An end-to-end visible–infrared fusion network for
image dehazing. <em>NEUCOM</em>, <em>599</em>, 128105. (<a
href="https://doi.org/10.1016/j.neucom.2024.128105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image dehazing poses significant challenges in environmental perception. Recent research mainly focus on deep learning-based methods with single modality, while they may result in severe information loss especially in dense-haze scenarios. The infrared image exhibits robustness to the haze, however, existing methods have primarily treated the infrared modality as auxiliary information, failing to fully explore its rich information in dehazing. To address this challenge, the key insight of this study is to design a visible–infrared fusion network for image dehazing. In particular, we propose a multi-scale Deep Structure Feature Extraction (DSFE) module, which incorporates the Channel-Pixel Attention Block (CPAB) to restore more spatial and marginal information within the deep structural features. Additionally, we introduce an inconsistency weighted fusion strategy to merge the two modalities by leveraging the more reliable information. To validate this, we construct a visible–infrared multimodal dataset called AirSim-VID based on the AirSim simulation platform. Extensive experiments performed on challenging real and simulated image datasets demonstrate that VIFNet can outperform many state-of-the-art competing methods. The code and dataset are available at https://github.com/mengyu212/VIFNet_dehazing .},
  archive      = {J_NEUCOM},
  author       = {Meng Yu and Te Cui and Haoyang Lu and Yufeng Yue},
  doi          = {10.1016/j.neucom.2024.128105},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128105},
  shortjournal = {Neurocomputing},
  title        = {VIFNet: An end-to-end visible–infrared fusion network for image dehazing},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MambaTSR: You only need 90k parameters for traffic sign
recognition. <em>NEUCOM</em>, <em>599</em>, 128104. (<a
href="https://doi.org/10.1016/j.neucom.2024.128104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic Sign Recognition (TSR) has made significant progress in recent years, and both convolution neural network (CNN)-based and transformer-based models have been widely explored. In addition, combining CNN and transformer can effectively utilize both local and global information for judgment. However, this approach is still affected by the secondary complexity of transformer and cannot maximize the performance. Recently, a state space model (SSM)-based architecture called Mamba has been proposed, which excels in long-range modelling while maintaining linear complexity. When we directly use the Mamba architecture for TSR, it performs poorly because the local features cannot be fully utilized, which are crucial for recognizing traffic sign details. In this paper, we explore the potential of this SSM-based model in TSR from both efficiency and effectiveness perspectives, and we customize a MambaTSR architecture with ∼ 90k parameters and ∼ 1.4 ms processing time. Specifically, we use patch embedding and a four-stage encoder at the macro level, while at the micro level we employ three-stream adaptive mining embedding (TAME) to obtain local information and four efficient visual state space (EVSS) blocks to explore global associations. Experiments on German, China, and India datasets show that our method achieves optimal performance and reduces parameters by ∼ 89 % and processing time by ∼ 58 % compared to the state-of-the-art method. The code can be accessed at https://github.com/1024AILab/MambaTSR .},
  archive      = {J_NEUCOM},
  author       = {Yiyuan Ge and Zhihao Chen and Mingxin Yu and Qing Yue and Rui You and Lianqing Zhu},
  doi          = {10.1016/j.neucom.2024.128104},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128104},
  shortjournal = {Neurocomputing},
  title        = {MambaTSR: You only need 90k parameters for traffic sign recognition},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep image clustering: A survey. <em>NEUCOM</em>,
<em>599</em>, 128101. (<a
href="https://doi.org/10.1016/j.neucom.2024.128101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep image clustering networks have the capability to categorize unlabeled images, thereby effectively utilizing them. This paper synthesizes recent researches about deep image clustering network and summarizes them within a general framework. Image Preprocessing part transforms collected images into a dataset accepted by the network, then Image Embedding part embeds images from the dataset into vectors which represents image features. After Feature Processing part further reduces the dimensionality or enhances these features, the following Feature Clustering part divides the images into several categories. Cluster Result Processing part treats the clustering outcomes to implement weighted, multi-view, subspace, multimodal, or self-supervised methods. Downstream Applications part employ the clustering results to address various real-world problems. The performance of common baseline clustering methods and several feature extraction architectures are also compared and analyzed. The results indicate that within deep image clustering networks, the choice of clustering algorithm has a relatively minor impact on clustering performance, whereas the selection of the feature extraction network architecture is decisive for clustering metrics. The choice of architecture should be customized based on the characteristics of the dataset. Finally, we provide suggestions for potential research directions in deep image clustering networks.},
  archive      = {J_NEUCOM},
  author       = {Huajuan Huang and Chen Wang and Xiuxi Wei and Yongquan Zhou},
  doi          = {10.1016/j.neucom.2024.128101},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128101},
  shortjournal = {Neurocomputing},
  title        = {Deep image clustering: A survey},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of graph theory-based diagnosis of neurological
disorders based on EEG and MRI. <em>NEUCOM</em>, <em>599</em>, 128098.
(<a href="https://doi.org/10.1016/j.neucom.2024.128098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph theory analysis, as a mathematical tool, has been widely employed in studying the connectivity of the brain to explore the structural organization. Through the computation of graph theory metrics, it can effectively reveal the nonlinear and complex behavioral features of neuroimaging data, e.g., Electroencephalogram (EEG) and Magnetic Resonance Imaging (MRI), which are often challenging to interpret using simple linear methods. Graph neural networks (GNNs), employing deep learning, offer a more flexible approach to handling large-scale, high-dimensional brain network data. This review aims to investigate the applications of graph theory and Graph Neural Networks in the diagnosis of neurological disorders. The complexity and multi-level features of neurological disorders pose challenges for traditional methods in addressing such issues. The paper begins by introducing the fundamental principles of graph theory and GNNs, elucidates the mechanisms behind diagnosis process using these methods, and then provides a comprehensive overview of their specific applications. Finally, it discusses and summarizes the current challenges in this research field, proposing future directions for development. In conclusion, this review provides a thorough theoretical foundation and methodological insight for exploring the potential applications of graph theory and GNNs in the diagnosis of neurological disorders.},
  archive      = {J_NEUCOM},
  author       = {Ying Yan and Guanting Liu and Haoyang Cai and Edmond Qi Wu and Jun Cai and Adrian David Cheok and Na Liu and Tao Li and Zhiyong Fan},
  doi          = {10.1016/j.neucom.2024.128098},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128098},
  shortjournal = {Neurocomputing},
  title        = {A review of graph theory-based diagnosis of neurological disorders based on EEG and MRI},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of green artificial intelligence: Towards a more
sustainable future. <em>NEUCOM</em>, <em>599</em>, 128096. (<a
href="https://doi.org/10.1016/j.neucom.2024.128096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Green artificial intelligence (AI) is more environmentally friendly and inclusive than conventional AI, as it not only produces accurate results without increasing the computational cost but also ensures that any researcher with a laptop can perform high-quality research without the need for costly cloud servers. This paper discusses green AI as a pivotal approach to enhancing the environmental sustainability of AI systems. Described are AI solutions for eco-friendly practices in other fields (green-by AI), strategies for designing energy-efficient machine learning (ML) algorithms and models (green-in AI), and tools for accurately measuring and optimizing energy consumption. Also examined are the role of regulations in promoting green AI and future directions for sustainable ML. Underscored is the importance of aligning AI practices with environmental considerations, fostering a more eco-conscious and energy-efficient future for AI systems.},
  archive      = {J_NEUCOM},
  author       = {Verónica Bolón-Canedo and Laura Morán-Fernández and Brais Cancela and Amparo Alonso-Betanzos},
  doi          = {10.1016/j.neucom.2024.128096},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128096},
  shortjournal = {Neurocomputing},
  title        = {A review of green artificial intelligence: Towards a more sustainable future},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive multi-scale graph neural architecture search
framework. <em>NEUCOM</em>, <em>599</em>, 128094. (<a
href="https://doi.org/10.1016/j.neucom.2024.128094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have gained significant attention for their ability to learn representations from graph-structured data, in which message passing and feature fusion strategies play an essential role. However, traditional Graph Neural Architecture Search (GNAS) mainly focuses on optimization with a static perceptive field to ease the search process. To efficiently utilize latent relationships between non-adjacent nodes as well as edge features, this work proposes a novel two-stage approach that is able to optimize GNN structures more effectively by adaptively aggregating neighborhood features in multiple scales. This adaptive multi-scale GNAS is able to assign optimal weights for different neighbors in different graphs and learning tasks. In addition, it takes latent relationships and edge features into message passing into account, and can incorporate different feature fusion strategies. Compared with traditional ones, our proposed approach can explore a much larger and more diversified search space efficiently. We also prove that traditional multi-hop GNNs are low-pass filters, which can lead to the removal of important low-frequency components of signals from remote neighbors in a graph, and they are not even expressive enough to distinguish some simple regular graphs, justifying the superiority of our approach. Experiments with seven datasets across three graph learning tasks, including graph regression, node classification, and graph classification, demonstrate that our method yields significant improvement compared with state-of-the-art GNAS approaches and human-designed GNN approaches. Specifically, for example, with our framework, the MAE of the 12-layer AM-GNAS was 0.102 for the ZINC dataset, yielding over 25% improvement.},
  archive      = {J_NEUCOM},
  author       = {Lintao Yang and Pietro Liò and Xu Shen and Yuyang Zhang and Chengbin Peng},
  doi          = {10.1016/j.neucom.2024.128094},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128094},
  shortjournal = {Neurocomputing},
  title        = {Adaptive multi-scale graph neural architecture search framework},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual contrastive learning for multi-view clustering.
<em>NEUCOM</em>, <em>599</em>, 128093. (<a
href="https://doi.org/10.1016/j.neucom.2024.128093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-representation subspace clustering, based on the self-representation property of linear subspaces, has demonstrated superior performance in subspace clustering. However, many existing methods learn self-representation in the embedding space, which fails to accurately capture the clustering structure of the data. Additionally, in the data embedding process, only the shared features among clusters are removed, and the discriminative features that distinguish different clusters cannot be effectively selected. To address these limitations, we propose a contrastive learning-based self-representation subspace clustering method named Multi-view Contrastive Subspace Clustering (MCSC). This method integrates feature selection and self-representation learning into a unified framework. It learns a shared self-representation coefficient in both the embedding space and the original space using contrastive learning, which allows for a more accurate description of the linear relationship between samples and a better depiction of the inter-sample structure simultaneously. Moreover, we employ the ℓ 1 , 2 ℓ1,2 -norm for feature selection, which eliminates shared redundancies while preserving important features specific to each cluster, making the samples more distinguishable. Extensive experiments on six datasets verify the validity of our proposed model.},
  archive      = {J_NEUCOM},
  author       = {Yichen Bao and Wenhui Zhao and Qin Zhao and Quanxue Gao and Ming Yang},
  doi          = {10.1016/j.neucom.2024.128093},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128093},
  shortjournal = {Neurocomputing},
  title        = {Dual contrastive learning for multi-view clustering},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BC4LLM: A perspective of trusted artificial intelligence
when blockchain meets large language models. <em>NEUCOM</em>,
<em>599</em>, 128089. (<a
href="https://doi.org/10.1016/j.neucom.2024.128089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, artificial intelligence (AI) and machine learning (ML) are reshaping society&#39;s production methods and productivity, and also changing the paradigm of scientific research. Among them, the AI language model represented by ChatGPT has made great progress. Such large language models (LLMs) serve people in the form of AI-generated content (AIGC) and are widely used in consulting, healthcare, and education. However, it is difficult to guarantee the authenticity and reliability of AIGC learning data. In addition, there are also hidden dangers of privacy disclosure in distributed AI training. Moreover, the content generated by LLMs is difficult to identify and trace, and it is difficult to cross-platform mutual recognition. The above information security issues in the coming era of AI powered by LLMs will be infinitely amplified and affect everyone&#39;s life. Therefore, we consider empowering LLMs using blockchain technology with superior security features to propose a vision for trusted AI. This survey mainly introduces the motivation and technical route of blockchain for LLM (BC4LLM), including reliable learning corpus, secure training process, and identifiable generated content. Meanwhile, this survey also reviews the potential applications and future challenges, especially in the frontier communication networks field, including network resource allocation, dynamic spectrum sharing, and semantic communication. Based on the above work combined with the prospect of blockchain and LLMs, it is expected to help the early realization of trusted AI and provide guidance for the academic community.},
  archive      = {J_NEUCOM},
  author       = {Haoxiang Luo and Jian Luo and Athanasios V. Vasilakos},
  doi          = {10.1016/j.neucom.2024.128089},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128089},
  shortjournal = {Neurocomputing},
  title        = {BC4LLM: A perspective of trusted artificial intelligence when blockchain meets large language models},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time local path planning strategy based on deep
distributional reinforcement learning. <em>NEUCOM</em>, <em>599</em>,
128085. (<a href="https://doi.org/10.1016/j.neucom.2024.128085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local path planning and obstacle avoidance in complex environments are two challenging problems in the research of intelligent robots. In this study, we develop a novel approach grounded in deep distributional reinforcement learning to address these challenges. Within this methodology, agents instantiated by deep neural networks perceive real-time local environmental information through sensor data, addressing inherent stochasticity and local path planning tasks in complex environments. End-to-end training is facilitated via distributional reinforcement learning algorithms and reward functions informed by heuristic knowledge. Optimal actions for path planning are determined through return value distributions. Finally, the simulation results show that the success rate of the proposed distributed algorithm is 98% in a random environment and 94% in a dynamic environment. This proves that the algorithm has better generalization and flexibility than the non-distributed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Shengli Du and Zexing Zhu and Xuefang Wang and Honggui Han and Junfei Qiao},
  doi          = {10.1016/j.neucom.2024.128085},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128085},
  shortjournal = {Neurocomputing},
  title        = {Real-time local path planning strategy based on deep distributional reinforcement learning},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PiClick: Picking the desired mask from multiple candidates
in click-based interactive segmentation. <em>NEUCOM</em>, <em>599</em>,
128083. (<a href="https://doi.org/10.1016/j.neucom.2024.128083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click-based interactive segmentation aims to generate target masks via human clicking, which facilitates efficient pixel-level annotation and image editing. In such a task, target ambiguity remains a problem hindering the accuracy and efficiency of segmentation. That is, in scenes with rich context, one click may correspond to multiple potential targets, while most previous interactive segmentors only generate a single mask and fail to deal with target ambiguity. In this paper, we propose a novel interactive segmentation network named PiClick , to yield all potentially reasonable masks and suggest the most plausible one for the user. Specifically, PiClick utilizes a Transformer-based architecture to generate all potential target masks by mutually interactive mask queries. Moreover, a Target Reasoning module is designed in PiClick to automatically suggest the user-desired mask from all candidates, relieving target ambiguity and extra-human efforts. Extensive experiments on 9 interactive segmentation datasets demonstrate PiClick performs favorably against previous state-of-the-arts considering the segmentation results. Moreover, we show that PiClick effectively reduces human efforts in annotating and picking the desired masks. To ease the usage and inspire future research, we release the source code of PiClick together with a plug-and-play annotation tool at https://github.com/cilinyan/PiClick .},
  archive      = {J_NEUCOM},
  author       = {Cilin Yan and Haochen Wang and Jie Liu and Xiaolong Jiang and Yao Hu and Xu Tang and Guoliang Kang and Efstratios Gavves},
  doi          = {10.1016/j.neucom.2024.128083},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128083},
  shortjournal = {Neurocomputing},
  title        = {PiClick: Picking the desired mask from multiple candidates in click-based interactive segmentation},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-level symmetric semantic alignment network for
image–text matching. <em>NEUCOM</em>, <em>599</em>, 128082. (<a
href="https://doi.org/10.1016/j.neucom.2024.128082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image–text matching has attracted much attention as one of the visual-linguistic tasks. Most of the existing methods tend to concentrate on single-level semantic similarity by global embeddings or local alignment, which fail to distinguish the ambiguous image–text instances with highly similar contexts due to insufficient interactions of cross-modal features. To mitigate this problem, in this paper, we propose a novel Multi-level Symmetric Semantic Alignment Network (MSSAN), which fully exploits the multi-level semantic features to capture the complicated correlations between images and text. Specifically, global–global-level alignment is first performed based on visual–textual global representations. Then, considering the local semantic consistency, local–local-level alignment is carried out through inter-modal bidirectional cross-attention module to model fine-grained region–word relations. Moreover, a Multi-granularity Feature Fusion Module (MFFM) is constructed to learn intra-modal distribution of significance and incorporate global concepts into local features to obtain more comprehensive semantic representations, thus achieving global–local-level alignment. Finally, in order to achieve a strong separation of semantically similar samples, we develop a novel generic triplet ranking loss with adaptively updatable margins to train our model. Extensive experimental results on Flickr8K, MSCOCO and Flickr30K datasets demonstrate that our proposed MSSAN is superior to other state-of-the-art methods by a considerable margin.},
  archive      = {J_NEUCOM},
  author       = {Wenzhuang Wang and Xiaoguang Di and Maozhen Liu and Feng Gao},
  doi          = {10.1016/j.neucom.2024.128082},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128082},
  shortjournal = {Neurocomputing},
  title        = {Multi-level symmetric semantic alignment network for image–text matching},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale feature fusion for single image novel view
synthesis. <em>NEUCOM</em>, <em>599</em>, 128081. (<a
href="https://doi.org/10.1016/j.neucom.2024.128081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single image novel view synthesis allows the generation of target images with different views from a single input image. Pixel generation methods are one of the main approaches for novel view synthesis, with previous methods typically using the input image to infer the target image in the new view. However, only features from input images in the source view might not be sufficient to generate a good target image, especially when only a single input image is available. In this paper, we fuse features from an input and a warped image to collaboratively generate pixels in the new view, with the warped image as an intermediate output generated by projecting pixels of the input image onto the target view via an estimated depth. Since the estimated depth and the generated warped image are not perfect, errors will be introduced when generating target pixels. To alleviate these and to ensure better channel information between the features from input and warped image, channel attention blocks are employed. In addition, in order to use skip connections for better novel view synthesis results, encoder features in different layers from the input image are transformed to the target view via multi-resolution depths. Here, instead of downsampling a single full-resolution depth to several lower-resolution depths, we adopt a multi-scale depth estimation network to predict multiple depths at different resolutions. Experimental results on benchmark datasets show that our method gives excellent view synthesis results and outperforms other state-of-the-art novel view synthesis methods.},
  archive      = {J_NEUCOM},
  author       = {Lei Jiang and Gerald Schaefer and Qinggang Meng},
  doi          = {10.1016/j.neucom.2024.128081},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128081},
  shortjournal = {Neurocomputing},
  title        = {Multi-scale feature fusion for single image novel view synthesis},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TMLNet: Triad multitask learning network for multiobjective
based change detection. <em>NEUCOM</em>, <em>599</em>, 128080. (<a
href="https://doi.org/10.1016/j.neucom.2024.128080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change detection is an essential computer vision task in remote sensing applications. It faces challenges of image registration errors, variation in image capturing conditions, clouds, etc. It is observed that an accurate change detection task requires effective feature learning, which needs a noiseless representation. Moreover, change detection improves with error-free image reconstruction as an auxiliary task, which needs joint feature representation by a feature extractor. In this work, we proposed a novel triad (which is a combination of input images and its difference) learning based multiresolution architecture TMLNet for effective change detection. We also proposed a multi-context local self-attention module to efficiently calculate long-range pixel relations with multiple contexts. An enhanced backbone module with top-down connections and multi-scale channel and spatial attention is utilized for change map generation. It provides less noisy features extracted through the backbone. Laplacian pyramid loss is used to preserve small details in feature reconstruction. A set of comprehensive experimentations reveals that the proposed scheme achieved the state-of-the-art result for the F1 Score, intersection over union, and overall accuracy values in seven benchmark datasets. Our model code is available at https://github.com/chouhan-avinash/TMLNet .},
  archive      = {J_NEUCOM},
  author       = {Avinash Chouhan and Arijit Sur and Dibyajyoti Chutia and Shiv Prasad Aggarwal},
  doi          = {10.1016/j.neucom.2024.128080},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128080},
  shortjournal = {Neurocomputing},
  title        = {TMLNet: Triad multitask learning network for multiobjective based change detection},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Motion frequency exploration based force separator for
surgical robots interacting with a beating heart. <em>NEUCOM</em>,
<em>599</em>, 128079. (<a
href="https://doi.org/10.1016/j.neucom.2024.128079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotics-assisted beating heart surgery holds significant potential for application as it can reduce the risks of infection. A crucial requirement in beating heart surgery is the real-time and accurate feedback of the interaction forces between the end-effector and cardiac tissues. The primary challenge is developing a sensorless scheme to separate the beating motion-coupled force (MCF) from the robot dynamic state-coupled force (SCF). Acquiring the accurate beating frequency before surgery is often challenging, which limits the use of conventional force observers. To address these difficulties, this article proposes an online force separation scheme. Specifically, we establish a robot-cardiac tissue coupled model that considers robot dynamics, force generation mechanisms, and heart motion characteristics. Based on this, we design a motion frequency exploration-based force separator (MSEFS), utilizing an online expectation–maximization procedure for the joint estimation of the motion state and frequency parameter. Simulation results demonstrate that the proposed scheme surpasses existing force estimation schemes in performance due to its capability for motion frequency exploration.},
  archive      = {J_NEUCOM},
  author       = {Yanran Wei and Wenshuo Li and Jiayin Wang and Yangyang Cui and Xiang Yu and Lei Guo},
  doi          = {10.1016/j.neucom.2024.128079},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128079},
  shortjournal = {Neurocomputing},
  title        = {Motion frequency exploration based force separator for surgical robots interacting with a beating heart},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TransLevelSet: Integrating vision transformers with
level-sets for medical image segmentation. <em>NEUCOM</em>,
<em>599</em>, 128077. (<a
href="https://doi.org/10.1016/j.neucom.2024.128077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Vision Transformers (ViTs) have emerged as a breakthrough in computer vision and image analysis. Still, their exceptional performance depends on the availability of large amounts of annotated training data and the availability of considerable computational resources. This naturally raises the risk of overfitting and limited generalization capability in settings with limited training data. Aiming to cope with this issue, we propose the Level-Set Transformer (TransLevelSet), a hybrid methodology that encompasses an additional term in the loss function used in the ViT learning process, which has been originally defined in the context of Level-Set (LS) deformable models. This loss term avails the spatial information obtained by the level-set energy terms for image segmentation and mitigates the dependency of ViTs on the amount of available data. Moreover, this level-set loss promotes smooth and topologically consistent demarcation of structures, taking advantage of the capacity of ViTs to capture complex spatial relationships and contextual information. The main contributions of this work include: a) a pioneering approach to the integration of ViTs with level-sets; and, b) the application of the proposed methodology on two case studies related to cancer, namely the malignant melanoma, and colon cancer. We evaluate TransLevelSet on three different publicly available benchmark datasets for medical image segmentation, that include dermoscopic and histopathological images. The results of the experiments demonstrate consistent gains in terms of generalization capability introduced by the LS terms.},
  archive      = {J_NEUCOM},
  author       = {Dimitra-Christina C. Koutsiou and Michalis A. Savelonas and Dimitris K. Iakovidis},
  doi          = {10.1016/j.neucom.2024.128077},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128077},
  shortjournal = {Neurocomputing},
  title        = {TransLevelSet: Integrating vision transformers with level-sets for medical image segmentation},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neuroadaptive nonsingular fixed-time tracking control for
deferred state-constrained systems based on improved command filter.
<em>NEUCOM</em>, <em>599</em>, 128074. (<a
href="https://doi.org/10.1016/j.neucom.2024.128074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper designs a novel nonsingular fixed-time adaptive controller for uncertain nonlinear systems with deferred asymmetric time-varying state constraints (DATVSC) and external disturbances. Firstly, the difficulties arising from the unknown functions are eliminated by utilizing the radial basis function neural network (RBFNN). Then, the deferred state constraints are solved via the shifting function that drives the initial state to the origin. The time-varying nonlinear transformed function is developed to cope with DATVSC without the feasibility conditions imposed on intermediate control signals. Meanwhile, a modified finite-time command filter is introduced to directly obtain the derivative of the virtual signal, which eliminates the “differential explosion” and chattering phenomena. By incorporating the hyperbolic tangent function into the backstepping framework, an adaptive nonsingular NN fixed-time controller is presented to ensure that all error signals can converge to an arbitrarily small residual set within a fixed time and the DATVSC is not violated. Finally, both the rigorous stability analysis and two simulation results are provided to confirm the effectiveness of the presented theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Xiaoning Lv and Wei Wei and Weihai Zhang},
  doi          = {10.1016/j.neucom.2024.128074},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128074},
  shortjournal = {Neurocomputing},
  title        = {Neuroadaptive nonsingular fixed-time tracking control for deferred state-constrained systems based on improved command filter},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Managing the unknown in machine learning: Definitions,
related areas, recent advances, and prospects. <em>NEUCOM</em>,
<em>599</em>, 128073. (<a
href="https://doi.org/10.1016/j.neucom.2024.128073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the rapidly evolving domain of machine learning, the ability to adapt to unforeseen circumstances and novel data types is of paramount importance. The deployment of Artificial Intelligence is progressively aimed at more realistic and open scenarios where data, tasks, and conditions are variable and not fully predetermined, and therefore where a closed set assumption cannot be hold. In such evolving environments, machine learning is asked to be autonomous, continuous, and adaptive, requiring effective management of uncertainty and the unknown to fulfill expectations. In response, there is a vigorous effort to develop a new generation of models, which are characterized by enhanced autonomy and a broad capacity to generalize, enabling them to perform effectively across a wide range of tasks. The field of machine learning in open set environments poses many challenges and also brings together different paradigms, some traditional but others emerging, where the overlapping and confusion between them makes it difficult to distinguish them or give them the necessary relevance. This work delves into the frontiers of methodologies that thrive in these open set environments, by identifying common practices, limitations, and connections between the paradigms Open-Ended Learning, Open-World Learning, Open Set Recognition, and other related areas such as Continual Learning, Out-of-Distribution detection, Novelty Detection, and Active Learning. We seek to easy the understanding of these fields and their common roots, uncover open problems and suggest several research directions that may motivate and articulate future efforts towards more robust and autonomous systems.},
  archive      = {J_NEUCOM},
  author       = {Marcos Barcina-Blanco and Jesus L. Lobo and Pablo Garcia-Bringas and Javier Del Ser},
  doi          = {10.1016/j.neucom.2024.128073},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128073},
  shortjournal = {Neurocomputing},
  title        = {Managing the unknown in machine learning: Definitions, related areas, recent advances, and prospects},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event-triggered output-based distributed observer over
jointly connected networks and its application to the cooperative output
regulation problem. <em>NEUCOM</em>, <em>599</em>, 128072. (<a
href="https://doi.org/10.1016/j.neucom.2024.128072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the event-triggered output-based distributed observer (ETOBDO) is proposed for a leader system with linear dynamics over switching communication networks satisfying the jointly connected condition. Then ETOBDO is applied to solve the cooperative output regulation problem (CORP) of linear heterogeneous multi-agent systems (MASs) over jointly connected switching networks (JCSNs). Comparing with the similar results which only implement the distributed observer by the event-triggering mechanism, we implement both the distributed observer and the control law of each follower by the event-triggering mechanism. Thus, our overall output feedback control law can be directly implemented in a digital platform. Moreover, we give a rigorous proof for the prevention of Zeno phenomenon. A practical example adopted from the vehicle longitudinal dynamics is utilized to illustrate the effectiveness of the overall design.},
  archive      = {J_NEUCOM},
  author       = {Rui Zhang and Jie Huang},
  doi          = {10.1016/j.neucom.2024.128072},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128072},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered output-based distributed observer over jointly connected networks and its application to the cooperative output regulation problem},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A review of research on reinforcement learning algorithms
for multi-agents. <em>NEUCOM</em>, <em>599</em>, 128068. (<a
href="https://doi.org/10.1016/j.neucom.2024.128068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multi-agent reinforcement learning techniques have been widely used and evolved in the field of artificial intelligence. However, traditional reinforcement learning methods have limitations such as long training time, large sample data requirements, and highly delayed rewards. Therefore, this paper systematically and specifically studies the MARL algorithm. Firstly, this paper uses Citespace software to visually analyze the existing literature on multi-agent reinforcement learning and briefly indicates the research hotspots and key research directions in this field. Secondly, the applications of traditional reinforcement learning algorithms under two task objects, namely single-agent and multi-agent systems, are described in detail. Then, the paper highlights the diverse applications, challenges, and corresponding solutions of MARL algorithmic techniques in the field of MAS. Finally, the paper points out future research directions based on the existing limitations of the algorithm. Through this paper, readers will gain a systematic and in-depth understanding of MARL algorithms and how they can be utilized to better address the various challenges posed by MAS.},
  archive      = {J_NEUCOM},
  author       = {Kai Hu and Mingyang Li and Zhiqiang Song and Keer Xu and Qingfeng Xia and Ning Sun and Peng Zhou and Min Xia},
  doi          = {10.1016/j.neucom.2024.128068},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128068},
  shortjournal = {Neurocomputing},
  title        = {A review of research on reinforcement learning algorithms for multi-agents},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Insights on the different convergences in extreme learning
machine. <em>NEUCOM</em>, <em>599</em>, 128061. (<a
href="https://doi.org/10.1016/j.neucom.2024.128061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Networks (NN) are a powerful tool in approximation theory because of the existence of Universal Approximation (UA) results. In the last decades, a significant attention has been given to Extreme Learning Machines (ELMs), typically employed for the training of single layer NNs, and for which a UA result can also be proven. In a generic NN, the design of the optimal approximator can be recast as a non-convex optimization problem that turns out to be particularly demanding from the computational viewpoint. However, under the adoption of ELM, the optimization task reduces to a – possibly rectangular – linear problem. In this work, we detail how to design a sequence of ELM networks trained via a target dataset. Different convergence procedures are proposed and tested for some reference datasets constructed to be equivalent to approximation problems.},
  archive      = {J_NEUCOM},
  author       = {Davide Elia De Falco and Francesco Calabrò and Monica Pragliola},
  doi          = {10.1016/j.neucom.2024.128061},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128061},
  shortjournal = {Neurocomputing},
  title        = {Insights on the different convergences in extreme learning machine},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A robust segmentation of retinal fluids from OCT images
using MCFAR-net. <em>NEUCOM</em>, <em>599</em>, 128059. (<a
href="https://doi.org/10.1016/j.neucom.2024.128059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel architecture to detect Macular Edema (ME) in Optical Coherence Tomography (OCT) images that occurs due to high fluid accumulation between the retinal layers of the eye. These excessive fluids have swollen the macular region and may result in visual impairments. To alleviate this problem in its early stage, the proposed model, Multiscale Context Enhancive Aggregation &amp; Refinement Network (MCFAR-Net) is implemented to detect these fluids enabling the prevention of visual loss. This MCFAR-Net is incorporated with two Context Feature Enhancive Modules (CFEM). The upper module is initially trained using contrastive loss for extracting the most pertinent multiscale feature maps allowing to segment thick fluid regions from OCT images. Further, the lower module elevates the feature maps to segment the minute fluid regions using the outputs of upper CFEM along with input image. Finally, the output fluid probabilistic feature maps of both paths of the two modules are stacked together and fed as input to Feature Synthesizer (FS) Module. This module improves the true positive rate of the proposed algorithm and segments the fluid region more accurately. The performance of the proposed model is trained and evaluated using publicly available datasets like RETOUCH, OPTIMA, and DUKE datasets. This model outperformed existing state-of the-art algorithms by attaining an average dice coefficient of 95.63 % when tested on the RETOUCH dataset. The performance of proposed MCFAR-Net reduced the misclassification errors enabling to identify ME more precisely in its early stage allowing the expert doctor to provide immediate treatment to the patients.},
  archive      = {J_NEUCOM},
  author       = {P. Geetha Pavani and B. Biswal and Srinivasa Rao Kandula and P.K. Biswal and G. Siddartha and T. Niranjan and Bala Subrahmanyam N},
  doi          = {10.1016/j.neucom.2024.128059},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128059},
  shortjournal = {Neurocomputing},
  title        = {A robust segmentation of retinal fluids from OCT images using MCFAR-net},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unfolding explainable AI for brain tumor segmentation.
<em>NEUCOM</em>, <em>599</em>, 128058. (<a
href="https://doi.org/10.1016/j.neucom.2024.128058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor segmentation (BTS) has been studied from handcrafted engineered features to conventional machine learning (ML) methods, followed by the cutting-edge deep learning approaches. Each recent approach has attempted to overcome the challenges of previous methods and brought conveniences in efficacy, throughput, computation, explainability, investigation, and interpretability. Recently, deep learning (DL) algorithms show excellent performance regarding diverse fields, including image process, computer vision, health analytics, autonomous vehicles, and natural language processes; however, ultimately impediment in making the artificial intelligence explainable and interpretable to clinicians while dealing with critical health informatics and radiomics. Besides the sophisticated deep learning models for brain tumor segmentation, notorious notions like explainability, investigation, trust, and interpretability of DL raised significant concerns for clinicians in their domains. Among many DL methods, the neuro-symbolic learning (NSL) concept has gained more attention as it can contribute to explainable and interpretable AI. In the current study, we survey the prominent approaches, from handcrafted engineering conventional ML to deep learning algorithms, highlight the challenges in DL algorithms, and propose NSL architectures for BTS. Compared to existing surveys, our study not only outlines handcrafted to DL methods for BTS but also proposed explainable and interpretable pipelines appropriate for clinical practices. Our study can better facilitate novice learners in explainable AI and propose efficient, robust, interpretable DL models to facilitate the diagnosis, prognosis, and treatment of BTS.},
  archive      = {J_NEUCOM},
  author       = {Muhammad Hassan and Ahmed Ameen Fateh and Jieqiong Lin and Yijiang Zhuang and Guisen Lin and Hairui Xiong and Zhou You and Peiwu Qin and Hongwu Zeng},
  doi          = {10.1016/j.neucom.2024.128058},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128058},
  shortjournal = {Neurocomputing},
  title        = {Unfolding explainable AI for brain tumor segmentation},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A plug-and-play framework for curvilinear structure
segmentation based on a learned reconnecting regularization.
<em>NEUCOM</em>, <em>599</em>, 128055. (<a
href="https://doi.org/10.1016/j.neucom.2024.128055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curvilinear structures are present in various fields in image processing such as blood vessels in medical imaging or roads in remote sensing. Their detection is crucial for many applications. In this article, we propose an unsupervised plug-and-play framework for the segmentation of curvilinear structures that focuses on the preservation of their connectivity. This framework includes an algorithm for generating realistic pairs of connected/disconnected curvilinear structures and a reconnecting regularization operator that can be learned from a synthetic dataset. Once learned, this regularization operator can be plugged into a variational segmentation scheme and used to segment curvilinear structure images without requiring annotations. We demonstrate the interest of our approach on the segmentation of vascular images both in 2D and 3D and compare its results with classic unsupervised and deep learning-based approach. Comparative evaluations against unsupervised classic and deep learning-based methods highlight the superior performance of our approach, showcasing remarkable improvements in preserving the connectivity of curvilinear structures (approximately 90% in 2D and 70% in 3D). We finally showcase the good generalizability behavior of our approach on two different applications : road cracks and porcine corneal cells segmentations.},
  archive      = {J_NEUCOM},
  author       = {Sophie Carneiro-Esteves and Antoine Vacavant and Odyssée Merveille},
  doi          = {10.1016/j.neucom.2024.128055},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128055},
  shortjournal = {Neurocomputing},
  title        = {A plug-and-play framework for curvilinear structure segmentation based on a learned reconnecting regularization},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ex-fuzzy: A library for symbolic explainable AI through
fuzzy logic programming. <em>NEUCOM</em>, <em>599</em>, 128048. (<a
href="https://doi.org/10.1016/j.neucom.2024.128048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the decisions taken by machine learning systems is instrumental in their deployment in real-world systems, as it enables responsible decision-making, fosters trust, and facilitates debugging and improvement. The research field devoted to studying the techniques that explain and illustrate those decisions is called explainable AI. Fuzzy logic, with its interpretable fuzzy rule-based inference, has emerged as a popular tool for Explainable AI because of these interpretable classifiers. However, current fuzzy logic libraries provide limited inference capabilities and integration to machine learning or are only available in the Java or R language, which makes their integration with the standard machine libraries in Python challenging. This paper describes a software library that contains a Python implementation to perform fuzzy inference using different kinds of fuzzy sets, with a special focus on result visualization. This library follows the scikit-learn programming interface, enabling researchers to utilize it with minimum fuzzy logic background seamlessly. This toolkit unveils novel tools for programming fuzzy systems that are learnable using machine learning methods, leading to data-powered systems that maintain full transparency and accountability, accessible to virtually anyone without specialized AI training. The interpretability of these systems makes them highly valuable in industries like healthcare, law, and security.},
  archive      = {J_NEUCOM},
  author       = {Javier Fumanal-Idocin and Javier Andreu-Perez},
  doi          = {10.1016/j.neucom.2024.128048},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128048},
  shortjournal = {Neurocomputing},
  title        = {Ex-fuzzy: A library for symbolic explainable AI through fuzzy logic programming},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A causality guided loss for imbalanced learning in scene
graph generation. <em>NEUCOM</em>, <em>599</em>, 128042. (<a
href="https://doi.org/10.1016/j.neucom.2024.128042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unbiased visual relation detection on long-tailed annotations is a critical challenge in scene graph generation (SGG). Imbalanced learning aims to tackle the problem of class distribution that is long-tailed in order to learn unbiased models from imbalanced data. Since long-tailed datasets are inevitable in the real world, obtaining a balanced dataset can be expensive or even impossible. However, training models on such data are easily biased towards head classes and underperform on tail classes. To overcome this challenge, existing methods focus more on utilizing label frequency as prior knowledge, but ignore the research on how imbalanced datasets lead to prediction bias, which is crucial for solving the long-tail problem. Therefore we propose a causal graph for the training process. This causal graph reveals the conventional loss serves as a confounder of the features and predictions during training. Guided by the causal graph, a degree-of-difficulty loss (DDloss) is designed which is a simple yet effective method to alleviate catering to the head. We demonstrate the effectiveness of DDloss through extensive experiments on SGG and test its expansibility on long-tailed image classification.},
  archive      = {J_NEUCOM},
  author       = {Ru Peng and Chao Zhao and Xingyu Chen and Ziru Wang and Yaxin Liu and Yulong Liu and Xuguang Lan},
  doi          = {10.1016/j.neucom.2024.128042},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128042},
  shortjournal = {Neurocomputing},
  title        = {A causality guided loss for imbalanced learning in scene graph generation},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ROSE: Multi-level super-resolution-oriented semantic
embedding for 3D microvasculature segmentation from low-resolution
images. <em>NEUCOM</em>, <em>599</em>, 128038. (<a
href="https://doi.org/10.1016/j.neucom.2024.128038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current state-of-the-art segmentation methods often require high-resolution input to attain the high performance, which pushes the limit of data acquisition and brings large computation budgets. Instead, we present an end-to-end deep learning-based method, ROSE, for robust and precise segmentation of high-quality 3D super-resolution (SR) microvasculatures from low-resolution (LR) images as input, which can transform data from the LR imaging domain to the SR semantic domain (cross different modalities and scales). More specifically, a multi-tasking two-stream deep learning framework is proposed to learn the high-fidelity microvasculature SR image and semantic hybrid features simultaneously. During the proposed joint learning process, the high-resolution features of microvasculatures are further enhanced by the learned fine-grained structural/textural features from the microvasculature SR stream with a multi-level embedding scheme through the oriented feature aggregation at different fusion stages. In the constructed joint multi-level hybrid embedding spaces, the instance semantic embedding and the SR imaging embedding can be connected and integrated synergistically. We have conducted extensive experiments using public and real patient micro-cerebrovascular image datasets and compare our framework with traditional 3D vessel segmentation methods and the other state-of-the-art in deep learning. This robust and precise microvascular visualization in different brain regions by our method demonstrates its potential impact in magnetic resonance (MR) angiography and venography for the diagnosis of microvascular disease.},
  archive      = {J_NEUCOM},
  author       = {Yifan Wang and Haikuan Zhu and Hongbo Li and Guoli Yan and Sagar Buch and Ying Wang and Ewart Mark Haacke and Jing Hua and Zichun Zhong},
  doi          = {10.1016/j.neucom.2024.128038},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128038},
  shortjournal = {Neurocomputing},
  title        = {ROSE: Multi-level super-resolution-oriented semantic embedding for 3D microvasculature segmentation from low-resolution images},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised network distillation: An effective approach
to exploration in sparse reward environments. <em>NEUCOM</em>,
<em>599</em>, 128033. (<a
href="https://doi.org/10.1016/j.neucom.2024.128033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning can solve decision-making problems and train an agent to behave in an environment according to a predesigned reward function. However, such an approach becomes very problematic if the reward is too sparse and so the agent does not come across the reward during the environmental exploration. The solution to such a problem may be to equip the agent with an intrinsic motivation that will provide informed exploration during which the agent is likely to also encounter external reward. Novelty detection is one of the promising branches of intrinsic motivation research. We present Self-supervised Network Distillation (SND), a class of intrinsic motivation algorithms based on the distillation error as a novelty indicator, where the predictor model and the target model are both trained. We adapted three existing self-supervised methods for this purpose and experimentally tested them on a set of ten environments that are considered difficult to explore. The results show that our approach achieves faster growth and higher external reward for the same training time compared to the baseline models, which implies improved exploration in a very sparse reward environment. 1 In addition, the analytical methods we applied provide valuable explanatory insights into our proposed models.},
  archive      = {J_NEUCOM},
  author       = {Matej Pecháč and Michal Chovanec and Igor Farkaš},
  doi          = {10.1016/j.neucom.2024.128033},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128033},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised network distillation: An effective approach to exploration in sparse reward environments},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ESEN: Efficient GPU sharing of ensemble neural networks.
<em>NEUCOM</em>, <em>599</em>, 128030. (<a
href="https://doi.org/10.1016/j.neucom.2024.128030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble neural networks are widely applied in cloud-based inference services due to their remarkable performance, while the growing demand for low-latency services leads researchers to pay more attention to the execution efficiency of these models, especially the device utilization. It is highly desirable to fully utilize GPUs by multiplexing different inference tasks on the same GPU with advanced sharing technique, such as Multi-Process-Service (MPS). However, we find it struggling when applying MPS to Ensemble Neural Networks, which consist of multiple related sub-models. The critical challenge in this predicament revolves around the efficient allocation of resources within an ensemble, aiming to minimize job completion time. To tackle this challenge, we initially examine the interplay among individual neural networks within an ensemble, outlining a guideline for achieving the shortest job completion time. Subsequently, we establish a mathematical model to formalize the resource requirements of each neural network. We introduce a search-based allocation algorithm designed to swiftly identify optimal solutions. Finally, we introduce ESEN, comprising the search-based resource allocation algorithm and efficient model execution mechanisms within PyTorch. ESEN is augmented with customized execution mechanisms for user-friendly implementation. Experimental results demonstrate that proposed ESEN can attain an efficiency improvement up to 17.84% and a GPU utilization increase of 28.09% compared to the default strategy. With the optimization of GPU resource allocation, ESEN significantly improves the efficiency of ensemble models. It provides a low-latency and high-accuracy solution for online interactive services.},
  archive      = {J_NEUCOM},
  author       = {Jianan Wang and Yang Shi and Zhaoyun Chen and Mei Wen},
  doi          = {10.1016/j.neucom.2024.128030},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128030},
  shortjournal = {Neurocomputing},
  title        = {ESEN: Efficient GPU sharing of ensemble neural networks},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SgLFT: Semantic-guided late fusion transformer for video
corpus moment retrieval. <em>NEUCOM</em>, <em>599</em>, 128029. (<a
href="https://doi.org/10.1016/j.neucom.2024.128029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video corpus moment retrieval aims to locate video segments that semantically correspond to natural language queries in a large collection. Effective representation learning across the video, subtitle, and language modalities is crucial for success. However, existing methods prematurely combine visual and subtitle features, leading to redundant information that hinders language query matching. Moreover, these methods lack query guidance during visual encoding, overlooking fine-grained semantics. To address these limitations, we propose a simple yet effective approach called Semantic-guided Late Fusion Transformer (SgLFT) for video corpus moment retrieval. Our method leverages a Semantic-guided Locality-aware Transformer to capture fine-grained visual embeddings using distinguishable query semantics, independent of the presence of subtitles. Furthermore, we introduce a late fusion approach that merges subtitle and visual features under a Cross-modality Global-aware Context Fusion unit, enhancing global contextual details. Finally, a Query-aware Feature Learning module aligns the query and video into a unified representation for localization. Our framework effectively models fine-grained semantic interactions between modalities with query guidance, advancing cross-modal representation learning. Extensive experiments on the TVR and DiDeMo benchmarks demonstrate that SgLFT significantly outperforms previous state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Tongbao Chen and Wenmin Wang and Minglu Zhao and Ruochen Li and Zhe Jiang and Cheng Yu},
  doi          = {10.1016/j.neucom.2024.128029},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128029},
  shortjournal = {Neurocomputing},
  title        = {SgLFT: Semantic-guided late fusion transformer for video corpus moment retrieval},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pinning event-triggered sampled-data synchronization of
coupled reaction–diffusion neural networks. <em>NEUCOM</em>,
<em>599</em>, 128028. (<a
href="https://doi.org/10.1016/j.neucom.2024.128028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the synchronization problem of coupled reaction–diffusion neural networks (CRDNNs) is considered by using pinning event-triggered sampled-data (PETSD) control method under spatially point measurements. To save the limited transmission channel, a PETSD control mechanism by controlling a small fraction of the nodes is proposed to decrease the update frequency of controller and the unnecessary SD. Then, based on the Lyapunov–Krasovskii functional (LKF) and inequality techniques, sufficient conditions for exponential stability of the synchronization error system presented by linear matrix inequalities (LMIs) can be derived through the designed PETSD controller. Finally, simulation results of one numerical example are presented to demonstrate the effectiveness of the proposed design approach.},
  archive      = {J_NEUCOM},
  author       = {Feng-Liang Zhao and Zi-Peng Wang and Junfei Qiao and Huai-Ning Wu and Tingwen Huang},
  doi          = {10.1016/j.neucom.2024.128028},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128028},
  shortjournal = {Neurocomputing},
  title        = {Pinning event-triggered sampled-data synchronization of coupled reaction–diffusion neural networks},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Eliminating and mining strategies for open-world object
proposal. <em>NEUCOM</em>, <em>599</em>, 128026. (<a
href="https://doi.org/10.1016/j.neucom.2024.128026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object proposal serves as a crucial pre-task of many image and video understanding applications. However, modern approaches for object proposal are typically based on closed-world assumptions, focusing only on pre-defined categories. This approach cannot meet the diverse needs of real-world applications. To address this limitation, we introduce two strategies, namely the eliminating strategy and the mining strategy, to robustly train the Object Localization Network (OLN) for open-world object proposal. The eliminating strategy takes into account the spatial configuration between labeled boxes, thereby eliminating box anchors that overlap with multiple objects. The mining strategy employs a pseudo-label guided self-training scheme, enabling the mining of object boxes in novel categories. Without bells and whistles, our proposed method outperforms previous state-of-the-art methods on large-scale benchmarks, including COCO, Objects365, and UVO. The source codes are available at https://github.com/hustvl/EM-OLN .},
  archive      = {J_NEUCOM},
  author       = {Cheng Wang and Guoli Wang and Qian Zhang and Peng Guo and Wenyu Liu and Xinggang Wang},
  doi          = {10.1016/j.neucom.2024.128026},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128026},
  shortjournal = {Neurocomputing},
  title        = {Eliminating and mining strategies for open-world object proposal},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploiting indirect linear correlation for label
distribution learning. <em>NEUCOM</em>, <em>599</em>, 128022. (<a
href="https://doi.org/10.1016/j.neucom.2024.128022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label distribution learning represents the relevance of labels to samples using description degree, which can provide richer semantic information, thus finding wider applications. Exploiting label correlations is an effective approach to narrow down the hypothesis space of label distribution learning models. In existing works that utilize low-rank assumptions or label linear dependence to mine correlations, it is assumed that a label can be linearly expressed by other labels. However, this assumption can only be satisfied when there are linear dependency relationships between labels, thus the label correlation obtained by such methods is subject to certain distortion. To address this issue, this paper assumes that labels can be linearly represented by the same set of bases. The correlation between labels is represented by sharing common bases. Specifically, the paper employs matrix factorization to extract bases that can be used to represent all labels. And then designs a label distribution learning algorithm based on the property of sharing the same set of bases of the ground truth label distribution and predict label distribution. The effectiveness of the algorithm is verified through experimental validation. Generally speaking, the algorithm presented in this paper achieves optimal performance at 73.15% of the cases, with the best average ranking. In the two-tailed t t -test, the algorithm in this paper exhibits statistical superiority compared to all comparison algorithms.},
  archive      = {J_NEUCOM},
  author       = {Peiqiu Yu and Xiuyi Jia},
  doi          = {10.1016/j.neucom.2024.128022},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128022},
  shortjournal = {Neurocomputing},
  title        = {Exploiting indirect linear correlation for label distribution learning},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid-order distributed SGD: Balancing communication
overhead, computational complexity, and convergence rate for distributed
learning. <em>NEUCOM</em>, <em>599</em>, 128020. (<a
href="https://doi.org/10.1016/j.neucom.2024.128020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication overhead, computation load, and convergence speed are three major challenges in the scalability of distributed stochastic optimization algorithms in training large neural networks. In this paper, we propose the approach of hybrid-order distributed stochastic gradient descent (HO-SGD) which strikes a better balance between these three than the previous methods, for a general class of non-convex stochastic optimization problems. In particular, we advocate that by properly interleaving zeroth-order and first-order gradient updates, it is possible to significantly reduce the communication and computation overheads while guaranteeing a fast convergence. The proposed method guarantees the same order of convergence rate as in the fastest distributed methods (i.e., fully synchronous SGD) while having significantly less computational complexity and communication overhead per iteration, and the same order of communication overhead as in the state-of-the-art communication-efficient methods, with order-wisely less computational complexity. Moreover, it order-wisely improves the convergence rate of zeroth-order SGD methods. Finally and remarkably, empirical studies demonstrate that the proposed hybrid-order approach provides significantly higher test accuracies and superior generalization than all the baselines, owing to its novel exploration mechanism.},
  archive      = {J_NEUCOM},
  author       = {Naeimeh Omidvar and Seyed Mohammad Hosseini and Mohammad Ali Maddah-Ali},
  doi          = {10.1016/j.neucom.2024.128020},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128020},
  shortjournal = {Neurocomputing},
  title        = {Hybrid-order distributed SGD: Balancing communication overhead, computational complexity, and convergence rate for distributed learning},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Training neural networks end-to-end for hyperbox-based
classification. <em>NEUCOM</em>, <em>599</em>, 127961. (<a
href="https://doi.org/10.1016/j.neucom.2024.127961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern decision-making requires the use of powerful algorithms to make sense of a variety of data. In this context, hyperbox induction has been seen as a promising technique in which decisions on the data are represented as a series of orthogonal, multidimensional boxes (i.e., hyperboxes) that are often interpretable and human-readable. However, existing hyperbox induction methods are no longer capable of efficiently handling the increasing volumes of data many application domains are confronted with. Moreover, current methods offer little to no control on specific properties of the induced box models, such as the number or the sizes of the hyperboxes. In this work, we propose a novel, fully differentiable framework for hyperbox induction that makes use of recent advancement in neural networks. In contrast to existing approaches, our hyperbox-based models can be trained in an end-to-end fashion, which leads to significantly reduced training times and superior classification results.},
  archive      = {J_NEUCOM},
  author       = {Denis Mayr Lima Martins and Christian Lülf and Fabian Gieseke},
  doi          = {10.1016/j.neucom.2024.127961},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127961},
  shortjournal = {Neurocomputing},
  title        = {Training neural networks end-to-end for hyperbox-based classification},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive modeling of systems with uncertain dynamics via
continuous long-short term memories. <em>NEUCOM</em>, <em>599</em>,
127955. (<a href="https://doi.org/10.1016/j.neucom.2024.127955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents an innovative modeling approach for systems with uncertain dynamics, utilizing a novel long-short-term memory (LSTM) architecture featuring continuous temporal evolution. The proposed approximate model is resolved by introducing a non-parametric identifier, the trajectories converge to the states of systems exhibiting uncertain dynamics in an ultimately bounded manner. Given the multi-layered nature of continuous dynamics, we introduce two identifiers, considering the possibility of accessing or not accessing the LSTM’s internal state. Consequently, two identifiers have been devised, considering the influence of the internal state of the LSTM. Applying a control Lyapunov function to each identifier enables the derivation of weight evolution in the LSTM’s two layers: the output and the hidden layers. These weights are linked to input states’ short- and long-term effects on the LSTM’s dynamics. To validate the proposed identifiers’ effectiveness compared to traditional Hopfield-like differential neural networks, we provide a numerical example and conduct complementary experimental validations. These results confirm the theoretical findings regarding the impact of short and long-term temporal information on the LSTM’s current state and demonstrate superior identification quality compared to traditional neural networks exhibiting continuous dynamics adhering to the Hopfield form. Collectively, these findings substantiate the advancements presented in this study.},
  archive      = {J_NEUCOM},
  author       = {Alejandro Macias-Hernandez and Daniela F. Orozco-Granados and Isaac Chairez},
  doi          = {10.1016/j.neucom.2024.127955},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127955},
  shortjournal = {Neurocomputing},
  title        = {Adaptive modeling of systems with uncertain dynamics via continuous long-short term memories},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FCM-DCS: Fuzzy c means distorted contour-based segmentation
model for breast cancer detection. <em>NEUCOM</em>, <em>599</em>,
127937. (<a href="https://doi.org/10.1016/j.neucom.2024.127937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer (BC) is a commonly diagnosed cancer among women nowadays. The cancer cells in the breast tissues are known as BC. Comprehensive research on early-stage BC detection helped to increase the survival rate and reduce the amortality rate associated with this disease. Mammogram scan analysis is a commonly used breast tissue visualization method. This image data is analyzed adequately for accurate BC diagnosis. Region of interest (ROI) identification is crucial in an image-based BC detection system. The ROI detection helps to segment the cancer tissues from the mammogram images by analyzing the heterogeneity among cancerous and normal breast tissues. Early-stage BC issues have homogeneous features as normal breast tissues. So, it is an open challenge for the researchers to develop a more accurate segmentation method during the automatic BC stages detection system. This study introduced fuzzy C means (FCM) distorted contour-based segmentation (FCM DCS) method to address the real detection issues in present studies. It uses the distorted contour (DC) based method to identify the contour of the cancer tissue from mammogram images. The DC method is performed with the help of FCM to identify the cancer tissues. Moreover, a histogram and adaptive equalization method were utilized to reduce image noise and preserve the edge features. The result analysis shows that the FCM-DC methods achieved a maximum accuracy rate (98.76 %) than comparison methods in BC detection.},
  archive      = {J_NEUCOM},
  author       = {B. Krishnakumar and K. Kousalya},
  doi          = {10.1016/j.neucom.2024.127937},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127937},
  shortjournal = {Neurocomputing},
  title        = {FCM-DCS: Fuzzy c means distorted contour-based segmentation model for breast cancer detection},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient hyperparameter optimization with probability-based
resource allocating on deep neural networks. <em>NEUCOM</em>,
<em>599</em>, 127907. (<a
href="https://doi.org/10.1016/j.neucom.2024.127907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperparameter tuning is an essential step to obtain high model performance on the validation set before applying machine learning models. Hand tuning always requires massive labor and professional knowledge of specific machine learning fields. Various automatic hyperparameter optimization algorithms have been developed to address this problem. A well-known algorithm, Population Based Training (PBT), bridges parallel search and sequential optimization by introducing online adaptation of both hyperparameters and network weights, significantly enhancing optimization efficiency despite its static adaptation scheme. Inspired by this framework, we further propose a new efficient heuristic optimization algorithm called Probability-based Resource Allocating (PRA). PRA first applies a novel resource allocation scheme, concentrating resources efficiently and dynamically on well performing hyperparameter configurations and allowing the possibility of the escape from local optima. Furthermore, an innovative exploration strategy inspired by gradient descent methods is proposed to guide the search directions for new hyperparameters. Besides, PRA employs a hybrid approach of learning and evolving network weights. All of these contribute to accelerating the search for optimal hyperparameter configurations. In a series of experiments on deep neural networks, PRA achieved better performance than PBT-series algorithms and other typical Bayesian Optimization methods, demonstrating fast convergence and a low time budget.},
  archive      = {J_NEUCOM},
  author       = {Wenguo Li and Xudong Yin and Mudan Ye and Pengxu Zhu and Jinghua Li and Yao Yang},
  doi          = {10.1016/j.neucom.2024.127907},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127907},
  shortjournal = {Neurocomputing},
  title        = {Efficient hyperparameter optimization with probability-based resource allocating on deep neural networks},
  volume       = {599},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development and challenges of object detection: A survey.
<em>NEUCOM</em>, <em>598</em>, 128102. (<a
href="https://doi.org/10.1016/j.neucom.2024.128102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is a basic vision task that accompanies people’s daily lives all the time. The development of object detection technology has experienced an evolution from traditional-based algorithms to deep learning-based algorithms, which has made a qualitative leap in both detection accuracy and detection speed. With the advancement of deep learning, object detection techniques are increasingly becoming a part of everyday life, with the YOLO series of algorithms being extensively applied in various industries. In this paper, we initially present the frequently utilized datasets and evaluation criteria for object detection. Subsequently, we delve into the evolution of traditional object detection algorithms, highlighting two-stage and one-stage approaches through illustrative examples of classical methods. We also conduct a comprehensive summary and analysis of the detection results obtained by these methods. In addition, we introduce object detection applications in daily life, as well as the importance and some difficulties of these applications. Finally, we analyze and summarize the difficulties and challenges facing the task of object detection, and we look forward to the future development direction of object detection.},
  archive      = {J_NEUCOM},
  author       = {Zonghui Li and Yongsheng Dong and Longchao Shen and Yafeng Liu and Yuanhua Pei and Haotian Yang and Lintao Zheng and Jinwen Ma},
  doi          = {10.1016/j.neucom.2024.128102},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128102},
  shortjournal = {Neurocomputing},
  title        = {Development and challenges of object detection: A survey},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linguistic feature fusion for arabic fake news detection and
named entity recognition using reinforcement learning and swarm
optimization. <em>NEUCOM</em>, <em>598</em>, 128078. (<a
href="https://doi.org/10.1016/j.neucom.2024.128078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of the escalating use of social media in Arabic-speaking countries, driven by improved internet access, affordable smartphones, and a growing digital connectivity trend, this study addresses a significant challenge: the widespread dissemination of fake news. The ease and rapidity of spreading information on social media, coupled with a lack of stringent fact-checking measures, exacerbate the issue of misinformation. Our study examines how language features, especially Named Entity Recognition (NER) features, play a role in detecting fake news. We built two models: an AraBERT Multi-task Learning (MTL) based one for classifying Arabic fake news, and a token classification model that focuses on fake news NER features. The study combines embedding vectors from these models using an embedding fusion technique and applies machine learning algorithms for fake news detection in Arabic. We also introduced a feature selection algorithm named RLTTAO based on improving the Triangulation Topology Aggregation Optimizer (TTAO) performance using Reinforcement Learning and random opposition-based learning to enhance the performance by selecting relevant features, thereby improving the fusion process. Our results show that incorporating NER features enhances the accuracy of fake news detection in 5 out of 7 datasets, with an average improvement of 1.62%.},
  archive      = {J_NEUCOM},
  author       = {Abdelghani Dahou and Mohamed Abd Elaziz and Haibaoui Mohamed and Abdelhalim Hafedh Dahou and Mohammed A.A. Al-qaness and Mohamed Ghetas and Ahmed Ewess and Zhonglong Zheng},
  doi          = {10.1016/j.neucom.2024.128078},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128078},
  shortjournal = {Neurocomputing},
  title        = {Linguistic feature fusion for arabic fake news detection and named entity recognition using reinforcement learning and swarm optimization},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamics analysis of a new fractional-order SVEIR-KS model
for computer virus propagation: Stability and hopf bifurcation.
<em>NEUCOM</em>, <em>598</em>, 128075. (<a
href="https://doi.org/10.1016/j.neucom.2024.128075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates the stability and Hopf bifurcation of a fractional-order model of the computer virus known as Susceptible–Vaccinated–Exposed–Infected–Recovered–Kill Signals (SVEIR-KS) that has two delays. Utilizing the linearization technique, Laplace transform, Routh–Hurwitz criteria, and Hopf bifurcation theorem of fractional-order differential systems, the sufficient criteria for the system’s stability and Hopf bifurcation are determined. The study demonstrates that the stability and occurrence of the Hopf bifurcation of the fractional-order computer virus model are profoundly affected by fractional order q q and time delays. In order to confirm the validity of the theoretical results, various simulations and examples with appropriate parameters are provided. The results show a negative correlation between the delay critical value and the fractional order q q . Additionally we also dig into the effect in which kill signals prevent computer viruses from spreading over a network.},
  archive      = {J_NEUCOM},
  author       = {Linji Yang and Qiankun Song and Yurong Liu},
  doi          = {10.1016/j.neucom.2024.128075},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128075},
  shortjournal = {Neurocomputing},
  title        = {Dynamics analysis of a new fractional-order SVEIR-KS model for computer virus propagation: Stability and hopf bifurcation},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A substructure transfer reinforcement learning method based
on metric learning. <em>NEUCOM</em>, <em>598</em>, 128071. (<a
href="https://doi.org/10.1016/j.neucom.2024.128071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer reinforcement learning has gained significant traction in recent years as a critical research area, focusing on bolstering agents’ decision-making prowess by harnessing insights from analogous tasks. The primary transfer learning method involves identifying the appropriate source domains, sharing specific knowledge structures and subsequently transferring the shared knowledge to novel tasks. However, existing transfer methods exhibit a pronounced dependency on high task similarity and an abundance of source data. Consequently, we attempt to formulate a more efficacious approach that optimally exploits the previous learning experiences to direct an agent’s exploration as it learns new tasks. Specifically, we introduce a novel transfer learning paradigm rooted within the distance measure in the Markov chain, denoted as Distance Measure Substructure Transfer Reinforcement Learning (DMS-TRL). The core idea involves partitioning the Markov chain into the most basic small Markov units, which contain basic information about the agent’s transfer between two states, and then followed by employing a new distance measure technique to find the most similar structure, which is also the most suitable for transfer. Finally, we propose a policy transfer method to transfer knowledge through the Q table from the selected Markov unit to the target task. Through a series of experiments conducted on discrete Gridworld scenarios, we compare our approach with state-of-the-art learning methods. The results clearly illustrate that DMS-TRL can adeptly identify optimal policy in target tasks, exhibiting swifter convergence.},
  archive      = {J_NEUCOM},
  author       = {Peihua Chai and Bilian Chen and Yifeng Zeng and Shenbao Yu},
  doi          = {10.1016/j.neucom.2024.128071},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128071},
  shortjournal = {Neurocomputing},
  title        = {A substructure transfer reinforcement learning method based on metric learning},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consensus and attack-decomposition of switched one-sided
lipschitz multi-agent systems via event-triggered intermittent control.
<em>NEUCOM</em>, <em>598</em>, 128070. (<a
href="https://doi.org/10.1016/j.neucom.2024.128070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the exponential consensus of nonlinear switched multi-agent systems (MASs) subject to random attacks. The proposed model is enhanced by introducing the concept of mode-dependent average dwell time (MDADT) and the one-sided Lipschitz (OSL) condition, making it more practical and versatile with relaxed restrictions. Due to the unavailability of direct access to the states of MASs and the vulnerability of their output signals to unknown random attacks, achieving consensus through traditional methods becomes challenging. Hence, a novel attack-decomposition approach is proposed to extract the attack-free output signals from the attacked output signals. Then, the observer is constructed by utilizing attack-free output signals and employed to estimate the states of MASs. A mode-dependent event-triggering mechanism is presented to conserve resources for the observer-controller channels. In order to save control costs, the intermittent control scheme is designed for different switching modes whose control width depends on the minimum dwell time. Finally, an illustrative example is used to showcase the advantages of the theoretical method.},
  archive      = {J_NEUCOM},
  author       = {Maolin Wang and Min Xiao and Yaping Sun and Xinsong Yang and Tingwen Huang},
  doi          = {10.1016/j.neucom.2024.128070},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128070},
  shortjournal = {Neurocomputing},
  title        = {Consensus and attack-decomposition of switched one-sided lipschitz multi-agent systems via event-triggered intermittent control},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Top-k discriminative feature selection with uncorrelated
and ℓ2,0-norm equation constraints. <em>NEUCOM</em>, <em>598</em>,
128069. (<a href="https://doi.org/10.1016/j.neucom.2024.128069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised feature selection (FS) as an interpretable dimensionality reduction technique has received increasing attention, where linear discriminative analysis (LDA)-based method can select informative features discriminatively and obtain promising performance. When original data has more features than samples, however, LDA-based method generally encounters degradation since the appearance of irreversible scatter matrix. This situation is called the small sample size (SSS) problem. To overcome it and enhance the discriminant power of selected feature subsets, in this paper, we design an elegant LDA-based FS model referred to as Top- k k Discriminative FS (TDFS), which is constructed by seamlessly integrating the ℓ 2 , 0 ℓ2,0 -norm equation constraint into uncorrelated LDA model. More concretely, the ℓ 2 , 0 ℓ2,0 -norm equation constraint can explicitly characterize the number of selective features k k to ensure the sparsity of projected matrix and select top features. The uncorrelated LDA model aims to improve discriminative ability based on uncorrelated data in projected subspace. Given the formidable nature of solving this non-convex model, a novel optimization algorithm is further developed and the SSS problem can be efficaciously addressed during the optimization process. We first decompose projection matrix into a discrete selection matrix and its corresponding nonzero projection matrix, then concurrently optimize above two matrices by employing a column-by-column update scheme, during which the reversibility of scatter matrix in selective feature subspace can be easily guaranteed to solve SSS problem. The extensive experiments on four synthetic data sets and eight real-world data sets show that the proposed method outperforms eight competitors validated by three classifiers. Moreover, although the theoretical analysis proves that our algorithm has quartic time complexity on the number of selected features k k , the running time experiments verify that TDFS is still efficient and applicable in scenarios where only a small number of features need to be selected. From above perspectives, our algorithm shows desirable performance to achieve discriminative FS.},
  archive      = {J_NEUCOM},
  author       = {Jingyu Wang and Zhenyu Ma and Feiping Nie and Xuelong Li},
  doi          = {10.1016/j.neucom.2024.128069},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128069},
  shortjournal = {Neurocomputing},
  title        = {Top-k discriminative feature selection with uncorrelated and ℓ2,0-norm equation constraints},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive neural event-triggered consensus control for
unknown nonlinear second-order delayed multi-agent systems.
<em>NEUCOM</em>, <em>598</em>, 128067. (<a
href="https://doi.org/10.1016/j.neucom.2024.128067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss event-triggered consensus control for a heterogeneous second-order multi-agent systems with unknown nonlinear functions and state delays (SODMASs). Firstly, a broad adaptive dynamic event-triggered mechanism (ETM), which includes many existing ETM, is proposed. Based on this ETM and the approximation property of neural networks, an adaptive event-triggered protocol with weight estimation of neural network and time-varying integral gain compensation is designed to reduce communication frequency and to eliminate the uncertainty of nonlinear function and state delays. Then, the consensus problem for the heterogeneous SODMASs under the protocol is solved successfully by selecting a suitable Lyapunov–Krasovskii functional. In addition to these, it is also proved that all agents can exclude Zeno behavior under the proposed event-triggered protocol. Finally, a numerical example is given to verify the effectiveness of the proposed consensus protocol algorithm.},
  archive      = {J_NEUCOM},
  author       = {Jiejie Chen and Ping Jiang and Boshan Chen and Zhigang Zeng},
  doi          = {10.1016/j.neucom.2024.128067},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128067},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural event-triggered consensus control for unknown nonlinear second-order delayed multi-agent systems},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). New approach for learning structured graph with laplacian
rank constraint. <em>NEUCOM</em>, <em>598</em>, 128065. (<a
href="https://doi.org/10.1016/j.neucom.2024.128065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many existing graph-clustering methods get results in a two-stage manner, including constructing a graph from data and partitioning it. It always leads to sub-optimal performances. To address the drawbacks, imposing rank constraint on the graph’s Laplacian matrix is an effective way. It can learn a structured graph that connected components are exactly equal to the cluster numbers. According to separate connected components, it directly obtains clustering assignments. However, previous works heuristically solve it during the optimization without any theory guarantee. To handle this issue, we propose a novel solver to optimize this problem with theoretical advantages, enabling the structured bipartite graphs to directly indicate clustering results. Initially, we discover that pairwise and bipartite graphs exhibit the same connected components after undergoing a specific operation. Then, we derive an efficient algorithm to optimize two different clustering models with rank constraints based on this property. Moreover, our proposed method exhibits linear computational complexity to the data scale. Extensive empirical results on both synthetic and real benchmark data demonstrate that the proposed method outperforms existing methods.},
  archive      = {J_NEUCOM},
  author       = {Yu Duan and Feiping Nie and Rong Wang and Xuelong Li},
  doi          = {10.1016/j.neucom.2024.128065},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128065},
  shortjournal = {Neurocomputing},
  title        = {New approach for learning structured graph with laplacian rank constraint},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Open-category referring expression comprehension via
multi-modal knowledge transfer. <em>NEUCOM</em>, <em>598</em>, 128063.
(<a href="https://doi.org/10.1016/j.neucom.2024.128063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring expression comprehension (REC) is a challenging task that involves locating a particular object in an image based on a natural language query. Despite REC showing potential for identifying objects beyond a fixed set of predefined categories, existing models display limited accuracy when confronted with categories not seen during training. To overcome this limitation, in this work, we introduce a new setting called Open-Category Referring Expression Comprehension that focuses more on model generalization capabilities on unseen categories, and present an Multi-modal Knowledge Transfer REC (MTKREC) framework to address this challenge. Specifically, to handle various novel categories, our framework initially constructs an isolated proposal embedding method that integrates pre-training knowledge from CLIP. This method isolates object proposals by cropping them, passing them to CLIP for box-level embedding, and concurrently obtaining box-level proposal embedding from Faster-RCNN. Then, inspired by ResNet, our framework proposes a Residual Self-Attention (RSA) strategy within the fusion module to maximize the utilization of information from the isolated proposal embedding method. To further bolster the model’s capabilities, we transfer knowledge from UNITER by reusing its parameters during the multi-modal fusion process, and explore knowledge distillation techniques to accelerate the model’s performance. We also construct new datasets sub-sampled from RefCOCO, RefCOCO+, and RefCOCOg datasets, that enable evaluation for our model. Extensive experiments on new datasets demonstrate the effectiveness of our framework.},
  archive      = {J_NEUCOM},
  author       = {Wenyu Mi and Jianji Wang and Fuzhen Zhuang and Zhulin An and Wei Guo},
  doi          = {10.1016/j.neucom.2024.128063},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128063},
  shortjournal = {Neurocomputing},
  title        = {Open-category referring expression comprehension via multi-modal knowledge transfer},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-modal and multimodal data analysis based on functional
mapping of spectral descriptors and manifold regularization.
<em>NEUCOM</em>, <em>598</em>, 128062. (<a
href="https://doi.org/10.1016/j.neucom.2024.128062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal manifold modeling methods extend spectral geometry-aware data analysis to incorporate learning from multiple related and complementary modalities. However, most methods assume an equal number of homogeneous data samples in each modality and partial correspondences between modalities as prior knowledge. This work introduces two new multimodal modeling methods. The first method introduces a comprehensive framework for handling multimodal information in heterogeneous data without requiring specific prior knowledge. To achieve this, we begin by extracting local descriptors using spectral graph wavelet signatures (SGWS) to identify manifold localities. Then, we propose a manifold regularization framework that incorporates functional mapping between SGWS descriptors (FMBSD) to determine pointwise correspondences. The second method involves manifold regularized multimodal classification based on pointwise correspondences (M 2 2 CPC). This method addresses the challenge of multiclass classification in multimodal heterogeneous data by determining correspondences between modalities using the FMBSD method. Experimental results evaluating the FMBSD method on three widely used cross-modal retrieval datasets and evaluating the M 2 2 CPC method on three benchmark multimodal multiclass classification datasets demonstrate their effectiveness and superiority over state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Maysam Behmanesh and Peyman Adibi and Jocelyn Chanussot and Sayyed Mohammad Saeed Ehsani},
  doi          = {10.1016/j.neucom.2024.128062},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128062},
  shortjournal = {Neurocomputing},
  title        = {Cross-modal and multimodal data analysis based on functional mapping of spectral descriptors and manifold regularization},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lp- and risk consistency of localized SVMs. <em>NEUCOM</em>,
<em>598</em>, 128060. (<a
href="https://doi.org/10.1016/j.neucom.2024.128060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel-based regularized risk minimizers, also called support vector machines (SVMs), are known to possess many desirable properties but suffer from their super-linear computational requirements when dealing with large data sets. This problem can be tackled by using localized SVMs instead, which also offer the additional advantage of being able to apply different hyperparameters to different regions of the input space. In this paper, localized SVMs are analyzed with regards to their consistency. It is proven that they inherit L p Lp - as well as risk consistency from global SVMs under very weak conditions. Though there already exist results on the latter of these two properties, this paper significantly generalizes them, notably also allowing the regions that underlie the localized SVMs to change as the size of the training data set increases, which is a situation also typically occurring in practice.},
  archive      = {J_NEUCOM},
  author       = {Hannes Köhler},
  doi          = {10.1016/j.neucom.2024.128060},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128060},
  shortjournal = {Neurocomputing},
  title        = {Lp- and risk consistency of localized SVMs},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed robust support vector ordinal regression under
label noise. <em>NEUCOM</em>, <em>598</em>, 128057. (<a
href="https://doi.org/10.1016/j.neucom.2024.128057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordinal regression (OR) methods are designed for a type of classification problems where data labels have natural orders. In practice, data may be corrupted by label noise, which affects the training process thus degrading the generalization performance of OR methods. In OR, data are usually assumed to have latent variables underlying the ordinal labels, and label noise exhibits a special characteristic that it usually causes large latent variable value deviations. However, there are few existing works on OR considering label noise, and the existing works do not utilize the above-mentioned characteristic. Besides, most of the existing OR methods are centralized, which are inapplicable in some realistic distributed applications. In this paper, we utilize the characteristic of label noise in OR to develop a distributed robust support vector ordinal regression method (dRSVOR) under label noise. Specifically, after analyzing the characteristic of label noise in OR, we take the form of SVOR with explicit constraints to achieve robustness to one type of mislabeled samples. Then, we adopt correntropy, an information-theoretic measure, to achieve robustness to the other type of mislabeled samples. Theoretically, we analyze the consensus and convergence of dRSVOR. Experimentally, we conduct experiments on both synthetic data and real OR datasets to illustrate the effectiveness of the proposed method. The results show that the centralized version of dRSVOR outperforms several state-of-the-art OR methods considering label noise in centralized circumstances with label noise, and dRSVOR could approach the performance of the centralized version despite additional constraints in distributed scenarios.},
  archive      = {J_NEUCOM},
  author       = {Huan Liu and Jiankai Tu and Anqi Gao and Chunguang Li},
  doi          = {10.1016/j.neucom.2024.128057},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128057},
  shortjournal = {Neurocomputing},
  title        = {Distributed robust support vector ordinal regression under label noise},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unified formulation of geometry-aware discrete dynamic
movement primitives. <em>NEUCOM</em>, <em>598</em>, 128056. (<a
href="https://doi.org/10.1016/j.neucom.2024.128056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from demonstration (LfD) is considered as an efficient way to transfer skills from humans to robots. Traditionally, LfD has been used to transfer Cartesian and joint positions and forces from human demonstrations. The traditional approach works well for some robotic tasks, but for many tasks of interest, it is necessary to learn skills such as orientation, impedance, and/or manipulability that have specific geometric characteristics. An effective encoding of such skills can be only achieved if the underlying geometric structure of the skill manifold is considered and the constrains arising from this structure are fulfilled during both learning and execution. However, typical learned skill models such as dynamic movement primitives (DMPs) are limited to Euclidean data and fail in correctly embedding quantities with geometric constraints. In this paper, we propose a novel and mathematically principled framework that uses concepts from Riemannian geometry to allow DMPs to properly embed geometric constrains. The resulting DMP formulation can deal with data sampled from any Riemannian manifold including, but not limited to, unit quaternions and symmetric and positive definite matrices. The proposed approach has been extensively evaluated both on simulated data and real robot experiments. The performed evaluation demonstrates that beneficial properties of DMPs, such as convergence to a given goal and the possibility to change the goal during operation, apply also to the proposed formulation.},
  archive      = {J_NEUCOM},
  author       = {Fares J. Abu-Dakka and Matteo Saveriano and Ville Kyrki},
  doi          = {10.1016/j.neucom.2024.128056},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128056},
  shortjournal = {Neurocomputing},
  title        = {A unified formulation of geometry-aware discrete dynamic movement primitives},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Offline prompt polishing for low quality instructions.
<em>NEUCOM</em>, <em>598</em>, 128046. (<a
href="https://doi.org/10.1016/j.neucom.2024.128046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instruction-tuning is an effective avenue for making large language models (LLMs) better at following real users’ instructions. However, it is challenging in aligning to human preference in user scenario since the instructions model received are usually not well-formatted. In this paper, we introduce offline prompt polishing and inserting specific delimiters before inputting them to the models to cope with these bad instructions. To better understand the user behavior in proposing instructions and how language models align to them, we introduce User-based Instructional Dataset (UID), a dataset comprises over 96,000 instruction–response pairs which contains over 3k human-revised free-form instructions collected from real-world scenarios. Within UID, we kept both original and revised instructions to improve model robustness. We obtained various IOPTs checkpoints, a range of OPT models (125M to 13B) trained with UID, through offline prompt polishing and delimiter insertion. The results demonstrate that IOPT-2.7B trained on 6,000 instances can achieve comparable performance to a 175B InstructGPT. Besides, we rigorously measure the impact of various factors including data volume, model size, and instruction format on aligning to real users’ instructions. We summarize several findings to shed a light on instruction-tuning under user scenario. Our dataset will be made public upon acceptance.},
  archive      = {J_NEUCOM},
  author       = {Jia Yu and Zhanchao Zhou and Long Li and Ling Li and Yuming Yan and Renjun Xu and Zhenzhong Lan},
  doi          = {10.1016/j.neucom.2024.128046},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128046},
  shortjournal = {Neurocomputing},
  title        = {Offline prompt polishing for low quality instructions},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Task-specific alignment and multiple-level transformer for
few-shot action recognition. <em>NEUCOM</em>, <em>598</em>, 128044. (<a
href="https://doi.org/10.1016/j.neucom.2024.128044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the research field of few-shot learning, the main difference between image-based and video-based is the additional temporal dimension. In recent years, some works have used the Transformer to deal with frames, then get the attention feature and the enhanced prototype, and the results are competitive. However, some video frames may relate little to the action, and only using single frame-level or segment-level features may not mine enough information. We address these problems sequentially through an end-to-end method named “Task-Specific Alignment and Multiple-level Transformer Network (TSA-MLT)”. The first module (TSA) aims to filter the action-irrelevant frames for action duration alignment. Affine Transformation for frame sequence in the time dimension is used for linear sampling. The second module (MLT) focuses on the Multiple-level feature of the support prototype and query sample to mine more information for the alignment, which operates on different level features. We adopt a fusion loss according to a fusion distance that fuses the L2 sequence distance, which focuses on temporal order alignment, and the Optimal Transport distance, which focuses on measuring the gap between the appearance and semantics of the videos. Extensive experiments show our method achieves state-of-the-art results on the HMDB51 and UCF101 datasets and a competitive result on the benchmark of Kinetics and something-2-something V2 datasets. Our code will be available at the URL: https://github.com/cofly2014/tsa-mlt.git .},
  archive      = {J_NEUCOM},
  author       = {Fei Guo and Li Zhu and YiKang Wang and Jing Sun},
  doi          = {10.1016/j.neucom.2024.128044},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128044},
  shortjournal = {Neurocomputing},
  title        = {Task-specific alignment and multiple-level transformer for few-shot action recognition},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EDAspy: An extensible python package for estimation of
distribution algorithms. <em>NEUCOM</em>, <em>598</em>, 128043. (<a
href="https://doi.org/10.1016/j.neucom.2024.128043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimation of distribution algorithms (EDAs) are a type of evolutionary algorithms where a probabilistic model is learned and sampled in each iteration. EDAspy provides different state-of-the-art implementations of EDAs including the recent semiparametric EDA. The implementations are modularly built, allowing for easy extension and the selection of different alternatives, as well as interoperability with new components. EDAspy is totally free and open-source under the MIT license.},
  archive      = {J_NEUCOM},
  author       = {Vicente P. Soloviev and Pedro Larrañaga and Concha Bielza},
  doi          = {10.1016/j.neucom.2024.128043},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128043},
  shortjournal = {Neurocomputing},
  title        = {EDAspy: An extensible python package for estimation of distribution algorithms},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attractors coexistence and representation research of
lotka–volterra recurrent neural networks by matrix analysis theory.
<em>NEUCOM</em>, <em>598</em>, 128040. (<a
href="https://doi.org/10.1016/j.neucom.2024.128040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attractor neural network models have been extensively studied in maintaining brain working memory state, spatial representation, and other brain processing mechanisms. The coexistence of multiple attractors in nonlinear neural network is particularly worth studying. The attractor is a stable state in the dynamic system, and all adjacent states will eventually be pulled to the attractor over time. Attractors can be regarded as the expression of data in low-dimensional state space, and different kinds of attractors can be used to process different information. The coexistence of multiple attractors means that a neural network can store multiple patterns, that is to say different memory mechanisms appear at the same time. Investigating the coexistence and competition of attractors within Lotka–Volterra(LV) recurrent neural networks presents a pivotal avenue for understanding the dynamical underpinnings of complex systems, particularly in the realm of computational neuroscience and ecological modeling. This paper studies the coexistence of different types of attractors in asymmetric Lotka–Volterra recurrent neural networks. Through the weight matrix block and matrix decomposition theory, we obtain the explicit expressions of continuous attractors and discrete attractors. Since neurons have multiple grouping methods, each weight matrix block satisfying certain conditions corresponds to different attractors. Different from traditional symmetric networks, the eigenvalues of the asymmetric weight matrices may be complex, which may correspond to ring attractors. Our research shows that attractors can coexist under certain conditions, depending on the weight matrix and external input. Moreover, through simulation experiments, we show that external input will cause the competition of attractors. Finally, we provide several simulations of attractor coexistence to illustrate our theory.},
  archive      = {J_NEUCOM},
  author       = {Ruonan Wu and Ziqian Zong and Jiali Yu and Shizhi Zhang and Zhang Yi},
  doi          = {10.1016/j.neucom.2024.128040},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128040},
  shortjournal = {Neurocomputing},
  title        = {Attractors coexistence and representation research of Lotka–Volterra recurrent neural networks by matrix analysis theory},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel direct method to h∞ synchronization of switching
inertial neural networks with mixed time-varying delays.
<em>NEUCOM</em>, <em>598</em>, 128039. (<a
href="https://doi.org/10.1016/j.neucom.2024.128039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the H ∞ H∞ synchronization problem of switching inertial neural networks with mixed time-varying delays is discussed. A parameterized system solution-based direct analysis method combined with minimum residence time method is proposed to solve the considered problem. The advantage of this method is that no model transformation or construction of Lyapunov–Krasovskii functional is required, thus reducing the complexity of derivation process. In addition, the resulting synchronization conditions composed of some simple scalar inequalities can be easily solved via MATLAB. Finally, the reliability of the theoretical results is illustrated by numerical simulations.},
  archive      = {J_NEUCOM},
  author       = {Xian Zhang and Shilei Yuan and Yantao Wang and Xiaona Yang},
  doi          = {10.1016/j.neucom.2024.128039},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128039},
  shortjournal = {Neurocomputing},
  title        = {A novel direct method to h∞ synchronization of switching inertial neural networks with mixed time-varying delays},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Learning from demonstration for 7-DOF anthropomorphic
manipulators without offset via analytical inverse kinematics.
<em>NEUCOM</em>, <em>598</em>, 128036. (<a
href="https://doi.org/10.1016/j.neucom.2024.128036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from demonstration (LfD) has been widely studied as a convenient method for robot learning. In the LfD paradigm for redundant manipulators, the reproduced trajectories ought to be similar to human demonstrations in both task and joint space. Despite many advancements achieved in the context of learning in task space, the solutions for generating similar reproductions in joint space are still largely open. In this paper, a novel non-parametric LfD framework for 7-DOF anthropomorphic manipulators with high computational efficiency is proposed. The proposed method leverages redundancy resolution and kernel-based approaches to formulate an efficient model characterized by a limited set of open parameters. Experiments were conducted to evaluate the performance of the proposed method and compare it with the commonly used ‘LfD+IK’ solution. The results indicated that the proposed method behaves much better in terms of the similarity between the demonstration and reproduction with high computing efficiency. As the proposed method can learn from human demonstrations effectively in both task and joint space, it has the potential to significantly enhance human–robot collaboration, streamline assembly line processes, or improving robot learning. An important future challenge will be extending the proposed method for general-purpose redundant manipulators and considering task constraints to perform complex tasks.},
  archive      = {J_NEUCOM},
  author       = {Kui Hu and Jiwen Zhang and Dan Wu},
  doi          = {10.1016/j.neucom.2024.128036},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128036},
  shortjournal = {Neurocomputing},
  title        = {Learning from demonstration for 7-DOF anthropomorphic manipulators without offset via analytical inverse kinematics},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unified feature learning network for few-shot fault
diagnosis. <em>NEUCOM</em>, <em>598</em>, 128035. (<a
href="https://doi.org/10.1016/j.neucom.2024.128035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot fault diagnosis aims at diagnosing the state of mechanical signals with only a few training samples. Numerous contemporary approaches incorporate Time–Frequency Images (TFIs) derived from vibration signals to provide a thorough understanding of both the time and frequency domains. Current approaches often neglect the exploration of sample-level features, which hinders the enrichment and refinement of sample features. To this end, we propose a Unified Feature Learning Network (UFLN) designed to comprehensively model TFIs at two levels. We first present a Texture Enhancement Module (TEM) to amplify intricate details, aiding in the extraction of category-level features. Subsequently, we devise a dynamic Feature Selection Module (DFSM), tailored for the extraction of fault-related features. Finally, we develop an Intra-Diversity (ID) loss function to promote intra-class diversity, enriching the representation of each sample. Extensive experiments on three cases have demonstrated the effectiveness of the proposed UFLN approach.},
  archive      = {J_NEUCOM},
  author       = {Yan Xu and Xinyao Ma and Xuan Wang and Jinjia Wang and Gang Tang and Zhong Ji},
  doi          = {10.1016/j.neucom.2024.128035},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128035},
  shortjournal = {Neurocomputing},
  title        = {Unified feature learning network for few-shot fault diagnosis},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural network adaptive switched fault-tolerant control of
uncertain nonlinear systems with full state constraints.
<em>NEUCOM</em>, <em>598</em>, 128034. (<a
href="https://doi.org/10.1016/j.neucom.2024.128034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the neural network adaptive fault-tolerant control (NNAFTC) for a class of uncertain nonlinear systems with full state constraints. It is the first time to introduce switched adaptive fault compensation strategy for the controller design process. On the one hand, the proposed method overcomes the limitation needed to be given a prescribed local restriction region of the traditional state constraint schemes, such as log-type, tan-type and integral-type. On the other hand, the full-state constraint and switched fault-tolerant problem is effectively solved even if the existence of actuator failures. Concomitantly, the novel switched tuning functions, the NN approximation technique and the integral barrier Lyapunov functions (IBLF) are combined to construct the backstepping controllers and adaptation laws. It can be proved that all the closed-loop states are restricted in the proper compact sets for any given initial values. Finally, A simulation is shown to demonstrate the validity and advantages of the presented control approach.},
  archive      = {J_NEUCOM},
  author       = {Li-Bing Wu and Xi-Qin He and Liang-Dong Guo and Sheng-Juan Huang and Yu-Han Hu},
  doi          = {10.1016/j.neucom.2024.128034},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128034},
  shortjournal = {Neurocomputing},
  title        = {Neural network adaptive switched fault-tolerant control of uncertain nonlinear systems with full state constraints},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NeuronLab: BCI framework for the study of biosignals.
<em>NEUCOM</em>, <em>598</em>, 128027. (<a
href="https://doi.org/10.1016/j.neucom.2024.128027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain–Computer Interfaces (BCIs) allow the acquisition of brain activity using non-invasive techniques such as Electroencephalography (EEG). Since BCI devices do not commonly interpret the acquired EEG signals, external software applications play a critical role in the BCI lifecycle. Despite the literature offering a great variety of platforms and frameworks, they present several limitations, such as implementing old software architectures or needing more functionality to cover all phases of the BCI lifecycle. Based on these limitations, this work proposes the design and implementation of NeuronLab, a secure, multi-platform, standalone, multi-paradigm, and web-based framework that defines all BCI lifecycle phases and provides novel functionality compared to current open-source BCI software, such as sharing experiments between researchers and storing data on the cloud. This framework has been validated in two experiments common in BCI literature: P300 identification and limb movements detection. This verification has been performed based on performance metrics, such as CPU and RAM consumption, highlighting that NeuronLab is a promising solution for BCI scenarios requiring a distributed and collaborative platform for researchers and practitioners.},
  archive      = {J_NEUCOM},
  author       = {Sergio López Bernal and Juan Antonio Martínez López and Enrique Tomás Martínez Beltrán and Mario Quiles Pérez and Gregorio Martínez Pérez and Alberto Huertas Celdrán},
  doi          = {10.1016/j.neucom.2024.128027},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128027},
  shortjournal = {Neurocomputing},
  title        = {NeuronLab: BCI framework for the study of biosignals},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Determining r- and (r, s)-robustness of multiagent networks
based on heuristic algorithm. <em>NEUCOM</em>, <em>598</em>, 128025. (<a
href="https://doi.org/10.1016/j.neucom.2024.128025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph properties of r r - and ( r , s r,s )-robustness are of importance for multiagent networks since these properties ensure consensus among agents even in the presence of a limited number of arbitrarily misbehaving agents, given sufficiently large values for the integers r r and s s . However, determining the exact solutions of r r - and ( r , s r,s )-robustness of an arbitrary directed graph has been proven to be computationally complex NP-hard problem. In this paper, we introduce a novel method, named the Determining Robustness based Genetic Algorithm (DRSGA), for approximately calculating the r r - and ( r , s r,s )-robustness using heuristic algorithm. According to graph theory in mathematical analysis, we first formalize the method for calculating the r r - and ( r , s r,s )-robustness in directed graphs by utilizing a three-vertex set partition. Then, we transform these methods into a minimization problem of an n n -dimensional discrete function and employ DRSGA to obtain an approximate solution. Finally, we validate the efficacy of our algorithm through a series of experiments compared to existing mixed-integer programming algorithms.},
  archive      = {J_NEUCOM},
  author       = {Jie Jiang and Yiming Wu and Zhaoming Zhang and Ning Zheng and Wei Meng},
  doi          = {10.1016/j.neucom.2024.128025},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128025},
  shortjournal = {Neurocomputing},
  title        = {Determining r- and (r, s)-robustness of multiagent networks based on heuristic algorithm},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DANet: A spatio-temporal dynamics and detail aware network
for video prediction. <em>NEUCOM</em>, <em>598</em>, 128023. (<a
href="https://doi.org/10.1016/j.neucom.2024.128023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video prediction aims to predict the upcoming future frames by modeling the complex spatiotemporal dynamics from given videos. However, most existing video prediction methods still perform sub-optimal in generating high-visual-quality future frames. The reasons behind that are: 1) these methods struggle to reason accurate future motion due to extracting insufficient spatiotemporal correlations from the given frames. 2) The state transition units in the previous works are complex, which inevitably results in the loss of spatial details. When the videos contain variable motion patterns ( e.g. rapid movement of objects) and complex spatial information ( e.g. texture details), blurring artifacts and local absence of objects may occur in the predicted frames. In this work, to predict more accurate future motion and preserve more details information, we propose an end-to-end trainable dual-branch video prediction framework, spatiotemporal Dynamics and Detail Aware Network (DANet). Specifically, to predict future motion, we propose a SpatioTemporal Memory (ST-Memory) to learn motion evolution in the temporal domain from the given frames by transmitting the deep features along a zigzag direction. To obtain adequate spatiotemporal correlations among frames, the MotionCell is constructed in the ST-Memory to facilitate the expansion of the receptive field. The spatiotemporal attention is utilized in the ST-Memory to focus on the global variation of given frames. Additionally, to preserve useful spatial details, we design the Spatial Details Memory (SD-Memory) to capture the global and local dependencies of the given frames at the pixel level. Extensive experiments conducted on three public datasets for both synthetic and natural demonstrate that the DANet has excellent performance for video prediction compared with state-of-the-art methods. In brief, DANet outperforms the state-of-the-art methods in terms of MSE by 3.1, 1.0× 1 0 − 2 and 14.3 × 10 on three public benchmark datasets, respectively.},
  archive      = {J_NEUCOM},
  author       = {Huilin Huang and YePeng Guan},
  doi          = {10.1016/j.neucom.2024.128023},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128023},
  shortjournal = {Neurocomputing},
  title        = {DANet: A spatio-temporal dynamics and detail aware network for video prediction},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An overview: Attention mechanisms in multi-agent
reinforcement learning. <em>NEUCOM</em>, <em>598</em>, 128015. (<a
href="https://doi.org/10.1016/j.neucom.2024.128015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, in the field of Multi-Agent Systems (MAS), significant progress has been made in the research of algorithms that combine Reinforcement Learning (RL) with Attention Mechanism (AM). However, there is a lack of comprehensive reviews in this field. Based on this, this paper does the following work. Firstly, it reviews the classical algorithms of RL and AM; Secondly, it systematically introduces the combination of RL and AM; Thirdly, it sorts out their application in the field of single-agent and multi-agent, and pays attention to and looks forward to the challenges and future research prospects in this field; The last part offers a comprehensive analysis of the challenges encountered by research in this field and anticipates future research paths. The research offers a conceptual understanding and theoretical foundation for future applications of RL using AM and facilitates further in-depth study in this field for researchers.},
  archive      = {J_NEUCOM},
  author       = {Kai Hu and Keer Xu and Qingfeng Xia and Mingyang Li and Zhiqiang Song and Lipeng Song and Ning Sun},
  doi          = {10.1016/j.neucom.2024.128015},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128015},
  shortjournal = {Neurocomputing},
  title        = {An overview: Attention mechanisms in multi-agent reinforcement learning},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CoProLITE: Constrained proxy learning for lIver and hepaTic
lesion sEgmentation. <em>NEUCOM</em>, <em>598</em>, 128014. (<a
href="https://doi.org/10.1016/j.neucom.2024.128014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liver and hepatic lesion segmentation is an important task in medical image analysis, which plays a crucial role in diagnosis, treatment planning and monitoring of liver diseases. We observed an ordinal layout of the feature space that aligns with CT image characteristics will improve performance on liver and hepatic lesion segmentation task. In order to enforce the samples to conform to a specific layout of the feature space, we propose a novel liver and hepatic lesion segmentation method called CoProLITE, which learns a constrained proxy for each classes. Specifically, We replace the traditional FCN-based segmentation head by a proxy learning-based head to learn feature representations of the images, and introduces constraints during the training process to guide the learning of the proxies. We extensively evaluate CoProLITE on three public datasets and compare it to state-of-the-art methods. The experimental results demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yuchen Fu and Song Liu and Cong Wang and Zhiwei Jiang and Juan Du and Qing Gu},
  doi          = {10.1016/j.neucom.2024.128014},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128014},
  shortjournal = {Neurocomputing},
  title        = {CoProLITE: Constrained proxy learning for lIver and hepaTic lesion sEgmentation},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Low complexity, high throughput, energy efficient, pipelined
and reconfigurable ASIC realization architecture for multi-layer
perceptron models. <em>NEUCOM</em>, <em>598</em>, 128013. (<a
href="https://doi.org/10.1016/j.neucom.2024.128013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been continuously growing research interest in Artificial Neural Networks (ANNs) due to their vast acceptance in many real-world applications. This has led to the appearance of a variety of realization methods for multilayer perceptron (MLP) inference models. In this paper, we propose a generalized 3-stage, configurable, multiplier-less, massive parallel realization architecture for MLP inference models. We use offset binary coded distributive arithmetic (OBC-DA), which uses LUTs to reduce hardware requirements, to realize internal computing units of MLPs. The designing efforts to achieve a reduction in resource requirements are two-fold; (i) reduction in LUT size itself, which is achieved by exploiting symmetry induced by OBC-DA and thereby reducing LUT size by 50%, and (ii) reduction in total number of LUTs which is attained by sharing the LUTs. The resource efficiency of the proposed architecture is further improved by decomposing the LUTs into parallel and smaller LUTs. Moreover, the resource efficiency is also enhanced by utilizing the symmetry among the inputs in the MLP layer. The ASIC synthesis results for underlying MLPs establish that the proposed method for the realization of MLPs is much more efficient than the earlier reported methods and coincides with the findings of the generalized hardware-timing complexities.},
  archive      = {J_NEUCOM},
  author       = {Raghuvendra Pratap Tripathi and Virat Krishna and Manish Tiwari and Gaurav Trivedi and Amit Dhawan and Prashant Kumar},
  doi          = {10.1016/j.neucom.2024.128013},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128013},
  shortjournal = {Neurocomputing},
  title        = {Low complexity, high throughput, energy efficient, pipelined and reconfigurable ASIC realization architecture for multi-layer perceptron models},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024e). Adaptive finite-time bipartite consensus of multi-agent
systems with communication link uncertainty under signed digraph.
<em>NEUCOM</em>, <em>598</em>, 128012. (<a
href="https://doi.org/10.1016/j.neucom.2024.128012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the finite-time bipartite consensus problem of a class of nonlinear multi-agent systems (MASs) with communication link uncertainty under signed digraph. The existence of uncertainty affects the information exchange between agents. Therefore, this article designs a distributed adaptive finite-time observer that enables followers to accurately estimate the leader’s state. Afterwards, based on the state of the finite-time observer and neural networks, an adaptive controller is designed, which increases the degree of freedom of the parameters. This results in a faster convergence rate of the system. Subsequently, it is proven that MASs with communication link uncertainty can achieve bipartite consensus in finite-time by stability analysis. Finally, the effectiveness of the proposed control scheme is verified through simulation.},
  archive      = {J_NEUCOM},
  author       = {Qiufu Wang and Zhanshan Wang and Lei Ma},
  doi          = {10.1016/j.neucom.2024.128012},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128012},
  shortjournal = {Neurocomputing},
  title        = {Adaptive finite-time bipartite consensus of multi-agent systems with communication link uncertainty under signed digraph},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Applying deep learning image enhancement methods to improve
person re-identification. <em>NEUCOM</em>, <em>598</em>, 128011. (<a
href="https://doi.org/10.1016/j.neucom.2024.128011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification has gained significant attention in recent years due to its numerous practical applications in video surveillance. However, while artificial intelligence and deep learning methods have enabled substantial progress in particular aspects of this domain, putting together those individual advances to generate practical systems remains a computer vision challenge. Existing methods are typically designed assuming the target person’s images are captured under uniform, stable conditions with similar lighting levels, but this assumption may not hold in real-world scenarios, such as outdoor monitoring over 24 h, as image quality can vary considerably throughout day and night. In this paper, we propose a framework that incorporates image enhancement techniques to improve the performance of a person re-identification model. The proposed approach achieves a significant improvement in a demanding re-identification dataset, raising the mAP from 9.0% using a zero-shot baseline to 65.8% through the combined use of low-light image enhancement methods and noise reduction.},
  archive      = {J_NEUCOM},
  author       = {Oliverio J. Santana and Javier Lorenzo-Navarro and David Freire-Obregón and Daniel Hernández-Sosa and Modesto Castrillón-Santana},
  doi          = {10.1016/j.neucom.2024.128011},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128011},
  shortjournal = {Neurocomputing},
  title        = {Applying deep learning image enhancement methods to improve person re-identification},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of deep learning based malware detection
techniques. <em>NEUCOM</em>, <em>598</em>, 128010. (<a
href="https://doi.org/10.1016/j.neucom.2024.128010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularization of computer technology, the number of malware has increased dramatically in recent years. Some malware can threaten the network security of users by downloading and installing, and even spreading widely on the Internet, causing consequences such as private data leakage in the operating system, extortion, and network paralysis. In order to deal with these threats, researchers analyze malicious samples through various analysis techniques, which are usually divided into static and dynamic analysis based on the principle of whether the code needs to be executed or not. This paper analyzes in detail several classical methods of feature extraction in malware detection techniques. With the technological development of artificial intelligence, deep learning is gradually being introduced into malware detection, which does not require the identification of professional security personnel and greatly improves the generalization ability of detection. In the paper, text-based detection methods, image visualization-based detection, and graph structure-based detection techniques are reviewed according to different feature extraction methods. In addition, the paper compares 26 datasets that have been commonly used in recent years applied in the research field and explains the main contents and specifications of the datasets. Finally, a summary and outlook of the malware research field is given.},
  archive      = {J_NEUCOM},
  author       = {Huijuan Wang and Boyan Cui and Quanbo Yuan and Ruonan Shi and Mengying Huang},
  doi          = {10.1016/j.neucom.2024.128010},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128010},
  shortjournal = {Neurocomputing},
  title        = {A review of deep learning based malware detection techniques},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on collaborative hunting with robotic swarm: Key
technologies and application scenarios. <em>NEUCOM</em>, <em>598</em>,
128008. (<a href="https://doi.org/10.1016/j.neucom.2024.128008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with a single robot, robotic swarm realizes multi-agent cooperative operations through information interaction, and has such characteristics of wide combat monitoring range, flexible combat organization and strong reconfiguration. As the intelligence of robotic swarm, collaborative hunting tasks have been used in the fields of intrusion countermeasures, target elimination, scientific research, target rescue and etc. A comprehensive overview of current state of researches on collaborative hunting tasks with robotic swarm would be beneficial to researchers. Therefore, we provide an overview of research progress related to collaborative hunting tasks of robotic swarm in this paper. Specifically, we analyze key technologies in the collaborative hunting tasks from the perspectives of target searching, hunting task allocation and tracking path planning. Moreover, we summarize the differences of hunting strategies in different scenarios (i.e., air scenario, sea scenario and ground scenario), so it has important guiding significance for future researches. Finally, we discuss future research directions for collaborative hunting tasks of robotic swarm.},
  archive      = {J_NEUCOM},
  author       = {Wenyu Cai and Hao Chen and Meiyan Zhang},
  doi          = {10.1016/j.neucom.2024.128008},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128008},
  shortjournal = {Neurocomputing},
  title        = {A survey on collaborative hunting with robotic swarm: Key technologies and application scenarios},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Single image deraindrop leveraging luminance priors and
context aggregation. <em>NEUCOM</em>, <em>598</em>, 127971. (<a
href="https://doi.org/10.1016/j.neucom.2024.127971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many deep learning-based raindrop removal methods have been proposed recently and demonstrated good performance. However, most deep learning based raindrop removal methods struggle to restore distorted color and texture resulting from the refraction of raindrops emitted from different background points. To overcome this challenge, we propose a novel recurrent single-image deraindrop approach that utilizes luminance priors and contextual feature aggregation. Our method decomposes the deraindrop process into a raindrop detection network and a raindrop removal network, leveraging the luminance differences between the raindrop and non-raindrop regions for accurate detection. Contextual feature aggregation, achieved by dilated convolutions with different rates, helps recover raindrop attachment areas and maintain consistency in color and texture. We have extensively evaluated our method on synthetic and real raindrop datasets, demonstrating its effectiveness, generalization capability, and superior performance compared to state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yi Liu and Zhi Gao and Tiancan Mei and Han Yi},
  doi          = {10.1016/j.neucom.2024.127971},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127971},
  shortjournal = {Neurocomputing},
  title        = {Single image deraindrop leveraging luminance priors and context aggregation},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024g). Bipartite finite-time consensus of multi-agent systems with
intermittent communication via event-triggered impulsive control.
<em>NEUCOM</em>, <em>598</em>, 127970. (<a
href="https://doi.org/10.1016/j.neucom.2024.127970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concentrates on the bipartite finite-time consensus (BFTC) problem of nonlinear multi-agent systems (MASs) under intermittent communication via event-triggered impulsive control. First, a finite-time consensus (FTC) protocol with an event-triggered mechanism is developed for the MASs with nonlinear dynamics to save limited resources. Then, an impulsive control scheme is introduced to the designed algorithm to further improve the control performance. Based on the structurally balanced graph theory, both antagonistic and cooperative interactions are discussed in this article. Regarding whether the MASs have encountered intermittent communication, sufficient conditions are provided for achieving consensus of the MASs by using the Lyapunov theory and inductive methods. Moreover, the Zeno behavior is excluded. Finally, numerical simulations are given to validate the effectiveness of the algorithm. The result shows that the designed event-triggered BFTC control protocol with an impulsive strategy has a faster convergence rate than that without an impulsive strategy.},
  archive      = {J_NEUCOM},
  author       = {Xiao Wang and Shandan Wang and Jian Liu and Yongbao Wu and Changyin Sun},
  doi          = {10.1016/j.neucom.2024.127970},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127970},
  shortjournal = {Neurocomputing},
  title        = {Bipartite finite-time consensus of multi-agent systems with intermittent communication via event-triggered impulsive control},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tricking AI chips into simulating the human brain: A
detailed performance analysis. <em>NEUCOM</em>, <em>598</em>, 127953.
(<a href="https://doi.org/10.1016/j.neucom.2024.127953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, significant strides in Artificial Intelligence (AI) have led to various practical applications, primarily centered around training and deployment of deep neural networks (DNNs). These applications, however, require considerable computational resources, predominantly reliant on modern Graphics-Processing Units (GPUs). Yet, the quest for larger and faster DNNs has spurred the creation of specialized AI chips and efficient Machine-Learning (ML) software tools like TensorFlow and PyTorch have been developed for striking a balance between usability and performance. Simultaneously, the field of computational neuroscience shares a similar quest for increased computational power to simulate more extensive and detailed brain models, while also keeping usability high. Although GPUs have also entered this field, programming complexity remains high, resulting in cumbersome simulations. Inspired by AI progress, we introduce a workflow for easily accelerating brain simulations using TensorFlow and evaluate the performance of various, cutting-edge AI chips – including the Graphcore Intelligence-Processing Unit (IPU), GroqChip, Nvidia GPU with Tensor Cores, and Google Tensor-Processing Unit (TPU) – when simulating a biologically detailed as well as simpler brain models. Our model simulations explore the architectural tradeoffs of a modern-day CPU and these four AI platforms by varying computational density, memory requirements and floating-point numerical accuracy. Results show that the GroqChip achieves the best performance for small networks, yet is unable to simulate large-scale networks. At the scale of mammalian brains, the GPU, IPU and TPU achieve speedups ranging from 29x to 1,208x times over CPU runtimes. Remarkably, the TPU sets a new record for the largest, real-time simulation of the inferior-olivary nucleus in the brain. Reduced-accuracy floating-point implementations make some simulation results unreliable for brain research, notably for the GroqChip. Consequently, this work underscores the potential of ML libraries for accelerating brain simulations as well as the critical role of AI-chip numerical accuracy for biophysically realistic brain models.},
  archive      = {J_NEUCOM},
  author       = {Lennart P.L. Landsmeer and Max C.W. Engelen and Rene Miedema and Christos Strydis},
  doi          = {10.1016/j.neucom.2024.127953},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127953},
  shortjournal = {Neurocomputing},
  title        = {Tricking AI chips into simulating the human brain: A detailed performance analysis},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning compact and overlap-biased interactions for point
cloud registration. <em>NEUCOM</em>, <em>598</em>, 127949. (<a
href="https://doi.org/10.1016/j.neucom.2024.127949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud registration is a fundamental task in computer vision. Recent Transformer based methods for point cloud registration take advantage of the interaction modeling ability of the attention operation. However, feature ambiguity and low overlap are still the bottleneck in real scenes point cloud registration. In this paper, we present a new neural network to solve these two problems in Transformer architecture. First, we propose an Optimal Transport guided Cross Attention (OT-CA) to build compact interactions in CA which can mitigating the feature ambiguity problem. It uses a Spatial Consistency guided cost Regularization (SCR) to build the cost for the optimal transport problem, and get the weight matrix of CA by solving it. The structure information and more reasonable interactions can alleviate the feature ambiguity problem with fewer computing resources. Meanwhile, we propose a Separate-and-Joint Overlap Prediction module to solve the low-overlap problem. It adopts separate branches and training steps for feature matching and overlap prediction to reduce negative impacts between these two tasks, and adopts a joint training process to make full use of overlap information for learning better feature matching. Finally, the proposed modules are embedded into a coarse-to-fine pipeline. Our method shows state-of-the-art performance on three benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Lin Guo and Zhi Chen and Senmao Cheng and Fan Yang and Wenbing Tao},
  doi          = {10.1016/j.neucom.2024.127949},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127949},
  shortjournal = {Neurocomputing},
  title        = {Learning compact and overlap-biased interactions for point cloud registration},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Projected latent distillation for data-agnostic
consolidation in distributed continual learning. <em>NEUCOM</em>,
<em>598</em>, 127935. (<a
href="https://doi.org/10.1016/j.neucom.2024.127935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In continual learning applications on-the-edge multiple self-centered devices (SCD) learn different local tasks independently, with each SCD only optimizing its own task. Can we achieve (almost) zero-cost collaboration between different devices? We formalize this problem as a Distributed Continual Learning (DCL) scenario, where SCDs greedily adapt to their own local tasks and a separate continual learning (CL) model perform a sparse and asynchronous consolidation step that combines the SCD models sequentially into a single multi-task model without using the original data. Unfortunately, current CL methods are not directly applicable to this scenario. We propose Data-Agnostic Consolidation (DAC), a novel double knowledge distillation method which performs distillation in the latent space via a novel Projected Latent Distillation loss. Experimental results show that DAC enables forward transfer between SCDs and reaches state-of-the-art accuracy on Split CIFAR100, CORe50 and Split TinyImageNet, both in single device and distributed CL scenarios. Somewhat surprisingly, a single out-of-distribution image is sufficient as the only source of data for DAC.},
  archive      = {J_NEUCOM},
  author       = {Antonio Carta and Andrea Cossu and Vincenzo Lomonaco and Davide Bacciu and Joost van de Weijer},
  doi          = {10.1016/j.neucom.2024.127935},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127935},
  shortjournal = {Neurocomputing},
  title        = {Projected latent distillation for data-agnostic consolidation in distributed continual learning},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unleashing the potential of spiking neural networks for
epileptic seizure detection: A comprehensive review. <em>NEUCOM</em>,
<em>598</em>, 127934. (<a
href="https://doi.org/10.1016/j.neucom.2024.127934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is a prevalent neurological condition characterized by repeated seizures resulting from structural or functional changes in the brain. Standard treatment approaches include anti-epileptic medications and surgical interventions. However, for patients with drug-resistant epilepsy, long-term EEG recordings are essential to monitor medication efficacy and make necessary adjustments to minimize seizure frequency. Continuous monitoring of such patients requires compact and comfortable wearable devices. This review explores the potential of Spiking Neural Networks (SNNs) for low-power signal processing in neuromorphic systems, specifically addressing the demand for compact and wearable devices. SNNs offer rapid computation, minimal power consumption, and superior data representation compared to traditional artificial neural networks (ANNs). With biological plausibility and event-driven hardware support, SNNs are well-suited for modeling neural activity in epilepsy. The review delves into existing literature, investigating the potential of SNNs in seizure detection. It covers various aspects, including the neuronal system, neuromorphic computing, SNN architecture, spiking neuron models, spike encoding schemes, and training methodologies. Representative studies utilizing spike-based machine learning for seizure detection are examined. Furthermore, the review addresses gaps, challenges, strengths, weaknesses, and trade-offs in SNN implementations. By spotlighting the capabilities of SNNs, this review aims to stimulate further research and innovative approaches, contributing to the advancement of epilepsy diagnosis and management.},
  archive      = {J_NEUCOM},
  author       = {Resmi Cherian and Grace Mary Kanaga E},
  doi          = {10.1016/j.neucom.2024.127934},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127934},
  shortjournal = {Neurocomputing},
  title        = {Unleashing the potential of spiking neural networks for epileptic seizure detection: A comprehensive review},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Online industrial fault prognosis in dynamic environments
via task-free continual learning. <em>NEUCOM</em>, <em>598</em>, 127930.
(<a href="https://doi.org/10.1016/j.neucom.2024.127930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online industrial fault prognosis based on real-time condition monitoring plays a significant role in the predictive maintenance of the interested system in service. Despite the recent advances in deep learning-based fault prognosis, most existing works focus on offline tasks using static deep models, which cannot flexibly adapt their learning behavior to the real-time health conditions of the interested machines. To meet more realistic scenarios, it is essential but challenging to develop an online prognostic method that is capable of incrementally learning and flexibly adapting to different tasks in dynamic environments. Meanwhile, continual learning as a new learning paradigm aims at learning adaptively like humans. This paper proposes a novel online fault prognosis paradigm via task-free continual learning towards more practical industrial scenarios. Correspondingly, an intelligent fault prognosis method based on continual neural Dirichlet process mixture is developed for this problem. It dynamically allocates new resources to learn new tasks by integrating the mixture of experts with the Bayesian nonparametric framework, wherein each expert with two components is designed to perform remaining useful life prediction and task identification respectively. The comprehensive experimental results on two turbofan engine datasets validate the proposed method, which offers a promising solution for online fault prognosis under more open settings.},
  archive      = {J_NEUCOM},
  author       = {Chongdang Liu and Linxuan Zhang and Yimeng Zheng and Zhengyi Jiang and Jinghao Zheng and Cheng Wu},
  doi          = {10.1016/j.neucom.2024.127930},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127930},
  shortjournal = {Neurocomputing},
  title        = {Online industrial fault prognosis in dynamic environments via task-free continual learning},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel poisoning attacks for clustering methods via robust
feature generation. <em>NEUCOM</em>, <em>598</em>, 127925. (<a
href="https://doi.org/10.1016/j.neucom.2024.127925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers have shown that deep learning models are susceptible to adversarial examples, however, most existing works focus on supervised learning. Recently, research has shown that unsupervised learning, such as clustering, tends to be vulnerable due to adversarial attacks and poisoning attacks. This work mainly explores adversarial attacks against clustering models in two situations: attacks at decision time and data poisoning attacks. We present the possibility of adversarial attacks on the clustering model and offer clean-label poisoning attacks to clustering models by adding small perturbations on all training data. Concretely, firstly we present that the adversarial examples at decision time for the k-means model and Gaussian mixture model (GMM) can be crafted by moving the raw input to the decision boundary, which is also appropriate for the data poisoning attack. Secondly, we craft poisoning data by adding robust features to the benign inputs. The poisoning attack could make personal data unlearnable for clustering models, which preserves an individual’s privacy. Quantitative experimental results show that the success rate of proposed adversarial attacks for clustering models is close to 100%, and our data poisoning attack could make the clustering model like a random guess, which proves the effectiveness of our approaches. Adversarial attacks in clustering, containing decision time and data poisoning attacks, should receive more attention.},
  archive      = {J_NEUCOM},
  author       = {Chen Zhang and Zhuo Tang},
  doi          = {10.1016/j.neucom.2024.127925},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127925},
  shortjournal = {Neurocomputing},
  title        = {Novel poisoning attacks for clustering methods via robust feature generation},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). JRC: Deepfake detection via joint reconstruction and
classification. <em>NEUCOM</em>, <em>598</em>, 127862. (<a
href="https://doi.org/10.1016/j.neucom.2024.127862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has enabled realistic face manipulation for malicious purposes (e.g., deepfakes), which poses significant concerns over the integrity of the media in circulation. Most existing deep learning techniques for deepfake detection can achieve promising performance in the intra-dataset evaluation setting, but are unable to perform satisfactorily in the inter-dataset evaluation setting. Most previous methods use a backbone network to extract global features for making predictions and only employ binary supervision to train the network. Classification merely based on the learning of global features often leads to weak generalizability to deepfakes of unseen manipulation methods. In this paper, we design a two-branch Convolutional AutoEncoder (CAE), which considers the reconstruction and classification tasks simultaneously for deepfake detection. This Joint Reconstruction and Classification (JRC) method shares the information learned by one task with the other, each focusing on different aspects, and hence boosts the overall performance. JRC is end-to-end, and experiments demonstrate that it achieves state-of-the-art performance on three commonly-used datasets, particularly in the cross-dataset evaluation setting.},
  archive      = {J_NEUCOM},
  author       = {Bosheng Yan and Chang-Tsun Li and Xuequan Lu},
  doi          = {10.1016/j.neucom.2024.127862},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127862},
  shortjournal = {Neurocomputing},
  title        = {JRC: Deepfake detection via joint reconstruction and classification},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dual-prototype network combining query-specific and
class-specific attentive learning for few-shot action recognition.
<em>NEUCOM</em>, <em>598</em>, 127819. (<a
href="https://doi.org/10.1016/j.neucom.2024.127819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-Shot Action Recognition (FSAR) aims at recognizing novel action classes with only a few labelled samples. Due to its simplicity and effectiveness, the prototypical network has attracted increasing interest in the field of FSAR. It is key to learn representative prototypes from a few labelled videos with various action lengths and speeds. To address this issue, this paper presents a dual-prototype network that combines class-specific and query-specific attentive learning for FSAR. First, we propose a class-specific attentive learning method that computes the within-class similarity for each class of the support sample. This method not only increases the representativeness of prototypes but also mitigates the impact of noises and outlying samples. Second, the class-specific attention is combined with query-specific attention to establish two parallel sets of prototypes for FSAR. The incorporation of query-specific attention further increases the discrimination among prototypes for different query samples. Furthermore, we propose a temporal-relation model to express the temporal dependency of action videos with different lengths and speeds. The proposed method is validated on four benchmark datasets. Extensive experimental results demonstrate the superiority of our method to the other 11 state-of-the-art FSAR methods.},
  archive      = {J_NEUCOM},
  author       = {Lei Jiang and Yongzhao Zhan and Zhen Jiang and Na Tang},
  doi          = {10.1016/j.neucom.2024.127819},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127819},
  shortjournal = {Neurocomputing},
  title        = {A dual-prototype network combining query-specific and class-specific attentive learning for few-shot action recognition},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient one-shot neural architecture search with
progressive choice freezing evolutionary search. <em>NEUCOM</em>,
<em>598</em>, 127702. (<a
href="https://doi.org/10.1016/j.neucom.2024.127702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Architecture Search (NAS) is a fast-developing research field to promote automatic machine learning. Among the recently popular NAS methods, one-shot NAS has attracted significant attention since it greatly reduces the training cost compared with the previous NAS methods. In one-shot NAS, different architectures are encoded in a supernet, which is a stack of basic blocks, and each block contains multiple architecture choices. The supernet is usually trained only once and can be reused for different search scenarios. For each search scenario, the best candidate network architecture is searched within the supernet, and each candidate is formed by selecting one choice from each block in the supernet and inheriting the corresponding weights. In practice, the searching process involves numerous inference processes for each user case, which causes high overhead in terms of latency and energy consumption. To tackle this problem, we first observe that the choices of the first few blocks that belong to different candidate networks will become similar at the early search stage. Furthermore, these choices are already close to the optimal choices obtained at the end of the search. Leveraging this interesting feature, we propose a progressive choice freezing evolutionary search (PCF-ES) method that gradually freezes block choices for all candidate networks during the searching process. This approach gives us an opportunity to reuse the intermediate data produced by the frozen blocks instead of re-computing them. The experiment results show that the proposed PCF-ES with importance sampling provides up to 76% speedup and reduces carbon dioxide emissions by 71% during the searching stage.},
  archive      = {J_NEUCOM},
  author       = {Chen Zhang and Qiyu Wan and Lening Wang and Yu Wen and Mingsong Chen and Jingweijia Tan and Kaige Yan and Xin Fu},
  doi          = {10.1016/j.neucom.2024.127702},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127702},
  shortjournal = {Neurocomputing},
  title        = {Efficient one-shot neural architecture search with progressive choice freezing evolutionary search},
  volume       = {598},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Zero‐shot 3D pose estimation of unseen object by two‐step
RGB-d fusion. <em>NEUCOM</em>, <em>597</em>, 128041. (<a
href="https://doi.org/10.1016/j.neucom.2024.128041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D Object pose estimation is a critical task in many real-world applications, e.g., robotic manipulation and augmented reality. Most existing methods focus on estimating the object instances or categories which have been seen in the training phase. However, it is imperative to estimate the pose of unseen objects without re-training the network in real world. Therefore, we proposed a 3D pose estimation method for unseen objects without re-training. Specifically, given the CAD model of the unseen object, a set of template RGB-D images (RGB images and depth images) is rendered at different viewpoints. Then a feature embedding network, named PoseFusion, is designed to extract the scene feature. In this network, RGB-D images are utilized to extract the texture feature and geometric feature, respectively. Afterwards, a cross-modality alignment module is proposed to eliminate the noise in single modality. The aligned texture feature and aligned geometric feature are fused through a geometry guided fusion module. Thus, by PoseFusion, the template RGB-D images generated from the CAD model are abstracted into a set of template scene features, and the query scene features are also embedded from the captured RGB-D images from the unseen object. Finally, the query scene features are matched with the template scene features by calculating the masked local similarity. Then the identity and pose of unseen object are determined by the most similar template. Experiments on LINEMOD and T-LESS datasets demonstrate that our method outperforms other methods and generalizes better to unseen objects. Extensive ablation studies are performed to verify the effectiveness of the PoseFusion.},
  archive      = {J_NEUCOM},
  author       = {Guifang Duan and Shuai Cheng and Zhenyu Liu and Yanglun Zheng and Yunhai Su and Jianrong Tan},
  doi          = {10.1016/j.neucom.2024.128041},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128041},
  shortjournal = {Neurocomputing},
  title        = {Zero‐Shot 3D pose estimation of unseen object by two‐step RGB-D fusion},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable and parameter-free fusion graph learning for
multi-view clustering. <em>NEUCOM</em>, <em>597</em>, 128037. (<a
href="https://doi.org/10.1016/j.neucom.2024.128037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering aims to capture the consistency and complementary information present in view-specific data to achieve clustering alignment. However, existing multi-view clustering methods often rely on different regularization terms to quantify the importance of various views, which inevitably introduces additional hyperparameters. It is challenging to fine-tune these additional parameters in real-world applications. Additionally, these methods suffer from high time complexity and impose substantial constraints when applied in large-scale scenarios. To address these limitations, we propose a parameter-free and time-efficient graph fusion method for multi-view clustering that can integrate view-specific graphs and directly generate clustering labels. Specifically, we introduce an anchor strategy and generate bipartite graphs on different views to enhance efficiency. Subsequently, we employ a self-weighted graph fusion strategy to merge the view-specific bipartite graphs. Finally, we propose a new solver to handle these problems, enabling the structured bipartite graphs to directly indicate clustering results. In contrast to previous clustering methods, our approach does not introduce any additional parameters and entirely relies on self-weighting for the fusion of view-specific graphs. As a result, our proposed method exhibits linear computational complexity to the data scale. Extensive experimental results on various benchmark datasets demonstrate the effectiveness and efficiency of our approach. Our code is available at https://github.com/DuannYu/MvSST .},
  archive      = {J_NEUCOM},
  author       = {Yu Duan and Danyang Wu and Rong Wang and Xuelong Li and Feiping Nie},
  doi          = {10.1016/j.neucom.2024.128037},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128037},
  shortjournal = {Neurocomputing},
  title        = {Scalable and parameter-free fusion graph learning for multi-view clustering},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient construction and convergence analysis of sparse
convolutional neural networks. <em>NEUCOM</em>, <em>597</em>, 128032.
(<a href="https://doi.org/10.1016/j.neucom.2024.128032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new variant of convolutional neural network (CNN) based on L 1 L1 regularization is proposed. The main consideration is to generate a sparse weight matrix, i.e., to generate a sparse neural network model. To some extent, L 1 L1 regularization prevents the occurrence of overfitting and effectively improves the learning efficiency of the network. Unfortunately, the L 1 L1 regularization term is non-smooth, which leads to the occurrence of oscillations in experiments and poses a great challenge to the theoretical analysis. So, we overcome this drawback by using polishing techniques and rigorously prove the monotonicity of the error function and the strong and weak convergence theorems of the algorithm. Finally, numerical simulations on several data sets support our theoretical results and the superiority of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Shuai Zhao and Qinwei Fan and Qingmei Dong and Zhiwei Xing and Xiaofei Yang and Xingshi He},
  doi          = {10.1016/j.neucom.2024.128032},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128032},
  shortjournal = {Neurocomputing},
  title        = {Efficient construction and convergence analysis of sparse convolutional neural networks},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time-varying neurodynamic optimization approaches with
fixed-time convergence for sparse signal reconstruction.
<em>NEUCOM</em>, <em>597</em>, 128031. (<a
href="https://doi.org/10.1016/j.neucom.2024.128031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convergence speed is one of the most considerable features for sparse signal reconstruction algorithms. This paper introduces several novel fast time-varying neurodynamic optimization approaches (TVNOAs) with fixed-time convergence for sparse signal reconstruction. It is demonstrated that these trajectories converge to solutions within a fixed-time from arbitrary initial conditions, exhibiting a faster convergence rate due to the selection of appropriate time-varying coefficients. The fixed-time convergence of the proposed TVNOAs is investigated using the Polyak–Lojasiewicz condition. Moreover, explicit upper bounds for the settling time of TVNOAs are provided. Additionally, the robustness under bounded noises is further examined. Numerical experiments on sparse signal reconstruction validate the superiority of the proposed neurodynamic approaches.},
  archive      = {J_NEUCOM},
  author       = {Xingxing Ju and Xinsong Yang and Linbo Qing and Jinde Cao and Dianwei Wang},
  doi          = {10.1016/j.neucom.2024.128031},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128031},
  shortjournal = {Neurocomputing},
  title        = {Time-varying neurodynamic optimization approaches with fixed-time convergence for sparse signal reconstruction},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed adaptive finite-time output feedback containment
control for nonstrict-feedback stochastic multi-agent systems via
command filters. <em>NEUCOM</em>, <em>597</em>, 128021. (<a
href="https://doi.org/10.1016/j.neucom.2024.128021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, distributed adaptive finite-time output feedback containment control based on command filters is proposed for nonstrict-feedback stochastic multi-agent systems (SMASs) with unmodeled dynamics, input quantization and prescribed performance. The unknown states are estimated using a high-gain observer, the unmodeled dynamics is handled by introducing a measurable dynamic signal, and the input signal is processed using an integrated quantizer that combines the advantages of uniform quantizer and hysteretic quantizer. The hyperbolic tangent function and time-varying function are applied to construct the performance function, and the constrained containment error is transformed into an unconstrained system through nonlinear mapping (NM). Unknown smooth functions are handled with the superb approximation capability of radial basis function neural networks (RBFNNs). Based on stochastic finite-time theory and dynamic surface control (DSC) method, nonlinear command filters are introduced to reduce the use of black-box functions and simplify the controller design. Finally, the theoretical analysis and two sets of experimental results demonstrate that all signals in the controlled system are semi-global finite-time stability in probability (SGFSP) and the designed controller works well.},
  archive      = {J_NEUCOM},
  author       = {Hailin Tang and Tianping Zhang and Meizhen Xia},
  doi          = {10.1016/j.neucom.2024.128021},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128021},
  shortjournal = {Neurocomputing},
  title        = {Distributed adaptive finite-time output feedback containment control for nonstrict-feedback stochastic multi-agent systems via command filters},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recent advances on federated learning: A systematic survey.
<em>NEUCOM</em>, <em>597</em>, 128019. (<a
href="https://doi.org/10.1016/j.neucom.2024.128019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning has emerged as an effective paradigm to achieve privacy-preserving collaborative learning among different parties. Compared to traditional centralized learning that requires collecting data from each party, in federated learning, only the locally trained models or computed gradients are exchanged, without exposing any data information. As a result, it is able to protect privacy to some extent. In recent years, federated learning has become more and more prevalent and there have been many surveys for summarizing related methods in this hot research topic. However, most of them focus on a specific perspective or lack the latest research progress. In this paper, we provide a systematic survey on federated learning, aiming to review the recent advanced federated methods and applications from different aspects. Specifically, this paper includes four major contributions. First, we present a new taxonomy of federated learning in terms of the pipeline and challenges in federated scenarios. Second, we summarize federated learning methods into several categories and briefly introduce the state-of-the-art methods under these categories. Third, we overview some prevalent federated learning frameworks and introduce their features. Finally, some potential deficiencies of current methods and several future directions are discussed.},
  archive      = {J_NEUCOM},
  author       = {Bingyan Liu and Nuoyan Lv and Yuanchun Guo and Yawen Li},
  doi          = {10.1016/j.neucom.2024.128019},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128019},
  shortjournal = {Neurocomputing},
  title        = {Recent advances on federated learning: A systematic survey},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Continuous unsupervised domain adaptation using stabilized
representations and experience replay. <em>NEUCOM</em>, <em>597</em>,
128017. (<a href="https://doi.org/10.1016/j.neucom.2024.128017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce an algorithm for tackling the problem of unsupervised domain adaptation (UDA) in continual learning (CL) scenarios. The primary objective is to maintain model generalization under domain shift when new domains with solely unannotated data arrive continually. Under this setting, While there are many existing UDA algorithms, we have access to only the current target domain dataset simultaneously and need to update the model to learn a task with unannotated data without forgetting the tasks learnt before. Our contribution is to address this learning setting which faces challenges seen in both UDA and CL. The core assumption in the learning setting is that the tasks share the same classes which enables benefiting from knowledge transfer. Our solution is based on stabilizing the learned internal distribution after learning the initial task to enhances the model generalization on new domains. The internal distribution is modeled by network responses in the eventual model hidden layer. We model this internal distribution using a Gaussian mixture model (GMM ) and update the model by matching the internally learned distribution of new domains to the estimated GMM as a surrogate for the past learned internal distribution. Additionally, we leverage experience replay to overcome the problem of catastrophic forgetting, where the model loses previously acquired knowledge when learning new tasks. We offer theoretical analysis to explain why our algorithm would work. We also offer comparative and analytic experiments to demonstrate that our method is effective. Our implementation code is available at: https://github.com/rostami-m/LDACID .},
  archive      = {J_NEUCOM},
  author       = {Mohammad Rostami},
  doi          = {10.1016/j.neucom.2024.128017},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128017},
  shortjournal = {Neurocomputing},
  title        = {Continuous unsupervised domain adaptation using stabilized representations and experience replay},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aligned multi-view clustering for unmapped data via weighted
tensor nuclear norm and adaptive graph learning. <em>NEUCOM</em>,
<em>597</em>, 128016. (<a
href="https://doi.org/10.1016/j.neucom.2024.128016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering (MVC) is a prevailing clustering method that exploits consistency and complementarity among views to achieve satisfactory performance. The premise of MVC is that the samples of each view are mapped, that is, the same sample is placed in the same position among different views. However, multi-view data collected from the real world would also be unmapped, and thus conventional MVC methods are facing challenges. To address this problem, in our paper, we propose a novel aligned multi-view clustering (A-MVC) method for unmapped data. Specifically, the Calinski–Harabasz index is first employed to find the optimal view, and then the samples in other views are aligned to the samples in the optimal view with the help of the alignment matrix so that the unmapped data are converted into mapped ones. In addition, A-MVC absorbs the advantages of conventional multi-view clustering and employs both weighted tensor nuclear norm (TNN) and graph learning algorithms, which simultaneously learn the global representation and capture the local information. Finally, we integrate the alignment algorithm with a low-rank constraint based on weighted TNN and graph constraints into a unified framework. Extensive experimental results on certain unmapped multi-view datasets show that A-MVC outperforms other state-of-the-art methods. The codes and datasets are available at https://github.com/bingly/A-MVC .},
  archive      = {J_NEUCOM},
  author       = {Bing Cai and Gui-Fu Lu and Liang Yao and Jiashan Wan},
  doi          = {10.1016/j.neucom.2024.128016},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128016},
  shortjournal = {Neurocomputing},
  title        = {Aligned multi-view clustering for unmapped data via weighted tensor nuclear norm and adaptive graph learning},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fusing semantic information for syntax-guided paraphrase
generation. <em>NEUCOM</em>, <em>597</em>, 128009. (<a
href="https://doi.org/10.1016/j.neucom.2024.128009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Syntax-guided paraphrase generation (SGPG) refers to generating a paraphrase sentence that satisfies the given syntactic structure without changing the source sentences’ semantics. The commonly utilized syntactic structures are part-of-speech (POS) sequence, constituency parse tree, and masked template, with constituency parse tree achieving State-of-The-Art (SOTA) performance because of its rich syntactic information. As a result, further mining of syntactic information in parse trees has grown popular, yet fewer works pay attention to investigating semantic information in source sentences. A sentence is made up of two parts: syntax and semantics. Multiple studies have shown that improving the model’s ability to learn semantic information is critical for paraphrase construction as well as syntax learning. In this paper, we propose Fusing Semantic Information for Syntax-guided Paraphrase Generation (FS-SPG). Specifically, we propose a transformer-based semantic encoder to obtain detailed semantics from source sentences. This encoder contains a Semantics-Aware Attention mechanism for mining semantic information. In addition, we apply contrastive learning to improve the accuracy of parse tree nodes’ guidance to semantic sentences. Experiments on ParaNMT and QQP-Pos show that our model beats the SOTA model SI-SCP by 4.92% in syntactic metrics and 1.35% in semantic metrics.},
  archive      = {J_NEUCOM},
  author       = {Haoran Zhang and Li Li},
  doi          = {10.1016/j.neucom.2024.128009},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128009},
  shortjournal = {Neurocomputing},
  title        = {Fusing semantic information for syntax-guided paraphrase generation},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Information geometry of evolution of neural network
parameters while training. <em>NEUCOM</em>, <em>597</em>, 128007. (<a
href="https://doi.org/10.1016/j.neucom.2024.128007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANNs) are powerful tools capable of approximating any arbitrary mathematical function, but their interpretability remains limited, rendering them as black box models. To address this issue, numerous methods have been proposed to enhance the explainability and interpretability of ANNs. In this study, we introduce the application of information geometric framework to investigate phase transition-like behavior during the training of ANNs and relate these transitions to overfitting in certain models. The evolution of ANNs during training is studied by looking at the probability distribution of its parameters. Information geometry utilizing the principles of differential geometry, offers a unique perspective on probability and statistics by considering probability density functions as points on a Riemannian manifold. We create this manifold using a metric based on Fisher information to define a distance and a velocity. By parameterizing this distance and velocity with training steps, we study how the ANN evolves as training progresses. Utilizing standard datasets like MNIST, FMNIST and CIFAR-10, we observe a transition in the motion on the manifold while training the ANN and this transition is identified with over-fitting in the ANN models considered. The information geometric transitions observed is shown to be mathematically similar to the phase transitions in physics. Preliminary results showing finite-size scaling behavior is also provided. This work contributes to the development of robust tools for improving the explainability and interpretability of ANNs, aiding in our understanding of the variability of the parameters these complex models exhibit during training.},
  archive      = {J_NEUCOM},
  author       = {Abhiram Anand Thiruthummal and Eun-jin Kim and Sergiy Shelyag},
  doi          = {10.1016/j.neucom.2024.128007},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {128007},
  shortjournal = {Neurocomputing},
  title        = {Information geometry of evolution of neural network parameters while training},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Information-enhanced deep graph clustering network.
<em>NEUCOM</em>, <em>597</em>, 127992. (<a
href="https://doi.org/10.1016/j.neucom.2024.127992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph clustering is a significant task in complex network research. Deep graph clustering aims to uncover the potential community structure in graph data using the powerful feature extraction capability of deep learning, garnering much attention in recent decades. However, existing graph clustering methods fall short in fully utilizing available information, particularly in effectively fusing structural and attribute information, as well as utilizing coarse-grained data. Consequently, learned node representations remain limited, leading to suboptimal clustering results. To address these challenges, we propose I nformation- E nhanced D eep G raph C lustering N etwork (IEDGCN) for unsupervised attribute graphs. IEDGCN introduces key components to enhance information utilization and improve clustering performance. Firstly, we design a new higher-order neighborhood-weighted attribute matrix, effectively integrating higher-order neighborhood information with attributes. Secondly, a graph generation model guides the learning of the structural feature space more effectively. Additionally, IEDGCN captures more coarse-grained information by utilizing community and higher-order neighborhood features to refine clustering results. Finally, the proposed method is uniformly guided through a jointly supervised strategy for representation learning and cluster assignment. Experimental results on different benchmark datasets demonstrate the effectiveness of IEDGCN compared to state-of-the-art methods, emphasizing the importance of information enhancement for graph clustering.},
  archive      = {J_NEUCOM},
  author       = {Hongtao Liu and Jiahao Wei and Yiming Wu and Cong Liang},
  doi          = {10.1016/j.neucom.2024.127992},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127992},
  shortjournal = {Neurocomputing},
  title        = {Information-enhanced deep graph clustering network},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting severity of diabetic retinopathy from fundus
images: A transformer network-based review. <em>NEUCOM</em>,
<em>597</em>, 127991. (<a
href="https://doi.org/10.1016/j.neucom.2024.127991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic Retinopathy (DR) is considered one of the significant concerns worldwide, primarily due to its impact on causing vision loss among most people with diabetes. The severity of DR is typically comprehended manually by ophthalmologists from fundus photography-based retina images. This paper deals with an automated understanding of the severity stages of DR. In the literature, researchers have focused on this automation using traditional machine learning-based algorithms and convolutional architectures. However, the past works hardly focused on essential parts of the retinal image to improve the model performance. In this study, we adopt and fine-tune transformer-based learning models to capture the crucial features of retinal images for a more nuanced understanding of DR severity. Additionally, we explore the effectiveness of image transformers to infer the degree of DR severity from fundus photographs. For experiments, we utilized the publicly available APTOS-2019 blindness detection dataset, where the performances of the transformer-based models were quite encouraging.},
  archive      = {J_NEUCOM},
  author       = {Tejas Karkera and Chandranath Adak and Soumi Chattopadhyay and Muhammad Saqib},
  doi          = {10.1016/j.neucom.2024.127991},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127991},
  shortjournal = {Neurocomputing},
  title        = {Detecting severity of diabetic retinopathy from fundus images: A transformer network-based review},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Beyond singular prototype: A prototype splitting strategy
for few-shot medical image segmentation. <em>NEUCOM</em>, <em>597</em>,
127990. (<a href="https://doi.org/10.1016/j.neucom.2024.127990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of medical image semantic segmentation, few-shot learning, characterized by its efficient data utilization and flexible generalization capabilities, has been garnering increasing attention. The mainstream methods currently employ prototype-based approaches, which extract semantic knowledge from the annotated support images to guide the segmentation of the query image via masked global average pooling. However, such masked global average pooling leads to severe information loss, which is more problematic for medical images with large numbers of highly heterogeneous background categories. In this work, we propose a prototype splitting module (PSM) to effectively address the issue of semantic information loss in few-shot medical image segmentation. Specifically, PSM iteratively splits the support image masks into set of sub-masks containing segmented regions and unsegmented regions in a self-guided manner. This maximally retains the information within the original semantic classes and better extracts the representations of those classes. Additionally, we devise a multi-level cross attention module (MCAM) that transfers the foreground information from the support images to the query images across different levels to facilitate final segmentation prediction. We validate our method on multiple modal and multi-semantic medical image datasets. Results demonstrate that our approach achieves superior performance over existing state-of-the-art methods. The code has been released on https://github.com/fdngh/PSMnet .},
  archive      = {J_NEUCOM},
  author       = {Pengrui Teng and Wenjian Liu and Xuesong Wang and Di Wu and Changan Yuan and Yuhu Cheng and De-Shuang Huang},
  doi          = {10.1016/j.neucom.2024.127990},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127990},
  shortjournal = {Neurocomputing},
  title        = {Beyond singular prototype: A prototype splitting strategy for few-shot medical image segmentation},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AHCL-TC: Adaptive hypergraph contrastive learning networks
for text classification. <em>NEUCOM</em>, <em>597</em>, 127989. (<a
href="https://doi.org/10.1016/j.neucom.2024.127989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification is an essential and classic problem in natural language processing. In recent years, Graph Convolutional Networks (GCNs) have been widely applied to text classification tasks. However, there are still three critical challenges in practical applications: (1) Limited explanatory ability for domain-specific terminology; (2) Imbalanced sample distribution leading to a decline in model performance; (3) Excessive calculation consumption. To address these issues, this paper proposes an Adaptive Hypergraph Contrastive Learning Network (AHCL-TC) for text classification, which combines graph contrastive learning and hypergraph neural networks to better capture the internal relationship structure of domain-specific terminology and achieve superior performance with imbalanced sample distribution. AHCL-TC designs a neural network structure based on hypergraphs, using the high-order relationships of hypergraphs to model complex structures in text data. This structure allows the model to better understand multiple relationships between terms, thereby improving classification performance. Graph contrastive learning is used as the training framework of the model. By learning the intrinsic characteristics and structure of graph data, and using data enhancement algorithms to expand the data set, the model’s robustness to data imbalance is improved. Additionally, the paper presents a hypergraph adaptive augmentation algorithm designed for hypergraph structures to address the data imbalance problem. The proposed model is evaluated on multiple benchmark datasets, and the experimental results demonstrate its effectiveness for text classification tasks, outperforming baseline models even with reduced training data percentage. Furthermore, a comprehensive comparison of computational efficiency was conducted. The outcomes reveal that the computational consumption of our model is notably lower than that of other models.},
  archive      = {J_NEUCOM},
  author       = {Zhen Zhang and Hao Ni and Xiyuan Jia and Fangfang Su and Mengqiu Liu and Wenhao Yun and Guohua Wu},
  doi          = {10.1016/j.neucom.2024.127989},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127989},
  shortjournal = {Neurocomputing},
  title        = {AHCL-TC: Adaptive hypergraph contrastive learning networks for text classification},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attention-based multi-kernelized and boundary-aware network
for image semantic segmentation. <em>NEUCOM</em>, <em>597</em>, 127988.
(<a href="https://doi.org/10.1016/j.neucom.2024.127988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have witnessed the prosperity of image semantic segmentation brought by deep learning technology, including the integration of diverse network structures, attention mechanisms, and even boundary perception. Essentially, the main challenge of semantic segmentation lies in how to incorporate and align more information like contexts and details in the feature representation enabling the network to better distinguish and recognize objects in an image for improved semantic understanding. To this end, we propose a novel end-to-end deep framework termed Attention-Based Multi-Kernelized and Boundary-Aware Network to enhance the semantic segmentation performance. Specifically, the proposed network enables thoroughly exploring and engaging the multi-kernelized contextual information with high-frequency boundary information by applying novel modules of Multi-Kernelized Spatial Attention and Boundary-Aware Hybrid Attention, aiming to enhance the segmentation result with more comprehensive feature representation capability. Extensive experiments further consolidate the superiority of the proposed network with improved segmentation results with the mIoU of 51.1% and 82.9% on ADE20K and Cityscapes datasets, as well as classification results with Top-1 accuracy of 84.0% on ImageNet-1K dataset against competitive baselines.},
  archive      = {J_NEUCOM},
  author       = {Xuanchen Zhou and Gengshen Wu and Xin Sun and Pengpeng Hu and Yi Liu},
  doi          = {10.1016/j.neucom.2024.127988},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127988},
  shortjournal = {Neurocomputing},
  title        = {Attention-based multi-kernelized and boundary-aware network for image semantic segmentation},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NIV-SSD: Neighbor IoU-voting single-stage object detector
from point cloud. <em>NEUCOM</em>, <em>597</em>, 127987. (<a
href="https://doi.org/10.1016/j.neucom.2024.127987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous single-stage detectors typically suffer the misalignment between localization accuracy and classification confidence. To solve the misalignment problem, we introduce a novel rectification method named neighbor IoU-voting ( NIV ) strategy. Typically, classification and regression are treated as separate branches, making it challenging to establish a connection between them. Consequently, the classification confidence cannot accurately reflect the regression quality. NIV strategy can serve as a bridge between classification and regression branches by calculating two types of statistical data from the regression output to correct the classification confidence. Furthermore, to alleviate the imbalance of detection accuracy for complete objects with dense points (easy objects) and incomplete objects with sparse points (difficult objects), we propose a new data augmentation scheme named object resampling . It undersamples easy objects and oversamples difficult objects by randomly transforming part of easy objects into difficult objects. Finally, combining the NIV strategy and object resampling augmentation, we design an efficient single-stage detector termed NIV-SSD . Extensive experiments on several datasets indicate the effectiveness of the NIV strategy and the competitive performance of the NIV-SSD detector. The code is available at https://github.com/Say2L/NIV-SSD .},
  archive      = {J_NEUCOM},
  author       = {Shuai Liu and Di Wang and Quan Wang and Kai Huang},
  doi          = {10.1016/j.neucom.2024.127987},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127987},
  shortjournal = {Neurocomputing},
  title        = {NIV-SSD: Neighbor IoU-voting single-stage object detector from point cloud},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differentially private consensus and distributed
optimization in multi-agent systems: A review. <em>NEUCOM</em>,
<em>597</em>, 127986. (<a
href="https://doi.org/10.1016/j.neucom.2024.127986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few decades, distributed multi-agent system (MAS) control has received growing attention due to its numerous advantages. Nonetheless, the substantial reliance on local information exchange in distributed MAS control has given rise to significant privacy concerns. Differential privacy (DP), a mathematically rigorous privacy notion, has gained popularity as a means of safeguarding privacy across multiple fields, including distributed MAS control. In this paper, we present an in-depth overview of the techniques for preserving DP in distributed MAS control, concentrating on consensus and distributed optimization. We begin by outlining the defining features and modeling of MASs from the control theory perspective. Then, we illustrate the motivation for adopting differentially private mechanisms to protect the privacy of distributed MAS control and present the fundamental principles of DP. Based on them, we investigate the cutting-edge techniques designed to preserve DP in consensus and distributed optimization. This review sheds light on the current landscape of DP applications in distributed MAS control and lays the groundwork for future progress in this essential field.},
  archive      = {J_NEUCOM},
  author       = {Yamin Wang and Hong Lin and James Lam and Ka-Wai Kwok},
  doi          = {10.1016/j.neucom.2024.127986},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127986},
  shortjournal = {Neurocomputing},
  title        = {Differentially private consensus and distributed optimization in multi-agent systems: A review},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RAR: Recombination and augmented replacement method for
insertion-based lexically constrained text generation. <em>NEUCOM</em>,
<em>597</em>, 127985. (<a
href="https://doi.org/10.1016/j.neucom.2024.127985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lexically constrained text generation aims to generate text by indicated keywords. Previous work has employed non-autoregressive insertion methods which iteratively insert tokens between keywords to generate complete sentences. However, the semantic constraints imposed by discrete tokens limit the flexibility of generated text, leading to a lack of diversity and regularity in the generated text. To address this issue, we introduce the RAR model which builds upon the iterative insertion-based generation method. This model uses recombination and augmented replacement method to change the structure and regularity of the text to enhance text quality, the RAR model offers flexibility by adjusting the positional relationships between tokens by recombination method. Meanwhile, we use two kinds of custom token-level classifiers to divide the Replacement method into two parts: hard replacement and soft replacement. The “Hard Replacement” involves substituting words to improve text structure, while the “Soft Replacement” focuses on modifying text regularity through word form adjustments. We adopt different replacement methods according to the different stages of text generation, bringing more flexibility to the generation process. Experimental results on multiple datasets demonstrate that RAR achieves significant improvements in text fluency and diversity. Our code is released on https://github.com/Kenfree0/RAR .},
  archive      = {J_NEUCOM},
  author       = {Fengrui Kang and Xianying Huang and Bingyu Li},
  doi          = {10.1016/j.neucom.2024.127985},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127985},
  shortjournal = {Neurocomputing},
  title        = {RAR: Recombination and augmented replacement method for insertion-based lexically constrained text generation},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A video object detector with spatio-temporal attention
module for micro UAV detection. <em>NEUCOM</em>, <em>597</em>, 127973.
(<a href="https://doi.org/10.1016/j.neucom.2024.127973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many deep neural network-based methods have recently been proposed for object detection due to the significant success of deep learning in computer vision. However, existing object detection methods typically extract the appearance features of objects from single image so that they usually suffer from poor performance in detecting micro Unmanned Aerial Vehicle (UAV), because micro UAV lacks of rich color, shape and texture information. To address this issue, we introduce the temporal information of objects from videos and develop a Spatio-Temporal Attention Module (STAM) to efficiently enhance feature map extraction for detecting micro UAV, and then integrate STAM into YOLOX to develop a video object detector for micro UAV. Meanwhile, we propose a lightweight Spatial Pyramid Pooling (SPP) module termed Group Simplified Spatial Pyramid Pooling-Fast with Cross Stage Partial (Group SimSPPFCSP) for the backbone’s final stage layer to efficiently and lightly extract more semantic information, and we propose a neck with rich propagation pathways (NRPP) to facilitate the effective propagation of spatial and temporal information across different levels. Furthermore, we propose two data augmentation operations including SeqMosaic and SeqMixUp, to augment video data for video object detection. Experimental results show that our model can achieve competitive precision (with 5.0 mAP and 8.1 mAP S m a l l Small improvement) while maintaining real-time inference speed (35.3 fps).},
  archive      = {J_NEUCOM},
  author       = {Haozhi Xu and Zhigang Ling and Xiaofang Yuan and Yaonan Wang},
  doi          = {10.1016/j.neucom.2024.127973},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127973},
  shortjournal = {Neurocomputing},
  title        = {A video object detector with spatio-temporal attention module for micro UAV detection},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). US-LIME: Increasing fidelity in LIME using uncertainty
sampling on tabular data. <em>NEUCOM</em>, <em>597</em>, 127969. (<a
href="https://doi.org/10.1016/j.neucom.2024.127969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LIME has gained significant attention as an explainable artificial intelligence algorithm that sheds light on how complex machine learning models make decisions within a specific locality. One of the challenges of LIME is its instability and infidelity in acquiring explanations in multiple runs. This study focuses on improving LIME&#39;s fidelity by presenting a new sampling strategy. The idea is to generate more focused data samples close to the decision boundary and simultaneously close to the original data point (the sample targeted to be explained). Then, these newly concentrated data are used to train a simple and interpretable linear model as an alternative to the original complex model. The approach leads to high-quality and local sample generation and thus improves the overall fidelity of the model while preserving the constancy of the explanations compared to competing methods. The superiority of the proposed method is shown through comprehensive experiments and comparing the results with LIME, LS-LIME, S-LIME, and BayLIME in terms of fidelity while maintaining stability. This method also performs better than BayLIME, SLIME, and LS-LIME algorithms in terms of execution time. In addition, tests related to the effect of kernel width and data increase on stability and fidelity criteria have been performed. Non-dependence on kernel width in fidelity is also one of the strengths of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Hamid Saadatfar and Zeinab Kiani-Zadegan and Benyamin Ghahremani-Nezhad},
  doi          = {10.1016/j.neucom.2024.127969},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127969},
  shortjournal = {Neurocomputing},
  title        = {US-LIME: Increasing fidelity in LIME using uncertainty sampling on tabular data},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Investigating latent representations and generalization in
deep neural networks for tabular data. <em>NEUCOM</em>, <em>597</em>,
127967. (<a href="https://doi.org/10.1016/j.neucom.2024.127967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent deep neural network architectures that are tailored to tabular data operate at the feature level and process multiple latent representations simultaneously, typically one per feature. We investigate the impact of varying the dimension and number of such latent representations on model performance and generalization. Our results identify distinct model behaviors during both training and testing phases. To ease analysis of these behaviors, we propose a novel tool for characterizing data complexity and use it to highlight intricate relationships between data complexity, model complexity and model performance. We hypothesize a phenomenon of implicit self-regularization which intensifies with model capacity and sample-to-dimension ratio. While this self-regularization can mitigate over-fitting, it may also lead to reduced performance on training data. Our findings expand the understanding of neural networks applied to tabular data and provide insights that can help practitioners and/or automated methods in designing neural networks architectures that better match the complexity of specific tabular data sets.},
  archive      = {J_NEUCOM},
  author       = {Edouard Couplet and Pierre Lambert and Michel Verleysen and John A. Lee and Cyril de Bodt},
  doi          = {10.1016/j.neucom.2024.127967},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127967},
  shortjournal = {Neurocomputing},
  title        = {Investigating latent representations and generalization in deep neural networks for tabular data},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Residual echo state networks: Residual recurrent neural
networks with stable dynamics and fast learning. <em>NEUCOM</em>,
<em>597</em>, 127966. (<a
href="https://doi.org/10.1016/j.neucom.2024.127966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Residual connections have been established as a staple for modern deep learning architectures. Most of their applications are cast towards feedforward computing. In this paper, we study the architectural bias of residual connections in the context of recurrent neural networks (RNNs), specifically in the temporal dimension. We frame our discussion from the perspective of Reservoir Computing and dynamical system theory, focusing on important aspects of neural computation like memory capacity, long-term information processing, stability, and nonlinear computation capability. Experiments corroborate the striking advantage brought by temporal residual connections for a plethora of different time series processing tasks, comprehending memory-based, forecasting, and classification problems.},
  archive      = {J_NEUCOM},
  author       = {Andrea Ceni and Claudio Gallicchio},
  doi          = {10.1016/j.neucom.2024.127966},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127966},
  shortjournal = {Neurocomputing},
  title        = {Residual echo state networks: Residual recurrent neural networks with stable dynamics and fast learning},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Designs of graph echo state networks for node
classification. <em>NEUCOM</em>, <em>597</em>, 127965. (<a
href="https://doi.org/10.1016/j.neucom.2024.127965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among the Graph Neural Network (GNN) models that address the task of node classification, Graph Echo State Networks (GESN) have proved particularly effective in addressing the challenge of heterophily, i.e. the presence of a significant fraction of inter-class edges in the learning task graph. The effectiveness of GESN is paired with its efficiency, owing to the reservoir computing paradigm. While previous literature has analyzed the design of reservoirs for sequence ESN and GESN for graph-level tasks, the problem of providing effective designs of reservoirs for node-level GESN is so far largely unexplored. In this paper we analyze the impact of different reservoir designs on node classification accuracy and on the quality of node embeddings computed by GESN, focusing both on dense and sparse reservoir layouts. As measures of embedding richness, we adopt both graph topology-dependent metrics previously employed in the analysis of embedding smoothing, and topology-independent metrics from the areas of information theory and numerical analysis. In particular, we propose the application of entropy measures for quantifying information in node embeddings.},
  archive      = {J_NEUCOM},
  author       = {Alessio Micheli and Domenico Tortorella},
  doi          = {10.1016/j.neucom.2024.127965},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127965},
  shortjournal = {Neurocomputing},
  title        = {Designs of graph echo state networks for node classification},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The unreasonable effectiveness of early discarding after one
epoch in neural network hyperparameter optimization. <em>NEUCOM</em>,
<em>597</em>, 127964. (<a
href="https://doi.org/10.1016/j.neucom.2024.127964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reach high performance with deep learning, hyperparameter optimization (HPO) is essential. This process is usually time-consuming due to costly evaluations of neural networks. Early discarding techniques limit the resources granted to unpromising candidates by observing the empirical learning curves and canceling neural network training as soon as the lack of competitiveness of a candidate becomes evident. Despite two decades of research, little is understood about the trade-off between the aggressiveness of discarding and the loss of predictive performance. Our paper studies this trade-off for several commonly used discarding techniques such as successive halving and learning curve extrapolation. Our surprising finding is that these commonly used techniques offer minimal to no added value compared to the simple strategy of discarding after a constant number of epochs of training. The chosen number of epochs mostly depends on the available compute budget. We call this approach i i -Epoch ( i i being the constant number of epochs with which neural networks are trained) and suggest to assess the quality of early discarding techniques by comparing how their Pareto-Front (in consumed training epochs and predictive performance) complement the Pareto-Front of i i -Epoch.},
  archive      = {J_NEUCOM},
  author       = {Romain Egele and Felix Mohr and Tom Viering and Prasanna Balaprakash},
  doi          = {10.1016/j.neucom.2024.127964},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127964},
  shortjournal = {Neurocomputing},
  title        = {The unreasonable effectiveness of early discarding after one epoch in neural network hyperparameter optimization},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-fidelity reinforcement learning with control variates.
<em>NEUCOM</em>, <em>597</em>, 127963. (<a
href="https://doi.org/10.1016/j.neucom.2024.127963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many computational science and engineering applications, the output of a system of interest corresponding to a given input can be queried at different levels of fidelity with different costs. Typically, low-fidelity data is cheap and abundant, while high-fidelity data is expensive and scarce. In this work we study the reinforcement learning (RL) problem in the presence of multiple environments with different levels of fidelity for a given control task. We focus on improving the RL agent’s performance with multifidelity data. Specifically, a multifidelity estimator that exploits the cross-correlations between the low- and high-fidelity returns is proposed to reduce the variance in the estimation of the state–action value function. The proposed estimator, which is based on the method of control variates, is used to design a multifidelity Monte Carlo RL (MFMCRL) algorithm that improves the learning of the agent in the high-fidelity environment. The impacts of variance reduction on policy evaluation and policy improvement are theoretically analyzed by using probability bounds. Our theoretical analysis and numerical experiments demonstrate that for a finite budget of high-fidelity data samples, our proposed MFMCRL agent attains superior performance compared with that of a standard RL agent that uses only the high-fidelity environment data for learning the optimal policy. 2},
  archive      = {J_NEUCOM},
  author       = {Sami Khairy and Prasanna Balaprakash},
  doi          = {10.1016/j.neucom.2024.127963},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127963},
  shortjournal = {Neurocomputing},
  title        = {Multi-fidelity reinforcement learning with control variates},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient learning in spiking neural networks.
<em>NEUCOM</em>, <em>597</em>, 127962. (<a
href="https://doi.org/10.1016/j.neucom.2024.127962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) are a large class of neural model distinct from ‘classical’ continuous-valued networks such as multilayer perceptrons (MLPs). With event-driven dynamics and a continuous-time model in contrast to the discrete-time model of their classical counterparts, they offer interesting advantages in representational capacity and energy consumption. Spiking networks may also be more biologically plausible, offering more insights into neuroscience. However, developing models of learning for SNNs has historically proven challenging: as discrete-time systems, their dynamics are much more complex and they cannot benefit from the strong theoretical developments in MLPs such as convergence proofs and optimal gradient descent. Nor do they gain automatically from algorithmic improvements that have produced efficient matrix inversion and batch training methods. Most of the existing research has focused on the most well-studied learning mechanism in SNNs, spike-timing-dependent plasticity (STDP), and although there has been progress, there are also notable pathologies that have often been solved with a variety of ad-hoc techniques. While efforts have been made to map SNNs to classical convolutional neural networks (CNNs), these have not yet shown any decisive efficiency advantage over conventional CNNs. More promising research directions lie in the realm of pure spiking learning models that exploit the inherent temporal dynamics (and often leverage recurrency). Metrics are needed; one possibility would be a measure of total energy cost per unit reduction in error. This tutorial overview looks at existing techniques for learning in SNNs and offers some thoughts for future directions.},
  archive      = {J_NEUCOM},
  author       = {Alexander Rast and Mario Antoine Aoun and Eleni G. Elia and Nigel Crook},
  doi          = {10.1016/j.neucom.2024.127962},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127962},
  shortjournal = {Neurocomputing},
  title        = {Efficient learning in spiking neural networks},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Drifting explanations in continual learning.
<em>NEUCOM</em>, <em>597</em>, 127960. (<a
href="https://doi.org/10.1016/j.neucom.2024.127960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual Learning (CL) trains models on streams of data, with the aim of learning new information without forgetting previous knowledge. However, many of these models lack interpretability, making it difficult to understand or explain how they make decisions. This lack of interpretability becomes even more challenging given the non-stationary nature of the data streams in CL. Furthermore, CL strategies aimed at mitigating forgetting directly impact the learned representations. We study the behavior of different explanation methods in CL and propose CLEX (ContinuaL EXplanations), an evaluation protocol to robustly assess the change of explanations in Class-Incremental scenarios, where forgetting is pronounced. We observed that models with similar predictive accuracy do not generate similar explanations. Replay-based strategies, well-known to be some of the most effective ones in class-incremental scenarios, are able to generate explanations that are aligned to the ones of a model trained offline. On the contrary, naive fine-tuning often results in degenerate explanations that drift from the ones of an offline model. Finally, we discovered that even replay strategies do not always operate at best when applied to fully-trained recurrent models. Instead, randomized recurrent models (leveraging on an untrained recurrent component) clearly reduce the drift of the explanations. This discrepancy between fully-trained and randomized recurrent models, previously known only in the context of their predictive continual performance, is more general, including also continual explanations.},
  archive      = {J_NEUCOM},
  author       = {Andrea Cossu and Francesco Spinnato and Riccardo Guidotti and Davide Bacciu},
  doi          = {10.1016/j.neucom.2024.127960},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127960},
  shortjournal = {Neurocomputing},
  title        = {Drifting explanations in continual learning},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). On integrated lateral and longitudinal control of
brain-controlled vehicles. <em>NEUCOM</em>, <em>597</em>, 127957. (<a
href="https://doi.org/10.1016/j.neucom.2024.127957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A brain-controlled vehicle (BCV) is a vehicle that uses the Brain–Computer interface (BCI) to analyze the driver’s electroencephalogram (EEG) to obtain human control commands, which can help disabled people extend movement range and improve their self-independence. At this stage, research on the control of BCVs usually focuses only on the lateral control or longitudinal control, and few studies have focused on the problem of integrated lateral and longitudinal control. Given this situation, this paper investigates the integrated control of brain-controlled vehicles (BCV) in both lateral and longitudinal directions, and proposes a control method that utilizes speed as the coupling point. Firstly, the vehicle’s speed is determined by the provided road information. To control the vehicle’s longitudinal speed, a hierarchical control method based on model predictive control (MPC) is implemented. This method introduces a threshold σ σ to speed up the calculation process and reduce resource consumption. Then, a global controller is developed to conduct the motion control. This controller utilizes three local ANFIS intelligent controllers, employing soft-switching combinations, to generate the steering wheel angle signal. The generated steering wheel angle signal is combined with the cornering command issued by the driver. This fusion process produces the final command, which is responsible for the vehicle’s motion control. Finally, a simulation model is developed to test the integrated control of the BCV in terms of both lateral and longitudinal movements. Multiple experiments are conducted under varying conditions, and the results prove that the proposed method is able to complete the integrated control of the BCV well, which fully illustrates its effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Na Dong and Xianzheng Li and Zhiqiang Wu},
  doi          = {10.1016/j.neucom.2024.127957},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127957},
  shortjournal = {Neurocomputing},
  title        = {On integrated lateral and longitudinal control of brain-controlled vehicles},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RRA-FFSCIL: Inter-intra classes representation and
relationship augmentation federated few-shot incremental learning.
<em>NEUCOM</em>, <em>597</em>, 127956. (<a
href="https://doi.org/10.1016/j.neucom.2024.127956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL), as a distributed machine learning paradigm, enables on-device model training and inference without data updates or privacy breaches, promoting edge intelligence in Industrial Internet of Things (IIoTs) applications. However, FL applying in IIoTs faces some challenges in practice: (1) the catastrophic forgetting of old data resulting from a streaming reception for arriving data; (2) the forgetting exacerbated by the non-i.i.d. data distribution across devices; (3) the overfitting caused by insufficient sample size of new data (i.e., few samples). To address the above problems, we propose an inter-intra classes representation and relationship augmentation federated few-shot incremental learning framework called RRA-FFSCIL, effectively mitigating catastrophic forgetting from local and global perspectives. Specifically, forgetting from streaming data is alleviated by designed modules in the client side of RRA-FFSCIL: a random few-shot (FS) episodic adaptation strategy, a class-projection relation strengthening loss function, and a class-aware distribution balancing loss function. Meanwhile, the mitigation of global forgetting from non-i.i.d. of distributions across devices thanks to selecting the best old models on the server to assist local class relation enhancement. We conduct extensive experiments on three datasets (cifar100, tinyImageNet, miniImageNet) to validate the effectiveness and superiority of RRA-FFSCIL in addressing the forgetting problem associated with streaming data.},
  archive      = {J_NEUCOM},
  author       = {Yalan Jiang and Yang Cheng and Dan Wang and Bin Song},
  doi          = {10.1016/j.neucom.2024.127956},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127956},
  shortjournal = {Neurocomputing},
  title        = {RRA-FFSCIL: Inter-intra classes representation and relationship augmentation federated few-shot incremental learning},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differential graph convolution network for point cloud
understanding. <em>NEUCOM</em>, <em>597</em>, 127940. (<a
href="https://doi.org/10.1016/j.neucom.2024.127940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smoothing of the graph convolution is not conducive to characterizing local differences of point cloud. To solve this problem, we propose a Differential Graph Convolutional Network (Differ-GCN) for point cloud analysis. First, we propose a new graph construction strategy that can make similar nodes in the local space belong to the same graph, which can better represent the local commonality. After that, the features of the graph are extracted by the similarity matrix. Some of the smoothing information of the graph is removed to optimize the over-smoothing nodes and combined with the local difference of the points to get the beneficial features for downstream tasks. Finally, each neighbor point is processed to generate a mask, and pooling is performed through the mask to reduce information loss. The experiment results show that Differ-GCN performs excellent in object classification and part segmentation. The processing speed of Differ-GCN for point cloud is much faster than the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yun Bai and Guanlin Li and Chaozhi Yang and Yachuan Li and Qian Xiao and Zongmin Li},
  doi          = {10.1016/j.neucom.2024.127940},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127940},
  shortjournal = {Neurocomputing},
  title        = {Differential graph convolution network for point cloud understanding},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient and robust varying-parameter projection neural
network for sparse signal reconstruction. <em>NEUCOM</em>, <em>597</em>,
127939. (<a href="https://doi.org/10.1016/j.neucom.2024.127939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse signal reconstruction plays an important role in many practical applications, and therefore, many scholars strive to study its various effective (approximate) solution approaches, including some projection neural network models with finite-time or fixed-time convergence due to their parallel nature and convenience for hardware implementation. However, we experimentally find that noise has a significant influence on the convergence performance of these models. To overcome this problem, in this paper, we propose a new efficient varying-parameter projection neural network model (VPPNN) using the sliding mode control technique and a novel time-varying parameter for sparse signal reconstruction. Theoretical analysis shows that this new model not only has shorter fixed convergence time under certain conditions but also has noise-tolerance when compared to the existing projection neural network models. Numerical simulation experiments (via sparse signal/image reconstruction) are performed to illustrate the superiority of the new proposed model over the existing ones in terms of the convergence rate and robustness.},
  archive      = {J_NEUCOM},
  author       = {Qing Hu and Bing Zheng},
  doi          = {10.1016/j.neucom.2024.127939},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127939},
  shortjournal = {Neurocomputing},
  title        = {An efficient and robust varying-parameter projection neural network for sparse signal reconstruction},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving few-shot named entity recognition via semantics
induced optimal transport. <em>NEUCOM</em>, <em>597</em>, 127938. (<a
href="https://doi.org/10.1016/j.neucom.2024.127938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition (NER) is to identify and categorize entities in unstructured text, which serves as a fundamental task for a variety of natural language processing (NLP) applications. In particular, emerging few-shot NER methods aim to learn model parameters well with few samples and have received considerable attention. The dominant few-shot NER methods usually employ pre-trained language models (PLMs) as their basic architecture and fine-tune model parameters with few NER samples. Since the sample size is small and there are a large number of parameters in PLMs, fine-tuning may result in the parameters of PLMs being highly biased. To address this issue, this study introduces the semantic distribution distance constraints to optimize the fine-tuning process of few-shot NER models and develops a framework named Semantic Constraints on few-shot Named Entity Recognition (SCNER). Specifically, the framework formulates the general knowledge transfer of PLMs as an optimal transport procedure with a semantic prior. And, a Semantics-induced Optimal Transport (SOT) regularizer is developed to utilize the importance and similarities of tokens within sentences. SOT builds the semantic distribution of the sentence and defines the transport costs between tokens to achieve the token-level optimal transport procedures. Finally, SOT is employed as a regularization term of few-shot NER to introduce the semantic distribution distance constraint for effectively transferring general knowledge from PLMs. The experiments on four public datasets demonstrate that the proposed method significantly improves the performance of NER models in both few-shot and fully supervised scenarios. SCNER is a common framework that can be applied to a variety of models without adding additional learning parameters, and can be used to enhance the generalization ability and adaptability of various few-shot NER models.},
  archive      = {J_NEUCOM},
  author       = {Diange Zhou and Shengwen Li and Qizhi Chen and Hong Yao},
  doi          = {10.1016/j.neucom.2024.127938},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127938},
  shortjournal = {Neurocomputing},
  title        = {Improving few-shot named entity recognition via semantics induced optimal transport},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RealSinger: Ultra-realistic singing voice generation via
stochastic differential equations. <em>NEUCOM</em>, <em>597</em>,
127933. (<a href="https://doi.org/10.1016/j.neucom.2024.127933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthesizing high-quality singing voice from music score is a challenging problem in music generation and has many practical applications. Samples generated by existing singing voice synthesis (SVS) systems can roughly reflect the lyrics, pitch and duration in a given score, but they fail to contain necessary details. In this paper, based on stochastic differential equations (SDE) we propose RealSinger to generate 22.05kHz ultra-realistic singing voice conditioned on a music score. Our RealSinger learns to find the stochastic process path from a source of white noise to the target singing voice manifold under the conditional music score, allowing to sing the music score while maintaining the local voice details of the target singer. During training, our model learns to accurately predict the direction of movement in the ambient Euclidean space onto the low-dimensional singing voice manifold. RealSinger’s framework is very flexible. It can either generate intermediate feature representations of the singing voice, such as mel-spectrogram, or directly generate the final waveform, as in the end-to-end style which rectify defects and accumulation errors introduced by two-stage connected singing synthesis systems. An extensive subjective and objective test on benchmark datasets shows significant gains in perceptual quality using RealSinger. The mean opinion scores (MOS) obtained with RealSinger are closer to those of the human singer’s original high-fidelity singing voice than to those obtained with any state-of-the-art method. Audio samples are available at https://realsinger.github.io/ .},
  archive      = {J_NEUCOM},
  author       = {Ziqiang Shi and Shoule Wu},
  doi          = {10.1016/j.neucom.2024.127933},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127933},
  shortjournal = {Neurocomputing},
  title        = {RealSinger: Ultra-realistic singing voice generation via stochastic differential equations},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Object detection and crowd analysis using deep learning
techniques: Comprehensive review and future directions. <em>NEUCOM</em>,
<em>597</em>, 127932. (<a
href="https://doi.org/10.1016/j.neucom.2024.127932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection using deep learning has attracted considerable interest from researchers because of its competency in performing state-of-the-art tasks, including detection, observation, and action recognition. Deep Learning (DL)-based object detection models extract features directly from data, which is more efficient and effective than traditional methods requiring handcrafted features. Further, DL also effectively tackles spatiotemporal challenges by leveraging techniques; hence, researchers can develop better object detection models and implement more efficient strategies for object recognition. Moreover, optimizing these models improves performance and recognizes objects within videos or images. This survey comprises of an overview of related review papers and DL-based Object Detection (OD) algorithms. Object detection algorithms are presented as two classifications, namely Two-stage and One-stage methods, with Convolutional Neural Network (CNN) as the backbone. OD’s applications are examined here, and crowd analysis has been extensively studied and researched for potential applications. Most of the papers in object detection rely on Convolutional Neural Networks (CNNs) (28%), whereas crowd analysis papers are distributed as follows: 24% in counting, 25% in categorizing, and 25% in analyzing individual behaviors, and 27% in others. In recent years, deep learning has significantly advanced object detection capabilities to provide effective solutions for various applications, including crowd analysis.},
  archive      = {J_NEUCOM},
  author       = {B. Ganga and Lata B.T. and Venugopal K.R.},
  doi          = {10.1016/j.neucom.2024.127932},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127932},
  shortjournal = {Neurocomputing},
  title        = {Object detection and crowd analysis using deep learning techniques: Comprehensive review and future directions},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal training of mean variance estimation neural
networks. <em>NEUCOM</em>, <em>597</em>, 127929. (<a
href="https://doi.org/10.1016/j.neucom.2024.127929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focusses on the optimal implementation of a Mean Variance Estimation network (MVE network) (Nix and Weigend, 1994). This type of network is often used as a building block for uncertainty estimation methods in a regression setting, for instance Concrete dropout (Gal et al., 2017) and Deep Ensembles (Lakshminarayanan et al., 2017). Specifically, an MVE network assumes that the data is produced from a normal distribution with a mean function and variance function. The MVE network outputs a mean and variance estimate and optimizes the network parameters by minimizing the negative loglikelihood. In our paper, we present two significant insights. Firstly, the convergence difficulties reported in recent work can be relatively easily prevented by following the simple yet often overlooked recommendation from the original authors that a warm-up period should be used. During this period, only the mean is optimized with a fixed variance. We demonstrate the effectiveness of this step through experimentation, highlighting that it should be standard practice. As a sidenote, we examine whether, after the warm-up, it is beneficial to fix the mean while optimizing the variance or to optimize both simultaneously. Here, we do not observe a substantial difference. Secondly, we introduce a novel improvement of the MVE network: separate regularization of the mean and the variance estimate. We demonstrate, both on toy examples, multiple benchmark UCI regression data sets, and on the UTKFace data set, that following the original recommendations and the novel separate regularization can lead to significant improvements.},
  archive      = {J_NEUCOM},
  author       = {Laurens Sluijterman and Eric Cator and Tom Heskes},
  doi          = {10.1016/j.neucom.2024.127929},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127929},
  shortjournal = {Neurocomputing},
  title        = {Optimal training of mean variance estimation neural networks},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Complex spiking neural network with synaptic time delay
evaluated by anti-damage capabilities under random attacks.
<em>NEUCOM</em>, <em>597</em>, 127928. (<a
href="https://doi.org/10.1016/j.neucom.2024.127928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {External attack can affect the normal functioning of electronic equipment including neuromorphic hardware, which leads to failure. Research on the brain-like model with robustness is beneficial to obtain its stable performance under external attack. Synaptic time delay (STD) is highly correlated with bio-brain function. However, the synaptic plasticity of brain-like models still lacks bio-rationality. Inspired by the bio-synaptic time delay, the purpose of this paper is to investigate a bio-rational brain-like model with bio-consistent STD evaluated by the anti-damage capabilities. In this paper, we propose a spiking neural network (SNN) with the topology of a complex network called the ComSNN, in which the topology has both the SWP and SFP conforming to biological functional brain networks, the nodes are Izhikevich neuron models, and the edges are synaptic plasticity models with random time delay conforming to the dynamic range of bio-synaptic time delay. Then, the anti-damage capabilities of the ComSNNs with different types of STDs under random attacks are evaluated based on the two anti-damage indicators. Further, taking a speech recognition task as the case study, the anti-damage capabilities of these ComSNNs are verified in application. Finally, the anti-damage mechanism of the ComSNN with STD is discussed. Our results indicate the following: (i) In terms of two anti-damage indicators, the ComSNN with random STD is superior to the ComSNN with fixed STD; in turn, the ComSNN with fixed STD is superior to the ComSNN without STD. (ii) Compared with the ComSNN without random attacks, the speech recognition accuracy of the ComSNN with random STD under random attacks still remains almost the same, which indicates the ComSNN has anti-damage capabilities in application; the recognition accuracies of ComSNNs with different types of STDs present the consistent order with the results based on the two anti-damage indicators. (iii) A correlation between the mean synaptic weight and the anti-damage capabilities implies that the intrinsic factor of the anti-damage capabilities is the synaptic plasticity; synaptic plasticity can change dynamic topological characteristics of SNNs, the analysis results of dynamic topological characteristics imply that the STD impacts the anti-damage capabilities of the network.},
  archive      = {J_NEUCOM},
  author       = {Lei Guo and Hongmei Yue and Youxi Wu and Guizhi Xu},
  doi          = {10.1016/j.neucom.2024.127928},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127928},
  shortjournal = {Neurocomputing},
  title        = {Complex spiking neural network with synaptic time delay evaluated by anti-damage capabilities under random attacks},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced attention guided teacher–student network for weakly
supervised object detection. <em>NEUCOM</em>, <em>597</em>, 127910. (<a
href="https://doi.org/10.1016/j.neucom.2024.127910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly Supervised Object Detection (WSOD) has attracted increasing attention due to the convenience and low-cost of acquiring image-level annotations. Most existing WSOD methods follow Multiple Instance Learning (MIL) paradigm to select bounding boxes from proposals based on their classification scores. However, MIL-based WSOD methods often focus on discriminative regions, leading to incomplete and missing instances. To address these issues, we introduce a novel WSOD framework named Enhanced Attention Guided Teacher–Student Network (EATSN). This framework aims to improve detection performance through the guidance of attention map and consistency learning. specifically, we initially train a teacher network using MIL process to generate pseudo ground-truth labels. Subsequently, the weak augmented and strong augmented images are fed into teacher and student models to produce the enhanced attention map. During the training iterations, pseudo labels are utilized to guide the student model, while the teacher model refines its parameters through the Exponential Moving Average(EMA) from the student. Finally we design a proposal selection method that leverages the enhanced attention map and bounding boxes scores to achieve better detection results. Experimental results on benchmark datasets demonstrate that our method achieves comparable performance.},
  archive      = {J_NEUCOM},
  author       = {Mingyang Li and Ying Gao and Wentian Cai and Weixian Yang and Zihao Huang and Xiping Hu and Victor C.M. Leung},
  doi          = {10.1016/j.neucom.2024.127910},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127910},
  shortjournal = {Neurocomputing},
  title        = {Enhanced attention guided Teacher–Student network for weakly supervised object detection},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Posit and floating-point based izhikevich neuron: A
comparison of arithmetic. <em>NEUCOM</em>, <em>597</em>, 127903. (<a
href="https://doi.org/10.1016/j.neucom.2024.127903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reduced precision number formats have become increasingly popular in various fields of computational science, as they offer the potential to enhance energy efficiency, reduce silicon area, and improve processing speed. However, this is often at the expense of introducing arithmetic errors that can impact the accuracy of a system. The optimal balance must be struck, judiciously choosing a number format using as few bits as possible, while minimising accuracy loss. In this study, we examine one such format, posit arithmetic as a replacement for floating-point when conducting spiking neuron simulations, specifically using the Izhikevich neuron model. This model is capable of simulating complex neural firing behaviours, 20 of which were originally identified by Izhikevich and are used in this study. We compare the accuracy, spike count, and spike timing of the two arithmetic systems at different bit-depths against a 64-bit floating-point gold-standard. Additionally, we test a rescaled set of Izhikevich equations to mitigate against arithmetic errors by taking advantage of posit arithmetic’s tapered accuracy. Our findings indicate that there is no difference in performance between 32-bit posit, 32-bit floating-point, and our 64-bit reference for all but one of the tested firing types. However, at 16-bit, both arithmetic systems diverge from the 64-bit reference, albeit in different ways. For example, 16-bit posit demonstrates an 18 × 18× improvement in accumulated spike timing error over a 1000ms simulation compared to 16-bit floating-point when simulating regular (tonic) spiking. This finding holds particular importance given the prevalence of this particular firing type in specific regions of the brain. Furthermore, when we rescale the neuron equations, this error is eliminated altogether. Although current Posit Arithmetic Units are no smaller than Floating Point Units of the same bit-width, our results demonstrate that 64-bit floating-point can be replaced with 16-bit posit which could enable significant area savings in future systems.},
  archive      = {J_NEUCOM},
  author       = {T. Fernandez-Hart and James C. Knight and T. Kalganova},
  doi          = {10.1016/j.neucom.2024.127903},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127903},
  shortjournal = {Neurocomputing},
  title        = {Posit and floating-point based izhikevich neuron: A comparison of arithmetic},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bandit-NAS: Bandit sampling and training method for neural
architecture search. <em>NEUCOM</em>, <em>597</em>, 127684. (<a
href="https://doi.org/10.1016/j.neucom.2024.127684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Neural Architecture Search algorithms achieve a low error rate in vision tasks, such as image classification, by training child networks with equal resources during the search. However, it is unnecessary to allocate equal resources or fully converge scores to assess which child architectures should be adopted, resulting in computational redundancy. In this study, we present Bandit-NAS, an approach that automatically computes data slicing and training time for each child network. Firstly, we formulate the search for the optimal training time for a given resource as an M-armed bandit problem. Secondly, we extend the original NAS methods by proposing an end-to-end bandit algorithm, combined with reinforcement learning-based NAS algorithms, to determine an update strategy. Bandit-NAS enables simultaneous training of M child networks within a specified resource constraint (one epoch training time), with the allocation of training data based on the current accuracy of the child networks, thereby minimizing their error rate. Experimental results on 3 different datasets, MNIST , CIFAR-10 and CIFAR-100 demonstrate the superiority of Bandit-NAS over baseline NAS algorithms, such as ENAS and DQNAS, achieving lower error rates and faster search time.},
  archive      = {J_NEUCOM},
  author       = {Yiqi Lin and Yuki Endo and Jinho Lee and Shunsuke Kamijo},
  doi          = {10.1016/j.neucom.2024.127684},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127684},
  shortjournal = {Neurocomputing},
  title        = {Bandit-NAS: Bandit sampling and training method for neural architecture search},
  volume       = {597},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DenseViT-XGB: A hybrid approach for dates varieties
identification. <em>NEUCOM</em>, <em>596</em>, 127976. (<a
href="https://doi.org/10.1016/j.neucom.2024.127976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digitization of variety identification is of great importance for the improvement of farming practices in date fruit production. In this study, we have developed a hybrid approach called DenseViT-XGB for date fruit variety identification. DenseViT-XGB combines the advantages of the DenseNet121 and Vision Transformer architectures and utilizes the XGBoost classifier. To test and validate our approach, two datasets of date fruit images, one from Saudi Arabia and one from Turkey, were used. The model used in the study proved to perform well on both datasets. The accuracy, F1-score, and AUC reached 99.93% , 99.73% , and 99.85% for the Saudi Arabian dataset and 99.65% , 99.40% , and 99.23% for the Turkish dataset, respectively. DenseViT-XGB enhances feature extraction and global relationships in date fruit images by leveraging the dense connections and attention mechanisms of Vision Transformer. The integration of the XGBoost classifier further contributes to the accuracy of the model. These results underline the potential of DenseViT-XGB as a reliable and efficient technique for accurately recognizing different varieties of date fruits, impacting precision agriculture.},
  archive      = {J_NEUCOM},
  author       = {Ines Neji and Najib Ben Aoun and Noureddine Boujnah and Ridha Ejbali},
  doi          = {10.1016/j.neucom.2024.127976},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127976},
  shortjournal = {Neurocomputing},
  title        = {DenseViT-XGB: A hybrid approach for dates varieties identification},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visual fire detection using deep learning: A survey.
<em>NEUCOM</em>, <em>596</em>, 127975. (<a
href="https://doi.org/10.1016/j.neucom.2024.127975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Fire Detection (VFD), through the rapid and accurate identification of smoke and flame in images and videos, is crucial for early fire warning and reducing fire hazards. In recent years, the introduction of deep learning has significantly advanced this field, especially in the automatic extraction of discriminative features necessary for VFD. This paper provides a comprehensive review of the latest technological advancements in fire detection using deep learning, offering a broad perspective. Initially, it details the publicly available benchmark datasets widely used in VFD research and the corresponding evaluation metrics, providing a basis for researchers to assess the performance of various algorithms. Subsequently, we propose a systematic categorization framework, dividing VFD tasks into three key directions: fire classification, fire localization, and fire segmentation. For these directions, we thoroughly review the innovative improvements in deep learning models tailored for image and video inputs and discusses how these advancements enhance the accuracy and efficiency of fire detection. Finally, we highlight the challenges in the field and explore future research directions, intending to inspire and guide both newcomers and seasoned researchers in this area.},
  archive      = {J_NEUCOM},
  author       = {Guangtao Cheng and Xue Chen and Chenyi Wang and Xiaobo Li and Baoyi Xian and Hao Yu},
  doi          = {10.1016/j.neucom.2024.127975},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127975},
  shortjournal = {Neurocomputing},
  title        = {Visual fire detection using deep learning: A survey},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Brain age estimation with a greedy dual-stream model for
limited datasets. <em>NEUCOM</em>, <em>596</em>, 127974. (<a
href="https://doi.org/10.1016/j.neucom.2024.127974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain age estimation involves predicting an individual’s biological age from their brain images. This process offers valuable insights into the aging process and the progression of neurodegenerative diseases. Conducting large-scale datasets for medical image analysis is a challenging and time-consuming task. Existing approaches mostly depend on large datasets, which are hard to obtain and expensive. These approaches also require sophisticated, resource-intensive models with a large number of parameters, necessitating a significant amount of processing power. As a result, there is a vital need to develop innovative methods that can achieve robust performance with limited datasets and efficient use of computational resources. This paper proposes a novel slice-based dual-stream method called GDSM (Greedy Dual-Stream Model) for brain age estimation. This method addresses the limitations of large dataset requirements and computational resource intensiveness. The proposed method incorporates local and global aspects of the brain, thereby refining the focus on specific target regions. The approach employs four backbones to predict ages based on local and global features, complemented by a final model for age correction. Our method demonstrates a Mean Absolute Error (MAE) of 3.25 years on the IBID’s test set, which contains only 289 subjects. To demonstrate the robustness of our approach for any small dataset, we analyzed the proposed method with the IXI dataset and achieved an MAE of 4.18 years on the IXI’s test set. By leveraging dual-stream and greedy strategies, this approach achieves efficiency and robust performance, making it comparable with other state-of-the-art methods. The code for the GDSM model is available at https://github.com/iman2693/GDSM .},
  archive      = {J_NEUCOM},
  author       = {Iman Kianian and Hedieh Sajedi},
  doi          = {10.1016/j.neucom.2024.127974},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127974},
  shortjournal = {Neurocomputing},
  title        = {Brain age estimation with a greedy dual-stream model for limited datasets},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MMAIndoor: Patched MLP and multi-dimensional cross attention
based self-supervised indoor depth estimation. <em>NEUCOM</em>,
<em>596</em>, 127972. (<a
href="https://doi.org/10.1016/j.neucom.2024.127972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth estimation can provide auxiliary information for scene perception. Generally, extensive textureless surfaces, such as walls and ceilings, exist in indoor environments, and they share similar scene and semantic content. Overly consistent features of local textureless areas fail to reflect changes in depth information, thus degrading the performance of existing depth estimation methods. In response to this challenge, we propose a special indoor depth estimation method, named as MMAIndoor, which can provide global semantic guidance and shape priors for local textureless depth estimation. The depth estimation network is designed efficiently, encompassing the initial convolutional stage and the latent patched multi-layer perceptron (Pat-MLP) stage. The novel Pat-MLP block utilizes MLP partitioning to globally model depth-local information from the convolutional stage and it incorporate axial shift operations to extract local information from various spatial locations, suppressing the smoothing effect of MLP and improving precise estimation of sharp depth changes or small structures indoors. Further, we build a multi-dimensional cross attention (MCA) module to address the weak correlation of the current residual connections for the global context. This MCA captures global dependencies across multi-dimensions by sequentially executing cross attention on both channels and spatial, and effectively mitigate semantic gaps in residual connections. Sufficient experimental results demonstrate the state-of-the-art performance of MMAIndoor on benchmark datasets including NYUv2, ScanNet, and InteriorNet.},
  archive      = {J_NEUCOM},
  author       = {Chen Lv and Chenggong Han and Tianshu Song and He Jiang and Qiqi Kou and Jiansheng Qian and Deqiang Cheng},
  doi          = {10.1016/j.neucom.2024.127972},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127972},
  shortjournal = {Neurocomputing},
  title        = {MMAIndoor: Patched MLP and multi-dimensional cross attention based self-supervised indoor depth estimation},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Middle fusion and multi-stage, multi-form prompts for robust
RGB-t tracking. <em>NEUCOM</em>, <em>596</em>, 127959. (<a
href="https://doi.org/10.1016/j.neucom.2024.127959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-T tracking, a vital downstream task of object tracking, has made remarkable progress in recent years. Yet, it remains hindered by two major challenges: (1) the trade-off between performance and efficiency; (2) the scarcity of training data. To address the latter challenge, some recent methods employ prompts to fine-tune pre-trained RGB tracking models and leverage upstream knowledge in a parameter-efficient manner. However, these methods inadequately explore modality-independent patterns and disregard the dynamic reliability of different modalities in open scenarios. We propose M3PT, a novel RGB-T prompt tracking method that leverages middle fusion and multi-modal and multi-stage visual prompts to overcome these challenges. We pioneer the use of the adjustable middle fusion meta-framework for RGB-T tracking, which could help the tracker balance the performance with efficiency, to meet various demands of application. Furthermore, based on the meta-framework, we utilize multiple flexible prompt strategies to adapt the pre-trained model to comprehensive exploration of uni-modal patterns and improved modeling of fusion-modal features in diverse modality-priority scenarios, harnessing the potential of prompt learning in RGB-T tracking. Evaluating on 6 existing challenging benchmarks, our method surpasses previous state-of-the-art prompt fine-tuning methods while maintaining great competitiveness against excellent full-parameter fine-tuning methods, with only 0.34 M fine-tuned parameters. Our code are available at https://github.com/rainbowsea123/M3PT .},
  archive      = {J_NEUCOM},
  author       = {Qiming Wang and Yongqiang Bai and Hongxing Song},
  doi          = {10.1016/j.neucom.2024.127959},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127959},
  shortjournal = {Neurocomputing},
  title        = {Middle fusion and multi-stage, multi-form prompts for robust RGB-T tracking},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EPPE: An efficient progressive policy enhancement framework
of deep reinforcement learning in path planning. <em>NEUCOM</em>,
<em>596</em>, 127958. (<a
href="https://doi.org/10.1016/j.neucom.2024.127958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is a key process in robotics, playing an important role in fields such as autonomous driving and logistic delivery. Our work addresses the dual challenges of training efficiency and composite optimization in path planning using Deep Reinforcement Learning (DRL). We introduce the Efficient Progressive Policy Enhancement (EPPE) framework, which integrates the advantages of sparse rewards, aimed at achieving a globally optimal policy for the agent, with process rewards that provide real-time feedback for the agent’s policy adjustment. This framework not only significantly enhances policy learning efficiency but also effectively resolves the reward coupling issues introduced by process rewards, thereby ensuring the achievement of a globally optimal policy. Within this framework, the initial reward structure incorporates guiding rewards, which are a type of process reward based on conventional path planning algorithms, and assigns significant weights to provide real-time feedback, thereby effectively enhancing the training efficiency. Additionally, the Incremental Reward Adjustment (IRA) model is proposed to progressively increase the reward weights in the composite optimization part. The Fine-tuning Policy Optimization (FPO) model, supporting the IRA model, makes gradual adjustments to the learning rate throughout the entire process. Simulated experiments demonstrate the advantage of our framework in path composite optimization. In static obstacle environments, compared to seven benchmark algorithms, the time and distance to reach the target are improved by at least 10.4%. In mixed obstacle environments, these improvements are at least 19.1% and 18.2%. Additionally, our framework also significantly enhances the training efficiency of DRL.},
  archive      = {J_NEUCOM},
  author       = {Wang Zhao and Ye Zhang and Zikang Xie},
  doi          = {10.1016/j.neucom.2024.127958},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127958},
  shortjournal = {Neurocomputing},
  title        = {EPPE: An efficient progressive policy enhancement framework of deep reinforcement learning in path planning},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The use of reinforcement learning algorithms in object
tracking: A systematic literature review. <em>NEUCOM</em>, <em>596</em>,
127954. (<a href="https://doi.org/10.1016/j.neucom.2024.127954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object tracking is a computer vision task that aims to locate and continuously follow the movement of an object in video frames, given an initial annotation. Despite its importance, this task can prove to be challenging due to factors such as occlusion, deformations, and fast motion. Reinforcement Learning (RL) has been proposed as a viable solution for addressing these challenges by adapting to changes in object appearance and effectively handling occlusions, which can improve system performance. This study carries out a Systematic Literature Review on the use of Reinforcement Learning in object tracking between 2015 and 2023, by collecting and analyzing current trends, metrics, and benchmarks used in the field. Guidelines proposed by Kitchenham were used to conduct the research, resulting in 75 studies being accepted based on their score on the quality scale attributed by the authors of this review. The studies were categorized to present the current state of research based on metadata, trends for publication, RL approach, RL algorithm, Deep Learning use, object tracking type, and camera control. Additionally, an analysis was performed on the evaluation process for system performance, focusing on benchmarks and metrics for Single Object Tracking, Multiple Object Tracking, and Active Object Tracking. This study addresses a gap by conducting a comprehensive Systematic Literature Review focusing exclusively on Reinforcement Learning for Object Tracking. The review offers researchers an updated, detailed, and objective scientific overview of the field that can be incorporated into future studies.},
  archive      = {J_NEUCOM},
  author       = {David J. Barrientos R. and Marie Chantelle C. Medina and Bruno J. T. Fernandes and Pablo V. A. Barros},
  doi          = {10.1016/j.neucom.2024.127954},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127954},
  shortjournal = {Neurocomputing},
  title        = {The use of reinforcement learning algorithms in object tracking: A systematic literature review},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). When decoupled GCN meets group discrimination: A special
graph contrastive learning framework. <em>NEUCOM</em>, <em>596</em>,
127952. (<a href="https://doi.org/10.1016/j.neucom.2024.127952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While Graph Contrastive Learning (GCL) has demonstrated satisfactory outcomes, three main problems remain. First, to effectively transmit the message of higher-order hop nodes, it is imperative to stack multiple graph convolution layers, which results in heightened computational demands and memory requirements. Second, the traditional GCL framework employs the pairwise comparison of positive and negative samples, which could slow model training and necessitate considerable computing resources. Third, the GCL paradigm places considerable emphasis on the data augmentation. Some augmentation techniques focus on altering the graph’s structure, which demand significant computational resources. In order to resolve the aforementioned problems in GCL, we incorporate the decoupled GCN into GCL paradigm and develop a new GCL framework termed D ecoupled G roup D iscrimination (DGD), which relies on a one-layer Multi-Layer Perceptron (MLP) encoder and entirely abandons GCN. We also put forward a new negative sample generation strategy which is customized for DGD and enriches the graph structure information during training. Furthermore, we identify a more effective approach to aggregate information from individual nodes by a range of learnable parameters. Experiments on various datasets for the node classification reveal that DGD yields the superior accuracy, faster training time, and less memory consumption. Specifically, DGD improves the overall accuracy of the node classification by a margin of 1 to 2 percentages with the time required for the model training diminished by over 90% and the memory reduced exceeding 70%.},
  archive      = {J_NEUCOM},
  author       = {Yinjie Gao and Yaxin Sun and Shan Jin and Dawei Zhang and Jinli Cao and Zhonglong Zheng},
  doi          = {10.1016/j.neucom.2024.127952},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127952},
  shortjournal = {Neurocomputing},
  title        = {When decoupled GCN meets group discrimination: A special graph contrastive learning framework},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robustness of models addressing information disorder: A
comprehensive review and benchmarking study. <em>NEUCOM</em>,
<em>596</em>, 127951. (<a
href="https://doi.org/10.1016/j.neucom.2024.127951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning and deep learning models are increasingly susceptible to adversarial attacks, particularly in critical areas like cybersecurity and Information Disorder. This study provides a comprehensive evaluation of model Robustness against such attacks across key tasks well-assessed in Information Disorder literature: Toxic Speech Detection, Sentiment Analysis, Propaganda Detection, and Hate Speech Detection. Rigorous experiments conducted across 13 models and 12 diverse datasets highlight significant vulnerabilities. The methodological framework implements adversarial attacks that strategically manipulates model inputs based on keyword significance, identified using the LIME method, an advanced explainable AI technique. The evaluation measures Robustness primarily through accuracy of the models and attack success rates. The experiments reveal that current models display inconsistent resistance to adversarial manipulations, underscoring an urgent need for developing more sophisticated defensive strategies. The study sheds light on the critical weaknesses in existing models and charts a course for future research to fortify AI resilience against evolving cyber threats. The findings advocate for a paradigm shift in model training and development to prioritize adversarial Robustness, ensuring that AI systems are equipped to handle real-world adversarial scenarios effectively.},
  archive      = {J_NEUCOM},
  author       = {Giuseppe Fenza and Vincenzo Loia and Claudio Stanzione and Maria Di Gisi},
  doi          = {10.1016/j.neucom.2024.127951},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127951},
  shortjournal = {Neurocomputing},
  title        = {Robustness of models addressing information disorder: A comprehensive review and benchmarking study},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy balance and synchronization of the cross-ring
photosensitive neural network. <em>NEUCOM</em>, <em>596</em>, 127950.
(<a href="https://doi.org/10.1016/j.neucom.2024.127950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After detecting different external light stimuli, photosensitive neurons encode these stimuli and trigger different discharge patterns and membrane potentials, thereby transmitting signals in the neural network. The cross-ring structure can simulate complex dynamic behaviors in the neuron system, which helps to achieve synchronous behavior between neurons. This article, respectively, uses linear resistors and induction coils to connect four photosensitive neurons and constructs a cross-ring photosensitive neural network. We examine the energy balance and synchronization stability of the system by adjusting the coupling channels and external stimuli while also estimating the impact of noise. A system composed of identical neurons achieves energy balance and complete synchronization, whereas a system composed of diverse neurons is able to achieve phase synchronization by adjusting the coupling gain. However, under magnetic field coupling, a system composed of the same chaotic neurons can only achieve energy balance and complete synchronization with a larger coupling gain. For both types of coupled systems, noise may affect the synchronization of neuron systems in chaotic states, but it has no effect on the synchronization of spike-shaped neuron systems. Resistance coupling can synchronize more quickly than magnetic field coupling, but magnetic field coupling is more susceptible to variations in the coupling gain ratio. The study will give the domains of neuroscience and artificial intelligence a theoretical groundwork as well as a deeper knowledge of the workings and governing principles of neural networks.},
  archive      = {J_NEUCOM},
  author       = {Shu Zhou and Guodong Huang and Rui Zhu and Yunhai Wang and Yuan Chai},
  doi          = {10.1016/j.neucom.2024.127950},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127950},
  shortjournal = {Neurocomputing},
  title        = {Energy balance and synchronization of the cross-ring photosensitive neural network},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). Semi-supervised heterogeneous domain adaptation for
few-sample credit risk classification. <em>NEUCOM</em>, <em>596</em>,
127948. (<a href="https://doi.org/10.1016/j.neucom.2024.127948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit risk classification is a crucial area in machine learning-enhanced financial decision support systems, and numerous studies have achieved significant progress. However, data in the modern financial landscape is inherently complex, characterized by a lack of labeled data, cross-domain heterogeneity, and class imbalance. These three major problems hinder the achievement of credit risk classification. Therefore, we propose a semi-supervised heterogeneous domain adaptation method and an imbalanced data augmentation method to overcome these challenges with a single neural network-based model. Experimental results obtained from four representative benchmark datasets confirm the superior performance of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Zhaoqing Liu and Guangquan Zhang and Jie Lu},
  doi          = {10.1016/j.neucom.2024.127948},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127948},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised heterogeneous domain adaptation for few-sample credit risk classification},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). SPNet: Semantic preserving network with semantic constraint
and non-semantic calibration for color constancy. <em>NEUCOM</em>,
<em>596</em>, 127947. (<a
href="https://doi.org/10.1016/j.neucom.2024.127947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent methods introduce semantics obtained from pre-trained classification models into color constancy to guide the model in learning object-color mapping, thereby improving the illumination estimation ability. However, the task discrepancy between classification and color constancy leads to a representation learning gap, resulting in semantic loss during training. Moreover, semantic-based methods emphasize semantic regions, leading to the neglect of clues contained in non-semantic regions. Overall, semantic-based methods face the challenge of underutilizing critical information. To address this problem, we propose a Semantic Preserving Network (SPNet). We first design a Semantic Constraint Module (SCM) in SPNet. SCM provides semantic constraints to ensure uninterrupted semantic knowledge transfer during training, which prevents semantic loss. Additionally, we further propose an Auxiliary Calibration Module (ACM). ACM explores background regions with a restricted range of innate colors. The high consistency property of their color contributes to the calibration of illumination colors. Meanwhile, ACM recalibrates local–global consistency to avoid large estimation bias in other background regions where illumination clues are insufficient. Extensive experiments on the benchmark datasets show that our method achieves superior performance without extra inference consumption.},
  archive      = {J_NEUCOM},
  author       = {Wen Zhang and Zhijiang Li and Li Zhang and Zhenshan Tan},
  doi          = {10.1016/j.neucom.2024.127947},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127947},
  shortjournal = {Neurocomputing},
  title        = {SPNet: Semantic preserving network with semantic constraint and non-semantic calibration for color constancy},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SegCFT: Context-aware fourier transform for efficient
semantic segmentation. <em>NEUCOM</em>, <em>596</em>, 127946. (<a
href="https://doi.org/10.1016/j.neucom.2024.127946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation has been one of the most critical tasks in computer vision. Recent works mainly focus on improving segmentation performance by designing high-capacity transformer architectures. They try to solve the high data consumption and computing costs required for model training and deployment in the cloud, but the high computation overhead still makes it difficult to be directly applied to limited resource devices. In this paper, we propose a novel fast Fourier Transform (FFT) based Context-aware Feature Mixer under the transformer-like architecture for precise and efficient semantic segmentation, called SegCFT. Different from the self-attention-based transformer, SegCFT uses a Hierarchical Fourier Transform (HFT) to reduce computational cost via non-parametric calculation and promote segmentation performance by fusing the channel-wise and pixel-wise contexts. To integrate the features from the frequency domain of DFT into the spatial domain of the transformer-like architecture, an Adaptive Modulation Unit (AMU) is designed to modulate the frequency-domain features and ensure consistency between the frequency domain and the spatial domain. Experimental evaluation on two semantic segmentation benchmarks, ADE20k and Cityscapes, shows that SegCFT achieves competitive segmentation performance, while the training and inference costs are superior to the previous methods.},
  archive      = {J_NEUCOM},
  author       = {Yinqi Zhang and Lingfu Jiang and Fuhai Chen and Jiao Xie and Baochang Zhang and Gaoqi He and Shaohui Lin},
  doi          = {10.1016/j.neucom.2024.127946},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127946},
  shortjournal = {Neurocomputing},
  title        = {SegCFT: Context-aware fourier transform for efficient semantic segmentation},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse multi-view image clustering with complete similarity
information. <em>NEUCOM</em>, <em>596</em>, 127945. (<a
href="https://doi.org/10.1016/j.neucom.2024.127945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view image clustering aims to efficiently divide the collection of images by studying the characteristics of different views. Many studies performed Laplacian dimensionality reduction on the original image to avoid noise interference in constructing the similarity matrix. However, they ignored the problem that local similarity information and isolated image information are lost due to dimensionality reduction. These problems will result in the similarity matrix being insufficient to accurately describe the similarity between images, which in turn affects the clustering accuracy. Therefore, we propose a sparse multi-view spectral clustering model with complete similarity information between images (SMSC-CSI). The model combines the original image space and the low-dimensional spectral embedding space based on the adaptive neighbors method to learn the initial similarity matrices of each view jointly. On the one hand, the original space can retain all the similarity information between images so that the initial similarity matrix can accurately describe the similarity between images, which is conducive to accurate clustering. On the other hand, the low-dimensional space can avoid noise interference and retain the main structure of high-dimensional data, improving the robustness of the initial similarity matrix. Meanwhile, to ensure consistency among the views, the model minimizes the difference between the initial similarity matrix and the central fusion matrix by alternately updating to obtain the optimal weights and central fusion matrix for each view. Finally, we can obtain ideal clustering results directly with low model complexity and without post-processing steps such as K-means by adding non-negative Laplace rank constraints and ℓ 0 ℓ0 -norm constraints to the model objective function. Experimental results on different real image datasets show that SMSC-CSI can outperform some traditional clustering models and recent models on multi-view image clustering.},
  archive      = {J_NEUCOM},
  author       = {Shuaiyong Li and Xuyuntao Zhang and Chao Zhang and Shenghao Fu and Sai Zhang},
  doi          = {10.1016/j.neucom.2024.127945},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127945},
  shortjournal = {Neurocomputing},
  title        = {Sparse multi-view image clustering with complete similarity information},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-source transfer learning via optimal transport feature
ranking for EEG classification. <em>NEUCOM</em>, <em>596</em>, 127944.
(<a href="https://doi.org/10.1016/j.neucom.2024.127944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor imagery (MI) brain-computer interface (BCI) paradigms have been extensively used in neurological rehabilitation. However, due to the required long calibration time and non-stationary nature of electroencephalogram (EEG) signals, it is challenging to obtain a substantial sample size of EEG data. Transfer learning (TL), which leverages knowledge from existing subjects to enhance the learning performance in new subjects, has been employed to solve this problem. Previous studies often extract sample features directly from the two domains for transfer learning, leading to poor features and negative transfer. To overcome this limitation, an optimal transport feature selection method was developed in this study to select the most suitable features for migration to enhance the generalization capability of the TL. This was achieved by analyzing the diagonal value similarity of the optimal transport coupling matrix. First, the Riemannian tangent space mapping method was used to map the sample covariance matrix of EEG trials from the Riemannian manifold to tangent space. Secondly, the optimal subset of EEG features was selected via the optimal transport feature selection method. Subsequently, the separate distribution alignment method was employed to minimize dissimilarities between the source and target domains. Finally, the weighted voting mechanisms were integrated for decision fusion. The proposed multi-source transfer feature learning (MSTFL) method was validated based on two public BCI Competition IV datasets. Our results demonstrated superior classification accuracy of 85.93% and 79.48%, respectively, on the two public datasets, compared to state-of-the-art models. These findings indicate the effectiveness of our proposed MSTFL model for both feature extraction and classification of MI signals.},
  archive      = {J_NEUCOM},
  author       = {Junhao Li and Qingshan She and Feng Fang and Yun Chen and Yingchun Zhang},
  doi          = {10.1016/j.neucom.2024.127944},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127944},
  shortjournal = {Neurocomputing},
  title        = {Multi-source transfer learning via optimal transport feature ranking for EEG classification},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hyper-heuristic with deep q-network for the
multi-objective unmanned surface vehicles scheduling problem.
<em>NEUCOM</em>, <em>596</em>, 127943. (<a
href="https://doi.org/10.1016/j.neucom.2024.127943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a learning-based hyper-heuristic algorithm for the coverage path planning problem of multiple unmanned surface vehicles (USV). The makespan and coverage of the USVs are considered simultaneously. The proposed method does not need to specify the location of the mapping task points in advance; instead, the task allocation and path planning can be realized only based on the parameter information of the USV and the watershed. Considering the uncertainty in the actual mapping process, the triangular fuzzy numbers are used to represent the mapping time and mapping radius of USVs. In order to solve the multi-USV scheduling problem efficiently, this paper proposes an NSGA-II based on dueling double deep Q-network called NSGA-II-DQN. NSGA-II-DQN integrates ten effective global search operators and five local search operators, which can achieve a good balance between exploration and exploitation. Experiment results in various scenarios demonstrate that NSGA-II-DQN can efficiently search for travel paths covering the entire water area for multiple USVs in a short planning time.},
  archive      = {J_NEUCOM},
  author       = {Ningjun Xu and Zhangsong Shi and Shihong Yin and Zhengrong Xiang},
  doi          = {10.1016/j.neucom.2024.127943},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127943},
  shortjournal = {Neurocomputing},
  title        = {A hyper-heuristic with deep Q-network for the multi-objective unmanned surface vehicles scheduling problem},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time lightweight drone detection model: Fine-grained
identification of four types of drones based on an improved yolov7
model. <em>NEUCOM</em>, <em>596</em>, 127941. (<a
href="https://doi.org/10.1016/j.neucom.2024.127941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the rapid progress of artificial intelligence has enhanced the human-robot relationship through the development of several autonomous robots; such as drones. The overwhelming rise of drones has brought both relevant advantages and threatening risks into our daily lives. They are strongly deployed to achieve hard tasks and reach critical areas within a short period of time. In the past few years, drones&#39; anarchic and malicious use has generated many incidents and accidents, causing far-reaching impacts. Due to their dual-edged nature, they are regarded as potential threats. Recognizing the type of flying drones represents a challenging task for anti-drone systems to reinforce airspace safety and security. To this end, we propose a novel lightweight model able to differentiate between the main types of drones in real-time using appropriate modules. To find the optimal compromise between size, performance and speed, a lightweight model is proposed based on Yolov7 with the incorporation of CNeB and C3C2 modules as well as the Re- Parameterization Decoupled (RePD) head structure. Further, a CNeB module is used to reduce the model’s size and improve the model’s performance, a C3C2 module to enhance the feature extraction and fusion and a Re- Parameterization Decoupled RePD to improve both the efficacy and accuracy of the prediction part while reducing the inference time. The experimental results show that the Yolov7-CNeB-C3C2-RePD meets the anti-drone requirements by improving the detection performance, minimizing the inference speed and reducing the model size. In comparison to other models, the developed has provided high results reaching 91.9% precision, 90.5% recall, 95% mAP@0.5, and 20.3 ms during the inference stage, which outperforms the other algorithms in the benchmark. Furthermore, the model has an average detection speed of 0.003 ms per image and a capacity to process 27.88 frames per second, thus satisfying the real-time requirements.},
  archive      = {J_NEUCOM},
  author       = {Yasmine Ghazlane and El Hilali Alaoui Ahmed and Medromi Hicham},
  doi          = {10.1016/j.neucom.2024.127941},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127941},
  shortjournal = {Neurocomputing},
  title        = {Real-time lightweight drone detection model: Fine-grained identification of four types of drones based on an improved yolov7 model},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient verification of neural networks based on neuron
branching and LP abstraction. <em>NEUCOM</em>, <em>596</em>, 127936. (<a
href="https://doi.org/10.1016/j.neucom.2024.127936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development and wide application of neural networks in various domains including safety-critical systems, it is more and more important to investigate formal methods to provide strict guarantees on their behavior. As formal verification of a neural network has high computational complexity, caused by the nonlinear nature of activation functions such as ReLU, it is vital to improve the efficiency to solve verification problems. In this work, we propose a complete verification method for neural networks by means of neuron branching and linear programming (LP) abstraction. Specifically, the approach of branch and bound is adopted and a branching strategy is developed to divide a complex verification problem into sub-problems with smaller search space. And for each sub-problem, a part of ReLU neurons are abstracted with LP constraints and the others are accurately encoded with mixed integer linear programming (MILP) constraints, and an abstraction strategy is deployed to guide such mixed LP/MILP encoding so that the problem can be solved with reduced complexity. The method is implemented as a tool named BAVerify (Branching and Abstraction based Verification of neural networks), which is evaluated through experiments on benchmark network models and their verification problems. Experimental results show that BAVerify achieves a 43.13% advantage in verification efficiency compared with state-of-the-art complete methods for formal verification of neural networks.},
  archive      = {J_NEUCOM},
  author       = {Liang Zhao and Xinmin Duan and Chenglong Yang and Yuehao Liu and Yansong Dong and Xiaobing Wang and Wensheng Wang},
  doi          = {10.1016/j.neucom.2024.127936},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127936},
  shortjournal = {Neurocomputing},
  title        = {Efficient verification of neural networks based on neuron branching and LP abstraction},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Group consensus protocol with input delay for HMASs in
cooperative-competitive networks. <em>NEUCOM</em>, <em>596</em>, 127931.
(<a href="https://doi.org/10.1016/j.neucom.2024.127931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper primarily examines group consensus (GC) in heterogeneous multi-agent systems (HMASs) within the context of cooperative-competitive networks and input delay. The agent dynamics are modeled using single and double integrators, while the complex network encompassing these agents demonstrate both cooperative and competitive relationships. We first propose control protocols incorporating delays to address GC in HMASs. Secondly, we establish algebraic criteria employing frequency-domain analysis techniques to ensure the achievement of GC in directed network topologies for HMASs, which is equally applicable to undirected networks. Following this, we conduct an extensive discussion to determine the upper boundary for permissible input delays in HMASs. Finally, simulations are performed to validate our theoretical findings and the algorithms.},
  archive      = {J_NEUCOM},
  author       = {Denghao Pang and Hao Meng and Jinde Cao and Song Liu},
  doi          = {10.1016/j.neucom.2024.127931},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127931},
  shortjournal = {Neurocomputing},
  title        = {Group consensus protocol with input delay for HMASs in cooperative-competitive networks},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving robustness with image filtering. <em>NEUCOM</em>,
<em>596</em>, 127927. (<a
href="https://doi.org/10.1016/j.neucom.2024.127927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial robustness is one of the most challenging problems in Deep Learning and Computer Vision research. State-of-the-art techniques to enforce robustness are based on Adversarial Training, a computationally costly optimization procedure. For this reason, many alternative solutions have been proposed, but none proved effective under stronger or adaptive attacks. This paper presents Image-Graph Extractor (IGE), a new image filtering scheme that extracts the fundamental nodes of an image and their connections through a graph structure. By utilizing the IGE representation, we have developed a new defense technique, Filtering as a Defense, which prevents attackers from creating malicious patterns that can deceive image classifiers. Moreover, we show that data augmentation with filtered images effectively improves the model’s robustness to data corruptions. We validate our techniques on Convolutional Neural Networks on CIFAR-10, CIFAR-100, and ImageNet.},
  archive      = {J_NEUCOM},
  author       = {Matteo Terzi and Mattia Carletti and Gian Antonio Susto},
  doi          = {10.1016/j.neucom.2024.127927},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127927},
  shortjournal = {Neurocomputing},
  title        = {Improving robustness with image filtering},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CurveMEF: Multi-exposure fusion via curve embedding network.
<em>NEUCOM</em>, <em>596</em>, 127915. (<a
href="https://doi.org/10.1016/j.neucom.2024.127915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-exposure image fusion (MEF) aims to combine multiple images with different exposures into a single image to improve visual quality and preserve details. This paper proposes a curve embedding network for MEF (CurveMEF), which formulates the MEF task as estimating optimal fusion curves based on state feedback using pixel intensities as state variables. The fusion curve is embedded into CurveNet, a lightweight deep network, as a physical prior constraint. Leveraging the proposed physical informed MEF method, the fusion curve can adaptively adjust the pixel distribution of overexposed and underexposed regions based on the pixel intensities, and distinguish the importance of source images. CurveMEF supports both RGB and luminance channel inputs, demonstrating its flexibility. Experimental results show that CurveMEF achieves competitive performance compared to state-of-the-art methods in both qualitative and quantitative analysis. Moreover, CurveNet requires significantly fewer parameters and training data, enabling fast training and inference. The proposed method delivers high-speed and high-quality fusion while significantly reducing computational, providing an efficient and cost-effective solution. The code is publicly available at: https://github.com/PiratePai/CurveMEF .},
  archive      = {J_NEUCOM},
  author       = {Pai Peng and Zhongliang Jing and Han Pan and Yang Liu and Buer Song},
  doi          = {10.1016/j.neucom.2024.127915},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127915},
  shortjournal = {Neurocomputing},
  title        = {CurveMEF: Multi-exposure fusion via curve embedding network},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Breaking the water dilemma: Transmission-guided bilevel
adaptive learning for underwater imagery. <em>NEUCOM</em>, <em>596</em>,
127909. (<a href="https://doi.org/10.1016/j.neucom.2024.127909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneously enhancing the visual effects and resolution of underwater images poses a challenging task as it involves two types of image enhancement tasks, underwater image enhancement and image super-resolution. In spite of the emergence of various deep learning models, almost all existing methods are tailored to one specific enhancement task, rendering them unsuitable for super-resolution in underwater scenes, which consequently resulting in color distortion, unpleasant artifacts and missing high-frequency details. To address this challenge, we propose a multi-level degradation removal enhancer that utilizes underwater transmission prior to improve the quality of underwater images, dubbed as SimUESR . Specifically, the proposed SimUESR is designed to be guided by multiple sets of transmission-inspired guidance, which are cascaded with multi-stage degradation removal modules via a feature modulation operation. Through this, the underwater prior is used as modulation information to modulate contrast and color deviation, gradually embedded through the transmission-guided modules at the feature level. Then the enhanced features are incorporated into a multi-level degradation removal module to generate lossless image content. To release the burden of manually designing loss, we introduce a novel bilevel adaptive learning strategy that combines finite-difference approximation to automatically search for the desired loss, effectively improving visual perception performance. The experimental results demonstrate the remarkable superiority of the proposed method for underwater enhancement and super-resolution tasks, achieving improvements of 0.57 dB and 2.87 dB in PSNR on the UFO-120 and EUVP datasets, respectively. The code is available at https://github.com/lpm1001/SimUESR .},
  archive      = {J_NEUCOM},
  author       = {Sihan Xie and Peiming Li and Jiaxin Gao and Ziyu Yue and Xin Fan and Risheng Liu},
  doi          = {10.1016/j.neucom.2024.127909},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127909},
  shortjournal = {Neurocomputing},
  title        = {Breaking the water dilemma: Transmission-guided bilevel adaptive learning for underwater imagery},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An empirical study of excitation and aggregation design
adaptions in CLIP4Clip for video–text retrieval. <em>NEUCOM</em>,
<em>596</em>, 127905. (<a
href="https://doi.org/10.1016/j.neucom.2024.127905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CLIP4Clip model transferred from the CLIP has been the de-factor standard to solve the video clip retrieval task from frame-level input, triggering the surge of CLIP4Clip-based models in the video–text retrieval domain. In this work, we rethink the inherent limitation of widely-used mean pooling operation in the frame features aggregation and investigate the adaptions of excitation and aggregation design for discriminative video representation generation. We present a novel excitation-and-aggregation design, including (1) The excitation module is available for capturing non-mutually-exclusive relationships among frame features and achieving frame-wise features recalibration, and (2) The aggregation module is applied to learn exclusiveness used for frame representations aggregation. Similarly, we employ the cascade of sequential module and aggregation design to generate discriminative video representation in the sequential type. Besides, we adopt the excitation design in the tight type to obtain representative frame features for multi-modal interaction. The proposed modules are evaluated on three benchmark datasets of MSR-VTT, ActivityNet and DiDeMo, achieving MSR-VTT (43.9 R@1), ActivityNet (44.1 R@1) and DiDeMo (31.0 R@1). They outperform the CLIP4Clip results by +1.2% (+0.5%), +4.5% (+1.9%) and +9.5% (+2.7%) relative (absolute) improvements, demonstrating the superiority of our proposed excitation and aggregation designs. We hope our work will serve as an alternative for frame representations aggregation and facilitate future research.},
  archive      = {J_NEUCOM},
  author       = {Xiaolun Jing and Genke Yang and Jian Chu},
  doi          = {10.1016/j.neucom.2024.127905},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127905},
  shortjournal = {Neurocomputing},
  title        = {An empirical study of excitation and aggregation design adaptions in CLIP4Clip for video–text retrieval},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-agent reinforcement learning clustering algorithm
based on silhouette coefficient. <em>NEUCOM</em>, <em>596</em>, 127901.
(<a href="https://doi.org/10.1016/j.neucom.2024.127901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important branch of emerging artificial intelligence algorithms, multi-agent reinforcement learning (MARL) has shown strong performance in collaborative environments. It can utilize multiple agents to find the optimal set of strategies for solving sequential decision problem through trial-and-error. One of the main challenges facing multi-agent system is the non-stationarity problem, which brings poor convergence and seriously affects its performance. Clustering is a commonly used unsupervised analytical method in machine learning, which aims to group samples with similar internal properties into the same cluster. In this paper, we propose a MARL clustering algorithm based on silhouette coefficient (SC-MARLC), and use the trial-and-error strategy to find the best cluster groups. In SC-MARLC, we establish a mapping relationship between multi-agent and samples, construct a novel clustering model based on MARL, and design a good clustering subset structure based on the sample silhouette coefficient. The designed structure is helpful for multi-agent system to solve the non-stationary problem. Finally, we compare the performance of SC-MARLC with 11 existing clustering algorithms on fifteen public datasets. The results show that the new clustering algorithm performs best on ten datasets.},
  archive      = {J_NEUCOM},
  author       = {Peng Du and Fenglian Li and Jianli Shao},
  doi          = {10.1016/j.neucom.2024.127901},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127901},
  shortjournal = {Neurocomputing},
  title        = {Multi-agent reinforcement learning clustering algorithm based on silhouette coefficient},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust locally nonlinear embedding (RLNE) for dimensionality
reduction of high-dimensional data with noise. <em>NEUCOM</em>,
<em>596</em>, 127900. (<a
href="https://doi.org/10.1016/j.neucom.2024.127900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local Linear Embedding (LLE) is a nonlinear manifold learning method for dimensionality reduction in high-dimensional data. However, when the data is distorted by noise, efficiency of LLE significantly diminishes. This paper proposes a robust locally nonlinear embedding (RLNE) method to alleviate the impact of noise. This is achieved by constructing nonlinear functions between data neighbors in high-dimensional space, and then mapping the relationships to low manifolds. The constrained least squares method is used to obtain more uniform weights to ensure that the neighborhood is approximately located on the local nonlinear patches of the manifold. Theoretical analysis is conducted on the reasons underlying RLNE&#39;s robustness to noise. Experimental results on synthetic and real-world data highlight RLNE&#39;s ability to preserve the intrinsic structure of data, showcasing robustness across various types data with various levels of noise, as well as with a larger number of nearest neighbors.},
  archive      = {J_NEUCOM},
  author       = {Yichen Xu and Eric Li},
  doi          = {10.1016/j.neucom.2024.127900},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127900},
  shortjournal = {Neurocomputing},
  title        = {Robust locally nonlinear embedding (RLNE) for dimensionality reduction of high-dimensional data with noise},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning consensus representations in multi-latent spaces
for multi-view clustering. <em>NEUCOM</em>, <em>596</em>, 127899. (<a
href="https://doi.org/10.1016/j.neucom.2024.127899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering integrates features from different views to perform clustering. This problem has attracted increasing attention in recent years because multi-view data has become more common. The mainstream methods focus on learning a common representation or decoupling the view-specific and the shared representations in subspaces and then performing clustering on the fused results. However, it is still an open question how to best enforce that the learned representations possess good clustering properties and thus improve the clustering performance. In this paper, we propose a novel unsupervised model called Deep Multi-view Consensus Clustering (DMCC) to learn consensus view-specific representations in multiple latent spaces, where specificity and consistency are jointly retained for representation learning. For each view, DMCC learns view-specific representations in individual latent spaces with the help of a reconstruction target and a soft K-means objective. Furthermore, by aligning the cluster indicator matrices of each view, DMCC encourages consensus across views and enables one view to get help from other views to guide its representation learning. Thus, the learned representations are cluster-friendly within each view, and consistent across views. The proposed method achieves state-of-the-art performance in four metrics on extensive datasets. Among all datasets, our proposed method DMCC achieves an average of 2.6% and 2.5% better performance than state-of-the-art methods in RI and NMI, respectively. We also visualize the learned representations to show that our approach does learn cluster-friendly representations and to demonstrate the effectiveness of encouraging mutual consensus across views.},
  archive      = {J_NEUCOM},
  author       = {Qianli Ma and Jiawei Zheng and Sen Li and Zhenjing Zheng and Sen Li and Garrison W. Cottrell},
  doi          = {10.1016/j.neucom.2024.127899},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127899},
  shortjournal = {Neurocomputing},
  title        = {Learning consensus representations in multi-latent spaces for multi-view clustering},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MRMNet: Multi-scale residual multi-branch neural network for
object detection. <em>NEUCOM</em>, <em>596</em>, 127886. (<a
href="https://doi.org/10.1016/j.neucom.2024.127886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks in object detection methods are designed to handle the challenging task of multi-scale object detection in computer vision. However, small objects occupy small blocks of pixels, and feature information can easily be overwhelmed, which further leads to certain shortcomings and deficiencies in the network’s multi-scale representation abilities. To alleviate this problem, we propose a novel multi-scale residual multi-branch neural network (MRMNet) for object detection. Particularly, we first propose a multi-scale extension (MSE) module to structurally construct optimal solutions to enhance feature extraction and alleviate information loss, thus effectively improving multi-scale object detection performance. Furthermore, we propose a contextual feature refinement (CFR) module, which draws on the idea of residuals to introduce a multi-residual structure and the feature of partial convolution, which can effectively alleviate the problem of small objects being overwhelmed by conflicting semantic information while avoiding the degradation problem of deep feature networks in some sense. Finally, by combining our own MSE module and integrating it into the existing Modified CSP v6 backbone, we propose a new backbone network, the multi-scale residual (MSRes) network. Experimental results show that our MRMNet and MSRes backbone achieve a competitive detection performance of 43.1% AP on the MS-COCO 2017 dataset.},
  archive      = {J_NEUCOM},
  author       = {Yongsheng Dong and Yafeng Liu and Xuelong Li},
  doi          = {10.1016/j.neucom.2024.127886},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127886},
  shortjournal = {Neurocomputing},
  title        = {MRMNet: Multi-scale residual multi-branch neural network for object detection},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A single-image GAN model using self-attention mechanism and
DenseNets. <em>NEUCOM</em>, <em>596</em>, 127873. (<a
href="https://doi.org/10.1016/j.neucom.2024.127873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image generation from a single natural image using generative adversarial networks (GANs) has attracted extensive attention recently due to the GANs’ practical ability to produce photo-realistic images and their potential applications in computer vision. However, learning a powerful generative model that generates realistic, high-quality images from only a single natural image is still a challenging problem. Training GANs in limited data regimes often causes some issues, such as overfitting, memorization, training divergence, poor image quality, and a long training time. In this study, we investigated the state-of-the-art GAN models in computer vision tasks. We conducted several experiments to deeply understand the challenges of learning a powerful generative model. We introduced a novel unconditional GAN model that produces realistic, high-quality, diverse images based on a single training image. In our model, we employed a self-attention mechanism (SAM), a densely connected convolutional network (DenseNet) architecture, and a relativistic average least-squares GAN with gradient penalty (RaLSGAN-GP) for both the generator and discriminator networks to perform image generation tasks better. SAM controls the global contextual information level. It is complementary to convolutions for large feature maps and gives the generator and discriminator more capability to capture long-range dependencies in feature maps. It compensates for the long training time and low image quality issues. DenseNet connects each layer to every other layer in a feed-forward manner to ensure maximum information flow between layers in the network. It is highly parameter efficient and requires less computation to achieve high performance. It provides improved information and gradient flow throughout the network for easy training. It has a regularizing effect that reduces overfitting in image generation. RaLSGAN-GP further improves data generation quality and the stability of our model at no computational cost and provides much more stable training. Thanks to the appropriate combination of SAM, DenseNet, and RaLSGAN-GP, our model successfully generates realistic, high-quality, diverse images while maintaining the global context of the training image. We conducted experiments, user studies, and model evaluation methods to test our model’s performance and compared it with the previous well-known models on three datasets (Places, LSUN, ImageNet). We demonstrated our model’s capability in image synthesis and image manipulation tasks. In our experiments, we showed that our model utilized parameters more efficiently, prevented overfitting, better captured the internal patch statistics of images with complex structures and textures, achieved comparable performance in single image generation tasks, and had much better visual results than its competitive peers. User studies confirmed that the images generated by our model were commonly confused with the original images. Our model can provide a powerful tool for various image manipulation tasks as well as data augmentation in domains dealing with limited training data.},
  archive      = {J_NEUCOM},
  author       = {Eyyup Yildiz and Mehmet Erkan Yuksel and Selcuk Sevgen},
  doi          = {10.1016/j.neucom.2024.127873},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127873},
  shortjournal = {Neurocomputing},
  title        = {A single-image GAN model using self-attention mechanism and DenseNets},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). TSGAN: A two-stage interpretable learning method for image
cartoonization. <em>NEUCOM</em>, <em>596</em>, 127864. (<a
href="https://doi.org/10.1016/j.neucom.2024.127864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpreting style transfer methods and generating high-quality style images are two challenging computer vision tasks. However, most of the current image style transfer methods are inexplicable, and their image cartoonilation performance is also not satisfactory due to the complex lines and rich abstract features of cartoon style. To alleviate these two issues, in this paper we propose a novel two-stage interpretable learning method, the two-stage generative adversarial network (TSGAN), for image cartoonization. Particularly, we first divide the generative model into a content learning stage and a stylization stage. The advantages are twofold. The first is that the finely differentiated two-stage image generation model has better interpretability and easy understanding. The second is that TSGAN can adjust the content and style details of the generated image. We further propose a Cartoon Image Enhance (CIE) module for dynamically sampling salient cartoon texture details from training data to generate cartoon images with higher quality. Experimental results show that our TSGAN is effective when compared with four representative methods in terms of visual, qualitative, and quantitative comparisons and user research.},
  archive      = {J_NEUCOM},
  author       = {Yongsheng Dong and Luoyi Li and Lintao Zheng},
  doi          = {10.1016/j.neucom.2024.127864},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127864},
  shortjournal = {Neurocomputing},
  title        = {TSGAN: A two-stage interpretable learning method for image cartoonization},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain estimation and coupled controller design for
high-dimensional nonlinear multi-agent systems. <em>NEUCOM</em>,
<em>596</em>, 127859. (<a
href="https://doi.org/10.1016/j.neucom.2024.127859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the consensus problem of a class of high-dimensional nonlinear multi-agent systems. The agents are homogeneous and have coupled interactions with their nearby agents. Firstly, we study the consensus of this class of nonlinear multi-agent systems and present some consensus conditions based on the linearization technique. By transforming the consensus problem into a stability problem, we show that there exists a domain such that if all pairs of connected agents stay in the domain, the system will achieve consensus under the consensus conditions. Then, we propose a method to estimate the consensus domain since the accurate description of the domain is still challenging. Moreover, a method of coupled controller design is presented to make the multi-agent systems achieve consensus. At last, two numerical examples and a practical example are used to show the effectiveness of the results proposed in this paper.},
  archive      = {J_NEUCOM},
  author       = {Wang Zhenchun and Zhang Yuting and Li Shaobao},
  doi          = {10.1016/j.neucom.2024.127859},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127859},
  shortjournal = {Neurocomputing},
  title        = {Domain estimation and coupled controller design for high-dimensional nonlinear multi-agent systems},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven adaptive consensus control for heterogeneous
nonlinear multi-agent systems using online reinforcement learning.
<em>NEUCOM</em>, <em>596</em>, 127818. (<a
href="https://doi.org/10.1016/j.neucom.2024.127818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a distributed control algorithm based on a data-driven approach is developed to solve the consensus control of heterogeneous nonlinear Multi-Agent Systems (MAS). The consensus obtained from the solution of the Hamilton–Jacobi–Bellman (HJB) equation is challenging for unknown nonlinear systems. To address this issue, improved online reinforcement learning (RL) is employed to generate an approximate solution for each agent to achieve consensus. Unlike model-based RL and traditional algorithms, this method leverages I/O data to guide the learning of policies without any prior knowledge of agent dynamics. Furthermore, the adaptability of algorithm to heterogeneous nonlinear agents is enhanced by implementing online updates to the control strategy and dynamic linearization (DL). The convergence analysis of the algorithm is provided, along with the impact of the learning rate parameters on the consensus of MAS. By comparing with other data-driven methods, simulations are conducted to verify the stability and adaptability of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Xiaoqiang Ji and Xicheng Zhang and Shaoqing Zhu and Fuqin Deng and Bin Zhu},
  doi          = {10.1016/j.neucom.2024.127818},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127818},
  shortjournal = {Neurocomputing},
  title        = {Data-driven adaptive consensus control for heterogeneous nonlinear multi-agent systems using online reinforcement learning},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predicting the generalization gap in neural networks using
topological data analysis. <em>NEUCOM</em>, <em>596</em>, 127787. (<a
href="https://doi.org/10.1016/j.neucom.2024.127787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding how neural networks generalize on unseen data is crucial for designing more robust and reliable models. In this paper, we study the generalization gap of neural networks using methods from topological data analysis. For this purpose, we compute homological persistence diagrams of weighted graphs constructed from neuron activation correlations after a training phase, aiming to capture patterns that are linked to the generalization capacity of the network. We compare the usefulness of different numerical summaries from persistence diagrams and show that a combination of some of them can accurately predict and partially explain the generalization gap without the need of a test set. Evaluation on two computer vision recognition tasks (CIFAR10 and SVHN) shows competitive generalization gap prediction when compared against state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Rubén Ballester and Xavier Arnal Clemente and Carles Casacuberta and Meysam Madadi and Ciprian A. Corneanu and Sergio Escalera},
  doi          = {10.1016/j.neucom.2024.127787},
  journal      = {Neurocomputing},
  month        = {9},
  pages        = {127787},
  shortjournal = {Neurocomputing},
  title        = {Predicting the generalization gap in neural networks using topological data analysis},
  volume       = {596},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Residual spatial fusion network for RGB-thermal semantic
segmentation. <em>NEUCOM</em>, <em>595</em>, 127913. (<a
href="https://doi.org/10.1016/j.neucom.2024.127913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation plays an important role in widespread applications such as autonomous driving and robotic sensing. This work focuses on RGB-Thermal (RGB-T) semantic segmentation, since RGB images are easily affected by lighting conditions, e.g., darkness, and thermal images are robust to the night scenario as a compensating modality. However, existing works either simply fuse RGB-T images or adopt the encoder with the same backbone for the two modalities, neglecting the semantic difference under varying lighting conditions. Therefore, we present a Residual Spatial Fusion Network (RSFNet) for RGB-T semantic segmentation. Specifically, RSFNet employs an asymmetric encoder to learn the compensating features of RGB and thermal images. To fuse the dual-modality features, it generates pseudo-labels by adopting the saliency detection skill to supervise feature learning, and develops the Residual Spatial Fusion (RSF) module with structural re-parameterization to learn more promising features by spatially fusing the cross-modality features. RSF adopts a hierarchical feature fusion to aggregate multi-level features, and applies the spatial weights with the residual connection to adaptively control the multi-spectral feature fusion by the confidence gate. Extensive experiments were carried out on two benchmarks, i.e., MFNet database and PST900 database. The results have shown the state-of-the-art segmentation performance of our method, which strikes a good balance between accuracy and speed.},
  archive      = {J_NEUCOM},
  author       = {Ping Li and Junjie Chen and Binbin Lin and Xianghua Xu},
  doi          = {10.1016/j.neucom.2024.127913},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127913},
  shortjournal = {Neurocomputing},
  title        = {Residual spatial fusion network for RGB-thermal semantic segmentation},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uncertainty-aware representation calibration for
semi-supervised medical imaging segmentation. <em>NEUCOM</em>,
<em>595</em>, 127912. (<a
href="https://doi.org/10.1016/j.neucom.2024.127912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning methods aim to address the scarcity of pixel-level annotations in medical image segmentation. Previous approaches typically rely on filtering strategies to obtain pseudo-labels or implement consistency constraints for unlabeled images, which cannot robustly identify regions-of-interest (ROIs) with intricate semantic information. However, this often leads to uncertain predictions in semantically ambiguous areas and results in subpar segmentation outcomes. We observe that this issue stems from the dispersion of the representations of uncertain predictions among the boundaries of the semantically clustered representations of certain predictions. To this end, we propose a novel Uncertainty-Aware Representation Calibration (UA-RC) framework. This framework leverages an efficient uncertainty-aware criterion within a teacher–student SSL architecture to identify the representations of uncertain predictions. Then, UA-RC calibrates them via a semantic contrast paradigm by constructing positive prototypes and negative representations from certain predictions. Furthermore, UA-RC incorporates class-wise memory banks to store massive, diverse representations from training data, facilitating the calibration process and allowing for a better disentanglement of representations related to ROIs and backgrounds. Extensive experiments on four datasets, including Kvasir-SEG, ISIC-2018, BUL-2020, and ACDC, demonstrate the competitive edge of UA-RC over existing alternatives. Codes is available at https://github.com/Wu0409/UARC .},
  archive      = {J_NEUCOM},
  author       = {Yuanchen Wu and Xiaoqiang Li and Yue Zhou},
  doi          = {10.1016/j.neucom.2024.127912},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127912},
  shortjournal = {Neurocomputing},
  title        = {Uncertainty-aware representation calibration for semi-supervised medical imaging segmentation},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint-modal graph convolutional hashing for unsupervised
cross-modal retrieval. <em>NEUCOM</em>, <em>595</em>, 127911. (<a
href="https://doi.org/10.1016/j.neucom.2024.127911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal hashing retrieval has garnered significant attention for its exceptional retrieval efficiency and low storage consumption, especially in large-scale data retrieval. However, due to the difference in modality and semantic gap, the existing methods fail to fuse multi-modal information effectively or adjust weight adaptively, which further damages the discriminative ability of the generated hash code. In this paper, we propose an innovative approach called the Joint-Modal Graph Convolutional Hashing (JMGCH) method via adaptive weight assignment for unsupervised cross-modal retrieval. JMGCH consists of a Feature Encoding Module (FEM), a Joint-Modal Graph Convolutional Module (JMGCM), an Adaptive Weight Allocation Fusion Module (AWAFM), and a Hash Code Learning Module (HCLM). After the image and text have been encoded, we use the graph convolutional network to further explore the semantic structure. To consider both the intra-modal and inter-modal semantic relationships, JMGCM is proposed to capture the correlations of different modalities, and then fuse the features from uni-modality and cross-modality by designed AWAFM. Finally, in order to obtain the hash code with greater expressive capacity, the features of one modality are used to reconstruct the features of another one, so as to reduce the gap between different modalities. We conduct extensive experiments on three widely used cross-modal retrieval datasets, and the results demonstrate that our proposed framework achieves satisfactory retrieval performance.},
  archive      = {J_NEUCOM},
  author       = {Hui Meng and Huaxiang Zhang and Li Liu and Dongmei Liu and Xu Lu and Xinru Guo},
  doi          = {10.1016/j.neucom.2024.127911},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127911},
  shortjournal = {Neurocomputing},
  title        = {Joint-modal graph convolutional hashing for unsupervised cross-modal retrieval},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Partial ordered wasserstein distance for sequential data.
<em>NEUCOM</em>, <em>595</em>, 127908. (<a
href="https://doi.org/10.1016/j.neucom.2024.127908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring the distance between data sequences is a challenging problem, especially in the presence of outliers and local distortions. Existing measures typically align the two sequences before calculating their distance based on the difference between the corresponding elements. However, those alignments are not flexible enough to accommodate local distortions and severe effects of outliers. In this article, we propose a novel distance, termed as Partial Ordered Wasserstein (POW), which is flexible to align two sequences and robust w.r.t outliers. We further analyze some properties of the proposed distance, and show that POW enables a simple way to automatically and adaptively select the amount of transported mass, so as to accommodate outliers. Two different applications of POW are then studied: time-series classification and multi-step localization. Finally, we conduct extensive experiments on widely available public datasets to evaluate the performance of the proposed distances. Experimental results, obtained via a thorough experimental protocol, show the performance superiority of POW over several existing distance measures. Our Python source code is available on https://github.com/TungDP/Partial-Ordered-Wasserstein-Distance},
  archive      = {J_NEUCOM},
  author       = {Tung Doan and Tuan Phan and Phu Nguyen and Khoat Than and Muriel Visani and Atsuhiro Takasu},
  doi          = {10.1016/j.neucom.2024.127908},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127908},
  shortjournal = {Neurocomputing},
  title        = {Partial ordered wasserstein distance for sequential data},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated deep long-tailed learning: A survey.
<em>NEUCOM</em>, <em>595</em>, 127906. (<a
href="https://doi.org/10.1016/j.neucom.2024.127906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The federated learning privacy-preserving framework has achieved fruitful results in training deep models across clients. This survey aims to provide a systematic overview of federated deep long-tailed learning. We analyze the problems of federated deep long-tailed learning of class imbalance/missing, different long-tailed distributions, and biased training, and summarize the current approaches that fall into the following three categories: information enhancement, model component optimization, and algorithm-based calibration. Meanwhile, we also sort out the representative open-source datasets for different tasks. We conduct abundant experiments on CIFAR-10/100-LT using LeNet-5/ResNet-8/ResNet-34 and evaluate the model performance with multiple metrics. We also consider a text classification task and evaluate the performance of multiple methods using LSTM on the 20NewsGroups-LT. We discuss the challenges posed by data heterogeneity, model heterogeneity, fairness, and security, and identify future research directions for the follow-up studies.},
  archive      = {J_NEUCOM},
  author       = {Kan Li and Yang Li and Ji Zhang and Xin Liu and Zhichao Ma},
  doi          = {10.1016/j.neucom.2024.127906},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127906},
  shortjournal = {Neurocomputing},
  title        = {Federated deep long-tailed learning: A survey},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep reinforcement learning based distributed multi-UAV
dynamic area coverage algorithm for complex environment.
<em>NEUCOM</em>, <em>595</em>, 127904. (<a
href="https://doi.org/10.1016/j.neucom.2024.127904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic area coverage algorithm is often used in multiple unmanned aerial vehicle (multi-UAV) systems to realize searching or monitoring an area of interest (AOI). Improving coverage efficiency is one of the important research issues of dynamic area coverage. In this paper, we propose a distributed dynamic area coverage algorithm based on a reinforcement learning (RL) algorithm to enhance the coverage efficiency in complex application environments. A coverage information fusion based discrete soft actor–critic algorithm (herein FDSAC) is proposed to solve the non-stationary problem of RL algorithm in area coverage task under the communication constraint environment. Considering the equivalence of UAVs in the area coverage tasks, we introduce a multi-UAV cooperative learning method for FDSAC by sharing the strategy and experience of the UAVs to accelerate the learning speed of FDSAC in multi-UAV system. With the FDSAC algorithm, the UAVs can intelligently select the best coverage points and achieve almost optimal coverage point planning for the entire coverage process. In addition, we also provide a coverage point adjustment method based on the distribution of obstacles to enable the proposed algorithm adapt to obstacle environments. The experimental results demonstrate that the proposed algorithm can efficiently complete the area coverage task in complex communication and stochastic control noise environment. The good scalability, environment adaptability, and practicality of our algorithm have been also confirmed in different complex environments of different experimental platforms.},
  archive      = {J_NEUCOM},
  author       = {Jian Xiao and Guohui Yuan and Yuxi Xue and Jinhui He and Yaoting Wang and Yuanjiang Zou and Zhuoran Wang},
  doi          = {10.1016/j.neucom.2024.127904},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127904},
  shortjournal = {Neurocomputing},
  title        = {A deep reinforcement learning based distributed multi-UAV dynamic area coverage algorithm for complex environment},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incorporating structural constraints into continuous
optimization for causal discovery. <em>NEUCOM</em>, <em>595</em>,
127902. (<a href="https://doi.org/10.1016/j.neucom.2024.127902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directed Acyclic Graphs (DAGs) provide an efficient framework to describe the causal relations in actual applications, and it appears more and more important to learn a DAG from training data in causal discovery. Recently, a novel methodology, which projects the acyclic constraints by an algebraic characterization and employs continuous optimization to carry the causal discovery, gradually became the mainstream. However, such methods focus on a best-fitting to the training data and cannot utilize the prior knowledge in an efficient way. To resolve this problem, we suggest incorporating structural constraints into continuous optimization. For edge constraints, we regard the activation value of the difference between the constraint matrix after thresholding and the weight matrix as the optimization goal. For path constraints, we use the deviation concluded from the power matrix on k th path graphs to design the penalty functions. For ordering constraints, we exploit the representation based on the negative edge/path constraints. The mathematical derivations prove that equality constraint program (ECP), in which proposed equality constraints powerfully embody the required structural restrictions, are solvable. Furthermore, the experimental evaluations indicate that the proposed method develops higher scalability and accuracy against state-of-the-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Zidong Wang and Xiaoguang Gao and Xiaohan Liu and Xinxin Ru and Qingfu Zhang},
  doi          = {10.1016/j.neucom.2024.127902},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127902},
  shortjournal = {Neurocomputing},
  title        = {Incorporating structural constraints into continuous optimization for causal discovery},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive event-triggered optimal h∞ tracking control for
uncertain nonlinear systems: Comparative analysis applied to autonomic
tractor-trailer system. <em>NEUCOM</em>, <em>595</em>, 127898. (<a
href="https://doi.org/10.1016/j.neucom.2024.127898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an event-triggered tracking optimization control method is proposed for nonlinear uncertain systems with H ∞ discounted cost. First, the linearization method using the infinite series expansion theorem is given. And the tracking control design problem is solved by appropriate state augment. Secondly, the zero sum differential game strategy is introduced to address the control design problem of uncertain systems with event-triggered inputs. The actor-critic-disturbance networks framework is used to approximate the optimization of event- triggered controller strategy, optimization costs, and the disturbance strategy, respectively. Due to the consideration of discrete time and continuous time dynamics, we put the impulsive system method to use and choose appropriate Lyapunov functions to prove stability and boundedness, at the same time, there will be no infinite triggering situation. Finally, the effectiveness of the proposed scheme is demonstrated by an example of a practical tractor system with n trailers through simulation compared with another typical design method.},
  archive      = {J_NEUCOM},
  author       = {Yang Chen and Yan-Jun Liu and Lei Liu},
  doi          = {10.1016/j.neucom.2024.127898},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127898},
  shortjournal = {Neurocomputing},
  title        = {Adaptive event-triggered optimal h∞ tracking control for uncertain nonlinear systems: Comparative analysis applied to autonomic tractor-trailer system},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A biogeography-based optimization algorithm with local
search for large-scale heterogeneous distributed scheduling with
multiple process plans. <em>NEUCOM</em>, <em>595</em>, 127897. (<a
href="https://doi.org/10.1016/j.neucom.2024.127897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since modern production mode has shifted from a single factory to a multi-factory production network, distributed scheduling has been derived. Distributed scheduling problem (DSP) is characterized by many varieties, large scale, redundant production factories, flexible production processes, and high-value products. Each factory in the heterogeneous DSP can be considered an individual entity, and there may be several production process plans. To address the heterogeneous DSP with multiple process plans, we consider minimizing the global makespan over all factories containing the transportation time delivering tasks from factories to their destinations and propose a biogeography-based optimization algorithm combined with local search based on heuristic rules (BBO-LH) to find the optimal production plan and enhance productivity. First, a new encoding scheme with three-segment representation has been developed to avoid illegal solutions and realize the information sharing between solutions selecting different process plans. Then two efficient local search approaches have been proposed based on different heuristic rules on sequence and equipment allocation respectively, to improve the search efficiency. Besides, BBO-LH has adopted a cosine migration rate model to replace the linear one to strengthen the ability to jump out of local optima. BBO-LH is compared with a genetic algorithm (GA_X), using generated examples to test the performance of the proposed strategies, and simulation results show the effectiveness of the proposed BBO-LH on large-scale heterogeneous DSP with multiple process plans.},
  archive      = {J_NEUCOM},
  author       = {Yaya Zhang and Xingsheng Gu},
  doi          = {10.1016/j.neucom.2024.127897},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127897},
  shortjournal = {Neurocomputing},
  title        = {A biogeography-based optimization algorithm with local search for large-scale heterogeneous distributed scheduling with multiple process plans},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot biomedical relation extraction using data
augmentation and domain information. <em>NEUCOM</em>, <em>595</em>,
127881. (<a href="https://doi.org/10.1016/j.neucom.2024.127881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation extraction (RE) plays a pivotal role in biomedical information extraction. However, traditional approaches are often limited by high data annotation costs and extensive time investments. To address this challenge, this study proposes an innovative few-shot learning approach for biomedical RE tasks that utilizes data augmentation and domain information. Specifically, this method enhances the diversity of training data through a synthesized data augmentation strategy. At the same time, it combines domain information with prompt learning techniques. By incorporating domain information, the model’s generalization capability for rare data instances is improved. Furthermore, the prompt learning approach, by integrating prompt templates into the model input, guides the pre-trained language model to more accurately adapt to the RE task. Our model demonstrated exceptional performance in three different biomedical RE tasks, particularly on the I2B2-2010 RE dataset. In the 1-shot, 10-shot, and 50-shot settings, the F1 scores increased by 14.38%, 9.50%, and 6.05%, respectively.},
  archive      = {J_NEUCOM},
  author       = {Bocheng Guo and Di Zhao and Xin Dong and Jiana Meng and Hongfei Lin},
  doi          = {10.1016/j.neucom.2024.127881},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127881},
  shortjournal = {Neurocomputing},
  title        = {Few-shot biomedical relation extraction using data augmentation and domain information},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Successive model-agnostic meta-learning for few-shot fault
time series prognosis. <em>NEUCOM</em>, <em>595</em>, 127879. (<a
href="https://doi.org/10.1016/j.neucom.2024.127879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta learning is a promising technique for solving few-shot fault prediction problems, which have attracted the attention of many researchers in recent years. Existing meta-learning methods for time series prediction, which predominantly rely on random and similarity matching-based task partitioning, facing three major limitations: (1) feature exploitation inefficiency; (2) suboptimal task data allocation; and (3) limited robustness with small samples. To this end, we introduce a novel‘meta-task’ partitioning scheme, underpinned by a differential autoregressive algorithm, that treats a continuous time period of a time series as a meta-task, composed of multiple successive short time periods. This approach allows us to extract more comprehensive features and relationships from the data, resulting in more accurate predictions. Furthermore, our findings indicate that the differential autoregressive approach significantly bolsters robustness across diverse datasets. Extensive experiments on several fault and time series prediction datasets demonstrate that our approach substantially enhances prediction performance and generalization capability under both few-shot and general conditions.},
  archive      = {J_NEUCOM},
  author       = {Hai Su and Jiajun Hu and Songsen Yu and Juhua Liu and Xiangyang Qin},
  doi          = {10.1016/j.neucom.2024.127879},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127879},
  shortjournal = {Neurocomputing},
  title        = {Successive model-agnostic meta-learning for few-shot fault time series prognosis},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). StaTDS library: Statistical tests for data science.
<em>NEUCOM</em>, <em>595</em>, 127877. (<a
href="https://doi.org/10.1016/j.neucom.2024.127877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Data Science, there is a continual demand for statistical comparison to identify the most advantageous algorithms. Finding a software tool that facilitates the execution of multiple tests on different Data Science experiments without relying on additional libraries poses a challenge. This paper introduces StaTDS, an open-source library and web application implemented entirely in pure Python, designed to analyze, test, and compare Data Science algorithms. StaTDS implements all statistical tests without external dependencies. It ensures its durability and avoids future uncontrolled deprecated dependencies. With support for a wide variety of statistical tests (24 in total), StaTDS surpasses existing libraries dedicated to statistical testing. Moreover, the library incorporates tests to guide users in determining whether to employ parametric or non-parametric tests, such as the assessment of normality and homoscedasticity. This platform-independent library is available on GitHub under the GNU General Public License.},
  archive      = {J_NEUCOM},
  author       = {Christian Luna and Antonio R. Moya and José María Luna and Sebastián Ventura},
  doi          = {10.1016/j.neucom.2024.127877},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127877},
  shortjournal = {Neurocomputing},
  title        = {StaTDS library: Statistical tests for data science},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Low-rank representation induced missing-view recovery for
incomplete multi-view clustering. <em>NEUCOM</em>, <em>595</em>, 127870.
(<a href="https://doi.org/10.1016/j.neucom.2024.127870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications, multi-view data suffers from incompleteness, which refers to the absence of some samples in each view. Incomplete multi-view clustering is developed to capture the common cluster structure across incomplete views. However, some existing IMC methods ignore the missing samples or the latent relationship between the available and the unavailable samples. We propose a novel missing-view recovery strategy to overcome these two drawbacks. Considering that each missing sample and part of the observable samples belong to the same category, we recover each missing sample via the linear combination of observed samples within each view. Based on the semantic consistency, we extract a unified self-representation graph from complete views and impose a low-rank constraint on it. Furthermore, we learn a comprehensive representation from complete multi-view data and introduce the dynamic weights to consider the importance of various views. The experimental results on several datasets demonstrate that the proposed method outperforms the state-of-the-art IMC approaches.},
  archive      = {J_NEUCOM},
  author       = {Wei Liu and Xiaoyuan Jing and Xiaodong Jia and Xiaoke Zhu and Yaru Hao},
  doi          = {10.1016/j.neucom.2024.127870},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127870},
  shortjournal = {Neurocomputing},
  title        = {Low-rank representation induced missing-view recovery for incomplete multi-view clustering},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Backstepping based neural h∞ optimal tracking control for
nonlinear state constrained systems with input delay and disturbances.
<em>NEUCOM</em>, <em>595</em>, 127869. (<a
href="https://doi.org/10.1016/j.neucom.2024.127869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of H ∞ H∞ optimal tracking control for a class of nonlinear state constrained systems with input delay and disturbances. With the aid of Pade approximation, an auxiliary variable is devised to eliminate the effects of input delay. Combining barrier Lyapunov functions (BLFs) with backstepping design technique, a feedforward adaptive controller is designed to transform the tracking control problem of nonlinear state constrained system into an equivalent H ∞ H∞ control problem of input-affine error system without state constraints, wherein neural networks (NNs) are employed to approximate unknown system dynamics. Then based on single-network adaptive dynamic programming (ADP), an H ∞ H∞ optimal feedback controller is developed by utilizing a single critic network to learn the Nash equilibrium related to Hamilton–Jacobi–Isaacs (HJI) equation. Therefore, the whole tracking controller can be constructed by integrating the feedforward adaptive controller with the optimal feedback controller. Moreover, it is proven by Lyapunov’s theory that all signals within the closed-loop system are uniformly ultimately bounded (UUB), and the tracking error converges to a small neighborhood of the origin without violating any state constraints. Two simulation examples are also presented to validate the effectiveness of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Yuzhu Huang and Zhaoyan Zhang and Xiong Yang},
  doi          = {10.1016/j.neucom.2024.127869},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127869},
  shortjournal = {Neurocomputing},
  title        = {Backstepping based neural h∞ optimal tracking control for nonlinear state constrained systems with input delay and disturbances},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable bio-inspired training of deep neural networks with
FastHebb. <em>NEUCOM</em>, <em>595</em>, 127867. (<a
href="https://doi.org/10.1016/j.neucom.2024.127867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent work on sample efficient training of Deep Neural Networks (DNNs) proposed a semi-supervised methodology based on biologically inspired Hebbian learning, combined with traditional backprop-based training. Promising results were achieved on various computer vision benchmarks, in scenarios of scarce labeled data availability. However, current Hebbian learning solutions can hardly address large-scale scenarios due to their demanding computational cost. In order to tackle this limitation, in this contribution, we investigate a novel solution, named FastHebb (FH), based on the reformulation of Hebbian learning rules in terms of matrix multiplications, which can be executed more efficiently on GPU. Starting from Soft-Winner-Takes-All (SWTA) and Hebbian Principal Component Analysis (HPCA) learning rules, we formulate their improved FH versions: SWTA-FH and HPCA-FH. We experimentally show that the proposed approach accelerates training speed up to 70 times, allowing us to gracefully scale Hebbian learning experiments on large datasets and network architectures such as ImageNet and VGG.},
  archive      = {J_NEUCOM},
  author       = {Gabriele Lagani and Fabrizio Falchi and Claudio Gennaro and Hannes Fassold and Giuseppe Amato},
  doi          = {10.1016/j.neucom.2024.127867},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127867},
  shortjournal = {Neurocomputing},
  title        = {Scalable bio-inspired training of deep neural networks with FastHebb},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge graph reasoning via dynamic subgraph attention
with low resource computation. <em>NEUCOM</em>, <em>595</em>, 127866.
(<a href="https://doi.org/10.1016/j.neucom.2024.127866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) suffer from inherent incompleteness, which has spurred research into knowledge graph reasoning (KGR), i.e., ways to infer missing facts based on existing triples. The most prevalent approaches employ a static mechanism for entity representation across the entire graph, sharing entity embeddings for different query relations. Nevertheless, these static entity embeddings fail to capture specific semantics for various query scenarios, resulting in inaccurate entity representations and susceptibility to reasoning errors. Furthermore, the whole graph learning style requires substantial computational resources, especially since KGs are often of large-scale. Consequently, these methods are impractical in low-resource environments. To address these issues, we devise a framework called dynamic subgraph attention (DSA), which learns dynamic entity embeddings for different query relations across subgraphs. In our approach, by utilizing multi-hop path history information obtained through path-based learning, we guide a dynamic attention mechanism to generate dynamic entity embeddings for different query relations. To ensure the semantic information of entities, the embedding-based and path-based learning are jointly trained for KGR. Additionally, the proposed dynamic aggregation mechanism operates on subgraphs, resulting in a remarkable 6–7 times resource conservation compared to GPU computations. Empirical experiments further demonstrate that DSA outperforms the current methods significantly on three benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Yin Wang and Nan Xia and Hang Yu and Xiangfeng Luo},
  doi          = {10.1016/j.neucom.2024.127866},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127866},
  shortjournal = {Neurocomputing},
  title        = {Knowledge graph reasoning via dynamic subgraph attention with low resource computation},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). Improving the transferability of adversarial examples
through black-box feature attacks. <em>NEUCOM</em>, <em>595</em>,
127863. (<a href="https://doi.org/10.1016/j.neucom.2024.127863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are vulnerable and susceptible to imperceptible perturbations. Adversarial examples become more and more popular. Black-box attacks are considered to be the most realistic scenario. Currently, transfer-based black-box attacks show excellent performance. However, transfer-based black-box attacks all require an agent model of the attack, which we call the source model. This leads to the existing transfer-based attacks limited by the features focused on the source model, which creates a bottleneck in improving the transferability of adversarial examples. In order to solve this problem, we propose an attack that mainly targets features that are insensitive to the source model, which we call the black-box feature attack. Specifically, we categorize the features of the image into white-box features and black-box features. The white-box features are source model-sensitive features and the black-box features are source model insensitive features. White-box features are only specific to the source model, while black-box features are more generalized for unknown models. By destroying the image white-box features, the fitted image is obtained and the model intermediate layer feature map is extracted. Afterward, the fitting gradient is found for the fitted images with different fitting degrees. We construct loss functions based on the obtained fitting gradients and feature maps to guide the attacks to better destroy the black-box features of the images. Extensive experiments demonstrate that our methods have higher transferability compared to state-of-the-art methods, which achieve more than 90% of transferability under the normal model. It is also significantly better than other methods on adversarially trained models. Even in the white-box setting, our attack has the best performance.},
  archive      = {J_NEUCOM},
  author       = {Maoyuan Wang and Jinwei Wang and Bin Ma and Xiangyang Luo},
  doi          = {10.1016/j.neucom.2024.127863},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127863},
  shortjournal = {Neurocomputing},
  title        = {Improving the transferability of adversarial examples through black-box feature attacks},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning hierarchical discrete prior for co-speech gesture
generation. <em>NEUCOM</em>, <em>595</em>, 127831. (<a
href="https://doi.org/10.1016/j.neucom.2024.127831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of Co-Speech Gesture Generation, Vector-Quantized Variational Autoencoder (VQ-VAE) based methods have shown promising results by separating the generation process into two stages: learning discrete gesture priors via pretraining for gesture reconstruction, which encodes gesture into a discrete codebook, followed by learning the mapping between speech audio and gesture codebook indices. This design leverages pretraining of motion VQVAE with the motion reconstruction task to improve the quality of generated gestures. However, the vanilla VQVAE’s codebook often fails to encode both low-level and high-level gesture features adequately, resulting in limited reconstruction quality and generation performance. To address this, we propose the Hierarchical Discrete Audio-to-Gesture (HD-A2G), which innovates (i) a two-stage hierarchical codebook structure for capturing high-level and low-level gesture priors, enabling the reconstruction of gesture details. (ii) it further integrates high-level and low-level feature using an AdaIn layer, effectively enhancing the learning of gesture’s rhythm and content. (iii) it explicitly maps text and audio onset features to the appropriate levels of the codebook, ensuring learning accurate hierarchical associations for the generation stage. Experimental results on the BEAT and Trinity datasets demonstrate that HD-A2G outperform the baseline method in both pretrained gesture reconstruction and audio-conditioned gesture generation with a clear margin, achieving the state-of-the-art performance qualitatively and quantitatively.},
  archive      = {J_NEUCOM},
  author       = {Jian Zhang and Osamu Yoshie},
  doi          = {10.1016/j.neucom.2024.127831},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127831},
  shortjournal = {Neurocomputing},
  title        = {Learning hierarchical discrete prior for co-speech gesture generation},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MAFormer: A transformer network with multi-scale attention
fusion for visual recognition. <em>NEUCOM</em>, <em>595</em>, 127828.
(<a href="https://doi.org/10.1016/j.neucom.2024.127828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision Transformer and its variants have demonstrated great potential in various computer vision tasks. However conventional vision transformers often focus on global dependency at a coarse level, which results in a learning challenge on global relationships and fine-grained representation at a token level. In this paper, we introduce Multi-scale Attention Fusion into transformer ( MAFormer ), which explores local aggregation and global feature extraction in a dual-stream framework for visual recognition. We develop a simple but effective module to explore the full potential of transformers for visual representation by learning fine-grained and coarse-grained features at a token level and dynamically fusing them. Our Multi-scale Attention Fusion (MAF) block consists of: i) a local window attention branch that learns short-range interactions within windows, aggregating fine-grained local features; ii) global feature extraction through a novel Global Learning with Down-sampling (GLD) operation to efficiently capture long-range context information within the whole image; iii) a fusion module that self-explores the integration of both features via attention. Our MAFormer achieves state-of-the-art results on several common vision tasks. In particular, MAFormer-L achieves 85.9% Top-1 accuracy on ImageNet, surpassing CSWin-B and LV-ViT-L by 1.7% and 0.6% respectively. On MSCOCO, MAFormer outperforms the prior art CSWin by 1.7% mAPs on object detection and 1.4% on instance segmentation with similar-sized parameters. With the performance, MAFormer demonstrates the ability to generalize across various visual benchmarks and prospects as a general backbone for different self-supervised pre-training tasks in the future.},
  archive      = {J_NEUCOM},
  author       = {Huixin Sun and Yunhao Wang and Xiaodi Wang and Bin Zhang and Ying Xin and Baochang Zhang and Xianbin Cao and Errui Ding and Shumin Han},
  doi          = {10.1016/j.neucom.2024.127828},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127828},
  shortjournal = {Neurocomputing},
  title        = {MAFormer: A transformer network with multi-scale attention fusion for visual recognition},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A head-to-head attention with prompt text augmentation for
text classification. <em>NEUCOM</em>, <em>595</em>, 127815. (<a
href="https://doi.org/10.1016/j.neucom.2024.127815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-text classification is an important task in natural language processing (NLP). The classification results are unsatisfactory due to the sparsity of Chinese short texts, insufficient annotation data, single tasks, and classification imbalance problems. Therefore, we propose a method based on a self-attention mechanism to focus on the relationships between attention heads, which can improve the performance of models represented by self-attention for short-text classification tasks. In addition, we designed a text augmentation template based on prompt learning with embedded labels. This allows single-task classification to be transformed into multitask classification while allowing the model to focus on the semantic consistency of the labels with the text. We conducted experiments on the CHNSenticorp, COLD, and SST-2 datasets to achieve better results than several popular text classification methods.},
  archive      = {J_NEUCOM},
  author       = {Bo Peng and Kundong Han and Liang Zhong and Shengbo Wu and Tao Zhang},
  doi          = {10.1016/j.neucom.2024.127815},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127815},
  shortjournal = {Neurocomputing},
  title        = {A head-to-head attention with prompt text augmentation for text classification},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient subspace clustering and feature extraction via
ℓ2,1-norm and ℓ1,2-norm minimization. <em>NEUCOM</em>, <em>595</em>,
127813. (<a href="https://doi.org/10.1016/j.neucom.2024.127813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nuclear norm-based Latent Low-Rank Representation (LatLRR) has gained much attention due to its success in subspace clustering and feature extraction. However, it suffers from high computational costs due to the calculation of singular value decomposition for large matrices. To this end, we develop an efficient subspace clustering and feature extraction method (ESCFE) which substitutes the nuclear norm with the ℓ 2 , 1 ℓ2,1 -norm and ℓ 1 , 2 ℓ1,2 -norm respectively. Theoretically proof shows both the ℓ 2 , 1 ℓ2,1 -norm and ℓ 1 , 2 ℓ1,2 -norm can serve as the convex surrogates of the nuclear norm while can derive closed-form solutions. Furthermore, the ℓ 2 , 1 ℓ2,1 -norm (or ℓ 1 , 2 ℓ1,2 -norm) regularization promotes column (or row) structure sparsity due to the discriminative nature inherited from the ℓ 1 ℓ1 -norm. Thus the proposed ESCFE is robust to outliers in data and can extract features with joint sparsity. Extensive experiments on multiple benchmark datasets demonstrate the superiority of our method in both efficiency and effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Xiaoguang Qiao and Caikou Chen and Weiye Wang},
  doi          = {10.1016/j.neucom.2024.127813},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127813},
  shortjournal = {Neurocomputing},
  title        = {Efficient subspace clustering and feature extraction via ℓ2,1-norm and ℓ1,2-norm minimization},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cognitive mapping and episodic memory emerge from simple
associative learning rules. <em>NEUCOM</em>, <em>595</em>, 127812. (<a
href="https://doi.org/10.1016/j.neucom.2024.127812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Episodic memory enables animals to map contexts and environmental features in space and time but is underused in artificial intelligence (AI). Here we show how simple associative learning rules can be expanded to basic episodic memory in AI. We augment an agent-based foraging simulation, ASIMOV, modeled on the simple neuronal circuitry of an invertebrate forager, by adding a novel computational module for simple episodic memory, the Feature Association Matrix (FAM). The FAM is a set of computationally light, graph learning algorithms which functionally resemble the auto- and hetero-associative circuits of the hippocampus for episodic memory. In simulations, FAM enables highly efficient foraging and navigation and shows how higher-order conditioning mechanisms give rise to spatial cognitive mapping by chaining pair-wise associations and encoding them with additional contexts. Thus, FAM demonstrates a biologically inspired, bottom-up enhancement of AI for higher-order cognition.},
  archive      = {J_NEUCOM},
  author       = {Ekaterina D. Gribkova and Girish Chowdhary and Rhanor Gillette},
  doi          = {10.1016/j.neucom.2024.127812},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127812},
  shortjournal = {Neurocomputing},
  title        = {Cognitive mapping and episodic memory emerge from simple associative learning rules},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Regularized online exponentially concave optimization.
<em>NEUCOM</em>, <em>595</em>, 127789. (<a
href="https://doi.org/10.1016/j.neucom.2024.127789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate regularized online exponentially concave (abbr. exp-concave) optimization, in which each loss function consists of a time-varying exp-concave function and a fixed convex regularization. If the whole loss function is exp-concave, a classical method called online Newton step (ONS) enjoys an O ( d log T ) O(dlogT) regret bound, where d d is the dimensionality and T T is the time horizon. However, in the regularized setting, the sum of an exp-concave function and a convex regularization is not necessarily an exp-concave function, which implies that ONS is not applicable. To address this problem, we propose the proximal online Newton step (ProxONS), and show that it can attain the same O ( d log T ) O(dlogT) regret bound for any convex regularization. The main idea is to first perform an iteration of ONS with the exp-concave part in each loss function and then perform a proximal mapping with the regularization part. Furthermore, we demonstrate that by utilizing the standard online-to-batch conversion, our ProxONS can be extended to solve stochastic optimization with a regularized exp-concave objective, and enjoy an O ( d log T / T ) O(dlogT/T) convergence rate with high probability. Experimental results on two real datasets verify the effectiveness of our ProxONS.},
  archive      = {J_NEUCOM},
  author       = {Xu Yang and Peng Tian and Xiao Cheng and Yuanyu Wan and Mingli Song},
  doi          = {10.1016/j.neucom.2024.127789},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127789},
  shortjournal = {Neurocomputing},
  title        = {Regularized online exponentially concave optimization},
  volume       = {595},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Late better than early: A decision-level information fusion
approach for RGB-thermal crowd counting with illumination awareness.
<em>NEUCOM</em>, <em>594</em>, 127888. (<a
href="https://doi.org/10.1016/j.neucom.2024.127888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we make the first research effort to address the RGB-Thermal (RGB-T) crowd counting problem with the decision-level late fusion manner. Being different from the existing pixel-level or feature-level fusion methods, our proposition chooses to fuse the density maps yielded by RGB and thermal counterparts via spatially adaptive weighting with RGB illumination-aware attention. Our key intuition to conduct RGB-T density map fusion lies in 2 main folders. First, compared with the raw RGB-T images or convolutional feature maps, RGB-T density maps contain stronger counting-wise semantic meanings. Secondly, they are also of high spatial resolution for revealing fine local details. To fuse them adaptively, a spatial weighting map for each modality, together with an illumination-related RGB weight is generated. In this way, the issues of RGB illumination awareness and local counting pattern characterization ability are concerned jointly. To the best of our knowledge, we are the first to leverage RGB-T crowd counting concerning these 2 issues in a unified way. Meanwhile, cross-modality feature interaction is conducted between RGB and thermal modalities to facilitate spatial weighting map generation. The experiments on 2 well-established RGB-T crowd counting datasets ( i.e. , RGBT-CC and DroneRGBT) verify the superiority of our proposition. The source code and pretrained models will be released upon acceptance at https://github.com/hustaia/DLF-IA .},
  archive      = {J_NEUCOM},
  author       = {Jian Cheng and Chen Feng and Yang Xiao and Zhiguo Cao},
  doi          = {10.1016/j.neucom.2024.127888},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127888},
  shortjournal = {Neurocomputing},
  title        = {Late better than early: A decision-level information fusion approach for RGB-thermal crowd counting with illumination awareness},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). StyleVTON: A multi-pose virtual try-on with identity and
clothing detail preservation. <em>NEUCOM</em>, <em>594</em>, 127887. (<a
href="https://doi.org/10.1016/j.neucom.2024.127887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual try-on models have been developed using deep learning techniques to transfer clothing product images onto a candidate. While previous research has primarily focused on enhancing the realism of the garment transfer, such as improving texture quality and preserving details, there is untapped potential to further improve the shopping experience for consumers. The present study outlines the development of an innovative multi-pose virtual try-on model, namely StyleVTON, to potentially enhance consumers’ shopping experiences. Our method synthesises a try-on image while also allowing for changes in pose. To achieve this, StyleVTON first predicts the segmentation of the target pose based on the target garment. Next, the segmentation layout guides the warping process of the target garment. Finally, the pose of the candidate is transferred to the desired posture. Our experiments demonstrate that StyleVTON can generate satisfactory images of candidates wearing the desired clothes in a desired pose, potentially offering a promising solution for enhancing the virtual try-on experience. Our findings reveal that StyleVTON outperforms other comparable methods, particularly in preserving the facial identity of the candidate and geometrically transforming the garments.},
  archive      = {J_NEUCOM},
  author       = {Tasin Islam and Alina Miron and Xiaohui Liu and Yongmin Li},
  doi          = {10.1016/j.neucom.2024.127887},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127887},
  shortjournal = {Neurocomputing},
  title        = {StyleVTON: A multi-pose virtual try-on with identity and clothing detail preservation},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhance audio-visual segmentation with hierarchical encoder
and audio guidance. <em>NEUCOM</em>, <em>594</em>, 127885. (<a
href="https://doi.org/10.1016/j.neucom.2024.127885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the pivotal technologies leading towards embodied intelligence, audio-visual segmentation is geared towards achieving precise segmentation of sounding objects, offering vast application prospects in scenarios such as emergency rescue and natural exploration. Nevertheless, the performance of audio-visual segmentation technology encounters limitations stemming from challenges related to the adaptation and fusion of cross-modal information encoding, as well as the decoding and generation of masks. To address these issues, this paper explores the adaptation of multi-modal information based on a shared encoder by employing a neural architecture search method to design a hierarchical encoder cooperation module for enhanced information interaction. An intermediate loss is leveraged to help the encoder to keep spatial knowledge reserved. Furthermore, an audio-guided class-aware decoder is devised to guide the generation of masks. Our approach has yielded competitive experimental results across multiple datasets, thus substantiating its effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Cunhan Guo and Heyan Huang and Yanghao Zhou},
  doi          = {10.1016/j.neucom.2024.127885},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127885},
  shortjournal = {Neurocomputing},
  title        = {Enhance audio-visual segmentation with hierarchical encoder and audio guidance},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). LMFormer: Lightweight and multi-feature perspective via
transformer for human pose estimation. <em>NEUCOM</em>, <em>594</em>,
127884. (<a href="https://doi.org/10.1016/j.neucom.2024.127884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effectiveness of Token Mixer in visual tasks is well-established; however, its high computational complexity and a relatively singular spatial relationship modeling perspective present challenges. In this study, we propose LMFormer, a hybrid model based on CNN and Transformer architectures for human pose estimation. To achieve this, we first design a lightweight multi-feature perspective Token Mixer, using a lightweight feature reconstruction strategy to simultaneously aggregate the spatial and channel feature information, thereby enhancing the performance and generalization capabilities of the model. Subsequently, we explore multi-scale information interaction by developing an iterative multi-feature weighting module, coupled with the design of a multi-scale information propagation mechanism incorporated into the skip connections. Finally, we validate the effectiveness of the network on benchmark datasets, including COCO, MPII, and CrowdPose, utilizing a multi-scale deep supervision strategy. Extensive experiments demonstrate that LMFormer, with reduced computational complexity, comprehensively captures multi-scale features, resulting in significant performance improvements. Specifically, LMFormer-B achieves an AP score of 65.8 on the COCO val dataset, surpassing MobileNetV2 and ShuffleNetV2 by 1.0 and 5.6 points, respectively. Moreover, its parameters are merely 19.8% and 25% of MobileNetV2 and ShuffleNetV2, with corresponding GFLOPs at 43.8% and 50%. We aim to provide new insights into lightweight and efficient feature extraction strategies, as well as efficient Token Mixer designs.},
  archive      = {J_NEUCOM},
  author       = {Biao Li and Shoufeng Tang and Wenyi Li},
  doi          = {10.1016/j.neucom.2024.127884},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127884},
  shortjournal = {Neurocomputing},
  title        = {LMFormer: Lightweight and multi-feature perspective via transformer for human pose estimation},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Employing feature mixture for active learning of object
detection. <em>NEUCOM</em>, <em>594</em>, 127883. (<a
href="https://doi.org/10.1016/j.neucom.2024.127883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active learning aims to select the most informative samples for annotation from a large amount of unlabeled data, in order to reduce time-consuming and labor-intensive manual labeling efforts. Although active learning for object detection has made substantial progress in recent years, developing an accurate and efficient active learning algorithm for object detection remains a challenge. In this paper, we propose a novel unsupervised active learning method for deep object detection. This is based on our hypotheses that an object is more likely to be wrongly predicted by the model, if the prediction changes when its feature representations are slightly mixed by another feature representations at a very small ratio. Such unlabeled samples can be regarded as informative samples that can be selected by active learning. Our method employs base representations of all categories generated from the object detection network to examine the robustness of every detected object. We design a scoring function to calculate the informative score of each unlabeled image. We conduct extensive experiments on two public datasets, i.e. , PASCAL VOC and MS-COCO. Experiment results show that our approach consistently outperforms state-of-the-art single-model based methods with significant margins. Our approach also performs on par with multi-model based methods, at much lesser computational cost.},
  archive      = {J_NEUCOM},
  author       = {Licheng Zhang and Siew-Kei Lam and Dingsheng Luo and Xihong Wu},
  doi          = {10.1016/j.neucom.2024.127883},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127883},
  shortjournal = {Neurocomputing},
  title        = {Employing feature mixture for active learning of object detection},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal cues enhanced multimodal learning for action
recognition in RGB-d videos. <em>NEUCOM</em>, <em>594</em>, 127882. (<a
href="https://doi.org/10.1016/j.neucom.2024.127882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action recognition is an important and active research direction in computer vision, where temporal modeling is critical for action representation. Generally, unimodal methods that use only RGB or skeleton modality for human action recognition have their limitations, e.g., information redundancy/environment noise of RGB video modality, and spatial interaction deficiency of skeleton modality. In this paper, we present a novel multimodal learning approach based on RGB and skeleton modalities for action recognition in RGB-D videos. Specifically, we (1) transfer skeleton knowledge to RGB video for effective video compression, which produces the informative action image from raw RGB video, (2) introduce the temporal cues enhancement module to adequately learn the spatiotemporal representation for action classification, and (3) propose a multi-level multimodal co-learning framework for human action recognition in RGB-D videos. Experimental results on NTU RGB+D, PKU-MMD, and N-UCLA datasets demonstrate the effectiveness of the proposed multimodal learning method.},
  archive      = {J_NEUCOM},
  author       = {Dan Liu and Fanrong Meng and Qing Xia and Zhiyuan Ma and Jinpeng Mi and Yan Gan and Mao Ye and Jianwei Zhang},
  doi          = {10.1016/j.neucom.2024.127882},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127882},
  shortjournal = {Neurocomputing},
  title        = {Temporal cues enhanced multimodal learning for action recognition in RGB-D videos},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bi-syntax guided transformer network for aspect sentiment
triplet extraction. <em>NEUCOM</em>, <em>594</em>, 127880. (<a
href="https://doi.org/10.1016/j.neucom.2024.127880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect Sentiment Triplet Extraction is an emerging and challenging task that attempts to present a complete picture of aspect-based sentiment analysis. Prior research efforts mostly leverage various tagging schemes to extract the three elements in a triplet. However, these methods fail to explicitly model the complicated relations between aspects and opinions and the boundaries of multi-word aspects and opinions. In this paper, we propose a bi-syntax guided transformer network in an end-to-end manner to address these challenges. Firstly, we devise three types of representations, including sequence distance representation, constituency distance representation, and dependency distance representation, to learn the comprehensive language representation. Specifically, sequence distance representation utilizes sequence distance between words to enhance the contextual representation. Constituency distance representation adopts constituency distance between words in a constituency tree to capture the intra-span relation between words. Dependency distance representation employs dependency distance between words in a dependency tree to capture the long-distance relation between aspects and opinions. Extensive experiments are conducted on four benchmark datasets to validate the effectiveness of our method. The results demonstrate that the proposed approach achieves better performance than baseline methods. We conduct further detailed analysis to demonstrate that our method effectively handles multi-word terms and overlapping triplets.},
  archive      = {J_NEUCOM},
  author       = {Shufeng Hao and Yu Zhou and Ping Liu and Shuang Xu},
  doi          = {10.1016/j.neucom.2024.127880},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127880},
  shortjournal = {Neurocomputing},
  title        = {Bi-syntax guided transformer network for aspect sentiment triplet extraction},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Video saliency prediction for first-person view UAV videos:
Dataset and benchmark. <em>NEUCOM</em>, <em>594</em>, 127876. (<a
href="https://doi.org/10.1016/j.neucom.2024.127876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual saliency prediction plays a crucial role in Unmanned Aerial Vehicle (UAV) video analysis tasks. In this paper, an eye-tracking dataset of the immersive viewing of videos captured from a First-Person View (FPV) of UAVs is developed, which consists of 200 video clips captured by DJI FPV drones, with a resolution of 4K QHD. The videos cover six different genres and fourteen unique scenes. To study human visual attention in watching FPV videos, fixation points are recorded using an eye tracker integrated into a VR headset. Based on the dataset, a simple yet effective FPV UAV video Saliency prediction model (FUAVSal) is proposed as a baseline, considering spatial–temporal feature, camera motion information and FPV prior. To establish benchmarks for saliency prediction in immersive FPV UAV video viewing, sixteen computational models are evaluated on this dataset. Detailed quantitative and qualitative comparisons are provided. The developed dataset and benchmarks aim to facilitate research on visual saliency prediction for First-Person View UAV videos.},
  archive      = {J_NEUCOM},
  author       = {Hao Cai and Kao Zhang and Zhao Chen and Chenxi Jiang and Zhenzhong Chen},
  doi          = {10.1016/j.neucom.2024.127876},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127876},
  shortjournal = {Neurocomputing},
  title        = {Video saliency prediction for first-person view UAV videos: Dataset and benchmark},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Autonomous driving in traffic with end-to-end vision-based
deep learning. <em>NEUCOM</em>, <em>594</em>, 127874. (<a
href="https://doi.org/10.1016/j.neucom.2024.127874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a shallow end-to-end vision-based deep learning approach for autonomous vehicle driving in traffic scenarios. The primary objectives include lane keeping and maintaining a safe distance from preceding vehicles. This study leverages an imitation learning approach, creating a supervised dataset for robot control from expert agent demonstrations using the state-of-the-art Carla simulator in different traffic conditions. This dataset encompasses three different versions complementary to each other and we have made it publicly available along with the rest of the materials. The PilotNet neural model is utilized in two variants: the first one with complementary outputs for brake and throttle control commands along with dropout; the second one incorporates these improvements and adds the vehicle speed. Both models have been trained with the aforementioned dataset. The experimental results demonstrate that the models, despite their simplicity and shallow architecture, including only small-scale changes, successfully drive in traffic conditions without sacrificing performance in free-road environments, broadening their area of application widely. Additionally, the second model adeptly maintains a safe distance from leading cars and exhibits satisfactory generalization capabilities to diverse vehicle types. A new evaluation metric to measure the distance to the front vehicle has been created and added to Behavior Metrics; an open-source autonomous driving assessment tool built on CARLA that performs experimental validations of autonomous driving solutions.},
  archive      = {J_NEUCOM},
  author       = {Sergio Paniego and Enrique Shinohara and JoséMaría Cañas},
  doi          = {10.1016/j.neucom.2024.127874},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127874},
  shortjournal = {Neurocomputing},
  title        = {Autonomous driving in traffic with end-to-end vision-based deep learning},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolving filter criteria for randomly initialized network
pruning in image classification. <em>NEUCOM</em>, <em>594</em>, 127872.
(<a href="https://doi.org/10.1016/j.neucom.2024.127872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network pruning aims to enhance the performance of deep neural networks by eliminating redundant components from the model. However, existing pruning methods typically require a well-trained model and employ fixed, single pruning criteria throughout the pruning cycles. To address these limitations, we propose a novel method called Evolutionary Filter Criteria (EvoFC). This method enables the automated search for the network pruning ratio and criterion during a population-based heuristic search process. We introduce a unique encoding space that represents the chosen pruning criterion and ratio for each layer, facilitating the acquisition of optimal architecture configurations for candidate networks during iterations. Additionally, we devise a novel weight inheritance mechanism to mitigate the computational burden associated with the population-based nature of the method, resulting in a significant reduction in overall training time. We validate our method by applying it to randomly initialized networks and conducting empirical experiments on CIFAR-10/100, ILSVRC-2012 and Places365 datasets. The results demonstrate that our method effectively reduces the number of FLOPs while striking a fine balance between accuracy and computational efficiency. This underscores the practical value of our method in optimizing performance while efficiently utilizing computational resources, particularly when pruning networks starting from random initialization.},
  archive      = {J_NEUCOM},
  author       = {Xiangru Chen and Chenjing Liu and Peng Hu and Jie Lin and Yunhong Gong and Yingke Chen and Dezhong Peng and Xue Geng},
  doi          = {10.1016/j.neucom.2024.127872},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127872},
  shortjournal = {Neurocomputing},
  title        = {Evolving filter criteria for randomly initialized network pruning in image classification},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prior knowledge-infused self-supervised learning and
explainable AI for fault detection and isolation in PEM electrolyzers.
<em>NEUCOM</em>, <em>594</em>, 127871. (<a
href="https://doi.org/10.1016/j.neucom.2024.127871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel Fault Detection and Isolation (FDI) method for Proton Exchange Membrane (PEM) electrolyzers is presented. The challenge of limited availability of labeled fault data is addressed through the utilization of Bond Graphs (BG) and Self-Supervised Learning (SSL). The Linear Fractional Transformation-Bond Graph (LFT-BG) model is employed to generate uncertain residuals and pseudo labels, enabling the training of a deep neural network through self-supervised learning. Additionally, the BG-XAI method is introduced, leveraging eXplainable AI (XAI) and structural equations from Bond Graphs to provide explanations for the decisions made by the deep learning model. The superior performance of the proposed approach, particularly in dealing with limited labeled data, is demonstrated through comparative assessments against various state-of-the-art SSL methods. The demo code of the proposed method is available in this repository: https://github.com/mohan696matlab/SSL_based_Hybrid_FDI .},
  archive      = {J_NEUCOM},
  author       = {Balyogi Mohan Dash and Belkacem Ould Bouamama and Komi Midzodzi Pekpe and Mahdi Boukerdja},
  doi          = {10.1016/j.neucom.2024.127871},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127871},
  shortjournal = {Neurocomputing},
  title        = {Prior knowledge-infused self-supervised learning and explainable AI for fault detection and isolation in PEM electrolyzers},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Coexistence of locally multistable equilibrium points for
n-neuron delayed quaternion-valued neural networks with continuous
piecewise nonlinear activation functions. <em>NEUCOM</em>, <em>594</em>,
127868. (<a href="https://doi.org/10.1016/j.neucom.2024.127868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the coexistence of multistable equilibrium points (EPs) for n n -neuron delayed quaternion-valued neural networks (DQVNNs) in which the continuous and piecewise nonlinear functions are used as the activation functions. Using the state space decomposition technique, Brouwer’s fixed point theorem, and Lagrange’s mean value theorem, some novel sufficient conditions have been derived to ensure the coexistence of 5 4 n 54n EPs in which 3 4 n 34n of them are locally stable. Furthermore, in this scientific contribution, positively invariant sets have been estimated which actually turned out to be quite challenging for the activation functions of the designed DQVNNs. Finally, some comparisons and convincing simulations with the application to associative memory of DQVNNs are given to verify the theoretical results at the end of this article.},
  archive      = {J_NEUCOM},
  author       = {Shiv Shankar Chouhan and Subir Das and Xiaofeng Chen},
  doi          = {10.1016/j.neucom.2024.127868},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127868},
  shortjournal = {Neurocomputing},
  title        = {Coexistence of locally multistable equilibrium points for n-neuron delayed quaternion-valued neural networks with continuous piecewise nonlinear activation functions},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GroupTransNet: Group transformer network for RGB-d salient
object detection. <em>NEUCOM</em>, <em>594</em>, 127865. (<a
href="https://doi.org/10.1016/j.neucom.2024.127865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an active topic in computer vision, RGB-D salient object detection has witnessed substantial progress. Although the existing methods have achieved appreciable performance, there are still some challenges. The locality of convolutional neural networks requires that the model has a sufficiently deep global receptive field, while the local characteristic represented by transformer with strong globality is always not enough. Besides, the shared information of contextual features tends to be usually overlooked. To address these bottlenecks, we propose a novel group transformer network (GroupTransNet), which is good at learning the long-range dependencies of cross layer features to promote more perfect feature expression between high-level and low-level features. Importantly, we soft group the features of the middle and latter three levels to absorb the semantic information of slightly former level features. Firstly, the input features are adaptively purified by the element-wise operation and sequential attention mechanism. Afterwards, the intermediate features are uniformly fused at different layers, and then processed by several transformers in multiple groups. Finally, the output features are clustered within different classifications and combined with underlying features. Extensive experiments demonstrate the proposed GroupTransNet outperforms the competitors and achieves new state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Xian Fang and Mingfeng Jiang and Jinchao Zhu and Xiuli Shao and Hongpeng Wang},
  doi          = {10.1016/j.neucom.2024.127865},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127865},
  shortjournal = {Neurocomputing},
  title        = {GroupTransNet: Group transformer network for RGB-D salient object detection},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning on spatiotemporal graphs: A systematic review,
methodological landscape, and research opportunities. <em>NEUCOM</em>,
<em>594</em>, 127861. (<a
href="https://doi.org/10.1016/j.neucom.2024.127861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning approaches, given their low cost and high reliability, have gained much popularity in different subjects, such as computer vision and natural language processing, and more recently in graph data types. Spatiotemporal graph-based neural networks have been more and more developed to solve problems related to spatiotemporal data, mainly for analyzing changes over time and for provisioning purposes. In this systematic literature review, we have aimed to answer the most important questions regarding spatiotemporal graph deep learning architectures in different applications domains, such as traffic related topics, medical imaging, and geographical data analysis. We have selected more than 50 papers that cover a wide range of applications and very different architectures and innovations. We have also noticed that most of them consider the spatiotemporal graphs to be quite classic graphs without any further sophisticated modeling of temporal and spatial data evolution. Moreover, core problems (such as node classification, frequent pattern recognition, etc.) and application domains are not sufficiently addressed by the state-of-the-art. This study thus opens many perspectives to new developments in spatio-temporal graph deep learning with different strategies in order to solve various end-to-end tasks and other problems related to this special kind of graph.},
  archive      = {J_NEUCOM},
  author       = {Assaad Zeghina and Aurélie Leborgne and Florence Le Ber and Antoine Vacavant},
  doi          = {10.1016/j.neucom.2024.127861},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127861},
  shortjournal = {Neurocomputing},
  title        = {Deep learning on spatiotemporal graphs: A systematic review, methodological landscape, and research opportunities},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Balanced quantum neural architecture search.
<em>NEUCOM</em>, <em>594</em>, 127860. (<a
href="https://doi.org/10.1016/j.neucom.2024.127860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, there has been continuously increasing attention on Neural Architecture Search (NAS). The design of network architecture is aimed at automatically generating efficient neural networks in the absence of prior knowledge. Most of current oneshot NAS methods are based on weight sharing. However, there are two main problems that lead to suboptimal search results. Firstly, the large scale supernet results in a complex and difficult search for optimal subnetwork structures in the large discrete search space. Secondly, weight sharing makes the internal weight parameters of the supernet cannot always vary towards the final weights required for the optimal network structure due to the influence of different structures. These problems are responsible for the fact that the performance of the subnetworks searched by the supernet cannot represent the real performance of the subnetworks trained from scratch. To solve these problems, we propose the method based on quantum evolution and balance pool, called BQNAS, which consists of two stages. The single path supernet is trained based on weight sharing and balance pool sampling method. Then, quantum parallelism is exploited for one-hot encoding and searching for the optimal subnetwork structure based on quantum evolutionary algorithms. It can greatly improve the search efficiency of oneshot approaches in subnetwork sampling and evaluate the real performance for searching for superior subnetwork structure. Extensive experiments on two datasets show that the proposed approach outperforms the state-of-the-art ones. Specifically, BQNAS achieves a top-1 accuracy of 97.27% on CIFAR-10 and 81.36% on CIFAR-100.},
  archive      = {J_NEUCOM},
  author       = {Yangyang Li and Guanlong Liu and Peixiang Zhao and Ronghua Shang and Licheng Jiao},
  doi          = {10.1016/j.neucom.2024.127860},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127860},
  shortjournal = {Neurocomputing},
  title        = {Balanced quantum neural architecture search},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Excitatory and inhibitory neuronal synapse unit: A novel
recurrent cell for time series prediction. <em>NEUCOM</em>,
<em>594</em>, 127858. (<a
href="https://doi.org/10.1016/j.neucom.2024.127858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series prediction is one of the most challenging topics in real-world applications. Most studies undertook advanced mathematics and computer techniques above benchmark methods but often unable to guarantee forecasting models’ generalization and reliability. This paper proposed a biologically motivated recurrent unit based on neuronal synaptic activity mechanism and chaotic behaviors in deep learning domain called Excitatory and Inhibitory Neural Synapse unit (EINS). The major contribution of this research is to create a flexible and robust recurrent unit based on neuroscience theory. It conducted experiments on three real-world time series forecast examples including finance, household power, weather for generalization and robustness evaluation using eight state-of-the-art recurrent architecture units as baseline models to compare convergence rate and forecasting accuracy. Experimental results showed that EINS achieved satisfactory performances in time series prediction reliability and effectiveness.},
  archive      = {J_NEUCOM},
  author       = {LuoChao Wang and Raymond S.T. Lee},
  doi          = {10.1016/j.neucom.2024.127858},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127858},
  shortjournal = {Neurocomputing},
  title        = {Excitatory and inhibitory neuronal synapse unit: A novel recurrent cell for time series prediction},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PRGNN: Modeling high-order proximity with relational graph
neural network for knowledge graph completion. <em>NEUCOM</em>,
<em>594</em>, 127857. (<a
href="https://doi.org/10.1016/j.neucom.2024.127857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relational Graph Neural Networks (RGNNs) are designed to extract structural information from relational graphs and have garnered attention in the domain of Knowledge Graph Completion (KGC). However, recent empirical investigations have indicated that some prominent RGNN-based methodologies have not significantly enhanced precision, prompting questions regarding the efficacy of RGNNs in KGC applications. In this paper, we introduce a novel RGNN-based KGC approach, the Proximity Relational Graph Neural Network (PRGNN), which excels at modeling high-order proximities among entities. PRGNN is founded on a notably straightforward yet effective RGNN framework that discards unnecessary components commonly incorporated in previous approaches, such as attention layers, and linear and non-linear mappings. We demonstrate that PRGNN empowers traditional KGC techniques to apprehend high-order proximities among entities more effectively. Through extensive experimentation on benchmark datasets, we establish that PRGNN consistently outperforms conventional KGC methods and achieves state-of-the-art results. Furthermore, we show that PRGNN necessitates considerably less training time (ranging from one-third to one-fifth) and fewer parameters (ranging from half to two-thirds), rendering it an exceptionally efficient approach. All data and code have been made available at 1 .},
  archive      = {J_NEUCOM},
  author       = {Danhao Zhu},
  doi          = {10.1016/j.neucom.2024.127857},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127857},
  shortjournal = {Neurocomputing},
  title        = {PRGNN: Modeling high-order proximity with relational graph neural network for knowledge graph completion},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NCLDR: Nearest-neighbor contrastive learning with dual
correlation loss for dimensionality reduction. <em>NEUCOM</em>,
<em>594</em>, 127848. (<a
href="https://doi.org/10.1016/j.neucom.2024.127848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimensionality reduction is an efficient method for alleviating the issue of dimensionality in high-dimensional data. As a popular self-supervised learning method, contrastive learning has recently garnered considerable attention. In this paper, we propose NCLDR: Nearest-Neighbor Contrastive Learning with Dual Correlation Loss for Dimensionality Reduction, a novel dimensionality reduction method that is porting a contrastive learning framework to the specific task of dimensionality reduction. Firstly, NCLDR uses the nearest-neighbor to construct feature pairs from the training set itself. Afterwards, to decorrelate feature variables that produce representations invariant across such pairs, a basic multi-layer perceptron (MLP) network architecture with a dual correlation loss function is designed. Compared to most dimensionality reduction methods, NCLDR bypasses the complexity of optimizing kNN graphs and facilitates the embedding of out-of-sample data. Additionally, it also alleviates the issue of “dimensional collapse” in the low-dimensional representation space. Finally, experimental results demonstrate that the proposed method achieves significant improvements over state-of-the-art dimensionality reduction methods.},
  archive      = {J_NEUCOM},
  author       = {Linlin Feng and Changpeng Wang and Pei Liu and Kangjian Ge and Jiangshe Zhang},
  doi          = {10.1016/j.neucom.2024.127848},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127848},
  shortjournal = {Neurocomputing},
  title        = {NCLDR: Nearest-neighbor contrastive learning with dual correlation loss for dimensionality reduction},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A novel stochastic configuration network with enhanced
feature extraction for industrial process modeling. <em>NEUCOM</em>,
<em>594</em>, 127833. (<a
href="https://doi.org/10.1016/j.neucom.2024.127833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic configuration networks (SCNs), possessing sound generalization performance and low computational burden, have been extensively investigated in data analysis field. But in practice, it performs poor. This is mainly caused by two aspects: (1) the increment of random hidden nodes with incompact constraints may bring the emergence of redundant nodes, thereby resulting in poor modeling performance, and (2) SCNs have limited feature extraction capabilities. To address these issues, a novel SCN inserting feature layer, termed as FSCN, is presented in this paper. First, the embedded feature layer establishes a connection between the input and hidden layers, thus mapping the input data into a suitable feature space. Second, an inequality constraint based on Greville iterative method is established. It can not only facilitate the construction of high-quality hidden nodes but also guarantee convergence of the built model. Then, the Greville iterative method is also employed for output weight updating. Finally, comparative experiments on a real-valued nonlinear function, four real-world data sets and the modeling of two real industrial processes are conducted and the comparison results with other modeling methods show that FSCN has superior performance in terms of both model accuracy and compactness.},
  archive      = {J_NEUCOM},
  author       = {Qianjin Wang and Wei Yang and Wei Dai and Xiaoping Ma},
  doi          = {10.1016/j.neucom.2024.127833},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127833},
  shortjournal = {Neurocomputing},
  title        = {A novel stochastic configuration network with enhanced feature extraction for industrial process modeling},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MASSNet: Multiscale attention for single-stage ship instance
segmentation. <em>NEUCOM</em>, <em>594</em>, 127830. (<a
href="https://doi.org/10.1016/j.neucom.2024.127830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maritime surveillance is essential in understanding, predicting, and ensuring the security of events in the complex marine environment. In this context, we have used instance segmentation techniques, which provides an accurate and efficient method for segmenting objects (Ships) in maritime surveillance. However, prevalent two-stage algorithms have limitations, including complex models, extended training time, and high memory consumption, making them impractical for real-world application. To address these challenges, we present an efficient solution called Multiscale Attention for Single-Stage Ship Instance Segmentation, or MASSNet. MASSNet uses the power of attention mechanisms to enhance multiscale feature extraction across various dimensions, resulting in a more refined and contextually-aware representation. This approach significantly improves segmentation accuracy and overall performance. In our extensive experiments, we evaluate the effectiveness of MASSNet on three challenging datasets: MariboatS, ShipInsSeg, and ShipSG. Our proposed model achieves mask Average Precision (mask AP) scores of 55.4%, 55.5%, and 74.1% on MariboatS, ShipInsSeg, and ShipSG datasets and outperforms other models such as YOLACT, SOLO and SOLOv2 architectures. MASSNet offers a robust and efficient solution for Ship Instance Segmentation, making significant improvement in the capabilities of maritime surveillance.},
  archive      = {J_NEUCOM},
  author       = {Rabi Sharma and Muhammad Saqib and C.T. Lin and Michael Blumenstein},
  doi          = {10.1016/j.neucom.2024.127830},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127830},
  shortjournal = {Neurocomputing},
  title        = {MASSNet: Multiscale attention for single-stage ship instance segmentation},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Advancing zero-shot semantic segmentation through attribute
correlations. <em>NEUCOM</em>, <em>594</em>, 127829. (<a
href="https://doi.org/10.1016/j.neucom.2024.127829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot semantic segmentation aims to segment novel classes that have not been encountered during the training phase. Existing methods leverage available text features obtained from pretrained language models to produce semantic segmentation results for both base and novel classes. However, the text-based feature-producing paradigm only provides insufficient class correlations and limits the full exploitation of image features from base classes. Besides, there exists a non-negligible domain gap between the text and image domains, resulting in severe feature bias during feature production. Different from existing methods, we advance the zero-shot semantic segmentation through attribute correlations. Specifically, we introduce a set of shared-attribute labels, of which the design fully considers the structural relations between attributes and classes, to provide rational and sufficient attribute-class correlations. Besides, due to the minor intra-class variations of shared attributes, the text features are more easily mapped to image features, thereby alleviating the domain gap issue. Furthermore, we propose a hierarchical semantic segmentation framework incorporating an attribute prompt tuning method. This approach is designed to enhance the model’s adaptation to the attribute segmentation task and effectively leverage attribute features to produce better semantic segmentation results. Correspondingly, we construct a Visual Hierarchical Semantic Classes (VHSC) benchmark, meticulously annotating shared-attributes at the pixel level to conduct the experiments. Extensive experiments on the VHSC benchmark showcase the superior performance of our method compared to existing zero-shot semantic segmentation methods, achieving mIoU of 73.0% and FBIoU of 87.5%. The VHSC benchmark and our code are available at https://github.com/RuntongZHANG/ZeroShot-VHSC .},
  archive      = {J_NEUCOM},
  author       = {Runtong Zhang and Fanman Meng and Shuai Chen and Qingbo Wu and Linfeng Xu and Hongliang Li},
  doi          = {10.1016/j.neucom.2024.127829},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127829},
  shortjournal = {Neurocomputing},
  title        = {Advancing zero-shot semantic segmentation through attribute correlations},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SC-net: Multimodal metaphor detection using semantic
conflicts. <em>NEUCOM</em>, <em>594</em>, 127825. (<a
href="https://doi.org/10.1016/j.neucom.2024.127825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The phenomenon of metaphors is often regarded as a departure from semantic selection and common sense in semantic composition tasks, with their fundamental characteristics being semantic conflicts. Recognizing intricate and elusive metaphors has consistently posed a formidable challenge in the realm of natural language processing. In this paper, we introduce a novel multimodal metaphor detection model named SC-Net. This model benefits from linguistic metaphor identification theories and aims to exploit the inherent semantic conflicts in metaphors to detect whether multimodal corpora are metaphorical. The model projects each modality into two distinct subspaces: a modality-semantic feature space and a modality-latent metaphorical feature space. The features derived from these spaces provide a comprehensive perspective for capturing both intramodal semantic conflicts and intermodal semantic conflicts for prediction purposes. Our experiments conducted on the Chinese, English, and Bilingual Met-meme datasets and the MultiBully dataset demonstrate that our proposed SC-Net achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Xiaoyu He and Long Yu and Shengwei Tian and Qimeng Yang and Jun Long},
  doi          = {10.1016/j.neucom.2024.127825},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127825},
  shortjournal = {Neurocomputing},
  title        = {SC-net: Multimodal metaphor detection using semantic conflicts},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Multi-source domain adaptation handling inaccurate label
spaces. <em>NEUCOM</em>, <em>594</em>, 127824. (<a
href="https://doi.org/10.1016/j.neucom.2024.127824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation with inaccurate label is a challenging and interesting topic in transfer learning, dealing with source and target domains with shift label spaces. Most existing domain adaptation methods assume aware label distributions among source and target domains. However, this cannot always be guaranteed in reality. Furthermore, existing multi-domain adaptation methods rarely deal with label heterogeneity among source domains. Thus, in this paper, we propose a multi-source domain adaptation method handling Inaccurate label (IncLabDA) during transfer. The proposed method designs a module that can transfer knowledge from multi-source domains with both homogeneous and heterogeneous label spaces in universal scenario. Anchors are generated from pre-trained model to build data-matching via a contrastive method avoiding to referring original data. In addition, class center consistency combined with clustering strategy considering both global and local confidences is adopted to recognize out-of-distribution samples. By removing source private classes and target unknown samples, highly confident target samples are collected to self-supervise the adaptation. At the same time, constraints enlarging the distance among target known classes and between the known and unknown samples are applied to enhance the performance of the proposed model. Experiments on real-world datasets validate the superiority of the IncLabDA model.},
  archive      = {J_NEUCOM},
  author       = {Keqiuyin Li and Jie Lu and Hua Zuo and Guangquan Zhang},
  doi          = {10.1016/j.neucom.2024.127824},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127824},
  shortjournal = {Neurocomputing},
  title        = {Multi-source domain adaptation handling inaccurate label spaces},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Partial label learning with heterogeneous domain adaptation.
<em>NEUCOM</em>, <em>594</em>, 127822. (<a
href="https://doi.org/10.1016/j.neucom.2024.127822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial label learning (PLL) seeks a classification model with partially labeled (PL) instances. Each PL instance is attached with a candidate label set, with only one being ground-truth. A fundamental assumption of the previous PLL works is that there are sufficient PL instances in the learning process. Nevertheless, this assumption may not always be valid. In real-world scenarios, there may be only a few PL instances available for training. To this end, we introduce a new PLL method with heterogeneous domain adaptation (PLL-HDA). PLL-HDA leverages the knowledge from the source domain to induce a PLL classifier of the target domain, which contains only a few PL instances for training. Firstly, PLL-HDA introduces a common subspace to measure the instances from the source and target domains, where the instances from these domains are described by heterogeneous features of distinct dimensions. Secondly, we augment the features of the common subspace by merging the original features from both domains. Thirdly, a large-margin-based PLL learning system is established on the augmented features. It leads to a simplified dual form, which can be directly resolved by off-the-shelf support vector machine solvers. Lastly, a heuristic framework is proposed to resolve the PLL-HDA classification model. In this framework, the tasks of learning the classifier on the augmented features and identifying the ground-truth labels of target domain are conducted alternately. Extensive experiments on both the controlled PLL and real-world PLL datasets illustrate the superiority of PLL-HDA over the existing PLL methods. Our code is available at: https://github.com/Sux86 .},
  archive      = {J_NEUCOM},
  author       = {Liang Zhao and Yanshan Xiao and Bo Liu},
  doi          = {10.1016/j.neucom.2024.127822},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127822},
  shortjournal = {Neurocomputing},
  title        = {Partial label learning with heterogeneous domain adaptation},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sauron u-net: Simple automated redundancy elimination in
medical image segmentation via filter pruning. <em>NEUCOM</em>,
<em>594</em>, 127817. (<a
href="https://doi.org/10.1016/j.neucom.2024.127817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Sauron, a filter pruning method that eliminates redundant feature maps of convolutional neural networks (CNNs). Sauron optimizes, jointly with the loss function, a regularization term that promotes feature maps clustering at each convolutional layer by reducing the distance between feature maps. Sauron then eliminates the filters corresponding to the redundant feature maps by using automatically adjusted layer-specific thresholds. Unlike most filter pruning methods, Sauron requires minimal changes to typical neural network optimization because it prunes and optimizes CNNs jointly, which, in turn, accelerates the optimization over time. Moreover, unlike with other cluster-based approaches, the user does not need to specify the number of clusters in advance, a hyperparameter that is difficult to tune. We evaluated Sauron and five state-of-the-art filter pruning methods on four medical image segmentation tasks. This is an area where little attention has been paid to filter pruning, but where smaller CNN models are desirable for local deployment, mitigating privacy concerns associated with cloud-based solutions. Sauron was the only method that achieved a reduction in model size of over 90% without deteriorating substantially the performance. Sauron also achieved, overall, the fastest models at inference time in machines with and without GPUs. Finally, we show through experiments that the feature maps of models pruned with Sauron are highly interpretable, which is essential for medical image segmentation.},
  archive      = {J_NEUCOM},
  author       = {Juan Miguel Valverde and Artem Shatillo and Jussi Tohka},
  doi          = {10.1016/j.neucom.2024.127817},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127817},
  shortjournal = {Neurocomputing},
  title        = {Sauron U-net: Simple automated redundancy elimination in medical image segmentation via filter pruning},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-support matching networks with multiscale attention for
few-shot semantic segmentation. <em>NEUCOM</em>, <em>594</em>, 127811.
(<a href="https://doi.org/10.1016/j.neucom.2024.127811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Few-shot segmentation (FSS) have displayed remarkable capabilities in predicting segmentation masks for unseen class images, using only a limited number of annotated images. However, existing methods have overlooked the influence of contextual information on segmentation and primarily rely on supporting prototypes, with limited research on query prototyping. Effectively utilizing multi-scale features and query information poses a challenging problem in this domain. To address these challenges, this paper proposes a novel approach called the multi-scale and attention-based self-support prototype few-shot semantic segmentation network (MASNet). First, a multi-scale feature enhancement module is designed to obtain features at different scales to enrich global context information. Then, simple and efficient channel attention is utilized to guide the query features related to the target class. Finally, the query prototype is matched with the query features using a self-supporting matching module. This strategy efficiently captures class-based features and addresses the issue of intra-class variance in few-shot segmentation. The experimental results on Pascal-5i, COCO-20i and Abdominal MRI datasets demonstrate that the proposed method achieves remarkable robustness and improved accuracy performance.},
  archive      = {J_NEUCOM},
  author       = {Yafeng Yang and Yufei Gao and Lin Wei and Mengyang He and Yucheng Shi and Hailing Wang and Qing Li and Zhiyuan Zhu},
  doi          = {10.1016/j.neucom.2024.127811},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127811},
  shortjournal = {Neurocomputing},
  title        = {Self-support matching networks with multiscale attention for few-shot semantic segmentation},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ARIoU: Anchor-free rotation-decoupling IoU-based
optimization for 3D object detection. <em>NEUCOM</em>, <em>594</em>,
127807. (<a href="https://doi.org/10.1016/j.neucom.2024.127807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rotation-decoupling strategy was developed in outdoor 3D object detection with certain performance improvement. However, its anchor-based architecture limits its further improvement in indoor 3D object detection. In this study, we propose an Anchor-free Rotation-decoupling IoU-based optimization, termed ARIoU, which is specifically devised to indoor 3D object detection. A pivotal aspect of our approach is a customized encoding–decoding scheme that integrates the anchor-free framework with the rotation decoupling strategy to mitigate the negative effect caused by rotation sensitivity. Specifically, the unwanted length/width/rotation prediction randomness induced by labeled rotation ambiguity is alleviated. Furthermore, we plug our ARIoU as the optimization targets in both classification and regression branches to solve the misalignment issue in predicting precision and confidence estimation. Experiments on the SUN RGB-D and S3DIS datasets demonstrate the effectiveness of our approach. Code is available at https://github.com/wenchened/ARIOU .},
  archive      = {J_NEUCOM},
  author       = {Chenyiming Wen and Hualian Sheng and Ming-Min Zhao and Min-Jian Zhao},
  doi          = {10.1016/j.neucom.2024.127807},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127807},
  shortjournal = {Neurocomputing},
  title        = {ARIoU: Anchor-free rotation-decoupling IoU-based optimization for 3D object detection},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep progressive feature aggregation network for multi-frame
high dynamic range imaging. <em>NEUCOM</em>, <em>594</em>, 127804. (<a
href="https://doi.org/10.1016/j.neucom.2024.127804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High dynamic range (HDR) imaging is an important task in image processing that aims to generate well-exposed images in scenes with varying illumination. Although existing multi-exposure fusion methods have achieved impressive results, generating high-quality HDR images in dynamic scenes remains difficult. The primary challenges are ghosting artifacts caused by object motion between low dynamic range images and distorted content in underexposure and overexposed regions. In this paper, we propose a deep progressive feature aggregation network for improving HDR imaging quality in dynamic scenes. To address the issues of object motion, our method implicitly samples high-correspondence features and aggregates them in a coarse-to-fine manner for alignment. In addition, our method adopts a densely connected network structure based on the discrete wavelet transform, which aims to decompose the input features into multiple frequency subbands and adaptively restore corrupted contents. Experiments show that our proposed method can achieve state-of-the-art performance under different scenes, compared to other promising HDR imaging methods. Specifically, the HDR images generated by our method contain cleaner and more detailed content, with fewer distortions, leading to better visual quality.},
  archive      = {J_NEUCOM},
  author       = {Jun Xiao and Qian Ye and Tianshan Liu and Cong Zhang and Kin-Man Lam},
  doi          = {10.1016/j.neucom.2024.127804},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127804},
  shortjournal = {Neurocomputing},
  title        = {Deep progressive feature aggregation network for multi-frame high dynamic range imaging},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiagent-based deep reinforcement learning framework for
multi-asset adaptive trading and portfolio management. <em>NEUCOM</em>,
<em>594</em>, 127800. (<a
href="https://doi.org/10.1016/j.neucom.2024.127800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The highly dynamic nature of stock markets has motivated researchers to propose various supervised learning models to assist investors to optimize financial performance. Machine learning models have been used to predict price trends, and approaches have been proposed for portfolio management. However, these studies focus on only one kind of financial issue, and the methods proposed exhibit poor generalizability. We address these problems with a multi-agent portfolio adaptive trading framework based on reinforcement learning to create an automated trading system with the best trading strategy that can be achieved by long-short situation judgment and adaptive capital allocation. We use the TD3 algorithm in the multi-agent algorithm to mitigate the overestimation and overfitting exhibited by traditional value functions and improve training stability. Experimental results show that the proposed framework outperforms single-agent reinforcement learning algorithms while achieving more stable returns.},
  archive      = {J_NEUCOM},
  author       = {Li-Chen Cheng and Jian-Shiou Sun},
  doi          = {10.1016/j.neucom.2024.127800},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127800},
  shortjournal = {Neurocomputing},
  title        = {Multiagent-based deep reinforcement learning framework for multi-asset adaptive trading and portfolio management},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scattering moment matching-based interpretable domain
adaptation for transfer diagnostic tasks. <em>NEUCOM</em>, <em>594</em>,
127699. (<a href="https://doi.org/10.1016/j.neucom.2024.127699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One significant fact familiar to the signal processing-based diagnostic community but generally ignored by the transfer learning-based diagnostic community is that the cyclostationarity of the monitored signal conveys the actual diagnostic information. Popular network architectures, e.g. , ResNet, and domain discrepancy metrics, e.g. , maximum mean discrepancy, in current transfer diagnostic research are generally borrowed from the transfer learning community yet do not explicitly consider machine fault physics. As Jérôme Antoni points out, signal processing and machine learning methods are not mutually exclusive but should complement each other. The current article aims to develop an interpretable domain adaptation method for transfer diagnostic tasks by simultaneously exploiting the ideas of cyclostationary signal processing and domain adaptation techniques. By taking NTScatNet as the network backbone and scattering moment distance as the domain discrepancy metric, the proposed scattering moment matching-based domain adaptation method is more interpretable and matches fault physics better than conventional deep transfer learning methods. Besides, the proposed method does not require target domain data during the training phase, thus relaxing the assumption of standard domain adaptation. The effectiveness and superiority of the proposed domain adaptation method were verified on four transfer diagnostic case studies, i.e. , transfer diagnostic across bearing specifications, transfer diagnostic across escalator roller specifications, transfer diagnostic across transducers on bearing datasets, and transfer diagnostic across transducers on the gearbox datasets.},
  archive      = {J_NEUCOM},
  author       = {Chao Liu and Tianyu Han and Gang Zhang and Haoran Sun and Xi Shi},
  doi          = {10.1016/j.neucom.2024.127699},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127699},
  shortjournal = {Neurocomputing},
  title        = {Scattering moment matching-based interpretable domain adaptation for transfer diagnostic tasks},
  volume       = {594},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An indicator-based evolutionary algorithm with adaptive
archive update cycle for multi-objective multi-robot task allocation.
<em>NEUCOM</em>, <em>593</em>, 127836. (<a
href="https://doi.org/10.1016/j.neucom.2024.127836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-robot task allocation problem has garnered significant attention in research and development. This paper addresses the multi-robot task allocation problem by introducing a unified model that seamlessly transforms into four popular mathematical models through simple parameter adjustments. We propose an efficient indicator-based multi-objective evolutionary algorithm with a hybrid encoding scheme for task execution order and robot starting point information. The algorithm employs the hypervolume indicator for environmental selection to enhance convergence and the modified crowding distance for archive updates to promote diversity. Additionally, an adaptive archive update mechanism is designed for time efficiency. In experiments comparing our proposed algorithm with 8 state-of-the-art algorithms on 18 randomly generated instances of various sizes, along with 4 real-world problems from the TSPLIB benchmark, our algorithm consistently outperformed the comparison algorithms in five key indicators. These results underscore the effectiveness of our approach in addressing real-world multi-robot task allocation problems.},
  archive      = {J_NEUCOM},
  author       = {Chengxin Wen and Hongbin Ma},
  doi          = {10.1016/j.neucom.2024.127836},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127836},
  shortjournal = {Neurocomputing},
  title        = {An indicator-based evolutionary algorithm with adaptive archive update cycle for multi-objective multi-robot task allocation},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolution-guided value iteration for optimal tracking
control. <em>NEUCOM</em>, <em>593</em>, 127835. (<a
href="https://doi.org/10.1016/j.neucom.2024.127835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, an evolution-guided value iteration (EGVI) algorithm is established to address optimal tracking problems for nonlinear nonaffine systems. Conventional adaptive dynamic programming algorithms rely on gradient information to improve the policy, which adheres to the first order necessity condition. Nonetheless, these methods encounter limitations when gradient information is intricate or system dynamics lack differentiability. In response to this challenge, evolutionary computation is leveraged by EGVI to search for the optimal policy without requiring an action network. The competition within the policy population serves as the driving force for policy improvement. Therefore, EGVI can effectively handle complex and non-differentiable systems. Additionally, this innovative method has the potential to enhance exploration efficiency and bolster the robustness of algorithms due to its population-based characteristics. Furthermore, the convergence of the algorithm and the stability of the policy are investigated based on the EGVI framework. Finally, the effectiveness of the established method is comprehensively demonstrated through two simulation experiments.},
  archive      = {J_NEUCOM},
  author       = {Haiming Huang and Ding Wang and Mingming Zhao and Qinna Hu},
  doi          = {10.1016/j.neucom.2024.127835},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127835},
  shortjournal = {Neurocomputing},
  title        = {Evolution-guided value iteration for optimal tracking control},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). PCSformer: Pair-wise cross-scale sub-prototypes mining with
CNN-transformers for weakly supervised semantic segmentation.
<em>NEUCOM</em>, <em>593</em>, 127834. (<a
href="https://doi.org/10.1016/j.neucom.2024.127834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating initial seeds is an important step in weakly supervised semantic segmentation (WSSS). Our approach concentrates on generating and refining initial seeds. The convolutional neural networks (CNNs)–based initial seeds focus only on the most discriminative regions and lack global information about the target. The Vision Transformer (ViT)–based approach can capture long-range feature dependencies due to the unique advantage of the self-attention mechanism. Still, we find that it suffers from distractor object leakage and background leakage problems. Based on these observations, we propose PCSformer, which improves the model’s ability to extract features through a Pair-wise Cross-scale (PC) strategy and solves the problem of distractor object leakage by further extracting potential target features through Sub-Prototypes (SP) mining. In addition, the proposed Conflict Self-Elimination (CSE) module further alleviates the background leakage problem. We validate our approach on the widely adopted Pascal VOC 2012 and MS COCO 2014, and extensive experiments demonstrate our superior performance. Furthermore, our method proves to be competitive for WSSS in medical images and challenging scenarios involving deformable and cluttered scenes. Additionally, we extend the PCSformer to weakly supervised object localization tasks, further highlighting its scalability and versatility. The code is available at https://github.com/ChunmengLiu1/PCSformer .},
  archive      = {J_NEUCOM},
  author       = {Chunmeng Liu and Yao Shen and Qingguo Xiao and Guangyao Li},
  doi          = {10.1016/j.neucom.2024.127834},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127834},
  shortjournal = {Neurocomputing},
  title        = {PCSformer: Pair-wise cross-scale sub-prototypes mining with CNN-transformers for weakly supervised semantic segmentation},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semiglobal fixed/preassigned-time synchronization of
stochastic neural networks with random delay via adaptive control.
<em>NEUCOM</em>, <em>593</em>, 127832. (<a
href="https://doi.org/10.1016/j.neucom.2024.127832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents two kinds of novel results about semiglobal synchronization in probability for stochastic systems. To this end, new criteria of semiglobal fixed-time synchronization in probability (SFXTSp) and semiglobal preassigned-time synchronization in probability (SPATSp) are proposed. In contrast to the existing results of semiglobal synchronization in probability, our criteria have wider applicability in SFXTSp and SPATSp due to their flexible forms. Meanwhile, based on the properties of convex functions and Jensen’s inequality, our approaches overcome the issue arising from the non-equivalence between the Lyapunov function and its expectation, making our conclusions more rigorous. In addition, to achieve SFXTSp of stochastic neural networks with random delay (RDSNNs), a unified adaptive controller is developed. By modifying the parameters of the unified controller, RDSNNs reach SPATSp in a predetermined time. Ultimately, numerical simulations are conducted to confirm the practicality and accuracy of the derived outcomes.},
  archive      = {J_NEUCOM},
  author       = {Guanghui Jiang and Leimin Wang and Xiaofang Hu and Haoyu Li and Xiaofeng Zong},
  doi          = {10.1016/j.neucom.2024.127832},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127832},
  shortjournal = {Neurocomputing},
  title        = {Semiglobal fixed/preassigned-time synchronization of stochastic neural networks with random delay via adaptive control},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). No tricks no bluff, focusing on localizing crisp boundaries
in image media. <em>NEUCOM</em>, <em>593</em>, 127827. (<a
href="https://doi.org/10.1016/j.neucom.2024.127827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Boundary detection, as a fundamental task for computer vision applications, plays an important role in many tasks such as image deblurring, semantic segmentation, camouflaged object detection, and salient object detection. The thickness problem of boundary prediction is so prevalent in existing methods that NMS has to be used as a post-processing method to thin the prediction boundaries. However, we believe that additional post-processing does not constitute an end-to-end behavior, and the results obtained do not reflect the true boundary localization capabilities of the algorithm. In comparison to the superior end-to-end approach, NMS reveals notable limitations in rectifying erroneous predictions and achieving high-quality results similar to the ground truth. Furthermore, the use of NMS will inevitably compromise the prediction of fragile boundaries. Therefore, we remove the NMS step from the boundary detection process and generalize two reasons for the detector’s poor ability to localize crisp boundaries: boundary blurring and static cues. Aliasing region loss ( L a r Lar ) and hollow region loss ( L h r Lhr ) are introduced to mitigate the occurrence of false positives in various types of regions, thereby addressing the issue of boundary blurring. For static cues, we propose a dimension attention (DimAttn) module which can realize multidimensional and multi-range clew interaction. In fact, our method can be plug-and-play in any existing boundary detection model. Extensive experiments have demonstrated that the boundary prediction results of the proposed framework are crisper and exhibit remarkable superiority in detecting fragile boundaries compared with scenarios utilizing NMS.},
  archive      = {J_NEUCOM},
  author       = {Jianhang Zhou and Hongwei Zhao and Haoyu Zhao and Pengyu Mu and Long Xing and Mingsi Sun},
  doi          = {10.1016/j.neucom.2024.127827},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127827},
  shortjournal = {Neurocomputing},
  title        = {No tricks no bluff, focusing on localizing crisp boundaries in image media},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive neural quantized control for full-state constrained
markov jumping nonlinear systems with incomplete transition
probabilities and unknown control directions. <em>NEUCOM</em>,
<em>593</em>, 127821. (<a
href="https://doi.org/10.1016/j.neucom.2024.127821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article devises an adaptive quantized control scheme for full-state constrained Markov jumping nonlinear systems with incomplete transition probabilities and unknown control directions. First, the barrier Lyapunov functions were utilized to achieve full-state constraints on the investigated system, while the Nussbaum function has been adopted to overcome the issue of unknown control directions. Then, by means of command filtered backstepping control technique, an adaptive quantized controller is developed, where an improved error compensation mechanism was established to eliminate the effect of filter error, and a hysteresis quantizer was employed to diminish the transmission rate. Furthermore, it is demonstrated that the designed controller assures that all signals of the closed-loop system are bounded in the mean square sense. Finally, two illustrative examples were provided to validate the effectiveness of the proposed control method.},
  archive      = {J_NEUCOM},
  author       = {Xiaona Song and Junjie Zhang and Shuai Song},
  doi          = {10.1016/j.neucom.2024.127821},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127821},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural quantized control for full-state constrained markov jumping nonlinear systems with incomplete transition probabilities and unknown control directions},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A parameterised model for link prediction using node
centrality and similarity measure based on graph embedding.
<em>NEUCOM</em>, <em>593</em>, 127820. (<a
href="https://doi.org/10.1016/j.neucom.2024.127820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction is a crucial aspect of graph machine learning, with applications as diverse as disease prediction, social network recommendations, and drug discovery. It involves the prediction of potential new links between nodes within a network. Despite its importance, current models for link prediction exhibit notable limitations. Graph Convolutional Networks have shown high efficiency in link prediction across various datasets. However, they face significant challenges when applied to short-path networks and ego networks, resulting in poor performance. This issue represents a critical area of concern that our work seeks to address. This paper introduces the Node Centrality and Similarity-based Parameterised Model (NCSM), a novel method for link prediction tasks. NCSM uniquely integrates node centrality and similarity measures as edge features in a customised Graph Neural Network (GNN) layer, effectively leveraging the topological information of large networks. This model represents the first parameterised GNN-based link prediction model that considers topological information. The proposed model was evaluated on five benchmark graph datasets, each comprising thousands of nodes and edges. Experimental results highlight NCSM&#39;s superiority over existing state-of-the-art models like Graph Convolutional Networks and Variational Graph Autoencoder, as it outperforms them across various metrics and datasets. This exceptional performance can be attributed to NCSM&#39;s innovative integration of node centrality, similarity measures, and its efficient use of topological information.},
  archive      = {J_NEUCOM},
  author       = {Haohui Lu and Shahadat Uddin},
  doi          = {10.1016/j.neucom.2024.127820},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127820},
  shortjournal = {Neurocomputing},
  title        = {A parameterised model for link prediction using node centrality and similarity measure based on graph embedding},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retinal disease diagnosis with unsupervised grad-CAM guided
contrastive learning. <em>NEUCOM</em>, <em>593</em>, 127816. (<a
href="https://doi.org/10.1016/j.neucom.2024.127816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To alleviate the reliance on expensive annotations, contrastive learning techniques have been applied to diagnose diseases from various types of medical images. However, popular contrastive learning methods, which generate positive pairs by random cropping, face challenges in diagnosing retinal diseases, due to the retinal disease’s characteristic that retinal lesions are tiny and randomly distributed in abnormal fundus images. These lesions may be missed after random cropping, resulting in semantically inconsistent positive pairs that hinder the effectiveness of contrastive learning for retinal disease diagnosis. To address this issue, we propose a novel unsupervised gradient-weighted class activation mapping (Grad-CAM) strategy to roughly locate lesions, thereby suppressing or even eliminating semantically inconsistent positive pairs. Specifically, we develop a gradient-weighted Class Activation Map guided Contrastive Learning (CAMCL) method with two branches for the Grad-CAM based instance discrimination task and the k-nearest neighbors (KNN)-based cluster-wise discrimination task, respectively. By minimizing the KNN loss, the cluster-wise discrimination branch learns high-level representations containing class semantic information. This is then followed by gradient back-propagation to generate Grad-CAM heatmaps from unlabeled data. The generated heatmaps can highlight class-discriminative regions in abnormal fundus images (e.g., retinal lesions) to identify semantically consistent positive pairs while suppressing inconsistent ones. The semantically consistent positive pairs are then input to the instance discrimination task for contrastive learning. In this manner, the semantic inconsistency problem is relieved, and the improved contrastive learning pipeline can be effectively used for retinal disease diagnosis. Experimental results on five retinal disease classification datasets show that our model surpasses other contrastive learning methods, indicating a promising approach for clinical application.},
  archive      = {J_NEUCOM},
  author       = {Zhongchen Zhao and Huai Chen and Yu-ping Wang and Deyu Meng and Qi Xie and Qi Yu and Lisheng Wang},
  doi          = {10.1016/j.neucom.2024.127816},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127816},
  shortjournal = {Neurocomputing},
  title        = {Retinal disease diagnosis with unsupervised grad-CAM guided contrastive learning},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SRFDet3D: Sparse region fusion based 3D object detection.
<em>NEUCOM</em>, <em>593</em>, 127814. (<a
href="https://doi.org/10.1016/j.neucom.2024.127814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlike the earlier 3D object detection approaches that formulate hand-crafted dense (in thousands) object proposals by leveraging anchors on dense feature maps, we formulate n p np (in hundreds) number of learnable sparse object proposals to predict 3D bounding box parameters. The sparse proposals in our approach are not only learnt during training but also are input-dependent, so they represent better object candidates during inference. Leveraging the sparse proposals, we fuse only the sparse regions of multi-modal features and we propose S parse R egion F usion based 3D object Det ection (SRFDet3D) network with mainly three components: an encoder for feature extraction, a region proposal generation module for sparse input-dependent proposals and a decoder for multi-modal feature fusion and iterative refinement of object proposals. Additionally for optimal training, we formulate our sparse detector with many-to-one label assignment based on Optimal Transport Algorithm (OTA). We conduct extensive experiments and analysis on publicly available large-scale autonomous driving datasets: nuScenes, KITTI, and Waymo. Our LiDAR-only SRFDet3D-L network achieves 63.1 mAP and outperforms the state-of-the-art networks on the nuScenes dataset, surpassing the dense detectors on KITTI and Waymo datasets. Our LiDAR-Camera model SRFDet3D achieves 64.7 mAP with improvements over existing fusion methods.},
  archive      = {J_NEUCOM},
  author       = {Gopi Krishna Erabati and Helder Araujo},
  doi          = {10.1016/j.neucom.2024.127814},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127814},
  shortjournal = {Neurocomputing},
  title        = {SRFDet3D: Sparse region fusion based 3D object detection},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PNNCLR: Stochastic pseudo neighborhoods for contrastive
learning based unsupervised representation learning problems.
<em>NEUCOM</em>, <em>593</em>, 127810. (<a
href="https://doi.org/10.1016/j.neucom.2024.127810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nearest neighbor (NN) sampling provides more semantic variations than predefined transformations for self-supervised learning (SSL) based image recognition problems. However, its performance is restricted by the quality of the support set, which holds positive samples for the contrastive loss. In this work, we show that the quality of the support set plays a crucial role in any nearest neighbor based method for SSL. We then provide a refined baseline (pNNCLR) to the nearest neighbor based SSL approach (NNCLR). To this end, we introduce pseudo nearest neighbors (pNN) to control the quality of the support set, wherein, rather than sampling the nearest neighbors, we sample in the vicinity of hard nearest neighbors by varying the magnitude of the resultant vector and employing a stochastic sampling strategy to improve the performance. Additionally, to stabilize the effects of uncertainty in NN-based learning, we employ a smooth-weight-update approach for training the proposed network. Evaluation of the proposed method on multiple public image recognition and medical image recognition datasets shows that it performs up to 8 percent better than the baseline nearest neighbor method, and is comparable to other previously proposed SSL methods. The code is available at https://github.com/mb16biswas/pnnclr .},
  archive      = {J_NEUCOM},
  author       = {Momojit Biswas and Himanshu Buckchash and Dilip K. Prasad},
  doi          = {10.1016/j.neucom.2024.127810},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127810},
  shortjournal = {Neurocomputing},
  title        = {PNNCLR: Stochastic pseudo neighborhoods for contrastive learning based unsupervised representation learning problems},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weighted parallel decoupled feature pyramid network for
object detection. <em>NEUCOM</em>, <em>593</em>, 127809. (<a
href="https://doi.org/10.1016/j.neucom.2024.127809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most representative detectors, feature pyramid network (FPN) has achieved remarkable improvement in object detection. Thanks to its distinctive top-down feature fusion path and multi-scale detection paradigm, FPN has become an essential component in modern detectors and has attracted increasing attention. Nevertheless, since the information of each level feature is not object-specific and the heterogeneity of classification and localization tasks in detection, FPN and its numerous variants endure information redundancy and task conflict. To address these two deficiencies that greatly limit the detection performance, this paper proposes weighted parallel decoupled FPN (WPDFPN). Specifically, selective fusion and elimination (SFE) focusing on internal construction of pyramid is first proposed. Compared to existing feature fusion methods, SFE effectively fuses complementary information between different level features and eliminates redundant information to produce object-specific feature at each pyramid level. Then, a novel weighted parallel FPN (WPFPN) is constructed by investigating the combination manners of feature fusion paths. Different from the sequential bidirectional pyramids, WPFPN performs the top-down and bottom-up paths in parallel and aggregates them using a weighted strategy, adaptively integrating object semantics and details. On this basis, feature decoupling mechanism and decoupled head are both developed to learn task-specific features for classification and localization, thus effectively mitigating the task conflict. Without bells and whistles, WPDFPN achieves 43.6 AP on the MS COCO dataset with ResNet-101 as backbone in Faster R-CNN framework. This achievement suppresses the baseline FPN by 3.1 points and demonstrates competitive performance in comparison with some state-of-the-art detectors. Code is available at https://github.com/HB-X/WPDFPN .},
  archive      = {J_NEUCOM},
  author       = {Bo Han and Lihuo He and Junjie Ke and Chenwei Tang and Xinbo Gao},
  doi          = {10.1016/j.neucom.2024.127809},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127809},
  shortjournal = {Neurocomputing},
  title        = {Weighted parallel decoupled feature pyramid network for object detection},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sentence salience contrastive learning for abstractive text
summarization. <em>NEUCOM</em>, <em>593</em>, 127808. (<a
href="https://doi.org/10.1016/j.neucom.2024.127808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstractive Text summarization aims to generate a short summary for a document while preserving salient information. Recently, contrastive learning has been extended from visual representation to summarization tasks. At present, the methods of contrastive learning summarization focus on modeling the global semantics of source documents, targets and candidate summaries to maximize their similarities. However, they ignore the influence of sentence semantics in the document. In this paper, we propose a sentence-level salience contrastive learning method to help the model capture salient information and denoise. The model expresses the sentence salience according to the semantic similarity between the summaries and sentences of the source document, and integrates the similarity distance into the contrastive loss in the form of soft weights. Therefore, our model maximize the similarity between summaries and salient information, while minimizing the similarity between summaries and potential noise. We have verified our method in three widely used datasets, CNN/Daily Mail, XSum and PubMed. The experimental results show that the proposed method can significantly improve the baseline performance and achieve competitive performance in the existing contrastive learning methods.},
  archive      = {J_NEUCOM},
  author       = {Ying Huang and Zhixin Li and Zhenbin Chen and Canlong Zhang and Huifang Ma},
  doi          = {10.1016/j.neucom.2024.127808},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127808},
  shortjournal = {Neurocomputing},
  title        = {Sentence salience contrastive learning for abstractive text summarization},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analyzing and interpreting convolutional neural networks
using latent space topology. <em>NEUCOM</em>, <em>593</em>, 127806. (<a
href="https://doi.org/10.1016/j.neucom.2024.127806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of explainability methods for Convolutional Neural Networks (CNNs), under the growing framework of e x plainable Artificial Intelligence (xAI) for image understanding, is crucial due to neural networks success in contrast with their black box nature. However, usual methods focus on image visualizations and are inadequate to analyze the encoded contextual information (that captures the spatial dependencies of pixels considering their neighbors), as well as to explain the evolution of learning across layers without degrading the information. To address the latter, this paper presents a novel explanatory method based on the study of the latent representations of CNNs through their topology, and supported by Topological Data Analysis (TDA). For each activation layer after a convolution, the pixel values of the activation maps along the channels are considered latent space points. The persistent homology of this data is summarized via persistence landscapes, called Latent Landscapes. This provides a global view of how contextual information is being encoded, its variety and evolution, and allows for statistical analysis. The applicability and effectiveness of our approach is demonstrated by experiments conducted with CNNs trained on distinct datasets: (1) two U-Net segmentation models on RGB and pseudo-multiband images (generated by considering vegetation indices) from the agricultural benchmark CRBD were evaluated, in order to explain the difference in performance; and (2) a VGG-16 classification network on CIFAR-10 (RGB) was analyzed, showing how the information evolves within the network. Moreover, comparisons with state-of-the-art methods (Grad-CAM and occlusion) prove the consistency and validity of our proposal. It offers novel insights into the decision making process and helps to compare how models learn.},
  archive      = {J_NEUCOM},
  author       = {Clara I. López-González and María J. Gómez-Silva and Eva Besada-Portas and Gonzalo Pajares},
  doi          = {10.1016/j.neucom.2024.127806},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127806},
  shortjournal = {Neurocomputing},
  title        = {Analyzing and interpreting convolutional neural networks using latent space topology},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PRISM: Deep metric learning based personal grouping method
to reduce intersubject variability for motor imagery brain–computer
interface. <em>NEUCOM</em>, <em>593</em>, 127805. (<a
href="https://doi.org/10.1016/j.neucom.2024.127805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor imagery brain–computer interfaces (MI–BCIs) that use electroencephalogram (EEG) signals are essential for motor rehabilitation. One of the most important problems in MI–BCIs is intersubject variability, as brain signals can vary significantly among individuals due to differences in cognitive processing and mental states. To address this issue, some studies have proposed intrasubject learning models that train and evaluate within specific individuals, while others have suggested intersubject learning models that aim to generalize across subjects. However, insufficient data are available for intrasubject learning, so they cannot use a deep learning model, and still, the problem of intersubject variability is unsolved in intersubject learning. To tackle these challenges, we developed a new framework based on deep metric learning called the Personal grouping method for Reducing InterSubject variability using deep Metric learning (PRISM). PRISM aims to reduce intersubject variability by calculating the similarity between subjects based on their EEG signals and generating clusters. Based on these clusters, the model can train by reducing intersubject variability while maintaining the advantage of intersubject learning. Our thorough evaluation indicates that PRISM is poised to redefine the standards in MI–BCIs, significantly alleviating the challenges of intersubject variability. We compared the performance of PRISM and the existing learning paradigm, and the performance of PRISM was similar to that of the intrasubject learning model (p &gt; &amp;gt; 0.4), which is the best existing model, and it performed better than the intersubject learning model (**p &lt; &amp;lt; 0.001). Our results indicate that the PRISM framework outperforms intersubject learning and closely matches intrasubject learning models. This suggests that PRISM combines the specificity of intrasubject learning with intersubject model generalizability, thereby enhancing performance.},
  archive      = {J_NEUCOM},
  author       = {Kyungdo Kim and Kwangsoo Kim and Seung-Bo Lee},
  doi          = {10.1016/j.neucom.2024.127805},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127805},
  shortjournal = {Neurocomputing},
  title        = {PRISM: Deep metric learning based personal grouping method to reduce intersubject variability for motor imagery brain–computer interface},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Double reuses based residual network. <em>NEUCOM</em>,
<em>593</em>, 127803. (<a
href="https://doi.org/10.1016/j.neucom.2024.127803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep residual network (ResNet) had shown remarkable performance in image recognition tasks, due to its shorter connections between layers close to the input and those close to the output. And densely connected convolutional network (DenseNet) had further improved recognition performance by dense feature reuses. To improve the performance of residual units in ResNet and feature reuses in DenseNet, we propose a simple and effective convolutional network architecture, named double reuses based residual network (DRRNet). DRRNet improves the residual unit of ResNet, where the feature reuse connections are added to combine all feature maps from the convolutional layers to produce the residual, and uses a residual reuse path outside units to reuse all residuals as the final feature maps for classification. Residual learning used in DRRNet can alleviate the vanishing-gradient problem. The double reuses including inner-unit feature reuses and outer-unit residual reuses effectively decrease computational cost as compared with dense connections in DenseNet, and further strengthen the forward feature propagation. DRRNet is evaluated on three object recognition benchmark datasets and an object detection dataset. In comparison with the state-of-the-art, DRRNet achieves a good balance between classification accuracy and computational cost, and optimal detection performance.},
  archive      = {J_NEUCOM},
  author       = {Qian Liu and Yixiong Zhong},
  doi          = {10.1016/j.neucom.2024.127803},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127803},
  shortjournal = {Neurocomputing},
  title        = {Double reuses based residual network},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). An autonomous stair climbing method for the crawler robot
based on a hybrid reinforcement learning controller. <em>NEUCOM</em>,
<em>593</em>, 127802. (<a
href="https://doi.org/10.1016/j.neucom.2024.127802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to problems in using deep reinforcement learning to perform the stair climbing task for the crawler robot, such as the lack of theoretical values for stair size range, the inaccurate force on the model using wheel to simulate track and difficulty in training, we propose an autonomous stair climbing method for the crawler robot based on a hybrid reinforcement learning controller. We propose a dynamics parameter settings method for fast simulation model by studying the distribution model of the ground pressure of the track, which improves the accuracy of the force on the fast simulation model in the stair climbing task. Our method calculates the climbing ability of the crawler robot by studying the kinematics and dynamics models of the real crawler robot in each stage of the stair climbing task, and combining with the control flow of the hybrid reinforcement learning controller. Further, we develop the training course of the hybrid reinforcement learning controller. The agent is trained in ROS-Gazebo. The course reduces the impact of poor trajectory on training, achieves higher success rates and faster convergence speed compared to random training, and effectively improves the generalization ability of the strategy.},
  archive      = {J_NEUCOM},
  author       = {Sheng Zhang and Jianzhong Wang and Endi Wang and Yong Sun},
  doi          = {10.1016/j.neucom.2024.127802},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127802},
  shortjournal = {Neurocomputing},
  title        = {An autonomous stair climbing method for the crawler robot based on a hybrid reinforcement learning controller},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KFEX-n: A table-text data question-answering model based on
knowledge-fusion encoder and EX-n tree decoder. <em>NEUCOM</em>,
<em>593</em>, 127795. (<a
href="https://doi.org/10.1016/j.neucom.2024.127795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Answering questions about hybrid data combining tables and text is challenging. Recent research has employed encoder-tree decoder frameworks to simulate the reasoning process of arithmetic expressions for generating answers. However, this approach overlooks the inherent diversity of expressions; there might be multiple valid reasoning paths, leading to a decrease in the accuracy of inferred expression trees. Moreover, encoders, lacking rich domain knowledge, struggle to capture deep relationships between questions and supporting evidence; this limitation results in models making errors when selecting operation units. In this paper, we propose a Knowledge-Fusion encoder and EX-N tree decoder table-text data question-answering model(KFEX-N). During the encoding process, the integration of traditional encoders with cross-fusion encoders forms a knowledge-fusion encoder, endowing the model with rich domain knowledge and enhancing its understanding of the operational units required to answer questions. Additionally, we propose an EX-N tree decoder. It reduces the diversity of inference paths through a constrained structure and mitigates the occurrence of final answer errors resulting from decoding errors. We validate our model using publicly available Table-Text QA datasets (TAT-QA and Fin-QA) and achieve state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Ye Tao and Jiawang Liu and Hui Li and Wenqian Cao and Xiugong Qin and Yunlong Tian and Yongjie Du},
  doi          = {10.1016/j.neucom.2024.127795},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127795},
  shortjournal = {Neurocomputing},
  title        = {KFEX-N: A table-text data question-answering model based on knowledge-fusion encoder and EX-N tree decoder},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Directional cooperative networks. <em>NEUCOM</em>,
<em>593</em>, 127788. (<a
href="https://doi.org/10.1016/j.neucom.2024.127788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although various machine learning methods have been proposed for industrial applications, there are not many examples of their application in some industrial sectors. Data collected within organizations are inconsistently formatted and expensive to annotate, resulting in insufficient datasets for training. This hinders the widespread use of machine learning methods. The challenge is to address the need for more performance of machine learning models due to the lack of available data. We address this problem by introducing Directed Cooperative Networks (DCNs). This approach addresses the lack of data by connecting two neural networks with a function that evaluates the output of Generator. Estimator, the one of the networks, acts as an approximate function of the evaluation function, assisting Generator to output a product that yields the desired evaluation function value. When the networks are sufficiently trained, Estimator’s output approaches the output of the evaluation function, and Generator will produce products with the desired attributes. A data-independent method is the evolutionary algorithm (EA). Since EA is optimized by feedback from the environment, good results can be obtained by using the evaluation function of the product as its environment. However, its effectiveness decreases as the combination of product components becomes more complex. One of the outstanding properties of DCN is its potential to outperform EA on complex problems because it learns using the gradient of the search field. DCN does not require rewriting the evaluation function into a back-propagatable form, even if the function is complex. Using a neural network that behaves as an approximate function of the evaluation function, the gradient descent method can be applied even if the evaluation function is non-differentiable. To validate the effectiveness of the proposed method, DCN is applied to a molecular search task and analyzed in comparison with other approaches. This study aims to demonstrate the superior performance of DCN in dealing with data shortages in complex problems in industrial applications.},
  archive      = {J_NEUCOM},
  author       = {Yasuaki Ito and Le-Minh Nguyen},
  doi          = {10.1016/j.neucom.2024.127788},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127788},
  shortjournal = {Neurocomputing},
  title        = {Directional cooperative networks},
  volume       = {593},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Unveiling the potential of progressive training diffusion
model for defect image generation and recognition in industrial
processes. <em>NEUCOM</em>, <em>592</em>, 127837. (<a
href="https://doi.org/10.1016/j.neucom.2024.127837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial defect image generation is a crucial technique for augmenting defect image data, catering to fulfill the exigencies of training data necessary for defect recognition methods. In recent years, generative adversarial networks have seen widespread use in generating defect images. However, constrained by the scarcity of training data and the intricate variability in various defect categories, the existing methods are susceptible to issues such as training instability, a dearth of diversity, and suboptimal image quality. To overcome these challenges, this paper proposes a defect image generation framework based on a progressive training diffusion model (PTDM). Firstly, this study adopts a denoising diffusion model, supplanting traditional generative adversarial networks, to mitigate issues related to training instability and the dearth of diversity observed in generated images. Secondly, a novel progressive training strategy based on the self-designed image quality evaluator is developed to efficiently generate numerous defect images while maintaining quality. Finally, extensive experiments on a steel surface defect image dataset were conducted to validate the performance of the proposed framework in defect image generation and recognition tasks.},
  archive      = {J_NEUCOM},
  author       = {Yalin Wang and Zexiong Zhou and Xujie Tan and Yuqing Pan and Junqi Yuan and Zhifeng Qiu and Chenliang Liu},
  doi          = {10.1016/j.neucom.2024.127837},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127837},
  shortjournal = {Neurocomputing},
  title        = {Unveiling the potential of progressive training diffusion model for defect image generation and recognition in industrial processes},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-stage fine-tuning with ChatGPT data augmentation for
learning class-imbalanced data. <em>NEUCOM</em>, <em>592</em>, 127801.
(<a href="https://doi.org/10.1016/j.neucom.2024.127801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of long-tailed distributed data is a challenging problem, which suffers from serious class imbalance and hence poor performance on tail classes, which have only a few samples. Owing to this paucity of samples, learning on the tail classes is especially challenging for fine-tuning when transferring a pretrained model to a downstream task. In this work, we present a simple modification of standard fine-tuning to cope with these challenges. Specifically, we propose a two-stage fine-tuning. In Stage 1, we fine-tune the final layer of the pretrained model with class-balanced augmented data, generated using ChatGPT. As a large generative language model, ChatGPT is capable of generating novel and contextually similar responses to a given prompt, which makes it an excellent candidate for data augmentation. In Stage 2, we perform the standard fine-tuning. Our modification has several benefits: (1) it leverages pretrained representations by only fine-tuning a small portion of the model parameters while keeping the rest untouched; (2) it allows the model to learn an initial representation of the specific task; and importantly (3) it protects the learning of tail classes from being at a disadvantage during the model updating. We conduct extensive experiments on synthetic datasets of both two-class and multi-class tasks of text classification as well as a real-world application to ADME (i.e., absorption, distribution, metabolism, and excretion) semantic drug labeling. The experimental results show that the proposed two-stage fine-tuning outperforms vanilla fine-tuning and state-of-the-art methods on the above datasets.},
  archive      = {J_NEUCOM},
  author       = {Taha ValizadehAslani and Yiwen Shi and Jing Wang and Ping Ren and Yi Zhang and Meng Hu and Liang Zhao and Hualou Liang},
  doi          = {10.1016/j.neucom.2024.127801},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127801},
  shortjournal = {Neurocomputing},
  title        = {Two-stage fine-tuning with ChatGPT data augmentation for learning class-imbalanced data},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient image denoising with heterogeneous kernel-based
CNN. <em>NEUCOM</em>, <em>592</em>, 127799. (<a
href="https://doi.org/10.1016/j.neucom.2024.127799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in deep learning have notably advanced the field of image denoising. Yet, blindly increasing the depth or width of convolutional neural networks (CNNs) cannot ameliorate the network effectively, and even leads to training difficulties and sophisticated training tricks. In this paper, a lightweight CNN with heterogeneous kernels (HKCNN) is designed for efficient noise removal. HKCNN comprises four modules: a multiscale block (MB), an attention enhancement block (AEB), an elimination block (EB), and a construct block (CB). Specifically, the MB leverages heterogeneous kernels alongside re-parameterization to capture diverse complementary structure information, bolstering discriminative ability and the denoising robustness of the denoiser. The AEB incorporates an attention mechanism that prioritizes salient features, expediting the training stage and boosting denoising efficacy. The EB and CB are designed to further suppress noise and reconstruct latent clean images. Besides, the HKCNN integrates perceptual loss for both retaining semantic details and improving image perceptual quality, so as to refine the denoising output. Comprehensive qualitative and quantitative evaluations highlight the superior performance of HKCNN over state-of-the-art denoising methods, validating its efficacy in practical image denoising scenarios.},
  archive      = {J_NEUCOM},
  author       = {Yuxuan Hu and Chunwei Tian and Jian Zhang and Shichao Zhang},
  doi          = {10.1016/j.neucom.2024.127799},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127799},
  shortjournal = {Neurocomputing},
  title        = {Efficient image denoising with heterogeneous kernel-based CNN},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards algorithms and models that we can trust: A
theoretical perspective. <em>NEUCOM</em>, <em>592</em>, 127798. (<a
href="https://doi.org/10.1016/j.neucom.2024.127798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade it became increasingly apparent the inability of technical metrics such as accuracy, sustainability, and non-regressiveness to well characterize the behavior of intelligent systems. In fact, they are nowadays requested to meet also ethical requirements such as explainability, fairness, robustness, and privacy increasing our trust in their use in the wild. Of course often technical and ethical metrics are in tension between each other but the final goal is to be able to develop a new generation of more responsible and trustworthy machine learning. In this paper, we focus our attention on machine learning algorithms and associated predictive models, questioning for the first time, from a theoretical perspective, if it is possible to simultaneously guarantee their performance in terms of both technical and ethical metrics towards machine learning algorithms that we can trust. In particular, we will investigate for the first time both theory and practice of deterministic and randomized algorithms and associated predictive models showing the advantages and disadvantages of the different approaches. For this purpose we will leverage the most recent advances coming from the statistical learning theory: Complexity-Based Methods, Distribution Stability, PAC-Bayes, and Differential Privacy. Results will show that it is possible to develop consistent algorithms which generate predictive models with guarantees on multiple trustworthiness metrics.},
  archive      = {J_NEUCOM},
  author       = {Luca Oneto and Sandro Ridella and Davide Anguita},
  doi          = {10.1016/j.neucom.2024.127798},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127798},
  shortjournal = {Neurocomputing},
  title        = {Towards algorithms and models that we can trust: A theoretical perspective},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relation-aware heterogeneous graph neural network for entity
alignment. <em>NEUCOM</em>, <em>592</em>, 127797. (<a
href="https://doi.org/10.1016/j.neucom.2024.127797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity alignment refers to finding equivalent entities from different knowledge graphs. Most of the existing entity alignment methods are studied based on homogeneous graphs. However, the knowledge graph is a heterogeneous graph containing many types of nodes, such as entities, relations, and attributes. Therefore, we propose introducing a heterogeneous graph neural network to model entities and relations simultaneously and propose an iterative fusion method to enhance the interaction between these two semantic nodes. Since not all datasets contain relation information, this paper does not directly introduce a feature representation of relations. The generalizability of the approach is improved by utilizing a relation-aware strategy to obtain information about the relation. Specifically, the information propagation of the head and tail entities in the triplet is utilized to obtain the feature representation of the relation. Experimental results show that the present method performs better on three cross-lingual datasets D B P 15 K DBP15K and two large-scale datasets D W Y 100 K DWY100K .},
  archive      = {J_NEUCOM},
  author       = {Zirui Zhang and Yiyu Yang and Benhui Chen},
  doi          = {10.1016/j.neucom.2024.127797},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127797},
  shortjournal = {Neurocomputing},
  title        = {Relation-aware heterogeneous graph neural network for entity alignment},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Observer-based adaptive neutral network inverse optimal
containment control for nonlinear multiagent systems with input
quantization. <em>NEUCOM</em>, <em>592</em>, 127796. (<a
href="https://doi.org/10.1016/j.neucom.2024.127796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on the issue of addressing an adaptive neural network (NN) inverse optimal containment control for nonlinear multiagent systems (MASs), which are subject to immeasurable states and quantized input signals simultaneously. To tackle this problem, we utilize a NN to model unknown agents and design a NN observer to estimate the immeasurable states. Additionally, we decompose the hysteretic quantized input into two bounded nonlinear functions. By employing the adaptive backstepping approach and inverse optimal principle, we formulate an adaptive NN inverse optimal containment control method. The developed inverse optimal containment control scheme guarantees that the controlled system is input-to-state stabilizable (ISS). Finally, we validate the effectiveness of our proposed control scheme through simulation results.},
  archive      = {J_NEUCOM},
  author       = {Shiqi Wen and Shaocheng Tong},
  doi          = {10.1016/j.neucom.2024.127796},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127796},
  shortjournal = {Neurocomputing},
  title        = {Observer-based adaptive neutral network inverse optimal containment control for nonlinear multiagent systems with input quantization},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Private-preserving language model inference based on secure
multi-party computation. <em>NEUCOM</em>, <em>592</em>, 127794. (<a
href="https://doi.org/10.1016/j.neucom.2024.127794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the exponential expansion of Internet information, technology that combines big data and artificial intelligence has gradually developed. Pre-trained large-scale language models with the transformer architecture as the core have begun to be used in daily life, resulting in the huge market of MLaaS. leading to the significant market of Machine Learning as a Service (MLaaS). Although MLaaS brings huge benefits to users, it requires receiving users’ data for processing, which includes many sensitive data. While MLaaS offers considerable benefits, it necessitates processing users’ data, which includes much sensitive data.Therefore, the problem of privacy data leakage has also been exposed. In this article paper, we propose a novel language model secure inference scheme based on secure multi-party computation (MPC) technology. This solution involves three non-colluding parties: the data provider, the model provider, and the computing power provider. Compared with direct inference on pre-trained large models, the proposed security inference framework improves the inference speed by 1.55–6.25 times. Our findings demonstrate that, when compared to conventional inference methods on pre-trained large-scale models, our approach significantly enhances inference efficiency, achieving speed improvements ranging from 1.55 to 6.25 times.},
  archive      = {J_NEUCOM},
  author       = {Chen Song and Ruwei Huang and Sai Hu},
  doi          = {10.1016/j.neucom.2024.127794},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127794},
  shortjournal = {Neurocomputing},
  title        = {Private-preserving language model inference based on secure multi-party computation},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised detecting anomalies in multivariate time series
by robust convolutional LSTM encoder–decoder (RCLED). <em>NEUCOM</em>,
<em>592</em>, 127791. (<a
href="https://doi.org/10.1016/j.neucom.2024.127791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring modern industrial systems generates a large amount of multivariate time series data. One of the critical tasks of monitoring these systems is anomaly detection. The auto-encoder has emerged as a promising solution for detecting anomalies in systems lacking explicit anomaly data in their historical records; however, its performance can be sensitive to noisy data. This work aims at developing a robust anomaly detection model based on the autoencoder for multivariate time series. The autoencoder architecture consists of convolution, long short-term memory, and self-attention layers for better extraction of complex features from multivariate time series. In addition, a novel training technique, inherited from the idea of robust principal component analysis, was developed to efficiently train the proposed model when the input data is affected by noise. To evaluate the model’s performance, we tested it on two data sets: synthetic, real-industrial, and three public data. We also compare the performance of our model to that of the other state-of-the-art models. The results show that the proposed model outperforms all the latest models, especially when the noise level is considerable.},
  archive      = {J_NEUCOM},
  author       = {Tuan Le and Hai Canh Vu and Amélie Ponchet-Durupt and Nassim Boudaoud and Zohra Cherfi-Boulanger and Thao Nguyen-Trang},
  doi          = {10.1016/j.neucom.2024.127791},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127791},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised detecting anomalies in multivariate time series by robust convolutional LSTM Encoder–Decoder (RCLED)},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). CompleteDT: Point cloud completion with
information-perception transformers. <em>NEUCOM</em>, <em>592</em>,
127790. (<a href="https://doi.org/10.1016/j.neucom.2024.127790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a novel point cloud completion network, called CompleteDT. To fully capture the 3D geometric structure of point clouds, we introduce an Information-Perception Transformer (IPT) that can simultaneously capture local features and global geometric relations. CompleteDT comprises a Feature Encoder, Query Generator, and Query Decoder. Feature Encoder extracts local features from multi-resolution point clouds to capture intricate geometrical structures. Query Generator uses the proposed IPT, utilizing the Point Local Attention (PLA) and Point Global Attention (PGA) modules, to learn local features and global correlations, and generate query features that represent predicted point clouds. The PLA captures local information within local points by adaptively measuring weights of neighboring points, while PGA adapts multi-head self-attention by transforming it into a layer-by-layer form where each head learns global features in a high-dimensional space of different dimensions. By dense connections, the module allows for direct information exchange between each head and facilitates the capture of long global correlations. By combining the strengths of both PLA and PGA, the IPT can fully leverage local and global features to facilitate CompleteDT to complete point clouds. Lastly, the query features undergo refining to generate a complete point cloud through the Query Decoder. Our experimental results demonstrate that CompleteDT outperforms current state-of-the-art methods, effectively learning from incomplete inputs and predicting complete outputs.},
  archive      = {J_NEUCOM},
  author       = {Jun Li and Shangwei Guo and Luhan Wang and Shaokun Han},
  doi          = {10.1016/j.neucom.2024.127790},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127790},
  shortjournal = {Neurocomputing},
  title        = {CompleteDT: Point cloud completion with information-perception transformers},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised graph representations with generative
adversarial learning. <em>NEUCOM</em>, <em>592</em>, 127786. (<a
href="https://doi.org/10.1016/j.neucom.2024.127786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) are powerful neural models for representation learning on graphs. In this work we study a self-supervised learning GNN method GraphSSGAN (Graph Self-Supervised Generative Adversarial Network) that learns generalized node representations using only unlabeled data. The core idea lies in learning representations that capture both the local information of the links and the global information of the plausibility of the subgraph samples. Specifically, node features of the original graph are first encoded into latent representations by optimizing a link prediction objective. Then the generator converts noise vectors to node representations in the latent space and predicts the link probabilities from the generated node representations. The discriminator leverages the graph convolutional network (GCN) architecture to produce permutation-invariant graph-level embeddings, and the intermediate node representations are used by simple classifiers in the downstream tasks. In addition, we introduce several technical tricks including Gumbel-Top- k k trick, Gumbel-Softmax trick and mini-batch training via subgraph sampling to improve the training process. Through extensive experiments on node classification and link prediction tasks, we demonstrate the effectiveness of the proposed model and the contribution of GAN framework on graph representation learning.},
  archive      = {J_NEUCOM},
  author       = {Xuecheng Sun and Zonghui Wang and Zheming Lu and Ziqian Lu},
  doi          = {10.1016/j.neucom.2024.127786},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127786},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised graph representations with generative adversarial learning},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid optimization algorithm for multi-agent dynamic
planning with guaranteed convergence in probability. <em>NEUCOM</em>,
<em>592</em>, 127764. (<a
href="https://doi.org/10.1016/j.neucom.2024.127764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper aims to solve the problem of multi-agent path planning in complex environment using optimization algorithm. To address the issue of local optimum and premature convergence, a new method is proposed based on the whale optimization algorithm, combining the chaotic initialization, the reverse search and the differential evolution methods. It is theoretically proved that this algorithm is globally convergent in probability. When applied to path planning problems, the proposed optimization algorithm can effectively find a globally optimal and smoother path. Through simulation experiments with multi-UAVs, it is demonstrated that the proposed algorithm has better performance than the state-of-the-art methods in environment with both static and dynamic obstacles, reflecting the global convergence and robustness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Ye Zhang and Yutong Zhu and Haoyu Li and Jingyu Wang},
  doi          = {10.1016/j.neucom.2024.127764},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127764},
  shortjournal = {Neurocomputing},
  title        = {A hybrid optimization algorithm for multi-agent dynamic planning with guaranteed convergence in probability},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Class-driven nonnegative matrix factorization with manifold
regularization for data clustering. <em>NEUCOM</em>, <em>592</em>,
127751. (<a href="https://doi.org/10.1016/j.neucom.2024.127751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative matrix factorization (NMF) is an effective technique to extract the underlying low-dimensional structure of data by utilizing its parts-based representation, which has been widely used in feature extraction and machine learning. However, NMF is an unsupervised learning algorithm without utilizing the discriminative prior information. In this paper, we put forward a new class-driven NMF with manifold regularization (MCDNMF) algorithm, which incorporates both the local manifold regularization and the label information of data into the NMF model. Specifically, MCDNMF not only encodes the local geometrical structure of data space by using the manifold regularization, but also takes the available label information by introducing the class-driven constraint. This class-driven constraint forces the new representations of data points to be more similar within the same class while different between other classes. Therefore, the discriminative abilities of clustering are greatly boosted. Experimental results on several datasets validate the effectiveness of proposed MCDNMF in comparison with the other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Huirong Li and Yani Zhou and Pengjun Zhao and Lei Wang and Chengxiang Yu},
  doi          = {10.1016/j.neucom.2024.127751},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127751},
  shortjournal = {Neurocomputing},
  title        = {Class-driven nonnegative matrix factorization with manifold regularization for data clustering},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph learning with label attention and hyperbolic embedding
for temporal event prediction in healthcare. <em>NEUCOM</em>,
<em>592</em>, 127736. (<a
href="https://doi.org/10.1016/j.neucom.2024.127736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digitization of healthcare systems has led to the proliferation of electronic health records (EHRs), serving as comprehensive repositories of patient information. However, the vast volume and complexity of EHR data present challenges in extracting meaningful insights. This paper addresses the need for automated analysis of EHRs by proposing a novel graph learning model with label attention (GLLA) for temporal event prediction. GLLA utilizes graph neural networks to capture intricate relationships between medical codes and patients, incorporating hierarchical structures and shared risk factors. Furthermore, it introduces the Label Attention and Attention-based Transformer (LAAT) algorithm to analyze unstructured clinical notes as a multi-label classification problem. Evaluation on the widely-used MIMIC III dataset demonstrates the efficacy of GLLA in enhancing diagnostic prediction performance. The contributions of this research include a comprehensive analysis of existing models, the identification of limitations, and the development of innovative approaches to improve the accuracy and effectiveness of EHR analysis. Ultimately, GLLA aims to advance healthcare decision-making, disease management strategies, and patient outcomes.},
  archive      = {J_NEUCOM},
  author       = {Usman Naseem and Surendrabikram Thapa and Qi Zhang and Shoujin Wang and Junaid Rashid and Liang Hu and Amir Hussain},
  doi          = {10.1016/j.neucom.2024.127736},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127736},
  shortjournal = {Neurocomputing},
  title        = {Graph learning with label attention and hyperbolic embedding for temporal event prediction in healthcare},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bengali fake reviews: A benchmark dataset and detection
system. <em>NEUCOM</em>, <em>592</em>, 127732. (<a
href="https://doi.org/10.1016/j.neucom.2024.127732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of fake reviews on various online platforms has created a major concern for both consumers and businesses. Such reviews can deceive customers and cause damage to the reputation of products or services, making it crucial to identify them. Although the detection of fake reviews has been extensively studied in English language, detecting fake reviews in non-English languages such as Bengali is still a relatively unexplored research area. The novelty of this study unfolds on three fronts: (i) a new publicly available dataset called Bengali Fake Review Detection (BFRD) dataset is introduced, (ii) a unique pipeline has been proposed that translates English words to their corresponding Bengali meaning and also back transliterates Romanized Bengali to Bengali, (iii) a weighted ensemble model that combines four pre-trained transformers model is proposed. The developed dataset consists of 7710 non-fake and 1339 fake food-related reviews collected from social media posts. Rigorous experiments have been conducted to compare multiple deep learning and pre-trained transformer language models and our proposed model to identify the best-performing model. According to the experimental results, the proposed ensemble model attained a weighted F1-score of 0.9843 on a dataset of 13,390 reviews, comprising 1339 actual fake reviews, 5,356 augmented fake reviews, and 6695 reviews randomly selected from the 7710 non-fake instances.},
  archive      = {J_NEUCOM},
  author       = {G M Shahariar and Md. Tanvir Rouf Shawon and Faisal Muhammad Shah and Mohammad Shafiul Alam and Md. Shahriar Mahbub},
  doi          = {10.1016/j.neucom.2024.127732},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127732},
  shortjournal = {Neurocomputing},
  title        = {Bengali fake reviews: A benchmark dataset and detection system},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blind image deblurring using both l0 and l1 regularization
of max-min prior. <em>NEUCOM</em>, <em>592</em>, 127727. (<a
href="https://doi.org/10.1016/j.neucom.2024.127727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image deblurring involves estimating the blur kernel from intermediate latent images to recover their corresponding sharp, deblurred versions. In recent years, sophisticated priors such as dark channel, extreme channel, local maximum gradient, and patch-wise minimal pixels have demonstrated promising effectiveness. In this study, we propose a Max-min ( Mm Mm ) prior for effective blind image deblurring. This work is motivated by the observation that the 1 − Mm 1−Mm map of blurred images is less sparse than that of the corresponding clean images. The difference between the highest and lowest intensities around dominant edges is greater than in smooth areas. We theoretically and empirically demonstrate that blurring greatly diminishes this inherent characteristic. This property enables us to establish a new energy function and propose a blur kernel estimation model using L 0 and L 1 regularization of the Mm Mm prior. The proposed method employs a linear operator to compute the Mm Mm map, combined with an efficient optimization scheme to handle various specific scenarios. Through visual and quantitative experiments, we show that the proposed algorithm outperforms state-of-the-art algorithms. In terms of deblurring quality, robustness, and computational efficiency, the developed model surpasses comparable methods. The implemented code is available at https://github.com/eqtedaei/mm-prior-deblur},
  archive      = {J_NEUCOM},
  author       = {Amir Eqtedaei and Alireza Ahmadyfard},
  doi          = {10.1016/j.neucom.2024.127727},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127727},
  shortjournal = {Neurocomputing},
  title        = {Blind image deblurring using both l0 and l1 regularization of max-min prior},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Position-aware compositional embeddings for compressed
recommendation systems. <em>NEUCOM</em>, <em>592</em>, 127677. (<a
href="https://doi.org/10.1016/j.neucom.2024.127677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {GNN recommendation models like NGCF (Wang et al., 2019), LightGCN (He et al., 2020), map each user/item to a unique embedding vector by an embedding table as input features, and then learn further their representations by leveraging multi-hop neighbors on the bipartite graph. In real world, the embedding layer incurs gigabytes of memory consumption for hundreds of thousands of users and items, which is difficult to be deployed due to a plethora of engineering challenges. There are different methods to reduce the size of an embedding table. However, most hashing-based models fail to capture graph-structure information and keep topological distance for users/items in the compressed embedding space. To this end, we present Position-aware Compositional Embedding (PCE) as a low-memory alternative to the embedding layer. PCE constructs unique embedding for each user/item by combining fixed-size anchor nodes and its attached co-cluster on the graph. PCE incorporates global and co-cluster positions into compositional embeddings, obtaining competitive representation capability in the compressed case. Extensive experiments on three recommendation graphs demonstrate that our PCE exceeds state-of-the-art compression techniques. In particular, compared with complete embedding table schema, PCE has a ∼ ∼ 5% relative loss in Recall@20 averagely and 16x fewer parameters. Moreover, our model can be compressed by 2x while getting even better accuracy.},
  archive      = {J_NEUCOM},
  author       = {Zongshen Mu and Yueting Zhuang and Siliang Tang},
  doi          = {10.1016/j.neucom.2024.127677},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127677},
  shortjournal = {Neurocomputing},
  title        = {Position-aware compositional embeddings for compressed recommendation systems},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cubature particle filtering fusion with descent gradient and
maximum correntropy for non-gaussian noise. <em>NEUCOM</em>,
<em>592</em>, 127634. (<a
href="https://doi.org/10.1016/j.neucom.2024.127634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the challenges posed by known heavy-tailed non-Gaussian noise characteristics in multi-sensor fusion, such as complex modeling, reduced estimation accuracy, and inadequate real-time performance, a non-Gaussian cubature particle filter sequential fusion method based on Gradient Descent (GD) and Maximum Correntropy Criterion (MCC) is proposed. Firstly, the proposed approach employs the gradient descent technique to minimize the Pseudo-Huber loss function. This optimization aims to approximate a known heavy-tailed non-Gaussian distribution to a Gaussian distribution, thereby reducing the complexity associated with modeling non-Gaussian noise. Furthermore, by incorporating the MCC into the Cubature Particle Filtering (CPF) process, we achieve real-time optimal estimation of the state, leading to a further improvement in the accuracy of the filter. Finally, a sequential fusion approach is employed for multi-sensor fusion, ensuring real-time filtering and fusion of measurement values. The simulation results demonstrate that in the multi-sensor fusion problem under non-Gaussian noise, the proposed fusion method in this paper can effectively reduce the algorithm’s time complexity while ensuring accuracy.},
  archive      = {J_NEUCOM},
  author       = {Quanbo Ge and Liangyi Zhang and Zhongyuan Zhao and Xingguo Zhang and Zhenyu Lu},
  doi          = {10.1016/j.neucom.2024.127634},
  journal      = {Neurocomputing},
  month        = {8},
  pages        = {127634},
  shortjournal = {Neurocomputing},
  title        = {Cubature particle filtering fusion with descent gradient and maximum correntropy for non-gaussian noise},
  volume       = {592},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the effects of recursive convolutional layers in
convolutional neural networks. <em>NEUCOM</em>, <em>591</em>, 127767.
(<a href="https://doi.org/10.1016/j.neucom.2024.127767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Recursive Convolutional Layer (RCL) is a module that wraps a recursive feedback loop around a convolutional layer (CL). The RCL has been proposed to address some of the shortcomings of Convolutional Neural Networks (CNNs), as its unfolding increases the depth of a network without increasing the number of weights. We investigated the “naïve” substitution of CL with RCL on three base models: a 4-CL model, ResNet, DenseNet and their RCL-ized versions: C-FRPN, R-ResNet, and R-DenseNet using five image classification datasets. We find that this one-to-one replacement significantly improves the performances of the 4-CL model, but not those of ResNet or DenseNet. This led us to investigate the implication of the RCL substitution on the 4-CL model which reveals, among a number of properties, that RCLs are particularly efficient in shallow CNNs. We proceeded to re-visit the first set of experiments by gradually transforming the 4-CL model and the C-FRPN into respectively ResNet and R-ResNet, and find that the performance improvement is largely driven by the training regime whereas any depth increase negatively impacts the RCL-ized version. We conclude that the replacement of CLs by RCLs shows great potential in designing high-performance shallow CNNs.},
  archive      = {J_NEUCOM},
  author       = {Johan Chagnon and Markus Hagenbuchner and Ah Chung Tsoi and Franco Scarselli},
  doi          = {10.1016/j.neucom.2024.127767},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127767},
  shortjournal = {Neurocomputing},
  title        = {On the effects of recursive convolutional layers in convolutional neural networks},
  volume       = {591},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lag synchronization for coupled neural networks with
multistate or multiderivative couplings. <em>NEUCOM</em>, <em>591</em>,
127766. (<a href="https://doi.org/10.1016/j.neucom.2024.127766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, two kinds of lag synchronization for coupled neural networks (CNNs) are addressed, that is, the cases with multiple state or derivative couplings. Firstly, several lag synchronization criteria for these two CNNs are derived by selecting proper state feedback controllers. Furthermore, since external disturbances in neural network implementation should not be ignored, the impact of external disturbances on the lag synchronization for CNNs are also further investigated. Lastly, the obtained criteria are verified through two illustrative examples.},
  archive      = {J_NEUCOM},
  author       = {Yan-Ran Zhu and Jin-Liang Wang and Xiao Han},
  doi          = {10.1016/j.neucom.2024.127766},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127766},
  shortjournal = {Neurocomputing},
  title        = {Lag synchronization for coupled neural networks with multistate or multiderivative couplings},
  volume       = {591},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bidirectional neural network for trajectory planning: An
application to medical emergency vehicle. <em>NEUCOM</em>, <em>591</em>,
127763. (<a href="https://doi.org/10.1016/j.neucom.2024.127763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the autonomous trajectory optimization of in-hospital emergency vehicles, aiming to plan a fast, safe, and comfortable trajectory for real time navigation to reach the emergency room. This has direct and significant practical implications for saving patients’ time and reducing the burden on medical staff. To address it, we propose a novel real-time trajectory planning algorithm and introduce a training framework that contributes to planner’s transferability. In the dataset preparation phase, we employ an optimization-based method to solve the in-hospital trajectory planning problem, generating substantial trajectories. In the training phase, we design a neural network-based planner to establish logical connections between states and control commands. To enhance interaction with the vehicle itself, we design a novel network training framework that incorporates a neural network-based vehicle simulator to learn the vehicle’s self-information, facilitating training the planner. During the inference phase, our planner can plan a collision-free, time-efficient, and comfortable trajectory. Furthermore, our algorithm demonstrates ease of transferability to different vehicle models. Finally, extensive simulations experiments are conducted to validate the safety, speed, and comfortability of the algorithm’s trajectory planning, as well as its excellent transferability.},
  archive      = {J_NEUCOM},
  author       = {Liqun Huang and Runqi Chai and Kaiyuan Chen and Senchun Chai and Yuanqing Xia and Guo-Ping Liu},
  doi          = {10.1016/j.neucom.2024.127763},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127763},
  shortjournal = {Neurocomputing},
  title        = {Bidirectional neural network for trajectory planning: An application to medical emergency vehicle},
  volume       = {591},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary computation in bioinformatics: A survey.
<em>NEUCOM</em>, <em>591</em>, 127758. (<a
href="https://doi.org/10.1016/j.neucom.2024.127758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bioinformatics is a subject that studies life phenomena by using mathematical and information science theories and techniques. Its main tasks, such as DNA sequence comparison, protein structure prediction and cell metabolism analysis, can be regarded as complex optimization problems with different characteristics. Evolutionary computing is a kind of global optimization algorithm inspired by nature. Over the years, scholars have accumulated fruitful results in solving complex optimization problems such as large-scale, dynamic, multi-modal, multi-objective and multi-constrained problems by using Evolutionary Computation algorithms, and have successfully applied to the above optimization tasks in bioinformatics. This paper mainly summarizes the work of Evolutionary Computation technologies in bioinformatics from 2019 to 2023 at multiple levels, including Genomics, Proteomics, metabolomics and molecular networks related optimization tasks, as well as further applications in disease diagnosis and drug development.},
  archive      = {J_NEUCOM},
  author       = {Yanyun Zhang and Li Cheng and Guanyu Chen and Daniyal Alghazzawi},
  doi          = {10.1016/j.neucom.2024.127758},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127758},
  shortjournal = {Neurocomputing},
  title        = {Evolutionary computation in bioinformatics: A survey},
  volume       = {591},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TPN: Triple network algorithm for deep reinforcement
learning. <em>NEUCOM</em>, <em>591</em>, 127755. (<a
href="https://doi.org/10.1016/j.neucom.2024.127755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The target net method has been the foundation of deep reinforcement learning since Deepmind first proposed it in 2015. Almost all the current popular reinforcement learning algorithms include target net. However, while the slowly updated target network improves the stability of the algorithm, it also reduces the performance of the algorithm. In this paper, the authors design a novel triple-network algorithm(TPN). TPN combines the temporal-difference(TD) algorithm and policy gradient(PG) theorem. Using three networks to estimate the state value( v v ), action value ( q ) (q) , and policy( π π ). These networks have no primary or secondary distinction but are trained synchronously and influence each other. The author found that through this TPN architecture, the convergence and stability of the algorithm can be greatly improved without increasing the amount of calculation. Although it is only a basic framework at present. The calculation process of TPN is simple and easy to implement. Experiments prove that the convergence speed and stability of TPN in discrete cases are better than PPO.},
  archive      = {J_NEUCOM},
  author       = {Chen Han and Xuanyin Wang},
  doi          = {10.1016/j.neucom.2024.127755},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127755},
  shortjournal = {Neurocomputing},
  title        = {TPN: Triple network algorithm for deep reinforcement learning},
  volume       = {591},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consensus multi-view subspace clustering based on graph
filtering. <em>NEUCOM</em>, <em>591</em>, 127742. (<a
href="https://doi.org/10.1016/j.neucom.2024.127742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering has attracted an increasing amount of attention because it can capture information from multiple views as well as avoid the curse of dimensionality. The existing methods cannot simultaneously achieve both the effective reduction of negative impact of noise and the high-quality consensus representation within a unified framework. To handle this issue, this paper proposes a novel Consensus Multi-view subspace clustering based on Graph Filtering, named CMGF. First, CMGF learns a latent data space by using view-specific k k -order filters to reduce noise and redundant information. Then, CMGF obtains the spectral embedding matrix of each view by imposing graph regularization constraint. Ultimately, to generate a consensus representation, we integrate the spectral embedding matrix of each view by using an adaptively weighted scheme. Experimental results on ten real-word datasets show that the proposed method outperforms state-of-the-art baselines significantly. Experiments also demonstrate that the graph filtering employed in CMGF enhances the smoothness of the data and improves the distinctiveness of the cluster structure.},
  archive      = {J_NEUCOM},
  author       = {Mei Chen and Yiying Yao and Yuanyuxiu You and Boya Liu and Yu Wang and Song Wang},
  doi          = {10.1016/j.neucom.2024.127742},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127742},
  shortjournal = {Neurocomputing},
  title        = {Consensus multi-view subspace clustering based on graph filtering},
  volume       = {591},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving texture integrity through second-order constraints
on warping maps. <em>NEUCOM</em>, <em>591</em>, 127739. (<a
href="https://doi.org/10.1016/j.neucom.2024.127739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pose Transfer has recently gained significant attention, particularly for its user-friendly applications in the animation industry. The primary objective is to transform a given RGB image into a new target pose. This process involves two consecutive tasks: initially, warping the image to approximately align with the target pose, and subsequently using this rough estimation to generate a photorealistic image of the input in the desired pose. The primary challenge lies in the first task, where the image undergoes a rough transformation to its new location in the target pose. Current deep learning approaches rely on first-order warping, employing an affine transformation to move all image pixels. Despite yielding promising results, this approach has significant challenges when dealing with complex deformations, mainly due to the simplistic nature of its linear function. In contrast, we suggest transferring patches using a set of correlation layers. In each layer, the warping for each pixel of the image is individually estimated. We additionally introduce a constraint aimed at minimizing the energy of second derivatives across the entire warping map of the pixels. This allows for keeping the integration of local textures following the warping process, a feature already ensured in the affine-based transformation by restricting the transition to a linear function for all the image pixels. Our approach not only preserves the integrity of local textures, akin to the affine transformation, but achieves this by individually estimating the warping for each image pixel, thereby enabling finer adjustments of the input sample to the target pose. We illustrate the superior performance of this technique compared to affine-based strategies on the renowned DeepFashion database.},
  archive      = {J_NEUCOM},
  author       = {Mohsen Tabejamaat and Farhood Negin and François Bremond},
  doi          = {10.1016/j.neucom.2024.127739},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127739},
  shortjournal = {Neurocomputing},
  title        = {Improving texture integrity through second-order constraints on warping maps},
  volume       = {591},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). OV-VG: A benchmark for open-vocabulary visual grounding.
<em>NEUCOM</em>, <em>591</em>, 127738. (<a
href="https://doi.org/10.1016/j.neucom.2024.127738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open-vocabulary learning has emerged as a cutting-edge research area, particularly in light of the widespread adoption of vision-based foundational models. Its primary objective is to comprehend novel concepts that are not encompassed within a predefined vocabulary. One key facet of this endeavor is Visual Grounding (VG), which entails locating a specific region within an image based on a corresponding language description. While current foundational models excel at various visual language tasks, there is a noticeable absence of models specifically tailored for open-vocabulary visual grounding (OV-VG). This research endeavor introduces novel and challenging OV tasks, namely Open-Vocabulary Visual Grounding (OV-VG) and Open-Vocabulary Phrase Localization (OV-PL). The overarching aim is to establish connections between language descriptions and the localization of novel objects. To facilitate this, we have curated a comprehensive annotated benchmark, encompassing 7272 OV-VG images (comprising 10,000 instances) and 1000 OV-PL images. In our pursuit of addressing these challenges, we delved into various baseline methodologies rooted in existing open-vocabulary object detection (OV-D), VG, and phrase localization (PL) frameworks. Surprisingly, we discovered that state-of-the-art (SOTA) methods often falter in diverse scenarios. Consequently, we developed a novel framework that integrates two critical components: Text-Image Query Selection (TIQS) and Language-Guided Feature Attention (LGFA). These modules are designed to bolster the recognition of novel categories and enhance the alignment between visual and linguistic information. Extensive experiments demonstrate the efficacy of our proposed framework, which consistently attains SOTA performance across the OV-VG task. Additionally, ablation studies provide further evidence of the effectiveness of our innovative models. Codes and datasets will be made publicly available at https://github.com/cv516Buaa/OV-VG .},
  archive      = {J_NEUCOM},
  author       = {Chunlei Wang and Wenquan Feng and Xiangtai Li and Guangliang Cheng and Shuchang Lyu and Binghao Liu and Lijiang Chen and Qi Zhao},
  doi          = {10.1016/j.neucom.2024.127738},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127738},
  shortjournal = {Neurocomputing},
  title        = {OV-VG: A benchmark for open-vocabulary visual grounding},
  volume       = {591},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). OF-DFN: Optical flow prediction network for different
perspective image fusion. <em>NEUCOM</em>, <em>591</em>, 127737. (<a
href="https://doi.org/10.1016/j.neucom.2024.127737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, non-decision-level image fusion algorithms require extremely high registration precision of the images to be fused. In the face of different perspective image fusion scenarios, traditional feature registration algorithms and learning-based methods have poor robustness and are unsuitable for large image differences because of the Registration-Fusion separation. In addition, the lack of relevant datasets also hinders the development of different perspective image fusion methods. Given the above problems, we collect 5000 sets of different perspective RGB-MONO datasets in multiple scenes for raw data support. We present an end-to-end learned system for fusing two different perspective photographs into a chosen target view. The cascaded feature extraction based on encoder–decoder structure enables learning optical flow at different feature levels systematically. Then the optical flow module enables the image to be continuously registered and optimized during the fusion process, thus avoiding the deviations introduced by non-end-to-end algorithms. Extensive quantitative and qualitative experiments demonstrate that our proposed system can effectively fuse images from different perspectives in our self-built dataset. Compared with non-end-to-end fusion, our method provides superior performance in several fusion evaluation indicators.},
  archive      = {J_NEUCOM},
  author       = {Tianshun You and Ming Liu and Yongming Zhao and Liquan Dong},
  doi          = {10.1016/j.neucom.2024.127737},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127737},
  shortjournal = {Neurocomputing},
  title        = {OF-DFN: Optical flow prediction network for different perspective image fusion},
  volume       = {591},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal bipartite graph matching-based goal selection for
policy-based hindsight learning. <em>NEUCOM</em>, <em>591</em>, 127734.
(<a href="https://doi.org/10.1016/j.neucom.2024.127734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sparse reward problem stands as a significant challenge in the field of reinforcement learning. Hindsight Experience Replay (HER) addresses this by goal relabeling, allowing the agent to learn from unsuccessful experiences. Some studies combine policy gradient methods with HER, resulting in policy-based hindsight learning algorithms. However, Policy-based hindsight learning involves the use of importance sampling, where the distribution of hindsight goals and the distribution of desired goals contribute to the computation of importance weights. When there is a significant difference between the two distributions, importance weights may become skewed, thereby impacting the evaluation of the policy and leading to suboptimal policies. To address this, we propose modeling the goal selection as an optimization problem for distribution matching. After we augment the original desired goals using Kernel Density Estimation (KDE), we further convert the optimization problem for distribution matching into a bipartite graph matching problem that minimizes the sum of weights. Our optimal bipartite graph matching-based hindsight goal selection method can select hindsight goals that are the most closely aligned with the original goals. Experimental results show that algorithms combined with the optimal bipartite graph matching-based hindsight goal selection outperform the original algorithms. Visualizations also demonstrate the superiority of our method in selecting hindsight goals.},
  archive      = {J_NEUCOM},
  author       = {Shiguang Sun and Hanbo Zhang and Zeyang Liu and Xingyu Chen and Xuguang Lan},
  doi          = {10.1016/j.neucom.2024.127734},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127734},
  shortjournal = {Neurocomputing},
  title        = {Optimal bipartite graph matching-based goal selection for policy-based hindsight learning},
  volume       = {591},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-free anti-disturbance tracking control for high-order
discrete-time nonlinear system based on concurrent learning extended
state observer. <em>NEUCOM</em>, <em>591</em>, 127733. (<a
href="https://doi.org/10.1016/j.neucom.2024.127733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research objective of this paper is to address the tracking control problem of high-order discrete-time nonlinear systems in the presence of completely unknown internal uncertainties, unknown external disturbances, and unknown control input gain. To address this challenge, the paper proposes a high-order discrete-time model-free anti-disturbance tracking control method without relying on prior knowledge of system parameters. The core of the approach is the development of a data-driven concurrent learning extended state observer. The uniqueness of this observer lies in its ability to estimate unknown control input gains without the persistent excitation and ensure the convergence of the estimates. Based on the concurrent learning extended state observer, a high-order discrete-time tracking control law is designed to precisely track the reference signal, ensuring the stability of the nonlinear closed-loop system. The effectiveness of this method was verified by applying simulation verification to the heading tracking control of surface automatic vehicles.},
  archive      = {J_NEUCOM},
  author       = {Huijuan Li and Nan Gu and Dan Wang and Zhouhua Peng},
  doi          = {10.1016/j.neucom.2024.127733},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127733},
  shortjournal = {Neurocomputing},
  title        = {Model-free anti-disturbance tracking control for high-order discrete-time nonlinear system based on concurrent learning extended state observer},
  volume       = {591},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Element-conditioned GAN for graphic layout generation.
<em>NEUCOM</em>, <em>591</em>, 127730. (<a
href="https://doi.org/10.1016/j.neucom.2024.127730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Layout guides the position and scale of design elements for desirable aesthetics and effective demonstration. Recently, Generative Adversarial Networks (GANs) have proved their capability in generating effective layouts. However, current GANs ignore the situation where the amounts and types of the input design elements are given and determined. In this paper, we propose EcGAN, an element-conditioned GAN for graphic layout generation conditioned on specified design elements (design elements’ amount and types). We represent each element by a bounding box and propose three components: element mask, element condition loss and two-step discriminators, to solve the bounding box modelling problem for element-conditioned layout generation. Experiments reveal that EcGAN outperforms existing methods quantitatively and qualitatively. We also perform detailed ablation studies to highlight the effect of each component and a user study to further validate our model. Finally, we demonstrate two of EcGAN’s applications for practical design scenarios.},
  archive      = {J_NEUCOM},
  author       = {Liuqing Chen and Qianzhi Jing and Yunzhan Zhou and Zhaoxing Li and Lei Shi and Lingyun Sun},
  doi          = {10.1016/j.neucom.2024.127730},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127730},
  shortjournal = {Neurocomputing},
  title        = {Element-conditioned GAN for graphic layout generation},
  volume       = {591},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Video anomaly detection: A systematic review of issues and
prospects. <em>NEUCOM</em>, <em>591</em>, 127726. (<a
href="https://doi.org/10.1016/j.neucom.2024.127726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increase in the deployment of surveillance camera in outdoor and indoor settings have resulted in a growing demand for intelligent systems that can accurately detect and recognize human actions as well as other entities of interest within the captured video data. Although, human action recognition is a well-established topic in computer vision, abnormal behaviour detection has recently received increased research attention. Several abnormal behaviour detection systems have been proposed over the years to ensure human safety. However, only a few comprehensive and systematic reviews report on the current state and future direction of video anomaly detection(VAD) research. This present effort aims to contribute a systematic and detailed review of current research and advances in the detection of anomalous actions and entities in videos. The review focuses on studies published between 2003 and 2023. During the literature selection process, 530 scholarly articles were identified and evaluated to showcase prevalent research trends, techniques, datasets, and frameworks within the realm of VAD This review aims to offer a comprehensive understanding of key areas of focus among researchers, provide resources for commonly used public datasets for evaluation and experimentation, and examine advancements and integration of network design to accommodate the needs for handling multimedia information. To sum up, this study highlights various potential opportunities and obstacles about the VAD domain.VAD has gained significant interest in recent years due to its potential applications in various domains such as security, surveillance, traffic monitoring, medical imaging among others. Areas of further research include, Anomaly detection in real-time, multi-camera anomaly detection, privacy preserving in VAD to mention a few. The study revealed some key trends and challenges in VAD that can guide future research direction.},
  archive      = {J_NEUCOM},
  author       = {Yau Alhaji Samaila and Patrick Sebastian and Narinderjit Singh Sawaran Singh and Aliyu Nuhu Shuaibu and Syed Saad Azhar Ali and Temitope Ibrahim Amosa and Ghulam E. Mustafa Abro and Isiaka Shuaibu},
  doi          = {10.1016/j.neucom.2024.127726},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127726},
  shortjournal = {Neurocomputing},
  title        = {Video anomaly detection: A systematic review of issues and prospects},
  volume       = {591},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ESIE-BERT: Enriching sub-words information explicitly with
BERT for intent classification and slot filling. <em>NEUCOM</em>,
<em>591</em>, 127725. (<a
href="https://doi.org/10.1016/j.neucom.2024.127725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural language understanding (NLU) has two core tasks: intent classification and slot filling. The success of pre-training language models resulted in a significant breakthrough in the two tasks. The architecture based on autoencoding (BERT-based model) can optimize the two tasks jointly. However, we note that BERT-based models convert each complex token into multiple sub-tokens by the Wordpiece algorithm, which generates an out-of-alignment between the length of the tokens and the labels. This leads to BERT-based models not performing well in label prediction, limiting model performance improvement. Many existing models can address this issue, but some hidden semantic information is discarded during fine-tuning. We addressed the problem by introducing a novel joint method on top of BERT. This method explicitly models multiple sub-token features after the Wordpiece tokenization, contributing to both tasks. Our proposed method effectively extracts contextual features from complex tokens using the Sub-words Attention Adapter (SAA), preserving overall utterance information. Additionally, we propose an Intent Attention Adapter (IAA) to acquire comprehensive sentence features, assisting users in predicting intent. Experimental results confirm that our proposed model exhibits significant improvements on two public benchmark datasets. Specifically, the slot-filling F1 score improves from 96.5 to 98.2 (an absolute increase of 1.7% ) on the Airline Travel Information Systems (ATIS) dataset.},
  archive      = {J_NEUCOM},
  author       = {Yu Guo and Zhilong Xie and Xingyan Chen and Huangen Chen and Leilei Wang and Huaming Du and Shaopeng Wei and Yu Zhao and Qing Li and Gang Wu},
  doi          = {10.1016/j.neucom.2024.127725},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127725},
  shortjournal = {Neurocomputing},
  title        = {ESIE-BERT: Enriching sub-words information explicitly with BERT for intent classification and slot filling},
  volume       = {591},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing class imbalance solutions: A projection-based
fuzzy LS-TSVM approach. <em>NEUCOM</em>, <em>591</em>, 127712. (<a
href="https://doi.org/10.1016/j.neucom.2024.127712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance and noise present significant challenges in numerous real-world classification tasks. The prevalence of an uneven distribution of samples typically results in a bias towards the majority class in Support Vector Machine (SVM) classifiers, compounded by the often inherent noise within these samples. Addressing both class imbalance and noise, we introduce two fuzzy-based methodologies. The first method employs intuitionistic fuzzy membership, resulting in the development of the Robust Energy-based Intuitionistic Fuzzy Least Squares Twin Support Vector Machine (IF-RELSTSVM), a model specifically designed for class imbalance learning. The IF-RELSTSVM model is distinguished by its use of intuitionistic fuzzy scores for both classes, significantly attenuating the detrimental effects of noise and outliers. A distinctive attribute of IF-RELSTSVM is its proficiency in processing noisy data points, whether proximate to or distant from the hyperplane. Additionally, we introduce a novel concept of hyperplane-based fuzzy membership, calculating fuzzy memberships through a projection-based approach. This foundation supports the formulation of a Robust Energy-based Fuzzy Least Squares Twin Support Vector Machine (F-RELSTSVM), also aimed at class imbalance learning. The efficacy of the proposed IF-RELSTSVM and F-RELSTSVM algorithms is rigorously evaluated across several benchmark and synthetic datasets, employing the Area Under the ROC Curve (AUC) as a performance metric. Experimental findings indicate that these algorithms surpass baseline models in the majority of datasets tested. Statistical analyses further validate the significance of our proposed methods, demonstrating their suitability for application in environments characterized by noise and class imbalance. A case study in credit card fraud detection showcases the F-RELSTSVM algorithm achieving an impressive average AUC of 90.84%, thereby outperforming comparable algorithms and highlighting the practical applicability of our approaches in tackling challenging datasets.},
  archive      = {J_NEUCOM},
  author       = {M. Tanveer and Ritik Mishra and Bharat Richhariya},
  doi          = {10.1016/j.neucom.2024.127712},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127712},
  shortjournal = {Neurocomputing},
  title        = {Enhancing class imbalance solutions: A projection-based fuzzy LS-TSVM approach},
  volume       = {591},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RadarNet: A parallel spatiotemporal encoder network for
radar extrapolation. <em>NEUCOM</em>, <em>591</em>, 127665. (<a
href="https://doi.org/10.1016/j.neucom.2024.127665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radar extrapolation has been one of the most important means for nowcasting. Most current models achieve good performance in high-frequency sequences (e.g., video, more than 24 fps), while the temporal resolution of radar echo sequences is much lower (1 frame every 6 min) and the transforms are much more complex. The spatiotemporal characters with some similarities would not change a lot in video sequences; however, the radar echo sequences include more intangible changes (e.g., the echo evolution of generation or vanish, and so on), which leads to unique distinct spatial and temporal characters, respectively. Therefore, the singular peculiarity would be mitigated, leading to a rapid decline in precision and sharpness during the extrapolation process. In general, temporal feature extraction is utilized to understand the variation in pixel locations, while spatial feature extraction is employed to capture the distribution variation of specific regions. In this work, we propose a feature decomposition network, termed as RadarNet to improve the extrapolation precision. The parallel independent encoders are used to enhance multi-scale spatial feature extraction and temporal motion feature capture of radar echoes, respectively. In addition, we design a specialized cross fusion mechanism to achieve the inputs of the decoder which may enhance the performance of the extrapolation. The extrapolation experiments are conducted on real radar echo datasets from Shijiazhuang and Nanjing that demonstrate the effectiveness of our model.},
  archive      = {J_NEUCOM},
  author       = {Wei Tian and Lei Yi and Xianghua Niu and Rong Fang and Lixia Zhang and Huanhuan Liu and Zhuo Xu and Shengqin Jiang and Yonghong Zhang},
  doi          = {10.1016/j.neucom.2024.127665},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127665},
  shortjournal = {Neurocomputing},
  title        = {RadarNet: A parallel spatiotemporal encoder network for radar extrapolation},
  volume       = {591},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global exponential synchronization of complex networks with
reaction diffusions and finite distributed delays coupling.
<em>NEUCOM</em>, <em>590</em>, 127765. (<a
href="https://doi.org/10.1016/j.neucom.2024.127765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates global exponential synchronization of complex networks with reaction diffusions and finite distributed delays coupling (RDDCCNs). Some restrictions on the coupling configuration matrix and time-varying delays are removed. By constructing comparison functions, utilizing analytic method and inequality techniques, a criterion for exponential synchronization of RDDCCNs is attained under adaptive intermittent control. A corresponding outcome without RDs is also acquired. At last, two simulations are proposed to illustrate validity of the obtained criteria.},
  archive      = {J_NEUCOM},
  author       = {Yun Xing and Chaoyang Zheng and Yin Sheng and Zhigang Zeng},
  doi          = {10.1016/j.neucom.2024.127765},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127765},
  shortjournal = {Neurocomputing},
  title        = {Global exponential synchronization of complex networks with reaction diffusions and finite distributed delays coupling},
  volume       = {590},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An overview on deep clustering. <em>NEUCOM</em>,
<em>590</em>, 127761. (<a
href="https://doi.org/10.1016/j.neucom.2024.127761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the great success of deep learning and especially deep unsupervised learning, many deep architectural clustering methods, collectively known as deep clustering, have emerged. Deep clustering shows the potential to outperform traditional methods, especially in handling complex high-dimensional data, taking full advantage of deep learning. To achieve a comprehensive overview of the field of deep clustering, this review systematically explores deep clustering methods and their various applications. First, the basic network architecture of deep clustering is described in detail, including the common network frameworks, and loss functions. Subsequently, deep clustering is divided into several categories based on the network architecture, and benchmark datasets and evaluation metrics in the field are introduced. Next, the real-world applications of deep clustering are explored in depth, providing successful cases in the fields of bioinformatics, medicine, anomaly detection, and image processing, highlighting the broad applicability of deep clustering in solving real-world challenges. Finally, the paper summarizes its contributions and explores potential directions for future research in deep clustering.},
  archive      = {J_NEUCOM},
  author       = {Xiuxi Wei and Zhihui Zhang and Huajuan Huang and Yongquan Zhou},
  doi          = {10.1016/j.neucom.2024.127761},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127761},
  shortjournal = {Neurocomputing},
  title        = {An overview on deep clustering},
  volume       = {590},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advanced insights through systematic analysis: Mapping
future research directions and opportunities for xAI in deep learning
and artificial intelligence used in cybersecurity. <em>NEUCOM</em>,
<em>590</em>, 127759. (<a
href="https://doi.org/10.1016/j.neucom.2024.127759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper engages in a comprehensive investigation concerning the application of Explainable Artificial Intelligence (xAI) within the context of deep learning and Artificial Intelligence, with a specific focus on its implications for cybersecurity. Firstly, the paper gives an overview of xAI techniques and their significance and benefits when applied in cybersecurity. Subsequently, the authors methodically delineate their systematic mapping study, which serves as an investigative tool for discerning the potential trajectory of the field. This strategic methodological framework lets one identify the future research directions and opportunities that underlie the integration of xAI within the realm of Deep Learning, Artificial Intelligence, and cybersecurity, which are described in-depth. Then, the paper brings together all the gathered insights from this extensive investigation and closes with final conclusions.},
  archive      = {J_NEUCOM},
  author       = {Marek Pawlicki and Aleksandra Pawlicka and Rafał Kozik and Michał Choraś},
  doi          = {10.1016/j.neucom.2024.127759},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127759},
  shortjournal = {Neurocomputing},
  title        = {Advanced insights through systematic analysis: Mapping future research directions and opportunities for xAI in deep learning and artificial intelligence used in cybersecurity},
  volume       = {590},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Center-bridged interaction fusion for hyperspectral and
LiDAR classification. <em>NEUCOM</em>, <em>590</em>, 127757. (<a
href="https://doi.org/10.1016/j.neucom.2024.127757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent classifications in Earth Observation (EO) commonly involve a combination of Hyperspectral Image (HSI) and Light Detection and Ranging (LiDAR) signals. However, many current methods fail to consider the HSI-LiDAR information concurrently, especially in terms of both its intra- and inter-modality aspects. Additionally, current methods are generally limited in their ability to fuse the features extracted from different modalities. Hence, this paper proposes a center-bridged framework, called Interaction Fusion (IF), that can leverage diverse information concerning the intra- and inter-modality relationships at the same time. More specifically, intra- and inter-modality information can be enriched by introducing the center patch of HSI (cp-HSI) as an extra input, This introduces additional contextual information within and across modalities that can be leverage for deeper insights. Further, we propose a fusion matrix as a structural feature map designed to integrate nine views generated by a view generator, enabling the adaptive combination of intra- and inter-modality information. Overall, our approach allows potential patterns to be captured, while mitigating any bias resulting from incomplete information. Extensive experiments conducted on three widely recognized datasets – Trento, MUUFL, and Houston – demonstrate that the IF framework achieves state-of-the-art results, surpassing existing methods.},
  archive      = {J_NEUCOM},
  author       = {Lu Huo and Jiahao Xia and Leijie Zhang and Haimin Zhang and Min Xu},
  doi          = {10.1016/j.neucom.2024.127757},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127757},
  shortjournal = {Neurocomputing},
  title        = {Center-bridged interaction fusion for hyperspectral and LiDAR classification},
  volume       = {590},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MD-GCCF: Multi-view deep graph contrastive learning for
collaborative filtering. <em>NEUCOM</em>, <em>590</em>, 127756. (<a
href="https://doi.org/10.1016/j.neucom.2024.127756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative Filtering (CF), a classical recommender system approach, learns users’ interests and behavioral preferences for items through a user–item interaction graph. CF based on graph neural network (GNN) and CF based on graph contrastive learning (GCL) show strong advantages in both modeling multi-layer signals and solving label sparsity, respectively. However, there are still two key problems to be solved: Most CF models based on (1) GNN suffer from the over-smoothing problem and are unable to aggregate deep collaborative signals and (2) GCL adopts a single aggregation paradigm, resulting in a lack of diversity in the feature representation of collaborative signals. To solve the above problems, a multi-view deep graph contrastive learning for collaborative filtering (MD-GCCF) has been proposed from two perspectives. First, a deep graph collaborative signal aggregation module is proposed to learn potential intention similarity representations for deep collaborative signal propagation within a few layers. Second, a novel multi-view contrastive learning module has been proposed, utilizing both local and global contrastive learning views from the collaborative signal aggregation module to enhance deep structures and semantic features in collaborative signals. MD-GCCF improves by 9.52%, 3.34%, and 2.49% compared to the rival models, respectively, in the Amazon book, Yelp2018, and Gowalla datasets.},
  archive      = {J_NEUCOM},
  author       = {Xinlu Li and Yujie Tian and Bingbing Dong and Shengwei Ji},
  doi          = {10.1016/j.neucom.2024.127756},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127756},
  shortjournal = {Neurocomputing},
  title        = {MD-GCCF: Multi-view deep graph contrastive learning for collaborative filtering},
  volume       = {590},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Dynamic loss yielding more transferable targeted
adversarial examples. <em>NEUCOM</em>, <em>590</em>, 127754. (<a
href="https://doi.org/10.1016/j.neucom.2024.127754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial examples are known to have the property of transferability; as a result, deep neural networks can be compromised by transfer-based attacks in black-box scenarios. Recent studies have shown that targeted adversarial examples are far more difficult to transfer than untargeted adversarial examples. We find that the widely used pattern for targeted attacks ( i . e ., minimizing the loss with respect to the target label) is insufficient for the transfer scenario. To address this issue, we propose a dynamic loss to yield more transferable targeted adversarial examples. In each iteration of attack optimization, in addition to minimizing the loss with respect to the target label, we dynamically select the top k labels (excluding the target label) with high classification probability to penalize ( i . e ., maximize) their corresponding loss. As a result, the probability of adversarial examples being classified as target labels will be significantly higher than that of being classified as other labels. Extensive experiments on ImageNet and the Google Cloud Vision API show that the dynamic loss significantly outperforms the traditional loss. For example, in the ensemble-based transfer scenario, the dynamic Cross-Entropy (CE) loss can improve the transferability of targeted adversarial examples by 2 ∼ 6 2∼6 times relative to the traditional CE loss. Code is available at https://github.com/mingcheung/Targeted-Transfer-with-Dynamic-Loss .},
  archive      = {J_NEUCOM},
  author       = {Ming Zhang and Yongkang Chen and Hu Li and Cheng Qian and Xiaohui Kuang},
  doi          = {10.1016/j.neucom.2024.127754},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127754},
  shortjournal = {Neurocomputing},
  title        = {Dynamic loss yielding more transferable targeted adversarial examples},
  volume       = {590},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel spectral super-resolution network with dominant
information between spatial and spectral domains. <em>NEUCOM</em>,
<em>590</em>, 127753. (<a
href="https://doi.org/10.1016/j.neucom.2024.127753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing spectral super-resolution (SSR) methods have achieved satisfactory performance by designing complicated deep convolution neural networks (DCNNs) to extract spectral and spatial features. However, these methods ignore the fact that the significance of spatial and spectral information in each hyperspectral image (HSI) is different, and most of them directly fuse two kinds of information with concatenation and convolution operation, which resulting in generating redundant information and have negative effects on reconstruction. To address such inadequacies, this paper proposes a novel adaptive spatial–spectral modulation network (ASSM-Net). Specifically, we propose a new adaptive feature fusion module (AFFM) to replace traditional convolutional fusion schemes. Through explicitly measuring the weights of spatial information and spectral features of HSI, AFFM can select dominant features for each pixel to modulate spatial and spectral information. Additionally, we develop a pixel-weighted aware attention (PAA) mechanism to enhance the feature interdependences for recovering finer structure information. Finally, a large number of quantitative and qualitative experiments reveal that the proposed network achieves competitive reconstruction results on three benchmark datasets (NTIRE 2022, CAVE and Harvard).},
  archive      = {J_NEUCOM},
  author       = {Weixiao Zhao and Minggang Dong and Yan Wang and Ruoqi Tan and Tianhao Wu},
  doi          = {10.1016/j.neucom.2024.127753},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127753},
  shortjournal = {Neurocomputing},
  title        = {A novel spectral super-resolution network with dominant information between spatial and spectral domains},
  volume       = {590},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantifying uncertainty of uplift: Trees and t-learners.
<em>NEUCOM</em>, <em>590</em>, 127741. (<a
href="https://doi.org/10.1016/j.neucom.2024.127741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uplift modeling refers to the task of estimating the causal effect of a treatment on an individual, also known as the conditional average treatment effect. However, uplift models do not usually provide uncertainty estimates of the predictions. We explain why estimating uncertainty of the treatment effect is particularly important in many common use cases and we show how epistemic uncertainty of the uplift estimates can be quantified for T-learners and trees. We tested the methods on three empirical datasets and evaluated them on a simulated dataset. We found that high uncertainty might be the result of both modeling choices and properties of the data. Sometimes there is not enough data or the data is simply not rich enough to identify the treatment effect well resulting in high uncertainty. In addition, our results suggest that one commonly used dataset might not be suitable for benchmarking.},
  archive      = {J_NEUCOM},
  author       = {Otto Nyberg and Arto Klami},
  doi          = {10.1016/j.neucom.2024.127741},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127741},
  shortjournal = {Neurocomputing},
  title        = {Quantifying uncertainty of uplift: Trees and T-learners},
  volume       = {590},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). One-step incremental multi-view spectral clustering based on
graph linkage learning. <em>NEUCOM</em>, <em>590</em>, 127740. (<a
href="https://doi.org/10.1016/j.neucom.2024.127740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most traditional multi-view spectral clustering algorithms involve two separate steps: solving the spectral embedding matrix and clustering, which may introduce errors during the clustering process. Moreover, in practical applications, the number of available views may increase over time, and the approach of re-fusing all views in each computation would result in elevated computational costs. In this paper, we propose a novel model: One-step Incremental Multi-view Spectral Clustering based on Graph Linkage learning (OIMvSC). OIMvSC only needs to store the consensus spectral embedding matrix and the consensus label matrix of all previous views and combines them with the spectral embedding matrix of the newly available view to solve the fused consensus spectral embedding matrix and consensus label matrix. To further enhance clustering performance, OIMvSC introduces graph linkage learning, which reduces erroneous connections between clusters while preserving correct connections within clusters. A convergent iterative algorithm for solving OIMvSC is proposed. Experimental results demonstrate that OIMvSC exhibits excellent clustering performance.},
  archive      = {J_NEUCOM},
  author       = {Weijun Wang and Ling Jing},
  doi          = {10.1016/j.neucom.2024.127740},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127740},
  shortjournal = {Neurocomputing},
  title        = {One-step incremental multi-view spectral clustering based on graph linkage learning},
  volume       = {590},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mitigating biases in long-tailed recognition via
semantic-guided feature transfer. <em>NEUCOM</em>, <em>590</em>, 127735.
(<a href="https://doi.org/10.1016/j.neucom.2024.127735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dealing with significant class imbalance poses a significant challenge in various real-world applications, particularly when the accurate classification and generalization of minority classes are of crucial. One key factor that results in model biases is the inadequate representation of intra-class diversity in samples from tail classes. To tackle this challenge, transfer learning strategies have emerged as a viable approach to promote the data distribution of tail classes by transferring feature learned from head classes. However, existing methods often assume that transferability exists between any head class and tail class, and randomly transfer information during training, which can be problematic when the head and tail classes have uncorrelated semantics. To tackle this problem, we propose a novel feature transfer strategy to promote the learning of discriminative representations for tail classes. Firstly, we compute the semantic similarity in a hybrid manner by combining local visual features and global semantic features. Secondly, we utilize the Gaussian mixture model to represent each class with multiple and anisotropic prototypes, which helps us fit the actual distribution accurately. We then carry out distribution-aware head-to-tail feature transfer, leveraging an optimization objective that can derive a computationally efficient closed-form upper bound. This procedure mitigates representation biases in the feature space and achieves state-of-the-art results on CIFAR100-LT, ImageNet-LT, and iNaturalist long-tailed benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Sheng Shi and Peng Wang and Xinfeng Zhang and Jianping Fan},
  doi          = {10.1016/j.neucom.2024.127735},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127735},
  shortjournal = {Neurocomputing},
  title        = {Mitigating biases in long-tailed recognition via semantic-guided feature transfer},
  volume       = {590},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel two-stage wrapper feature selection approach based
on greedy search for text sentiment classification. <em>NEUCOM</em>,
<em>590</em>, 127729. (<a
href="https://doi.org/10.1016/j.neucom.2024.127729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is a crucial step in obtaining subjective data from online text sources. Nevertheless, the substantial challenge of high dimensionality prevails within text classification. Addressing this, dimension reduction emerges as a valuable approach to enhance the efficacy of classification in the domain of machine learning. The discerning removal of redundant features not only expedites training processes but also bolsters the achievement of accurate classifications. It is worth noting that the effectiveness of distinct feature selection methodologies can be contingent upon the unique attributes inherent in diverse datasets. Within the purview of this investigation, a novel two-stage approach is introduced, characterized by a greedy search-based wrapper feature selection algorithm. The underpinning of this algorithm involves leveraging the outcomes yielded by filter-based feature selection techniques to establish a prioritized sequence for the scrutiny of features within the proposed framework. This strategic sequencing harnesses the cumulative insights from a series of filter-based methodologies, thereby facilitating the curation of feature subsets that underscore pivotal attributes. Nonetheless, it is acknowledged that the greedy selection approach primarily favors features with high-ranking scores, and thus, it may not adequately evaluate the potential of feature combinations that involve low-scoring elements. An extensive experimental inquiry was conducted across widely recognized sentiment analysis datasets to assess the performance of the introduced methodology. The computational findings eloquently demonstrate that the proposed algorithm attains an average accuracy of 96.88% for nine public sentiment datasets and 94.43% for the Humir datasets when coupled with the multinomial Naive Bayes classifier. Furthermore, the experimental outcomes conspicuously establish the superiority of the proposed technique in state-of-the-art studies across the same set of nine sentiment datasets and the Humir datasets.},
  archive      = {J_NEUCOM},
  author       = {Ensar Arif Sağbaş},
  doi          = {10.1016/j.neucom.2024.127729},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127729},
  shortjournal = {Neurocomputing},
  title        = {A novel two-stage wrapper feature selection approach based on greedy search for text sentiment classification},
  volume       = {590},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic-aware normalizing flow with feature fusion for
image anomaly detection. <em>NEUCOM</em>, <em>590</em>, 127728. (<a
href="https://doi.org/10.1016/j.neucom.2024.127728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of computer vision, anomaly detection is a binary classification task used to identify exceptional instances within image datasets. Typically, it can be divided into two aspects: texture defect detection and semantic anomaly detection. Existing methods often use pre-trained feature extractors to singly capture semantic or spatial features of images, and then employ different classifiers to handle these two types of anomaly detection tasks. However, these methods fail to fully utilize the synergistic relationship between these two types of features, resulting in algorithms that excel in one type of anomaly detection task but perform poorly in the other type. Therefore, we propose a novel approach that successfully combines these two types of features into a normalizing flow learning module to address both types of anomaly detection tasks. Specifically, we first adopt a pre-trained Vision Transformer (ViT) model to capture both texture and semantic features of input images. Subsequently, using the semantic features as input, we design a novel normalizing flow model to fit the semantic distribution of normal data. In addition, we introduce a feature fusion module based on attention mechanisms to integrate the most relevant texture and semantic information between these two types of features, significantly enhancing the model’s ability to simultaneously represent the spatial texture and semantic features of the input image. Finally, We conduct comprehensive experiments on well-known semantic and texture anomaly detection datasets, namely Cifar10 and MVTec, to evaluate the performance of our proposed method. The results demonstrate that our model achieves outstanding performance in both semantic and texture anomaly detection tasks, particularly achieving state-of-the-art results in semantic anomaly detection.},
  archive      = {J_NEUCOM},
  author       = {Wei Ma and Yao Li and Shiyong Lan and Wenwu Wang and Weikang Huang and Wujiang Zhu},
  doi          = {10.1016/j.neucom.2024.127728},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127728},
  shortjournal = {Neurocomputing},
  title        = {Semantic-aware normalizing flow with feature fusion for image anomaly detection},
  volume       = {590},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ZS-SRT: An efficient zero-shot super-resolution training
method for neural radiance fields. <em>NEUCOM</em>, <em>590</em>,
127714. (<a href="https://doi.org/10.1016/j.neucom.2024.127714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Radiance Fields (NeRF) have achieved great success in the task of synthesizing novel views that preserve the same resolution as the training views. However, it is challenging for NeRF to synthesize high-quality high-resolution novel views with low-resolution training data. To solve this problem, we propose a zero-shot super-resolution training framework (ZS-SRT) for NeRF. This framework aims to guide the NeRF model to synthesize high-resolution novel views via single-scene internal learning rather than requiring any external high-resolution training data. Our method consists of two stages. First, we learn a scene-specific degradation mapping by performing internal learning on a pretrained low-resolution coarse NeRF. Second, we optimize a super-resolution fine NeRF by conducting inverse rendering with our mapping function so as to backpropagate the gradients from low-resolution 2D space into the super-resolution 3D sampling space. Then, we further introduce a temporal ensemble strategy in the inference phase to compensate for the scene estimation errors. Our method is featured on two points: (1) it does not consume high-resolution views or additional scene data to train super-resolution NeRF; (2) it can speed up the training process by adopting a coarse-to-fine strategy. By conducting extensive experiments on public datasets, we have qualitatively and quantitatively demonstrated the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Xiang Feng and Yongbo He and Yubo Wang and Chengkai Wang and Zhenzhong Kuang and Jiajun Ding and Feiwei Qin and Jun Yu and Jianping Fan},
  doi          = {10.1016/j.neucom.2024.127714},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127714},
  shortjournal = {Neurocomputing},
  title        = {ZS-SRT: An efficient zero-shot super-resolution training method for neural radiance fields},
  volume       = {590},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised graph autoencoder with redundancy reduction
for community detection. <em>NEUCOM</em>, <em>590</em>, 127703. (<a
href="https://doi.org/10.1016/j.neucom.2024.127703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection is a significant research topic in network science, which has been revisited with graph neural networks. As a powerful graph representation learning model, graph autoencoder (GAE) is commonly used for unsupervised community detection. However, most GAE-based methods ignore multi-scale features of encoding layers, which inherently provide useful information for community detection. Moreover, these methods fail to simultaneously improve the representation learning process and clustering performance through a unified objective function. To address these issues, we propose a self-supervised graph autoencoder model with redundancy reduction for community detection. Firstly, we introduce a multi-scale module based on GAE to obtain discriminative node representations from different encoding layers. In particular, a redundancy reduction strategy is employed to eliminate redundancy information in the latent embedding space. Then, a node clustering module is used to obtain initial community labels. To fully utilize the multi-scale features to further refine clustering performance, a self-supervised module is designed to utilize current clustering labels to supervise the node representation learning process, thus constructing an end-to-end model for community detection. Finally, we validate the effectiveness of the proposed method on real-world networks. Experimental results demonstrate that our method outperforms several state-of-the-art methods in community detection.},
  archive      = {J_NEUCOM},
  author       = {Xiaofeng Wang and Guodong Shen and Zengjie Zhang and Shuaiming Lai and Shuailei Zhu and Yuntao Chen and Daying Quan},
  doi          = {10.1016/j.neucom.2024.127703},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127703},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised graph autoencoder with redundancy reduction for community detection},
  volume       = {590},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TISE-LSTM: A LSTM model for precipitation nowcasting with
temporal interactions and spatial extract blocks. <em>NEUCOM</em>,
<em>590</em>, 127700. (<a
href="https://doi.org/10.1016/j.neucom.2024.127700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precipitation nowcasting has a profound impact on humanity and society, especially in areas with heavy rainfall, playing a central role in alerting against rainstorm disasters. At present, numerous deep learning-based methods have been proposed and proven superior to traditional radar echo extrapolation techniques like the Recurrent Neural Networks (RNNs). Our study introduces a novel precipitation forecasting model named TISE-LSTM, which can use the real image of the past half hour to predict the radar echo image of the next hour. By integrating the TIB and SEB into TISL-LSTM, we can alleviate the inherent issue observed in existing models, which is the decrease in forecast accuracy for high radar echo regions with extended extrapolation time. On both the CIKM23017 and AHEM real radar echo datasets, the performance of TISL-LSTM (including POD, FAR, CSI and HSS) is improved compared to the second-ranked model by 7.53%, 2.32%, 8.93%, 2.6%, and 14.84%, 6.18%, 8.92%, 18.12%, respectively, when the precipitation threshold is set to 40. Moreover, our model obtained an optimal MAE, MSE, SSIM score. Predicted images and the graphs of each metric over extrapolation time both demonstrate that our model accurately forecasts regions with high radar echoes even with a one-hour extrapolation.},
  archive      = {J_NEUCOM},
  author       = {Changyong Zheng and Yifan Tao and Jingjing Zhang and Lina Xun and Teng Li and Qing Yan},
  doi          = {10.1016/j.neucom.2024.127700},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127700},
  shortjournal = {Neurocomputing},
  title        = {TISE-LSTM: A LSTM model for precipitation nowcasting with temporal interactions and spatial extract blocks},
  volume       = {590},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Attention-based adaptive structured continuous sparse
network pruning. <em>NEUCOM</em>, <em>590</em>, 127698. (<a
href="https://doi.org/10.1016/j.neucom.2024.127698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural network models, especially CNNs, have a wide range of applications in many fields, but their high computational power requirements limit the deployment applications in many resource-constrained embedded devices. Pruning techniques reduce the computational power requirements of models by removing redundant structures from CNNs. Most existing static pruning methods use a global uniform pruning rate to prune pre-trained models and require finetuning to recover accuracy after pruning, resulting in high training costs, and the global uniform pruning rate is sub-optimal. While dynamic pruning methods perform pruning during training and use auxiliary modules to calculate the saliency scores of channels, but do not exploit its function of assisting network training. We propose an adaptive structured continuous sparse network pruning method based on the attention mechanism that prunes the original network during training. The attention-based channel similarity calculation module calculates the channel saliency scores while refining features to assist network training, and the adaptive continuous sparse control module gradually discretizes the channel saliency scores and assigns the pruning rate of each layer according to the preset pruning rate target. The pruned model is output after training and no additional fine-tuning is required. We validate the proposed method on CIFAR-10 and the large-scale dataset Imagenet using networks with different structures, and our method outperforms the comparative pruning methods at different pruning rates. In CIFAR-10, our method can reduce VGG-16 by 34.4% FLOPs while top-1 accuracy increased by 0.19%. In Imagenet, we can reduce ResNet-34 by 51.5% FLOPs, while the top-1 accuracy decreases by only 0.89%.},
  archive      = {J_NEUCOM},
  author       = {Jiaxin Liu and Wei Liu and Yongming Li and Jun Hu and Shuai Cheng and Wenxing Yang},
  doi          = {10.1016/j.neucom.2024.127698},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127698},
  shortjournal = {Neurocomputing},
  title        = {Attention-based adaptive structured continuous sparse network pruning},
  volume       = {590},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Iterative image rain removal network using consecutive
residual long short-term memory. <em>NEUCOM</em>, <em>589</em>, 127752.
(<a href="https://doi.org/10.1016/j.neucom.2024.127752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image rain removal is designed to effectively separate rain streaks from the background image layer. However, rain streaks in real-world scenarios vary in density, shape, and direction, making it difficult to decompose rainy images into clean backgrounds and rain layers. In this study, we introduce an iterative framework for image deraining to progressively enhance rainy images using a residual long short-term memory structure. The overall network comprises a multidomain residue channel, a fusion module, and a consecutive residual long short-term memory. We introduce multidomain residue channels by computing them in both the image and wavelet low-frequency domains. We propose a fusion module to combine the residue channel for guidance with wavelet domain features for rain removal. We also propose a feature extraction module based on successive residual long short-term memory to extract the main features in the wavelet domain. An iterative image restoration framework comprising three primary modules is introduced to progressively enhance rainy images. To evaluate the performance of the proposed approach, we conduct experiments using widely used benchmarks. The results demonstrate that our method outperforms state-of-the-art methods in image rain removal https://github.com/workofsu/ .},
  archive      = {J_NEUCOM},
  author       = {Su Yeon Park and Tae Hee Park and Il Kyu Eom},
  doi          = {10.1016/j.neucom.2024.127752},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127752},
  shortjournal = {Neurocomputing},
  title        = {Iterative image rain removal network using consecutive residual long short-term memory},
  volume       = {589},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weakly supervised classification through manifold learning
and rank-based contextual measures. <em>NEUCOM</em>, <em>589</em>,
127717. (<a href="https://doi.org/10.1016/j.neucom.2024.127717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last decade, significant advances have been achieved by machine learning approaches, notably in supervised learning scenarios. Supported by the advent of deep learning and comprehensive training sets, the accuracy achieved on classification tasks has improved significantly. Simultaneously, we have experienced massive growth in multimedia data and applications, which have become ubiquitous in several domains. However, with the increase in multimedia data collections, significant bottlenecks associated with the lack of labeled data emerged. To surpass this critical issue, developing methods capable of exploiting the unlabeled data and operating under weak supervision has become imperative. This work proposes a rank-based model capable of using contextual information encoded in the unlabeled data to perform weakly supervised classification. We evaluated the proposed weakly supervised approach on multimedia classification tasks with and without manifold learning algorithms, considering several combinations of rank correlation measures and classifiers. An experimental evaluation was conducted on 6 public image datasets considering different features, including convolutional neural networks and visual transformers. Positive gains were achieved compared to supervised and semi-supervised baselines for the same amount of labeled data. For instance, the proposed approach with manifold learning enhanced the accuracy of the Optimum-Path Forest (OPF) classifier from 71.77% to 83.24% when applied to the Flowers dataset and ResNet features. Among the conclusions, this work reveals that rank-based correlation measures and manifold learning can be used for a more effective labeled set expansion.},
  archive      = {J_NEUCOM},
  author       = {João Gabriel Camacho Presotto and Lucas Pascotti Valem and Nikolas Gomes de Sá and Daniel Carlos Guimarães Pedronette and João Paulo Papa},
  doi          = {10.1016/j.neucom.2024.127717},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127717},
  shortjournal = {Neurocomputing},
  title        = {Weakly supervised classification through manifold learning and rank-based contextual measures},
  volume       = {589},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trust region policy optimization via entropy regularization
for kullback–leibler divergence constraint. <em>NEUCOM</em>,
<em>589</em>, 127716. (<a
href="https://doi.org/10.1016/j.neucom.2024.127716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust region policy optimization (TRPO) is one of the landmark policy optimization algorithms in deep reinforcement learning. Its purpose is to maximize a surrogate objective based on an advantage function, subject to the limited Kullback–Leibler (KL) divergence of two consecutive policies. Although there have been many successful applications of this algorithm in the literature, the approach has often been criticized for suppressing the exploration ability of some application environments due to its strict divergence constraint. As such, most researchers prefer to use entropy regularization, which is added to the expected discounted rewards or the surrogate objectives. That said, there is much debate about whether there might be an alternative strategy for regularizing TRPOs. In this paper, we present just that. Our strategy is to regularize the KL divergence-based constraint via Shannon entropy. This approach enlarges the difference between two consecutive policies and thus derives a new TRPO scheme with entropy regularization for use with KL divergence constraint. Next, the surrogate objective and Shannon entropy are approximated linearly, while the KL divergence is expanded quadratically. An efficient conjugate gradient optimization procedure then solves two sets of linear equations, providing a detailed code-level implementation that can be used for a fair experimental comparison. Extensive experiments within eight benchmark environments demonstrate that our proposed method is superior to both the original TRPO and the entropy regularized objective TRPO. Further, theoretical and experimental analysis shows that three TRPO-like methods have an equal time complexity and a close computational burden.},
  archive      = {J_NEUCOM},
  author       = {Haotian Xu and Junyu Xuan and Guangquan Zhang and Jie Lu},
  doi          = {10.1016/j.neucom.2024.127716},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127716},
  shortjournal = {Neurocomputing},
  title        = {Trust region policy optimization via entropy regularization for Kullback–Leibler divergence constraint},
  volume       = {589},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PatchDetector: Pluggable and non-intrusive patch for small
object detection. <em>NEUCOM</em>, <em>589</em>, 127715. (<a
href="https://doi.org/10.1016/j.neucom.2024.127715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is one of the core tasks in computer vision that serves as a crucial underpinning for numerous applications. In recent years, deep learning-based methods have achieved remarkable performance in object detection. However, the performance of small objects still remains unsatisfactory. Therefore, some specific architectures have been proposed to address this issue in certain areas, such as remote-sensing and UAV images. In this paper, we aim to design a pluggable and non-intrusive method, termed as PatchDetector, to improve the performance of small object detection, which can effectively avoid the time and resource overhead of retraining the entire network. To achieve that, we first analyze why the mainstream networks perform poorly on small objects and find out that the fundamental reason is that the features of small are superseded by the background, which leads to a significant semantic gap in multi-level layers. Then, significance analysis is conducted to find the essential features for improving the small object detection. Next, with the located significant features, we devise a pluggable patch network for extracting essential features for small objects, which is non-intrusive to the original network. Experiments on mainstream detectors, including YOLO series and Faster RCNN, show that the proposed PatchDetector achieves 0 . 4 % ∼ 2 . 0 % 0.4%∼2.0% mAP on small objects while not compromising the performance of medium and large objects.},
  archive      = {J_NEUCOM},
  author       = {Linyun Zhou and Shengxuming Zhang and Tian Qiu and Wenxiang Xu and Zunlei Feng and Mingli Song},
  doi          = {10.1016/j.neucom.2024.127715},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127715},
  shortjournal = {Neurocomputing},
  title        = {PatchDetector: Pluggable and non-intrusive patch for small object detection},
  volume       = {589},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-parametric gaussian process movement primitive with
via-point constraint for effective and safe robot skill learning.
<em>NEUCOM</em>, <em>589</em>, 127711. (<a
href="https://doi.org/10.1016/j.neucom.2024.127711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from demonstration (LFD) algorithms has been proven to be an effective way to encode basic human skills, such as probabilistic movement primitives (ProMPs). However, such algorithms are based on parametric methods, which means that more effort is required to expand to multi-dimensional and high reproduction accuracy. In this article, a novel non-parametric LFD algorithm is proposed, named Gaussian process movement primitive based on Gaussian mixture regression (GPGR), which has lower computational complexity and high accuracy. We encapsulate the variability of the demonstration set into the prior of Gaussian processes and propose a necessary and sufficient condition to ensure that the generated trajectory can pass the expected via point with 100% probability, which is different from existing ProMPs and their variants. In addition, we propose a novel trajectory obstacle avoidance method. The method allows efficient and safe robot obstacle avoidance by solving for a small number of via points. The effectiveness of the algorithm is validated through a series of experiments on the LASA dataset and the Franka Emika Panda robot.},
  archive      = {J_NEUCOM},
  author       = {Jiayun Fu and Zhehao Jin and Andong Liu and Wen-An Zhang and Li Yu},
  doi          = {10.1016/j.neucom.2024.127711},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127711},
  shortjournal = {Neurocomputing},
  title        = {Non-parametric gaussian process movement primitive with via-point constraint for effective and safe robot skill learning},
  volume       = {589},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sampled-data model-free adaptive integral sliding mode
control for nonlinear continuous-time networked control systems with
fading channels and packet dropouts. <em>NEUCOM</em>, <em>589</em>,
127708. (<a href="https://doi.org/10.1016/j.neucom.2024.127708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a sampled-data model-free adaptive integral sliding mode control (SMFAISMC) scheme is presented for nonlinear continuous-time networked control systems (NCSs) where the control input of the NCSs is assumed to be transmitted over the fading channel and the random packet dropouts is encountered at the output side simultaneously. Firstly, the original nonlinear continuous-time NCSs are converted to a linearized sampled-data model by employing the dynamic linearization (DL) method. Then, the controller gain updating algorithm and the auxiliary prediction compensation strategy are designed to counteract the adverse effects of stochastic fading and packet dropouts, respectively. Furthermore, a SMFAISMC scheme with sampling period is constructed, which is almost data-driven except that the sampling period and the structure information from the state to the output are needed. Note that the introduction of the sampling period gives the SMFAISMC scheme the ability to suppress the disadvantages of poor convergence due to the improper selection of sampling time. Finally, the boundedness of the tracking error is proved by using the contraction mapping principle and the validity of the developed SMFAISMC scheme is further verified via simulation.},
  archive      = {J_NEUCOM},
  author       = {Lina Chang and Zhongsheng Hou},
  doi          = {10.1016/j.neucom.2024.127708},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127708},
  shortjournal = {Neurocomputing},
  title        = {Sampled-data model-free adaptive integral sliding mode control for nonlinear continuous-time networked control systems with fading channels and packet dropouts},
  volume       = {589},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The neural network models with delays for solving absolute
value equations. <em>NEUCOM</em>, <em>589</em>, 127707. (<a
href="https://doi.org/10.1016/j.neucom.2024.127707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An inverse-free neural network model with mixed delays is proposed for solving the absolute value equation (AVE) A x − | x | − b = 0 Ax−|x|−b=0 , which includes an inverse-free neural network model with discrete delay as a special case. By using the Lyapunov–Krasovskii theory and the linear matrix inequality (LMI) method, the developed neural network models are proved to be exponentially convergent to the solution of the AVE. Compared with the existing neural network models for solving the AVE, the proposed models feature the ability of solving a class of AVE with ‖ A − 1 ‖ &gt; 1 ‖A−1‖&amp;gt;1 . Numerical simulations are given to show the effectiveness of the proposed delayed neural network models.},
  archive      = {J_NEUCOM},
  author       = {Dongmei Yu and Gehao Zhang and Cairong Chen and Deren Han},
  doi          = {10.1016/j.neucom.2024.127707},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127707},
  shortjournal = {Neurocomputing},
  title        = {The neural network models with delays for solving absolute value equations},
  volume       = {589},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Coexistence and locally exponential stability of multiple
equilibrium points for fractional-order impulsive control
cohen–grossberg neural networks. <em>NEUCOM</em>, <em>589</em>, 127705.
(<a href="https://doi.org/10.1016/j.neucom.2024.127705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different from the existing multiple Mittag-Leffler stability or multiple asymptotic stability, the multiple exponential stability, which has explicit and faster convergence rate, is investigated in this paper for fractional-order impulsive control Cohen–Grossberg neural networks. First, by using the definition of Dirac delta function, the fractional-order control Cohen–Grossberg neural networks are translated into fractional-order impulsive neural networks, in which pulse effect relies on the fractional order of the addressed system. Then, based on maximum norm, 1 − 1− norm and general q − q− norm ( q = 2 n ) (q=2n) , a series of novel criteria are obtained respectively to ensure that such n − n− neuron neural networks can have ∏ i = 1 n ( 2 L i + 1 ) ∏i=1n(2Li+1) total equilibrium points and ∏ i = 1 n ( L i + 1 ) ∏i=1n(Li+1) locally exponentially stable equilibrium points, by utilizing the known fixed point theorem, the method of average impulsive interval, the theory of fractional-order differential equations, and the method of Lyapunov function. This paper’s investigation reveals the effects of impulsive function, impulsive interval, and fractional order on the dynamic behaviors. Finally, theoretical results are shown to be effective by four illustrative examples.},
  archive      = {J_NEUCOM},
  author       = {Jinsen Zhang and Xiaobing Nie},
  doi          = {10.1016/j.neucom.2024.127705},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127705},
  shortjournal = {Neurocomputing},
  title        = {Coexistence and locally exponential stability of multiple equilibrium points for fractional-order impulsive control Cohen–Grossberg neural networks},
  volume       = {589},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finding robust and influential nodes from networks under
cascading failures using a memetic algorithm. <em>NEUCOM</em>,
<em>589</em>, 127704. (<a
href="https://doi.org/10.1016/j.neucom.2024.127704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the research of complex networks, how to find a set of nodes in the network with the most extensive range in the propagation process, i.e., the Influence Maximization (IM) problem, is one of the focal topics. Existing studies mainly consider the information dissemination process on networks and how to select diffusive nodes efficiently, but little attention has been paid to changes related to the network structure. In reality, networked systems are exposed to uncertain interferences and even destructive sabotages, and cascading failures are one common destruction that can cause networks to collapse even if only a small number of nodes fail. In the case of various complex environmental factors, how to select robust and influential nodes, i.e., the robust influence maximization (RIM) problem, is of great importance in promoting the realistic application of the influence maximization problem. This paper investigates the RIM problem under cascading failures to address the shortcomings in previous studies. Based on existing research, a new performance evaluation metric, R S-cf , is designed to assess the level of robust influence in a numerical form. For solving the seed determination problem, a Memetic algorithm towards the RIM problem under cascading failures, MA-RIM CF , is designed to find nodes with stable information propagation capability guided by R S-cf . Experiments have been conducted on both synthetic and realistic networks to validate the performance of the algorithm. Results indicate that MA-RIM CF can obtain competitive candidates over existing approaches, and seeds with robust and influential abilities are generated to solve diffusion dilemmas.},
  archive      = {J_NEUCOM},
  author       = {Shun Cai and Shuai Wang and Minghao Chen},
  doi          = {10.1016/j.neucom.2024.127704},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127704},
  shortjournal = {Neurocomputing},
  title        = {Finding robust and influential nodes from networks under cascading failures using a memetic algorithm},
  volume       = {589},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synergizing triple attention with depth quality for RGB-d
salient object detection. <em>NEUCOM</em>, <em>589</em>, 127672. (<a
href="https://doi.org/10.1016/j.neucom.2024.127672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object refers to the conspicuous objects or regions within an image that stand out prominently from its surroundings. Depth maps are commonly utilized as supplementary inputs for salient object detection, referred to as RGB-D SOD. Due to the diverse acquisition sensors, such as infrared detectors and stereo cameras, the quality of acquired depth maps varies considerably. The low-quality depth introduces noise that seriously reduces detection accuracy. To tackle this problem, a triple attention architecture based on a 3D convolutional neural network tailored for quality-aware salient object detection is proposed in this paper, which capitalizes on the strengths across modality, channel, and spatial dimensions. The modality attention learns the quality factors based on the overall modal features. The channel attention highlights features in the dimension of channels, and the patch-level spatial attention establishes long-range dependencies. Thus, the quality factors, channel differences, and spatial contrast are combined to achieve global and local fusion. To enable the evaluations on low-quality depth maps, an assessment criterion is further introduced to categorize the RGB-D datasets. Experimental results of state-of-the-art methods on different quality levels demonstrate the proposed method’s effectiveness, especially for the low-quality depth.},
  archive      = {J_NEUCOM},
  author       = {Peipei Song and Wenyu Li and Peiyan Zhong and Jing Zhang and Piotr Konuisz and Feng Duan and Nick Barnes},
  doi          = {10.1016/j.neucom.2024.127672},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127672},
  shortjournal = {Neurocomputing},
  title        = {Synergizing triple attention with depth quality for RGB-D salient object detection},
  volume       = {589},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Kernel support vector machine classifiers with ℓ0-norm hinge
loss. <em>NEUCOM</em>, <em>589</em>, 127669. (<a
href="https://doi.org/10.1016/j.neucom.2024.127669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machines (SVMs) are some of the most successful machine learning models for binary classification problems. Their key idea is maximizing the margin from the data to the hyperplane subject to correct classification on training samples. In the SVM training model, hinge loss is sensitive to label noise and unstable for resampling. Moreover, binary loss is the most natural choice for modeling classification errors. Motivated by this, we focus on the kernel SVM with the ℓ 0 ℓ0 -norm hinge loss (referred to as ℓ 0 ℓ0 - KSVM ); this is a composite function of the hinge loss and ℓ 0 ℓ0 -norm, which has the potential to address the aforementioned challenges. In consideration of the non-convexity and non-smoothness of the ℓ 0 ℓ0 -norm hinge loss, we first characterize the limiting subdifferential of the ℓ 0 ℓ0 -norm hinge loss and then derive the equivalent relationship between the proximal stationary point, the Karush–Kuhn–Tucker point, and the local optimal solution of ℓ 0 ℓ0 -KSVM. Second, we develop an alternating direction method of multipliers for ℓ 0 ℓ0 -KSVM and find that any limit point of the sequence generated by the proposed algorithm is a locally optimal solution. Lastly, experiments on synthetic and real datasets demonstrate that ℓ 0 ℓ0 - KSVM can achieve comparable accuracy compared to the standard kernel SVMs and that the former generally results in fewer support vectors.},
  archive      = {J_NEUCOM},
  author       = {Rongrong Lin and Yingjia Yao and Yulan Liu},
  doi          = {10.1016/j.neucom.2024.127669},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127669},
  shortjournal = {Neurocomputing},
  title        = {Kernel support vector machine classifiers with ℓ0-norm hinge loss},
  volume       = {589},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RCDformer: Transformer-based dense depth estimation by
sparse radar and camera. <em>NEUCOM</em>, <em>589</em>, 127668. (<a
href="https://doi.org/10.1016/j.neucom.2024.127668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate depth cues are crucial for 3D perception tasks, and monocular depth estimation networks are no longer sufficient for realistic scenarios. Currently, the most effective approaches are to introduce depth information from other modalities into the image. Radar has become a popular sensor for fusion with cameras due to its low price and all-weather working characteristics. This paper aims to explore how to more effectively integrate the heterogeneous data of radar point clouds and RGB images to improve the performance of depth estimation. Most of the previous works have not fully exploited the potential of integrating these two modalities, so we propose RCDformer, a novel network based on the transformer architecture that fuses radar-camera for dense depth estimation. Without reducing the receptive field, our approach can fully model the contextual relationships between sensors to reduce the impact of radar noise on overall performance. With the proposed Radar-guided Multi-scale Depth Fusion (RGDF) module, the prior spatial information mapped by the Radar Feature Extractor (RFE) is embedded into a set of multi-scale hierarchical features output by Image Feature Extractor (IFE) via the modified deformable cross-attention, which aims to guide the depth prediction of images. Furthermore, we discover that incorporating the Radar Cross Section (RCS) attribute as an extended channel for the radar map is beneficial for dense depth estimation, which improves the overall performance of our model. We evaluate the proposed method on the nuScenes dataset, and the experiment results show that our method still achieves significant advantages in most metrics compared to the state-of-the-art models.},
  archive      = {J_NEUCOM},
  author       = {Xinyue Huang and Yongtao Ma and Zedong Yu and Haibo Zhao},
  doi          = {10.1016/j.neucom.2024.127668},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127668},
  shortjournal = {Neurocomputing},
  title        = {RCDformer: Transformer-based dense depth estimation by sparse radar and camera},
  volume       = {589},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differential privacy in deep learning: A literature survey.
<em>NEUCOM</em>, <em>589</em>, 127663. (<a
href="https://doi.org/10.1016/j.neucom.2024.127663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption of deep learning is facilitated in part by the availability of large-scale data for training desirable models. However, these data may involve sensitive personal information, which raises privacy concerns for data providers. Differential privacy has been thought of as a key technique in the privacy preservation field, which has drawn much attention owing to its capability of providing rigorous and provable privacy guarantees for training data. Training deep learning models in a differentially private manner is a topic that is gaining traction as this alleviates the reconstruction and inference of sensitive information effectively. Taking this cue, in this paper, we present here a comprehensive and systematic study on differentially private deep learning from the facets of privacy attack and privacy preservation. We explore a new taxonomy to analyze the privacy attacks faced in deep learning and then survey the type of privacy preservation based on differential privacy to tackle such privacy attacks in deep learning. Finally, we propose the first probe into the real-world application of differentially private deep learning, and then conclude with several potential future research avenues. This survey provides promising directions for protecting sensitive information in training data via differential privacy during deep learning model training.},
  archive      = {J_NEUCOM},
  author       = {Ke Pan and Yew-Soon Ong and Maoguo Gong and Hui Li and A.K. Qin and Yuan Gao},
  doi          = {10.1016/j.neucom.2024.127663},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127663},
  shortjournal = {Neurocomputing},
  title        = {Differential privacy in deep learning: A literature survey},
  volume       = {589},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TransPose: 6D object pose estimation with geometry-aware
transformer. <em>NEUCOM</em>, <em>589</em>, 127652. (<a
href="https://doi.org/10.1016/j.neucom.2024.127652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient and accurate estimation of objects’ pose is essential in numerous practical applications. Due to the depth data contains abundant geometric information, some existing methods devote to extract features from 3D point cloud. However, these depth-based methods focus on extracting the point cloud local features and consider less about the global information. How to extract and utilize the local and global geometry features in depth information is crucial to achieve accurate predictions. To this end, we propose TransPose , a novel 6D pose framework that exploits Transformer Encoder with geometry-aware module to develop better learning of point cloud feature representations. To better extract local geometry features, we finely design the graph convolution network-based feature extractor that first uniformly sample point cloud and extract point pair features of point cloud. To further improve robustness to occlusion, we adopt Transformer to perform the propagation of global information, making each local feature obtains global information. Moreover, we introduce geometry-aware module in Transformer Encoder, which to form an effective constrain for point cloud feature learning and makes the global information exchange more tightly coupled with point cloud tasks. Extensive experiments indicate the effectiveness of TransPose, our pose estimation pipeline achieves competitive results on three benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Xiao Lin and Deming Wang and Guangliang Zhou and Chengju Liu and Qijun Chen},
  doi          = {10.1016/j.neucom.2024.127652},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127652},
  shortjournal = {Neurocomputing},
  title        = {TransPose: 6D object pose estimation with geometry-aware transformer},
  volume       = {589},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive fixed-time dynamic surface tracking control for
high-order nonstrict-feedback nonlinear switched systems.
<em>NEUCOM</em>, <em>589</em>, 127590. (<a
href="https://doi.org/10.1016/j.neucom.2024.127590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the adaptive fixed-time neural tracking dynamic surface control (DSC) for high-order nonlinear switched systems. The uncertain nonlinear functions are approximated by neural networks (NNs). And the obstacles of high-order terms are eliminated by the adding a power integrator. A novel fixed-time convergence filter is proposed to refrain from the problem of repeated differentiation of virtual controllers. On the basis of the backstepping control algorithm and the common Lyapunov function (CLF) method, a novel adaptive fixed-time neural DSC strategy is developed. It is proven that the states in the closed-loop system are bounded and the tracking error converges to an area of zero in fixed time. The simulation experiments further verify the feasibility of the mentioned method.},
  archive      = {J_NEUCOM},
  author       = {Huanqing Wang and Zhu Meng and Jiawei Ma and Xudong Zhao},
  doi          = {10.1016/j.neucom.2024.127590},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127590},
  shortjournal = {Neurocomputing},
  title        = {Adaptive fixed-time dynamic surface tracking control for high-order nonstrict-feedback nonlinear switched systems},
  volume       = {589},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep operational audio-visual emotion recognition.
<em>NEUCOM</em>, <em>588</em>, 127713. (<a
href="https://doi.org/10.1016/j.neucom.2024.127713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotions play a large role in interpersonal communication, marketing, healthcare and the service industry. For this reason, much research has been carried out on emotion classification until today. Audio-visual emotion recognition is a field within artificial intelligence and machine learning that focuses on recognizing and understanding human emotions from both visual and audio cues. It combines computer vision and audio processing techniques to analyze and interpret emotional states expressed by individuals. This paper presents a deep learning model developed over an operational neural network using multiple inputs and aimed at audio-visual emotion recognition. The proposed network utilizes both visual and audio information in an end to end approach. The primary objective of this work is to demonstrate that multi-input models can produce more efficient outcomes compared to single-input models in emotion classification. Another objective is to demonstrate the superior performance of weight calculation methods employed in operational neural networks compared to the conventional weight calculation methods used in convolutional neural networks. Therefore, we want to demonstrate that substituting convolutional neural network approaches with operational neural network methods can yield superior outcomes in emotion categorization models. In the proposed architecture, regular convolutional layers are replaced with operational layers. The experimental results demonstrate that the operational convolutional architecture performs better compared to the classical convolutional neural network architecture.},
  archive      = {J_NEUCOM},
  author       = {Kaan Aktürk and Ali Seydi Keçeli},
  doi          = {10.1016/j.neucom.2024.127713},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127713},
  shortjournal = {Neurocomputing},
  title        = {Deep operational audio-visual emotion recognition},
  volume       = {588},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Supervised contrastive learning for graph representation
enhancement. <em>NEUCOM</em>, <em>588</em>, 127710. (<a
href="https://doi.org/10.1016/j.neucom.2024.127710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have exhibited significant success in various applications, but they face challenges when labeled nodes are limited. A novel self-supervised learning paradigm has emerged, enabling GNN training without labeled nodes and even surpassing GNNs with limited labeled data. However, self-supervised methods lack class-discriminative node representations due to the absence of labeled information during training. In this paper, we exploit a supervised graph contrastive learning approach (SGCL) framework to tackle the issue of limited labeled nodes, ensuring coherent grouping of nodes within the same class. We propose augmentation techniques based on a novel centrality function to highlight important topological structures. Additionally, we introduce a supervised contrastive learning method that removes the necessity for negative samples and simplifies complex elements effortlessly. Our approach combines supervised contrastive loss and node similarity regularization while achieving consistent grouping of unlabeled nodes with labeled ones. Furthermore, we utilize the pseudo-labeling technique to propagate label information to distant nodes and address the underfitting problem, especially with low-degree nodes. Experimental results on real-world graphs demonstrate that SGCL outperforms both semi-supervised and self-supervised methods in node classification.},
  archive      = {J_NEUCOM},
  author       = {Mohadeseh Ghayekhloo and Ahmad Nickabadi},
  doi          = {10.1016/j.neucom.2024.127710},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127710},
  shortjournal = {Neurocomputing},
  title        = {Supervised contrastive learning for graph representation enhancement},
  volume       = {588},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Triple alignment-enhanced complex question answering over
knowledge bases. <em>NEUCOM</em>, <em>588</em>, 127709. (<a
href="https://doi.org/10.1016/j.neucom.2024.127709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Program induction is a crucial paradigm for complex question answering over knowledge bases. In the existing learning framework, the predicted program is required to strictly align (word-by-word) with a gold program, which could cause over penalization for minor deviations. Meanwhile, due to the existence of synonyms, program induction question answering often fails to retrieve answer from the knowledge base because individual function argument cannot perfectly replicate the target argument. To address above misalignment problems, we propose a triple alignment-enhanced complex question answering (TACQA) method by incorporating global token alignment, function alignment, and argument alignment. First, apart from the classical global token alignment, the predicted functions are extracted and aligned separately with the gold functions, enabling efficient learning of implicit structural information related to the query framework of program from input questions. Second, an argument alignment is introduced to correct the ambiguous function arguments, which enhances the disambiguation processing efficiency of multi-argument by optimizing candidate pool construction and similarity calculation. The experiments on KQA Pro show that our method consistently outperforms the SOTA methods, demonstrating the effectiveness of triple alignment processing mechanism for simultaneously addressing function misalignment and argument ambiguity in program induction and further improving the model performance.},
  archive      = {J_NEUCOM},
  author       = {Dong Wang and Sihang Zhou and Jian Huang and Xiangrong Ni},
  doi          = {10.1016/j.neucom.2024.127709},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127709},
  shortjournal = {Neurocomputing},
  title        = {Triple alignment-enhanced complex question answering over knowledge bases},
  volume       = {588},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal control strategies and target selection in
multi-pursuer multi-evader differential games. <em>NEUCOM</em>,
<em>588</em>, 127701. (<a
href="https://doi.org/10.1016/j.neucom.2024.127701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with a conflict that N N -pursuers versus M M -evaders. It is a multi-pursuer multi-evader game extended from classical differential game theory to simultaneously address target selection and multi-player pursuit-evasion. Every pursuer attempts to intercept the evader it has chosen as its target while every evader does the opposite. This is modeled as a multi-player nonzero-sum differential game under a weighted directed graph. Moreover, a novel and more practical framework, the Unique-Choice (UC) games framework, is provided. Hamilton–Jacobi–Isaacs (HJI) is used for solving the game to derive the optimal distributed control strategy for each player based on graph theory. An important but has not been extensively studied issue, target selection, is studied. Different from the former research, this paper proposes a more reasonable criterion for target selection which makes the cost of pursuers minimized. The pursuers are proven to intercept evaders successfully with the proposed optimal pursuit strategy. Several illustrative examples under two different cases are presented, and the results show that the cost of pursuers with the proposed target selection algorithm is the minimum of all results.},
  archive      = {J_NEUCOM},
  author       = {Yinglu Zhou and Yinya Li and Andong Sheng and Guoqing Qi and Jinliang Cong},
  doi          = {10.1016/j.neucom.2024.127701},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127701},
  shortjournal = {Neurocomputing},
  title        = {Optimal control strategies and target selection in multi-pursuer multi-evader differential games},
  volume       = {588},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-YOLOv8: An infrared moving small object detection
model based on YOLOv8 for air vehicle. <em>NEUCOM</em>, <em>588</em>,
127685. (<a href="https://doi.org/10.1016/j.neucom.2024.127685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of infrared moving small objects faces significant challenges in the field of object detection for air vehicles. These types of objects usually occupy a small number of pixels in an infrared image, resulting in limited feature information, considerable feature loss, low recognition accuracy, and various challenges in single-frame detection. To address these challenges, this paper proposes an efficient multi-input method named Multi-YOLOv8, which is based on the YOLOv8s model. The proposed method uses current frames as a primary input and incorporates optical flow processing images and background suppression images as auxiliary inputs to improve detection performance. In addition, an improved method is developed for optical flow computations, named the pyramidal weight-momentum Horn–Schunck (PWMHS) method, which can process optical flows efficiently and precisely. An improved version of the Wise-IoU (WIoU) v3, referred to as α* -WIoU v3, is proposed as a bounding box regression (BBR) loss function to optimize the YOLOv8 network. Further, the BiFormer module and lightweight convolution GSConv are introduced to improve the attention to key information for the objects and balance the computational cost and detection performance, respectively. Moreover, a small object detection layer is added the YOLOv8 network to improve the capability for small object detection. Finally, a warming-up training method that can reduce the dependency on auxiliary inputs and ensure model stability in case of auxiliary input failures is developed. The results of the comprehensive experiments on an open-access dataset reveal that the proposed model outperforms the mainstream models in overall performance. The proposed method can significantly enhance the detection ability of infrared moving small objects.},
  archive      = {J_NEUCOM},
  author       = {Shizun Sun and Bo Mo and Junwei Xu and Dawei Li and Jie Zhao and Shuo Han},
  doi          = {10.1016/j.neucom.2024.127685},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127685},
  shortjournal = {Neurocomputing},
  title        = {Multi-YOLOv8: An infrared moving small object detection model based on YOLOv8 for air vehicle},
  volume       = {588},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simplified neural architecture for efficient human motion
prediction in human-robot interaction. <em>NEUCOM</em>, <em>588</em>,
127683. (<a href="https://doi.org/10.1016/j.neucom.2024.127683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human motion prediction is essential for safe and effective human-robot interaction, but modeling the intricate spatio-temporal dynamics inherent in human movement remains challenging. While recent methods have advanced motion prediction accuracy, they rely on complex neural architectures such as Graph Convolutional Networks and Recurrent Neural Networks, demanding extensive hyperparameter tuning. To overcome this limitation, we propose a streamlined multi-stage layer incremental perceptron (MSLP) architecture that achieves competitive results with far fewer parameters, improving efficiency. The MSLP eschews the complexity of prevalent networks and instead takes a stepped refinement approach to predict intricate motions using a lightweight model. This simplified yet effective design enables nuanced learning of spatio-temporal relationships without exhaustive tuning. Specifically, the MSLP incorporates two key components: a multi-channel feature extraction and enhancement block (MFE-block) and a temporal feature extraction module (TFE-block). The MFE-block strengthens the representation of each action node by integrating multi-dimensional action features. The TFE-block then captures the contextual relationships between actions over time. Together, the MFE-block and TFE-block allow the MSLP to model the complex spatial and temporal dynamics of human movement using a streamlined architecture and minimal parameter tuning. When evaluated on established datasets including Human3.6 M, CMU, 3DPW, and AMASS, the proposed MSLP method achieves improved accuracy gains of 16.7%-67.0% over existing state-of-the-art techniques. Additionally, the MSLP significantly reduces the number of parameters by 35.7%-99.5% compared to prior architectures. We find that the proposed MSLP significantly improves both long-term prediction and generalization capabilities of the model.},
  archive      = {J_NEUCOM},
  author       = {Juncheng Zou},
  doi          = {10.1016/j.neucom.2024.127683},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127683},
  shortjournal = {Neurocomputing},
  title        = {Simplified neural architecture for efficient human motion prediction in human-robot interaction},
  volume       = {588},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ConvTKG: A query-aware convolutional neural network-based
embedding model for temporal knowledge graph completion.
<em>NEUCOM</em>, <em>588</em>, 127680. (<a
href="https://doi.org/10.1016/j.neucom.2024.127680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge graphs (TKGs) are still far from completeness although they have benefited many artificial intelligence applications successfully. To alleviate the incompleteness of TKGs, temporal knowledge graph completion (TKGC) aims to perform link prediction and reason new time-sensitive facts from existing facts. Among the various TKGC methods, temporal knowledge graph embedding (TKGE) methods represent entities, relations, and timestamps in low-dimensional spaces, which are known for their high reasoning performance and robust scalability. Some previous researches on TKGE aim to endow the embedding quadruple with the translational characteristic by modeling the global relationship in the embedding quadruple. However, the weights of same dimensional entries of the embedding quadruple are fixed and unique, which limits the ability to capture diverse global relationships. Besides, most TKGE models view timestamps as a kind of general feature and overlook their interrelations and correlations with the queries. Moreover, the distinct characteristics of an entity as the subject entity and the object entity of facts have not been fully leveraged. In this paper, we propose a query-aware embedding model based on the convolutional neural network (CNN) named ConvTKG to perform TKGE, thus tackling the TKGC task. We design a new temporal information encoder based on the Gated Recurrent Unit (GRU) and attention mechanism to learn the query-aware representation of temporal information. More importantly, we utilize a CNN-based decoder where multiple one-dimensional convolution kernels are operated on the matrix composed of entity embedding, relation embedding, and temporal representation to capture global relationships among them. In addition, we assign two independent vectors for each entity and take advantage of the inverse relation to allow them to be learned dependently. Experiments show that ConvTKG achieves better link prediction performance than previous state-of-the-art baseline methods for TKGC on three benchmark datasets: ICEWS14, ICEWS05-15, and GDELT.},
  archive      = {J_NEUCOM},
  author       = {Mingsheng He and Lin Zhu and Luyi Bai},
  doi          = {10.1016/j.neucom.2024.127680},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127680},
  shortjournal = {Neurocomputing},
  title        = {ConvTKG: A query-aware convolutional neural network-based embedding model for temporal knowledge graph completion},
  volume       = {588},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical knowledge-enhancement framework for multi-hop
knowledge graph reasoning. <em>NEUCOM</em>, <em>588</em>, 127673. (<a
href="https://doi.org/10.1016/j.neucom.2024.127673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-hop reasoning has gained significant attention in the area of knowledge graph completion, intending to predict missing facts through existing knowledge. However, due to sparsity knowledge and lack of reachable paths for the model to make sensible decisions, most multi-hop reasoning models suffer from degradation performance on the sparse knowledge graphs (KGs). Faced with this challenge, we propose the Hierarchical Knowledge-Enhancement Framework (Hi-KnowE), which improves reasoning performance over sparse KGs by conducting hierarchical dynamic path completion under various background knowledge guidance. Hi-KnowE is based on hierarchical reinforcement learning, breaking the task into high-level and low-level processes. Firstly, we apply high-level policy to reason relations and the relation action space is enlarged under rule guidance. Secondly, tail entities are obtained by low-level policy and semantic knowledge is used to refine the entity action space. The sparsity problem is alleviated by generating reliable information. Moreover, we introduce rule-based inner attention, adopting the overall semantics of relevant rules to assist agent reasoning. This strategy makes the path for the agent more logical and flexible. We further evaluate Hi-KnowE on four sparse datasets extracted from Wikidata and FreeBase. The results outperform the baseline models, demonstrating improvements of up to 1.5% and 1.9% in MRR and Hit@10.},
  archive      = {J_NEUCOM},
  author       = {Shaorong Xie and Ruishen Liu and Xinzhi Wang and Xiangfeng Luo and Vijayan Sugumaran and Hang Yu},
  doi          = {10.1016/j.neucom.2024.127673},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127673},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical knowledge-enhancement framework for multi-hop knowledge graph reasoning},
  volume       = {588},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label-text bi-attention capsule networks model for
multi-label text classification. <em>NEUCOM</em>, <em>588</em>, 127671.
(<a href="https://doi.org/10.1016/j.neucom.2024.127671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label text classification (MLTC) is the process of establishing relationships between documents and their corresponding labels. Previous research has focused on mining textual information, treating labels as information-less vectors in classification. This ignores the semantic and dependency relationships of labels. In real-life scenarios, the neglect of label information contradicts the classification process, which presents significant challenges for MLTC tasks. Label embedding partially resolves label information loss. Efficiently exploring semantic and dependency relationships of labels and their text connections remains a new challenge. In this paper, we propose a Label-Text Bi-Attention Capsule Networks (LTBACN) model for in-depth exploration of the dependency relationships between labels and text. Specifically, we first incorporate label information into nodes through label embedding, construct a graph structure to represent the dependency relationships between labels, and use Graph Convolutional Networks (GCN) to propagate information between nodes to further mine the relationships between labels. Subsequently, we employ a label-text bi-attention mechanism to learn the feature relationships between labels and text. The label-to-text attention mechanism extracts label-relevant text representations, while the text-to-label attention mechanism extracts the most relevant label representations for the text. We then merge these two types of feature representations to obtain fused representations that incorporate label-text bi-directional information. Finally, the fused features are fed into a capsule network classifier to capture multi-level semantic information and match the corresponding labels. The experimental results demonstrate that LTBACN outperforms other methods in terms of classification effectiveness. Compared to state-of-the-art methods, LTBACN achieves a significant improvement of 0.41%–0.68% in M i c r o − F 1 Micro−F1 measure, 0.52%–3.26% in M a c r o − F 1 Macro−F1 measure, 0.32%–2.18% in P @ k P@k measure, and 0.01%–1.18% in n D C G @ k nDCG@k measure on the AAPD and RCV1-v2 datasets.},
  archive      = {J_NEUCOM},
  author       = {Gang Wang and Yajun Du and Yurui Jiang and Jia Liu and Xianyong Li and Xiaoliang Chen and Hongmei Gao and Chunzhi Xie and Yan-li Lee},
  doi          = {10.1016/j.neucom.2024.127671},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127671},
  shortjournal = {Neurocomputing},
  title        = {Label-text bi-attention capsule networks model for multi-label text classification},
  volume       = {588},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning visual stimulus-evoked EEG manifold for neural
image classification. <em>NEUCOM</em>, <em>588</em>, 127654. (<a
href="https://doi.org/10.1016/j.neucom.2024.127654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual neural decoding, namely the ability to interpret external visual stimuli from patterns of brain activity, is a challenging task in neuroscience research. Recent studies have focused on characterizing patterns of activity across multiple neurons that can be described in terms of population-level features. In this study, we combine spatial, spectral, and temporal features to achieve neural manifold classification capable to characterize visual perception and to simulate the working memory activity in the human brain. We treat spatio-temporal and spectral information separately by means of custom deep learning architectures based on Riemann manifold and the two-dimensional EEG spectrogram representation. In addition, a CNN-based classification model is used to classify visual stimulus-evoked EEG signals while viewing the 11-class (i.e., all-black plus 0-9 digit images) MindBigData Visual MNIST dataset. The effectiveness of the proposed integration strategy is evaluated on the stimulus-evoked EEG signal classification task, achieving an overall accuracy of 86%, comparable to state-of-the-art benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Salvatore Falciglia and Filippo Betello and Samuele Russo and Christian Napoli},
  doi          = {10.1016/j.neucom.2024.127654},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127654},
  shortjournal = {Neurocomputing},
  title        = {Learning visual stimulus-evoked EEG manifold for neural image classification},
  volume       = {588},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conditional visibility aware view synthesis via parallel
light fields. <em>NEUCOM</em>, <em>588</em>, 127644. (<a
href="https://doi.org/10.1016/j.neucom.2024.127644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the area of neural rendering-based novel view synthesis, illumination is important since shadows cast by objects under various light sources provide indications about their geometries and materials. However, due to high physical device complexity and simulation distortion, large-scale photorealistic multiple illumination multi-view datasets are difficult to obtain. In order to address this problem, a physical-virtual interactive parallel light fields based collection method is proposed in this paper. The physical part of parallel light fields is firstly used to capture 3D models and 2D images of objects under different lights. Then a Reak-to-Sim adaptation module was proposed to enhance realism by estimating material characteristic. Instead of manually setting, the learned resulting material parameters are then utilized to initialize virtual engine blender for subsequent rendering and data collection. Besides, to better handle self-occlusion problem in the acquired parallel light fields dataset, a conditional visibility module is designed in modeling visibility of each sampling point along a sampling ray. Compared with the Neuray, by introducing Conditional Normalizing Flow, visibility are assumed as samples from some distribution due to the fact that visibilities along the ray should be monotonically decreasing and are within the range of [ 0 , 1 ] [0,1] . The visibility are calculated in a data driven manner, which brings more flexibility. By pretraining the conditional visibility network in parallel light field dataset, experiments demonstrate that more photorealistic inputs improve Peak-Signal-Noise Ratio (PSNR) and Structure Similarity Index Measure (SSIM) by 0.11% and 0.68% in validation dataset NeRF synthesis and LLFF. Besides, compared to Neuray, the proposed conditional visibility module is more flexible and get a PSNR improvement of 0.55 and 0.5 in NeRF synthesis and LLFF dataset, respectively.},
  archive      = {J_NEUCOM},
  author       = {Yu Shen and Yuke Li and Yuhang Liu and Yutong Wang and Long Chen and Fei-Yue Wang},
  doi          = {10.1016/j.neucom.2024.127644},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127644},
  shortjournal = {Neurocomputing},
  title        = {Conditional visibility aware view synthesis via parallel light fields},
  volume       = {588},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A recurrent neural network approach for nonconvex interval
quadratic programming. <em>NEUCOM</em>, <em>588</em>, 127636. (<a
href="https://doi.org/10.1016/j.neucom.2024.127636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the paper, a new approach is presented to tackle an interval optimization problem with nonconvex interval objective function and affine interval equality and inequality constraints utilizing a recurrent neural network. The approach involves converting the nonconvex interval quadratic programming into a cubic optimization via convex combinations and considering its weight as a decision variable. The recurrent neural network is then established to solve the cubic optimization through subgradient techniques and an exterior penalty function method. Moreover, it is proven that there is a unique global solution to the recurrent neural network, and its trajectory can reach the feasible region in a finite time and remain there. Additionally, it is demonstrated that the trajectory of recurrent neural network converges exponentially or in finite time towards a singleton belonging to the set of critical points of the cubic optimization. This approach is beneficial for interval quadratic programming problems where the weight is unknown or challenging to determine in practical applications. Finally, the effectiveness of this approach is verified through two numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Jianmin Wang and Sitian Qin},
  doi          = {10.1016/j.neucom.2024.127636},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127636},
  shortjournal = {Neurocomputing},
  title        = {A recurrent neural network approach for nonconvex interval quadratic programming},
  volume       = {588},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A visual question and answering system with support for
compound emotions using facial landmark identification with MediaPipe
and CNN classifier. <em>NEUCOM</em>, <em>588</em>, 127623. (<a
href="https://doi.org/10.1016/j.neucom.2024.127623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question and Answering is a fast-evolving field of research where we attempt to answer the question based on an image as a context. In this paper, we try to add support for answering questions that are based on emotions with face detection and basic emotion extraction. With the basic emotions, we further try to find out compound emotions to expand the area of answerable questions. We complete the said operations in two stages: i) Caption generation. ii) Question and answering with that caption as context. The context generation process can be further divided into i) general caption generator ii) emotional caption generator. In general caption generator, we try to find a single sentence providing a basic information about the input context image, using an Attention [9] based model. In the later phase, the emotional caption generator finds the information of the emotions of the faces of the image using RetinaFace [20] and DeepFace [1] . In emotional caption generator, apart from basic emotion generation, we also try to find compound emotions depicted by each of the faces by learning the patterns in facial landmarks generated by MediaPipe [7] with CNN based architecture. In this module, we also generate a set of know question and answers to use in the next phase. As for the question and answering part, we first use BERT [4] for finding an answer, given a question and the captions generated as context of the question. If the confidence of answer exceeds a threshold value, we report that answer as final. If not, we try to find the known question similar to the asked question. The answer generated then is the final answer.},
  archive      = {J_NEUCOM},
  author       = {Lavika Goel and Nilarnab Debnath and Sanskar Mundaniya},
  doi          = {10.1016/j.neucom.2024.127623},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {127623},
  shortjournal = {Neurocomputing},
  title        = {A visual question and answering system with support for compound emotions using facial landmark identification with MediaPipe and CNN classifier},
  volume       = {588},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). CNN injected transformer for image exposure correction.
<em>NEUCOM</em>, <em>587</em>, 127688. (<a
href="https://doi.org/10.1016/j.neucom.2024.127688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capturing images with incorrect exposure settings fails to deliver a satisfactory visual experience. Only when the exposure is properly set, can the color and details of the images be appropriately preserved. Previous exposure correction methods based on convolutions often produce exposure deviation in images as a consequence of the restricted receptive field of convolutional kernels. This issue arises because convolutions are not capable of capturing long-range dependencies in images accurately. To overcome this challenge, we can apply the Transformer to address the exposure correction problem, leveraging its capability in modeling long-range dependencies to capture global representation. However, solely relying on the window-based Transformer leads to visually disturbing blocking artifacts due to the application of self-attention in small patches. In this paper, we propose a CNN Injected Transformer (CIT) to harness the individual strengths of CNN and Transformer simultaneously. Specifically, we construct the CIT by utilizing a window-based Transformer to exploit the long-range interactions among different regions in the entire image. Within each CIT block, we incorporate a channel attention block (CAB) and a half-instance normalization block (HINB) to assist the window-based self-attention to acquire the global statistics and refine local features. In addition to the hybrid architecture design for exposure correction, we apply a set of carefully formulated loss functions to improve the spatial coherence and rectify potential color deviations. Extensive experiments demonstrate that our image exposure correction method outperforms state-of-the-art approaches in terms of both quantitative and qualitative metrics.},
  archive      = {J_NEUCOM},
  author       = {Shuning Xu and Xiangyu Chen and Binbin Song and Caishi Huang and Jiantao Zhou},
  doi          = {10.1016/j.neucom.2024.127688},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127688},
  shortjournal = {Neurocomputing},
  title        = {CNN injected transformer for image exposure correction},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vision transformers are active learners for image copy
detection. <em>NEUCOM</em>, <em>587</em>, 127687. (<a
href="https://doi.org/10.1016/j.neucom.2024.127687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image Copy Detection (ICD) is developed to identify and track duplicated or manipulated images. The majority of existing methods rely on Convolutional Neural Networks (CNNs) and are trained using unsupervised learning techniques, which leads to subpar performance. We discover that by carefully designing the training process, Vision Transformer (ViT) backbones yield superior results. Specifically, directly training a ViT for ICD often leads to overfitting on the training images, which in turn results in poor generalization to unseen (test) images. Consequently, we initially train a CNN (such as ResNet-50), and during the ViT training, the distances between the features of CNN and ViT are regularized. We also incorporate an active learning method to further enhance performance. Notably, due to the visual discrepancy between auto-generated transformations and those used in the query set, we incorporate a small number (approximately 0.5% of unlabeled training images) of manually produced and labeled positive pairs. Training models on these pairs results in a significant performance boost though with little cost. Experimental findings demonstrate the effectiveness of our approach, and our method achieves state-of-the-art performance. Our code is available at: https://github.com/WangWenhao0716/ViT4ICD .},
  archive      = {J_NEUCOM},
  author       = {Zhentao Tan and Wenhao Wang and Caifeng Shan},
  doi          = {10.1016/j.neucom.2024.127687},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127687},
  shortjournal = {Neurocomputing},
  title        = {Vision transformers are active learners for image copy detection},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mix-tower: Light visual question answering framework based
on exclusive self-attention mechanism. <em>NEUCOM</em>, <em>587</em>,
127686. (<a href="https://doi.org/10.1016/j.neucom.2024.127686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual question answering (VQA) holds the potential to enhance artificial intelligence proficiency in understanding natural language, stimulate advances in computer vision technologies, and expand the range of practical applications. In the current domain of VQA, single-tower architectures suffer from huge parameter issues, whereas dual-tower architectures face some challenges due to insufficient cross-modal data interactions. To address these issues, we propose a novel Mix-Tower model, which is a simple, lightweight yet effective VQA model. Our model uses the self-attention mechanism Transformer as the base unit. In the pre-training phase, we train the model with only 1.15M data. In addition, we analyze the effect of three factors on the model performance, namely the number of different layers in Transformer, the number of layers in FeedForward Networks, and the combination of different class features. For downstream tasks, the OK-VQA and COCO-QA datasets are applied for performance validation. Experimental results show that our model outperforms the best-known baselines by 7.61% and 7.89% on the OK-VQA and COCO-QA datasets, respectively. Meanwhile, our minimal model has only 35M parameters, significantly smaller than the other baseline models. Various results demonstrate that our model achieves lightweight while maintaining superior performance. Our codes is available at: https://github.com/jianruichen/MixTower .},
  archive      = {J_NEUCOM},
  author       = {Deguang Chen and Jianrui Chen and Luheng Yang and Fanhua Shang},
  doi          = {10.1016/j.neucom.2024.127686},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127686},
  shortjournal = {Neurocomputing},
  title        = {Mix-tower: Light visual question answering framework based on exclusive self-attention mechanism},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi2Human: Controllable human image generation with
multimodal controls. <em>NEUCOM</em>, <em>587</em>, 127682. (<a
href="https://doi.org/10.1016/j.neucom.2024.127682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating high-quality and diverse human images presents a substantial difficulty within the field of computer vision, especially in developing controllable generative models that can utilize input from various modalities. Such models could enable innovative applications like digital human, fashion design, and content creation. In this study, we introduce Multi2Human, a two-stage image synthesis framework for controllable human image generation with multimodal controls . In the first stage, a novel WAvelet-vqVaE (WAVE) architecture is designed to embed human images using a learnable codebook. The WAVE model enhances the conventional Vector Quantized Variational Autoencoder (VQVAE) by integrating wavelets throughout the encoder, thereby enhancing the quality of image reconstruction and synthesis. In the second stage, a new Multimodal Conditioned Diffusion Model (MCDM) is designed to estimate the underlying prior distribution within the discrete latent space using a discrete diffusion process, thus allowing for human image generation conditioned on multimodal controls. Quantitative and qualitative analysis demonstrates that the proposed method has the ability to create high-quality, lifelike full-body human images while satisfying the specified multimodal controls. Our code is available at https://github.com/gxl-groups/Multi2Human .},
  archive      = {J_NEUCOM},
  author       = {Xiaoling Gu and Shengwenzhuo Xu and Yongkang Wong and Zizhao Wu and Jun Yu and Jianping Fan and Mohan S. Kankanhalli},
  doi          = {10.1016/j.neucom.2024.127682},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127682},
  shortjournal = {Neurocomputing},
  title        = {Multi2Human: Controllable human image generation with multimodal controls},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Learning-to-rank debias with popularity-weighted negative
sampling and popularity regularization. <em>NEUCOM</em>, <em>587</em>,
127681. (<a href="https://doi.org/10.1016/j.neucom.2024.127681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most learning-to-rank recommendation models assume users prefer interacted items more than non-interacted ones. All non-interacted items have the same chance to be selected as negative samples. However, the observed interaction data usually shows long-tailed distributions, making traditional recommendation models trained on such data tend to rank popular items higher than users’ true preference and degrading the performance of recommender systems. Some existing debias methods focus on eliminating such popularity bias, while simply removing all the popularity bias may diminish recommendation accuracy because popularity also contains some useful information implying item attractiveness, making it pivotal to handling popularity bias in proper ways. In this paper, popularity is recognized to have both positive and negative effects on recommendation. The positive effect of popularity should be amplified while the negative effect should be mitigated. Therefore, this paper proposes two novel schemes to distinguish the positive and negative impact of popularity in learning-to-rank models. First, we propose a popular-weighted sampler to sample non-interacted popular items from users’ collaborative items as negative samples with higher probabilities. We believe that if a popular item is collaboratively similar to a user but not interacted with by him, it is more likely to be a true negative sample for the user. We sample such items with higher probabilities to mitigate the harmful negative popularity bias. Second, popularity could be a significant indicator of items’ intrinsic quality. Hence, we design a popularity regularization scheme to capture item attractiveness, prompting cold-start users to prefer popular items. Finally, we conduct extensive experiments to evaluate the performance of the proposed schemes. Experimental results demonstrate that our approach can improve existing learning-to-rank models’ performance and outperform state-of-the-art debias methods.},
  archive      = {J_NEUCOM},
  author       = {Chenxu Wang and Aodian Liu and Tao Qin},
  doi          = {10.1016/j.neucom.2024.127681},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127681},
  shortjournal = {Neurocomputing},
  title        = {Learning-to-rank debias with popularity-weighted negative sampling and popularity regularization},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning scene-vectors for remote sensing image scene
classification. <em>NEUCOM</em>, <em>587</em>, 127679. (<a
href="https://doi.org/10.1016/j.neucom.2024.127679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representing the scenes by learning the subtle variations in the spatial content of different classes is crucial for scene classification in remote sensing images. In this paper, we propose a scene attribute modeling to obtain a discriminative and compact representation for scene classification. First, we construct a scene attribute model (SAM) by training a Gaussian mixture model (GMM) using convolutional features to capture the scene attributes implicitly. Then, we perform a maximum a posteriori (MAP) adaptation to enhance the contribution of significant attributes in each scene resulting in a high-dimensional feature vector which contains redundant attributes from all the scenes. Hence, we use factor analysis to obtain a compact representation of the high-dimensional feature vector termed scene-vector , which retains only the significant attributes specific to a scene. The proposed approach is demonstrated on three benchmark datasets, namely, UC Merced Land Use, AID, and NWPU-RESISC45 datasets. We further show that, being a compact representation, our scene-vector outperforms state-of-the-art methods for scene classification in remote sensing images.},
  archive      = {J_NEUCOM},
  author       = {Rajeshreddy Datla and Nazil Perveen and Krishna Mohan C.},
  doi          = {10.1016/j.neucom.2024.127679},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127679},
  shortjournal = {Neurocomputing},
  title        = {Learning scene-vectors for remote sensing image scene classification},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The stability and statistic of domain decomposition
algorithm with mini-batch learning for optimal transport.
<em>NEUCOM</em>, <em>587</em>, 127678. (<a
href="https://doi.org/10.1016/j.neucom.2024.127678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Wasserstein distance in the optimal transport (OT) model is being widely used in machine learning applications due to its mathematical and geometric properties. Since the entropy regularized OT is a convex problem, and for its large-scale problems, many algorithms have been proposed. Existing methods mainly adopt iterative random projection techniques to approximate the Wasserstein distance in the OT model. In this paper, we employ the entropic domain decomposition algorithm with mini-batch learning to calculate the entropy regularized OT problem and investigate the stability of this algorithm. The algorithm performs on different cells of the domain instead of using the projection technique and it is based on a mini-batch loss function. The corresponding solution in each iteration is derived from the dual problem of entropy regularized OT on each decomposed cell. Once the solutions to the dual problem on all decomposed cells are obtained, the corresponding transport plan in each iteration can be obtained. We show that the transport plan computed by its dual variables is admissible, and we also give the sub-gradient approximation result. In addition, we exploit the statistical concentration result of the subsampled mini-batch Wasserstein distance on decomposed cells. Finally, the numerical experiments validate that the proposed algorithm can save computational time further.},
  archive      = {J_NEUCOM},
  author       = {Judy Yangjun Lin and Huoxia Liu},
  doi          = {10.1016/j.neucom.2024.127678},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127678},
  shortjournal = {Neurocomputing},
  title        = {The stability and statistic of domain decomposition algorithm with mini-batch learning for optimal transport},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing digital rock analysis through generative
artificial intelligence: Diffusion models. <em>NEUCOM</em>,
<em>587</em>, 127676. (<a
href="https://doi.org/10.1016/j.neucom.2024.127676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the realm of computer vision, the landscape has been significantly reshaped by the abundance of extensive and diverse datasets, leading to remarkable breakthroughs in image processing. These advancements have reverberated across a wide spectrum of applications, catalyzing transformative outcomes. However, in stark contrast, the field of digital rock analysis finds itself grappling with a conspicuous dearth of data, a challenge that casts a formidable shadow over the effective deployment of computer vision techniques for rock image analysis. In response to this pressing issue, this paper presents a pioneering methodology designed to surmount the hurdles posed by data limitation in the realm of digital rock analysis. At the core of this innovative approach lies the fusion of artificially generated digital rock images, created using a state-of-the-art diffusion model, with their authentic counterparts. This fusion is guided by the overarching objective of augmenting the efficacy of various digital rock analysis applications. This integration endeavors to bridge the gap between the limited available data and the substantial demands of the digital rock analysis domain. The practical significance and potential of this integrated approach are vividly demonstrated through a series of concrete implementations. These include, but are by no means limited to, enhancing image quality to facilitate clearer visualization of intricate rock structures and refining the estimation of petrophysical properties with increased accuracy.},
  archive      = {J_NEUCOM},
  author       = {Mohammad Esmaeili},
  doi          = {10.1016/j.neucom.2024.127676},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127676},
  shortjournal = {Neurocomputing},
  title        = {Enhancing digital rock analysis through generative artificial intelligence: Diffusion models},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Syntax-guided controllable sentence simplification.
<em>NEUCOM</em>, <em>587</em>, 127675. (<a
href="https://doi.org/10.1016/j.neucom.2024.127675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentence simplification is to rephrase a sentence into a form that is easier to read and understand while preserving its essential meaning and information. Recently, monolingual neural machine translation methods have emerged as a popular approach for this task. However, these methods often overlook the syntactic tree information of sentences, which can be crucial for effective simplification. To address this issue, we propose a syntax-guided controllable sentence simplification model that leverages graph attention networks to incorporate the syntactic information of dependency trees. Specifically, besides the sentence encoder, we propose a graph encoder that encodes dependency trees to enrich the syntactic information. Within the decoder, we introduce a syntax-augmented cross-attention that aggregates both sentence and syntax information simultaneously to the target side for simplification. We evaluate our proposed model on two benchmark datasets, showcasing that it outperforms state-of-the-art methods by a significant margin. Our proposed model underscores the significance of incorporating syntactic knowledge in sentence simplification.},
  archive      = {J_NEUCOM},
  author       = {Lulu Wang and Aishan Wumaier and Tuergen Yibulayin and Maihemuti Maimaiti},
  doi          = {10.1016/j.neucom.2024.127675},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127675},
  shortjournal = {Neurocomputing},
  title        = {Syntax-guided controllable sentence simplification},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-view graph learning model with dual strategies for
solving math word problems. <em>NEUCOM</em>, <em>587</em>, 127674. (<a
href="https://doi.org/10.1016/j.neucom.2024.127674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, graph-based deep learning models have exhibited remarkable performance in generating solution expressions for the math word problem (MWP). However, most of these models have not taken into account the limitations and errors in constructing prior knowledge graphs, which may affect their accuracy and reliability in practical applications. In addition, during graph learning, they focus on extracting information from each given graph, while neglecting the adaptability and unification of graph representation learning. In this paper, we propose a novel multi-view graph learning-to-tree model with dual-strategy (MVG-DS-T), in which it performs adaptive and consistent multi-view representation learning through two benchmark graphs. Specifically, we construct benchmark graphs via semantic dependency parsing of MWP text, considering both semantic and quantitative aspects, i.e., semantic graph and quantitative graph. Then, the reconstruction strategy is employed to reconstruct the structure of the benchmark graphs to capture the adaptive representation information suitable for downstream tasks, while the alignment strategy is utilized to overcome the limitation of independent view representations by unifying the semantic and quantity embedding information through graph structure. Also, an adaptive length normalized loss balancing term for the tree-based decoder is introduced to control the model focus on label length during training, resulting in better equation generation. Extensive experiments demonstrate the effectiveness of the proposed approach on the MWP task. The empirical results show that MVG-DS-T achieves performance comparable to that of the state-of-the-art graph-based models in the existing literature.},
  archive      = {J_NEUCOM},
  author       = {Zhiwei Wang and Qi Lang and Xiaodong Liu and Wenlin Jing},
  doi          = {10.1016/j.neucom.2024.127674},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127674},
  shortjournal = {Neurocomputing},
  title        = {A multi-view graph learning model with dual strategies for solving math word problems},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A neural network algorithm framework based on graph
structure for general combinatorial optimization. <em>NEUCOM</em>,
<em>587</em>, 127670. (<a
href="https://doi.org/10.1016/j.neucom.2024.127670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combinatorial optimization problems (COPs) play an important role in both industrial production and theoretical research. As a classical class of optimization algorithms, evolutionary algorithms have shown good performance in COPs. However, as the size of the problem increases, it becomes difficult for evolutionary algorithms to produce satisfactory solutions within the specified time. In recent years, neural network algorithms have been applied to solve COPs and have shown superior effects. Inspired by this, this paper proposes a new algorithm based on graph structure for solving COPs. Through relaxation, COPs are transformed into their corresponding continuous optimization problems. The output state of our algorithm is converted to a discrete solution by approximation method. Compared with previous algorithms, our algorithm can not only solve COPs with general form such as binary quadratic programming (BQP), but also solve COPs with special form, which greatly expands the application scope of neural network algorithms. In addition, our algorithm can be embedded into other problem frameworks such as solving multi-objective combinatorial optimization problem (MOCOP) through scalarization method. A new penalty function is added to the objective function, which enables our algorithm to overcome the inconsistency between the optimal solution of the original problem and the corresponding continuous problem, so that our algorithm can perform well on various problems. Several numerical simulations are used to illustrate the effectiveness of our algorithm in solving COPs. Experimental results show that our algorithm can effectively solve COPs with general form and has a shorter solving time compared to traditional evolutionary algorithms.},
  archive      = {J_NEUCOM},
  author       = {Shijie Zhao and Shenshen Gu},
  doi          = {10.1016/j.neucom.2024.127670},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127670},
  shortjournal = {Neurocomputing},
  title        = {A neural network algorithm framework based on graph structure for general combinatorial optimization},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An enhanced structural developmental neural network with
information saturation for continual unsupervised learning.
<em>NEUCOM</em>, <em>587</em>, 127666. (<a
href="https://doi.org/10.1016/j.neucom.2024.127666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an enhanced structural developmental neural network with information saturation (ESDNNIS) is proposed for continual unsupervised learning. It improves SDNNIS in the following respects: (1) it makes a distinction between the developmental stages of neurons to better regulate the updating of neurons; (2) it adopts the forgetting mechanism to control the network size; (3) it changes the way coverage domain parameter is initialized and updated to divide clusters more accurately; and (4) it adds a parent–child relationship update mechanism to provide better robustness to sample input order. ESDNNIS inherits the unsupervised incremental learning and class segmentation capabilities of SDNNIS, and achieves better class incremental clustering for more complex datasets while using fewer neurons than SDNNIS. The experimental results show that the accuracy of clustering results of ESDNNIS is improved by 10.94% on average compared with SDNNIS, while the number of generated neurons is reduced by 71.93% on average.},
  archive      = {J_NEUCOM},
  author       = {Haibin Xie and Zhiyong Ding and Peng Li and Xin Xu},
  doi          = {10.1016/j.neucom.2024.127666},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127666},
  shortjournal = {Neurocomputing},
  title        = {An enhanced structural developmental neural network with information saturation for continual unsupervised learning},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-population evolutionary neural architecture search
with stacked generalization. <em>NEUCOM</em>, <em>587</em>, 127664. (<a
href="https://doi.org/10.1016/j.neucom.2024.127664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, neural architecture search (NAS) algorithms based on Evolutionary Computation (EC) have demonstrated immense potential in the automated design of deep neural network architectures, garnering widespread attention in the field of deep learning. Most EC-based NAS algorithms select the best individual based on overall fitness score. However, some eliminated suboptimal individuals may only perform weakly in overall classification performance, but perform well on certain classes. To search valuable suboptimal individuals and prevent them from being eliminated, we propose a multi-population evolutionary NAS algorithm with stacked generalization (MPE-NAS). Each population evolves based on the classification accuracy of different classes. After completing the evolution process, the stacked generalization approach is utilized to fuse the searched architectures. Moreover, an integrated performance predictor based on k-nearest neighbor (KNN) regression, random forest (RF) and support vector machine (SVM) is proposed to alleviate computational cost during architecture performance evaluation. On the CIFAR benchmark dataset, the proposed algorithm is examined and compared with the most advanced algorithms, and its effectiveness is confirmed based on experiments. In addition, the proposed multi-population evolutionary (MPE) search strategy is applied to others EC-based NAS algorithms, and achieves the performance improvement without increasing computational resources.},
  archive      = {J_NEUCOM},
  author       = {Changwei Song and Yongjie Ma and Yang Xu and Hong Chen},
  doi          = {10.1016/j.neucom.2024.127664},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127664},
  shortjournal = {Neurocomputing},
  title        = {Multi-population evolutionary neural architecture search with stacked generalization},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CrowdTrans: Learning top-down visual perception for crowd
counting by transformer. <em>NEUCOM</em>, <em>587</em>, 127650. (<a
href="https://doi.org/10.1016/j.neucom.2024.127650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in crowd counting methods have relied on density maps as an intermediary representation for counting, whereby the ground truth of the density map is obtained through the convolution of dot annotations with a fixed Gaussian kernel. However, the presence of perspective phenomena introduces scale variations among targets, leading to a significant challenge in scene generalization. Existing approaches suffer from limitations in accommodating a limited number of scales within the density map generation and prediction processes. In order to address this problem, we introduce a novel transformer network, CrowdTrans, which incorporates a two-channel tasks-based density map estimator and generator. This innovative approach learns a density map by leveraging both pixel-wise classification and regression. Furthermore, we devise an end-to-end framework that facilitates the joint learning of the density map estimator and the corresponding label generator. Through extensive experimentation on widely utilized datasets, our results demonstrate the state-of-the-art performance of our proposed method, thus validating the effectiveness of our novel designs.},
  archive      = {J_NEUCOM},
  author       = {Weiyu Guo and Shaopeng Yang and Yuheng Ren and Yongzhen Huang},
  doi          = {10.1016/j.neucom.2024.127650},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127650},
  shortjournal = {Neurocomputing},
  title        = {CrowdTrans: Learning top-down visual perception for crowd counting by transformer},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gaze-based human intention prediction in the hybrid foraging
search task. <em>NEUCOM</em>, <em>587</em>, 127648. (<a
href="https://doi.org/10.1016/j.neucom.2024.127648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An agent’s ability to predict a human’s intention can facilitate the effectiveness of a human-agent team. The aim of this study was to explore the feasibility of predicting human intention in the hybrid foraging search task using eye gaze data and machine learning. In the hybrid foraging search paradigm, the human performs searches in patches and decides to stay and exploit a patch or to leave and explore another patch. Researchers have modeled the “patch-leaving problem” on the collective level using the marginal value theorem. However, few have attempted to predict the exact moment when the human will leave. In the current study, 40 participants performed the hybrid foraging search task while eye gaze data were collected with an eye-tracker. The leaving intention was associated with larger pupil size, shorter average fixation duration, larger number of fixations, longer saccade amplitude, and faster saccade velocity compared to the searching intention. A cross-subject machine learning model with an artificial neural network algorithm was able to predict whether a participant would leave the current patch with up to 78% accuracy with a 2-second data analysis window. The length of the data analysis window did not significantly affect prediction accuracy. Furthermore, the earlier the behavior prediction was made, the lower the reliability of the prediction. These results demonstrate that eye gaze features and machine learning algorithms are useful in predicting human intention in visual search tasks.},
  archive      = {J_NEUCOM},
  author       = {Yunxian Pan and Jie Xu},
  doi          = {10.1016/j.neucom.2024.127648},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127648},
  shortjournal = {Neurocomputing},
  title        = {Gaze-based human intention prediction in the hybrid foraging search task},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PHD-NAS: Preserving helpful data to promote neural
architecture search. <em>NEUCOM</em>, <em>587</em>, 127646. (<a
href="https://doi.org/10.1016/j.neucom.2024.127646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Architecture Search (NAS) has achieved promising results in many domains. However, the enormous computational burden consumed by the NAS procedure significantly hinders its application. Existing works focus on mitigating the search cost by either designing a more efficient algorithm or searching in an elaborately designed search space, heavily relying on expert experience and domain knowledge. We notice that few works focus on dataset optimization for NAS, however, the truth is that not all samples are essential for the search process, which can be omitted actually. Therefore, we propose to only preserve helpful data for the supernet training to improve the efficiency. Specifically, we compute the forgetting and remembering events for each sample during the supernet training to determine the data importance. Samples that the supernet has predicted correctly in consecutive epochs have low importance and will be gradually removed from the dataset during training. We further formulate our method into a unified cycled-learning framework for jointly optimizing proxy dataset and architecture search. By combining with different algorithms, we demonstrate that our framework can find architectures with comparable performance using much less training data and search time in various search spaces and benchmarks, validating the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Shun Lu and Yu Hu and Longxing Yang and Jilin Mei and Zihao Sun and Jianchao Tan and Chengru Song},
  doi          = {10.1016/j.neucom.2024.127646},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127646},
  shortjournal = {Neurocomputing},
  title        = {PHD-NAS: Preserving helpful data to promote neural architecture search},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust control for affine nonlinear systems under the
reinforcement learning framework. <em>NEUCOM</em>, <em>587</em>, 127631.
(<a href="https://doi.org/10.1016/j.neucom.2024.127631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the robust control problem of affine nonlinear systems with both additive and multiplicative uncertainty. Different from existing actor-critic (AC) algorithms for adaptive dynamic programming (ADP), we introduce an uncertainty estimator and propose an actor-critic-estimator (ACE) algorithm. The proposed algorithm alternates between the value evaluation, uncertainty estimation, and policy update to generate the adaptive robust control law without knowing the system dynamics. Especially, during the step of uncertainty estimation, we approximate the uncertainty by a radial basis function neural network (RBFNN) and design the appropriate utility function accordingly instead of using the supremum of the uncertainty as in existing studies. The Lyapunov stability theorem provides theoretical demonstrations of the stability and convergence. We further demonstrate that the affine nonlinear systems with uncertainty is uniformly ultimately bounded (UUB) stable when the learned adaptive robust control law is adopted. The performance of the proposed algorithm is demonstrated through a torsion pendulum system and an inverted pendulum system.},
  archive      = {J_NEUCOM},
  author       = {Wenxin Guo and Weiwei Qin and Xuguang Lan and Jieyu Liu and Zhaoxiang Zhang},
  doi          = {10.1016/j.neucom.2024.127631},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127631},
  shortjournal = {Neurocomputing},
  title        = {Robust control for affine nonlinear systems under the reinforcement learning framework},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards interactive reinforcement learning with intrinsic
feedback. <em>NEUCOM</em>, <em>587</em>, 127628. (<a
href="https://doi.org/10.1016/j.neucom.2024.127628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) and brain–computer interfaces (BCI) have experienced significant growth over the past decade. With rising interest in human-in-the-loop (HITL), incorporating human input with RL algorithms has given rise to the sub-field of interactive RL. Adjacently, the field of BCI has long been interested in extracting informative brain signals from neural activity for use in human–computer interactions. A key link between these fields lies in the interpretation of neural activity as feedback such that interactive RL approaches can be employed. We denote this new and emerging medium of feedback as intrinsic feedback . Despite intrinsic feedback’s ability to be conveyed automatically and even unconsciously, proper exploration surrounding this key link has largely gone unaddressed by both communities. Thus, to help facilitate a deeper understanding and a more effective utilization, we provide a tutorial-style review covering the motivations, approaches, and open problems of intrinsic feedback and its foundational concepts.},
  archive      = {J_NEUCOM},
  author       = {Benjamin Poole and Minwoo Lee},
  doi          = {10.1016/j.neucom.2024.127628},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127628},
  shortjournal = {Neurocomputing},
  title        = {Towards interactive reinforcement learning with intrinsic feedback},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid hyperplane gradient learning algorithm for RBF neural
network. <em>NEUCOM</em>, <em>587</em>, 127626. (<a
href="https://doi.org/10.1016/j.neucom.2024.127626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient-based algorithms are still popularly used for training radial basis function neural network (RBFNN). However, these algorithms may lead to the vanishing gradient (saddle point or local minimum) problem, which is one of the common problems that limit learning performance. To cope with this, a hybrid hyperplane gradient learning algorithm (HHGLA) is proposed to improve the learning performance of the RBFNN in this paper. First, a hyperplane gradient (HPG), based on a hyperspace constructed by a solution population (SP), is introduced. Thus, the search process can cross the surface of the cost function to avoid the appearance of vanishing gradient. Second, an adaptive learning rate is designed to restrict the search process into this hyperspace. Then, during the learning process, the hyperspace is constantly contracted to approximate the global optimal solution. Third, the convergence property of HHGLA-based RBFNN is thoroughly analyzed to ensure its application success. Finally, empirical comparisons of the proposed HHGLA-RBFNN are given to illustrate its superiority. The simulation results show the feasibility of HHGLA-RBFNN of accuracy.},
  archive      = {J_NEUCOM},
  author       = {Miao-li Ma and Zhe-kun Huang and Yu-hang Liao and Li-yi Zhou and Li-jie Jia and Cun-zhen Liang and Zhi-jun Guo},
  doi          = {10.1016/j.neucom.2024.127626},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127626},
  shortjournal = {Neurocomputing},
  title        = {Hybrid hyperplane gradient learning algorithm for RBF neural network},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast-DSAGCN: Enhancing semantic segmentation with
multifaceted attention mechanisms. <em>NEUCOM</em>, <em>587</em>,
127625. (<a href="https://doi.org/10.1016/j.neucom.2024.127625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time semantic segmentation provides precise insights into dynamic street environments for autonomous driving, traffic control, and urban planning. However, state-of-the-art models following attention mechanisms and deep convolutional neural networks have improved semantic segmentation at the cost of complex architectures and high computation complexity. The study aims to mitigate the presence of gridding artifacts and enhance semantic segmentation performance. In addition, we propose a multi-level downsampling approach before employing the depth-wise split separable global convolution with the bottleneck to achieve a trade-off between accuracy and inference time. The spatial attention module used in this study effectively keeps low-level spatial characteristics, enhancing the accuracy of localization, robustness against disturbances, processing efficiency, and the ability to handle occlusions. Thorough tests of the Cityscapes and CamVid datasets available for public access indicate that the model presented is capable of efficiently processing high-resolution photos in real time, resulting in exceptional performance. The model has achieved an accuracy of 72.3% on the cityscapes dataset and 72.7% on the CamVid dataset.},
  archive      = {J_NEUCOM},
  author       = {Khawaja Iftekhar Rashid and Chenhui Yang and Chenxi Huang},
  doi          = {10.1016/j.neucom.2024.127625},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127625},
  shortjournal = {Neurocomputing},
  title        = {Fast-DSAGCN: Enhancing semantic segmentation with multifaceted attention mechanisms},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pinning intra-layer synchronization in multiplex networks of
nonidentical layers. <em>NEUCOM</em>, <em>587</em>, 127624. (<a
href="https://doi.org/10.1016/j.neucom.2024.127624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate intra-layer synchronization in multiplex networks via pinning control strategies. All layers have different topologies and different intrinsic node dynamics. Novel sufficient criteria are derived for pinning intra-layer synchronization of multiplex networks, which indicates that the pinned node set can stabilize the multiplex network if, for each layer, the pinned node(s) can access all unpinned nodes. A distributed adaptive algorithm and finite-time pinning algorithm for intra-layer synchronization of multiplex networks are also proposed. Finally, we give some numerical examples to validate the effectiveness of these theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Yujuan Han and Wenlian Lu and Tianping Chen},
  doi          = {10.1016/j.neucom.2024.127624},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127624},
  shortjournal = {Neurocomputing},
  title        = {Pinning intra-layer synchronization in multiplex networks of nonidentical layers},
  volume       = {587},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep multi-threshold spiking-UNet for image processing.
<em>NEUCOM</em>, <em>586</em>, 127653. (<a
href="https://doi.org/10.1016/j.neucom.2024.127653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {U-Net, known for its simple yet efficient architecture, is widely utilized for image processing tasks and is particularly suitable for deployment on neuromorphic chips. This paper introduces the novel concept of Spiking-UNet for image processing, which combines the power of Spiking Neural Networks (SNNs) with the U-Net architecture. To achieve an efficient Spiking-UNet, we face two primary challenges: ensuring high-fidelity information propagation through the network via spikes and formulating an effective training strategy. To address the issue of information loss, we introduce multi-threshold spiking neurons, which improve the efficiency of information transmission within the Spiking-UNet. For the training strategy, we adopt a conversion and fine-tuning pipeline that leverage pre-trained U-Net models. During the conversion process, significant variability in data distribution across different parts is observed when utilizing skip connections. Therefore, we propose a connection-wise normalization method to prevent inaccurate firing rates. Furthermore, we adopt a flow-based training method to fine-tune the converted models, reducing time steps while preserving performance. Experimental results show that, on image segmentation and denoising, our Spiking-UNet achieves comparable performance to its non-spiking counterpart, surpassing existing SNN methods. Compared with the converted Spiking-UNet without fine-tuning, our Spiking-UNet reduces inference time by approximately 90%. This research broadens the application scope of SNNs in image processing and is expected to inspire further exploration in the field of neuromorphic engineering. The code for our Spiking-UNet implementation is available at https://github.com/SNNresearch/Spiking-UNet .},
  archive      = {J_NEUCOM},
  author       = {Hebei Li and Yueyi Zhang and Zhiwei Xiong and Xiaoyan Sun},
  doi          = {10.1016/j.neucom.2024.127653},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127653},
  shortjournal = {Neurocomputing},
  title        = {Deep multi-threshold spiking-UNet for image processing},
  volume       = {586},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). OFMPNet: Deep end-to-end model for occupancy and flow
prediction in urban environment. <em>NEUCOM</em>, <em>586</em>, 127649.
(<a href="https://doi.org/10.1016/j.neucom.2024.127649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of motion prediction is pivotal for autonomous driving systems, providing crucial data to choose a vehicle behavior strategy within its surroundings. Existing motion prediction techniques primarily focus on predicting the future trajectory of each agent in the scene individually, utilizing its past trajectory data. In this paper, we introduce an end-to-end neural network methodology designed to predict the future behaviors of all dynamic objects in the environment. This approach leverages the occupancy map and the scene’s motion flow. We are investigating various alternatives for constructing a deep encoder–decoder model called OFMPNet. This model uses a sequence of bird’s-eye-view road images, occupancy grid, and prior motion flow as input data. The encoder of the model can incorporate transformer, attention-based, or convolutional units. The decoder considers the use of both convolutional modules and recurrent blocks. Additionally, we propose a novel time-weighted motion flow loss, whose application has shown a substantial decrease in end-point error. Our approach has achieved state-of-the-art results on the Waymo Occupancy and Flow Prediction benchmark, with a Soft IoU of 52.1% and an AUC of 76.75% on Flow-Grounded Occupancy.},
  archive      = {J_NEUCOM},
  author       = {Youshaa Murhij and Dmitry Yudin},
  doi          = {10.1016/j.neucom.2024.127649},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127649},
  shortjournal = {Neurocomputing},
  title        = {OFMPNet: Deep end-to-end model for occupancy and flow prediction in urban environment},
  volume       = {586},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predefined-time cooperative output regulation for
second-order nonlinear multiagent systems with an unknown exosystem via
dynamic gain method. <em>NEUCOM</em>, <em>586</em>, 127647. (<a
href="https://doi.org/10.1016/j.neucom.2024.127647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The predefined-time cooperative output regulation of second-order nonlinear multiagent systems with an unknown exosystem is investigated in this paper. Existing similar work is almost limited to exactly known exosystems, and the upper bound of convergence time for closed-loop systems is difficult to adjust and predict, which may not meet practical needs. In this paper, we first propose a new dynamic compensator called predefined-time distributed observer, which guarantees that each agent estimates the state and parameters about the linear exosystem with unknown system matrix through the general directed communication network within the time set by an explicit parameter. Subsequently, combining the improved dynamic gain control method and the proposed predefined-time distributed observer, a novel distributed dynamic predefined-time control scheme is proposed, which solves the problem of this paper by simplifying the tedious arithmetic process caused by the traditional backstepping method. The final simulation experiments verify the effectiveness of the proposed control scheme.},
  archive      = {J_NEUCOM},
  author       = {Zengke Jin and Chaoli Wang and Dong Liang and Zhenying Liang and Shihua Li},
  doi          = {10.1016/j.neucom.2024.127647},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127647},
  shortjournal = {Neurocomputing},
  title        = {Predefined-time cooperative output regulation for second-order nonlinear multiagent systems with an unknown exosystem via dynamic gain method},
  volume       = {586},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling implicit variable and latent structure for
aspect-based sentiment quadruple extraction. <em>NEUCOM</em>,
<em>586</em>, 127642. (<a
href="https://doi.org/10.1016/j.neucom.2024.127642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The realm of aspect-based sentiment analysis (ABSA), which delves into the nuanced sentiment expressions individuals hold towards specific services or products, has demonstrated immense potential in real-world applications. Recently, ABSA has evolved into the development of aspect-based sentiment quadruple extraction (ASQP). ASQP’s objective is to predict four crucial sentiment elements: aspect , sentiment , opinion and category , where such comprehensive approach paints a holistic description of sentiment, facilitating downstream applications. However, prevailing ASQP models suffer from various limitations, such as inefficiency in decoding, inadequate handling of implicit aspects and opinions, and underutilization of structural information. In this paper, we explore an innovative approach to enhance ASQP. Firstly, we adopt a pointer-based non-autoregressive generative framework, enabling the parallel generation of all sentiment quadruples. This approach preserves the advantages of generative methods while significantly boosting decoding efficiency. Additionally, we introduce latent variable learning to model the aspect and opinion elements, effectively enhancing our ability to reason about implicit ASQP components. Furthermore, we propose an aspect-and-opinion-guided latent structure to bolster sentiment-aware context learning. This dynamically induced graph structure adapts to the specific requirements of the task, offering optimal support for ASQP. Our method outperforms current state-of-the-art models on four benchmark ASQP datasets, demonstrating its significant superiority. A detailed analysis highlights the benefits of non-autoregressive decoding in achieving high inference efficiency, the effectiveness of the variational module in capturing implicit sentiment elements, and the value of the dynamically induced latent structure in accurate sentiment feature learning. Moreover, our system excels in producing interpretable predictions.},
  archive      = {J_NEUCOM},
  author       = {Yu Nie and Jianming Fu and Yilai Zhang and Chao Li},
  doi          = {10.1016/j.neucom.2024.127642},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127642},
  shortjournal = {Neurocomputing},
  title        = {Modeling implicit variable and latent structure for aspect-based sentiment quadruple extraction},
  volume       = {586},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised cross domain semantic segmentation with mutual
refinement and information distillation. <em>NEUCOM</em>, <em>586</em>,
127641. (<a href="https://doi.org/10.1016/j.neucom.2024.127641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised cross domain semantic segmentation recently has gained much attention, due to its powerful ability of solving the segmentation problem on unlabeled domains. Traditional methods often employ an adversarial network to confuse the source and target inputs, so as to align them in a new feature space. However, these methods cannot well fuse the source and target domain information because the information of the two domains does not really interact with each other and are passed through separate network branches. To tackle this problem, we propose a real interactive learning framework, named Mutual Refinement and Information Distillation (MURID), to align the two domains. Concretely, MURID introduces a Mutual Refinement module in shallow network layers to enhance information sharing and integration between the source and target domains, which can effectively transfer knowledge from source domain to target domain. In addition, in order to avoid using the same structure for testing as for training, which would result in huge computational requirements, we exploit an Information Distillation module to simplify the testing network while maintaining the powerful inference capability of the training. Moreover, we incorporate Curriculum Learning, a self-training mechanism that iteratively trains the network using pseudo-labels obtained from the target domain, to further improve performance. Extensive experiments were conducted on three popular datasets, i.e. , GTA5 → → Cityscapes and Synthia → → Cityscapes, and the results demonstrate the state-of-the-art performance of our method. Additionally, detailed analysis and ablation studies are also carried out to validate the effectiveness of each designed module.},
  archive      = {J_NEUCOM},
  author       = {Dexin Ren and Shidong Wang and Zheng Zhang and Wankou Yang and Mingwu Ren and Haofeng Zhang},
  doi          = {10.1016/j.neucom.2024.127641},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127641},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised cross domain semantic segmentation with mutual refinement and information distillation},
  volume       = {586},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-agent cooperative strategy with explicit teammate
modeling and targeted informative communication. <em>NEUCOM</em>,
<em>586</em>, 127638. (<a
href="https://doi.org/10.1016/j.neucom.2024.127638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mainstream Multi-Agent Reinforcement Learning (MARL) methods introduce the teammate modeling or the communication mechanism into Centralized Training Decentralized Execution (CTDE) paradigm, which can improve coordination performance. However, the existing teammate modeling methods predict either actions or local observations, limiting their applicability. In addition, the traditional communication mechanism only considers the quantity of the communication links while ignoring the quality of retained communication links, leading to inefficient and redundant communication. To solve the above problems, this paper proposes a novel Multi-Agent Cooperative Strategy with Explicit Teammate Modeling and Targeted Informative Communication (MACS), which can generate and send the more informative message with the higher communication efficiency, further improving the coordination performance. Specifically, the Variational Auto-Encoder (VAE) is leveraged to allow each agent to simultaneously predict the observations and actions of teammates, thus generating more comprehensive communication message. Then, we propose a new Mutual Information (MI) between the communication message and teammate Q-value, which can obtain the informative message, ensuring the exploration and stability of the method. In addition, a targeted dynamic informative communication graph is established by the Graph Neural Network (GNN) which can reduce the redundant communication link through hypothetical analysis, further improving the overall communication efficiency. Eventually, we conduct experiments in StarCraft II, Collaborative Navigation, and Multi-Target Multi-Sensor Coverage environments. Experimental results show that the proposed approach is superior to the state-of-the-art in terms of coordination performance and communication efficiency.},
  archive      = {J_NEUCOM},
  author       = {Rui Jiang and Xuetao Zhang and Yisha Liu and Yi Xu and Xuebo Zhang and Yan Zhuang},
  doi          = {10.1016/j.neucom.2024.127638},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127638},
  shortjournal = {Neurocomputing},
  title        = {Multi-agent cooperative strategy with explicit teammate modeling and targeted informative communication},
  volume       = {586},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-level semantic enhancement based on self-distillation
BERT for chinese named entity recognition. <em>NEUCOM</em>,
<em>586</em>, 127637. (<a
href="https://doi.org/10.1016/j.neucom.2024.127637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important foundational task in the field of natural language processing, the Chinese named entity recognition (NER) task has received widespread attention in recent years. Self-distillation plays a role in exploring the potential of the knowledge carried by internal parameters in the BERT NER model, but few studies have noticed the impact of different granularity semantic information during the distillation process. In this paper, we propose a multi-level semantic enhancement approach based on self-distillation BERT for Chinese named entity recognition. We first design a feasible data augmentation method to improve the training quality for handling complex entity compositions, then construct a boundary smoothing module to achieve the model’s moderate learning on entity boundaries. Besides, we utilize the distillation reweighting method to let the model acquire balanced entity and context knowledge. Experimental results on two Chinese named entity recognition benchmark datasets Weibo and Resume have 72.09% and 96.93% F1 scores, respectively. Compared to three different basic distillation BERT models, our model can also produce better results. The source code is available at https://github.com/lookmedandan/MSE .},
  archive      = {J_NEUCOM},
  author       = {Zepeng Li and Shuo Cao and Minyu Zhai and Nengneng Ding and Zhenwen Zhang and Bin Hu},
  doi          = {10.1016/j.neucom.2024.127637},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127637},
  shortjournal = {Neurocomputing},
  title        = {Multi-level semantic enhancement based on self-distillation BERT for chinese named entity recognition},
  volume       = {586},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ultrahigh-definition video quality assessment: A new dataset
and benchmark. <em>NEUCOM</em>, <em>586</em>, 127633. (<a
href="https://doi.org/10.1016/j.neucom.2024.127633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video quality assessment (VQA) based on deep learning requires a massive amount of data for support. However, existing mainstream datasets do not consider the Ultrahigh-definition VQA (UHD-VQA) task, such as KoNViD1k and LIVE-Qualcomm, and can only be used for general resolution VQA tasks. These VQA datasets suffer from limitations, including low resolution and restricted scenarios. To address these issues, we present a novel UHD-VQA dataset, named UHD-VQ5k, which contains 5500 video clips, each 10 s in duration, with a resolution of 3840 × 2160 and a frame rate of 30 frames per second. Moreover, we provide strict expert ratings for each video in accordance with the ITU-R BT.500-13 standard. In addition, for the task of VQA, we propose a Hybrid Resformer Video Quality Assessment (HR-VQA) Network. The network consists of two branches, IQA and VQA, to take both video frames and video segments as inputs. In the IQA branch, features are extracted using a Resformer architecture, which including two parallel components: ResNet50 and ViT (Vision Transformer). These two components are connected through the Bidirectional Local Global Interaction module. And in the VQA branch, video segment quality is evaluated by extracting features with Swin-3D (Video Swin Transformer). The scores from both branches are individually regressed and combined through ensemble learning to obtain the ultimate video quality score. Furthermore, we introduce a “Usability Rate (UR)” metric that further enhances the accuracy of individual video predictions. Through experimental validation, our algorithm not only achieves state-of-the-art (SOTA) performance on the UHD-VQ5k dataset but also demonstrates promising results on the KONVID1k dataset and the preliminary dataset of the NAIC2023 Challenge.},
  archive      = {J_NEUCOM},
  author       = {Ruochen Li and Wenmin Wang and Huanqiang Hu and Tongbao Chen and Minglu Zhao},
  doi          = {10.1016/j.neucom.2024.127633},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127633},
  shortjournal = {Neurocomputing},
  title        = {Ultrahigh-definition video quality assessment: A new dataset and benchmark},
  volume       = {586},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-negative scaled edge-consensus of saturated networked
systems via adaptive output-feedback control. <em>NEUCOM</em>,
<em>586</em>, 127632. (<a
href="https://doi.org/10.1016/j.neucom.2024.127632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates fully distributed scaled non-negative edge-consensus problems of networked systems with actuator saturation and unmeasurable internal states. By using the adaptive control method, output-feedback-based low-gain technique, and graph theory, a new adaptive algorithm is designed to obtain scaled edge-consensus conditions, under which the difficulties caused by the constraints on edge states and controllers are overcome. There are three interesting characteristics that any global information of networks is not used in this paper’s algorithm and result, including the number of vertexes and edges; the feasible solutions of the scaled edge-consensus conditions exist and can be easily obtained; the convergence rate of the controller is adjustable. Furthermore, the designed algorithm is expanded in the cases without actuator saturation. Finally, three examples are given to verify the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Yaping Sun and Xinsong Yang and Yini Zhao and Housheng Su},
  doi          = {10.1016/j.neucom.2024.127632},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127632},
  shortjournal = {Neurocomputing},
  title        = {Non-negative scaled edge-consensus of saturated networked systems via adaptive output-feedback control},
  volume       = {586},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A federated learning incentive mechanism in a non-monopoly
market. <em>NEUCOM</em>, <em>586</em>, 127630. (<a
href="https://doi.org/10.1016/j.neucom.2024.127630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning, a privacy-preserving collaborative machine learning paradigm, has led to the proposal of various incentive mechanisms to encourage active participation of data owners. However, most of the existing mechanisms focused on the monopsony market scenario, where only one server-side entity (buyer) is involved. In real-world scenarios, multiple server parties may express simultaneous interest in the data of a client (seller), leading to a non-monopoly market. This paper aims to bridge this gap by introducing the concept of incentivizing federated learning in a non-monopoly market and presents a non-monopoly federated learning incentive mechanism, coined as NmFLI. NmFLI employs a double-auction mechanism to implement federated learning incentives and utilizes the Vickery–Clarke–Groves (VCG) mechanism to ensure client trustworthiness. Additionally, NmFLI devises a method for measuring data quality by calculating the value of clients based on their historical performance, which effectively balances accuracy and computational complexity. We demonstrate that NmFLI possesses properties such as individual rationality and strategy-proofness. Experimental results indicate that NmFLI can effectively incentivize federated learning and achieve higher accuracy than baseline models across various scenarios. For example, when the objectives of various tasks overlap, NmFLI outperforms the best baseline by 3.09% with imbalanced client data while maintaining the same data size. Moreover, NmFLI surpasses the best baseline by 6.12% with different amounts of client data.},
  archive      = {J_NEUCOM},
  author       = {Shijie Na and Yuzhi Liang and Siu-Ming Yiu},
  doi          = {10.1016/j.neucom.2024.127630},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127630},
  shortjournal = {Neurocomputing},
  title        = {A federated learning incentive mechanism in a non-monopoly market},
  volume       = {586},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A classification and regression assisted optimization
algorithm for high-dimensional expensive many-objective problems.
<em>NEUCOM</em>, <em>586</em>, 127629. (<a
href="https://doi.org/10.1016/j.neucom.2024.127629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expensive optimization problem, widespread in real-world applications, poses great challenges to traditional evolutionary algorithms (EAs) due to its costly evaluations. A lot of investigations have proved that it is a practical way to incorporate surrogate models into EAs to reduce the number of time-consuming evaluations. Although various types of surrogate models from the community of machine learning, such as regression models that approximate the fitness values of candidate solutions or classification models that predict candidate solutions’ category, have been widely applied separately, none of them consistently outperforms the other. Considering the intrinsic consistency of alleviating computational burden to improve the optimization efficiency, this paper introduces a two-layer architecture to integrate regression and classification models and synergize global and local evolution for high-dimensional expensive many-objective optimization problem (EMaOP). To implement this idea, the Kriging model based on incremental learning is utilized to explore the potential promising space. Further, multi local support vector machine (SVM) classifiers assisted improved differential evolution is run by turn with the global search to accelerate convergence. Accordingly, a novel surrogate-assisted EA, named Classification- and Regression-assisted evolutionary algorithm (CR-SAEA), is proposed on this basis. Experimental studies on several benchmark functions with up to 11 objectives and 200 dimensions confirm the effectiveness of the proposed algorithm and its competitiveness against state-of-the-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Huantong Geng and Feifei Song and Junye Shen and Jiaxing Li},
  doi          = {10.1016/j.neucom.2024.127629},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127629},
  shortjournal = {Neurocomputing},
  title        = {A classification and regression assisted optimization algorithm for high-dimensional expensive many-objective problems},
  volume       = {586},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event-triggered passivity and synchronization of multiple
derivative coupled reaction–diffusion neural networks. <em>NEUCOM</em>,
<em>586</em>, 127619. (<a
href="https://doi.org/10.1016/j.neucom.2024.127619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper studies the event-triggered passivity and synchronization problems for multiple derivative coupled reaction–diffusion neural networks. Two types of multiple derivative coupled reaction–diffusion neural networks, with and without time-varying delay, are considered. According to the characteristics of multiple derivative coupled reaction–diffusion neural networks, an event-triggered condition is constructed. By imposing appropriate Lyapunov functionals and inequality techniques, several passivity conditions are established for these two networks under the designed event-triggered controllers. Then, synchronization criteria of these two networks are derived based on the relationship between output-strict passivity and synchronization. Moreover, the non-occurrence of the Zeno behavior in the proposed control is proved. Numerical example is illustrated to verify the effectiveness of the proposed criteria. Finally, theoretical results and the associated image encryption application are validated through numerical simulations and statistical analyses.},
  archive      = {J_NEUCOM},
  author       = {Yihao Wang},
  doi          = {10.1016/j.neucom.2024.127619},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127619},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered passivity and synchronization of multiple derivative coupled reaction–diffusion neural networks},
  volume       = {586},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning-based stabilization of markov jump linear systems.
<em>NEUCOM</em>, <em>586</em>, 127618. (<a
href="https://doi.org/10.1016/j.neucom.2024.127618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we explore the stabilization problem of discrete-time Markov jump linear systems from a new perspective. We establish a novel learning-based framework that combines control theory and learning methods to design stabilizing feedback gains. Firstly, we reformulate the stabilization problems for discrete-time Markov jump linear systems into finite-time counterparts. Subsequently, leveraging techniques from the field of learning, we effectively and efficiently solve the finite-time stabilization problems. We systematically investigate two typical stabilization problems of discrete-time Markov jump linear systems within the proposed framework, namely the detector-based feedback stabilization and the static output feedback stabilization problems. Extensive simulation on various numerical examples demonstrates the advantages of our approach over several existing methods for discrete-time Markov jump linear systems.},
  archive      = {J_NEUCOM},
  author       = {Jason J.R. Liu and Masaki Ogura and Qiyu Li and James Lam},
  doi          = {10.1016/j.neucom.2024.127618},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127618},
  shortjournal = {Neurocomputing},
  title        = {Learning-based stabilization of markov jump linear systems},
  volume       = {586},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weighted jump in random walk graph sampling.
<em>NEUCOM</em>, <em>586</em>, 127581. (<a
href="https://doi.org/10.1016/j.neucom.2024.127581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph sampling is a challenging problem in network analysis due to the complex structures of networks. Currently, a series of graph sampling algorithms based on random walks achieve good results in graph sampling tasks. However, the existing methods often reduce the conductance of graphs, causing the sampler to stay in the same node for a long time. This results in undersampling. In this paper, we propose a novel Weighted Jump Random Walk (WJRW) algorithm to generate representative samples. We design a parameter in the WJRW algorithm that can adjust the proportions of random walk and random jump in every step. According to the issue of repeated sample nodes in the Generalized Maximum Degree (GMD) method and the problem of large deviations in the Simple Random Walk (SRW), WJRW addresses the weaknesses of the GMD method and enhances the diffusion of a random walker on graphs, leading to a more representative sample. Then, WJRW addresses the issue of large deviations in SRW and enhances the efficiency of the unbiased estimator. By generating smoother stationary distributions. Numerical experiments with extensive real-world networks verify that our method achieves higher accuracy than classical and state-of-the-art methods in estimating distribution estimation.},
  archive      = {J_NEUCOM},
  author       = {Xiao Qi},
  doi          = {10.1016/j.neucom.2024.127581},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127581},
  shortjournal = {Neurocomputing},
  title        = {Weighted jump in random walk graph sampling},
  volume       = {586},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint contrastive learning of structural and semantic for
graph collaborative filtering. <em>NEUCOM</em>, <em>586</em>, 127547.
(<a href="https://doi.org/10.1016/j.neucom.2024.127547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, graph collaborative filtering has been proposed as a superior recommendation technique, due to its outstanding capability of capturing high-order correlations from user–item interactions. Despite effectiveness, it still suffers from two limitations on representation learning: (1) imbalanced data distribution. User/item nodes with high-degree usually interfere with the representation learning process of low-degree nodes, deteriorating the recommendation accuracy; (2) structural noise vulnerability. The neighborhood aggregation scheme for the node representing could easily amplify structural noises, damaging the robustness of recommenders. The latest studies have made progress in overcoming the two limitations by capturing self-supervision signals via contrastive learning. Nevertheless, they somehow rely on heuristics to design, at a certain distance from a more comprehensive settlement. To make contrastive learning more entrenched with graph collaborative filtering, this paper proposes a multi-task framework JCG that integrates joint contrastive learning strategies with a backbone of graph-based recommender. Specifically, (1) we design six contrastive learning tasks categorized as structural and semantic, and obtain nine joint strategies by combining two tasks from each category; (2) we systematically study the effect of joint strategies on graph collaborative filtering, finding that JCG with feasible strategies could achieve up to 18.5% and 17.9% performance gain over the backbone on datasets of Yelp and ML, respectively; (3) performance comparison with other competitive baselines demonstrates the superiority of our JCG, especially that on mitigating the two limitations of data imbalance and noise vulnerability. We hope that our conclusion could provide new insight for future studies.},
  archive      = {J_NEUCOM},
  author       = {Jie Dai and Qingshan Li and Tianyi Nong and Qipeng Bi and Hua Chu},
  doi          = {10.1016/j.neucom.2024.127547},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127547},
  shortjournal = {Neurocomputing},
  title        = {Joint contrastive learning of structural and semantic for graph collaborative filtering},
  volume       = {586},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Show, tell and rectify: Boost image caption generation via
an output rectifier. <em>NEUCOM</em>, <em>585</em>, 127651. (<a
href="https://doi.org/10.1016/j.neucom.2024.127651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based models have excellent performance in capturing the interactions between textual and visual features. However, language bias remains a thorny problem in the image captioning domain, leading to the inconsistency between the generated sentences and the actual images. Existing models focus on preventing the wrong words from being output, with little attention to how to correct them. The problem is that if the current word has not yet been output, the model cannot accurately determine whether it is correct. To address this issue, a Double Decoding Transformer framework is proposed. First, a Rectifier is introduced to correct the output sentences in the absence of a language pre-trained module. In addition, visual features provide powerful guidance for attention distribution and redistribution in the Decoder and the Rectifier of the proposed framework, respectively. Due to the presence of downsampling, information loss in the visual feature extraction process is inevitable. Therefore, a Visual Feature Compensation (VFC) module is proposed to compensate for the loss of visual information as much as possible. Finally, by integrating these two modules into a transformer-based framework, a Double Decoding Transformer – D 2 D2 Transformer is built. Extensive experiments on the MSCOCO dataset with the “Karpathy” test set demonstrate the validity of the proposed model.},
  archive      = {J_NEUCOM},
  author       = {Guowei Ge and Yufeng Han and Lingguang Hao and Kuangrong Hao and Bing Wei and Xue-song Tang},
  doi          = {10.1016/j.neucom.2024.127651},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127651},
  shortjournal = {Neurocomputing},
  title        = {Show, tell and rectify: Boost image caption generation via an output rectifier},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Normalizing flow based uncertainty estimation for deep
regression analysis. <em>NEUCOM</em>, <em>585</em>, 127645. (<a
href="https://doi.org/10.1016/j.neucom.2024.127645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty estimation is a critical component of building safe and reliable machine learning models. Accurate estimation of uncertainties is essential for identifying and mitigating potential risks and ensuring that machine learning systems operate reliably in real-world scenarios. Various approaches, such as ensemble and Bayesian neural networks have been developed by sampling probability predictions from submodels, which is computationally expensive. At present, these techniques are incapable of precisely delineating the boundary separating in-distribution (ID) and out-of-distribution (OOD) data. To fill up this research gap, this paper presents a normalizing flow based framework to directly predict parameters of prior distributions over the probability with a neural network, the proposed model is able to effectively differentiate between ID and OOD data in regression problems. The posterior distributions learned by the model precisely represent uncertainties for OOD data based solely on ID data, without the need for OOD data during training. This approach has shown promising results in a number of applications, including image depth estimation and image adversarial attacks.},
  archive      = {J_NEUCOM},
  author       = {Baobing Zhang and Wanxin Sui and Zhengwen Huang and Maozhen Li and Man Qi},
  doi          = {10.1016/j.neucom.2024.127645},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127645},
  shortjournal = {Neurocomputing},
  title        = {Normalizing flow based uncertainty estimation for deep regression analysis},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Formal verification of robustness and resilience of
learning-enabled state estimation systems. <em>NEUCOM</em>,
<em>585</em>, 127643. (<a
href="https://doi.org/10.1016/j.neucom.2024.127643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a formal verification guided approach for a principled design and implementation of robust and resilient learning-enabled systems. We focus on learning-enabled state estimation systems (LE-SESs), which have been widely used in robotics applications to determine the current state (e.g., location, speed, direction, etc.) of a complex system. The LE-SESs are networked systems, composed of a set of connected components including: Bayes filters for state estimation, and neural networks for processing sensory input. We study LE-SESs from the perspective of formal verification, which determines the satisfiabilty of a system model against the specified properties. Over LE-SESs, we investigate two key properties – robustness and resilience – and provide their formal definitions. To enable formal verification, we reduce the LE-SESs to a novel class of labelled transition systems, named {PO} 2 -LTS in the paper, and formally express the properties as constrained optimisation objectives. We prove that the verification problems are NP-complete. Based on {PO} 2 -LTS and the optimisation objectives, practical verification algorithms are developed to check the satisfiability of the properties on the LE-SESs. As a major case study, we interrogate a real-world dynamic tracking system which uses a single Kalman Filter (KF) – a special case of Bayes filter – to localise and track a ground vehicle. Its perception system, based on convolutional neural networks, processes a high-resolution Wide Area Motion Imagery (WAMI) data stream. Experimental results show that our algorithms can not only verify the properties of the WAMI tracking system but also provide representative examples, the latter of which inspired us to take an enhanced LE-SESs design where runtime monitors or joint-KFs are required. Experimental results confirm the improvement in the robustness of the enhanced design.},
  archive      = {J_NEUCOM},
  author       = {Wei Huang and Yifan Zhou and Gaojie Jin and Youcheng Sun and Jie Meng and Fan Zhang and Xiaowei Huang},
  doi          = {10.1016/j.neucom.2024.127643},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127643},
  shortjournal = {Neurocomputing},
  title        = {Formal verification of robustness and resilience of learning-enabled state estimation systems},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advanced intelligent monitoring technologies for animals: A
survey. <em>NEUCOM</em>, <em>585</em>, 127640. (<a
href="https://doi.org/10.1016/j.neucom.2024.127640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective animal intelligent monitoring is of great value in terms of ecological protection and endangered specie conservation. At present, computer vision technologies have shed light on animal intelligent monitoring. Especially, numerous deep learning-based models and methods have been developed to address various challenges, and have made substantial strides in this field. However, there are still several problems to be solved and related areas to be mined, such as exploring new strategies to enhance the robustness and generalization ability of models, designing novel models for complex environments, and establishing large-scale publicly available animal datasets for performance verification of models. Therefore, we comprehensively elaborated and analyzed existing works on animal intelligent monitoring based on advanced information science technologies, so as to provide useful information assistance for relevant researchers. In this paper, we focus on three primary task fields: precise animal localization, tracking and individual identification. Specifically, we elucidate the definition and significance of each monitoring task, and summarize the baseline models for addressing different problems. We provide a specific analysis of strategies and prototypes of the models and methods employed in each tasks following by the technical progression from traditional machine learning to deep learning. In addition, we make a comparison and analysis of the relevant methods, summarize their similarities and differences between them, and point out the advantages and disadvantages of these methods. Finally, we present several unresolved challenges and problems in animal intelligent monitoring and provide potential research directions in the future. We expect that our review can serve as reference and guidance for related research fields.},
  archive      = {J_NEUCOM},
  author       = {Pengfei Xu and Yuanyuan Zhang and Minghao Ji and Songtao Guo and Zhanyong Tang and Xiang Wang and Jing Guo and Junjie Zhang and Ziyu Guan},
  doi          = {10.1016/j.neucom.2024.127640},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127640},
  shortjournal = {Neurocomputing},
  title        = {Advanced intelligent monitoring technologies for animals: A survey},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of object tracking methods: From general field to
autonomous vehicles. <em>NEUCOM</em>, <em>585</em>, 127635. (<a
href="https://doi.org/10.1016/j.neucom.2024.127635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object tracking is a key technology in the field of intelligent vehicle environmental perception. Accurate and efficient object tracking technologies provide autonomous vehicles with real-time information of moving objects, helping judge the behavioral intention of the objects and predict the trajectories. With the rapid development of artificial intelligence and vehicular sensors, object tracking algorithms have made great progress. Recently however, only a few studies focus on object tracking technology for autonomous vehicles, especially involving multi-source sensors and information fusion algorithms. This study systematically and comprehensively reviews over 230 studies, therein noting the recent research achievements in object tracking are generalized. First, the single object tracking (SOT) and multiple object tracking (MOT) algorithms based on vision sensor are introduced respectively, including 2D, 3D, and intelligent vehicle object tracking algorithms, while the pros and cons of the classical algorithms and latest algorithms are summarized. Then, the object tracking methods based on point cloud and multimodal fusion are discussed and analyzed, and a variety of object tracking datasets are displayed. Finally, on the basis of the research status of intelligent vehicle object tracking algorithms, the challenges and opportunities of future research are presented.},
  archive      = {J_NEUCOM},
  author       = {Jingwei Cao and Hongyu Zhang and Lisheng Jin and Jiawang Lv and Guoyang Hou and Chengtao Zhang},
  doi          = {10.1016/j.neucom.2024.127635},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127635},
  shortjournal = {Neurocomputing},
  title        = {A review of object tracking methods: From general field to autonomous vehicles},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024h). Efficient adversarial training with multi-fidelity
optimization for robust neural network. <em>NEUCOM</em>, <em>585</em>,
127627. (<a href="https://doi.org/10.1016/j.neucom.2024.127627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial examples (AEs) pose a significant threat to the security and reliability of deep neural networks. Adversarial training (AT) is one of the effective defense methods, involving the integration of a number of generated AEs into the training process to enhance model robustness. However, the computational cost associated with AE generation is unbearable, particularly for large-scale tasks. In pursuit of fast AT, many algorithms generate AEs by adopting a simple attack strategy, but they often sacrifice the quality of AEs and suffer from catastrophic overfitting, resulting in suboptimal model robustness. To address these issues, our approach incorporates multi-fidelity optimization, which employs a dynamic attack strategy to generate AEs with varying fidelity within a suitable range. Furthermore, we introduce a surrogate-assisted fidelity estimation module at the beginning of our proposed algorithm, allowing for the adaptive determination of the fidelity range tailored to specific tasks. Comparative experiments with seven state-of-the-art algorithms on three networks and three datasets demonstrate that the proposed algorithm obtains a competitive robust accuracy but spends only 50% of the training time of the projected gradient descent algorithm.},
  archive      = {J_NEUCOM},
  author       = {Zhaoxin Wang and Handing Wang and Cong Tian and Yaochu Jin},
  doi          = {10.1016/j.neucom.2024.127627},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127627},
  shortjournal = {Neurocomputing},
  title        = {Efficient adversarial training with multi-fidelity optimization for robust neural network},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AM-EEGNet: An advanced multi-input deep learning framework
for classifying stroke patient EEG task states. <em>NEUCOM</em>,
<em>585</em>, 127622. (<a
href="https://doi.org/10.1016/j.neucom.2024.127622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke is the leading cause of adult disability among all prevalent pathologies around the world. To improve post-stroke patients&#39; active daily life and living quality, revealing the underlying brain mechanism of stroke recovery is crucial. The EEG feature signals (power spectrum density and functional connectivity) in two different states (eyes-close, eyes-open) show their ability as predictors in post-stroke recovery. In addition, deep learning methods can successfully extract EEG features to predict. To this end, we propose an advanced multi-input deep-learning framework that can extract multi-EEG feature signals and explain results from EEG feature inputs for stroke patients. A total of 72 post-stroke patients were recruited in this study. Each would be asked to participate in two experiments (eyes-closed and eyes-open resting state). The deep learning framework would be based on their EEG feature signals to predict their task states. AM-EEGNet achieves high performance (Accuracy: 97.22%, Sensitivity: 0.94, and Specificity: 1.00) in the EEG-based states classification problems. In addition, we demonstrated the explanation result from EEG features. Our results suggest that AM-EEGNet is robust enough to learn EEG features from stroke patients and can explain the EEG features related to tasks. Moreover, our results reveal the difference in those two eyes-close and eyes-open resting states for stroke patients. Model details can be found at https://github.com/linbingru/am-eegnet .},
  archive      = {J_NEUCOM},
  author       = {Ping-Ju Lin and Wei Li and Xiaoxue Zhai and Jingyao Sun and Yu Pan and Linhong Ji and Chong Li},
  doi          = {10.1016/j.neucom.2024.127622},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127622},
  shortjournal = {Neurocomputing},
  title        = {AM-EEGNet: An advanced multi-input deep learning framework for classifying stroke patient EEG task states},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blind image quality assessment based on hierarchical
dependency learning and quality aggregation. <em>NEUCOM</em>,
<em>585</em>, 127621. (<a
href="https://doi.org/10.1016/j.neucom.2024.127621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image quality assessment (IQA) aims to build a quality prediction model to assess image quality automatically rather than artificially. Due to a lack of reference images, blind image quality assessment (BIQA) has become an attractive yet challenging research topic. Inspired by the hierarchical perception mechanism in the human visual system, some existing BIQA methods aggregate multi-stage features of a convolutional neural network (CNN). However, they are regardless of the latent dependencies. To solve this problem, we propose a novel BIQA method based on hierarchical dependency learning and quality aggregation (HDLaQA). The proposed method includes multi-stage feature extraction, hierarchical dependency learning, and quality aggregation. In multi-stage feature extraction, a CNN is used as the feature extractor and multi-stage features are output for further learning. In hierarchical dependency learning, spatial and channel dependencies among the multi-stage features are modeled. To this end, a dual-head spatial dependency (DSD) module is designed to harvest the spatial dependencies between the adjacent-stage features and deliver these dependencies to the next stage. Moreover, exponential bilinear pooling (EBP) is presented to learn the channel dependencies, which is more stable than commonly used BP. In quality aggregation, multiple quality scores are predicted based on the learned dependencies, and multiple learnable weights are used to measure the importance of the predicted scores for final quality evaluation. Experimental results on seven IQA databases demonstrate the competitiveness of the proposed method on both synthetic and authentic distortions.},
  archive      = {J_NEUCOM},
  author       = {Jili Xia and Lihuo He and Xinbo Gao and Bo Hu},
  doi          = {10.1016/j.neucom.2024.127621},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127621},
  shortjournal = {Neurocomputing},
  title        = {Blind image quality assessment based on hierarchical dependency learning and quality aggregation},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel structure learning method of bayesian networks based
on the neighboring complete node ordering search. <em>NEUCOM</em>,
<em>585</em>, 127620. (<a
href="https://doi.org/10.1016/j.neucom.2024.127620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning the optimal structure of a Bayesian network (BN) from observational data has received considerable research attention. In most structure learning methods based on scoring and searching, the discrete space of BNs is used, and the scale of the network grows exponentially with the number of nodes n n , that is, O ( n ! 2 C n 2 ) O(n!2Cn2) . Any existing scoring function in the BN space has multiple peaks. Thus, when using heuristic algorithms, local optimum problems may occur while searching in this space. As the search process involves only a small part of the space, the final learning result is not always ideal. In this study, the scoring and searching task is implemented in the complete node ordering space, and a novel neighbor operation is proposed for improving learning accuracy. This technique reduces the search space to O ( n ! ) O(n!) and facilitates optimized learning of a structure. Furthermore, techniques for efficiency optimization are proposed, which address the problems of high computational complexity and repetitive calculation of family scores.},
  archive      = {J_NEUCOM},
  author       = {Chuchao He and Peng Wang and LinYu Tian and Ruohai Di and Zidong Wang and Yu Yang},
  doi          = {10.1016/j.neucom.2024.127620},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127620},
  shortjournal = {Neurocomputing},
  title        = {A novel structure learning method of bayesian networks based on the neighboring complete node ordering search},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shape-aware speckle matching network for cross-domain 3D
reconstruction. <em>NEUCOM</em>, <em>585</em>, 127617. (<a
href="https://doi.org/10.1016/j.neucom.2024.127617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The learning-based binocular 3D reconstruction method outperforms traditional vision algorithms in terms of precision and efficiency. However, in some cross-domain scenes, the precision of the well-trained network drastically decreases when handling samples in diverse contexts. This paper proposes an end-to-end shape-aware speckle matching network (SSMNet) that combines shape-mask information to achieve improved precision and completeness of disparity calculation in cross-domain applications. The cascade attention mechanism is inserted in the feature extraction stage to concentrate on valuable regions. The shape-aware module is designed to learn additional shape contour information, and multiscale features are integrated simultaneously to construct the cost-volume for the subsequent lightweight 3D aggregation. In addition, instance normalization is adopted to guarantee style migration, and a hybrid loss function is used to supervise the learning process. Furthermore, a high-precision binocular speckle dataset is built, including training and testing sets in different distributions. Extensive quantitative and qualitative experiments demonstrate that SSMNet enhances cross-domain capability and achieves state-of-the-art performance. Measurement precision evaluation illustrates that the proposed method can realize the desired highly precise 3D shape measurement in a real industrial scenario.},
  archive      = {J_NEUCOM},
  author       = {Yanzhen Dong and Haitao Wu and Xiao Yang and Xiaobo Chen and Juntong Xi},
  doi          = {10.1016/j.neucom.2024.127617},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127617},
  shortjournal = {Neurocomputing},
  title        = {Shape-aware speckle matching network for cross-domain 3D reconstruction},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Weakly-supervised auto-encoder via energy regularization
and soft multi-label learning on k labeled samples. <em>NEUCOM</em>,
<em>585</em>, 127596. (<a
href="https://doi.org/10.1016/j.neucom.2024.127596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification is a hot topic in computer vision tasks. As a simple unsupervised network model, auto-encoder can learn and apply features to classification. However, due to the lack of prior knowledge of auto-encoder, there are significant limitations in their performance in practical applications. On the contrary, although precise labels can guide supervised learning to learn accurately, it is difficult to obtain strong supervised information on many tasks because of the high cost of data annotation. In this paper, we propose a weakly-supervised auto-encoder via energy regularization and soft multi-label learning on k k labeled samples (WSAE), where weakly-supervised learning not only reduces the workload of manual labeling but also introduces supervised information, which improves the performance of auto-encoder to a large extent. Specifically, we first explore a lower bound value of training data that needs to be labeled in weakly supervised learning. Then, we discriminate the visual consistency of k k labeled samples compared to unlabeled samples with soft multi-label to efficiently increase the difference of features between classes and reduce the variation of features within classes for more discriminative feature representations and higher classification accuracy. In addition, an energy regularization is introduced to the model to fit the probability distribution of the data so that the smaller the energy, the more concentrated the probability distribution and the more ordered the system. The model with energy regularization can represent the data better, thereby improving the feature extraction ability and increasing the classification accuracy of the network. Extensive experiments are conducted on some publicly available datasets and demonstrate that our method outperforms the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Huiling Wang and Jun Sun and Xiaofeng Gu and Zunhao Hu and Chao Zhou},
  doi          = {10.1016/j.neucom.2024.127596},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127596},
  shortjournal = {Neurocomputing},
  title        = {Weakly-supervised auto-encoder via energy regularization and soft multi-label learning on k labeled samples},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proactive image manipulation detection via deep semi-fragile
watermark. <em>NEUCOM</em>, <em>585</em>, 127593. (<a
href="https://doi.org/10.1016/j.neucom.2024.127593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malicious image tampering refers to intentionally manipulating images to make them harmful to the owners or users. It has become one of the most severe challenges to image authenticity. Conventional methods for detecting tampering by identifying visual artifacts and distortions have limitations due to the rapid advancement of image manipulation techniques, which leave fewer detectable traces. To address these challenges, we propose a proactive media authentication method using deep learning-based semi-fragile watermarks. The designed scheme utilizes deep neural networks to embed an invisible watermark into a target image that is pixel-by-pixel entangled with it, which acts as an indicator of tampering trails. Once the watermarked image is counterfeited, the embedded watermark will exhibit changes accordingly, so we can locate the tampered regions by comparing retrieved and original watermarks. This proactive authentication mechanism makes our method effective against various image tamper techniques, including image copy&amp;move, splicing and in-painting. Although our watermark is designed to be fragile to malicious tampering operations, it remains robust to benign image-processing operations such as JPEG compression, scaling, saturation, contrast adjustments, etc. This design enables our watermark to retain effectiveness when shared over the internet. Extensive experiments demonstrate that our method achieves state-of-the-art forgery detection with superior robustness, imperceptibility and security performance.},
  archive      = {J_NEUCOM},
  author       = {Yuan Zhao and Bo Liu and Tianqing Zhu and Ming Ding and Xin Yu and Wanlei Zhou},
  doi          = {10.1016/j.neucom.2024.127593},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127593},
  shortjournal = {Neurocomputing},
  title        = {Proactive image manipulation detection via deep semi-fragile watermark},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Practical fixed-time event-triggered output feedback
containment control for second-order nonlinear multi-agent systems with
switching topologies. <em>NEUCOM</em>, <em>585</em>, 127580. (<a
href="https://doi.org/10.1016/j.neucom.2024.127580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the fixed-time containment of the second-order nonlinear multi-agent system (MAS) accompanied by switching topologies and event-triggered communication. The agent is subjected to unknown nonlinear dynamics. A fixed-time RBF observer was constructed based on information obtained from neural networks and event-triggered communication. By combining the controller with the identification information from the observer, it is demonstrated that the system can achieve practical fixed-time output feedback containment and exclude Zeno behavior during the control process. The effectiveness of the proposed event-triggered control method for fixed-time output feedback containment control of the second-order nonlinear MAS is verified by simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Rongxiang Lu and Jie Wu and Xisheng Zhan and Huaicheng Yan},
  doi          = {10.1016/j.neucom.2024.127580},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127580},
  shortjournal = {Neurocomputing},
  title        = {Practical fixed-time event-triggered output feedback containment control for second-order nonlinear multi-agent systems with switching topologies},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical approximate optimal interaction control of
human-centered modular robot manipulator systems: A stackelberg
differential game-based approach. <em>NEUCOM</em>, <em>585</em>, 127573.
(<a href="https://doi.org/10.1016/j.neucom.2024.127573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Stackelberg game-based approximate optimal interaction control approach is presented for human-centered modular robot manipulator (MRM) systems. Joint torque feedback (JTF) technique is utilized to form the MRM dynamic model. The major objective of optimal control with human–robot collaboration (HRC) is transformed into approximating Stackelberg equilibrium by adopting Stackelberg game governed between the human and the MRM that are regarded as players with different hierarchical level in interaction process. On the basis of the adaptive dynamic programming (ADP), the approximate optimal interaction control policy with HRC task is developed via critic neural network (NN)-based Stackelberg game manner for addressing Hamilton–Jacobian (HJ) equations. The position tracking error is ultimately uniformly bounded (UUB) according to the Lyapunov theory. Experiment results demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Tianjiao An and Xinye Zhu and Bing Ma and Hucheng Jiang and Bo Dong},
  doi          = {10.1016/j.neucom.2024.127573},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127573},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical approximate optimal interaction control of human-centered modular robot manipulator systems: A stackelberg differential game-based approach},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Overview of knowledge reasoning for knowledge graph.
<em>NEUCOM</em>, <em>585</em>, 127571. (<a
href="https://doi.org/10.1016/j.neucom.2024.127571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs are large-scale semantic networks that considerably impact knowledge representation. Mining hidden knowledge from existing data, including triplet knowledge reasoning, is a primary objective of knowledge graphs. With the development of Neural Network (NN) and Deep Learning (DL), the interpretability of triplet knowledge reasoning gradually decreases; furthermore, what machines learn is not actual reasoning but digital reasoning shortcuts. To solve this problem, more background knowledge needs to be introduced into knowledge graphs: causal graphs can offer valuable causal logic knowledge for reasoning; temporal quadruples can provide essential temporal distribution details; and commonsense graphs can furnish pertinent commonsense understanding to support reasoning. In recent years, many scholars have incorporated additional background knowledge into knowledge graphs to construct more complex reasoning mechanisms. This paper reviews the basic concepts and definitions of knowledge reasoning and the reasoning methods used for knowledge graphs. Specifically, we dissect the reasoning methods into four categories: triplet reasoning, causal inference, temporal inference, and commonsense reasoning. Finally, we discuss the remaining challenges and research opportunities related to knowledge graph reasoning.},
  archive      = {J_NEUCOM},
  author       = {Xinliang Liu and Tingyu Mao and Yanyan Shi and Yanzhao Ren},
  doi          = {10.1016/j.neucom.2024.127571},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127571},
  shortjournal = {Neurocomputing},
  title        = {Overview of knowledge reasoning for knowledge graph},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning for optimal control of linear
impulsive systems with periodic impulses. <em>NEUCOM</em>, <em>585</em>,
127569. (<a href="https://doi.org/10.1016/j.neucom.2024.127569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the finite- and infinite-horizon optimal control problems of linear impulsive systems with periodic impulses under the quadratic performance index. Necessary and sufficient conditions for the optimal impulsive system are derived in terms of hybrid Riccati equations by utilizing the variational method and the collocation method combined with a time-varying Lyapunov function. Different from the existing model-based impulsive control schemes, three reinforcement learning (RL)-based algorithms are proposed to solve the optimal impulsive controller and hybrid controller for the impulsive system without the exact knowledge of the system dynamics. The asymptotical stability of the impulsive control system and the convergence of the RL-based algorithms are proved rigorously. Finally, a numerical simulation illustrates the effectiveness of the proposed control methods.},
  archive      = {J_NEUCOM},
  author       = {Yan Wu and Shixian Luo and Feiqi Deng},
  doi          = {10.1016/j.neucom.2024.127569},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127569},
  shortjournal = {Neurocomputing},
  title        = {Reinforcement learning for optimal control of linear impulsive systems with periodic impulses},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differentially private stochastic gradient descent with
low-noise. <em>NEUCOM</em>, <em>585</em>, 127557. (<a
href="https://doi.org/10.1016/j.neucom.2024.127557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern machine learning algorithms aim to extract fine-grained information from data to provide accurate predictions, which often conflicts with the goal of privacy protection. This paper addresses the practical and theoretical importance of developing privacy-preserving machine learning algorithms that ensure good performance while preserving privacy. In this paper, we focus on the privacy and utility (measured by excess risk bounds) performances of differentially private stochastic gradient descent (SGD) algorithms in the setting of stochastic convex optimization. Specifically, we examine the pointwise problem in the low-noise setting for which we derive sharper excess risk bounds for the differentially private SGD algorithm. In the pairwise learning setting, we propose a simple differentially private SGD algorithm based on gradient perturbation. Furthermore, we develop novel utility bounds for the proposed algorithm, proving that it achieves optimal excess risk rates even for non-smooth losses. Notably, we establish fast learning rates for privacy-preserving pairwise learning under the low-noise condition, which is the first of its kind.},
  archive      = {J_NEUCOM},
  author       = {Puyu Wang and Yunwen Lei and Yiming Ying and Ding-Xuan Zhou},
  doi          = {10.1016/j.neucom.2024.127557},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127557},
  shortjournal = {Neurocomputing},
  title        = {Differentially private stochastic gradient descent with low-noise},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synergistic registration of CT-MRI brain images and retinal
images: A novel approach leveraging reinforcement learning and modified
artificial rabbit optimization. <em>NEUCOM</em>, <em>585</em>, 127506.
(<a href="https://doi.org/10.1016/j.neucom.2024.127506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image registration is a pivotal application within the field of medical imaging. It entails the fusion of commonalities among data of disparate modalities into a unified coordinate system, thereby achieving complementary imaging information. This process plays a crucial role in scenarios such as accurate disease diagnosis, surgical guidance, patient monitoring, and radiological therapy. Due to the distinct characteristics exhibited by changes in the same region over time or across different modalities, swiftly and accurately identifying corresponding relationships between pre-registered images remains a formidable challenge. This paper proposes the incorporation of an enhanced Artificial Rabbits Optimization (ARO) algorithm as an agent within the framework of reinforcement learning. The method, referred to as RL-mARO, is employed for medical image registration. By utilizing Normalized Mutual Information (NMI) as a reward and penalty feedback for the similarity metric, the agent continuously adjusts and alters the learning strategies within the population, thereby progressively converging towards the correct registration direction. The contribution of reinforcement learning to ARO was validated on the IEEE CEC2020 benchmark dataset. Simultaneously, registration experiments were conducted on the multi-modal brain dataset, Retrospective Image Registration Evaluation Project (RIRE), as well as the single-modal fundus dataset, Fundus Image Registration Dataset (FIRE). The results of both registration experiments demonstrate that the RL-mARO model exhibits elevated robustness and registration accuracy.},
  archive      = {J_NEUCOM},
  author       = {Xiaolei Luo and Hua Zou and Yi Hu and Peng Gui and Yang Xu and Dengyi Zhang and Wei Hu and Min Hu},
  doi          = {10.1016/j.neucom.2024.127506},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127506},
  shortjournal = {Neurocomputing},
  title        = {Synergistic registration of CT-MRI brain images and retinal images: A novel approach leveraging reinforcement learning and modified artificial rabbit optimization},
  volume       = {585},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Elegans-AI: How the connectome of a living organism could
model artificial neural networks. <em>NEUCOM</em>, <em>584</em>, 127598.
(<a href="https://doi.org/10.1016/j.neucom.2024.127598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces Elegans-AI models, a class of neural networks that leverage the connectome topology of the Caenorhabditis elegans to design deep and reservoir architectures. Utilizing deep learning models inspired by the connectome, this paper leverages the evolutionary selection process to consolidate the functional arrangement of biological neurons within their networks. The initial goal involves the conversion of natural connectomes into artificial representations. The second objective centers on embedding the complex circuitry topology of artificial connectomes into both deep learning and deep reservoir networks, highlighting their neural-dynamic short-term and long-term memory and learning capabilities. Lastly, our third objective aims to establish structural explainability by examining the heterophilic/homophilic properties within the connectome and their impact on learning capabilities. In our study, the Elegans-AI models demonstrate superior performance compared to similar models that utilize either randomly rewired artificial connectomes or simulated bio-plausible ones. Notably, these Elegans-AI models achieve a top-1 accuracy of 99.99% on both Cifar10 and Cifar100, and 99.84% on MNIST Unsup. They do this with significantly fewer learning parameters, particularly when reservoir configurations of the connectome are used. Our findings indicate a clear connection between bio-plausible network patterns, the small-world characteristic, and learning outcomes, emphasizing the significant role of evolutionary optimization in shaping the topology of artificial neural networks for improved learning performance.},
  archive      = {J_NEUCOM},
  author       = {Francesco Bardozzo and Andrea Terlizzi and Claudio Simoncini and Pietro Lió and Roberto Tagliaferri},
  doi          = {10.1016/j.neucom.2024.127598},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127598},
  shortjournal = {Neurocomputing},
  title        = {Elegans-AI: How the connectome of a living organism could model artificial neural networks},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust social recommendation based on contrastive learning
and dual-stage graph neural network. <em>NEUCOM</em>, <em>584</em>,
127597. (<a href="https://doi.org/10.1016/j.neucom.2024.127597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {GNN-based social recommendation aims to use social network information to improve recommendation performance of traditional user–item interaction network (U–I network). However, in graph neural network information aggregation, both social networks and U–I networks inevitably have noise, which affects accuracy of recommendation results. To reduce the noise impact of network data, we propose Robust Social Recommendation based on Contrastive Learning and Dual-Stage Graph Neural Network (CLDS). First, considering instability of social networks, we propose the social preference network. It is robust and retains only social friend relationships with common preferences. Based on it and U–I network, we construct a social recommendation pre-training model. Next, we propose self-contrastive learning method. The method initializes multiple social network node representations through Gaussian distribution, pre-training and random disturbance, respectively. Then, it uses contrastive learning on the generated multiple node representations to enhance the robustness of node representation. Finally, CLDS avoids directly capturing potentially user–user and item–item information in U–I networks which is incomplete and untrusted. And instead, it only extracts user–item information to reduce the noise generated by GNN-based U–I network information aggregation. We conduct experiments under the open-source real network dataset. The experimental results show that CLDS outperforms state-of-art methods in social recommendation. The code is available at: https://github.com/Andrewsama/CLDS-master .},
  archive      = {J_NEUCOM},
  author       = {Gang-Feng Ma and Xu-Hua Yang and Haixia Long and Yanbo Zhou and Xin-Li Xu},
  doi          = {10.1016/j.neucom.2024.127597},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127597},
  shortjournal = {Neurocomputing},
  title        = {Robust social recommendation based on contrastive learning and dual-stage graph neural network},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adjustable iterative q-learning for advanced neural tracking
control with stability guarantee. <em>NEUCOM</em>, <em>584</em>, 127592.
(<a href="https://doi.org/10.1016/j.neucom.2024.127592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, an accelerated Q-learning algorithm with evolving control is established to solve the optimal tracking control problem. First, an accelerated Q-learning scheme is constructed with an advanced Q-function. By utilizing the advanced Q-function, calculating of the feedforward control input can be avoided and the terminal tracking error can be eliminated. Then, by introducing the relaxation factor, the convergence rate of the iterative Q-function sequence is accelerated significantly, which is a potential way to diminish the computational burden. Furthermore, the convergence, positive definiteness, and stability conditions of the accelerated Q-learning algorithm are analyzed with some preconditions of the relaxation factor. Thus, the developed algorithm can achieve evolving control. Finally, the fantastic performance of the developed algorithm with critic network implementation is verified through two simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Yuan Wang and Ding Wang and Mingming Zhao and Ao Liu and Junfei Qiao},
  doi          = {10.1016/j.neucom.2024.127592},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127592},
  shortjournal = {Neurocomputing},
  title        = {Adjustable iterative Q-learning for advanced neural tracking control with stability guarantee},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross coordination of behavior clone and reinforcement
learning for autonomous within-visual-range air combat. <em>NEUCOM</em>,
<em>584</em>, 127591. (<a
href="https://doi.org/10.1016/j.neucom.2024.127591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a novel hierarchical framework to resolve within-visual-range (WVR) air-to-air combat under complex nonlinear 6 degrees-of-freedom (6-DOF) dynamics of the aircraft and missile. The decision process is constructed with two layers from the top to the bottom and adopts reinforcement learning to solve them separately. The top layer designs a new combat policy to decide the autopilot commands (such as the target heading, velocity, and altitude) and missile launch according to the current combat situation. Then the bottom layer uses a control policy to answer the autopilot commands by calculating the actual input signals (deflections of the rudder, elevator, aileron, and throttle) for the aircraft. For the combat policy, we present a new learning method called “E2L” that can mimic the knowledge of the expert under the two-layer decision frame to inspire the intelligence of the agent in the early stage of training. This method establishes a cross coordination of behavior clone (BC) and proximal policy optimization (PPO). Under the mechanism, the agent is alternately updated around the latest strategy, using BC with gradient clipping and PPO with Kullback–Leibler divergence loss and the modified BC demonstration trajectories, which can learn competitive combat strategies more stably and quickly. Sufficient experimental results show that the proposed method can achieve better combat performance than the baselines.},
  archive      = {J_NEUCOM},
  author       = {Lun Li and Xuebo Zhang and Chenxu Qian and Minghui Zhao and Runhua Wang},
  doi          = {10.1016/j.neucom.2024.127591},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127591},
  shortjournal = {Neurocomputing},
  title        = {Cross coordination of behavior clone and reinforcement learning for autonomous within-visual-range air combat},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards the adversarial robustness of facial expression
recognition: Facial attention-aware adversarial training.
<em>NEUCOM</em>, <em>584</em>, 127588. (<a
href="https://doi.org/10.1016/j.neucom.2024.127588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Beyond the in-the-lab environment, deep-learning-based facial expression recognition (FER) models that provide reliable performance on wild datasets are gradually becoming applied to the real world. However, the fact that neural networks are inherently vulnerable to digital attacks (e.g., adversarial examples) and their performance is not exposed to external threats reduces the applicability of FER technology. So, we design a so-called test-time attack scenario in which FER models are deceived by superimposing imperceptible perturbation(s) on test images. This scenario, which targets the testing phase in which model weakness is revealed, clearly shows how vulnerable FER models are to external attacks. As a remedy against this attack, we propose a novel method called FAAT, which adversarially trains the model by paying attention to core region(s) of face. FAAT aims to improve model robustness so that the model can be generalized to unseen perturbation(s) while focusing on facial expression-related areas. For example, FAAT’s robustness against PGD attack with a performance improvement of up to 18% is encouraging. Also, various benchmarking results based on our attack scenario analyze the fidelity of prior arts and will promote the development direction of future models.},
  archive      = {J_NEUCOM},
  author       = {Daeha Kim and Heeje Kim and Yoojin Jung and Seongho Kim and Byung Cheol Song},
  doi          = {10.1016/j.neucom.2024.127588},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127588},
  shortjournal = {Neurocomputing},
  title        = {Towards the adversarial robustness of facial expression recognition: Facial attention-aware adversarial training},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Class similarity weighted knowledge distillation for few
shot incremental learning. <em>NEUCOM</em>, <em>584</em>, 127587. (<a
href="https://doi.org/10.1016/j.neucom.2024.127587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot class incremental learning illustrates the challenges of learning new concepts, where the learner can access only a small sample per concept. The standard incremental learning techniques cannot be applied directly because of the small number of samples for training. Moreover, catastrophic forgetting is the propensity of an Artificial Neural Network to fully and abruptly forget previously learned knowledge upon learning new knowledge. This problem happens due to a lack of supervision in older classes or an imbalance between the old and new classes. In this work, we propose a new distillation structure to tackle the forgetting and overfitting issues. Particularly, we suggest a dual distillation module that adaptably draws knowledge from two different but complementary teachers. The first teacher is the base model, which has been trained on large class data, and the second teacher is the updated model from the previous K-1 session, which contains the modified knowledge of previously observed new classes. Thus, the first teacher can reduce overfitting issues by transferring the knowledge obtained from the base classes to the new classes. While the second teacher can reduce knowledge forgetting by distilling knowledge from the previous model. Additionally, we use semantic information as word embedding to facilitate the distillation process. To align visual and semantic vectors, we used the attention mechanism of the embedding of visual data. With extensive experiments on different data sets such as Mini-ImageNet, CIFAR100, and CUB200, our model shows state-of-the-art performance compared to the existing few shot incremental learning methods.},
  archive      = {J_NEUCOM},
  author       = {Feidu Akmel and Fanman Meng and Qingbo Wu and Shuai Chen and Runtong Zhang and Maregu Assefa},
  doi          = {10.1016/j.neucom.2024.127587},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127587},
  shortjournal = {Neurocomputing},
  title        = {Class similarity weighted knowledge distillation for few shot incremental learning},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consensus of a new multi-agent system via multi-task,
multi-control mechanism and multi-consensus strategy. <em>NEUCOM</em>,
<em>584</em>, 127586. (<a
href="https://doi.org/10.1016/j.neucom.2024.127586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the consensus problem of a new multi-agent system via multi-task, multi-control mechanism and multi-consensus strategy. Firstly, two multi-task algorithms are proposed, which can reasonably select some agent nodes with better performance to form the multi-agent system according to different tasks. Secondly, a multi-control protocol designed in this paper integrates continuous control mechanism, impulsive control mechanism and hybrid control mechanism, which has strong applicability and efficiency. Thirdly, a multi-consensus strategy is designed, and it can be converted into “average consensus strategy”, “leader-following consensus strategy” and “hybrid consensus strategy” through different parameter settings, which greatly broadens the application field of the multi-agent system. We construct a dynamic model for the proposed multi-agent system, analyze it by using matrix measure and Lyapunov stability theory, and obtain the theorems that enable it to achieve multiple consensus. Finally, the efficiency and practicability of our theories are verified through several simulation experiments. We further carry out some comparative analysis with some relevant papers, and obtain the superiority of our theories in multiple indicators.},
  archive      = {J_NEUCOM},
  author       = {Xiang Hu and Yu Xiong and Zufan Zhang and Chuandong Li},
  doi          = {10.1016/j.neucom.2024.127586},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127586},
  shortjournal = {Neurocomputing},
  title        = {Consensus of a new multi-agent system via multi-task, multi-control mechanism and multi-consensus strategy},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DICAM: Deep inception and channel-wise attention modules for
underwater image enhancement. <em>NEUCOM</em>, <em>584</em>, 127585. (<a
href="https://doi.org/10.1016/j.neucom.2024.127585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In underwater environments, imaging devices suffer from water turbidity, attenuation of lights, scattering, and particles, leading to low quality, poor contrast, and biased color images. This has led to great challenges for underwater condition monitoring and inspection using conventional vision techniques. In recent years, underwater image enhancement has attracted increasing attention due to its critical role in improving the performance of current computer vision tasks in underwater object detection and segmentation. As existing methods, built mainly from natural scenes, have performance limitations in improving the color richness and distributions we propose a novel deep learning-based approach namely Deep Inception and Channel-wise Attention Modules (DICAM) to enhance the quality, contrast, and color cast of the hazy underwater images. The proposed DICAM model enhances the quality of underwater images, considering both the proportional degradations and non-uniform color cast. Extensive experiments on two publicly available underwater image enhancement datasets have verified the superiority of our proposed model compared with several state-of-the-art conventional and deep learning-based methods in terms of full-reference and reference-free image quality assessment metrics. The source code of our DICAM model is available at https://github.com/hfarhaditolie/DICAM .},
  archive      = {J_NEUCOM},
  author       = {Hamidreza Farhadi Tolie and Jinchang Ren and Eyad Elyan},
  doi          = {10.1016/j.neucom.2024.127585},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127585},
  shortjournal = {Neurocomputing},
  title        = {DICAM: Deep inception and channel-wise attention modules for underwater image enhancement},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linear convergence of decentralized estimation for
statistical estimation using gradient method. <em>NEUCOM</em>,
<em>584</em>, 127584. (<a
href="https://doi.org/10.1016/j.neucom.2024.127584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been a growing interest in solving consensus optimization problems in a multi-agent system. It is known that there is an exactness-speed dilemma for decentralized optimization for the naive gradient method, where either we have fast linear convergence to a neighborhood of size O ( η ) O(η) using a fixed constant step size η η , or slow convergence to the exact optimizer with a decreasing step size. We reinvestigate a special case of this problem from a statistical point of view, where each agent’s local function is a sample estimate of a common population function. It is shown that when considering the convergence to the population target instead of to the exact consensual solution, the convergence is linear up to the statistical accuracy of the problem, using a step size only depending on the network characteristics instead of the sample size N N . The objective function is not required to be strongly convex (but their statistical limit is), which allows for example the absolute deviation function which is used in median regression. Such results are in stark contrast to the optimization literature, where strong convexity of the objective function is necessary for linear convergence.},
  archive      = {J_NEUCOM},
  author       = {Wangli Xu and Kehan Wang and Heng Lian},
  doi          = {10.1016/j.neucom.2024.127584},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127584},
  shortjournal = {Neurocomputing},
  title        = {Linear convergence of decentralized estimation for statistical estimation using gradient method},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A large-scale microblog dataset and stock movement
prediction based on supervised contrastive learning model.
<em>NEUCOM</em>, <em>584</em>, 127583. (<a
href="https://doi.org/10.1016/j.neucom.2024.127583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of Deep Neural Networks (DNN) with Natural Language Processing (NLP) technologies has opened new avenues in financial market prediction, particularly through the utilization of textual information. This study represents a significant advancement, which offers two primary contributions to stock trend prediction: (i) the exploitation of textual data (news, comments, microblogs) using advanced DNN architectures, enhancing market information utilization; (ii) significant improvement of the accuracy of predicting the direction of stock volatility by integrating textual and neural network technologies. Meanwhile, we have crawled, filtered, and constructed a large-scale microblog dataset. This dataset includes approximately 114,992 microblog textual data from 40 Science and Technology Innovation Board (STIB) companies in China during 2021. We conducted a comprehensive analysis using various DNN techniques, including Feedback Neural Networks (FNN), Supervised Contrastive Learning (SCL), Cross Entropy (CE), and Dual Contrastive Learning (DualCL), in conjunction with bag of words models, BERT, and Roberta compilers. Our findings reveal that the SCL method, when combined with microblog data, significantly increases prediction accuracy, particularly during the COVID-19 period. Furthermore, we discovered that using a cross-stock dataset enhances the accuracy of all prediction methods, and random allocation of microblog data leads to better results than sequential allocation. Additionally, we compared the efficacy of traditional models like the CAPM, three-factor, and five-factor models against neural network-based methods. Our results suggest a notable superiority of the SCL method in increasing prediction accuracy. Finally, applying our findings to real-world trading strategies, we demonstrated the practical advantages of using the SCL method in trading, evidenced by significant improvements across all performance indicators.},
  archive      = {J_NEUCOM},
  author       = {Song Yang and Daniel Tang},
  doi          = {10.1016/j.neucom.2024.127583},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127583},
  shortjournal = {Neurocomputing},
  title        = {A large-scale microblog dataset and stock movement prediction based on supervised contrastive learning model},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event-triggered adaptive vibration control for a flexible
satellite with time-varying actuator faults. <em>NEUCOM</em>,
<em>584</em>, 127578. (<a
href="https://doi.org/10.1016/j.neucom.2024.127578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, vibration control is studied for the flexible satellite through wireless communication, and given the fact that the actuators are prone to unknown faults, the input signal event-triggering and time-varying actuator faults are considered for the flexible satellite simultaneously. The satellite system is composed of two symmetrical flexible panels attached to a centrebody, which is a distributed parameter system and the established model is represented by partial differential equations (PDEs). Based on the PDEs model of the flexible satellite, the input event-triggered mechanism using the relative threshold strategy is designed firstly to lower the communication burden, and then the event-triggered-based adaptive fault-tolerant control laws are developed with the aid of the designed auxiliary signals for the system with time-varying actuator faults. With the proposed control scheme, the vibration of the system is controlled to the small neighborhood of zero, and the angle of the panels is regulated to the desired position. Finally, numerical simulation results are given to further show the effectiveness of the designed control scheme.},
  archive      = {J_NEUCOM},
  author       = {Ning Ji and Qingzhen Zhang and Jinkun Liu},
  doi          = {10.1016/j.neucom.2024.127578},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127578},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered adaptive vibration control for a flexible satellite with time-varying actuator faults},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Laplacian adaptive weighted discriminant analysis for
semi-supervised multi-class classification. <em>NEUCOM</em>,
<em>584</em>, 127577. (<a
href="https://doi.org/10.1016/j.neucom.2024.127577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-class discriminant analysis via adaptive weighted scheme (MDAAWS) has been proposed for supervised learning, which can deal with the issue that some classes may be vanished in the subspace. However, the acquisition of labeled data is expensive and time-consuming, while the unlabeled data is easy to obtained. To achieve a wide application, we propose a novel semi-supervised multi-class dimensionality reduction method based on MDAAWS, named Laplacian adaptive weighted discriminant analysis (LapAWDA), by applying manifold regularization to labeled and unlabeled data. This method inherits the merit of MDAAWS, assigning each pairwise class with an adaptive weight to avoid the issue of class vanishing. To enhance the robustness, we introduce the ℓ 2 , 1 ℓ2,1 norm into LapAWDA to obtain a sparse discriminant projection matrix. Moreover, an alternative and iterative scheme is designed to find the solution of LapAWDA. Extensive experiments on several synthetic and real-world datasets demonstrate the excellent performance of LapAWDA.},
  archive      = {J_NEUCOM},
  author       = {Yangtao Xue and Li Zhang and Hongwei Yin},
  doi          = {10.1016/j.neucom.2024.127577},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127577},
  shortjournal = {Neurocomputing},
  title        = {Laplacian adaptive weighted discriminant analysis for semi-supervised multi-class classification},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). MsVFE and v-SIAM: Attention-based multi-scale feature
interaction and fusion for outdoor LiDAR semantic segmentation.
<em>NEUCOM</em>, <em>584</em>, 127576. (<a
href="https://doi.org/10.1016/j.neucom.2024.127576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The semantic segmentation of outdoor LiDAR point clouds is one of the gigantic fields in the large-scale driving scenario. However, the performances of the state-of-the-art methods are unsatisfactory caused by the intrinsic limitations of the outdoor point clouds with excessive distribution of sparsity and imbalanced distribution of density, both of which become great challenges for a precise segmentation of LiDAR point clouds. To tackle the aforementioned intrinsic problems of point clouds with an improved segmentation performance, we propose a brand new attention-based feature interaction module called Voxel Slicing and Interaction based Attention Module (V-SIAM) that is integrated into the segmentation networks. Our V-SIAM is composed of a Voxel Slicing and Interaction Module (V-SIM) followed by a Voxel Attention Module (VAM), where the V-SIM is utilized to significantly reduce the negative impact caused by the imbalanced point density, in terms of enhancing the interaction of the voxel feature by a novel feature slicing, leading to the enriched voxel feature details of the point clouds. Moreover, the VAM is utilized to reduce the negative effect caused by the excessive sparsity of the point clouds, in terms of recalibration among voxel features via an innovative way, leading to the extraction of adaptive and self-enhanced voxel features. Besides the V-SIAM, a Multi-scale Voxel Feature Extractor (MsVFE), utilized as the preprocessing module of the segmentation networks, is proposed to further alleviate the negative influence caused by the excessive sparsity of the point clouds, realized by fusing the multi-scale voxel information of the sparse point clouds, leading to extraction of more detailed features of the point clouds. Our experimental results show that the proposed methods achieve 73.7% mIoU on the large-scale SemanticKITTI benchmark, outperforming the state-of-the-art PVKD and 2DPass by +1.3% mIoU and +0.8% mIoU, respectively. Moreover, our proposed MsVFE and V-SIAM achieve the state-of-the-art performance on the Toronto3D dataset and KITTI-360 dataset.},
  archive      = {J_NEUCOM},
  author       = {Jingru Yang and Jin Wang and Kaixiang Huang and Guodong Lu and Yu Sun and Huan Yu and Cheng Zhang and Ying Yang and Wenming Zou},
  doi          = {10.1016/j.neucom.2024.127576},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127576},
  shortjournal = {Neurocomputing},
  title        = {MsVFE and V-SIAM: Attention-based multi-scale feature interaction and fusion for outdoor LiDAR semantic segmentation},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sliding-mode surface-based adaptive optimal nonzero-sum
games for saturated nonlinear multi-player systems with
identifier-critic networks. <em>NEUCOM</em>, <em>584</em>, 127575. (<a
href="https://doi.org/10.1016/j.neucom.2024.127575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the sliding-mode surface-based adaptive optimal nonzero-sum games control problem for continuous-time nonlinear systems with input constraints. By constructing a value function associated with the sliding-mode surface, the original nonzero-sum games problem can be transformed into constructing multiple optimal control policies. Then, an adaptive dynamic programming method under identifier-critic networks is introduced to deal with the Hamilton–Jacobi equation, where the identifier networks are applied to approximate the unknown dynamics. A remarkable feature is that the critic updating laws are designed through experience replay and gradient descent methodologies, such that the persistence of excitation condition can be excluded. Based on the Lyapunov stability theory, all signals of the close-loop system are verified to be uniformly ultimately bounded. Finally, simulation results are given to illustrate the effectiveness of the proposed optimal nonzero-sum games scheme.},
  archive      = {J_NEUCOM},
  author       = {Shihui Liu and Huanqing Wang and Yunfeng Liu and Ning Xu and Xudong Zhao},
  doi          = {10.1016/j.neucom.2024.127575},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127575},
  shortjournal = {Neurocomputing},
  title        = {Sliding-mode surface-based adaptive optimal nonzero-sum games for saturated nonlinear multi-player systems with identifier-critic networks},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Neural networks taking probability distributions as input:
A framework for analyzing exchangeable networks. <em>NEUCOM</em>,
<em>584</em>, 127572. (<a
href="https://doi.org/10.1016/j.neucom.2024.127572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, exchangeable network structures that take datasets as input have been widely used to obtain representations of various datasets. Although they perform well, analyzing exchangeable network with a dataset as input is challenging. Given that this type of network can be viewed as a function acting on probability measures since datasets are drawn from various distributions, this paper theoretically analyzes exchangeable network structures from a probabilistic perspective. This paper proposes a probabilistic analytical framework that neural networks acting on probability measures, which is an extension of Multi-Layer Perceptrons (MLP). When only samples from each distribution are available, in this new analytical framework, neural networks acting on probability measures correspond to the traditional exchangeable structure defined on datasets. Using this new analytical framework, we can demonstrate the ability of exchangeable network structures to capture complex patterns, as it provides the universal approximation property of exchangeable network structures. Furthermore, we derive a consistency result that shows the parameter estimation of exchangeable network structures is consistent statistically under certain conditions.},
  archive      = {J_NEUCOM},
  author       = {Chongchong Li and Yuting Liu and Zhi-Ming Ma},
  doi          = {10.1016/j.neucom.2024.127572},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127572},
  shortjournal = {Neurocomputing},
  title        = {Neural networks taking probability distributions as input: A framework for analyzing exchangeable networks},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The joint learning of multi-resolution feature for
multi-class retinal vessel segmentation. <em>NEUCOM</em>, <em>584</em>,
127570. (<a href="https://doi.org/10.1016/j.neucom.2024.127570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of multi-class vessel segmentation on retinal images is the basis for the arteriovenous quantitative analysis, and plays an important role in the diagnosis and treatment of cerebrovascular diseases. Due to the intricate details and intertwining of the retinal vessels, traditional feature learning networks based on single-level resolution images are prone to the troubles from arteriovenous confusion and vascular edge discontinuity. To this end, we develop a paradigm of multi-level image resolution joint learning. This scheme overcomes the limitation of the methods depending on single-level image resolution on feature modeling. Specifically, we designed a cross-scale feature fusion network with a dual-branch structure that integrates global and local perspectives. This approach enables the extraction of retinal image features across multiple resolutions, effectively compensating for the vascular feature gaps inherent in single-resolution network models. This framework not only corrects the intra-segment misclassification, but also improves continuity by supplementing the details of vascular edge. Furthermore, the cross-scale fusion process of the network at multiple stages is conducive to its optimization and enhances the collaborative learning ability of dual-branch. Meanwhile, we use the generative adversarial structure as the backbone to supervise and constrain the aforementioned feature fusion results. Finally, extensive experiments are conducted on three publicly available datasets, DRIVE-AV, LES-AV, and HRF-AV. It is shown that the proposed scheme outperforms the current state-of-the-art methods significantly. The source code is available at https://github.com/Tang9867/Multi-Resolution-Learning .},
  archive      = {J_NEUCOM},
  author       = {Xiaofan Tang and Hao Chen and Xiangru Li and Sihua Yang},
  doi          = {10.1016/j.neucom.2024.127570},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127570},
  shortjournal = {Neurocomputing},
  title        = {The joint learning of multi-resolution feature for multi-class retinal vessel segmentation},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive temporal aggregation for table tennis shot
recognition. <em>NEUCOM</em>, <em>584</em>, 127567. (<a
href="https://doi.org/10.1016/j.neucom.2024.127567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action recognition is one of the challenging video understanding tasks in computer vision. Although there has been extensive research in the task of classifying coarse-grained actions, existing methods are still limited in differentiating actions with low inter-class and high intra-class variation. Particularly, the table tennis sport that involves shots of high inter-class similarity, subtle variations, occlusion, and view-point variations. While a few datasets have been available for event spotting and shot recognition, these benchmarks are mostly recorded in a constrained environment with a clear view/perception of shots executed by players. In this paper, we introduce a Table tennis shots 1.0 dataset consisting of 9000 videos of 6 fine-grained actions collected in an unconstrained manner to analyze the performance of both players. To effectively recognize these different types of table tennis shots, we propose an adaptive temporal aggregation method that can handle the temporal interactions concerning the subtle variations among shots and low inter-class variations. Our method consists of two components, namely, (i) feature extraction module and (ii) temporal aggregation network. The feature extraction module is a 3D convolutional neural network (3D-CNN) that captures the spatial and temporal characteristics of table tennis shots. Here we propose to replace the final global average pooling layer (GAP) with the temporal aggregation network to overcome the loss of motion information due to averaging of temporal features. This temporal aggregation network utilizes the attention mechanism of bidirectional encoder representations from Transformers (BERT) to model the significant temporal interactions among the shots effectively. We demonstrate that our proposed approach improves the performance of existing 3D-CNN methods by ≈ ≈ 10% on the Table tennis shots 1.0 dataset.},
  archive      = {J_NEUCOM},
  author       = {Sravani Yenduri and Vishnu Chalavadi and Krishna Mohan C.},
  doi          = {10.1016/j.neucom.2024.127567},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127567},
  shortjournal = {Neurocomputing},
  title        = {Adaptive temporal aggregation for table tennis shot recognition},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Enhancing pseudo label quality for pedestrian and cyclist
in weakly supervised 3D object detection. <em>NEUCOM</em>, <em>584</em>,
127531. (<a href="https://doi.org/10.1016/j.neucom.2024.127531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised 3D object detection for autonomous driving primarily focuses on cars because of their distinct rectangle boundaries and abundant instances. However, detecting categories with ambiguous rectangle boundaries and fewer instances than cars, such as pedestrians and cyclists, remains challenging with limited research. Ambiguity in rectangle boundaries presents significant difficulties in generating accurate 3D pseudo labels, while the scarcity of instances often leads to convergence issues during detector training. Pedestrians and cyclists are dense inside the 3D bounding boxes but sparse at corners and boundaries. Density is a practical clue for locating and discriminating pedestrians and cyclists in point clouds. This paper proposes a density-based 3D pseudo-label generation module (DPL-3D), addressing the challenges of ambiguous rectangle boundaries. Ambiguity rectangle boundaries will lead to poor pseudo-label quality. Therefore, By leveraging the density information of 3D points, our DPL-3D improves the accuracy and localization quality of the generated pseudo labels. It effectively segments background points, improving the estimation of pseudo labels’ location, dimension, and orientation. Few training samples always lead to local optima. Introducing multi-modal data in the detector network could enhance the constraints of objects’ features, but 2D images and 3D point clouds have a resolution gap. A motivation for dealing with the resolution gap is that neighboring regions with similar colors and textures in 2D images may exhibit spatial proximity in 3D space. Therefore, a multi-modal network driven by superpixel segmentation is introduced. This network enables effective discrimination between objects in 2D images and 3D point clouds, bridging the resolution gap and leveraging complementary features from both modalities. Experimental results on the KITTI dataset demonstrate the effectiveness of the proposed methods in addressing the challenges associated with weakly-supervised 3D object detection, particularly for categories with ambiguous rectangle boundaries and few instances.},
  archive      = {J_NEUCOM},
  author       = {Haizhuang Liu and Yilin Wang and Huazhen Chu and Bochao Zou and Jiansheng Chen and Huimin Ma},
  doi          = {10.1016/j.neucom.2024.127531},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127531},
  shortjournal = {Neurocomputing},
  title        = {Enhancing pseudo label quality for pedestrian and cyclist in weakly supervised 3D object detection},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guided evolutionary neural architecture search with
efficient performance estimation. <em>NEUCOM</em>, <em>584</em>, 127509.
(<a href="https://doi.org/10.1016/j.neucom.2024.127509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Architecture Search (NAS) methods have been successfully applied to image tasks with excellent results. However, NAS methods are often complex and tend to converge to local minima as soon as generated architectures yield good results. This paper proposes GEA, a novel approach for guided NAS. GEA guides the evolution by exploring the search space by generating and evaluating several architectures in each generation at initialization stage using a zero-proxy estimator, where only the highest-scoring architecture is trained and kept for the next generation. Subsequently, GEA continuously extracts knowledge about the search space without increased complexity by generating several off-springs from an existing architecture at each generation. Moreover, GEA forces exploitation of the most performant architectures by descendant generation while simultaneously driving exploration through parent mutation and favouring younger architectures to the detriment of older ones. Experimental results demonstrate the effectiveness of the proposed method, and extensive ablation studies evaluate the importance of different parameters. Results show that GEA achieves competitive results on all data sets of NAS-Bench-101, NAS-Bench-201 and TransNAS-Bench-101 benchmarks, as well as in the DARTS search space.},
  archive      = {J_NEUCOM},
  author       = {Vasco Lopes and Miguel Santos and Bruno Degardin and Luís A. Alexandre},
  doi          = {10.1016/j.neucom.2024.127509},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127509},
  shortjournal = {Neurocomputing},
  title        = {Guided evolutionary neural architecture search with efficient performance estimation},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Special issue on hybrid artificial intelligence systems from
HAIS 2022 conference. <em>NEUCOM</em>, <em>584</em>, 127465. (<a
href="https://doi.org/10.1016/j.neucom.2024.127465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The six papers included in this special issue represent a selection of extended contributions presented at the 17th International Conference on Hybrid Artificial Intelligent Systems, HAIS 2022 held in Salamanca, Spain, September 6th-8th, 2022, and organized by the BISITE group at the University of Salamanca. The International Conference on Hybrid Artificial Intelligence Systems (HAIS 2022) has become a unique, established, and broad interdisciplinary forum for researchers and practitioners who are involved in developing and applying symbolic and sub-symbolic techniques aimed at the construction of highly robust and reliable problem-solving techniques to present the most relevant achievements in this field. HAIS Series of Conferences provides an interesting opportunity to present and discuss the latest theoretical advances and real-world applications in this multidisciplinary research field.},
  archive      = {J_NEUCOM},
  author       = {H.éctor Quintián and Emilio Corchado},
  doi          = {10.1016/j.neucom.2024.127465},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127465},
  shortjournal = {Neurocomputing},
  title        = {Special issue on hybrid artificial intelligence systems from HAIS 2022 conference},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Special issue SOCO 2022: New trends in soft computing and
its application in industrial and environmental problems.
<em>NEUCOM</em>, <em>584</em>, 127412. (<a
href="https://doi.org/10.1016/j.neucom.2024.127412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The eight papers included in this special issue represent a selection of extended contributions presented at the 17th International Conference on Soft Computing Models in Industrial and Environmental Applications, SOCO 2022 held in Salamanca, Spain, September 6th-8th, 2022, and organized by the BISITE group at University of Salamanca. SOCO 2022 international conference represents a collection or set of computational techniques in machine learning, computer science and some engineering disciplines which investigate, simulate, and analyse very complex issues and phenomena. This special issue is aimed at practitioners, researchers, and postgraduate students who are engaged in developing and applying advanced intelligent systems principles to solve real-world problems in the mentioned fields.},
  archive      = {J_NEUCOM},
  author       = {Héctor Quintián and Emilio Corchado},
  doi          = {10.1016/j.neucom.2024.127412},
  journal      = {Neurocomputing},
  month        = {6},
  pages        = {127412},
  shortjournal = {Neurocomputing},
  title        = {Special issue SOCO 2022: New trends in soft computing and its application in industrial and environmental problems},
  volume       = {584},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel population robustness-based switching response
framework for solving dynamic multi-objective problems. <em>NEUCOM</em>,
<em>583</em>, 127601. (<a
href="https://doi.org/10.1016/j.neucom.2024.127601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel population robustness-based switching response framework (PR-SRF) is proposed to develop effective dynamic multi-objective optimization algorithm (DMOA), which integrates different response strategies to comprehensively cope with the dynamic behaviors. In particular, the population robustness is described by the quantification of how severely the environmental changes affect current population, which is timely graded as three levels of weak, strong, and normal to enable the adaptive switch of three different responses of diversity-enhancement, diversity-maintenance, and the knowledge-transfer, respectively. In this way, associations between the adopted responses and the changing environments are successfully established, thereby facilitating more intelligent decision when handling the dynamic behaviors. According to the benchmark evaluation results, the proposed PR-SRF-DMOA yields better comprehensive performance than several other DMOAs with popular response strategies, and it also outperforms another three DMOAs with hybrid responses, which demonstrates the great competitiveness of our algorithm. In addition, ablation study proves that the proposed PR-SRF can sufficiently exploit the merits of different responses, which effectively alleviates the negative knowledge transfer in extremely fluctuating environments, thereby providing valuable references for the development of evolutionary transfer optimization (ETO) algorithms.},
  archive      = {J_NEUCOM},
  author       = {Han Li and Zheng Fang and Liwei Hu and Haonan Liu and Peishu Wu and Nianyin Zeng},
  doi          = {10.1016/j.neucom.2024.127601},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127601},
  shortjournal = {Neurocomputing},
  title        = {A novel population robustness-based switching response framework for solving dynamic multi-objective problems},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Augmenting the diversity of imbalanced datasets via
multi-vector stochastic exploration oversampling. <em>NEUCOM</em>,
<em>583</em>, 127600. (<a
href="https://doi.org/10.1016/j.neucom.2024.127600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of class imbalance is prevalent in many real-world data sets, causing learning models to skew towards the majority class and resulting in biased performance. Data augmentation methods, such as the well-known Synthetic Minority Over-sampling Technique (SMOTE), are commonly employed to address class imbalance by generating synthetic samples. However, the generation mechanism of SMOTE is relatively constrained resulting in insufficient diversity in synthetic samples. To overcome this limitation, this paper expands the classical SMOTE and introduces a novel generalized version, namely Multi-vector Stochastic Exploration Oversampling (MSEO). It broadens the set of mapping synthetic samples, originally formed by the determined direction vectors and scaling vectors through the neighboring samples, to a collection obtained through mappings with random direction vectors and scaling vectors. This allows the generated samples to escape the original linear interpolation region, facilitating a more flexible exploration of the sample space. We extensively evaluated the method on various types of datasets, including artificially generated datasets, multi-class real-world datasets, and the engineering dataset. The results indicate that MSEO exhibits significant advantages in enhancing classification performance and promoting diversity in synthetic samples.},
  archive      = {J_NEUCOM},
  author       = {Hongrui Li and Shuangxin Wang and Jiading Jiang and Chuiyi Deng and Junmei Ou and Ziang Zhou and Dingli Yu},
  doi          = {10.1016/j.neucom.2024.127600},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127600},
  shortjournal = {Neurocomputing},
  title        = {Augmenting the diversity of imbalanced datasets via multi-vector stochastic exploration oversampling},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of methods for addressing the challenges of
referring image segmentation. <em>NEUCOM</em>, <em>583</em>, 127599. (<a
href="https://doi.org/10.1016/j.neucom.2024.127599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring image segmentation is guided by natural language descriptions to separate the target objects in an image. This task is different from semantic segmentation and instance segmentation in that it involves unique challenges such as multimodal information fusion, variability of natural language expressions, and model robustness. In recent years, the emergence of deep learning techniques has led to innovative ideas and methods for solving these problems. We systematically analyze the main challenges of referring image segmentation and summarize the existing solutions. These include strategies such as multimodal fusion, expression query, multimodal pre-training, and robustness. In addition, we provide an overview of several datasets commonly used in referring image segmentation and analyze the performance of various representative approaches in comparison to different datasets, visual backbone models and threshold settings. Our focus also extends to the challenges and future developments in the field of referring image segmentation. Our survey paper will provide a comprehensive technical reference for future researchers.},
  archive      = {J_NEUCOM},
  author       = {Lixia Ji and Yunlong Du and Yiping Dang and Wenzhao Gao and Han Zhang},
  doi          = {10.1016/j.neucom.2024.127599},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127599},
  shortjournal = {Neurocomputing},
  title        = {A survey of methods for addressing the challenges of referring image segmentation},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel fine-grained rumor detection algorithm with
attention mechanism. <em>NEUCOM</em>, <em>583</em>, 127595. (<a
href="https://doi.org/10.1016/j.neucom.2024.127595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rumors circulating on social media platforms have consistently represented a substantial threat to societal security and stability. Both academia and the industry have dedicated heightened focus to addressing the issue of rumor detection. Recent research has made significant progress in using deep neural networks to model the textual content and propagation structure of rumors. However, these methods model rumor-related features at a coarse-grained level and do not take full advantage of the various contextual information associated with rumors. In this paper, we propose a new model called Hybrid Rumor Detection Model with Co-Attention Mechanisms(CoAHRD), which utilizes the original tweet content, social context information, and user information for rumor detection. First, we use the Fine-Grained Feature Learning(FGFL) algorithm to extract fine-grained features from the tweets. Based on this, we use the Graph Convolutional Network(GCN) to learn the Multi-relation graph propagation structure features of rumors. Next, we combine FGFL features with temporal encoding information to model the temporal structure of rumors. Then, we introduce a User Feature-Based Co-Attention Network(UFCoAN) to learn the tendency of different users to spread rumors. Finally, we fuse the above features through a fully connected layer and perform rumor detection. Extensive experiments on two publicly available datasets, PHEME and TWITTER15, show that our method outperforms the current mainstream methods. In particular, in terms of accuracy, our model improves by 0.9% and 1.6% over the best baseline method on the Twitter15 and PHEME datasets, respectively.},
  archive      = {J_NEUCOM},
  author       = {Ke Zhang and Jianjun Cao and Dechang Pi},
  doi          = {10.1016/j.neucom.2024.127595},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127595},
  shortjournal = {Neurocomputing},
  title        = {A novel fine-grained rumor detection algorithm with attention mechanism},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). DHFNet: Decoupled hierarchical fusion network for RGB-t
dense prediction tasks. <em>NEUCOM</em>, <em>583</em>, 127594. (<a
href="https://doi.org/10.1016/j.neucom.2024.127594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of RGB and thermal data for dense prediction tasks has been demonstrated to be an effective and robust approach in autonomous driving. Nevertheless, the challenge lies in fusing features from different modalities, as a simple fusion strategy may lead to redundant or conflicting semantic information. In this paper, we delve into the hierarchical connections between multi-modal features and propose a novel fusion paradigm termed DHFNet, which decouples multi-modal features into similar global long-distance and discrepant local detail features for hierarchical feature fusion. At each fusion stage, a Lightweight Global Self-attention (LGSA) module is designed to decouple the global long-distance features with cheap computational complexity cost, and a Cross Modal Long-distance Feature Fusion (CMLFF) module is designed to eliminate redundant features by facilitating information interaction between different modalities. During the process of decoupling local detail features, a Cross Modal Deformable Convolution (CMDC) module is proposed to dynamically extract effective local features and capture misaligned features between different modalities. Finally, the fused global long-distance and local detail features are recoupled to achieve efficient hierarchical fusion. The results on RGB-T semantic segmentation and object detection tasks demonstrate the effectiveness of proposed method. The code will be available at: https://github.com/donggaomu/DHFNet .},
  archive      = {J_NEUCOM},
  author       = {Haojie Chen and Zhuo Wang and Hongde Qin and Xiaokai Mu},
  doi          = {10.1016/j.neucom.2024.127594},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127594},
  shortjournal = {Neurocomputing},
  title        = {DHFNet: Decoupled hierarchical fusion network for RGB-T dense prediction tasks},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). Finite-time/fixed-time distributed optimization for
nonlinear multi-agent systems with time-varying cost function.
<em>NEUCOM</em>, <em>583</em>, 127589. (<a
href="https://doi.org/10.1016/j.neucom.2024.127589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed optimization, combining cooperative control and optimization objectives, is vital for practical applications. While current research predominantly focuses on linear multi-agent systems, the real-world demands often involve nonlinear systems with finite or fixed time constraints. This paper addresses the finite-time/fixed-time distributed optimization for nonlinear multi-agent systems with time-varying cost function. Under appropriate assumptions, we propose a finite-time distributed protocol and a fixed-time distributed protocol for the nonlinear multi-agent systems to ensure all agents achieve consensus and minimize the time-varying cost function, relaxing the conditions for strong convexity and bounded gradient difference of the cost function. Simulation experiments validate the effectiveness of these distributed protocols.},
  archive      = {J_NEUCOM},
  author       = {Wan-ying Li and Xu-hui Wang and Nan-jing Huang},
  doi          = {10.1016/j.neucom.2024.127589},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127589},
  shortjournal = {Neurocomputing},
  title        = {Finite-time/fixed-time distributed optimization for nonlinear multi-agent systems with time-varying cost function},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mask guided two-stream network for end-to-end few-shot
action recognition. <em>NEUCOM</em>, <em>583</em>, 127582. (<a
href="https://doi.org/10.1016/j.neucom.2024.127582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For few-shot video action recognition, it is essential to extract and align features from different videos. However, these operations can be complicated and unreliable due to the complexity of the video scene and the limitations of existing alignment algorithms. To enhance the saliency of the action-related features, we introduce segmentation mask frame sequences as prior information and devise a two-stream feature fusion module to fuse the multimodal features. Furthermore, we propose a self-attention-based temporal alignment module to predict the optimal alignment matrix between the features of samples in the query and support sets. This module avoids solving additional optimization problems in computing the alignment matrix, thus reducing the difficulty of the model for end-to-end learning. Our approach achieves competitive performance on four public datasets. We also experimentally validate the effectiveness of the proposed modules.},
  archive      = {J_NEUCOM},
  author       = {Zhiwei Xie and Yanxiang Gong and Jiangfei Ji and Zheng Ma and Mei Xie},
  doi          = {10.1016/j.neucom.2024.127582},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127582},
  shortjournal = {Neurocomputing},
  title        = {Mask guided two-stream network for end-to-end few-shot action recognition},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anchor graph-based multiview spectral clustering.
<em>NEUCOM</em>, <em>583</em>, 127579. (<a
href="https://doi.org/10.1016/j.neucom.2024.127579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant advances in graph-oriented clustering methods can be attributed to their effectiveness in leveraging relationships and complex structures within multiview data. However, several limitations persist in most existing graph-based multiview clustering approaches. First, quadratic or cubic complexity is required for graph construction or eigendecomposition of the Laplacian matrix in many existing methods. Second, certain methods overlook the differences between views and employ an identical indicator matrix, which can lead to over-learning in practical scenarios. Third, existing methods often neglect spatial structure and complementary information, focusing primarily on calculating error feature-by-feature using different norms. In order to tackle these drawbacks, we propose a new multiview spectral clustering model called A nchor G raph-based M ultiview S pectral C lustering(AG-MSC). AG-MSC incorporates an adaptive weighting mechanism that assigns weights to each view, enhancing the robustness of the algorithm. Using a tensor Schatten p p -norm constraint minimizes the discrepancy between indicator matrices obtained from different views, thereby preserving high-order information and spatial structure. To improve computational efficiency, we replace the full adjacency matrices of the corresponding views with anchor graphs. AG-MSC offers a distinct advantage over conventional spectral clustering by directly obtaining all sample categories without additional post-processing steps. We have validated the efficiency of our method through extensive experimental evaluations.},
  archive      = {J_NEUCOM},
  author       = {Yu Lei and Zuoyuan Niu and Qianqian Wang and Quanxue Gao and Ming Yang},
  doi          = {10.1016/j.neucom.2024.127579},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127579},
  shortjournal = {Neurocomputing},
  title        = {Anchor graph-based multiview spectral clustering},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Where to model the epistemic uncertainty of bayesian
convolutional neural networks for classification. <em>NEUCOM</em>,
<em>583</em>, 127568. (<a
href="https://doi.org/10.1016/j.neucom.2024.127568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling the epistemic uncertainty, Bayesian convolutional neural networks (Bayesian-CNNs) place a probability distribution on the kernel of convolutional neural networks (CNNs) to overcome problems of over-fitting and incapability of quantifying the prediction confidence. However, compared with CNNs with point estimates, Bayesian-CNNs have a limited improvement over classification performance. Some experiments show that the closer to the input layer, the larger the variances of the parameters in those layers of Bayesian-CNNs, which means the parameters of the low-level layers are not well-trained. Therefore, it is possibly inappropriate to model the epistemic uncertainty of the parameters in the layers close to the input. In this paper, the question of “where to model the epistemic uncertainty of Bayesian-CNNs” is studied by analyzing the performances by putting randomness over different convolutional groups. For this unique structure by combining certain and uncertain layers, a novel objective function is proposed which consists of KL loss for the uncertain parameters and cross-entropy loss for certain parameters. For the special objective function, a training scheme that updates these two kinds of parameters alternately is proposed. Partial-Bayesian-CNNs (P-Bayesian-CNNs) that model the epistemic uncertainty over the parameters of the last convolutional group are recommended because they bring the highest classification accuracy gain according to the experimental analysis. Compared to the traditional Bayesian-CNNs, P-Bayesian-CNNs increase the accuracy by 3.8% and 3.7% on CIFAR-10 and RAF-DB respectively. Besides, the experimental results by taking Res2Net and Xception as backbones also show performance improvement, which verifies the scalability of the P-Bayesian-CNNs.},
  archive      = {J_NEUCOM},
  author       = {Yuan Tai and Yihua Tan and Erbo Zou and Bo Lei and Qiang Fan and Yizhou He},
  doi          = {10.1016/j.neucom.2024.127568},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127568},
  shortjournal = {Neurocomputing},
  title        = {Where to model the epistemic uncertainty of bayesian convolutional neural networks for classification},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Granting leaders priority exit options promotes and
jeopardizes cooperation in social dilemmas. <em>NEUCOM</em>,
<em>583</em>, 127566. (<a
href="https://doi.org/10.1016/j.neucom.2024.127566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperation in human interactions often involves voluntary participation rather than obligatory requirements. This paper investigates the impact of voluntary exit strategies on cooperation within scale-free networks, employing spatial prisoner’s dilemma games as the framework. We analyze three distinct exit strategies: leader priority exit, fringe priority exit, and random exit, across varying dilemma strengths. Our findings reveal that in scenarios of weak dilemma strength, leader priority exit significantly diminishes cooperation, particularly when only a small subset of players is granted exit rights. In contrast, under strong dilemma strength conditions, both leader priority and random exits serve to unexpectedly bolster cooperation. This enhancement is primarily facilitated by high-degree nodes opting out, thereby enabling low-degree nodes to establish stable cooperation. Furthermore, our study underscores the pivotal role of network structure. In assortative networks, random exit emerges as the most effective strategy in promoting cooperation. On the other hand, disassortative networks exhibit a substantial increase in cooperation levels when employing leader priority exit. These results highlight the intricate interplay between exit strategies, dilemma strength, and network topology, offering critical insights for promoting cooperation in varied social contexts.},
  archive      = {J_NEUCOM},
  author       = {Shulan Li and Zhixue He and Danyang Jia and Chen Shen and Lei Shi and Jun Tanimoto},
  doi          = {10.1016/j.neucom.2024.127566},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127566},
  shortjournal = {Neurocomputing},
  title        = {Granting leaders priority exit options promotes and jeopardizes cooperation in social dilemmas},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integration of short and long-term interests: A preference
aware session-based recommender. <em>NEUCOM</em>, <em>583</em>, 127558.
(<a href="https://doi.org/10.1016/j.neucom.2024.127558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommenders have gathered tremendous e-commerce and media streaming applications where the task is to predict the next item user would consume based on the session history. In this arena, advancements have been accomplished using deep learning techniques to model users’ long-term and short-term preferences in a session. The long-term module focuses on the entire item set in a session, while the short-term emphasizes a fixed set of items just before making a choice. While users’ short-term preferences in general reflect their immediate actions or intentions, consideration of such preferences, specifically with a fixed item set, makes the prediction task increasingly challenging. In this work, we attempt to capture the short-term behavior of users considering a dynamic window which self-tunes depending on the category of the last few items. A novel gating network that leverages the different drivers such as price, rating, dwell time, etc. and the latent representation of the items and their categories is introduced. The efficacy of our proposed method G ated S ession-based R ecommender integrating S hort and L ong-term preferences (GSRSL) has been evaluated against eight recent baselines on four publicly available real-world datasets, Tmall, Diginetica, and Cosmetics. Our findings demonstrate a significant improvement in MRR, Hit, and NDCG of up to 13.62%, 11.46%, and 13.00%, respectively, across all the datasets.},
  archive      = {J_NEUCOM},
  author       = {Sanjay K. and Nargis Pervin},
  doi          = {10.1016/j.neucom.2024.127558},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127558},
  shortjournal = {Neurocomputing},
  title        = {Integration of short and long-term interests: A preference aware session-based recommender},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mlscorecheck: Testing the consistency of reported
performance scores and experiments in machine learning. <em>NEUCOM</em>,
<em>583</em>, 127556. (<a
href="https://doi.org/10.1016/j.neucom.2024.127556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing the reproducibility crisis in artificial intelligence through the validation of reported experimental results is a challenging task. It necessitates either the reimplementation of techniques or a meticulous assessment of papers for deviations from the scientific method and best statistical practices. To facilitate the validation of reported results, we have developed numerical techniques capable of identifying inconsistencies between reported performance scores and various experimental setups in machine learning problems, including binary/multiclass classification and regression. These consistency tests are integrated into the open-source package mlscorecheck , which also provides specific test bundles designed to detect systematically recurring flaws in various fields, such as retina image processing and synthetic minority oversampling.},
  archive      = {J_NEUCOM},
  author       = {György Kovács and Attila Fazekas},
  doi          = {10.1016/j.neucom.2024.127556},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127556},
  shortjournal = {Neurocomputing},
  title        = {Mlscorecheck: Testing the consistency of reported performance scores and experiments in machine learning},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Practical consensus tracking control for networked
euler–lagrange systems based on UDE integrated with RBF neural network.
<em>NEUCOM</em>, <em>583</em>, 127554. (<a
href="https://doi.org/10.1016/j.neucom.2024.127554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper solves the practical consensus tracking control problem for networked Euler–Lagrange (EL) systems using the uncertainty and disturbance estimator (UDE) in combination with the radial basis function (RBF) neural network. An integrated consensus algorithm is proposed for the networked EL systems, where the RBF neural network is first utilized to generate online estimation of the uncertain EL dynamics for enhancing the system adaptability, and then the UDE is applied to compensate external disturbances dynamically for improving the system robustness. Furthermore, a unified analysis framework for the closed-loop control system is established through performing the proper filter design and Lyapunov-like analysis. The proposed consensus tracking algorithm possesses a simple system structure for implementation and has a good robust performance in dealing with both uncertainties and disturbances. Numerical simulations are used to verify the effectiveness of the developed integrated consensus scheme.},
  archive      = {J_NEUCOM},
  author       = {Runlong Peng and Rongwei Guo and Lixia Liu and Jinchen Ji and Zhonghua Miao and Jin Zhou},
  doi          = {10.1016/j.neucom.2024.127554},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127554},
  shortjournal = {Neurocomputing},
  title        = {Practical consensus tracking control for networked Euler–Lagrange systems based on UDE integrated with RBF neural network},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing class-incremental object detection in remote
sensing through instance-aware distillation. <em>NEUCOM</em>,
<em>583</em>, 127552. (<a
href="https://doi.org/10.1016/j.neucom.2024.127552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection plays a important role within the field of remote sensing, boasting significant applications including intelligent monitoring and urban planning. However, traditional models are constrained by predefined classes and encounter a challenge known as catastrophic forgetting when attempting to learn new classes post-deployment. To address this problem, we propose a novel Instance-aware Distillation approach for Class-incremental Object Detection (IDCOD). Our approach capitalizes on the teacher model, a model from a previous stage, to serve as a guide during the training of the new model on novel data. This methodology facilitates the gradual acquisition of knowledge about new classes while simultaneously preserving the performance achieved on previously learned classes. Instance-aware distillation with masks of old and new classes aims to reduce forgetting and impact on new classes. Furthermore, we design a pseudo-label module to expand old class training data. Experiments on the challenging DOTA dataset, DIOR dataset, RTDOD dataset and PASCAL VOC dataset show that our method effectively detects old classes, incrementally detects new classes, and mitigates catastrophic forgetting.},
  archive      = {J_NEUCOM},
  author       = {Hangtao Feng and Lu Zhang and Xu Yang and Zhiyong Liu},
  doi          = {10.1016/j.neucom.2024.127552},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127552},
  shortjournal = {Neurocomputing},
  title        = {Enhancing class-incremental object detection in remote sensing through instance-aware distillation},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Brain magnetic resonance images segmentation via improved
mixtures of factor analyzers based on dynamic co-clustering.
<em>NEUCOM</em>, <em>583</em>, 127551. (<a
href="https://doi.org/10.1016/j.neucom.2024.127551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main goal of this paper is to attain accurate and automatic detection of brain tumors in gray magnetic resonance images using reducing the local dimensions. We propose a novel model called Improved Mixtures of Factor Analyzers based on Dynamic Co-Clustering (IMFADCC) for the detection and localization of brain tumors. After image preprocessing and enhancement, the optimal numbers of row clusters and column clusters corresponding to each row cluster, alongside other model parameters, are determined concurrently based on the size of the tumor by our model. Then, using the optimal values obtained, the image is co-clustered by simultaneously clustering rows and columns until the block containing the tumor is identified. The output image is divided into a certain number of blocks, one of which contains the tumor. For post-processing, the identified block is binarized using minimum error thresholding. The proposed model accurately detects and locates the block binarized within the original image while considering the remainder of the image as background. The effectiveness of the proposed method was assessed by evaluating its accuracy, Dice, intersection on union, geometric mean, receiver operating characteristic curve, specificity, and sensitivity criteria on the BraTS2018, BraTS2019, and BraTS2020 datasets. The results show that our method has significant performance and is highly accurate in detecting tumors of different sizes in complex and high-size images. Moreover, our method outperforms the existing diagnostic methods.},
  archive      = {J_NEUCOM},
  author       = {Rahman Farnoosh and Fatemeh Aghagoli},
  doi          = {10.1016/j.neucom.2024.127551},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127551},
  shortjournal = {Neurocomputing},
  title        = {Brain magnetic resonance images segmentation via improved mixtures of factor analyzers based on dynamic co-clustering},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SSRI-net: Subthreads stance–rumor interaction network for
rumor verification. <em>NEUCOM</em>, <em>583</em>, 127549. (<a
href="https://doi.org/10.1016/j.neucom.2024.127549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As online rumors have the potential to greatly affect areas such as social order, stock prices, and presidential elections, there is an emerging necessity for the automation of rumor verification. Although the current methods have achieved satisfactory performance, they still suffer from the following problems. First, the current methods simply concatenate the representations of different subthreads in their models, which may result in omitting some important information. Second, although stance information has been considered for the rumor verification task, it has not been fully utilized. To solve the problems, we propose the Subthreads Stance–Rumor Interaction Network (SSRI-Net) model for rumor verification. The proposed SSRI-Net model first introduces the Subthreads Interaction Attention mechanism between different subthreads to capture the interaction information between subthreads for a better understanding on user posts. Moreover, we also design the Stance–Rumor Interaction Network to fully integrate users’ stance information with rumor verification. We have conducted experiments on two public datasets, namely SemEval-2017 and PHEME datasets, for performance evaluation. Our SSRI-Net model outperforms the previous best models by 5.8% and 7.1% in Macro-F1 and Accuracy respectively on the SemEval-2017 dataset. In addition, our SSRI-Net model also outperforms the previous best models by 4.7% and 5.4% in Macro-F1 and Accuracy respectively on the PHEME dataset. The experimental results have shown that our proposed SSRI-Net model has outperformed the baseline models and achieved the state-of-the-art performance for rumor verification.},
  archive      = {J_NEUCOM},
  author       = {Zhendong Chen and Siu Cheung Hui and Lejian Liao and Heyan Huang},
  doi          = {10.1016/j.neucom.2024.127549},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127549},
  shortjournal = {Neurocomputing},
  title        = {SSRI-net: Subthreads Stance–Rumor interaction network for rumor verification},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fully distributed synchronization on directed graphs via
self-triggered control with positive minimum inter-event times.
<em>NEUCOM</em>, <em>583</em>, 127548. (<a
href="https://doi.org/10.1016/j.neucom.2024.127548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fully distributed synchronization problem is studied for heterogeneous linear multi-agent systems (MASs) on a directed graph by observer-based adaptive self-triggered control schemes guaranteed positive minimum inter-event times (MIETs). An improved adaptive observer used to estimate the leader state under composite triggering mechanisms is proposed to achieve the combination of event-triggered communication and control, which can be implemented in a self-triggered fashion. A positive auxiliary function serves as the triggered condition for updating the control protocol of the observer, and the feature of this design is that inter-event times have a positive lower bound. No global information related to the communication graph is required throughout the designed paradigm. By augmenting the observer and follower dynamics, optimality is imposed for a network of augmented systems in designing the control protocol to achieve synchronization among agents. Finally, the availability of the proposed theoretical results is demonstrated by a group of two-mass–spring systems.},
  archive      = {J_NEUCOM},
  author       = {Lina Xia and Qing Li and Ruizhuo Song and Lu Liu},
  doi          = {10.1016/j.neucom.2024.127548},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127548},
  shortjournal = {Neurocomputing},
  title        = {Fully distributed synchronization on directed graphs via self-triggered control with positive minimum inter-event times},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FDNet: Imperceptible backdoor attacks via frequency domain
steganography and negative sampling. <em>NEUCOM</em>, <em>583</em>,
127546. (<a href="https://doi.org/10.1016/j.neucom.2024.127546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backdoor attacks against Deep Neural Networks (DNNs) have surfaced as a substantial and concerning security challenge. These backdoor vulnerabilities in DNNs can be introduced by third-party sources through maliciously manipulated training data. Existing backdoor attacks are primarily built on perturbation trigger patterns in the spatial domain, which makes practical deployment arduous due to the ease of detection by inspectors. Moreover, shortcut learning renders the backdoor network less robust against defense methods. This work advances an effective and adaptable approach to backdoor attacks, situated in the frequency domain. This methodology involves the incorporation of specific natural perturbations within the frequency domain of images. Remarkably, these introduced triggers yield minimal alterations in the image’s semantic content, rendering them nearly imperceptible to human observers. To evade detection by machine-based defenders, we introduce a new training paradigm that incorporates negative sampling techniques. This approach compels the neural network to learn richer differences as trigger patterns. We evaluate our attacks on popular convolutional neural networks, visual transformers, and MLP-Mixer models as well as four standard datasets including MNIST, CIFAR-10, GTSRB, and ImageNet. Experimental results demonstrate that the trained networks can be successfully injected with backdoors. Our attack methods exhibit remarkable efficacy, achieving high attack success rates in both All-to-one (near 100% on all datasets) and All-to-all (over 90% except on ImageNet) scenarios and also demonstrate robustness against contemporary state-of-the-art defense mechanisms. Furthermore, our work reveals that DNNs can capture discrepancies in the frequency components of images that are barely perceptible to humans.},
  archive      = {J_NEUCOM},
  author       = {Liang Dong and Zhongwang Fu and Leiyang Chen and Hongwei Ding and Chengliang Zheng and Xiaohui Cui and Zhidong Shen},
  doi          = {10.1016/j.neucom.2024.127546},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127546},
  shortjournal = {Neurocomputing},
  title        = {FDNet: Imperceptible backdoor attacks via frequency domain steganography and negative sampling},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DAP: A dataset-agnostic predictor of neural network
performance. <em>NEUCOM</em>, <em>583</em>, 127544. (<a
href="https://doi.org/10.1016/j.neucom.2024.127544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training a deep neural network on a large dataset to convergence is a time-demanding task. This task often must be repeated many times, especially when developing a new deep learning algorithm or performing a neural architecture search. This problem can be mitigated if a deep neural network’s performance can be estimated without actually training it. In this work, we investigate the feasibility of two tasks: (i) predicting a deep neural network’s performance accurately given only its architectural descriptor, and (ii) generalizing the predictor across different datasets without re-training. To this end, we propose a dataset-agnostic regression framework that uses a novel dual-LSTM model and a new dataset difficulty feature. The experimental results show that both tasks above are indeed feasible, and the proposed method outperforms the existing techniques in all experimental cases. Additionally, we also demonstrate several practical use-cases of the proposed predictor.},
  archive      = {J_NEUCOM},
  author       = {Sui Paul Ang and Soan T.M. Duong and Son Lam Phung and Abdesselam Bouzerdoum},
  doi          = {10.1016/j.neucom.2024.127544},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127544},
  shortjournal = {Neurocomputing},
  title        = {DAP: A dataset-agnostic predictor of neural network performance},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024e). Cross-modal concept learning and inference for
vision-language models. <em>NEUCOM</em>, <em>583</em>, 127530. (<a
href="https://doi.org/10.1016/j.neucom.2024.127530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale pre-trained Vision-Language Models (VLMs), such as CLIP, establish the correlation between texts and images, achieving remarkable success on various downstream tasks with fine-tuning. In existing fine-tuning methods, the class-specific text description is matched against the whole image. We recognize that this image-scale matching is not effective since images from the same class often contain a set of different semantic objects, and an object further consists of a set of semantic parts or concepts. Individual semantic parts or concepts may appear in image samples from different classes. To address this issue, in this paper, we develop a new method called cross-model concept learning and inference (CCLI). Using the powerful text-image correlation capability of CLIP, our method automatically learns a large set of distinctive visual concepts from images using a set of semantic text concepts. Based on these visual concepts, we construct a discriminative representation of images and learn a concept inference network to perform downstream image classification tasks, such as few-shot learning and domain generalization. Extensive experimental results demonstrate that our CCLI method is able to improve the performance of the current state-of-the-art methods by large margins, for example, by up to 8.0% improvement on few-shot learning and by up to 1.3% for domain generalization.},
  archive      = {J_NEUCOM},
  author       = {Yi Zhang and Ce Zhang and Yushun Tang and Zhihai He},
  doi          = {10.1016/j.neucom.2024.127530},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127530},
  shortjournal = {Neurocomputing},
  title        = {Cross-modal concept learning and inference for vision-language models},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparing multi-class classifier performance by multi-class
ROC analysis: A nonparametric approach. <em>NEUCOM</em>, <em>583</em>,
127520. (<a href="https://doi.org/10.1016/j.neucom.2024.127520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The area under the Receiver Operating Characteristic (ROC) curve (AUC) is a standard metric for quantifying and comparing binary classifiers. Real world applications often require classification into multiple (more than two) classes. For multi-class classifiers that produce class membership scores, a popular multi-class AUC (MAUC) variant is to average the pairwise AUC values (Hand and Till, 2001). Due to the complicated correlation patterns, the variance of MAUC is often estimated numerically using resampling techniques. This work is a generalization of DeLong’s nonparameteric approach for binary AUC analysis (DeLong et al., 1988) to MAUC. We first derive the closed-form expression of the covariance matrix of the pairwise AUCs within a single MAUC. Then by dropping higher order terms, we obtain an approximate covariance matrix with a compact, matrix factorization form, which then serves as the basis for variance estimation of a single MAUC. We further extend this approach to estimate the covariance of correlated MAUCs that arise from multiple competing classifiers. For the special case of binary correlated AUCs, our results coincide with that of DeLong. Our numerical studies confirm the accuracy of the variance and covariance estimates. We provide the source code of the proposed covariance estimation of correlated MAUCs on GitHub ( https://tinyurl.com/euj6wvsz ) for its easy adoption by machine learning and statistical analysis packages to quantify and compare multi-class classifiers.},
  archive      = {J_NEUCOM},
  author       = {Jingyan Xu},
  doi          = {10.1016/j.neucom.2024.127520},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127520},
  shortjournal = {Neurocomputing},
  title        = {Comparing multi-class classifier performance by multi-class ROC analysis: A nonparametric approach},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Multi-perspective analysis on data augmentation in
knowledge distillation. <em>NEUCOM</em>, <em>583</em>, 127516. (<a
href="https://doi.org/10.1016/j.neucom.2024.127516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation stands as a capable technique for transferring knowledge from a larger to a smaller model, thereby notably enhancing the smaller model’s performance. In the recent past, data augmentation has been employed in contrastive learning based knowledge distillation techniques yielding superior results. Despite the significant role of data augmentation, its value remains underappreciated within the domain of knowledge distillation, with no in-depth analysis in the literature thus far. To make up for this oversight, we conduct a multi-perspective theoretical and experimental analysis on the role that data augmentation can play in knowledge distillation. We summarize the properties of data augmentation and list the core findings as follows. (a) Our investigations validate that data augmentation significantly boosts the performance of knowledge distillation on the tasks of image classification and object detection. And this holds true even if the teacher model lacks comprehensive information about the augmented samples. Moreover, our novel J oint D ata A ugmentation (JDA) approach outperforms single data augmentation in knowledge distillation. (b) The pivotal role of data augmentation in knowledge distillation can be theoretically explained via Sharpness-Aware Minimization. (c) The compatibility of data augmentation with various knowledge distillation methods can enhance their performance. In light of these observations, we propose a new method called C osine C onfidence D istillation (CCD) for more reasonable knowledge transfer from augmented samples. Experimental results not only demonstrate that CCD becomes the state-of-the-art method with less storage requirement on CIFAR-100 and ImageNet-1k, but also validate the superiority of CCD over DIST on the object detection benchmark dataset, MS-COCO.},
  archive      = {J_NEUCOM},
  author       = {Wei Li and Shitong Shao and Ziming Qiu and Aiguo Song},
  doi          = {10.1016/j.neucom.2024.127516},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127516},
  shortjournal = {Neurocomputing},
  title        = {Multi-perspective analysis on data augmentation in knowledge distillation},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synchronization for neural networks over event-triggered
multi-channel: Relay channels under cyber-attacks. <em>NEUCOM</em>,
<em>583</em>, 127503. (<a
href="https://doi.org/10.1016/j.neucom.2024.127503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses synchronization for master–slave neural networks (MSNNs) with remote transmission. To reduce the communication frequency, an event-triggered strategy combined with a dynamically adjusted threshold is employed. For the sake of enhancing the information transmission quality, a relay channels protocol that considers cyber-attacks is established, acknowledging that occurrence rates of cyber-attacks may vary across different channels. Furthermore, regarding the limited capacity of channels, the current research considers a multi-channel transmission mechanism, where the transmission arrangement for each channel relies on the occurrence rates of denial-of-service (DoS) attacks. A sufficient condition is then proposed to guarantee the synchronization of MSNNs. Finally, an example is adopted to substantiate the efficiency of the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Yumei Zhou and Xiantao Luo and Zijing Xiao and Jian Huang and Hongxia Rao and Yao Zhao},
  doi          = {10.1016/j.neucom.2024.127503},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127503},
  shortjournal = {Neurocomputing},
  title        = {Synchronization for neural networks over event-triggered multi-channel: Relay channels under cyber-attacks},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Coupled image and kernel prior learning for high-generalized
super-resolution. <em>NEUCOM</em>, <em>583</em>, 127500. (<a
href="https://doi.org/10.1016/j.neucom.2024.127500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolution neural networks (DCNNs) have demonstrated great success on single image super resolution, where most existing methods aim to construct a deep model in an fully-supervised way using large amount of synthetic image pairs under ideal degradation assumption. The super-resolution performance would be significantly degraded for the low-resolution images captured under uncontrolled imaging conditions with complicated degradation procedures. To handle the above limitations, this work proposes a high-generalized image super-resolution framework by synergistically learning the latent image and the degradation process to achieve the specific priors for an under-studying observation in an unsupervised manner. Specifically, we incorporate dual branches of networks to configure our framework, where one is structured with both convolution and transformer blocks to learn local-to-global prior to generate high-quality image while the other aims to learn the kernel prior with a simple convolution-based architecture. The kernel prior subnet is pre-trained to enhance the stability of the joint optimization for the overall unsupervised learning procedure. With the estimated degradation kernel and target image, we produce the approximated low-resolution version with a convolution-based degradation block to formulate the loss function for the specific learning. Moreover, to pursue visually plausible image generation, we further incorporate a perceptual loss by leveraging a pre-trained discriminator in Gan-based SR model. Extensive experiments on several benchmark datasets have demonstrated the effectiveness of our proposed high-generalized super-resolution model, manifesting superiority over both supervised and unsupervised state-of-the-art SR models.},
  archive      = {J_NEUCOM},
  author       = {Xian-Hua Han and Kazuhiro Yamawaki and Huiyan Jiang},
  doi          = {10.1016/j.neucom.2024.127500},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127500},
  shortjournal = {Neurocomputing},
  title        = {Coupled image and kernel prior learning for high-generalized super-resolution},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Independent dual graph attention convolutional network for
skeleton-based action recognition. <em>NEUCOM</em>, <em>583</em>,
127496. (<a href="https://doi.org/10.1016/j.neucom.2024.127496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) have been widely adopted in skeleton-based action recognition, achieving impressive outcomes. However, the convolution operations in GCNs fail to make full use of the original input data, which restricts its ability to accurately capture the correlation within the skeleton. To solve this issue, this study introduces an independent dual graph attention convolutional network (IDGAN). Specifically, IDGAN additionally incorporates an instinctive attention module that leverages self-attention to capture the correlation among the joints in the original input skeleton. In addition, two independent convolutional operations are used to process two self-attention modules, respectively, to further refine the relationship between skeleton joints. Extensive experiments on several publicly available datasets show that IDGAN outperforms most state-of-the-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Jinze Huo and Haibin Cai and Qinggang Meng},
  doi          = {10.1016/j.neucom.2024.127496},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127496},
  shortjournal = {Neurocomputing},
  title        = {Independent dual graph attention convolutional network for skeleton-based action recognition},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Coordinate-aware mask r-CNN with group normalization: A
underwater marine animal instance segmentation framework.
<em>NEUCOM</em>, <em>583</em>, 127488. (<a
href="https://doi.org/10.1016/j.neucom.2024.127488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsustainable fishing, driven by bycatch and discards, harms marine ecosystems. Addressing this, we propose a Coordinate-Aware Mask R-CNN (CAM-RCNN) method to enhance fish detection in commercial trawls. Leveraging CoordConv and Group Normalization, our approach improves generalisation and stability. To tackle class imbalance, a compound Dice and cross-entropy loss is employed, and image data are enhanced through multi-scale retinex and colour restoration. Evaluating on two fishing datasets, CAM-RCNN excels in accuracy and generalisation, achieving the best Average Precision (AP) for instance mask and BBOX prediction in both source (39.7%, 40.2%) and target domains (24.4%, 24.2%). This method promotes sustainable fishing by selectively capturing desired fish, reducing harm to non-target species.},
  archive      = {J_NEUCOM},
  author       = {Dewei Yi and Hasan Bayarov Ahmedov and Shouyong Jiang and Yiren Li and Sean Joseph Flinn and Paul G. Fernandes},
  doi          = {10.1016/j.neucom.2024.127488},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127488},
  shortjournal = {Neurocomputing},
  title        = {Coordinate-aware mask R-CNN with group normalization: A underwater marine animal instance segmentation framework},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BEV feature exchange pyramid networks-based 3D object
detection in small and distant situations: A decentralized federated
learning framework. <em>NEUCOM</em>, <em>583</em>, 127476. (<a
href="https://doi.org/10.1016/j.neucom.2024.127476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D object detection, whose task is to perceive the surrounding environment, plays a significant role in autonomous driving. In this study, we propose a new BEV-FePNet 3D detection model, which can effectively fuse multi-modal information in deeply abstract features. The BEV-FePNet has been validated experimentally on the nuScenes dataset, and the findings demonstrate that the proposed approach enhances the performance of the detector and obtains 71.6 % mAP detection performance. In addition, with the rapid development of the autonomous driving market, collecting a large amount of data for autonomous driving has become one of the important means to enhance 3D detecting models’ efficiency. However, local national data security policies have to be considered when autonomous driving manufacturers collect data in different countries, so it is difficult to transmit data abroad. To solve this problem, the DP-DeceFL framework has been proposed in this paper that utilizes differential privacy processing to enable information exchange between different countries without revealing sensitive information. Through the verification of nuScenes data, our proposed framework is superior to some selected federated learning frameworks.},
  archive      = {J_NEUCOM},
  author       = {Rukai Lan and Yong Zhang and Linbo Xie and Zhaolong Wu and Yifan Liu},
  doi          = {10.1016/j.neucom.2024.127476},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127476},
  shortjournal = {Neurocomputing},
  title        = {BEV feature exchange pyramid networks-based 3D object detection in small and distant situations: A decentralized federated learning framework},
  volume       = {583},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Structure-guided feature and cluster contrastive learning
for multi-view clustering. <em>NEUCOM</em>, <em>582</em>, 127555. (<a
href="https://doi.org/10.1016/j.neucom.2024.127555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering (MVC) technology performs unsupervised clustering on data collected from multiple sources, and has received intense attention in recent years. However, most existing MVC methods fail to consider retaining view-specific information when learning multi-view consistent representations. Besides, the feature and cluster structures of multi-view data cannot be fully leveraged in clustering. In this paper, we propose a structure-guided feature and cluster contrastive learning (SGFCC) for multi-view clustering. Specifically, SGFCC utilizes autoencoders to achieve view-specific information reconstruction in feature space, and extracts high-level features for multi-view consistent representation learning to eliminate the effects of view-specific information and noise on consistent representation. To fully capture the similar clustering structure of high-level features and semantic features of samples across different views, we adopt a structure-guided feature-level and cluster-level contrastive learning strategy in our SGFCC model. Furthermore, we design a clustering layer to explore the cluster structure of high-level features. Different from most existing MVC methods, our method applies a non-fusion scheme that aggregates the semantic information of all views to obtain the final semantic labels. Extensive experiments on public datasets demonstrate that our method outperforms other competitors in clustering tasks.},
  archive      = {J_NEUCOM},
  author       = {Zhenqiu Shu and Bin Li and Cunli Mao and Shengxiang Gao and Zhengtao Yu},
  doi          = {10.1016/j.neucom.2024.127555},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127555},
  shortjournal = {Neurocomputing},
  title        = {Structure-guided feature and cluster contrastive learning for multi-view clustering},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view 3D reconstruction based on deep learning: A
survey and comparison of methods. <em>NEUCOM</em>, <em>582</em>, 127553.
(<a href="https://doi.org/10.1016/j.neucom.2024.127553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important objective in computer vision is to analyze multiple images and subsequently reconstruct the shape and structure in 3D. Traditional multi-view 3D reconstruction techniques extract and match key features from images with known camera parameters. However, this approach is inefficient and fails to fully exploit the advantages of multi-view information. Advancements in deep learning have revolutionized multi-view 3D reconstruction by enabling end-to-end 3D shape inferencing without the need for sequential feature matching typically found in conventional algorithms. Recent rapid progress in this field necessitates a thorough review of current algorithms and provide insight into method of improving 3D reconstruction performance. This review classifies reconstruction algorithms according to their resultant model, including depth map, voxel, point cloud, mesh, and implicit surface. Additionally, this review encompasses the inclusion of frequently employed network training loss functions for network training, assessment metrics, and the incorporation of 3D datasets. Experimental results are also presented to assess the performance of different algorithms. Finally, the paper concludes with a summary, discussion of challenges, and potential future directions.},
  archive      = {J_NEUCOM},
  author       = {Juhao Wu and Omar Wyman and Yadong Tang and Damiano Pasini and Wenlong Wang},
  doi          = {10.1016/j.neucom.2024.127553},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127553},
  shortjournal = {Neurocomputing},
  title        = {Multi-view 3D reconstruction based on deep learning: A survey and comparison of methods},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Survey of continuous deep learning methods and techniques
used for incremental learning. <em>NEUCOM</em>, <em>582</em>, 127545.
(<a href="https://doi.org/10.1016/j.neucom.2024.127545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks and deep learning algorithms are designed to function similarly to biological synaptic structures. However, classical deep learning algorithms fail to fully capture the need for continuous learning; this has led to the advent of incremental learning. Incremental learning adds new challenges that are handled differently by modern state-of-the-art approaches. Some of these include: utilization of network memory as additional knowledge increases the size of the network, open-set recognition to be able to identify unrecognized information, and efficient knowledge distillation as most incremental learning algorithms are prone to catastrophic forgetting of previously learned knowledge. Recent advancements achieve incremental learning through a multitude of methods. Most methods are characterized by augmenting the normal algorithm of neural network training by both directly modifying the neural network structure and by adding additional learning steps. This paper analyzes and provides a comprehensive survey of existing methods and various techniques used for incremental learning. A novel categorization of the methods is also introduced based on recent trends of the state-of-the-art solutions. The study focuses on methods that provide incremental learning success as well as discusses emerging patterns in new research.},
  archive      = {J_NEUCOM},
  author       = {Justin Leo and Jugal Kalita},
  doi          = {10.1016/j.neucom.2024.127545},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127545},
  shortjournal = {Neurocomputing},
  title        = {Survey of continuous deep learning methods and techniques used for incremental learning},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-target feature selection with subspace learning and
manifold regularization. <em>NEUCOM</em>, <em>582</em>, 127533. (<a
href="https://doi.org/10.1016/j.neucom.2024.127533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing supervised Multi-Target Feature Selection (MTFS) methods seldom consider the nearest-neighbor relationship and statistical correlation of samples underlying the output space, which leads the result of feature selection to be easily interfered by the output noise, thus making it difficult to achieve satisfactory performance. This paper proposes a novel MTFS method to preserve both the global and local target correlations. Specifically, the low-rank constraint is introduced to achieve multi-layer regression structure to better decouple the inter-input and inter-target relationships. Moreover, the local nearest-neighbor relationships and variable correlations of the sample points in the output space are also explored through adaptive graph and manifold learning, to better utilize the target correlations to improve the MTFS performance. Following the above principle, the resulting objective function and the corresponding optimization algorithm are proposed. Extensive experiments on several public datasets show that the proposed method is superior to other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Dubo He and Shengxiang Sun and Li Xie},
  doi          = {10.1016/j.neucom.2024.127533},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127533},
  shortjournal = {Neurocomputing},
  title        = {Multi-target feature selection with subspace learning and manifold regularization},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Learnable product quantization for anomaly detection.
<em>NEUCOM</em>, <em>582</em>, 127532. (<a
href="https://doi.org/10.1016/j.neucom.2024.127532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many anomaly detection applications, anomaly samples are difficult to obtain. We propose a novel product quantization (PQ)-based anomaly detection scheme: Learnable Product Quantization (LPQ), which only requires very few abnormal samples to train the model. The scheme extracts feature from high-dimensional data using the deep learning network, decomposes the feature space into a Cartesian product of low dimensional subspaces using PQ, and then produces sub-codebooks consisting of sub-codewords with clustering techniques. As a result, the extracted features with similar sub-vector are mapped into the same bucket, which reduces the time complexity of nearest neighbor retrieval significantly. In order to achieve reasonable codebooks, a PQ Table is embedded into the network. While training, we propose a novel metric learning strategy that makes the semantically similar (normal) samples closer and dissimilar (outlier) samples farther. The experimental results on benchmark datasets demonstrate that our metric learning strategy is better than the triplet loss and the sigmoid cross-entropy loss on the anomaly detection task. In general, LPQ shows excellent performance and high efficiency in anomaly detection.},
  archive      = {J_NEUCOM},
  author       = {Shi Zhang and Weilin Chen and Binlong Lu and Huixia Lai},
  doi          = {10.1016/j.neucom.2024.127532},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127532},
  shortjournal = {Neurocomputing},
  title        = {Learnable product quantization for anomaly detection},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BEV-CFKT: A LiDAR-camera cross-modality-interaction fusion
and knowledge transfer framework with transformer for BEV 3D object
detection. <em>NEUCOM</em>, <em>582</em>, 127527. (<a
href="https://doi.org/10.1016/j.neucom.2024.127527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The BEV-CFKT proposed in this paper leverages knowledge transfer through transformers for LiDAR-Camera fusion in the Bird’s-Eye-View (BEV) space, aiming to achieve accurate and robust 3D object detection. BEV-CFKT comprises three main components, which include the generation of BEV features from images and point clouds, cross-modality interaction, and hybrid object queries using a monocular detection head. By unifying features from both point clouds and images into the BEV space, we simplify modal interaction, facilitate knowledge transfer, and extract richer structural and semantic information from multimodal data. This effectively enhances the network’s performance. To further improve detection performance, BEV-CFKT incorporates a temporal fusion module. Additionally, a hybrid object queries module based on a monocular detection head accelerates the convergence of our model. We demonstrate the effectiveness of our approach through an extensive set of experiments.},
  archive      = {J_NEUCOM},
  author       = {Ming Wei and Jiachen Li and Hongyi Kang and Yijie Huang and Jun-Guo Lu},
  doi          = {10.1016/j.neucom.2024.127527},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127527},
  shortjournal = {Neurocomputing},
  title        = {BEV-CFKT: A LiDAR-camera cross-modality-interaction fusion and knowledge transfer framework with transformer for BEV 3D object detection},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MSFFT: Multi-scale feature fusion transformer for cross
platform vehicle re-identification. <em>NEUCOM</em>, <em>582</em>,
127514. (<a href="https://doi.org/10.1016/j.neucom.2024.127514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A vital component of Intelligent Transportation Systems (ITS) is vehicle re-identification, which allows vehicles to be identified across surveillance devices. Re-identification of vehicles is usually done using information collected from standalone surveillance devices such as fixed surveillance cameras (CCTVs) or aerial devices (UAVs). Re-identifying vehicles across standalone surveillance systems is challenging when there is a severe illumination change, a change of viewpoint, or an occlusion. Cross platform surveillance (CCTV+UAV) based vehicle re-identification is yet to be explored and can mitigate some of the challenges faced during re-identifying vehicles with standalone surveillance systems. This paper proposes a novel cross platform vehicle identification dataset called MCU-VReID using 42 CCTVs and a UAV. A novel re-identification method called Multi-Scale Feature Fusion Transformer (MSFFT) is proposed to re-identify vehicles observed across the cross platform surveillance systems. The network consists of inception layers with transformer networks that enable it to learn the vehicle’s features at a variety of scales. The vehicles observed by two contrasting surveillance systems appear to be transformed representations of one another. Hence a two-stage training approach is facilitated for re-identifying vehicles observed across cross platform surveillance systems. The two-stage training approach aims to learn vehicle semantic transformations in the first stage using self-supervised approaches. The knowledge gained at the first stage relating to vehicle semantic transformations is transferred at the second stage of training to perform re-identification. Extensive experiments using the method demonstrate that MSFFT significantly improves over state-of-the-art methods to perform cross platform vehicle re-identification.},
  archive      = {J_NEUCOM},
  author       = {Ashutosh Holla B. and Manohara Pai M.M. and Ujjwal Verma and Radhika M. Pai},
  doi          = {10.1016/j.neucom.2024.127514},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127514},
  shortjournal = {Neurocomputing},
  title        = {MSFFT: Multi-scale feature fusion transformer for cross platform vehicle re-identification},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian graph convolutional network for traffic prediction.
<em>NEUCOM</em>, <em>582</em>, 127507. (<a
href="https://doi.org/10.1016/j.neucom.2024.127507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, adaptive graph convolutional network based traffic prediction methods, learning a latent graph structure from traffic data via various attention-based mechanisms, have achieved impressive performance. However, they are still limited to finding a better description of spatial relationships between traffic conditions due to: (1) ignoring the prior of the observed road network topology; (2) neglecting the presence of negative spatial relationships; and (3) lacking investigation on the uncertainty of the graph structure. In this paper, we propose a Bayesian Graph Convolutional Network (BGCN) framework to alleviate these issues. Under this framework, the graph structure is viewed as a random realization from a parametric generative model, and its posterior is inferred using the observed topology of the road network and traffic data. Specifically, the parametric generative model is comprised of two parts: (1) a constant adjacency matrix that discovers potential spatial relationships from the observed physical connections between roads using a Bayesian approach; (2) a learnable adjacency matrix that learns globally shared spatial correlations from traffic data in an end-to-end fashion and can model negative spatial correlations. The posterior of the graph structure is then approximated by performing Monte Carlo dropout on the parametric graph structure. We verify the effectiveness of our method on five real-world datasets, and the experimental results demonstrate that BGCN attains superior performance compared with state-of-the-art methods. The source code is available at https://github.com/JunFu1995/BGCN.git .},
  archive      = {J_NEUCOM},
  author       = {Jun Fu and Wei Zhou and Zhibo Chen},
  doi          = {10.1016/j.neucom.2024.127507},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127507},
  shortjournal = {Neurocomputing},
  title        = {Bayesian graph convolutional network for traffic prediction},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Being aware of localization accuracy by generating
predicted-IoU-guided quality scores. <em>NEUCOM</em>, <em>582</em>,
127504. (<a href="https://doi.org/10.1016/j.neucom.2024.127504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Localization quality estimation (LQE) methods benefit the post-process by additionally considering the prediction box’s localization accuracy. In this paper, we propose a more compatible detector called Classification-Localization-Quality (CLQ), which is not only applicable to general-distribution-based detection heads but also to delta-distribution-based heads. In this method, A lightweight and learnable LQE branch is designed to generate more accurate LQE scores. We also use an exponential factor and a weighted loss function respectively to optimize its effect and improve its training efficiency. To enhance task interaction during both the training and test phases, we merged this branch with the classification branch and trained them jointly. Experiment results show that CLQ achieves state-of-the-art performance at an accuracy of 47.8 AP and a speed of 11.5 fps with ResNeXt-101 as the backbone on COCO test-dev. We also extend our method to the ATSS baseline to evaluate the scalability. Codes are released at ( https://github.com/PanffeeReal/CLQ ).},
  archive      = {J_NEUCOM},
  author       = {Pengfei Liu and Changguang Song and Yuhan Guo and Guixin Tang and Weibo Wang and Jiubin Tan},
  doi          = {10.1016/j.neucom.2024.127504},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127504},
  shortjournal = {Neurocomputing},
  title        = {Being aware of localization accuracy by generating predicted-IoU-guided quality scores},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel device placement approach based on position-aware
subgraph neural networks. <em>NEUCOM</em>, <em>582</em>, 127501. (<a
href="https://doi.org/10.1016/j.neucom.2024.127501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coping with the growing demand for data and parameters in complex neural network (NN) models of contemporary times typically involves distributing them across multiple devices, giving rise to the device placement problem. Several widely adopted solutions to this challenge leverage graph embedding schemes. However, the current graph embedding models employed for device placement suffer from several limitations, such as being highly time-consuming in the search for optimal parallelization strategies and yielding suboptimal parallel results. In this paper, we develop a novel graph embedding approach CP-GNNAK for efficient device placement. CP-GNNAK mainly depends on an efficient subgraph-based node embedding strategy, namely GNN as kernel, and a novel cosine phase position embedding scheme. CP-GNNAK goes beyond encoding only the immediate neighbors by deriving the representation of each node from the encoding of a surrounding subgraph. This expanded approach significantly enhances the efficiency of device placement through the integration of subgraph sampling strategies. Additionally, the cosine phase position embedding not only considers the positional information between nodes but also captures the directional information underlying the nodes. This adds richness to the node embeddings and improves the performance of device placement. The experimental results clearly indicate that the CP-GNNAK model achieves the state-of-the-art device placement results. Specifically, the experimental results reveal a remarkable 13.77% improvement in runtime when employing CP-GNNAK compared to Placeto. CP-GNNAK also outperforms GraphSAGE by 7.36% and P-GNN by 0.94%. Turning to computation time, CP-GNNAK exhibits a substantial speedup of 3.40 × × over Placeto, 3.87 × × over GraphSAGE, and 3.20 × × over P-GNN.},
  archive      = {J_NEUCOM},
  author       = {Meng Han and Yan Zeng and Jilin Zhang and Yongjian Ren and Meiting Xue and Mingyao Zhou},
  doi          = {10.1016/j.neucom.2024.127501},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127501},
  shortjournal = {Neurocomputing},
  title        = {A novel device placement approach based on position-aware subgraph neural networks},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fully automated diagnosis of thyroid nodule ultrasound using
brain-inspired inference. <em>NEUCOM</em>, <em>582</em>, 127497. (<a
href="https://doi.org/10.1016/j.neucom.2024.127497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interpretability of artificial intelligence (AI) based medical diagnostic systems is crucial to make the diagnosis adequately convincible. Deep learning has been extensively investigated and utilized in the area of medical assistance diagnosis in recent decades due to its outstanding performance and objective prediction. However, a huge semantic chasm dividing clinicians and unexplainable deep models emerges. Here we design a brain-inspired inference framework from medical images to explainable features, then to the final diagnostic conclusions. The fast thinking module is responsible for recognizing medical features in ultrasound (US) images, and the slow-thinking module builds a model for inferring from medical features to diagnostic results by constructing a knowledge graph of medical features with tensor decomposition. The whole model infers through intuition and thinking like a human being, and gives the recognized medical image features while inferring the diagnosis, which greatly improves the interpretability of the model. We conducted studies on thyroid cancer diagnoses using US images. The American College of Radiology (ACR) Thyroid Imaging Reporting and Data System (TI-RADS) characteristics are employed as medical features describing thyroid nodules. Our brain-inspired medical inference framework outperforms commonly used deep learning algorithms, with an AUC score of 0.963 (95% confidential interval (CI)=0.923–1.000) for thyroid US image diagnosis. Results indicate that our framework improves diagnostic objectivity and interpretability while providing performance that is better than deep models. Our proposed brain-inspired medical inference framework could improve the efficiency of diagnosis and our technique is performant, objective and interpretable.},
  archive      = {J_NEUCOM},
  author       = {Guanghui Li and Qinghua Huang and Chunying Liu and Guanying Wang and Lingli Guo and Ruonan Liu and Longzhong Liu},
  doi          = {10.1016/j.neucom.2024.127497},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127497},
  shortjournal = {Neurocomputing},
  title        = {Fully automated diagnosis of thyroid nodule ultrasound using brain-inspired inference},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Representation modeling learning with multi-domain
decoupling for unsupervised skeleton-based action recognition.
<em>NEUCOM</em>, <em>582</em>, 127495. (<a
href="https://doi.org/10.1016/j.neucom.2024.127495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based action recognition is one of the basic researches in computer vision. In recent years, the unsupervised contrastive learning paradigm has achieved great success in skeleton-based action recognition. However, previous work often treated input skeleton sequences as a whole when performing comparisons, lacking fine-grained representation contrast learning. Therefore, we propose a contrastive learning method for R epresentation M odeling with M ulti-domain D ecoupling (RMMD), which extracts the most significant representations from input skeleton sequences in the temporal domain, spatial domain and frequency domain, respectively. Specifically, in the temporal and spatial domains, we propose a multi-level spatiotemporal mining reconstruction module (STMR) that iteratively reconstructs the original input skeleton sequences to highlight spatiotemporal representations under different actions. At the same time, we introduce position encoding and a global adaptive attention matrix, balancing both global and local information, and effectively modeling the spatiotemporal dependencies between joints. In the frequency domain, we use the discrete cosine transform (DCT) to achieve temporal-frequency conversion, discard part of the interference information, and use the frequency self-attention (FSA) and multi-level aggregation perceptron (MLAP) to deeply explore the frequency domain representation. The fusion of the temporal domain, spatial domain and frequency domain representations makes our model more discriminative in representing different actions. Besides, we verify the effectiveness of the model on the NTU RGB+D and PKU-MMD datasets. Extensive experiments show that our method outperforms existing unsupervised methods and achieves significant performance improvements in downstream tasks such as action recognition and action retrieval.},
  archive      = {J_NEUCOM},
  author       = {Zhiquan He and Jiantu Lv and Shizhang Fang},
  doi          = {10.1016/j.neucom.2024.127495},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127495},
  shortjournal = {Neurocomputing},
  title        = {Representation modeling learning with multi-domain decoupling for unsupervised skeleton-based action recognition},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical synchronization with structured
multi-granularity interaction for video question answering.
<em>NEUCOM</em>, <em>582</em>, 127494. (<a
href="https://doi.org/10.1016/j.neucom.2024.127494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video Question Answering (VideoQA) requires a thorough comprehension of linguistic and visual modalities. However, recent methods confront two problems: (1) Synchronous modeling of object action and frame scene instead of a step-by-step manner, which can better mine potential semantic attributes of videos, lacks research; (2) The relationship between cross-modal alignments at different granularity of abstraction is not fully utilized. Based on these insights, we propose a novel method named hierarchical synchronization with structured multi-granularity interaction (HSSMI) for VideoQA. First, a hierarchical synchronous reasoning module is put forward to model objects’ relations and dynamics and synchronously capture their synergistic influences over time when analyzing whole frames. It is seen as multiple Object ConvLSTMs (O-CLSTMs) in isolation or a Frame ConvLSTM (F-CLSTM) in collectivity. Specifically, O-CLSTM learns the object-level action states under neighboring spatial interplays. Meanwhile, F-CLSTM learns the frame-level scene state, where action information from O-CLSTMs is selectively aggregated into a common memory cell of F-CLSTM as instructed by questions. Besides, a boundary detector is equipped to discover scene discontinuities, enabling F-CLSTM to alter its time connectivity and adapt its sequential encoding process to videos. Thereafter, we develop a conditional VLAD with topic constraints for discriminative modality summarization. Last, a structured multi-granularity interaction module is proposed to integrate complemented clues on the global alignment between scene summary and full question and the local alignments between action summaries and words. This module encourages useful information passing through compositional syntactical topologies of questions to predict answers. Experiments on three public benchmark datasets demonstrate the superiority of our HSSMI against other state-of-the-art methods. Codes will be publicly available at https://github.com/Qiss33/HSSMI .},
  archive      = {J_NEUCOM},
  author       = {Shanshan Qi and Luxi Yang and Chunguo Li},
  doi          = {10.1016/j.neucom.2024.127494},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127494},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical synchronization with structured multi-granularity interaction for video question answering},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Degradation regression with uncertainty for blind
super-resolution. <em>NEUCOM</em>, <em>582</em>, 127486. (<a
href="https://doi.org/10.1016/j.neucom.2024.127486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some recent blind super-resolution (SR) efforts focus on designing complex degradation models to better simulate real-world degradations. The paired high-resolution (HR) &amp; low-resolution (LR) samples synthesized by these models can cover a large degradation space, which helps train a robust SR model in real scenarios. However, these diverse synthetic samples may render the SR model degradation-unaware and prevent it from achieving optimal results on LR images with specific degradations. Alternatively, another category of methods is proposed to estimate specific degradations in the given application and then tailor a degradation-aware SR model accordingly. Nonetheless, degradation estimation is an ill-posed problem and accurate estimation is quite challenging. Towards these issues, we propose a probabilistic degradation estimator (PDE) which can predict the degradation as a certain distribution rather than a single point. Specifically, we develop an intersection over union (IoU) based degradation regression loss with uncertainty, which could lead PDE to shrink the possible degradation space of the test LR image. This enables the degradation model to synthesize more degradation-specific training samples and further improve SR performance. In this way, our PDE can alleviate degradation redundancy compared with degradation-unaware methods and is more robust to the degradation estimation error than previous degradation-aware methods. Extensive experiments show that the proposed PDE can help the SR model produce better results on both synthetic and real-world images.},
  archive      = {J_NEUCOM},
  author       = {Shang Li and Guixuan Zhang and Zhengxiong Luo and Jie Liu and Zhi Zeng and Shuwu Zhang},
  doi          = {10.1016/j.neucom.2024.127486},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127486},
  shortjournal = {Neurocomputing},
  title        = {Degradation regression with uncertainty for blind super-resolution},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A signer-independent sign language recognition method for
the single-frequency dataset. <em>NEUCOM</em>, <em>582</em>, 127479. (<a
href="https://doi.org/10.1016/j.neucom.2024.127479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, there are over 70 million people worldwide using more than 300 sign languages for communication, resulting in a vast number of sign language categories. Sign language recognition faces two main challenges. Firstly, in real-world applications, sign language users may not be represented in the dataset, leading to weak recognition capabilities of the models. Secondly, constructing large-scale sign language datasets is time-consuming and labor-intensive. Additionally, existing sign language recognition models have complex structures, leading to severe overfitting issues in the single-frequency dataset. To address these challenges, we construct a signer-independent learning sign language recognition method for the single-frequency dataset. In this work, a SwC GR-MMixer model, which relies on Gated Recurrent Unit (GRU) and Multi-Layer Perceptron (MLP) is developed, resulting in significantly reduced model complexity. After extensive ablation experiments, the most suitable structure for the SwC GR-MMixer model in the single-frequency dataset, as well as data augmentation methods, were determined. We achieved the best performance so far on the CSL-500 dataset and tackled the challenges of recognizing sign language, including the limitations imposed by the independence of the signer and the paucity of data on single-frequency datasets (e.g., CSL-500 dataset with only one demonstration per signer) by using a mask replacement method. Leveraging spatial feature extraction method, signer-independent sign language recognition tasks are accomplished, achieving a 6.95% improvement in the signer-independent method on the LSA64 dataset.},
  archive      = {J_NEUCOM},
  author       = {Tianyu Liu and Tangfei Tao and Yizhe Zhao and Min Li and Jieli Zhu},
  doi          = {10.1016/j.neucom.2024.127479},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127479},
  shortjournal = {Neurocomputing},
  title        = {A signer-independent sign language recognition method for the single-frequency dataset},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain adaptation of anchor-free object detection for urban
traffic. <em>NEUCOM</em>, <em>582</em>, 127477. (<a
href="https://doi.org/10.1016/j.neucom.2024.127477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern detectors are mostly trained under single and limited conditions. However, object detection faces various complex and open situations in autonomous driving, especially in urban street scenes with dense objects and complex backgrounds. Due to the shift in data distribution, modern detectors cannot perform well in actual urban environments. Using domain adaptation to improve detection performance is one of the key methods to extend object detection from limited situations to open situations. To this end, this article proposes a Domain Adaptation of Anchor-Free object detection (DAAF) for urban traffic. DAAF is a cross-domain object detection method that performs feature alignment including two aspects. On the one hand, we designed a fully convolutional adversarial training method for global feature alignment at the image level. Meanwhile, images can generally be decomposed into structural information and texture information. In urban street scenes, the structural information of images is generally similar. The main difference between the source domain and the target domain is texture information. Therefore, during global feature alignment, this paper proposes a method called texture information limitation (TIL). On the other hand, in order to solve the problem of variable aspect ratios of objects in urban street scenes, this article uses an anchor-free detector as the baseline detector. Since the anchor-free object detector can obtain neither explicit nor implicit instance-level features, we adopt Pixel-Level Adaptation (PLA) to align local features instead of instance-level alignment for local features. The size of the object has the greatest impact on the final detection effect, and the object scale in urban scenes is relatively rich. Guided by the differentiation of attention mechanisms, a multi-level adversarial network is designed to perform feature alignment of the output space at different feature levels called Scale Information Limitation (SIL). We conducted cross-domain detection experiments by using various urban streetscape autonomous driving object detection datasets, including adverse weather conditions, synthetic data to real data, and cross-camera adaptation. The experimental results indicate that the method proposed in this article is effective.},
  archive      = {J_NEUCOM},
  author       = {Xiaoyong Yu and Xiaoqiang Lu},
  doi          = {10.1016/j.neucom.2024.127477},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127477},
  shortjournal = {Neurocomputing},
  title        = {Domain adaptation of anchor-free object detection for urban traffic},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Noise aware content-noise complementary GAN with local and
global discrimination for low-dose CT denoising. <em>NEUCOM</em>,
<em>582</em>, 127473. (<a
href="https://doi.org/10.1016/j.neucom.2024.127473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to rising concerns over radiation exposure in computed tomography (CT) imaging, effective denoising methods for low-dose CT (LDCT) images are crucial. In recent years, the use of deep learning techniques especially generative adversarial networks (GANs) significantly enhanced the efficiency of LDCT denoising methods, surpassing traditional methods. However, GAN-based denoising methods often face challenges in preserving structural consistency and fine details. This study introduces a novel GAN framework with three accretions to enhance the effectiveness of LDCT denoising. Firstly, our generator is designed to leverage a complementary learning scheme between image noise and image content via two distinct paths. One path focuses on exploring the anatomical information of the image, while the second path is dedicated to learning the noise pattern. This complementary learning scheme provides stable noise cancellation while preserving the maximum structural information of the image. Subsequently, we propose a novel noise-conscious mean absolute error loss to address the challenge posed by the non-stationary characteristic of CT noise. In contrast to conventional MAE loss, this loss attentively prioritizes the different parts of the image based on the local distribution of noise in that region. We also incorporate a gradient-domain loss into the loss function, which inspires the generator to preserve precise image details through explicit guidance. Finally, this study adopted a U-Net-based design for the discriminator to better regularize the model by discriminating between the clean image and the denoised image at both global and local levels. The merit of this discriminator is that it can better adapt to the non-stationary environment of GAN training and guide the generator to produce denoised images that are locally and globally consistent. Our thorough experiments using abdominal CT and lung CT datasets demonstrate the superior performance of our approach compared to state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Kousik Sarkar and Soumen Bag and Prasun Chandra Tripathi},
  doi          = {10.1016/j.neucom.2024.127473},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127473},
  shortjournal = {Neurocomputing},
  title        = {Noise aware content-noise complementary GAN with local and global discrimination for low-dose CT denoising},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparsity in transformers: A systematic literature review.
<em>NEUCOM</em>, <em>582</em>, 127468. (<a
href="https://doi.org/10.1016/j.neucom.2024.127468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformers have become the state-of-the-art architectures for various tasks in Natural Language Processing (NLP) and Computer Vision (CV); however, their space and computational complexity present significant challenges for real-world applications. A promising approach to address these issues is the introduction of sparsity, which involves the deliberate removal of certain parameters or activations from the neural network. In this systematic literature review, we aimed to provide a comprehensive overview of current research on sparsity in transformers. We analyzed the different sparsity techniques applied to transformers, their impact on model performance, and their efficiency in terms of time and space complexity. Moreover, we identified the major gaps and challenges in the existing literature. Our study also highlighted the importance of investigating sparsity in transformers for computational efficiency, reduced resource requirements, scalability, environmental impact, and hardware-algorithm co-design. By synthesizing the current state of research on sparsity in transformer-based models, we also provided valuable insights into their efficiency, impact on model performance, and potential trade-offs, contributing to advancing the field further.},
  archive      = {J_NEUCOM},
  author       = {Mirko Farina and Usman Ahmad and Ahmad Taha and Hussein Younes and Yusuf Mesbah and Xiao Yu and Witold Pedrycz},
  doi          = {10.1016/j.neucom.2024.127468},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127468},
  shortjournal = {Neurocomputing},
  title        = {Sparsity in transformers: A systematic literature review},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data privacy protection health status assessment for
rotating machinery with dual-task feature fusion framework.
<em>NEUCOM</em>, <em>582</em>, 127464. (<a
href="https://doi.org/10.1016/j.neucom.2024.127464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately assessing health status of rotating machinery is essential in reliable operation and predictive maintenance. Recently, health status assessment (HSA) of rotating machinery has acquired significant progress, particularly with the increasing popularity of deep learning. However, most methods regard HSA as a combination of isolated tasks, ignoring the hierarchical relationships between tasks in predictive maintenance. Also, they fail to learn multi-source features adequately. Besides, due to data silos and conflict of interests, the collaborative model training poses a strong demand for privacy protection. Thus, this paper proposes a data privacy protection HSA framework with dual-task feature fusion learning. First, we consider HSA of machinery as an integral dual-task process and synchronously obtain assessment results. The proposed framework constructs hierarchical health labels to ensure assessment accuracy, and utilizes adaptive information exchange channels to maintain balance between the dual tasks. Next, we design a feature fusion network based on channel independence and patch mechanisms to enhance the utilization of correlation information in multi-source signals. Finally, by employing decentralized swarm learning, achieve privacy-preserving joint training to address data silos. Experimental results validate the effectiveness and superiority of the proposed framework.},
  archive      = {J_NEUCOM},
  author       = {Xin He and Wei Zhou and Zhen Luo and Zuowei Ping and Maolin Wang},
  doi          = {10.1016/j.neucom.2024.127464},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127464},
  shortjournal = {Neurocomputing},
  title        = {Data privacy protection health status assessment for rotating machinery with dual-task feature fusion framework},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal pattern-aware QoS prediction by biased non-negative
tucker factorization of tensors. <em>NEUCOM</em>, <em>582</em>, 127447.
(<a href="https://doi.org/10.1016/j.neucom.2024.127447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic quality of service (QoS) data contain rich temporal patterns of user-service interactions, which are vital for better understanding user behaviors and service conditions. Canonical polyadic (CP)-based latent factorization model has proven to be capable of capturing such patterns. However, it models the relations among latent features of user, service and time in a rigid and unnatural way, causing its failures in capturing the complex patterns when the target QoS data become massive. To address that issue, this paper proposes a B iased N on-negative Tuc ker F actorization of 3D tensors (BNTucF) model with the four-fold ideas: (1) utilizing a core tensor for modeling the complex interactions among latent features; (2) incorporating linear biases into the model for accurate descriptions on QoS fluctuation; (3) constraining the model to be non-negative for describing QoS non-negativity; (4) deducing a single latent factor-dependent, multiplicative updating scheme for training the model in an efficient density-oriented way. Empirical studies demonstrate that the proposed BNTucF can learn complex dynamic user-service interaction patterns more accurately, hence achieving accurate predictions on missing QoS data.},
  archive      = {J_NEUCOM},
  author       = {Peng Tang and Tao Ruan and Hao Wu and Xin Luo},
  doi          = {10.1016/j.neucom.2024.127447},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127447},
  shortjournal = {Neurocomputing},
  title        = {Temporal pattern-aware QoS prediction by biased non-negative tucker factorization of tensors},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic and style based multiple reference learning for
artistic and general image aesthetic assessment. <em>NEUCOM</em>,
<em>582</em>, 127434. (<a
href="https://doi.org/10.1016/j.neucom.2024.127434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artistic Image Aesthetic Assessment (AIAA) is an emerging paradigm that predicts the aesthetic score as the popular aesthetic taste for an artistic image. Previous AIAA takes a single image as input to predict the aesthetic score of the image. However, most existing AIAA methods fail dramatically to predict the artistic images with a large variance of artistic subjective voting with only a single image. People are good at employing multiple similar references for making relative comparisons. Motivated by the practice that people considers similar semantics and specific artistic style to keep the consistency of the voting result, we present a novel Semantic and Style based Multiple Reference learning (SSMR) to mimic this natural process. Our novelty is mainly two-fold: (a) Similar Reference Index Generation (SRIG) module that considers artistic attribution of semantics and style to generate the index of reference images; (b) Multiple Reference Graph Reasoning (MRGR) module that employs graph convolutional network (GCN) to initialize and reason by adjusting the weight of edges with intrinsic relationships among multiple images. Our evaluation with the benchmark BAID, VAPS and TAD66K artistic aesthetic datasets demonstrates that the proposed SSMR outperforms state-of-the-art AIAA methods, and verifies the comparable to the SOTA IAA methods on the AVA general aesthetic dataset.},
  archive      = {J_NEUCOM},
  author       = {Tengfei Shi and Chenglizhao Chen and Xuan Li and Aimin Hao},
  doi          = {10.1016/j.neucom.2024.127434},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127434},
  shortjournal = {Neurocomputing},
  title        = {Semantic and style based multiple reference learning for artistic and general image aesthetic assessment},
  volume       = {582},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved asynchronous batch gradient method for ridge
polynomial neural network. <em>NEUCOM</em>, <em>581</em>, 127529. (<a
href="https://doi.org/10.1016/j.neucom.2024.127529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ridge polynomial neural network composed of pi-sigma modules is a typical higher-order feedforward network, which has good non-linear mapping capabilities. Due to the strong coupling of the network structure, the synchronous gradient method can easily result in significant fluctuations in updated weights. This will reduce the generalization ability of the ridge polynomial neural network for solving classification problems. In this paper, the proposed method is a novel improved asynchronous batch gradient method, and combined with the adaptive parameters of the activation function are trained synchronously. We strictly prove the convergence theorem of the improved method. The numerical experimental results also indicate that our method for training ridge polynomial neural networks can help the weight changes smoothly and the network has good generalization ability. The feasibility and effectiveness of our method are verified from both theoretical and experimental perspectives.},
  archive      = {J_NEUCOM},
  author       = {Yan Xiong and Shumei He},
  doi          = {10.1016/j.neucom.2024.127529},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127529},
  shortjournal = {Neurocomputing},
  title        = {An improved asynchronous batch gradient method for ridge polynomial neural network},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for steganalysis of diverse data types: A
review of methods, taxonomy, challenges and future directions.
<em>NEUCOM</em>, <em>581</em>, 127528. (<a
href="https://doi.org/10.1016/j.neucom.2024.127528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steganography and steganalysis are two interrelated aspects of the field of information security. Steganography seeks to conceal communications, whereas steganalysis aims to discover or, if possible, recover the data they contain. These two areas have garnered significant interest, especially among law enforcement agencies. Cybercriminals and even terrorists often employ steganography to avoid detection while in possession of incriminating evidence, even when that evidence is encrypted, since cryptography is prohibited or restricted in many countries. Therefore, a deep understanding of cutting-edge techniques for uncovering concealed information is essential in exposing illegal activities. Over the last few years, a number of strong and reliable steganography and steganalysis techniques have been introduced in the literature. This review paper provides a comprehensive overview of deep learning-based steganalysis techniques used to detect hidden information within digital media. The paper covers all types of cover in steganalysis, including image, audio, and video, and discusses the most commonly used deep learning techniques. In addition, the paper explores the use of more advanced deep learning techniques, such as deep transfer learning (DTL) and deep reinforcement learning (DRL), to enhance the performance of steganalysis systems. The paper provides a systematic review of recent research in the field, including data sets and evaluation metrics used in recent studies. It also presents a detailed analysis of DTL-based steganalysis approaches and their performance on different data sets. The review concludes with a discussion on the current state of deep learning-based steganalysis, challenges, and future research directions.},
  archive      = {J_NEUCOM},
  author       = {Hamza Kheddar and Mustapha Hemis and Yassine Himeur and David Megías and Abbes Amira},
  doi          = {10.1016/j.neucom.2024.127528},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127528},
  shortjournal = {Neurocomputing},
  title        = {Deep learning for steganalysis of diverse data types: A review of methods, taxonomy, challenges and future directions},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Layered isolation forest: A multi-level subspace algorithm
for improving isolation forest. <em>NEUCOM</em>, <em>581</em>, 127525.
(<a href="https://doi.org/10.1016/j.neucom.2024.127525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is an important field in data science that has been widely researched and applied, generating many methods. Among these methods, the isolation forest algorithm is outstanding because of its efficiency and effectiveness, especially in regard to large-scale data. Unfortunately, this algorithm has some drawbacks, such as being unable to effectively handle local outliers, possibly leading to normal data masking the detection of outliers due to space partitioning along the coordinate axes, and low utilization of training data. To address these issues, in this paper we propose an improved isolation forest algorithm based on multilayer subspace dividing, named layered isolation forest, which adapts to the different distributions of the dataset by dividing the sample space into subspaces and evaluating the anomaly degree of data in different spatial ranges. This algorithm obtains a more accurate and reasonable anomaly score, avoids the problems of the original algorithm, and improves the performance metrics. According to the experimental results, the proposed method maintains the efficiency of the original algorithm and exhibits the best comprehensive performance compared with similar algorithms on artificial synthetic datasets and real-world datasets from multiple domains.},
  archive      = {J_NEUCOM},
  author       = {Tao Liu and Zhen Zhou and Lijun Yang},
  doi          = {10.1016/j.neucom.2024.127525},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127525},
  shortjournal = {Neurocomputing},
  title        = {Layered isolation forest: A multi-level subspace algorithm for improving isolation forest},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Deep contrastive representation learning for multi-modal
clustering. <em>NEUCOM</em>, <em>581</em>, 127523. (<a
href="https://doi.org/10.1016/j.neucom.2024.127523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from the informative expression capability of contrastive representation learning (CRL), recent multi-modal learning studies have achieved promising clustering performance. However, it should be pointed out that the existing multi-modal clustering methods based on CRL fail to simultaneously take the similarity information embedded in inter- and intra-modal levels. In this study, we mainly explore deep multi-modal contrastive representation learning, and present a multi-modal learning network, named trustworthy multi-modal contrastive clustering (TMCC), which incorporates contrastive learning and adaptively reliable sample selection with multi-modal clustering. Specifically, we are concerned with an adaptive filter to learn TMCC via progressing from ‘easy’ to ‘complex’ samples. Based on this, with the highly confident clustering labels, we present a new contrastive loss to learn modal-consensus representation, which takes into account not only the inter-modal similarity but also the intra-modal similarity. Experimental results show that these principles in TMCC consistently help promote clustering performance improvement.},
  archive      = {J_NEUCOM},
  author       = {Yang Lu and Qin Li and Xiangdong Zhang and Quanxue Gao},
  doi          = {10.1016/j.neucom.2024.127523},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127523},
  shortjournal = {Neurocomputing},
  title        = {Deep contrastive representation learning for multi-modal clustering},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Normalized penalty gradient flow: A continuous-time approach
for solving constrained nonconvex nonsmooth optimization problems.
<em>NEUCOM</em>, <em>581</em>, 127518. (<a
href="https://doi.org/10.1016/j.neucom.2024.127518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To avoid calculating penalty parameters, this paper introduces a continuous-time approach that combines the normalized gradient flow with the penalty method to solve the nonconvex nonsmooth optimization problem with a convex constraint set. Subsequently, this approach is extended to solve nonconvex nonsmooth optimization with a box constraint set and affine equality constraints. Compared with the current methods, the proposed approach does not require calculating the penalty parameters, allows the objective function to be nonconvex or nonsmooth, and allows the initial point to be arbitrarily selected. It is proved that the solution trajectory with any initial point converges to the critical point set of the optimization problem. Finally, the effectiveness of the proposed approach is authenticated through several numerical experiments.},
  archive      = {J_NEUCOM},
  author       = {Sijian Wang and Xin Yu and Haihua Qin},
  doi          = {10.1016/j.neucom.2024.127518},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127518},
  shortjournal = {Neurocomputing},
  title        = {Normalized penalty gradient flow: A continuous-time approach for solving constrained nonconvex nonsmooth optimization problems},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Progressive expansion: Cost-efficient medical image analysis
model with reversed once-for-all network training paradigm.
<em>NEUCOM</em>, <em>581</em>, 127512. (<a
href="https://doi.org/10.1016/j.neucom.2024.127512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low computational cost artificial intelligence (AI) models are vital in promoting the accessibility of real-time medical services in underdeveloped areas. The recent Once-For-All (OFA) network (without retraining) can directly produce a set of sub-network designs with Progressive Shrinking (PS) algorithm; however, the training resource and time inefficiency downfalls are apparent in this method. In this paper, we propose a new OFA training algorithm, namely the Progressive Expansion ( ProX ) to train the medical image analysis model. It is a reversed paradigm to PS, where technically we train the OFA network from the minimum configuration and gradually expand the training to support larger configurations. Empirical results showed that the proposed paradigm could reduce training time up to 68%; while still being able to produce sub-networks that have either similar or better accuracy compared to those trained with OFA-PS on ROCT (classification), BRATS and Hippocampus (3D-segmentation) public medical datasets. The code implementation for this paper is accessible at: https://github.com/shin-wl/ProX-OFA .},
  archive      = {J_NEUCOM},
  author       = {Shin Wei Lim and Chee Seng Chan and Erma Rahayu Mohd Faizal and Kok Howg Ewe},
  doi          = {10.1016/j.neucom.2024.127512},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127512},
  shortjournal = {Neurocomputing},
  title        = {Progressive expansion: Cost-efficient medical image analysis model with reversed once-for-all network training paradigm},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simulation of an individual with motor disabilities by a
deep reinforcement learning model. <em>NEUCOM</em>, <em>581</em>,
127511. (<a href="https://doi.org/10.1016/j.neucom.2024.127511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have developed a new neural network model that simulates how the central nervous system (CNS) governs neural motor sensors. Our model uses reinforcement learning and transfer entropy to compare healthy individuals’ learning with those who have motor impairments. Our aim is to study effective connectivity and identify differences in information transmission between the two groups. By analyzing effective connectivity, we have identified patterns arising from zero and non-zero transfer entropy values. These patterns are mainly due to factors such as the level of connectivity, the neural network’s learning time, and the rules guiding the model training process. However, when these patterns appear in the input and output layers, they are not necessarily critical in distinguishing between a healthy network and an impaired one since these layers interact directly with the environment. On the other hand, our model can replicate neurobiological factors linked to neuronal injury, indicated by these patterns, when they appear in the intermediate layers. We found that healthy networks had more neurons involved in sensorimotor communication compared to diseased networks. This may be due to an increase in disease-related glial cells, which led to reduced effective connectivity between CNS regions. Additionally, we observed some patterns for the loss or gain of entropy; these patterns show the sensitivity of our model to the number of delays we take into account for the effective connectivity to ensure that the information transfer within the model behaves as a natural process.},
  archive      = {J_NEUCOM},
  author       = {Karla K. Sánchez-Torres and Suemi Rodríguez-Romo},
  doi          = {10.1016/j.neucom.2024.127511},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127511},
  shortjournal = {Neurocomputing},
  title        = {Simulation of an individual with motor disabilities by a deep reinforcement learning model},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Co-evolutionary dynamics in optimal multi-agent game with
environment feedback. <em>NEUCOM</em>, <em>581</em>, 127510. (<a
href="https://doi.org/10.1016/j.neucom.2024.127510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, game-based analysis and control problems with environmental feedback significantly contribute to the study of collective cooperation, and pose great challenges for the analysis of multi-agent game systems in complex real world. We consider co-evolutionary dynamics based on an extended multi-agent game with environmental feedback, which is modeled by optional public goods games (OPGGs). Firstly, the co-evolutionary dynamics of OPGGs with environment feedback can be modeled as two parts: the dynamics of OPGGs and synergy coefficient, where the former can represent the group game behavior of three strategies, and the latter can be seen as the evolutionary behavior in changing environments. Subsequently, some possible fixed points will emerge with respect to three types of boundaries for these co-evolutionary dynamics, and the existence and stability for the corresponding boundary fixed points are determined and analyzed. Meanwhile, the results are further extended to interior equilibrium point. It is observed that by combining voluntary participation and environment feedback, cooperation behavior can be still feasible, and the evolving system can oscillatingly converge to the persistent cooperation under some certain threshold conditions. Finally, an example is illustrated to validate the proposed approach. To sum up, environmental feedback mechanism provides a novel perspective to investigate the collective cooperation in a changing world.},
  archive      = {J_NEUCOM},
  author       = {Weiwei Han and Zhipeng Zhang and Yuying Zhu and Chengyi Xia},
  doi          = {10.1016/j.neucom.2024.127510},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127510},
  shortjournal = {Neurocomputing},
  title        = {Co-evolutionary dynamics in optimal multi-agent game with environment feedback},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Local dual-graph discriminant classifier for binary
classification. <em>NEUCOM</em>, <em>581</em>, 127508. (<a
href="https://doi.org/10.1016/j.neucom.2024.127508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based methods mine the potential structural information of data by constructing various graphs that positively affect the classifiers when dealing with classification problems. However, traditional graph-based classifiers are the most common single-graph classifiers and minimize only intra-class compactness, where inter-class separability is replaced by other factors. To consider real inter-class separability, we introduce a novel local dual-graph structure that can fully mine the geometric distribution of data by simultaneously maximizing the inter-class separability and minimizing the intra-class compactness. This local dual-graph structure reflects the relationship between samples and their neighbors and hence avoids the negative impact of outliers on the construction of graphs. Furthermore, a novel classifier called the local dual-graph discriminant classifier (LDGDC) is proposed using a local dual-graph structure. Originally, LDGDC is designed to perform the following optimization: minimization of the 2-norm regularization of model coefficients and intra-class compactness, and maximization of the inter-class separability, which is a non-convex optimization problem. To facilitate the solution, we transform the original non-convex problem of LDGDC into a convex problem. Finally, experiments were conducted on several public datasets, and the results demonstrate the effectiveness and robustness of the proposed LDGDC.},
  archive      = {J_NEUCOM},
  author       = {Xiaohan Zheng and Li Zhang and Leilei Yan},
  doi          = {10.1016/j.neucom.2024.127508},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127508},
  shortjournal = {Neurocomputing},
  title        = {Local dual-graph discriminant classifier for binary classification},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural networks-based data hiding in digital images:
overview. <em>NEUCOM</em>, <em>581</em>, 127499. (<a
href="https://doi.org/10.1016/j.neucom.2024.127499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, neural networks are actively used for data hiding; however, there is currently no systematic knowledge regarding their utilization in this field. This is a significant gap, considering that neural network-based data hiding has already formed a large and quite independent area of research. This review aims to provide such systematization. It also provides a general framework of neural network usage for data hiding, comparisons of quantitative and qualitative indicators of the effectiveness of existing data hiding methods, and discussion and conclusions containing the most promising directions and tools for research in the field of data hiding using neural networks, as well as the main achievements and the persisting challenges. This work targets researchers looking for the most suitable data hiding method for their application, as well as the developers of data hiding methods.},
  archive      = {J_NEUCOM},
  author       = {Kristina Dzhanashia and Oleg Evsutin},
  doi          = {10.1016/j.neucom.2024.127499},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127499},
  shortjournal = {Neurocomputing},
  title        = {Neural networks-based data hiding in digital images: Overview},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A new prognostic model for accurate assessment of
hepatocellular carcinoma risk using RNA editing data and unsupervised
machine learning. <em>NEUCOM</em>, <em>581</em>, 127498. (<a
href="https://doi.org/10.1016/j.neucom.2024.127498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A-to-I RNA editing is a long-known driving factor to the progression of hepatocellular carcinoma (HCC); however, its importance is often neglected in HCC subtyping and the modeling of prognosis, partially due to the high dimensional nature of the editing data. In this paper, we first obtain a comprehensive A-to-I RNA editing profile for HCC, among which two editing sites, IGFBP7 I387M (chr4:57110120) and SUMF2 A98G (chr7:56078974), are identified as having the driving function potential. Then, we exploit the clinical-related RNA editing profile in combination with the gene expressions to develop a new prognostic model for HCC. To preserve the inner structure of this editing profile in a latent space that has a much lower dimension, we employ variational autoencoder (VAE), an unsupervised learning neural network applied for the first time to compress the RNA editing profile. Empowered by VAE, we are able to cluster the HCC patients efficiently according to their editing profile, among which a group of patients with immune dysregulation and enrichment in cell proliferation and cancer-related pathways are identified. Based on the editing-related subtyping, we develop a prognostic model that consists of an easy-computing risk score and an adaptively trained threshold. Validations using three independent cohorts (LIHC, LIRI, and GSE14520) confirm that the new model is robust, sensitive, and specific. Furthermore, it is more accurate in prediction than six state-of-the-art competitors. The model is also found applicable to 18 more cancers besides HCC, which suggests a strong ability in generalization. To facilitate clinical usage, we develop a nomogram, drug targets, prognosis-associated genes, and relevant pathways are also identified, which pave the way for upcoming studies on HCC’s molecular mechanism, therapeutic targets, and many others.},
  archive      = {J_NEUCOM},
  author       = {Huimin Zhu and Hui Zhang and Yuanyan Xiong and Hui Li},
  doi          = {10.1016/j.neucom.2024.127498},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127498},
  shortjournal = {Neurocomputing},
  title        = {A new prognostic model for accurate assessment of hepatocellular carcinoma risk using RNA editing data and unsupervised machine learning},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning in fringe projection: A review.
<em>NEUCOM</em>, <em>581</em>, 127493. (<a
href="https://doi.org/10.1016/j.neucom.2024.127493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fringe projection is widely recognized as a prominent technique for 3D measurement, owing to its non-contact nature, high precision, and exceptional spatial resolution. However, it faces challenges in achieving a delicate equilibrium between speed and accuracy, conducting measurements on intricate optical surfaces, and capturing objects requiring a high dynamic range. Deep learning, with its robust capacity to comprehensively learn and automatically extract features, holds great promise in effectively addressing the challenges encountered in fringe projection. This article offers a comprehensive analysis, discussion, and summary of the historical development, current state, and emerging trends in the applications of deep learning in fringe projection. It covers various applications, network structures, datasets, challenges, and potential future directions of utilizing deep learning in fringe projection. The aim of this paper is to provide researchers in this field with a comprehensive understanding of the latest advancements, research trends, and practical applications of this technology, thus fostering its further development and application.},
  archive      = {J_NEUCOM},
  author       = {Haoyue Liu and Ning Yan and Bofan Shao and Shuaipeng Yuan and Xiaodong Zhang},
  doi          = {10.1016/j.neucom.2024.127493},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127493},
  shortjournal = {Neurocomputing},
  title        = {Deep learning in fringe projection: A review},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive operator selection with dueling deep q-network for
evolutionary multi-objective optimization. <em>NEUCOM</em>,
<em>581</em>, 127491. (<a
href="https://doi.org/10.1016/j.neucom.2024.127491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive operator selection is an online method that automatically adjusts the application rate of different operators based on their actual performance. This paper proposes an adaptive operator selection paradigm based on dueling deep Q-network (DDQN), aiming to improve the training efficiency of the Q-network for solving multi-objective optimization problems. The Q-network is decomposed into state value and action advantage networks, allowing the agent to learn state values more frequently and accurately. A novel state space and reward mechanism are designed to adapt to the characteristics of evolutionary multi-objective optimization. Combining adaptive operator selection with a multi-objective evolutionary algorithm with adaptive weights (AdaW), an AdaW-DDQN algorithm with high adaptability is proposed. Experimental results on three complex benchmark suites demonstrate that the proposed adaptive operator selection paradigm significantly improves the performance of multi-objective optimization algorithms. The AdaW-DDQN algorithm provides an effective and efficient solution for solving multi-objective optimization problems.},
  archive      = {J_NEUCOM},
  author       = {Shihong Yin and Zhengrong Xiang},
  doi          = {10.1016/j.neucom.2024.127491},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127491},
  shortjournal = {Neurocomputing},
  title        = {Adaptive operator selection with dueling deep Q-network for evolutionary multi-objective optimization},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proactive cooperative consensus control for a class of
human-in-the-loop multi-agent systems with human time-delays.
<em>NEUCOM</em>, <em>581</em>, 127485. (<a
href="https://doi.org/10.1016/j.neucom.2024.127485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we consider a class of human-in-the-loop (HiTL) multi-agent systems that divide agents into two parts: the nonautonomous agents controlled by human operators, and the autonomous agents. First, the human operators’ models are incorporated into the multi-agent system for constructing an HiTL multi-agent system model. Next, the cooperative consensus control problem is explored for the HiTL multi-agent system, and a method is proposed that enables autonomous agents to proactively collaborate with human-controlled agents in order to mitigate the effects of human time-delays. We first obtain the consensus sufficient condition for the HiTL multi-agent system without human time-delays, and then give the method by only designing the autonomous agents’ control gains to guarantee consensus. Subsequently, the delay-dependent consensus sufficient condition for the HiTL multi-agent system with human time-delays is also offered, and the method of controller design is updated for this case. Finally, a simulation experiment was designed, and the simulation results are presented to illustrate the effectiveness of the proposed methods.},
  archive      = {J_NEUCOM},
  author       = {Zhen Qin and Huai-Ning Wu and Jin-Liang Wang},
  doi          = {10.1016/j.neucom.2024.127485},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127485},
  shortjournal = {Neurocomputing},
  title        = {Proactive cooperative consensus control for a class of human-in-the-loop multi-agent systems with human time-delays},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Incremental template neighborhood matching for 3D anomaly
detection. <em>NEUCOM</em>, <em>581</em>, 127483. (<a
href="https://doi.org/10.1016/j.neucom.2024.127483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unsupervised 3D industrial anomaly detection is gaining increasing attention in the computer vision community. Most advanced multimodal methods obtain anomaly detection models by one-time training, ignoring the continuous generation of new samples in industrial scenarios. In this paper, we propose Incremental Template Neighborhood Matching ( ITNM ), a method that enables the model to be incrementally updated by incorporating new samples, simultaneously achieving better anomaly detection and localization performance. We use a weighted feature concatenation to combine the RGB information with the point cloud information to avoid the bias caused by the difference of feature dimension and magnitude. In training stage, Pixel-wise Coreset Selection (PCS) is used to compress the multimodal template set to prevent excessive memory usage. PCS preserves the distribution of nominal sample features as much as possible, while retaining the pixel position information. In inference stage, the query feature is compared to the ones within the pixel’s neighborhood in the template set. The distance between the query feature and the most similar template feature is calculated as the anomaly score. Template Neighborhood Matching (TNM) avoids underestimation of anomaly scores due to misaligned template matching of anomaly features. Our method achieves competitive performance on the MVTec 3D-AD dataset, when a low false positive rate is required. More importantly, the results of the incremental training experiments show that the incremental updating process is effective.},
  archive      = {J_NEUCOM},
  author       = {Jiaxun Wang and Xiang Wang and Ruiyang Hao and Haonan Yin and Biqing Huang and Xiao Xu and Jingxian Liu},
  doi          = {10.1016/j.neucom.2024.127483},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127483},
  shortjournal = {Neurocomputing},
  title        = {Incremental template neighborhood matching for 3D anomaly detection},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exponential synchronization of complex networks via
intermittent dynamic event-triggered control. <em>NEUCOM</em>,
<em>581</em>, 127478. (<a
href="https://doi.org/10.1016/j.neucom.2024.127478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the exponential synchronization in mean square (ESMS) of complex networks (CNs) under intermittent dynamic event-triggered control strategy (IE-TCS) is discussed. Compared with the existing literature, the intermittent control strategy (ICS) proposed is awakened when a certain situation occurs rather than periodically, which can better improve the control efficiency. The average control rate in this paper is more flexible. Furthermore, we give a positive lower bound for the event-triggered intervals to ensure that Zeno behavior does not occur. Combining the graph-theoretic approach with the Lyapunov method, some criteria for ESMS are obtained. In particular, we also discuss the ESMS of non-strongly connected CNs under IE-TCS. Besides, we combine the self-triggered control strategy (S-TCS) with the ICS, which is called the intermittent S-TCS, to study the ESMS of CNs. For practicability, the theoretical results are applied to research the ESMS of the microgrid system, and some relevant sufficient conditions are derived. Eventually, numerical simulations are put forward to verify the effectiveness of theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Xiaotong Liu and Ying Guo and Mingzhu Li and Yifan Zhang},
  doi          = {10.1016/j.neucom.2024.127478},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127478},
  shortjournal = {Neurocomputing},
  title        = {Exponential synchronization of complex networks via intermittent dynamic event-triggered control},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Area-keywords cross-modal alignment for referring image
segmentation. <em>NEUCOM</em>, <em>581</em>, 127475. (<a
href="https://doi.org/10.1016/j.neucom.2024.127475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring image segmentation aims to segment the instance corresponding to the given language description, which requires aligning information from two modalities. Existing approaches usually align the cross-modal information based on different forms of feature units, such as pixel-sentence, pixel-word and patch-word. The problem is that the semantic information embodied by these feature units may be mismatched, for example, the semantics transferred by a pixel is a part of the semantics of a sentence. When using this inconsistent information to model the relationship between feature units from two modalities, the obtained relationship between the modes are imprecise, resulting in inaccurate cross-modal features. In this paper, we propose to generate scalable area and keywords features to ensure that the feature units from the two modalities have comparable semantic granularity. Meanwhile, the scalable features provide sparse representation for image and text, which reduces computation complexity for computing cross-modal features. In addition, we design a novel multi-source driven dynamic convolution to inversely map the area-keywords cross-modal features to image to predicate mask. The experimental results on three benchmark datasets demonstrate that our proposed framework achieves advanced performance, and the calculation amount of the model has been greatly reduced.},
  archive      = {J_NEUCOM},
  author       = {Huiyong Zhang and Lichun Wang and Shuang Li and Kai Xu and Baocai Yin},
  doi          = {10.1016/j.neucom.2024.127475},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127475},
  shortjournal = {Neurocomputing},
  title        = {Area-keywords cross-modal alignment for referring image segmentation},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new feature selection method based on importance measures
for crude oil return forecasting. <em>NEUCOM</em>, <em>581</em>, 127470.
(<a href="https://doi.org/10.1016/j.neucom.2024.127470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel feature selection method, called Feature Selection based on Importance Measures (FS-IM), to enhance the forecasting of crude oil returns. FS-IM innovatively combines active learning with the application of Gaussian noise to input features and selects the most relevant features using an optimal threshold value. The paper applies a ridge regression (RR) model based on FS-IM (FS-RR) to identify the factors that have important information for crude oil return forecasting. The paper compares FS-IM with other dimension reduction methods such as Principal Component Analysis (PCA), Kernel Principal Component Analysis (KPCA), and Independent Component Analysis (ICA). The results show that FS-IM can significantly improve model accuracy, demonstrating its effectiveness in finding key features. Moreover, FS-IM is more stable and consistent than other dimension reduction methods in enhancing the prediction accuracy in different scenarios, indicating its superior capability in capturing complex relationships between input and output variables. Furthermore, this study compares FS-RR model with other 13 prediction models by conducting experiments using a series of evaluation metrics, different statistical tests, and different step-ahead predictions and training sets. The results confirm that the RR model based on FS-IM can consistently outperform other model in terms of predictive performance and economic value, proving its effectiveness and robustness. This study contributes to the literature on crude oil price forecasting by addressing the challenges of high-dimensional and complex data, and by providing a robust, practical tool for professionals in energy economics and finance.},
  archive      = {J_NEUCOM},
  author       = {Yuan Zhao and Yaohui Huang and Zhijin Wang and Xiufeng Liu},
  doi          = {10.1016/j.neucom.2024.127470},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127470},
  shortjournal = {Neurocomputing},
  title        = {A new feature selection method based on importance measures for crude oil return forecasting},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GRAformer: A gated residual attention transformer for
multivariate time series forecasting. <em>NEUCOM</em>, <em>581</em>,
127466. (<a href="https://doi.org/10.1016/j.neucom.2024.127466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent Neural Networks (RNNs), particularly when equipped with output windows – a standard practice in contemporary time series forecasting – have shown proficiency in handling short-term dependencies. Nonetheless, RNNs can encounter challenges in maintaining hidden states over extended forecasting periods, particularly in longer-term predictions where increased hidden state sizes and extended look-back windows can lead to gradient instability. In contrast, Transformer-based models, with their distinctive architecture designed to encode complex contextual relationships and enable computations to be done in parallel, are emerging as a popular alternative in this field. However, current research has mainly focused on modifying attention mechanisms, overlooking opportunities to improve the feedforward layer, which could lead to efficiency limitations. Moreover, prevailing methods often assume absolute independence between channels, disregarding distinct features among variables and failing to fully leverage channel-specific information. To address these gaps, we propose an efficient transformer design for multivariate time series prediction. Our approach integrates two key components: (i) a gated residual attention unit that enhances predictive accuracy and computational efficiency, and (ii) a channel embedding technique that differentiates between series and boosts performance. Theoretically, we prove that our model has recurrent dynamics introduced by the RNN layer. Through extensive experiments on real-world data, we demonstrate that our proposed method achieves competitive predictive accuracy compared to prior approaches while exhibiting accelerated processing relative to state-of-the-art transformers. Our code, data, and trained models are available at https://github.com/MythosAd/GRAformer .},
  archive      = {J_NEUCOM},
  author       = {Chengcao Yang and Yutian Wang and Bing Yang and Jun Chen},
  doi          = {10.1016/j.neucom.2024.127466},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127466},
  shortjournal = {Neurocomputing},
  title        = {GRAformer: A gated residual attention transformer for multivariate time series forecasting},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The cybersecurity mesh: A comprehensive survey of involved
artificial intelligence methods, cryptographic protocols and challenges
for future research. <em>NEUCOM</em>, <em>581</em>, 127427. (<a
href="https://doi.org/10.1016/j.neucom.2024.127427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world, it is vital to have strong cybersecurity measures in place. To combat the ever-evolving threats, adopting advanced models like cybersecurity mesh is necessary to enhance our protection. Cybersecurity mesh is an architecture scalable, flexible, composable, robust and resilient and allows the interoperability and coordination between intelligent systems to provide security services. Designing a cybersecurity mesh faces three major challenges: scalability, distributed or federated systems, and technology integration. For the design, it is necessary to apply security tools that support scalability because millions and millions of data are stored, processed, and analysed. Federated systems are needed to improve interoperability in a decentralized cybersecurity mesh. However, it can be tough to integrate different security tools and communication protocols. Cryptographic algorithms and AI models like federated learning, swarming intelligence and blockchain technologies are useful for security services. It is essential to study the integration of existing methods to determine the best technology for the job. We conduct a comprehensive analysis of intelligent systems, including federated learning, blockchain technology, and swarming intelligence, with a particular focus on how they have been and can be used to enhance cybersecurity. We examine the latest trends in these technologies, explore their connections, and weigh the pros and cons of each approach. To conduct this review, we utilized the Web of Science and Scopus databases and followed the PRISMA guidelines.},
  archive      = {J_NEUCOM},
  author       = {Bruno Ramos-Cruz and Javier Andreu-Perez and Luis Martínez},
  doi          = {10.1016/j.neucom.2024.127427},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127427},
  shortjournal = {Neurocomputing},
  title        = {The cybersecurity mesh: A comprehensive survey of involved artificial intelligence methods, cryptographic protocols and challenges for future research},
  volume       = {581},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical vector transformer vehicle trajectories
prediction with diffusion convolutional neural networks.
<em>NEUCOM</em>, <em>580</em>, 127526. (<a
href="https://doi.org/10.1016/j.neucom.2024.127526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dynamic and interactive autonomous driving scenarios, accurately predicting the future movements of vehicle agents is crucial. However, current methods often fail to capture trajectory uncertainty, leading to limitations in trajectory prediction performance. To address these limitations, this paper introduces the hierarchical vector transformer diffusion model, a novel trajectory prediction method that prioritizes both speed and accuracy. The proposed model decomposes the traffic scene modeling into local patches and global interactions, allowing for the acquisition of relevant environmental and global information. Moreover, a local diffusion encoder is employed to effectively capture the aleatoric uncertainty. The proposed model utilizes an adaptive graph structure to exploit the spatial and temporal relationships inherent in the trajectory data. By employing a graph diffusion process, the model effectively captures dynamic features from the historical trajectory information. Moreover, the model demonstrates adaptability by dynamically adjusting to diverse trajectory data and scenarios, thereby enabling the generation of predicted trajectories that are uncertainty aware. This approach contributes to more effective and efficient modeling of dynamic autonomous driving scenarios. Experimental results demonstrate the superior speed and accuracy of the proposed method compared to existing approaches for trajectory prediction. The proposed method significantly enhances prediction accuracy, achieving results of ADE 0.68 and FDE 1.02 on the Argoverse dataset. In comparison to the baseline model, there are notable improvements in ADE and FDE by 0.03 and 0.06, respectively. It is noteworthy that this method also reduces the inference time by 7% when compared to the currently fastest method.},
  archive      = {J_NEUCOM},
  author       = {Yingjuan Tang and Hongwen He and Yong Wang},
  doi          = {10.1016/j.neucom.2024.127526},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127526},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical vector transformer vehicle trajectories prediction with diffusion convolutional neural networks},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recurrent context layered radial basis function neural
network for the identification of nonlinear dynamical systems.
<em>NEUCOM</em>, <em>580</em>, 127524. (<a
href="https://doi.org/10.1016/j.neucom.2024.127524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel recurrent context layered radial basis function neural network (RCLRBFNN) for the identification of nonlinear dynamical systems. The proposed model consists of an additional context layer in which the nodes represent the unit-delayed outputs of the hidden layer radial centers. These delayed outputs undergo a nonlinear transformation by applying a tangent hyperbolic function. These transformed signals connect to the output layer neuron through the adjustable context layered weights. To tune the parameters of the proposed model the update equations are derived using the dynamic back-propagation algorithm. Further, an adaptive learning rate scheme is proposed to improve the performance of the learning algorithm. In the simulation experiment, a total of two examples are considered to test the efficacy and performance of the proposed model. The performance comparison is made with the conventional structure of the radial basis function neural network (RBFNN), Jordan Recurrent neural network (JRNN), and the feed-forward neural network (FFNN) (which is nothing but a single-layered multi-layered perceptron). Both the disturbance signal as well as system’s uncertainty scenarios are considered to test the robustness shown by the proposed model. The results showed that the proposed model has delivered a better identification accuracy as compared to the other neural models.},
  archive      = {J_NEUCOM},
  author       = {Rajesh Kumar},
  doi          = {10.1016/j.neucom.2024.127524},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127524},
  shortjournal = {Neurocomputing},
  title        = {Recurrent context layered radial basis function neural network for the identification of nonlinear dynamical systems},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). DARTS-PT-CORE: Collaborative and regularized
perturbation-based architecture selection for differentiable NAS.
<em>NEUCOM</em>, <em>580</em>, 127522. (<a
href="https://doi.org/10.1016/j.neucom.2024.127522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DARTS-PT is a well-known differentiable NAS method that measures the operation strength through its contribution to the supernet performance, extracting architecture from the underlying supernet. However, persistent issues of degraded architecture in DARTS-PT have been identified in recent studies. In response, we undertake a comprehensive analysis of this performance degradation issue and identify two primary contributing factors: the unfavorable competition among correlated operations during the operation selection process and the unfair advantage of parameter-free operations within DARTS-PT supernet. Building upon these findings, we propose DARTS-PT-CORE, a novel architecture selection algorithm that incorporates a collaborative operation competition mechanism and a regularization technique in the perturbation-based architecture selection approach. Our method aims to mitigate the negative effects of competition among correlated operations, yielding more reliable operation contribution scores. Furthermore, our regularization technique addresses the unfair advantage of parameter-free operations, facilitating a more balanced architecture selection process. Extensive experiments conducted on various datasets and search spaces indicate that DARTS-PT-CORE outperforms other state of-the-art methods. Specifically, in the DARTS search space, DARTS-PT-CORE achieves 2.43% test error on CIFAR10 and 16.23% test error on CIFAR100, while the search time is less than 0.8 GPU days. When transferring to ImageNet, DARTS-PT-CORE achieves 24.97% top-1 error. Such results underscore the effectiveness of our method in enhancing the reliability and balance of architecture selection in differentiable NAS.},
  archive      = {J_NEUCOM},
  author       = {Weisheng Xie and Hui Li and Xuwei Fang and Shaoyuan Li},
  doi          = {10.1016/j.neucom.2024.127522},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127522},
  shortjournal = {Neurocomputing},
  title        = {DARTS-PT-CORE: Collaborative and regularized perturbation-based architecture selection for differentiable NAS},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). An interpretable lightweight deep network with
ℓp(0&lt;p&lt;1) model-driven for single image super-resolution.
<em>NEUCOM</em>, <em>580</em>, 127521. (<a
href="https://doi.org/10.1016/j.neucom.2024.127521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to address the expensive computation cost of deep networks, some Single Image Super-Resolution (SISR) methods tried to design the lightweight networks by means of recursion or expert prior. However, they discuss the theoretical interpretation for the network’s design less. To address this issue, we propose a novel method for constructing an interpretable lightweight deep network for SISR by fusing the idea of model-driven and data-driven. That is, we give a theoretical interpretation for the lightweight network’s design from the optimization model of image degeneration. Considering that ℓ p ( 0 &lt; p &lt; 1 ) ℓp(0&amp;lt;p&amp;lt;1) -norm is sparser than the ℓ 1 ℓ1 -norm and can describe the noises of image degeneration better, our proposed SISR method firstly deduces an iteration algorithm from the ℓ p ( 0 &lt; p &lt; 1 ) ℓp(0&amp;lt;p&amp;lt;1) degeneration model. Then according to this theoretical deduction, an effective deep network is designed. Since our proposed deep network is designed according to the iteration algorithm, our network can not only realize the lightweight structure because of the weight sharing decided by the iterative principle, but also show a theoretical interpretation for designing the deep network. Extensive experimental results illustrate that our proposed method is superior to some related popular SISR methods with the lightweight structure.},
  archive      = {J_NEUCOM},
  author       = {Jianwei Zhao and Zhongfan Sun and Zhenghua Zhou and Tingwei Wang and Dabao Zhang and Jian Yang},
  doi          = {10.1016/j.neucom.2024.127521},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127521},
  shortjournal = {Neurocomputing},
  title        = {An interpretable lightweight deep network with ℓp(0&lt;p&lt;1) model-driven for single image super-resolution},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-free adaptive optimal control for nonlinear
multiplayer games with input disturbances. <em>NEUCOM</em>,
<em>580</em>, 127519. (<a
href="https://doi.org/10.1016/j.neucom.2024.127519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate a model-free identifier-critic-based optimal adaptive controller for multiplayer games with the input disturbances. Specifically, we first adopt the identifier neural network to identify the system dynamics. Simultaneously, we use the critic neural network to estimate the optimal cost function thereby obtaining the estimated optimal controller. Further taking the input disturbances into consideration, we add a feedback gain into the estimated optimal controller so as to obtain the controller. The learning of the identifier and critic network is online and simultaneous. Then, we analyze the stability of the proposed approach. Eventually, the simulation results illustrate the validity of the proposed controller.},
  archive      = {J_NEUCOM},
  author       = {Jing Shi and Chen Peng and Jin Zhang and Zhihao Zhang and Xiangpeng Xie},
  doi          = {10.1016/j.neucom.2024.127519},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127519},
  shortjournal = {Neurocomputing},
  title        = {Model-free adaptive optimal control for nonlinear multiplayer games with input disturbances},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). EAP: An effective black-box impersonation adversarial patch
attack method on face recognition in the physical world.
<em>NEUCOM</em>, <em>580</em>, 127517. (<a
href="https://doi.org/10.1016/j.neucom.2024.127517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition models and systems based on deep neural networks are vulnerable to adversarial examples. However, existing attacks on face recognition are either impractical or ineffective for black-box impersonation attacks in the physical world. In this paper, we propose EAP, an effective black-box impersonation attack method on face recognition in the physical world. EAP generates adversarial patches that can be printed by mobile and compact printers and attached to the source face to fool face recognition models and systems. To improve the transferability of adversarial patches, our approach incorporates random similarity transformations and image pyramid strategies, increasing input diversity. Furthermore, we introduce a meta-ensemble attack strategy that harnesses multiple pre-trained face models to extract common gradient features. We evaluate the effectiveness of EAP on two face datasets, using 16 state-of-the-art face recognition backbones, 9 heads, and 5 commercial systems. Moreover, we conduct physical experiments to substantiate its practicality. Our results demonstrate that EAP is capable of effectively executing impersonation attacks against state-of-the-art face recognition models and systems in both digital and physical environments.},
  archive      = {J_NEUCOM},
  author       = {Xiaoliang Liu and Furao Shen and Jian Zhao and Changhai Nie},
  doi          = {10.1016/j.neucom.2024.127517},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127517},
  shortjournal = {Neurocomputing},
  title        = {EAP: An effective black-box impersonation adversarial patch attack method on face recognition in the physical world},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bumpless transfer consensus control for linear multi-agent
systems under agent-dependent switching directed topologies.
<em>NEUCOM</em>, <em>580</em>, 127515. (<a
href="https://doi.org/10.1016/j.neucom.2024.127515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bumpless transfer consensus control problem for linear homogeneous multi-agent systems subject to agent-dependent switching directed communication topologies is investigated in this paper. According to the information of graph Laplacian matrix and relative state of agent, we propose a novel agent-dependent switching law to guide the switching among these topologies, then the leader-following consensus performance of multi-agent systems is achieved via using the multiple Lyapunov functions method. Further, since the switching consensus controllers are considered, the control signal bumps are inevitable at switching instants, and some sufficient conditions via linear matrix inequalities are developed to pursue the bumpless transfer performance of multi-agent systems. Besides, the agent-dependent switching law also allows the error dynamics under each directed subtopology to be unstabilizable. Finally, the theoretical results are verified by two illustrative examples.},
  archive      = {J_NEUCOM},
  author       = {Guangxu He and Jun Zhao},
  doi          = {10.1016/j.neucom.2024.127515},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127515},
  shortjournal = {Neurocomputing},
  title        = {Bumpless transfer consensus control for linear multi-agent systems under agent-dependent switching directed topologies},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A nonlocal feature self-similarity based tensor completion
method for video recovery. <em>NEUCOM</em>, <em>580</em>, 127513. (<a
href="https://doi.org/10.1016/j.neucom.2024.127513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nuclear norm-based tensor completion method effectively recovers missing multidimensional data in videos by minimizing the truncated nuclear norm. However, the conventional thresholding approach might overly punish larger singular values, which leads to loss of faithful information. In order to overcome this challenge, an improved model of the truncated nuclear norm-based tensor completion is proposed. This improved model is designed to incorporate information related to the prior rank and ensure the preservation of essential singular values to improve the approximation of the matrix rank. First, a video tensor is decomposed into matrices along different modes, and these matrices are divided into similar block matrices by using the K-means＋＋ clustering method, which utilizes the non-local similarity to reduce the influence of noise in the video. Afterwards, a ranking algorithm based on noise matrix analysis is used, which automatically gets the truncated threshold by iterative optimization. Additionally, we propose back-projection method to balance local and global optimization. Finally, to evaluate our proposal, extensive experimental evaluations have been carried out and show that our approach outperforms a lot of recent tensor completion techniques in terms of quality metrics and visual impact.},
  archive      = {J_NEUCOM},
  author       = {Shoupeng Lu and Peng Wang and Wenhui Zhu and Cheng Dai and Ying Zhang and Chuanjie Liu and Shengxin Dai},
  doi          = {10.1016/j.neucom.2024.127513},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127513},
  shortjournal = {Neurocomputing},
  title        = {A nonlocal feature self-similarity based tensor completion method for video recovery},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). ZVQAF: Zero-shot visual question answering with feedback
from large language models. <em>NEUCOM</em>, <em>580</em>, 127505. (<a
href="https://doi.org/10.1016/j.neucom.2024.127505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the prominent zero-shot generalization in new language tasks shown by large language models (LLMs), applying LLMs for zero-shot visual question answering (VQA) has been a new trend. However, most prior approaches directly use off-the-shelf captioning models to generate captions that compose in-context examples for LLMs, and such generated captions may be uninformative, thus leading the LLMs to give false predictions. To address this, we propose zero-shot VQA with feedback from LLMs (ZVQAF), a framework that applies LLMs to discriminate the quality of generated captions and leverages this feedback to train the captioning model. ZVQAF consists of two stages: the first stage is the training with feedback, which enables the captioning model to recognize the task objective and information requirements from the LLM, and the second stage is utilizing the optimized captioning model and LLM for inference. Extensive experiments show that ZVQAF achieves zero-shot VQA performance that is comparable or even superior to those previous zero-shot, few-shot, and end-to-end training approaches. For example, on VQAv2 test dataset, ZVQAF outperforms Flamingo (Alayrac et al., 2022) which employs end-to-end training by a large margin of 8.0%. In addition, on A-OKVQA dataset, ZVQAF outperforms zero-shot method Img2LLM (Guo et al., 2023) by 3.8% when employing LLMs with similar scales.},
  archive      = {J_NEUCOM},
  author       = {Cheng Liu and Chao Wang and Yan Peng and Zhixu Li},
  doi          = {10.1016/j.neucom.2024.127505},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127505},
  shortjournal = {Neurocomputing},
  title        = {ZVQAF: Zero-shot visual question answering with feedback from large language models},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive attention fusion network for cross-device GUI
element re-identification in crowdsourced testing. <em>NEUCOM</em>,
<em>580</em>, 127502. (<a
href="https://doi.org/10.1016/j.neucom.2024.127502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of mobile devices has ushered in an era of different device platforms. Different devices require a consistent user experience, especially with similar graphical user interfaces (GUIs). However, the different code bases of the various operating systems as well as the different GUI layouts and resolutions of the various devices pose a challenge for automated software testing. Crowdsourced software testing (CST) has emerged as a viable solution where crowdsourced workers perform tests on their own devices and provide detailed bug reports. Although CST is cost-effective, it is not very efficient and requires a large number of workers for manual testing. The potential of optimizing CST reproduction testing through computer vision remains largely untapped, especially when considering the uniformity of GUI elements on different devices. In this study, we present a novel deep learning model specifically designed to re-identify GUI elements in CST reproduction test scenarios, regardless of the underlying code changes on different devices. The model features a robust backbone network for feature extraction, an innovative attention mechanism with learnable factors to enhance the features of GUI elements and minimize interference from their backgrounds, and a classifier to determine matching labels for these elements. Our approach was validated on a large GUI element dataset containing 31,098 element images for training, 115,704 element images from real apps for testing, and 67 different background images. The results of our experiments underline the excellent accuracy of the model and the importance of each component. This work is a major step forward in improving the efficiency of reproduction testing in CST. The innovative solutions we propose could further reduce labor costs for CST platforms.},
  archive      = {J_NEUCOM},
  author       = {Li Zhang and Wei-Tek Tsai},
  doi          = {10.1016/j.neucom.2024.127502},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127502},
  shortjournal = {Neurocomputing},
  title        = {Adaptive attention fusion network for cross-device GUI element re-identification in crowdsourced testing},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SOIRP: Subject-object interaction and reasoning path based
joint relational triple extraction by table filling. <em>NEUCOM</em>,
<em>580</em>, 127492. (<a
href="https://doi.org/10.1016/j.neucom.2024.127492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint relational triple extraction methods based on table filling have gained considerable attention in recent years due to remarkable effectiveness and capabilities of extracting relational triples from complicated sentences. However, most of the existing methods disregard the impact of the information interaction between the subject and object in the relational triple and the intrinsic association among relational triples on relational overlapping triples extraction, resulting in the inability to extract the relational triples hidden in the sentence. Furthermore, previous sequence annotation methods failed to consider the case of entity nesting. Therefore, there is still room for improving the relational overlap problem and entity nesting problem. To address this issue, we propose a new joint relational triple extraction model based on table filling, SOIRP, which contains a Subject-Object Interaction (SOI) module consisting of several different interactions and a Reasoning Path Extraction (RPE) module based on the idea of decoder module in Transformer. We refine the subject-object interaction information captured by the former and the path inference information captured by the latter through multiple iterations. In addition, we introduce a new table filling method and decoding strategy, which can capture all entities in each sentence and align the boundary tokens of entity pairs for each relation. We evaluate our proposed model on two public datasets and the experimental results demonstrate that our model outperforms the baseline model. The code of our model can be available at: https://github.com/valentiner/SOIPR .},
  archive      = {J_NEUCOM},
  author       = {Qicai Dai and Wenzhong Yang and Liejun Wang and Fuyuan Wei and Meimei Tuo},
  doi          = {10.1016/j.neucom.2024.127492},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127492},
  shortjournal = {Neurocomputing},
  title        = {SOIRP: Subject-object interaction and reasoning path based joint relational triple extraction by table filling},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fixed-precision randomized quaternion singular value
decomposition algorithm for low-rank quaternion matrix approximations.
<em>NEUCOM</em>, <em>580</em>, 127490. (<a
href="https://doi.org/10.1016/j.neucom.2024.127490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fixed-precision randomized quaternion singular value decomposition algorithm (FPRQSVD) is presented to compute the low-rank quaternion matrix approximation. The FPRQSVD algorithm estimates the appropriate rank according to the given tolerance without a predetermined rank parameter, and computes the corresponding low-rank quaternion matrix approximation automatically. Error analysis indicates that the FPRQSVD algorithm is mathematically equivalent to the randomized quaternion singular value decomposition algorithm. Numerical experiments are given to demonstrate that the FPRQSVD algorithm is feasible and effective. Moreover, we use it to deal with the problem of color image inpainting.},
  archive      = {J_NEUCOM},
  author       = {Yonghe Liu and Fengsheng Wu and Maolin Che and Chaoqian Li},
  doi          = {10.1016/j.neucom.2024.127490},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127490},
  shortjournal = {Neurocomputing},
  title        = {Fixed-precision randomized quaternion singular value decomposition algorithm for low-rank quaternion matrix approximations},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DESReg: Dynamic ensemble selection library for regression
tasks. <em>NEUCOM</em>, <em>580</em>, 127487. (<a
href="https://doi.org/10.1016/j.neucom.2024.127487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, regression is a very demanded predictive task to solve a wide range of problems belonging to different research and society areas. Examples of applications include industry, economic, medical and energy fields. Ensemble methodology works by merging the output obtained from a set of base methods (learners), achieving successful results in both classification and regression tasks. Traditional ensembles use the output of the whole set of base methods, in a static way, to obtain the result of the ensemble. However, latest studies show that dynamic selection of learners or even dynamic aggregation of their outputs produce better results. Methodologies that integrate these techniques are called dynamic ensembles or dynamic ensemble selection. Although the literature and tools to work with dynamic ensembles for classification tasks is abundant, for regression tasks these resources are scarcer. This paper aims to mitigate these shortcomings by presenting a library for the design, development and execution of dynamic ensembles for regression problems. Specifically, the Python software package DESReg is presented. This library allows us to access to the latest dynamic ensemble techniques in the field, standing out for its high configurability, its support for extending it with user-defined functions or its parallel computation capabilities.},
  archive      = {J_NEUCOM},
  author       = {María D. Pérez-Godoy and Marta Molina and Francisco Martínez and David Elizondo and Francisco Charte and Antonio J. Rivera},
  doi          = {10.1016/j.neucom.2024.127487},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127487},
  shortjournal = {Neurocomputing},
  title        = {DESReg: Dynamic ensemble selection library for regression tasks},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain adaptive remote sensing image semantic segmentation
with prototype guidance. <em>NEUCOM</em>, <em>580</em>, 127484. (<a
href="https://doi.org/10.1016/j.neucom.2024.127484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current unsupervised domain adaptation (UDA) techniques in semantic segmentation effectively decrease the domain discrepancy between the labeled source domain and unlabeled target domain, thereby enhancing the model’s pixel-wise discriminative capability for target domain data. However, in remote sensing images (RSIs), our study uncovers that these approaches perform poorly in the presence of class distribution inconsistencies between the source and target domains. In this work, we propose a one-stage mean teacher framework with a novel auxiliary prototype classifier, named MTA, to address this issue. Specifically, the teacher model assigns pseudo labels at pixel level for target samples and captures knowledge from the student model via exponential moving average (EMA). With labeled source samples and target samples that have pseudo labels, the student model can alleviate the divergence between the source and target domains. In addition, the auxiliary prototype classifier (APC) reduces the performance degradation in the parametric softmax classifier of the student model caused by class distribution divergence. We also propose a prototype computation scheme to obtain each class prototype in the APC. Specifically, we build a memory bank for each class of the two domains to store feature embeddings dynamically. Then, we compute the class prototype by applying the clustering algorithm on memory banks corresponding to the class. Meanwhile, the APC reduces the intra-class domain discrepancy by optimizing the cross-entropy loss, which brings each class feature distribution of the two domains closer to the class prototype. The experimental results on RSIs UDA semantic segmentation tasks show the superiority of our approach over comparative methods.},
  archive      = {J_NEUCOM},
  author       = {Wankang Zeng and Ming Cheng and Zhimin Yuan and Wei Dai and Youming Wu and Weiquan Liu and Cheng Wang},
  doi          = {10.1016/j.neucom.2024.127484},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127484},
  shortjournal = {Neurocomputing},
  title        = {Domain adaptive remote sensing image semantic segmentation with prototype guidance},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A motion-aware and temporal-enhanced spatial–temporal graph
convolutional network for skeleton-based human action segmentation.
<em>NEUCOM</em>, <em>580</em>, 127482. (<a
href="https://doi.org/10.1016/j.neucom.2024.127482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action segmentation task is an important approach for understanding the actions from the video. Most of the conventional action recognition tasks can recognize only a single action from a given input video, thus we need to input a pre-trimmed video containing only one type of action. In contrast, temporal action segmentation (TAS) aims to segment a temporally untrimmed video sequence by time. Consequently, it has wider application prospects in various fields. Previously proposed TAS-based methods use only RGB color video as input to segment the actions, but RGB video is not robust against diverse backgrounds. Whereas skeleton-based features are more resilient as they do not incorporate any background information but there has been limited research exploring this feature modality. To this end, we propose a motion-aware and temporal-enhanced spatial–temporal graph convolutional network for the skeleton-based human action segmentation. Our framework contains a motion-aware module, multi-scale temporal convolutional network, temporal-enhanced graph convolutional network module and a refinement module. Our method can efficiently capture the motion information and long-range dependencies using skeleton features while improving temporal modeling. We have conducted experiments using four publicly available datasets to demonstrate the effectiveness of our introduced method. The code is available at https://github.com/11yxk/openpack .},
  archive      = {J_NEUCOM},
  author       = {Shurong Chai and Rahul Kumar Jain and Jiaqing Liu and Shiyu Teng and Tomoko Tateyama and Yinhao Li and Yen-Wei Chen},
  doi          = {10.1016/j.neucom.2024.127482},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127482},
  shortjournal = {Neurocomputing},
  title        = {A motion-aware and temporal-enhanced Spatial–Temporal graph convolutional network for skeleton-based human action segmentation},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph-based geometric structure line parsing.
<em>NEUCOM</em>, <em>580</em>, 127481. (<a
href="https://doi.org/10.1016/j.neucom.2024.127481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Line drawings by artists capture the organization, relationships, and semantics of observable objects. To endow machines with similar capacities and improve the storage and processing of such drawings, we investigate uniform representation and learning of hetero-dimensional line drawings. For this, nonlinear curves are first approximated as paths, resulting in node detection and link prediction (LP). An end-to-end trainable neural network is then developed for parsing structural-semantic sketches from images based on such representations. In particular, node regression and feature extraction are performed using convolutional neural networks(CNNs), and the prediction of connections is achieved using a graph-based encoder–decoder architecture. We provide a topology-guided graph initialization strategy, which increases the accuracy of LP but also greatly minimizes the self-overlapping among predicted paths. We also develop a semi-automatic toolkit for annotation generation, as well as a dataset for understanding structural sketches—the first large parametric dataset consistent with human visual perception. Through comparative experiments and ablation studies, we demonstrate the advantages and effectiveness of our methods.},
  archive      = {J_NEUCOM},
  author       = {Feng Li and Gang Li and Bin He and Ping Lu and Bin Cheng},
  doi          = {10.1016/j.neucom.2024.127481},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127481},
  shortjournal = {Neurocomputing},
  title        = {Graph-based geometric structure line parsing},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing long-term person re-identification using global,
local body part, and head streams. <em>NEUCOM</em>, <em>580</em>,
127480. (<a href="https://doi.org/10.1016/j.neucom.2024.127480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the task of long-term person re-identification. Typically, person re-identification assumes that people do not change their clothes, which limits its applications to short-term scenarios. To overcome this limitation, we investigate long-term person re-identification, which considers both clothes-changing and clothes-consistent scenarios. In this paper, we propose a novel framework that effectively learns and utilizes both global and local information. The proposed framework consists of three streams: global, local body part, and head streams. The global and head streams encode identity-relevant information from an entire image and a cropped image of the head region, respectively. Both streams encode the most distinct, less distinct, and average features using the combinations of adversarial erasing, max pooling, and average pooling. The local body part stream extracts identity-related information for each body part, allowing it to be compared with the same body part from another image. Since body part annotations are not available in re-identification datasets, pseudo-labels are generated using clustering. These labels are then utilized to train a body part segmentation head in the local body part stream. The proposed framework is trained by backpropagating the weighted summation of the identity classification loss, the pair-based loss, and the pseudo body part segmentation loss. To demonstrate the effectiveness of the proposed method, we conducted experiments on three publicly available datasets (Celeb-reID, PRCC, and VC-Clothes). The experimental results demonstrate that the proposed method outperforms the previous state-of-the-art method.},
  archive      = {J_NEUCOM},
  author       = {Duy Tran Thanh and Yeejin Lee and Byeongkeun Kang},
  doi          = {10.1016/j.neucom.2024.127480},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127480},
  shortjournal = {Neurocomputing},
  title        = {Enhancing long-term person re-identification using global, local body part, and head streams},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Learning a physics-based filter attachment for
hyperspectral imaging with RGB cameras. <em>NEUCOM</em>, <em>580</em>,
127474. (<a href="https://doi.org/10.1016/j.neucom.2024.127474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Countless RGB cameras are ubiquitously distributed in our daily lives, serving to perceive and depict the diverse colors of the world. Reconstructing hyperspectral images (HSI) from these trichromatic cameras emerges as a promising solution to address the limitations of existing, costly hyperspectral imaging systems. The performance of HSI reconstruction relies heavily on the camera spectral response (CSR). Thus, designing a better CSR and putting it into practice is the critical issue for RGB-based HSI reconstruction. However, the CSR curves designed in the existing works are overly random, making them challenging to manufacture directly. Additionally, the designed CSR curves require modifications to the camera hardware, resulting in the loss of RGB imaging functionality. In this paper, we propose a hyperspectral imaging system, which involves enhancing the CSR curve of existing RGB cameras and preserving RGB imaging functionality by adding a learnable physics-based spectral filter. Specifically, we first parameterize the spectral filter transmittance as a function of the filter thicknesses, based on the physical constraints of the multilayer interference principle. Then, we propose a joint optimization framework in which the thicknesses of the filter and the hyperspectral reconstruction network are optimized. In this manner, the thicknesses of the filter are obtained and used to manufacture the filter directly. Finally, we construct a prototype and verify the benefits of our spectral filter design method through experiments including both synthetic data and real images.},
  archive      = {J_NEUCOM},
  author       = {Maoqing Zhang and Lizhi Wang and Lin Zhu and Hua Huang},
  doi          = {10.1016/j.neucom.2024.127474},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127474},
  shortjournal = {Neurocomputing},
  title        = {Learning a physics-based filter attachment for hyperspectral imaging with RGB cameras},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CSPFormer: A cross-spatial pyramid transformer for visual
place recognition. <em>NEUCOM</em>, <em>580</em>, 127472. (<a
href="https://doi.org/10.1016/j.neucom.2024.127472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the Vision Transformer (ViT), which applied the Transformer structure to various visual detection tasks, has outperformed convolutional neural networks (CNNs). Nonetheless, due to the lack of scale representation ability of the Transformer, how to extract the local features of the scene to effectively form a global descriptor is still a challenging problem. In the paper, we propose a Cross-Spatial Pyramid Transformer (CSPFormer) to learn the discriminative global descriptors from multi-scale visual features for efficient visual place recognition. Specifically, we first develop a pyramid CNN module that can extract multi-scale visual feature representations. Then, the extracted feature representations of multi-scales are input to multiple connected spatial pyramid Transformer modules that adaptively learn the spatial relationship of the different scale descriptors, where the multiple self-attention is applied to learn a global descriptor from discriminative local descriptors. CNN pyramid features and Transformer multi-scale features are mutually weighted to perform cross-spatial feature representation. The multiple self-attention enhances the long-term dependencies of multi-scale visual descriptors and reduces the computational cost. To obtain the final place-matching result accurately, the cosine function is used to calculate the spatial similarity between the two scenes. Experimental results on public place datasets show that the proposed method achieves state-of-the-art on large-scale visual place recognition tasks. Our model has achieved 94.7%, 92.8%, 91.3%, and 95.7% average recall based on the top 1% candidate scenario on KITTI, Nordland, VPRICE, and EuRoc datasets, respectively.},
  archive      = {J_NEUCOM},
  author       = {Zhenyu Li and Pengjie Xu},
  doi          = {10.1016/j.neucom.2024.127472},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127472},
  shortjournal = {Neurocomputing},
  title        = {CSPFormer: A cross-spatial pyramid transformer for visual place recognition},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-intrusive speech quality assessment: A survey.
<em>NEUCOM</em>, <em>580</em>, 127471. (<a
href="https://doi.org/10.1016/j.neucom.2024.127471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech quality is a critical consideration for applications such as speech enhancement, coding, transmission, and synthesis. Accurately evaluating the quality of degraded speech without a reference is particularly challenging. As a result, non-intrusive speech quality assessment has been extensively researched due to its efficiency and ease of deployment. This survey comprehensively reviews these studies. Commonly used speech quality assessment databases are reviewed, as they serve as validation sets for objective metrics. Non-intrusive speech quality assessment methods are categorized and reviewed, and the performance of state-of-the-art and classical speech quality assessment methods is compared. The survey presents an overview of classic algorithms and recent advancements in the field of non-intrusive speech quality assessment.},
  archive      = {J_NEUCOM},
  author       = {Kailai Shen and Diqun Yan and Jing Hu and Zhe Ye},
  doi          = {10.1016/j.neucom.2024.127471},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127471},
  shortjournal = {Neurocomputing},
  title        = {Non-intrusive speech quality assessment: A survey},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised domain adaptation on graphs with contrastive
learning and minimax entropy. <em>NEUCOM</em>, <em>580</em>, 127469. (<a
href="https://doi.org/10.1016/j.neucom.2024.127469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label scarcity in a graph is frequently encountered in real-world applications due to the high cost of data labeling. To this end, semi-supervised domain adaptation (SSDA) on graphs aims to leverage the knowledge of a labeled source graph to aid in node classification on a target graph with limited labels. SSDA tasks need to overcome the domain gap between the source and target graphs. However, to date, this challenging research problem has yet to be formally considered by the existing approaches designed for cross-graph node classification. This paper proposes a novel method called SemiGCL to tackle the graph Semi -supervised domain adaptation with G raph C ontrastive L earning and minimax entropy training. SemiGCL generates informative node representations by contrasting the representations learned from a graph’s local and global views. Additionally, SemiGCL is adversarially optimized with the entropy loss of unlabeled target nodes to reduce domain divergence. Experimental results on benchmark datasets demonstrate that SemiGCL outperforms the state-of-the-art baselines on the SSDA tasks.},
  archive      = {J_NEUCOM},
  author       = {Jiaren Xiao and Quanyu Dai and Xiao Shen and Xiaochen Xie and Jing Dai and James Lam and Ka-Wai Kwok},
  doi          = {10.1016/j.neucom.2024.127469},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127469},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised domain adaptation on graphs with contrastive learning and minimax entropy},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MRSLN: A multimodal residual speaker-LSTM network to
alleviate the over-smoothing issue for emotion recognition in
conversation. <em>NEUCOM</em>, <em>580</em>, 127467. (<a
href="https://doi.org/10.1016/j.neucom.2024.127467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Emotion Recognition in Conversation (ERC) plays a significant role in the field of human–computer intelligent interaction since it enables computers to perceive and infer the emotions expressed by the individuals, thereby intelligently responding to them. Most of current ERC methods pay more attention to modeling the complex interaction between different modalities. However, the features extracted by their unimodal networks are over-smoothed and may contain insufficient intra-speaker contextual information, which results in suboptimal results. In this paper, we focus on the unimodal learning and propose a simple late fusion framework named Multimodal Residual Speaker-LSTM Network (MRSLN), which uses speaker information to directly model inter-speaker and intra-speaker dependency, rather than fuse it into the learned features. MRSLN uses the speaker-LSTM consisting of the inter-speaker LSTM, intra-speaker LSTM, and the residual network between the input and output of the inter-speaker LSTM. Our proposed method can alleviate the issue of over-smoothing in deep Long Short Term Memory (LSTM) network and also incorporate additional intra-speaker contextual information. Extensive experiments conducted on IEMOCAP and MELD datasets demonstrate that MRSLN effectively captures inter-speaker and intra-speaker information and outperforms currently complex state-of-the-art (SOTA) models in efficiency and classification performance.},
  archive      = {J_NEUCOM},
  author       = {Nannan Lu and Zhen Tan and Jiansheng Qian},
  doi          = {10.1016/j.neucom.2024.127467},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127467},
  shortjournal = {Neurocomputing},
  title        = {MRSLN: A multimodal residual speaker-LSTM network to alleviate the over-smoothing issue for emotion recognition in conversation},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SparseSwin: Swin transformer with sparse transformer block.
<em>NEUCOM</em>, <em>580</em>, 127433. (<a
href="https://doi.org/10.1016/j.neucom.2024.127433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in computer vision research have put transformer architecture as the state-of-the-art in computer vision tasks. One of the known drawbacks of the transformer architecture is the high number of parameters, this can lead to a more complex and inefficient algorithm. This paper aims to reduce the number of parameters and in turn, made the transformer more efficient. We present Sparse Transformer (SparTa) Block, a modified transformer block with an addition of a sparse token converter that reduces the dimension of high-level features to the number of latent tokens. We implemented the SparTa Block within the Swin-T architecture (SparseSwin) to leverage Swin&#39;s proficiency in extracting low-level features and enhance its capability to extract information from high-level features while reducing the number of parameters. The proposed SparseSwin model outperforms other state-of-the-art models in image classification with an accuracy of 87.26%, 97.43%, and 85.35% on the ImageNet100, CIFAR10, and CIFAR100 datasets respectively. Despite its fewer parameters, the result highlights the potential of a transformer architecture using a sparse token converter with a limited number of tokens to optimize the use of the transformer and improve its performance. The code is available at https://github.com/KrisnaPinasthika/SparseSwin .},
  archive      = {J_NEUCOM},
  author       = {Krisna Pinasthika and Blessius Sheldo Putra Laksono and Riyandi Banovbi Putera Irsal and Syifa’ Hukma Shabiyya and Novanto Yudistira},
  doi          = {10.1016/j.neucom.2024.127433},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127433},
  shortjournal = {Neurocomputing},
  title        = {SparseSwin: Swin transformer with sparse transformer block},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Voice-based age, gender, and language recognition based on
ResNet deep model and transfer learning in spectro-temporal domain.
<em>NEUCOM</em>, <em>580</em>, 127429. (<a
href="https://doi.org/10.1016/j.neucom.2024.127429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In personal identity recognition systems, detecting a person&#39;s age, gender, and language using voice signal characteristics is a crucial issue, especially because of the importance of security considerations. Age, gender, and language classification problems are important in signal processing because they are used to analyze and understand human behavior, interactions, and preferences. This can be especially useful in the fields of human-computer interaction, psychology, and social science research. In this paper, a new system for detecting a speaker&#39;s age, gender, and language based on deep learning models is presented. Deep learning models have shown great efficacy in various fields of signal processing. For this paper, a range of deep models were tested, including convolutional neural networks (CNNs), recurrent neural network (RNN), and a fine-tuning ResNet34 architecture. Additionally, techniques such as transfer learning were applied to improve the efficiency of the proposed system. The input voice signals are preprocessed by applying the spectro-temporal transform to obtain additional features that can be fed to the ResNet34 model, which is designed specifically for the task of voice signal processing. The dataset used in this paper was sourced from the Mozilla common voice initiative, which is dedicated to advancing speech recognition and language identification technologies. The performance of the proposed algorithm was evaluated in the presence of Gaussian noise to determine its robustness. The experimental results demonstrated that the proposed algorithm significantly outperformed basic algorithms and other deep neural networks in terms of age and gender recognition from voice signals.},
  archive      = {J_NEUCOM},
  author       = {Samira Mavaddati},
  doi          = {10.1016/j.neucom.2024.127429},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127429},
  shortjournal = {Neurocomputing},
  title        = {Voice-based age, gender, and language recognition based on ResNet deep model and transfer learning in spectro-temporal domain},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LPSRGAN: Generative adversarial networks for
super-resolution of license plate image. <em>NEUCOM</em>, <em>580</em>,
127426. (<a href="https://doi.org/10.1016/j.neucom.2024.127426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a super-resolution algorithm for reconstructing license plate images based on generative adversarial networks (GAN) for improving the recognition rate of low-resolution license plate images. To this end, this paper first designs a new image degradation model, called the n-stage random combination degradation model (n-RCD), which extends the traditional degradation model horizontally and vertically to better simulate the features of low-resolution license plate images in natural scenes. Subsequently, to address the problem that existing GAN models cannot adapt to the complex degradation space in natural scenes, this paper proposes a new network structure called LPSRGAN, which optimizes the SRGAN model from the generator and discriminator to improve its super-resolution capability. In addition, this paper also proposes a perceptual optical character recognition (OCR) loss for license plate images, which defines the connectionist temporal classification (CTC) loss of the output of the OCR network with character label values to better preserve the character details and features of the license plate images. Finally, the experiments reported in this paper show that the proposed algorithm improves the recognition rate of the original low-resolution license plate image by 12.48%, and the recognition rate of the reconstructed image reaches 93.90%. Based on this, this paper also tests the algorithm on actual captured data, and the results show that it performs well in natural scenes, demonstrating the algorithm has broad application prospects.},
  archive      = {J_NEUCOM},
  author       = {Yuecheng Pan and Jin Tang and Tardi Tjahjadi},
  doi          = {10.1016/j.neucom.2024.127426},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127426},
  shortjournal = {Neurocomputing},
  title        = {LPSRGAN: Generative adversarial networks for super-resolution of license plate image},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CAT: Continual adapter tuning for aspect sentiment
classification. <em>NEUCOM</em>, <em>580</em>, 127423. (<a
href="https://doi.org/10.1016/j.neucom.2024.127423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans can continually acquire, improve, and transfer knowledge throughout their lifespan so that they can accurately identify sentiment polarities of the data attributed to different domains. However, the continual learning of incrementally available aspect sentiment classification (ASC) tasks from different domains with non-stationary data distributions remains a long-standing challenge for learning-based models due to the catastrophic forgetting problem, which is the tendency to completely and abruptly forget previously learned knowledge upon learning new knowledge. In this work, we present Continual Adapter Tuning (CAT), a parameter-efficient framework that not only avoids catastrophic forgetting but also enables knowledge transfer from learned ASC tasks to new ASC tasks. To avoid catastrophic forgetting, we only learn and store a task-specific adapter for each ASC task while freezing the backbone pre-trained model. To promote new task learning, we propose a continual adapter initialization technique to transfer knowledge from preceding tasks. Besides, we also develop a novel label-aware contrastive learning to simultaneously learn the features of input samples and the parameters of classifiers in the same space so that we can efficiently classify a sample with the help of label semantics. To eliminate the need for task IDs in testing, we propose a simple yet efficient majority sentiment polarity voting strategy to obtain final sentiment polarities according to the polarities predicted by all reasoning paths in the adapter architecture. Experimental results show the high effectiveness of our CAT by achieving new state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Qiangpu Chen and Jiahua Huang and Wushao Wen and Qingling Li and Rumin Zhang and Jinghui Qin},
  doi          = {10.1016/j.neucom.2024.127423},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127423},
  shortjournal = {Neurocomputing},
  title        = {CAT: Continual adapter tuning for aspect sentiment classification},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application of neuroimaging in diagnosis of focal cortical
dysplasia: A survey of computational techniques. <em>NEUCOM</em>,
<em>580</em>, 127418. (<a
href="https://doi.org/10.1016/j.neucom.2024.127418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Focal Cortical Dysplasia (FCD) is a neurodevelopmental disorder characterized by abnormal neuronal migration, differentiation, and maturation, resulting in a range of clinical symptoms including drug-resistant epilepsy. Accurate and timely diagnosis of FCD is essential for effective treatment and management of patients with this condition. In recent years, there have been significant advances in neuroimaging and machine learning techniques, enabling automated detection of FCD lesions with increasing accuracy and efficiency. In this survey article, we provide an overview of the current state-of-the-art in computational techniques for the automated detection of FCD lesions using neuroimaging. We first introduce some common imaging findings that radiologists look for in FCD lesions, then review the automatic detection techniques studied in the last decade. These techniques have shown promising results in detecting and localizing FCD lesions, improving diagnostic accuracy and reducing misdiagnoses, diagnosis time, and cost of care. We suggest that the use of these types of quantitative image analysis tools and algorithms can play a key role in improving the overall management and outcome of patients with FCD. However, further studies are needed to validate and optimize the performance of these techniques in clinical practice. In summary, the combination of advanced neuroimaging and computational techniques has the potential to revolutionize the diagnosis and treatment of FCD, leading to better outcomes for patients with this condition.},
  archive      = {J_NEUCOM},
  author       = {Zohreh Ganji and Shadi Azizi and Reyhane Faraji and Hoda Zare},
  doi          = {10.1016/j.neucom.2024.127418},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127418},
  shortjournal = {Neurocomputing},
  title        = {Application of neuroimaging in diagnosis of focal cortical dysplasia: A survey of computational techniques},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AdaMO: Adaptive meta-optimization for cold-start
recommendation. <em>NEUCOM</em>, <em>580</em>, 127417. (<a
href="https://doi.org/10.1016/j.neucom.2024.127417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-learning has been proven effective in tackling the cold-start problem of recommendation systems. Most work in this line adopts the meta-optimization idea that learns global knowledge to initialize the base recommender and adapts it for unseen recommendation tasks. Typically, the process is non-adaptive in the sense that both the initialization and model fitting are not task-specific. Such non-adaptive approaches do not work well for the strict cold-start problem, where historical interaction data of the new users is scarce or not available at all. In this paper, we propose a novel adaptive meta-optimization approach, called Ada ptive M eta- O ptimization ( AdaMO ), to address the problem. AdaMO is fully adaptive, namely, it simultaneously customizes the initialization and model fitting according to task-specific information. During the cold-start phase, it aggregates task-specific information with transferred knowledge from all historical tasks to tune the initialization of the base model. In the subsequent warm-up phase, AdaMO mines the adaptive transition information from the behavior patterns and parameter status to effectively fit the model using transitional learning. By making a sophisticated balance between shared knowledge and task-specific information, AdaMO outperforms the state-of-the-art methods in various cold-start scenarios.},
  archive      = {J_NEUCOM},
  author       = {Juhua Pu and Yuanhong Wang and Fang Nan and Xingwu Liu},
  doi          = {10.1016/j.neucom.2024.127417},
  journal      = {Neurocomputing},
  month        = {5},
  pages        = {127417},
  shortjournal = {Neurocomputing},
  title        = {AdaMO: Adaptive meta-optimization for cold-start recommendation},
  volume       = {580},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Infrared colorization with cross-modality zero-shot
learning. <em>NEUCOM</em>, <em>579</em>, 127449. (<a
href="https://doi.org/10.1016/j.neucom.2024.127449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing infrared colorization methods based on image-to-image translation in a GAN framework require paired image data for network learning and are limited by data quality. They are also restricted in their colorization ability to perform spectral translation between infrared bands, specifically, long-wave infrared colorization methods cannot be directly applied to the near-infrared modality. This paper proposes a novel infrared colorization algorithm that leverages similarities in high-frequency features between visible and infrared images. The method achieves infrared colorization through frequency domain feature decoupling and reconstruction. By decoupling high-frequency and low-frequency features in the frequency domain, it retains similar high-frequency features and reconstructs removed low-frequency features. The network is trained using visible images, enabling cross-modality zero-shot learning, eliminating the need for infrared datasets during training. During inference, the low-frequency information of the infrared image’s frequency domain is removed, and the visible low-frequency information is supplemented using the trained network’s reconstruction capability, resulting in the desired coloring effect. The method is equipped with multi-modality cross-spectral colorization capability and performs well on multiple infrared spectral colorization tasks. The experimental results fully demonstrate the excellent cross-modality adaptability and broad spectral colorization capability of the method.},
  archive      = {J_NEUCOM},
  author       = {Chiheng Wei and Huawei Chen and Lianfa Bai and Jing Han and Xiaoyu Chen},
  doi          = {10.1016/j.neucom.2024.127449},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127449},
  shortjournal = {Neurocomputing},
  title        = {Infrared colorization with cross-modality zero-shot learning},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A variance-constrained method to encoding–decoding h∞ state
estimation for memristive neural networks with energy harvesting sensor.
<em>NEUCOM</em>, <em>579</em>, 127448. (<a
href="https://doi.org/10.1016/j.neucom.2024.127448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the encoding–decoding-based H ∞ H∞ state estimation issue under variance constraint for delayed memristive neural networks with energy harvesting sensor. In order to improve the transmission security, the encoding–decoding communication mechanism is introduced in the transmission channel, which can encode the transmitted data with limited bits. In addition, the energy level of the energy harvester is described by a random variable that obeys the specific probability distribution, in which the energy harvesting technology is used to provide the required energy and continuously maintain the operation of the sensor. The main objective is to present new encoding–decoding-based H ∞ H∞ state estimation method such that, in the presence of time-delay and energy harvesting mechanism, the desirable H ∞ H∞ performance requirement and the estimation error variance constraints are both ensured by providing some sufficient conditions. In the end, the feasibility of new encoding–decoding-based H ∞ H∞ state estimation algorithm is demonstrated by a simulation experiment.},
  archive      = {J_NEUCOM},
  author       = {Yan Gao and Jun Hu and Kun Chi and Chaoqing Jia and Jun Qi},
  doi          = {10.1016/j.neucom.2024.127448},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127448},
  shortjournal = {Neurocomputing},
  title        = {A variance-constrained method to encoding–decoding h∞ state estimation for memristive neural networks with energy harvesting sensor},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Redundant co-training: Semi-supervised segmentation of
medical images using informative redundancy. <em>NEUCOM</em>,
<em>579</em>, 127446. (<a
href="https://doi.org/10.1016/j.neucom.2024.127446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pseudo-labeling, consistency regularization, and co-training are common paradigms for semi-supervised learning. In this paper, we propose a novel method based on co-training and pseudo-labeling for the semi-supervised segmentation of the left ventricle. Our co-training strategy is novel and unlike most previous works does not rely on using multiple-view datasets, performing weak/strong augmentations on the input images or perturbations on the networks. We proposed creating redundant labels by utilizing the provided ground-truths and training networks segmenting different overlapping regions corresponding to the created labels. Although the new labels seem to be redundant, we demonstrated that they provide valuable information to the networks. The predictions of the redundant networks (which are trained on the redundant labels) can be used in the pixels where the primary network’s predictions are not reliable. This enables extracting a secondary source of information without requiring any additional ground-truths. The common practice in pseudo-labeling is using the reliable predictions of the unlabeled data and discarding the unreliable ones. However, we proposed utilizing predictions from the redundant networks to generate pseudo-labels for the unreliable pixels in the primary network’s predictions, rather than simply discarding them. We validated our method on two left ventricle segmentation datasets, and it surpassed the state-of-the-art semi-supervised learning approaches. Furthermore, we conducted extensive studies to analyze the proposed method from different aspects. Implementation of our work is available at https://github.com/behnam-rahmati/redundant-cotraining .},
  archive      = {J_NEUCOM},
  author       = {Behnam Rahmati and Shahram Shirani and Zahra Keshavarz-Motamed},
  doi          = {10.1016/j.neucom.2024.127446},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127446},
  shortjournal = {Neurocomputing},
  title        = {Redundant co-training: Semi-supervised segmentation of medical images using informative redundancy},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nuclei segmentation using attention aware and adversarial
networks. <em>NEUCOM</em>, <em>579</em>, 127445. (<a
href="https://doi.org/10.1016/j.neucom.2024.127445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of nuclei plays a critical role in pathology since assessments and diagnoses are mainly based on the recognition, measurement, and counting of nuclei. However, in digital pathology, automated nucleus segmentation is a challenging issue because of various factors such as color inconsistency in stained images, unclear nucleus boundaries, low contrast between background and nuclei, different shapes and sizes of nuclei, and intensity inhomogeneity not only inside nuclei but also across them and the background. In this work, an efficient method has been developed for nuclei segmentation. Its efficiency has been achieved through tissue and chemical invariant normalization, feature extraction with dense convolution layers, merging of local and global features, mask generation, and adversarial learning. For fair comparisons, state-of-the-art nuclei segmentations have been employed to the same data sets, and their performances have been evaluated using the same metrics. This paper’s main contributions are threefold: (i) Introducing a novel technique for nuclei segmentation using an adversarial network and a hybrid attention-aware network. (ii) Presenting the effective merging of global and local features to enhance pattern recognition, and the utilization of efficient hybrid attention blocks for extracting desired global information and improving relationships between feature regions at different locations. (iii) Presenting experimental results showing that the proposed technique accomplishes nuclei detection and extraction with higher accuracy (a minimum improvement of 3.7%) than other recent methods. Also, each stage provides considerable contributions to the segmentation performance. Particularly, the hybrid attention-aware network has improved the performance by 4.2% according to the dice coefficient.},
  archive      = {J_NEUCOM},
  author       = {Evgin Goceri},
  doi          = {10.1016/j.neucom.2024.127445},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127445},
  shortjournal = {Neurocomputing},
  title        = {Nuclei segmentation using attention aware and adversarial networks},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DAST-net: Dense visual attention augmented spatio-temporal
network for unsupervised video anomaly detection. <em>NEUCOM</em>,
<em>579</em>, 127444. (<a
href="https://doi.org/10.1016/j.neucom.2024.127444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an innovative end-to-end trainable framework named Dense Attention-aware Spatio-Temporal Network (DAST-Net) for video anomaly detection. The framework adeptly leverages both spatial and temporal data in an unsupervised manner, eliminating the need for manually crafted features. To enhance spatial feature representation, DAST-Net incorporates visual attention-aware residual connections within the denser residual network (DenserResNet), deviating from traditional identity skip connections. The rationale behind this connection choice is to augment the contextual understanding of features across various scales. For capturing temporal patterns, the framework employs a Convolutional LSTM Autoencoder (ConvLSTM-AE) module, enabling effective learning and representation of temporal dependencies in video data. Consequently, discriminating features from attention modules are combined with the features extracted by the ConvLSTM-AE module, enhancing visual recognition capabilities for both spatial and temporal aspects. Our proposed architecture outperforms state-of-the-art methods on four benchmark datasets, showcasing AUC scores of 85.4% on Ped1, 97.9% on Ped2, 89.8% on Avenue, and 73.7% on the ShanghaiTech dataset. The results demonstrate the performance of our method in identifying unusual events in video data.},
  archive      = {J_NEUCOM},
  author       = {Rangachary Kommanduri and Mrinmoy Ghorai},
  doi          = {10.1016/j.neucom.2024.127444},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127444},
  shortjournal = {Neurocomputing},
  title        = {DAST-net: Dense visual attention augmented spatio-temporal network for unsupervised video anomaly detection},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fetal cardiac ultrasound standard section detection model
based on multitask learning and mixed attention mechanism.
<em>NEUCOM</em>, <em>579</em>, 127443. (<a
href="https://doi.org/10.1016/j.neucom.2024.127443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fetal cardiac ultrasound is a valuable tool for screening fetal cardiac health during pregnancy. Ultrasound standard section testing is an essential part of fetal heart ultrasound diagnosis. Due to the many scattered and partially similar anatomical structures in standard ultrasound views of the fetal heart, the results strongly depend on the clinical experience and knowledge of the sonographer. To improve detection efficiency and reduce misdiagnosis and omission, we propose a single-stage fetal cardiac ultrasound standard plane detection model (FCUM) based on multitask learning and a hybrid attention mechanism to assist sonographers in diagnosis. The feature fusion pyramids of the backbone and detection networks of this model are each embedded with a hybrid attention mechanism module of our design, which enables the multitasking network to extract shared features more accurately and efficiently and improves the accuracy of the detection and classification networks. We designed a classification module for multilayer residual network feature fusion that leads to better classification and faster convergence time. We conducted comprehensive experiments on a dataset of fetal cardiac ultrasound images acquired with several types of devices and in different geographic regions. The experimental results show that our model outperforms baseline models such as YOLOv8 and ResNet-50 in terms of detection precision and classification accuracy.},
  archive      = {J_NEUCOM},
  author       = {Jie He and Lei Yang and Bocheng Liang and Shengli Li and Caixu Xu},
  doi          = {10.1016/j.neucom.2024.127443},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127443},
  shortjournal = {Neurocomputing},
  title        = {Fetal cardiac ultrasound standard section detection model based on multitask learning and mixed attention mechanism},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meta-learning to calibrate gaussian processes with deep
kernels for regression uncertainty estimation. <em>NEUCOM</em>,
<em>579</em>, 127441. (<a
href="https://doi.org/10.1016/j.neucom.2024.127441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although Gaussian processes (GPs) with deep kernels have been successfully used for meta-learning in regression tasks, its uncertainty estimation performance can be poor. We propose a meta-learning method for calibrating deep kernel GPs for improving regression uncertainty estimation performance with a limited number of training data. The proposed method meta-learns how to calibrate uncertainty using data from various tasks by minimizing the test expected calibration error, and uses the knowledge for unseen tasks. We design our model such that the adaptation and calibration for each task can be performed without iterative procedures, which enables effective meta-learning. In particular, a task-specific uncalibrated output distribution is modeled by a GP with a task-shared encoder network, and it is transformed to a calibrated one using a cumulative distribution function of a task-specific Gaussian mixture model (GMM). By integrating the GP and GMM into our neural network-based model, we can meta-learn the model parameters in an end-to-end fashion. Our experiments demonstrate that the proposed method improves uncertainty estimation performance while keeping high regression performance compared with the existing methods using real-world datasets in few-shot settings.},
  archive      = {J_NEUCOM},
  author       = {Tomoharu Iwata and Atsutoshi Kumagai},
  doi          = {10.1016/j.neucom.2024.127441},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127441},
  shortjournal = {Neurocomputing},
  title        = {Meta-learning to calibrate gaussian processes with deep kernels for regression uncertainty estimation},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction of rate of penetration based on drilling
conditions identification for drilling process. <em>NEUCOM</em>,
<em>579</em>, 127439. (<a
href="https://doi.org/10.1016/j.neucom.2024.127439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of rate of penetration is a prerequisite for optimization of drilling parameters. However, characteristics such as multiple drilling conditions, inconsistency in data length and various drilling variables can lead to inaccurate prediction of rate of penetration in actual drilling process. Therefore, it is important to use appropriate methods to predict rate of penetration for the above characteristics. This paper proposes an online prediction method of rate of penetration based on drilling conditions identification. First, data preprocessing and correlation analysis are employed to handle various drilling variables to obtain optimal model inputs. Then, dynamic time warping method is used to solve inconsistency in data length. Further, for multiple drilling conditions, the fuzzy c-means and dynamic time warping are combined to identify drilling conditions. Next, different extreme learning machine models optimized by genetic algorithm are built to predict rate of penetration for different drilling conditions. Finally, the results involving actual data illustrate that the prediction error of the proposed hybrid method of fuzzy c-means, dynamic time warping, extreme learning machine and genetic algorithm meets the requirements. The proposed hybrid method outperforms the comparative methods in four performance metrics, which verify the rationality and necessity of considering drilling conditions when predicting rate of penetration.},
  archive      = {J_NEUCOM},
  author       = {Xiao Yang and Min Wu and Chengda Lu and Wangnian Li and Luefeng Chen and Sheng Du},
  doi          = {10.1016/j.neucom.2024.127439},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127439},
  shortjournal = {Neurocomputing},
  title        = {Prediction of rate of penetration based on drilling conditions identification for drilling process},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UNFIS: A novel neuro-fuzzy inference system with
unstructured fuzzy rules. <em>NEUCOM</em>, <em>579</em>, 127437. (<a
href="https://doi.org/10.1016/j.neucom.2024.127437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important constraint of Fuzzy Inference Systems (FIS) is their structured rules. Indeed, each rule should evaluate all input variables in its antecedent part. Thus, the length of all fuzzy rules and the number of input variables are equal. However, in many decision-making problems evaluating some conditions on a limited set of input variables is sufficient to decide properly (unstructured rules). Consequently, the FIS’s performance, generalizability, and interpretability are restricted by the aforementioned limitation. This study provides a neuro-fuzzy inference system that can create each fuzzy rule taking into account various sets of input variables in order to handle this problem. To realize this capability, a new fuzzy selector neuron with an adaptive parameter is proposed that can select input variables in the antecedent part of each fuzzy rule. Moreover, the consequent part of the Takagi–Sugeno–Kang FIS is properly changed to consider only the selected set of input variables. To learn the parameters of the proposed architecture, the Levenberg–Marquardt (LM) method is used for regression problems. For classification applications, a trust-region-based learning method ( General quasi-Levenberg–Marquardt (GqLM) ) is proposed to minimize cross-entropy in multiclass problems. The performance of the proposed method is compared with some related previous approaches in some real-world classification and regression problems. Based on these comparisons, the proposed method has better or very close performance with a parsimonious structure consisting of unstructured fuzzy rules.},
  archive      = {J_NEUCOM},
  author       = {Armin Salimi-Badr},
  doi          = {10.1016/j.neucom.2024.127437},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127437},
  shortjournal = {Neurocomputing},
  title        = {UNFIS: A novel neuro-fuzzy inference system with unstructured fuzzy rules},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Distance profile layer for binary classification and
density estimation. <em>NEUCOM</em>, <em>579</em>, 127436. (<a
href="https://doi.org/10.1016/j.neucom.2024.127436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research on methods trying to explain solutions based on Neural Networks (NN) is a vivid target of Machine Learning works in recent years. Such a need arose due to the black-box nature of neural models and their tendency to provide a high certainty for incorrect decisions regarding events outside the area covered by the training set. In this work, we present a novel layer building a Distance Profile of recognized samples, aiming to substitute one-hot encoding of labels. The presented approach shows promising results in classification and unsupervised distribution density estimation and maintains a consistent representation for both recognition tasks. This approach manages certainty quantification for objects outside of the scope represented by available data and could potentially contribute to the Open Set Recognition and Out of Distribution Detection research fields.},
  archive      = {J_NEUCOM},
  author       = {Joanna Komorniczak and Paweł Ksieniewicz},
  doi          = {10.1016/j.neucom.2024.127436},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127436},
  shortjournal = {Neurocomputing},
  title        = {Distance profile layer for binary classification and density estimation},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hide and track: Towards blind video watermarking network in
frequency domain. <em>NEUCOM</em>, <em>579</em>, 127435. (<a
href="https://doi.org/10.1016/j.neucom.2024.127435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blind video watermarking (BVW) is the process of embedding visually imperceptible messages into a cover video, which can be retrieved even in the presence of distortion without requiring any reference to the original video. Compared to image watermarking, BVW encounters two critical challenges: 1) ensuring the visually imperceptible of the embedded information across sequential frames; 2) enabling quick localization of the watermarked frames in the event of temporal and spatial attacks such as frame dropping and video compression. This paper presents a robust blind video watermarking network by exploring a block-based selection mechanism in the frequency domain. The network comprises an encoding part that hides the watermark in a suitable location within the video to ensure visual imperceptibility of the watermark, and a decoding part that tracks the watermark in the frequency domain to ensure its robustness even when the video is distorted. Moreover, a plug-and-play watermark detector is designed to discover watermarking locations. This detector is readily applicable and can be easily integrated into most frequency watermarking embedding methods. Experimental results demonstrate that the proposed method outperforms the state-of-the-art methods on imperceptibility and robustness significantly. Our framework achieves an average peak signal-to-noise ratio (PSNR) of 37 . 59 dB and a Learned Perceptual Image Patch Similarity (LPIPS) of 1 . 12 × 1 0 − 2 . Furthermore, the extraction accuracy reaches 99.99% under a variety of temporal attacks which demonstrates the robustness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Zhiwei Zhang and Han Wang and Guisong Wang and Xinxiao Wu},
  doi          = {10.1016/j.neucom.2024.127435},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127435},
  shortjournal = {Neurocomputing},
  title        = {Hide and track: Towards blind video watermarking network in frequency domain},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adversarial patch-based false positive creation attacks
against aerial imagery object detectors. <em>NEUCOM</em>, <em>579</em>,
127431. (<a href="https://doi.org/10.1016/j.neucom.2024.127431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although adversarial attacks have revealed weaknesses in Deep Neural Networks (DNNs)-based aerial detectors, they present a new paradigm for concealing vulnerable assets from autonomous detection systems onboard satellites. Among them, adversarial patches were widely applied due to their physical realizability. Nonetheless, most existing adversarial patch-based attack methods are developed to hide objects from detectors to achieve a vanishing attack. This paper proposes a novel Adversarial Patch False Positive Creation Attack (APFP-CA) framework that enables aerial detectors to recognize non-existent objects, thereby realizing a creation attack. Concretely, the APFP-CA models the creation attack as a two-stage optimization problem. The first stage uses a well-designed efficient loss function to increase the objectness score of patches placed anywhere in the scene to achieve untargeted attacks. The second stage involves elaborating two category-dependent loss functions for fulfilling targeted attacks. Experiments conducted on diverse datasets and detectors demonstrate the effectiveness and universality of our method. Transfer attacks across different datasets and models validate the generalizability of the optimized adversarial patches. Finally, we perform several proportionally scaled experiments physically to illustrate that the optimized adversarial patches can successfully deceive aerial detectors in the physical world. The proposed approach offers a novel contribution to adversarial attacks against aerial imagery objectors and holds potential for practical applications in high-security systems.},
  archive      = {J_NEUCOM},
  author       = {Guijian Tang and Wen Yao and Tingsong Jiang and Yong Zhao and Jialiang Sun},
  doi          = {10.1016/j.neucom.2024.127431},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127431},
  shortjournal = {Neurocomputing},
  title        = {Adversarial patch-based false positive creation attacks against aerial imagery object detectors},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A semi-supervised cross-modal memory bank for cross-modal
retrieval. <em>NEUCOM</em>, <em>579</em>, 127430. (<a
href="https://doi.org/10.1016/j.neucom.2024.127430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core of semi-supervised cross-modal retrieval tasks lies in leveraging limited supervised information to measure the similarity between cross-modal data. Current approaches assume an association between unlabelled data and pre-defined k-nearest neighbour data, relying on classifier performance for this selection. With diminishing labelled data, classifier performance weakens, resulting in erroneous associations among unlabelled instances. Moreover, the lack of interpretability in class probabilities of unlabelled data hinders classifier learning. Thus, this paper focuses on learning pseudo-labels for unlabelled data, providing pseudo-supervision to aid classifier learning. Specifically, a cross-modal memory bank is proposed, dynamically storing feature representations in a common space and class probability representations in a label space for each cross-modal data. Pseudo-labels are derived by computing feature representation similarity and adjusting class probabilities. During this process, imposing constraints on the classification loss between labelled data and contrastive losses between paired cross-modal data is a prerequisite for the successful learning of pseudo-labels. This procedure significantly contributes to enhancing the credibility of these pseudo-labels. Empirical findings demonstrate that using only 10% labelled data, compared to prevailing semi-supervised techniques, this method achieves improvements of 2.6%, 1.8%, and 4.9% in MAP@50 on the Wikipedia, NUS-WIDE, and MS-COCO datasets, respectively.},
  archive      = {J_NEUCOM},
  author       = {Yingying Huang and Bingliang Hu and Yipeng Zhang and Chi Gao and Quan Wang},
  doi          = {10.1016/j.neucom.2024.127430},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127430},
  shortjournal = {Neurocomputing},
  title        = {A semi-supervised cross-modal memory bank for cross-modal retrieval},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relation-dependent contrastive learning with cluster
sampling for inductive relation prediction. <em>NEUCOM</em>,
<em>579</em>, 127425. (<a
href="https://doi.org/10.1016/j.neucom.2024.127425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation prediction is a task designed for knowledge graph completion which aims to predict missing relationships between entities. Recent subgraph-based models for inductive relation prediction have received increasing attention, which can predict relation for unseen entities based on the extracted subgraph surrounding the candidate triplet. However, they are not completely inductive because of their disability of predicting unseen relations. Moreover, they only rely on the graph neural network (GNN) to learn the embedding of extracted subgraph relations and independently assign learnable parameters to each relation, which ignores the role of relations and leads to inaccurate prediction on long-tail relations. In this paper, we introduce Re lation-dependent Co ntrastive Le arning (ReCoLe) for inductive relation prediction, which adapts contrastive learning with a novel sampling method based on clustering algorithm to enhance the role of relation and improve the generalization ability to unseen relations. Instead of directly learning embedding for relations, ReCoLe allocates a pre-trained GNN-based encoder for each relation to strengthen the influence of relations. The GNN-based encoder is optimized by contrastive learning, which improves the expressiveness of the embedding of long-tail relations and ensures satisfactory performance. In addition, the cluster sampling method equips ReCoLe with the ability to handle both unseen relations and entities. Experimental results suggest that ReCoLe outperforms state-of-the-art methods on commonly used inductive datasets.},
  archive      = {J_NEUCOM},
  author       = {Jianfeng Wu and Aolin Xiong and Sijie Mai and Haifeng Hu},
  doi          = {10.1016/j.neucom.2024.127425},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127425},
  shortjournal = {Neurocomputing},
  title        = {Relation-dependent contrastive learning with cluster sampling for inductive relation prediction},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Two stages prompting for few-shot multi-intent detection.
<em>NEUCOM</em>, <em>579</em>, 127424. (<a
href="https://doi.org/10.1016/j.neucom.2024.127424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on multi-intent detection in the few-shot scenario. Most prior works for multi-intent detection pick intent labels when estimated label-instance relevance scores are above a given threshold. However, these methods often perform poorly since it is nontrivial to precisely estimate the label-instance relevance scores and set an appropriate threshold in the few-shot scenario. In addition, these methods overlook the correlation among intents, which is vital to multi-intent detection. In light of these, we propose a prompt-based fine-tuning ( PFT ) method to tackle the issue of multi-intent detection in the few-shot scenario. Specifically, we first construct a prompt template to predict the number of intents. According to the number of intents, we then construct an intent prompt template to identify intents. To capture the correlation among intents, we also introduce a multi-view multi-head self-attention scheme based on PFT . Experimental results on two datasets demonstrate that our proposed method significantly outperforms the baselines.},
  archive      = {J_NEUCOM},
  author       = {Xingfa Zhou and Lan Yang and Xin Wang and Huayi Zhan and Rui Sun},
  doi          = {10.1016/j.neucom.2024.127424},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127424},
  shortjournal = {Neurocomputing},
  title        = {Two stages prompting for few-shot multi-intent detection},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Physics-informed neural nets for control of dynamical
systems. <em>NEUCOM</em>, <em>579</em>, 127419. (<a
href="https://doi.org/10.1016/j.neucom.2024.127419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks (PINNs) incorporate established physical principles into the training of deep neural networks, ensuring that they adhere to the underlying physics of the process while reducing the need for labeled data, since the desired output is not a prerequisite for physics-informed training. For modeling systems described by Ordinary Differential Equations (ODEs), traditional PINNs typically take continuous time as an input variable and produce the solution to the corresponding ODE. However, in their original form, PINNs neither accommodate control inputs nor do they effectively simulate variable long-range intervals without experiencing a significant decline in prediction accuracy. In this context, this work introduces a novel framework known as “Physics-Informed Neural Nets for Control” (PINC). PINC presents an innovative PINN-based architecture tailored to control problems, capable of simulating longer-range time horizons that are not predetermined during training. This increased flexibility sets it apart from traditional PINNs. The variable simulation time is achieved by adding inputs to the PINC network that convey the initial condition and the control signal for a particular time interval. Simulating variable long-range intervals involves running the PINC net across a sequence of shorter intervals. In this autoregressive process, the network predictions are linked in a self-feedback mode, with the initial state (input) of the next interval set to the last predicted state (network output) of the previous interval. We showcase the effectiveness of our proposal in identifying and controlling three nonlinear dynamic systems: the Van der Pol oscillator, the four-tank system, and an electric submersible pump. Crucially, these experiments demonstrate that learning the dynamics of these systems can be achieved without relying on any sample collected from the actual process, and it offers faster inference speed compared to numerical simulations.},
  archive      = {J_NEUCOM},
  author       = {Eric Aislan Antonelo and Eduardo Camponogara and Laio Oriel Seman and Jean Panaioti Jordanou and Eduardo Rehbein de Souza and Jomi Fred Hübner},
  doi          = {10.1016/j.neucom.2024.127419},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127419},
  shortjournal = {Neurocomputing},
  title        = {Physics-informed neural nets for control of dynamical systems},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive review of image retargeting.
<em>NEUCOM</em>, <em>579</em>, 127416. (<a
href="https://doi.org/10.1016/j.neucom.2024.127416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of display technologies, image retargeting plays a significant role in computer vision and pattern recognition communities currently. Image retargeting aims to display an image on a series of appliances with different resolutions and target aspect ratios. During the last decade, representative algorithms for image retargeting have been presented in the literature and achieved state-of-the-art performance. In this survey, we provide a comprehensive review of image retargeting, covering a wide variety of pioneering works for 2D image retargeting and stereoscopic image retargeting. 2D image retargeting focuses on preserving interesting regions when modifying the original image with arbitrary resolutions appropriately. Different from 2D image retargeting, stereoscopic image retargeting needs to preserve both the shape structure of salient objects and the depth consistency of 3D scenes simultaneously. In this survey, we start the first attempt to analyze the trends of 2D image retargeting and then summarize different types of stereoscopic image retargeting. Secondly, image retargeting quality assessment metrics for 2D images and stereoscopic images are introduced to evaluate retargeted images. Thirdly, we also investigate the evaluation datasets, and give the comparison results and analysis between different representative methods. Finally, the promising future research is thoroughly discussed to further improve the performance of 2D and stereoscopic image retargeting.},
  archive      = {J_NEUCOM},
  author       = {Xiaoting Fan and Zhong Zhang and Long Sun and Baihua Xiao and Tariq S. Durrani},
  doi          = {10.1016/j.neucom.2024.127416},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127416},
  shortjournal = {Neurocomputing},
  title        = {A comprehensive review of image retargeting},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trustworthy artificial intelligence -based federated
architecture for symptomatic disease detection. <em>NEUCOM</em>,
<em>579</em>, 127415. (<a
href="https://doi.org/10.1016/j.neucom.2024.127415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent viral outbreaks have had a significant impact on interpersonal relationships, particularly in enclosed spaces. Detecting and preventing the transmission of diseases such as COVID-19 has become a top priority. These diseases are typically identifiable through the symptoms they cause in humans. However, the collection of personal and health data for use in Artificial Intelligence models can give rise to ethical, security, and privacy issues. Therefore, it is necessary to have architectures that maintain the principles of Trustworthy Artificial Intelligence by design. This work proposes a decentralised architecture based on Federated Learning for symptomatic disease detection using the edge computing paradigm, storing the information in the device that collected it, and the foundations of Trustworthy Artificial Intelligence. The architecture is designed to be robust, secure, transparent, and responsible while maintaining data privacy. The proposed approach can be used with medical information capture systems with different user profiles.},
  archive      = {J_NEUCOM},
  author       = {Raúl López-Blanco and Ricardo S. Alonso and Sara Rodríguez-González and Javier Prieto and Juan M. Corchado},
  doi          = {10.1016/j.neucom.2024.127415},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127415},
  shortjournal = {Neurocomputing},
  title        = {Trustworthy artificial intelligence -based federated architecture for symptomatic disease detection},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Special issue on hybrid artificial intelligence systems
from HAIS 2021 conference. <em>NEUCOM</em>, <em>579</em>, 127414. (<a
href="https://doi.org/10.1016/j.neucom.2024.127414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The eight papers included in this special issue represent a selection of extended contributions presented at the 16th International Conference on Hybrid Artificial Intelligent Systems, HAIS 2021 held in Bilbao, Spain, September 22nd-24th, 2021, and organized by the BISITE group and the University of Deusto. The International Conference on Hybrid Artificial Intelligence Systems (HAIS 2021) has become a unique, established, and broad interdisciplinary forum for researchers and practitioners who are involved in developing and applying symbolic and sub-symbolic techniques aimed at the construction of highly robust and reliable problem-solving techniques to present the most relevant achievements in this field. HAIS Series of Conferences provides an interesting opportunity to present and discuss the latest theoretical advances and real-world applications in this multidisciplinary research field.},
  archive      = {J_NEUCOM},
  author       = {Héctor Quintián and Emilio Corchado},
  doi          = {10.1016/j.neucom.2024.127414},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127414},
  shortjournal = {Neurocomputing},
  title        = {Special issue on hybrid artificial intelligence systems from HAIS 2021 conference},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Special issue SOCO 2021: New trends in soft computing and
its application in industrial and environmental problems.
<em>NEUCOM</em>, <em>579</em>, 127413. (<a
href="https://doi.org/10.1016/j.neucom.2024.127413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The seven papers included in this special issue represent a selection of extended contributions presented at the 16th International Conference on Soft Computing Models in Industrial and Environmental Applications, SOCO 2021, held in Bilbao, Spain, September 22nd-24th, 2021, and organized by the BISITE group and the University of Deusto. The SOCO 2021 international conference represents a collection or set of computational techniques in machine learning, computer science and some engineering disciplines that investigate, simulate, and analyse very complex issues and phenomena. This special issue is aimed at practitioners, researchers, and postgraduate students who are engaged in developing and applying advanced intelligent systems principles to solve real-world problems in the mentioned fields.},
  archive      = {J_NEUCOM},
  author       = {Héctor Quintián and Emilio Corchado},
  doi          = {10.1016/j.neucom.2024.127413},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127413},
  shortjournal = {Neurocomputing},
  title        = {Special issue SOCO 2021: New trends in soft computing and its application in industrial and environmental problems},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Euler state networks: Non-dissipative reservoir computing.
<em>NEUCOM</em>, <em>579</em>, 127411. (<a
href="https://doi.org/10.1016/j.neucom.2024.127411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the numerical solution of ordinary differential equations, in this paper, we propose a novel Reservoir Computing (RC) model, called the Euler State Network (EuSN). The presented approach makes use of forward Euler discretization and antisymmetric recurrent matrices to design reservoir dynamics that are both stable and non-dissipative by construction. Our mathematical analysis shows that the resulting model is biased towards a unitary effective spectral radius and zero local Lyapunov exponents, intrinsically operating near the edge of stability. Experiments on long-term memory tasks show the clear superiority of the proposed approach over standard RC models in problems requiring effective propagation of input information over multiple time steps. Furthermore, results on time-series classification benchmarks indicate that EuSN can match (or even exceed) the accuracy of trainable Recurrent Neural Networks, while retaining the training efficiency of the RC family, resulting in up to ≈ 464 ≈464 -fold savings in computation time and ≈ 1750 ≈1750 -fold savings in energy consumption. At the same time, our results on time-series modeling tasks show competitive results against standard RC when the architecture is complemented by direct input-readout connections.},
  archive      = {J_NEUCOM},
  author       = {Claudio Gallicchio},
  doi          = {10.1016/j.neucom.2024.127411},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127411},
  shortjournal = {Neurocomputing},
  title        = {Euler state networks: Non-dissipative reservoir computing},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). G-DGANet: Gated deep graph attention network with
reinforcement learning for solving traveling salesman problem.
<em>NEUCOM</em>, <em>579</em>, 127392. (<a
href="https://doi.org/10.1016/j.neucom.2024.127392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combinatorial optimization problem (COP) is an NP-hard problem for which finding an optimal solution is difficult, especially as the problem size increases. The Traveling Salesman Problem (TSP), one of the COPs that can be formulated over a graph, is a well-researched area in operations research and computer science. Deep Reinforcement Learning (DRL) is now regarded as a promising approach for solving TSP and other NP hard problems. In this paper, we propose a novel Gated Deep Graph Attention Network (G-DGANet) which builds upon the existing Graph Neural Network (GNN) to solve TSP. The proposed G-DGANet uses gating mechanism between subsequent layers of the network to extract representations of nodes deeper in the network without loss in performance. G-DGANet also designs a novel aggregator to construct global graph embeddings from different embedding preferences. In addition, to effectively learn underlying structure of a graph, G-DGANet integrates node and edge information of the graph while updating node representations in the message passing mechanism. We used proximal policy optimization (PPO) to train G-DGANet on randomly generated instances. We conducted an experiment on randomly generated instances and on real-world road network data generated from digital maps to verify the performance of G-DGANet. The findings from experiments demonstrate that G-DGANet outperforms most traditional heuristics and existing DRL approaches, with high generalization abilities from random instance training to random instance testing and real-world road network instance testing.},
  archive      = {J_NEUCOM},
  author       = {Getu Fellek and Ahmed Farid and Shigeru Fujimura and Osamu Yoshie and Goytom Gebreyesus},
  doi          = {10.1016/j.neucom.2024.127392},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127392},
  shortjournal = {Neurocomputing},
  title        = {G-DGANet: Gated deep graph attention network with reinforcement learning for solving traveling salesman problem},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph manifold learning with non-gradient decision layer.
<em>NEUCOM</em>, <em>579</em>, 127390. (<a
href="https://doi.org/10.1016/j.neucom.2024.127390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generally, Graph convolution network (GCN) utilizes the graph convolution operators and the softmax to extract the deep representation and make the prediction, respectively. Although GCN successfully represents the connectivity relationship among the nodes by aggregating the information on the graph, the softmax-based decision layer may result in suboptimal performance in semi-supervised learning with less label support due to ignoring the inner distribution of the graph nodes. Besides, the gradient descent will take thousands of interaction for optimization. To address the referred issues, we propose a novel graph deep model with a non-gradient decision layer for graph mining. Firstly, manifold learning is unified with label local-structure preservation to capture the topological information and make accurate predictions with limited label support. Moreover, it is theoretically proven to have analytical solutions and acts as a non-gradient decision layer in graph convolution networks. Particularly, a joint optimization method is designed for this graph model, which extremely accelerates the convergence of the model. Finally, extensive experiments show that the proposed model has achieved excellent performance compared to the current models.},
  archive      = {J_NEUCOM},
  author       = {Ziheng Jiao and Hongyuan Zhang and Rui Zhang and Xuelong Li},
  doi          = {10.1016/j.neucom.2024.127390},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127390},
  shortjournal = {Neurocomputing},
  title        = {Graph manifold learning with non-gradient decision layer},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive finite-time passivity and synchronization of
coupled fractional-order memristive neural networks with multi-state
couplings. <em>NEUCOM</em>, <em>579</em>, 127380. (<a
href="https://doi.org/10.1016/j.neucom.2024.127380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the adaptive finite-time passivity (FTP) and finite-time synchronization (FTS) of coupled fractional-order memristive neural networks with multi-state couplings (CFMNNMCs) are investigated. Firstly, a sufficient condition for guaranteeing the FTP of CFMNNMCs is obtained by developing an edge-based adaptive strategy and a state-feedback controller. Furthermore, a node-based adaptive controller is designed to ensure the FTP of CFMNNMCs. Additionally, with the help of properties of Gamma function and some inequality techniques, the adaptive FTS problem for the considered network model is addressed. Finally, two numerical examples are given to demonstrate the validity of the adaptive FTP and FTS criteria.},
  archive      = {J_NEUCOM},
  author       = {Shi-Yu Yang and Hong-An Tang and Xiaofang Hu and Qingling Xia and Lidan Wang and Shukai Duan},
  doi          = {10.1016/j.neucom.2024.127380},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127380},
  shortjournal = {Neurocomputing},
  title        = {Adaptive finite-time passivity and synchronization of coupled fractional-order memristive neural networks with multi-state couplings},
  volume       = {579},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Focus and imagine: Occlusion suppression and repairing
transformer for occluded person re-identification. <em>NEUCOM</em>,
<em>578</em>, 127442. (<a
href="https://doi.org/10.1016/j.neucom.2024.127442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Occlusion scenarios pose a great challenge to person re-identification (ReID) task because various occlusions may weaken the discriminative features and introduce interference. Recently, Transformer-based networks, which can aggregate features of all the image patches to construct global features adaptively, have shown advantages in occluded person ReID. Existing methods mainly adopted Transformer as a feature extractor and enhanced local features from the output of the Transformer encoder. However, during the processing of self-attention blocks, disturbing features from occlusions may be diffused into all the tokens, making it difficult to construct effective local features. Therefore, we consider predicting the occlusion situation of images before feature extraction and guiding the Transformer encoder to focus on visible regions, suppressing interference from occlusion. Furthermore, we propose to imagine the partial target under occlusion and reconstruct pseudo-holistic features for more robust retrieval. To this end, the Occlusion Suppression and Repairing Transformer (OSRTrans) is proposed. First, we use a self-supervised occlusion predictor to predict occlusion scores of image patches. Then the Occlusion Suppression Encoder (OSE), guided by occlusion predictions, suppresses the interference from occlusion regions and constructs a global feature. Finally, inspired by contrastive learning, the Feature Repairing Head (FRH) is proposed to reconstruct pseudo-holistic features. Our method enhances model’s ability of extracting discriminative local features, and achieve the state-of-the-art performance on occluded person ReID benchmarks, e.g., Rank-1 of 72.9% on Occluded-DukeMTMC.},
  archive      = {J_NEUCOM},
  author       = {Ziwen Zhang and Shoudong Han and Donghaisheng Liu and Delie Ming},
  doi          = {10.1016/j.neucom.2024.127442},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127442},
  shortjournal = {Neurocomputing},
  title        = {Focus and imagine: Occlusion suppression and repairing transformer for occluded person re-identification},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-modal sarcasm detection based on multi-channel
enhanced fusion model. <em>NEUCOM</em>, <em>578</em>, 127440. (<a
href="https://doi.org/10.1016/j.neucom.2024.127440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The voluminous quantity of data accessible on social media platforms offers insight into the sentiment disposition of individual users, where multi-modal sarcasm detection is often confounding. Existing sarcasm detection methods use different information fusion methods to combine information from different modalities but ignore hidden information within modalities and inconsistent information between modalities. Discovering the implicit information within the modalities and strengthening the information interaction between modalities is still an important challenge. In this paper, we propose a Multi-Channel Enhanced Fusion (MCEF) model for cross-modal sarcasm detection to maximize the information extraction between different modalities. Specifically, text extracted from images acts as a new modality in the front-end fusion models to augment the utilization of image semantic information. Then, we propose a novel bipolar semantic attention mechanism to uncover the inconsistencies among different modal features. Furthermore, a decision-level fusion strategy from a new perspective is devised based on four models to achieve multi-channel fusion, each with a distinct focus, to leverage their advantages and mitigate the limitations. Extensive experiments demonstrate that our model surpasses current state-of-the-art models in multi-modal sarcasm detection.},
  archive      = {J_NEUCOM},
  author       = {Hong Fang and Dahao Liang and Weiyu Xiang},
  doi          = {10.1016/j.neucom.2024.127440},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127440},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal sarcasm detection based on multi-channel enhanced fusion model},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AudioRepInceptionNeXt: A lightweight single-stream
architecture for efficient audio recognition. <em>NEUCOM</em>,
<em>578</em>, 127432. (<a
href="https://doi.org/10.1016/j.neucom.2024.127432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has successfully adapted vision-based convolutional neural network (CNN) architectures for audio recognition tasks using Mel-Spectrograms. However, these CNNs have high computational costs and memory requirements, limiting their deployment on low-end edge devices. Motivated by the success of efficient vision models like InceptionNeXt and ConvNeXt, we propose AudioRepInceptionNeXt, a single-stream architecture. Its basic building block breaks down the parallel multi-branch depth-wise convolutions with descending scales of k × k k×k kernels into a cascade of two multi-branch depth-wise convolutions. The first multi-branch consists of parallel multi-scale 1 × k 1×k depth-wise convolutional layers followed by a similar multi-branch employing parallel multi-scale k × 1 k×1 depth-wise convolutional layers. This reduces computational and memory footprint while separating time and frequency processing of Mel-Spectrograms. The large kernels capture global frequencies and long activities, while small kernels get local frequencies and short activities. We also reparameterize the multi-branch design during inference to further boost speed without losing accuracy. Experiments show that AudioRepInceptionNeXt reduces parameters and computations by 50%+ and improves inference speed 1 . 28 × 1.28× over state-of-the-art CNNs like the Slow–Fast while maintaining comparable accuracy. It also learns robustly across a variety of audio recognition tasks.},
  archive      = {J_NEUCOM},
  author       = {Kin Wai Lau and Yasar Abbas Ur Rehman and Lai-Man Po},
  doi          = {10.1016/j.neucom.2024.127432},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127432},
  shortjournal = {Neurocomputing},
  title        = {AudioRepInceptionNeXt: A lightweight single-stream architecture for efficient audio recognition},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A survey of automatic sarcasm detection: Fundamental
theories, formulation, datasets, detection methods, and opportunities.
<em>NEUCOM</em>, <em>578</em>, 127428. (<a
href="https://doi.org/10.1016/j.neucom.2024.127428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sarcasm prevalent in social media poses challenges for sentiment analysis applications by flipping polarity, thus increasing the demand for sarcasm detection. In this article, we present a systematic survey of the research on sarcasm detection. We discuss the definition, problem formulation, datasets, as well as comprehensively review and evaluate methods that can detect sarcasm from three perspectives: the incongruity it contains, the sentimental cues it conveys, and the commonsense knowledge it implies. Specially, we detail sarcasm-related fundamental theories across disciplines, which may enhance sarcasm detection by leveraging interdisciplinary research and hope to facilitate collaborative efforts across research fields. We also discuss a variety of open problems, along with future opportunities for sarcasm detection.},
  archive      = {J_NEUCOM},
  author       = {Wangqun Chen and Fuqiang Lin and Guowei Li and Bo Liu},
  doi          = {10.1016/j.neucom.2024.127428},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127428},
  shortjournal = {Neurocomputing},
  title        = {A survey of automatic sarcasm detection: Fundamental theories, formulation, datasets, detection methods, and opportunities},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Nearly optimal stabilization of unknown continuous-time
nonlinear systems: A new parallel control approach. <em>NEUCOM</em>,
<em>578</em>, 127421. (<a
href="https://doi.org/10.1016/j.neucom.2024.127421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a novel online nearly optimal control (ONOC) method for unknown continuous-time (CT) nonaffine nonlinear systems without recovering unknown systems . First, a dynamic control law is proposed for CT nonaffine nonlinear systems using parallel control. To achieve the proposed dynamic control law, an affine augmented system (AAS) is constructed according to the original system, and an augmented performance index (API) is constructed on the basis of the original performance index (OPI). Then, the stability relationship between the original system and the AAS is provided, and it is proven that, by selecting a suitable parameter in the API, optimal control of the AAS with the API is equivalent to near-optimal control of the original system with the OPI. Subsequently, based on the proposed dynamic control law, we extend integral reinforcement learning (IRL) to completely unknown CT nonaffine systems, and it is further proved that closed-loop signals are uniformly ultimately bounded (UUB) without the assumption that the input dynamics are bounded. Furthermore, the OPI can be set to an arbitrary positive-definite form, and the UUB bound for the state vector can be predetermined. Lastly, simulations are offered to exhibit the correctness of the developed ONOC method. Source code of this paper is available at: https://github.com/lujingweihh/Adaptive-dynamic-programming-algorithms/tree/main/model_free_integral_reinforcement_learning .},
  archive      = {J_NEUCOM},
  author       = {Jingwei Lu and Xingxia Wang and Qinglai Wei and Fei-Yue Wang},
  doi          = {10.1016/j.neucom.2024.127421},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127421},
  shortjournal = {Neurocomputing},
  title        = {Nearly optimal stabilization of unknown continuous-time nonlinear systems: A new parallel control approach},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). P-adic distance and k-nearest neighbor classification.
<em>NEUCOM</em>, <em>578</em>, 127400. (<a
href="https://doi.org/10.1016/j.neucom.2024.127400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k k -Nearest Neighbor ( k k -NN) is a well-known supervised learning algorithm. The effect of the distance used in the analysis on the k k -NN performance is very important. According to Ostrowski’s theorem, there are only two nontrivial absolute values on the field of rational numbers, Q Q , which are the usual absolute value and the p p -adic absolute value for a prime p p . In view of this theorem, the p p -adic absolute value motivates us to calculate the p p -adic distance between two samples for the k k -NN algorithm. In this study, the p p -adic distance on Q Q was coupled with the k k -NN algorithm and was applied to 10 well-known public datasets containing categorical, numerical, and mixed (both categorical and numerical) type predictive attributes. Moreover, the p p -adic distance performance was compared with Euclidean, Manhattan, Chebyshev, and Cosine distances. It was seen that the average accuracy obtained from the p p -adic distance ranks first in 5 out of 10 datasets. Especially, in mixed datasets, the p p -adic distance gave better results than other distances. For r = 1 , 2 , 3 r=1,2,3 , the effect of the r r -decimal values of the number for the p p -adic calculation was examined on numerical and mixed datasets. In addition, the p p parameter of the p p -adic distance was tested with prime numbers less than 29, and it was found that the average accuracy obtained for each p p was very close to each other, especially in categorical and mixed datasets. Also, it can be concluded that k k -NN with the p p -adic distance may be more suitable for binary classification than multi-class classification.},
  archive      = {J_NEUCOM},
  author       = {Elif Kartal and Fatma Çalışkan and Beyaz Başak Eskişehirli and Zeki Özen},
  doi          = {10.1016/j.neucom.2024.127400},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127400},
  shortjournal = {Neurocomputing},
  title        = {P-adic distance and k-nearest neighbor classification},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DUGAN: Infrared and visible image fusion based on dual
fusion paths and a u-type discriminator. <em>NEUCOM</em>, <em>578</em>,
127391. (<a href="https://doi.org/10.1016/j.neucom.2024.127391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing infrared and visible image fusion techniques based on generative adversarial networks (GAN) generally disregard local and texture detail features, which tend to limit the fusion performance. Therefore, we propose a GAN model based on dual fusion paths and a U-type discriminator, denoted as DUGAN. Specifically, the image and gradient paths are integrated into the generator to fully extract the content and texture detail features from the source images and their corresponding gradient images. This incorporation aids the generator in generating fusion results with rich information by integrating output features of dual fusion paths. In addition, we construct a U-type discriminator to focus on input images’ global and local information, which drives the network to generate fusion results visually consistent with the source images. Furthermore, we integrate attention blocks in the discriminator to improve the representation of salient information. Experimental results demonstrate that DUGAN has better performance in qualitative and quantitative evaluation compared with other state-of-the-art methods. The source code has been released at https://github.com/chang-le-11/DUGAN .},
  archive      = {J_NEUCOM},
  author       = {Le Chang and Yongdong Huang and Qiufu Li and Yuduo Zhang and Lijun Liu and Qingjian Zhou},
  doi          = {10.1016/j.neucom.2024.127391},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127391},
  shortjournal = {Neurocomputing},
  title        = {DUGAN: Infrared and visible image fusion based on dual fusion paths and a U-type discriminator},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GAM: General affordance-based manipulation for contact-rich
object disentangling tasks. <em>NEUCOM</em>, <em>578</em>, 127386. (<a
href="https://doi.org/10.1016/j.neucom.2024.127386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picking up an entangled object is a difficult manipulation task due to its rich contact dynamics. Most existing solutions fail to produce grasp poses to enable reliable manipulation due to the dependence on simplified assumptions for the motion policies. Grasps generated by these methods tend to drop objects or cause undesired movements of non-grasped objects. To improve such object-disentangling tasks, we propose to extend the concept of reinforcement learning (RL)-based affordance to include arbitrary action consequences and implement a general affordance-based manipulation (GAM) framework. In the GAM, we train an RL agent that uses more fine-grained actions and outperforms previous methods with a smaller chance of dropping objects and making contact with non-grasped hooks. Then, a manipulation affordance prediction (MAP) model is trained to estimate the performances of the RL agent. Finally, the manipulation affordance-based grasp filter (MAGF) selects grasp poses that afford the desired manipulation performances, showing substantial improvements in five challenging hook disentangling tasks in simulation. The experiments show (1) the limitation of TAG generators, (2) the effectiveness of filtering TAGs with predicted manipulation performances based on the general affordance theory, and (3) the importance of avoiding contact with non-grasped objects in contact-rich manipulation.},
  archive      = {J_NEUCOM},
  author       = {Xintong Yang and Jing Wu and Yu-Kun Lai and Ze Ji},
  doi          = {10.1016/j.neucom.2024.127386},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127386},
  shortjournal = {Neurocomputing},
  title        = {GAM: General affordance-based manipulation for contact-rich object disentangling tasks},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-turn dialogue comprehension from a topic-aware
perspective. <em>NEUCOM</em>, <em>578</em>, 127385. (<a
href="https://doi.org/10.1016/j.neucom.2024.127385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialogue Machine Reading Comprehension requires language models to effectively decouple and model multi-turn dialogue passages. As a dialogue development goes after the intentions of participants, its topic may not remain constant throughout the whole passage. Hence, it is non-trivial to detect and leverage the topic shift in dialogue modeling. Topic modeling, although has been widely studied in plain text, deserves far more utilization in dialogue reading comprehension. This paper proposes to model multi-turn dialogues from a topic-aware perspective. This paper starts with a dialogue segmentation algorithm to split a dialogue passage into topic-concentrated fragments in an unsupervised way. Then these fragments are used as topic-aware language processing units in further dialogue comprehension. On one hand, the split segments indict specific topics rather than mixed intentions, thus showing convenience on in-domain topic detection and location. For this task, this paper designs a clustering system with a self-training auto-encoder, and two constructed datasets are built for evaluation. On the other hand, the split segments are an appropriate element of multi-turn dialogue response selection. For this purpose, this paper further presents a novel model, Topic-Aware Dual-Attention Matching (TADAM) Network, which takes topic segments as processing elements and matches response candidates with a dual cross-attention. Empirical studies on three public benchmarks show great improvements over baselines. Our work continues the previous studies on document topic, and brings the dialogue modeling to a novel topic-aware perspective with exhaustive experiments and analyses.},
  archive      = {J_NEUCOM},
  author       = {Xinbei Ma and Yi Xu and Hai Zhao and Zhuosheng Zhang},
  doi          = {10.1016/j.neucom.2024.127385},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127385},
  shortjournal = {Neurocomputing},
  title        = {Multi-turn dialogue comprehension from a topic-aware perspective},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Harmonic cut: An efficient and directly solved balanced
graph clustering. <em>NEUCOM</em>, <em>578</em>, 127381. (<a
href="https://doi.org/10.1016/j.neucom.2024.127381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, balanced clustering has garnered significant attention within its research domain. Previous studies have often employed various regularization terms to achieve balanced clustering. However, they inevitably bring extra hyper-parameters and suffer from high computational complexity. In this paper, we propose an efficient balanced graph cut model called Harmonic Cut. Harmonic cut is inspired by two key factors: harmonic mean and anchors’ labels are instances’ labels . The former elegantly derives a balance constraint. And the latter efficiently provides an idea for obtaining clustering labels. Unlike conventional spectral clustering methods, Harmonic cut directly acquires all cluster assignments, eliminating the need for additional k-means steps and significantly enhancing efficiency. We tackle the optimization problem associated with the Harmonic cut model using an efficient and heuristic algorithm, whose computational complexity scales linearly with the data size, denoted as n n . Finally, extensive experiments conducted on various real-world datasets demonstrate that Harmonic cut not only achieves comparable or even superior results, but also ensures both balance and efficiency. The code is available at https://github.com/DuannYu/HarmonicCut .},
  archive      = {J_NEUCOM},
  author       = {Yu Duan and Feiping Nie and Rong Wang and Xuelong Li},
  doi          = {10.1016/j.neucom.2024.127381},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127381},
  shortjournal = {Neurocomputing},
  title        = {Harmonic cut: An efficient and directly solved balanced graph clustering},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Emergence of sequential dynamical invariants in central
pattern generators from auto-organized constraints in their sequence
time intervals. <em>NEUCOM</em>, <em>578</em>, 127378. (<a
href="https://doi.org/10.1016/j.neucom.2024.127378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor coordination by the nervous system involves generating and coordinating muscle sequential activity. Such activity must be robust to produce effective motion that relies on patterned motor events ordered in a specific sequence and, at the same time, flexible in timing and duration to adapt to intrinsic and environmental circumstances. Motor neural circuits produce the signaling that muscles use for their sequential action. Even in rhythmic repetitive motion such as walking, breathing and chewing, variability in the timing of the events that build the sequence can be observed within the overall ordered rhythm of the motion. In this context, central pattern generators (CPGs) are key neural circuits to study the cycle-by-cycle balance between the robustness of the sequential order of neural events and the irregularity of the intracycle intervals that shape a rhythmic sequence. Recently, the presence of sequential dynamical invariants in the form of robust cycle-by-cycle relationships between specific sequence time intervals was unveiled in living CPGs. Variability of other sequence intervals remains unrelated and coexists with the presence of the invariants. Sequential dynamical invariants have been proposed to underlie the cycle-by-cycle CPG coordination. In this work, we used a minimal CPG circuit building block of two interacting inhibitory model neurons to assess the emergence of coordinated variability in sequential neural activity. We studied the conditions that produce sequential dynamical invariants in the circuit using intrinsically irregular neuron models and symmetric and asymmetric network topologies. We quantified the circuit irregularity and related it to the presence of invariants under different configurations. We found the conditions to propagate and sustain coordinated variability between time intervals, and thus our study illustrates the auto-organized constraint-based mechanisms for motor sequence coordination that shape sequential dynamical invariants. This is the first model study in which sequential dynamical invariants are observed considering only the intrinsic variability of CPG neurons without external stimuli. Finally, we discuss possible applications of this research in the context of autonomous robotics and artificial intelligence.},
  archive      = {J_NEUCOM},
  author       = {Blanca Berbel and Roberto Latorre and Pablo Varona},
  doi          = {10.1016/j.neucom.2024.127378},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127378},
  shortjournal = {Neurocomputing},
  title        = {Emergence of sequential dynamical invariants in central pattern generators from auto-organized constraints in their sequence time intervals},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exponential synchronization of nonlinear complex dynamic
networks via intermittent pinning control on time scales.
<em>NEUCOM</em>, <em>578</em>, 127375. (<a
href="https://doi.org/10.1016/j.neucom.2024.127375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly discusses exponential synchronization of nonlinear CDN via intermittent pinning control on T T . By using Lyapunov and time scales theory, a novel sufficient condition to guarantee the synchronization of CDNs is obtained. The method of intermittent pinning control is adopted in designing controllers to ensure the realization of synchronization of CDNs. Unlike most existing results, our results are an extension of previous results, integral delay and coupling disturbance are considered in the time-delay nonlinear CDNs. Therefore, our results are less conservative but more persuasive. Moreover, our model can be applied not only to continuous/discrete CDNS, but also to mixed CDNs. Finally, we give numerical simulations to demonstrate the feasibility of our theory.},
  archive      = {J_NEUCOM},
  author       = {Jie Sun and Yingxin Guo and Chuan Zhang},
  doi          = {10.1016/j.neucom.2024.127375},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127375},
  shortjournal = {Neurocomputing},
  title        = {Exponential synchronization of nonlinear complex dynamic networks via intermittent pinning control on time scales},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trust it or not: Confidence-guided automatic radiology
report generation. <em>NEUCOM</em>, <em>578</em>, 127374. (<a
href="https://doi.org/10.1016/j.neucom.2024.127374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical imaging plays a pivotal role in diagnosis and treatment in clinical practice. Inspired by the significant progress in automatic image captioning, various deep learning (DL)-based methods have been proposed to generate radiology reports for medical images. Despite promising results, previous works overlook the uncertainties of their models and are thus unable to provide clinicians with the reliability/confidence of the generated radiology reports to assist their decision-making. In this paper, we propose a novel method to explicitly quantify both the visual uncertainty and the textual uncertainty for DL-based radiology report generation. Such multi-modal uncertainties can sufficiently capture the model’s confidence degree at both the report level and sentence level, which can be further leveraged to weight the losses for more comprehensive model optimization. Experimental results have demonstrated that the proposed method for model uncertainty characterization and estimation can produce more reliable confidence scores for radiology report generation, and the modified loss function, which takes into account the uncertainties, leads to better model performance on two public radiology report datasets based on both standard evaluation metrics and experienced radiologists.},
  archive      = {J_NEUCOM},
  author       = {Yixin Wang and Zihao Lin and Zhe Xu and Haoyu Dong and Jie Luo and Jiang Tian and Zhongchao Shi and Lifu Huang and Yang Zhang and Jianping Fan and Zhiqiang He},
  doi          = {10.1016/j.neucom.2024.127374},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127374},
  shortjournal = {Neurocomputing},
  title        = {Trust it or not: Confidence-guided automatic radiology report generation},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Set representative vector and its asymmetric attention-based
transformation for heterogeneous set-to-set matching. <em>NEUCOM</em>,
<em>578</em>, 127372. (<a
href="https://doi.org/10.1016/j.neucom.2024.127372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous set-to-set matching, applied to fashion outfit recommendations, no longer depends on the similarity but on compatibility between items in sets. Existing state-of-the-art methods apply self- and cross-attention mechanisms to transform item vectors closer or farther apart and compute the matching score based on transformed item vectors. However, the transformation by attention mechanisms with fewer items in sets is performed in rather limited spaces, and the complex computation of scores in the head network would cause the instability of the training of entire networks. To overcome these problems, we propose to add a trainable set representative vector into each set and to embed discriminative information of items onto the vector through originally extended asymmetric attention mechanisms. This enables dynamic transformation in wider spaces and stable training without gradient vanishing problems to generate discriminative matching scores. Through experiments with heterogeneous set-to-set matching tasks, even-total, and fashion outfit matching tasks, we show the effectiveness of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Hirotaka Hachiya and Yuki Saito},
  doi          = {10.1016/j.neucom.2024.127372},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127372},
  shortjournal = {Neurocomputing},
  title        = {Set representative vector and its asymmetric attention-based transformation for heterogeneous set-to-set matching},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Memristive neural network circuit design based on locally
competitive algorithm for sparse coding application. <em>NEUCOM</em>,
<em>578</em>, 127369. (<a
href="https://doi.org/10.1016/j.neucom.2024.127369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse coding can quickly, accurately, and inexpensively represent the stimulus information received by biological vision neurons. However, there is no entire circuit that can realize real-time sparse coding by efficient analog computation. A memristor neural network circuit that solves the sparse coding problem in real-time and in parallel is proposed to solve such a problem. In our circuit, a novel memristor array structure can realize both reading and writing in parallel. A neural network circuit that can execute the Locally Competitive Algorithm (LCA) is designed based on this structure. Given these designs, the proposed neural networks circuit can utilize the programmability of the memristor array to real-time process various sparse coding problems. Based on the proposed circuit, the module can process binary and grayscale image sparse coding, providing a circuit implementation platform for sparse coding tasks. The simulation results demonstrate that the processing speed of sparse coding is improved compared with the MATLAB simulation and the application robustness is enhanced.},
  archive      = {J_NEUCOM},
  author       = {Qinghui Hong and Pingdan Xiao and Ruijia Fan and Sichun Du},
  doi          = {10.1016/j.neucom.2024.127369},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127369},
  shortjournal = {Neurocomputing},
  title        = {Memristive neural network circuit design based on locally competitive algorithm for sparse coding application},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Progressive correspondence learning by effective
multi-channel aggregation. <em>NEUCOM</em>, <em>578</em>, 127368. (<a
href="https://doi.org/10.1016/j.neucom.2024.127368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Establishing reliable correspondences between two images is non-trivial for solving various computer vision problems. Many learning-based feature matching methods train end-to-end networks using MLP to infer the probability of each initial correspondence being an inlier. However, these methods utilize continuous PointCN blocks as the main component of their networks, which have limited capacity to obtain contextual information for correspondence learning. In this paper, we propose a simple and effective module called the Multi-Channel Aggregation (MCA) module to capture rich context of correspondences, enabling reliable correspondence identification and accurate camera pose estimation between matching images. Specifically, our MCA module starts from a high-channel PointCN submodule and progressively obtains some high-to-low channel PointCN submodules. Meanwhile, it aggregates mutual information of different submodules to enhance the feature representation capacity. The proposed MCA module is a plug-and-play component that can boost the performance of existing learning-based methods. Extensive experiments across different datasets on the outlier removal and camera pose estimation tasks demonstrate the effectiveness of our MCA module. We have released the source code at https://github.com/guobaoxiao/MCA-Net .},
  archive      = {J_NEUCOM},
  author       = {Xin Liu and Shunxing Chen and Guobao Xiao and Changcai Yang and Riqing Chen},
  doi          = {10.1016/j.neucom.2024.127368},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127368},
  shortjournal = {Neurocomputing},
  title        = {Progressive correspondence learning by effective multi-channel aggregation},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fabisearch: A package for change point detection in and
visualization of the network structure of multivariate high-dimensional
time series in r. <em>NEUCOM</em>, <em>578</em>, 127321. (<a
href="https://doi.org/10.1016/j.neucom.2024.127321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we introduce the R package fabisearch , available on the Comprehensive R Archive Network (CRAN), which implements an original change point detection method for multivariate high-dimensional time series data and a new interactive, 3-dimensional, brain-specific network visualization capability in a flexible, stand-alone function. Change point detection is a commonly used technique in time series analysis, capturing the dynamic nature in which many real-world processes function. With the ever increasing troves of multivariate high-dimensional time series data, especially in neuroimaging and finance, there is a clear need for scalable and data-driven change point detection methods. Currently, change point detection methods for multivariate high-dimensional data are scarce, with even less available in high-level, easily accessible software packages. fabisearch , which implements the factorized binary search (FaBiSearch) methodology, is a novel statistical method for detecting change points in the network structure of multivariate high-dimensional time series which employs non-negative matrix factorization (NMF), an unsupervised dimension reduction and clustering technique. We utilize a new binary search algorithm to efficiently identify multiple change points and provide a new method for network estimation for data between change points. We show the functionality of the package and the practicality of the method by applying it to a neuroimaging and a finance data set. We also introduce an interactive, 3-dimensional, brain-specific network visualization capability in a flexible, stand-alone function. This function can be conveniently used with any node coordinate atlas, and nodes can be color coded according to community membership (if applicable). The output is a network laid over a cortical surface, which can be rotated in 3-dimensional space.},
  archive      = {J_NEUCOM},
  author       = {Martin Ondrus and Ivor Cribben},
  doi          = {10.1016/j.neucom.2024.127321},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127321},
  shortjournal = {Neurocomputing},
  title        = {Fabisearch: A package for change point detection in and visualization of the network structure of multivariate high-dimensional time series in r},
  volume       = {578},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Action recognition in compressed domains: A survey.
<em>NEUCOM</em>, <em>577</em>, 127389. (<a
href="https://doi.org/10.1016/j.neucom.2024.127389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action recognition (HAR) refers to the process in which computers analyze and process video data to obtain the categories of action presented in the video. It has a wide range of applications, such as video surveillance, human–computer interaction, and autonomous driving. The spatio-temporal features required for video analysis are typically extracted from the RGB pixels, which entail significant computational complexity and make it challenging for real-time action recognition. However, in the compressed domain, sparse representations, such as motion vectors, quantization parameters, transform coefficients, and residuals provide the comparable scene semantic information with reduced complexity. This paper provides an overview of the research efforts in action recognition based on the compressed domain. It includes a comprehensive review of both traditional and deep learning-based methods published between 2000 and 2023, focusing on compression standards and compression parameters. Specifically, we first summarize the compression standards and compressed algorithms used for compressing videos. Furthermore, we classify compressed-domain action recognition methods into traditional and deep learning-based approaches. Thirdly, we introduce public datasets and evaluation metrics, analyze the characteristics of these methods and compare their performance. Finally, we highlight challenges and suggest future research directions.},
  archive      = {J_NEUCOM},
  author       = {Yue Ming and Jiangwan Zhou and Nannan Hu and Fan Feng and Panzi Zhao and Boyang Lyu and Hui Yu},
  doi          = {10.1016/j.neucom.2024.127389},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127389},
  shortjournal = {Neurocomputing},
  title        = {Action recognition in compressed domains: A survey},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards to human intention: A few-shot open-set object
detection for x-ray hazard inspection. <em>NEUCOM</em>, <em>577</em>,
127388. (<a href="https://doi.org/10.1016/j.neucom.2024.127388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X-ray-prohibited item inspection is an important measure to maintain public safety and has been widely applied in industries such as transportation and logistics. Without bells and whistles, it is a classic few-shot object detection task due to the long-tailed distribution of data in the real world, i.e., rare items occur at low frequencies. Taking into account that most previous few-shot methods are designed to detect known categories and are unable to perceive unknown objects, this is not conducive to the screening of novel types of prohibited items because the predefined categories in specific datasets cannot cover all possible classes in the natural world. In this work, we propose a Few-shot Open-set X-ray Object Detection method (FOXOD) composed of four novel components, namely the Overlapping Object Separator (OOS), Unknown Interest Advisor (UIA), Knowledge Augmentation (KA), and Discriminant Classifier (DC). Our method aims to achieve perceptual alertness for all known prohibited items and potential unknown objects based on a few data. To alleviate the problem of high overlap between objects, OOS utilizes a hierarchical attention mechanism to sample local knowledge and decouple the features of overlapping individual targets. In addition, UIA is carefully designed to assist RPN in perceiving potential unknown proposals without supervision, while KA mitigates catastrophic forgetting of known classes by the model. Moreover, DC prevents overfitting and further identifies unknown positive objects from a large number of background proposals. Extensive experiments on SIXray and VOC datasets demonstrate that FOXOD outperforms other baselines in both X-ray and common scenarios. Code is available at: https://github.com/liumaozhen-lmz/-FOXOD .},
  archive      = {J_NEUCOM},
  author       = {Maozhen Liu and Xiaoguang Di and Teng Lv and Ming Liao and Xiaofei Zhang},
  doi          = {10.1016/j.neucom.2024.127388},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127388},
  shortjournal = {Neurocomputing},
  title        = {Towards to human intention: A few-shot open-set object detection for X-ray hazard inspection},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Refining and reweighting pseudo labels for weakly supervised
object detection. <em>NEUCOM</em>, <em>577</em>, 127387. (<a
href="https://doi.org/10.1016/j.neucom.2024.127387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-level weakly supervised object detection (WSOD) has made significant advancements by employing multiple instance learning (MIL) as a fundamental approach. However, challenges such as instance ambiguity and part domination persist, impeding the generation of more accurate and comprehensive boundingboxes for object detection. Moreover, existing methodologies typically treat WSOD as a two-stage task, involving weakly supervised detection followed by strongly supervised retraining. Unfortunately, the direct utilization of boundingbox-level labels predicted in the former stage, irrespective of their quality, only yields marginal improvements in detection performance. In this paper, we introduce a novel attention module and a boundingbox refinement module in the initial stage. The attention module operates across both spatial and global dimensions, enhancing the saliency and discriminative characteristics of region features associated with positive samples. The boundingbox refinement module employs multiple strategies to optimize labels, with the goal of generating high-quality boundingbox-level labels for subsequent strongly supervised retraining. Furthermore, in the second stage, we propose Loss-based Label Division (LLD) and Score-guided Weight Adjustment (SWA) strategies. These strategies effectively mitigate the impact of noisy labels during the retraining phase. To validate the effectiveness of the proposed modules and strategies, comprehensive ablation experiments are conducted. Experimental results on two public benchmarks including VOC2007 and VOC2012 show that our method achieves satisfactory performance. For access to the code, models, and additional details, please visit the following repository: https://github.com/better-chao/WSOD .},
  archive      = {J_NEUCOM},
  author       = {Yongchao Feng and Hao Zeng and Shiwei Li and Qingjie Liu and Yunhong Wang},
  doi          = {10.1016/j.neucom.2024.127387},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127387},
  shortjournal = {Neurocomputing},
  title        = {Refining and reweighting pseudo labels for weakly supervised object detection},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unified quantified adaptive control for multiple-time
stochastic synchronization of coupled memristive neural networks.
<em>NEUCOM</em>, <em>577</em>, 127384. (<a
href="https://doi.org/10.1016/j.neucom.2024.127384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the multiple-time (including the finite/fixed/predefined-time) stochastic synchronization issues on coupled memristive neural networks (CMNNs) are investigated with the design of a unified quantified adaptive chattering-free control scheme. Different from the construction of the general networks model, the consideration of the coupling between not only nodes but also node dimensions such that the given model becomes more general and practical. Then based on the algebraic inequality approach and with the design of a quantified adaptive control scheme, the fixed-time (FXT) stochastic synchronization criterion for CMNNs is proposed, and the networks can be finite-time (FT) synchronous when certain parameters are changed in the unified framework. To improve the existing FXT results, gamma function is used to obtain the settling time (ST) that estimates with lower conservatism. On the basis of criterion for FXT synchronization, by adding a limited FXT gain, CMNNs can not only achieve the predefined time (PDT) stochastic synchronization according to the actual situation, but also get rid of the limitation for system and controller parameters. Last but not least, the correctness of the theoretical outcomes can be verified by numerical simulation and secure communication scheme.},
  archive      = {J_NEUCOM},
  author       = {Lili Zhou and Huo Lin and Fei Tan},
  doi          = {10.1016/j.neucom.2024.127384},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127384},
  shortjournal = {Neurocomputing},
  title        = {Unified quantified adaptive control for multiple-time stochastic synchronization of coupled memristive neural networks},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dynamic label assignment strategy for one-stage detectors.
<em>NEUCOM</em>, <em>577</em>, 127383. (<a
href="https://doi.org/10.1016/j.neucom.2024.127383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In object detection field, label assignment (LA) is an important step in determining the detection accuracy, which assigns positive and negative labels for the training samples, so that the prediction loss could be calculated. Therefore, how to realize a more reasonable LA has always been a major concern for computer vision experts. Considering the difficulty of current LA strategy in adapting to different scenarios and the lack of interaction between the classification and localization tasks. We propose a novel dynamic LA scheme for one-stage object detector. Firstly, the qualities of the anchor boxes are computed based on the outputs of both classification and localization, which are used to assign the positive and negative samples and will also be adjusted during training. Secondly, the positive and negative samples for the classification and localization tasks are decoupled, and independent LA strategies are developed for each task. Finally, the interaction between the two network heads are enhanced through multiple shared convolution blocks so as to complete the two tasks in a more collaborative manner. Extensive experiments conducted on MS COCO, PASCAL VOC and CrowdHuman to support our design and analysis. With the newly introduced LA strategy, we improve the detection accuracy of existing one-stage detector to a new level.},
  archive      = {J_NEUCOM},
  author       = {Yi Zhang and Chen Luo},
  doi          = {10.1016/j.neucom.2024.127383},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127383},
  shortjournal = {Neurocomputing},
  title        = {A dynamic label assignment strategy for one-stage detectors},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multistability analysis of complex-valued recurrent neural
networks with sine and cosine activation functions. <em>NEUCOM</em>,
<em>577</em>, 127382. (<a
href="https://doi.org/10.1016/j.neucom.2024.127382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the multistability problem for complex-valued recurrent neural networks (CVRNNs) with a specific class of piecewise nonlinear activation functions . Firstly, a general class of piecewise nonlinear activation functions is presented to facilitate further analysis. Then, by resorting to the fixed point theorem and Lagrange’s mean value theorem, sufficient criteria are established which ascertain that the existence of ( 2 k + 1 ) 2 n (2k+1)2n equilibrium points. Meanwhile, it also verifies that ( k + 1 ) 2 n (k+1)2n equilibrium points of the considered CVRNNs with a piecewise nonlinear activation function are stable, where k k stands for a positive real number, which is associated with the frequency of sine and cosine functions . Moreover, the utilization of the activation functions provides a larger storage capacity in associative memory application. In the end of paper, three numerical examples are presented to demonstrate the feasibility and validity of the achieved theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Liu Yang and Weiqiang Gong and Qiang Li and Fanrong Sun and Mali Xing},
  doi          = {10.1016/j.neucom.2024.127382},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127382},
  shortjournal = {Neurocomputing},
  title        = {Multistability analysis of complex-valued recurrent neural networks with sine and cosine activation functions},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). AnatSwin: An anatomical structure-aware transformer network
for cardiac MRI segmentation utilizing label images. <em>NEUCOM</em>,
<em>577</em>, 127379. (<a
href="https://doi.org/10.1016/j.neucom.2024.127379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the extensive utilization of deep learning in medical image segmentation, the achieved accuracy remains inadequate for clinical requirements due to the scarcity of annotated data, which constrains the acquisition of anatomical knowledge. Leveraging anatomical information is particularly advantageous in medical image segmentation, especially for multi-modal and cross-domain tasks. To better capture and represent anatomical structures, we propose a Swin Transformer-based anatomical structure-aware network, AnatSwin, which adopts a unique approach by utilizing label images as inputs. Compared with gray-scale images, label images, devoid of intensity information, explicitly enhance the representation of anatomical shape and spatial tissue relationships, offering valuable resources for learning anatomical structures effectively and allowing the model to concentrate on understanding morphological and spatial relationship cues. AnatSwin follows an encoder–decoder architecture, where the encoder incorporates two branches that share weights. The Swin-Transformer block serves as the basic unit of the encoder, accepting both the template label (representing the correct anatomical structure) and the pseudo label (generated by a registration model) as inputs. In order to facilitate efficient interaction among features at the same hierarchy, an attention-based feature interaction (FI) block is introduced. FI block enhances the model’s ability to capture anatomical structure by promoting feature interactions within the two branches. Furthermore, the decoder employs FI blocks to learn relationships between features at the same hierarchy, ultimately improving the segmentation performance. Experimental evaluations demonstrate that the proposed AnatSwin outperforms state-of-the-art models, highlighting its significant potential in improving the learning and representation of anatomical structures, as well as optimizing tasks related to medical image segmentation. This work signifies a promising step forward in addressing the challenges of medical image segmentation and paves the way for further advancements in the field.},
  archive      = {J_NEUCOM},
  author       = {Heying Wang and Zhen Wang and Xiqian Wang and Zonghu Wu and Yongfeng Yuan and Qince Li},
  doi          = {10.1016/j.neucom.2024.127379},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127379},
  shortjournal = {Neurocomputing},
  title        = {AnatSwin: An anatomical structure-aware transformer network for cardiac MRI segmentation utilizing label images},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A reinforcement learning approach for adaptive tracking
control of a reusable rocket model in a landing scenario.
<em>NEUCOM</em>, <em>577</em>, 127377. (<a
href="https://doi.org/10.1016/j.neucom.2024.127377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores the application of reinforcement learning to control the descend/landing phase of a reusable rocket model, where the rocket must track a nominal/planar reference path with adequate attitude. To tackle the control problem, which is multivariable, a cascade control architecture is proposed, consisting of three single-input single-output controllers. The inner control loop is responsible for controlling the attitude using a reference for attitude provided by the outer loop and the thrust vectoring, where the gimbal angle is the manipulated variable. The position error is handled by the external loop, that handles the altitude error, used to adjust thrust. Several configurations, using Linear Quadratic Gaussian (LQG) control (LQ regulator with a Kalman observer), PID control and adaptive control based on Reinforcement Learning (optimal control with learning capability based on a linear regression model), are evaluated and compared.},
  archive      = {J_NEUCOM},
  author       = {Bertinho A. Costa and Francisco L. Parente and João Belfo and Nicola Somma and Paulo Rosa and José M. Igreja and Joris Belhadj and João M. Lemos},
  doi          = {10.1016/j.neucom.2024.127377},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127377},
  shortjournal = {Neurocomputing},
  title        = {A reinforcement learning approach for adaptive tracking control of a reusable rocket model in a landing scenario},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label-efficient object detection via region proposal network
pre-training. <em>NEUCOM</em>, <em>577</em>, 127376. (<a
href="https://doi.org/10.1016/j.neucom.2024.127376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised pre-training, based on the pretext task of instance discrimination, has fuelled the recent advance in label-efficient object detection. However, existing studies focus on pre-training only a feature extractor network to learn transferable representations for downstream detection tasks. This leads to the necessity of training multiple detection-specific modules from scratch in the fine-tuning phase. We argue that the region proposal network (RPN), a common detection-specific module, can additionally be pre-trained towards reducing the localization error of multi-stage detectors. In this work, we propose a simple pretext task that provides an effective pre-training for the RPN, towards efficiently improving downstream object detection performance. We evaluate the efficacy of our approach on benchmark object detection tasks and additional downstream tasks, including instance segmentation and few-shot detection. In comparison with multi-stage detectors without RPN pre-training, our approach is able to consistently improve downstream task performance, with largest gains found in label-scarce settings.},
  archive      = {J_NEUCOM},
  author       = {Nanqing Dong and Linus Ericsson and Yongxin Yang and Aleš Leonardis and Steven McDonagh},
  doi          = {10.1016/j.neucom.2024.127376},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127376},
  shortjournal = {Neurocomputing},
  title        = {Label-efficient object detection via region proposal network pre-training},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive emotion neural network based on ITCSO and grey
correlation contribution. <em>NEUCOM</em>, <em>577</em>, 127373. (<a
href="https://doi.org/10.1016/j.neucom.2024.127373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to further improve the performance of emotion neural network (ENN), a novel adaptive hormone regulation emotion neural network (HRENN) is proposed, which is based on the improved triple competitive swarm optimization (ITCSO) algorithm and grey correlation contribution. Firstly, the structure of HRENN is designed that is inspired by the biological mechanism of hormone regulation. The fast response characteristic of emotion processing and the feedback effect of hormone regulation can effectively improve the learning ability of HRENN. Secondly, the ITCSO algorithm is proposed for optimizing the parameters of HRENN. In order to strike a well balance between exploration and exploitation, triple competition mechanism is adopted. Two-thirds of particles participate in the optimization and different learning strategies for different particles are provided. These operations can greatly improve the optimization efficiency and the convergence accuracy. Moreover, grey correlation contribution is used to add or delete the dimension of particles. It means that the structure and parameters of HRENN can be adjusted simultaneously and the compact structure can be obtained. Finally, the stability and the convergence of ITCSO are proved using the Banach space and the principle of compression mapping. Experiment results show that the proposed ITCSO-HRENN has good self-organization ability, compact network structure, high convergence accuracy and superior computation efficiency compared with other methods.},
  archive      = {J_NEUCOM},
  author       = {Wei Zhang and Wanfeng Wei},
  doi          = {10.1016/j.neucom.2024.127373},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127373},
  shortjournal = {Neurocomputing},
  title        = {Adaptive emotion neural network based on ITCSO and grey correlation contribution},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized outlier exposure: Towards a trustworthy
out-of-distribution detector without sacrificing accuracy.
<em>NEUCOM</em>, <em>577</em>, 127371. (<a
href="https://doi.org/10.1016/j.neucom.2024.127371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the remarkable performance of deep neural networks (DNNs), it is often challenging to employ DNNs in safety-critical applications due to their overconfident predictions on even out-of-distribution (OoD) samples. To address this, an OoD detection task was motivated, and one of the OoD detection methods, Outlier Exposure (OE), demonstrated strong performance by leveraging OoD training samples . However, OE and its variants lead to a deterioration in in-distribution (ID) classification performance, and this issue is still unresolved. To this end, we propose Generalized OE (G-OE) that linearly mixes training data from all given samples, including OoD to produce reliable uncertainty estimates. G-OE also includes an effective filtering strategy to reduce the negative effect of OoD samples that are semantically similar to ID samples. We extensively evaluate the performance of G-OE on SC-OoD benchmarks: G-OE improves the performance of OoD detection and ID classification compared to existing OE-based methods.},
  archive      = {J_NEUCOM},
  author       = {Jiin Koo and Sungjoon Choi and Sangheum Hwang},
  doi          = {10.1016/j.neucom.2024.127371},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127371},
  shortjournal = {Neurocomputing},
  title        = {Generalized outlier exposure: Towards a trustworthy out-of-distribution detector without sacrificing accuracy},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised utterance order prediction for emotion
recognition in conversations. <em>NEUCOM</em>, <em>577</em>, 127370. (<a
href="https://doi.org/10.1016/j.neucom.2024.127370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the order of the utterances in a conversation changes, the meaning of the utterance also changes, and sometimes, this will cause different semantics or emotions. However, the existing representation learning models do not pay close attention to capturing the internal semantic differences of utterance caused by the change of utterance order. Based on this, we build a self-supervised utterance order prediction approach to learn the logical order of utterance, which helps understand the deep semantic relationship between adjacent utterances. Specially, the utterance binary composed of two adjacent utterances, which are ordered or disordered, is fed to the self-supervised model so that the self-supervised model can obtain firm representation learning ability for the semantic differences of the adjacent sentences. The self-supervised method is applied to the downstream conversation emotion recognition task to test the value of the approach. The features extracted from the self-supervised model are fused with the multimodal features to obtain a richer utterance representation. After that, emotion recognition models are applied to two different datasets. The experiment results show that our proposed approach outperforms the current state of the art on ERC benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Dazhi Jiang and Hao Liu and Geng Tu and Runguo Wei and Erik Cambria},
  doi          = {10.1016/j.neucom.2024.127370},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127370},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised utterance order prediction for emotion recognition in conversations},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Iterated relevance matrix analysis (IRMA) for the
identification of class-discriminative subspaces. <em>NEUCOM</em>,
<em>577</em>, 127367. (<a
href="https://doi.org/10.1016/j.neucom.2024.127367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and investigate the iterated application of Generalized Matrix Learning Vector Quantization for the analysis of feature relevances in classification problems, as well as for the construction of class-discriminative subspaces. The suggested Iterated Relevance Matrix Analysis (IRMA) identifies a linear subspace representing the classification specific information of the considered data sets using Generalized Matrix Learning Vector Quantization (GMLVQ). By iteratively determining a new discriminative subspace while projecting out all previously identified ones, a combined subspace carrying all class-specific information can be found. This facilitates a detailed analysis of feature relevances, and enables improved low-dimensional representations and visualizations of labeled data sets. Additionally, the IRMA-based class-discriminative subspace can be used for dimensionality reduction and the training of robust classifiers with potentially improved performance.},
  archive      = {J_NEUCOM},
  author       = {Sofie Lövdal and Michael Biehl},
  doi          = {10.1016/j.neucom.2024.127367},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127367},
  shortjournal = {Neurocomputing},
  title        = {Iterated relevance matrix analysis (IRMA) for the identification of class-discriminative subspaces},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RPCS v2.0: Object-detection-based recurrent point cloud
selection method for 3D dense captioning. <em>NEUCOM</em>, <em>577</em>,
127350. (<a href="https://doi.org/10.1016/j.neucom.2024.127350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D dense captioning is the process of generating natural language descriptions for objects in a 3D scene, represented as RGB-D scans or point clouds. Three problems currently limit the potential performance of existing methods. First, existing methods randomly select points from the point cloud, leading to the exclusion of important points or inclusion of low-value points, for the detected objects. This, in turn, degrades the quality of generated descriptions. Although our previously proposed method, namely Recurrent Point Clouds Selection (RPCS) mitigates aforementioned issue, it possesses an inaccurate termination criterion that causes unexpected interruptions in the loop. Furthermore, existing methods utilize the older object detector, which limits their inherent performance. Finally, the descriptions generated by existing methods only describe individual detected objects in the scene, which may be inconvenient for viewers from a visual perspective. To address these problems, we propose RPCS v2.0, which features several improvements over our original design. To maintain a high quality of generated descriptions while avoiding the unexpected interruptions inherent to the original RPCS method, we propose a modified termination criterion that continuously compares the element counts of the bad list. To address limitations associated with the older object detector, we implemented a newer object detector to further improve performance. Finally, to ensure the user-friendliness of visuals, we leveraged a language model to summarize the generated descriptions, producing a comprehensive representation of the entire scene. Our proposed approach, referred to as ScanT3D, significantly mitigated the issue of suboptimal description generation and outperformed the state-of-the-art methods by a large margin (65.84%CiDEr@0.5IoU) .},
  archive      = {J_NEUCOM},
  author       = {Shinko Hayashi and Zhiqiang Zhang and Jinjia Zhou},
  doi          = {10.1016/j.neucom.2024.127350},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127350},
  shortjournal = {Neurocomputing},
  title        = {RPCS v2.0: Object-detection-based recurrent point cloud selection method for 3D dense captioning},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dense affinity matching for few-shot segmentation.
<em>NEUCOM</em>, <em>577</em>, 127348. (<a
href="https://doi.org/10.1016/j.neucom.2024.127348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-Shot Segmentation (FSS) aims to segment the novel class images with a few annotated samples. In this paper, we propose a dense affinity matching (DAM) framework to exploit the support-query interaction by densely capturing both the pixel-to-pixel and pixel-to-patch relations in each support-query pair with the bidirectional 3D convolutions. Different from the existing methods that remove the support background, we design a hysteretic spatial filtering module (HSFM) to filter the background-related query features and retain the foreground-related query features with the assistance of the support background, which is beneficial for eliminating interference objects in the query background. We comprehensively evaluate our DAM on ten benchmarks under cross-category, cross-dataset, and cross-field FSS tasks . Experimental results demonstrate that DAM performs very competitively under different settings with only 0.68M parameters, especially under cross-field FSS tasks, showing its effectiveness and efficiency. Code will be released at: https://github.com/chenhao-zju/PMNet .},
  archive      = {J_NEUCOM},
  author       = {Hao Chen and Yonghan Dong and Zheming Lu and Yunlong Yu and Yingming Li and Jungong Han and Zhongfei Zhang},
  doi          = {10.1016/j.neucom.2024.127348},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127348},
  shortjournal = {Neurocomputing},
  title        = {Dense affinity matching for few-shot segmentation},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024f). VeriPrune: Equivalence verification of node pruned neural
network. <em>NEUCOM</em>, <em>577</em>, 127347. (<a
href="https://doi.org/10.1016/j.neucom.2024.127347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network compression is a widely used technique when deploying the neural network in energy-constrained and computation-constrained devices. To guarantee the compressed neural network is still usable without too much accuracy loss, the equivalence between the compressed networks and the original ones must be verified. However, the current verification approach can only verify the equivalence of the two neural networks in the same structure which is limited and unseen in real-world scenarios. In this paper, we proposed an equivalence verification method named VeriPrune, which can verify the equivalence of the deep neural networks without the structure limitation. In detail, we proposed an innovative virtual node completing method to solve the problem that node pruning causes structure change and invalidates the existing equivalence verification approaches. To demonstrate the feasibility and efficiency of the proposed approach, we conducted experiments on the public dataset with 49 DNNs and 1272 properties. The results show that the 83.9% properties, the 1067 of the total 1272 properties can be verified. The proposed VeriPrune can be further developed as a CASE tool for the industry settings.},
  archive      = {J_NEUCOM},
  author       = {Weiru Wang and Kai Wang and Zhiyang Cheng and Yilong Yang},
  doi          = {10.1016/j.neucom.2024.127347},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127347},
  shortjournal = {Neurocomputing},
  title        = {VeriPrune: Equivalence verification of node pruned neural network},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust misinformation prevention with uncertainty on
suspicious nodes. <em>NEUCOM</em>, <em>577</em>, 127344. (<a
href="https://doi.org/10.1016/j.neucom.2024.127344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The misinformation prevention (MP) problem, which aims to find anchor nodes (P-seeds) to start an anti-spread of positive information, has attracted abundant research attention due to its practical application in reducing the risk of social unrest. Existing MP researches ideally assume that the M-seeds (nodes start misinformation spread) are known in advance. However, the misinformation spread usually occurs abruptly so that M-seeds are not easy to be identified as prior knowledge. In this paper, we study the MP problem with uncertain M-seeds. We assume that only a set of suspicious nodes (S-nodes) is known. Each S-node has a transition probability (T-prob) for becoming an M-seed. With different T-prob availability, we propose and study two new research problems: (1) the probabilistic MP (PMP) problem given exactly all the T-probs, and (2) the robust MP (RMP) problem given a confidence interval for each T-prob. For the PMP problem, we propose the prefixed Hybrid sampling based Misinformation Prevention (pHMP) algorithm that return a ɛ ( 1 − 1 / e − ɛ ) (1−1/e−ɛ) -approximate solution. For the RMP problem, we optimize the worst-case ratio between the current solution and the optimal one. Two bi-criteria algorithms are proposed that achieve both δ δ absolute error and ɛ ( 1 − 1 / e − ɛ ) 2 ( 1 − η ) (1−1/e−ɛ)2(1−η) and ɛ ( 1 − 1 / e − ɛ ) ( 1 − η ) (1−1/e−ɛ)(1−η) relative error respectively. We conduct extensive experiments on several real world datasets. The results show the proposed algorithms are superior over the baseline algorithm on all datasets, and robust against the changing of different application conditions.},
  archive      = {J_NEUCOM},
  author       = {Qihao Shi and Wujian Yang and Can Wang and Mingli Song},
  doi          = {10.1016/j.neucom.2024.127344},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127344},
  shortjournal = {Neurocomputing},
  title        = {Robust misinformation prevention with uncertainty on suspicious nodes},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Hierarchical text classification with multi-label
contrastive learning and KNN. <em>NEUCOM</em>, <em>577</em>, 127323. (<a
href="https://doi.org/10.1016/j.neucom.2024.127323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the complicated label hierarchy, hierarchical text classification (HTC) has emerged as a challenging subtask in the realm of multi-label text classification. Existing methods enhance the quality of text representations by contrastive learning , but this supervised contrastive learning is designed for single-label setting and has two main limitations. On one hand, sample pairs with completely identical labels which should be treated as positive pairs are ignored. On the other hand, a simple pair is deemed as an absolutely positive or negative pair, which lacks consideration about the situation where sample pairs share some labels while having labels unique to each sample. Therefore, we propose a method combining multi-label contrastive learning with KNN (MLCL-KNN) for HTC. The proposed multi-label contrastive learning method can make text representations of sample pairs having more shared labels closer and separate those with no labels in common. During inference, we employ KNN to retrieve several neighbor samples and regard their labels as additional prediction, which is interpolated into the model output to further improve the performance of MLCL-KNN. Compared with the strongest baseline, MLCL-KNN achieves average improvements of 0.31%, 0.76%, 0.83%, and 0.43% on Micro-F1, Macro-F1, accuracy, and HiF respectively, which demonstrates its effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Jun Zhang and Yubin Li and Fanfan Shen and Yueshun He and Hai Tan and Yanxiang He},
  doi          = {10.1016/j.neucom.2024.127323},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127323},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical text classification with multi-label contrastive learning and KNN},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated detection and forecasting of COVID-19 using deep
learning techniques: A review. <em>NEUCOM</em>, <em>577</em>, 127317.
(<a href="https://doi.org/10.1016/j.neucom.2024.127317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In March 2020, the World Health Organization (WHO) declared COVID-19 a global epidemic, caused by the SARS-CoV-2 virus. Initially, COVID-19 was diagnosed using real-time reverse transcription–polymerase chain reaction (RT-PCR) tests with a turnaround time of 2–3 days. To enhance diagnostic accuracy , medical professionals use medical imaging alongside RT-PCR. A positive result on both RT-PCR and medical imaging confirms a COVID-19 diagnosis. Imaging modalities like chest X-ray (CXR), computed tomography (CT) scans, and ultrasound are widely utilized for rapid and precise COVID-19 diagnoses. However, interpreting COVID-19 from these images is time-consuming and susceptible to human error. Therefore, leveraging artificial intelligence (AI) methods, particularly deep learning (DL) models, can deliver consistent, high-performance results. Unlike conventional machine learning (ML), DL models automate all stages of feature extraction, selection, and classification. This paper presents a comprehensive review of using DL techniques for diagnosing COVID-19 from medical imaging. The introduction provides an overview of diagnosing the coronavirus using medical imaging, highlighting associated challenges. Subsequently, the paper delves into key aspects of Computer-Aided Diagnosis Systems (CADS) based on DL methods for diagnosing COVID-19, covering segmentation, classification, explainable AI (XAI), and predictive research. Additionally, it reviews the rehabilitation systems such as the Internet of Medical Things (IoMT) in the context of COVID-19. In another section, uncertainty quantification (UQ) research is showcased, focusing on DL models for the diagnosis of Covid-19. Crucial challenges and future research directions are outlined in another section. Finally, discussion and conclusion sections are also provided at the end of the paper.},
  archive      = {J_NEUCOM},
  author       = {Afshin Shoeibi and Marjane Khodatars and Mahboobeh Jafari and Navid Ghassemi and Delaram Sadeghi and Parisa Moridian and Ali Khadem and Roohallah Alizadehsani and Sadiq Hussain and Assef Zare and Zahra Alizadeh Sani and Fahime Khozeimeh and Saeid Nahavandi and U. Rajendra Acharya and Juan M. Gorriz},
  doi          = {10.1016/j.neucom.2024.127317},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127317},
  shortjournal = {Neurocomputing},
  title        = {Automated detection and forecasting of COVID-19 using deep learning techniques: A review},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Fast implementation of object detection algorithm based on
homomorphic model transformation. <em>NEUCOM</em>, <em>577</em>, 127313.
(<a href="https://doi.org/10.1016/j.neucom.2024.127313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen significant advancements in computer vision, spearheaded by the advent of deep learning networks. However, the rigid architectures of these networks limit their potential. This study investigates how altering existing networks architecture can enhance performance. However, modifying layers in a model leads to a mismatch in pre-trained weights, resulting in the loss of a considerable amount of information embedded in the pre-trained model. Concurrently, an inefficient post-training process can lead to a significant waste of time if it does not fully leverage the pre-trained model weights. We propose a novel Homomorphic Model Transformation (HMT), based on functional algebraic identity, to overcome this challenge. HMT ensures that the model’s output remains identical to that of the original model even after expanding its architecture. This enables post-training enhancements to commence from the highest point of the original model. Experiment results reveal that HMT significantly improve training efficiency, reducing post-training time by over 90%. Additionally, HMT significantly enhances model performance metrics in a short timeframe, demonstrating a 4.70% increase in AP on the AI-TOD dataset, a 6.88% improvement on the DOTA1.5 dataset, a 3.05% enhancement on the COCO2017 dataset, and a 4.89% elevation on the MRSAText dataset.},
  archive      = {J_NEUCOM},
  author       = {Jin Liu and Hongyun Zhang},
  doi          = {10.1016/j.neucom.2024.127313},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127313},
  shortjournal = {Neurocomputing},
  title        = {Fast implementation of object detection algorithm based on homomorphic model transformation},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A self-adaptive ensemble for user interest drift learning.
<em>NEUCOM</em>, <em>577</em>, 127308. (<a
href="https://doi.org/10.1016/j.neucom.2024.127308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User interest reflects user preference which plays an important role in commercial decision-making. Learning and predicting user interest has attracted significant attention in recent years, however, user interest will change under uncertain environments as time passes, called user interest drift. This may adversely impact the accuracy of machine learning model prediction and lead to a delay in decision-making. How to detect and adapt to user interest drift in streaming data is an important problem which needs to be addressed. In this paper, we propose a novel method to detect user interest drift, called the topic-based user interest drift detection method (T-IDDM), which can recognize the severity of user interest drift. Then, a self-adaptive ensemble (SA-Ensemble) method with an adaptive weighted voting strategy is proposed to deal with user interest drift and reduce the time decay of the voting process. Next, a dynamic voting strategies selection process is proposed and applied to improve model robustness. Finally, an application study of user interest drift learning is presented to verify the proposed method. Twelve sequential online reviews datasets are collected and tested for the experiment. A comparison of our method with state-of-the-art benchmark methods shows its efficiency.},
  archive      = {J_NEUCOM},
  author       = {Kun Wang and Li Xiong and Anjin Liu and Guangquan Zhang and Jie Lu},
  doi          = {10.1016/j.neucom.2024.127308},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127308},
  shortjournal = {Neurocomputing},
  title        = {A self-adaptive ensemble for user interest drift learning},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on kernel-based multi-task learning.
<em>NEUCOM</em>, <em>577</em>, 127255. (<a
href="https://doi.org/10.1016/j.neucom.2024.127255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Task Learning (MTL) seeks to leverage the learning process of several tasks by solving them simultaneously to arrive at better models. This advantage is obtained by coupling the tasks together so that paths to share information among them are created. While Deep learning models have successfully been applied to MTL in different fields, the performance of deep approaches often depends on using large amounts of data to fit complex models with many parameters, something which may not be always feasible or, simply, they may lack some advantages that other approaches have. Kernel methods, such as Support Vector Machines or Gaussian Processes, offer characteristics such as a better generalization ability or the availability of uncertainty estimations, that may make them more suitable for small to medium size datasets. As a consequence, kernel-based MTL methods stand out among these alternative approaches to deep models and there also exists a rich literature on them. In this paper we review these kernel-based multi-task approaches, group them according to a taxonomy we propose, link some of them to foundational work on machine learning, and comment on datasets commonly used in their study and on relevant applications that use them.},
  archive      = {J_NEUCOM},
  author       = {Carlos Ruiz and Carlos M. Alaíz and José R. Dorronsoro},
  doi          = {10.1016/j.neucom.2024.127255},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127255},
  shortjournal = {Neurocomputing},
  title        = {A survey on kernel-based multi-task learning},
  volume       = {577},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ECMEE: Expert constrained multi-expert ensembles with
category entropy minimization for long-tailed visual recognition.
<em>NEUCOM</em>, <em>576</em>, 127357. (<a
href="https://doi.org/10.1016/j.neucom.2024.127357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When the training dataset follows a long-tail distribution, models tend to prioritize the majority of the data, thus resulting in lower predictive accuracy for the minority data. Among existing methods, integrating multiple experts with different logit distributions has yielded promising results. However, the current state-of-the-art (SOTA) ensemble method , i.e., Self-supervised Aggregation of Diverse Experts, trains three expert models separately to favor the head, middle, and tail data, respectively, without imposing mutual constraints. Failure to constrain the magnitude of logits among experts may result in higher category entropy, making it difficult to achieve an optimal ensemble solution. To address this issue, we propose the Expert Constrained Multi-Expert Ensembles with Category Entropy Minimization method, which consists of two new strategies: (1) Confidence Enhancement Loss to constrain the expert models based on maximizing target and non-target logit margins, thereby minimizing category entropy; (2) Shot-aware Weights associated with expert models to accommodate the shot-headed characteristic of the experts. Experiments demonstrate that our method effectively reduces expert category entropy, improves integration effectiveness, and achieves SOTA results on three datasets in diverse test distributions.},
  archive      = {J_NEUCOM},
  author       = {Yu Fu and Changjing Shang and Jungong Han and Qiang Shen},
  doi          = {10.1016/j.neucom.2024.127357},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127357},
  shortjournal = {Neurocomputing},
  title        = {ECMEE: Expert constrained multi-expert ensembles with category entropy minimization for long-tailed visual recognition},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantum variational distance-based centroid classifier.
<em>NEUCOM</em>, <em>576</em>, 127356. (<a
href="https://doi.org/10.1016/j.neucom.2024.127356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum machine learning is a rapidly growing field with the potential to surpass classical methods and offer novel solutions to learning problems. Supervised classification , a prominent pattern recognition task, has attracted significant attention for improving existing methods using quantum techniques. Although previous quantum algorithms for distance-based classification have shown promise, they are not compatible with current Noisy Intermediate-Scale Quantum (NISQ) devices and cannot handle multiclass problems . To address these limitations, we present the quantum Variational Distance-based Centroid Classifier (qVDCC), a hybrid approach that combines the Quantum One-Class Classifier (QOCC) and Parameterized Quantum Circuits (PQCs). This approach greatly improves the feasibility of multiclass classification on NISQ devices, as it eliminates the need for a label qubit and uses a single-qubit measurement, regardless of data size. Our simulations on seven benchmark datasets using both noisy and noise-free simulations show that qVDCC is competitive with the k-nearest neighbors algorithm, while providing exponential data compression and efficient quantum data processing.},
  archive      = {J_NEUCOM},
  author       = {Nicolas M. de Oliveira and Daniel K. Park and Israel F. Araujo and Adenilton J. da Silva},
  doi          = {10.1016/j.neucom.2024.127356},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127356},
  shortjournal = {Neurocomputing},
  title        = {Quantum variational distance-based centroid classifier},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bearing fault diagnosis via fusing small samples and
training multi-state siamese neural networks. <em>NEUCOM</em>,
<em>576</em>, 127355. (<a
href="https://doi.org/10.1016/j.neucom.2024.127355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning techniques have been widely applied to fault diagnosis due to their outstanding feature extraction abilities. The success of deep-learning-based fault diagnosis methods is highly dependent on the quantity and quality of the training data . In practical scenarios, it is challenging to obtain sufficient high-quality training data for fault diagnosis tasks due to complex environments, which would affect the effectiveness of the deep learning methods. In this paper, a new fault diagnosis method is proposed for motor bearing fault diagnosis under small samples. The Siamese neural networks (SNNs) are employed to extract the fault features. A multi-stage training strategy is proposed to train the SNNs with the aim to prevent the training stagnation problem and handle the small sample problem. A multi-source feature fusion network is developed to make full use of the multi-source sensor data by fusing the extracted fault features for further fault diagnosis. The proposed method is applied to motor bearing fault diagnosis on two real-world datasets. Experimental results demonstrate the effectiveness and feasibility of the introduced method for motor bearing fault diagnosis under small samples.},
  archive      = {J_NEUCOM},
  author       = {Chuanbo Wen and Yipeng Xue and Weibo Liu and Guochu Chen and Xiaohui Liu},
  doi          = {10.1016/j.neucom.2024.127355},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127355},
  shortjournal = {Neurocomputing},
  title        = {Bearing fault diagnosis via fusing small samples and training multi-state siamese neural networks},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A linear multivariate decision tree with branch-and-bound
components. <em>NEUCOM</em>, <em>576</em>, 127354. (<a
href="https://doi.org/10.1016/j.neucom.2024.127354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a new linear multivariate decision tree (MDT) algorithm that incorporates linear programming and components of the branch-and-bound methodology, such as bound-based pruning and node selection strategies. MDTs are known to better separate classes than univariate counterparts. However, the methodology used to construct splitting hyperplanes significantly affects the tree&#39;s performance. To determine the splitting hyperplane at each node, we efficiently solve a deviation model, a linear program (LP) that minimizes the external deviation of misclassified alternatives from the splitting hyperplane. The proposed MDT, called the MDT-DevM, uses upper and lower bounds for pruning. The deviation at a node provides an upper bound for its child. The lower bound is derived from the leaf nodes. The proposed pruning rule much contributes to the induction of a shallower and more accurate decision tree. Several node selection strategies ( depth_first , breadth_first and best_first ) are tried in the proposed MDT. We have also presented a variant of MDT, called the MDT-SVM, which utilizes linear SVM to find the splitting hyperplane. We performed comprehensive experiments on artificial and real datasets with different levels of complexity. We compared the proposed methods with benchmark classifiers . The proposed MDTs outperform the linear classifiers . The MDT-DevM shows better performance as the data becomes more dispersed and imbalanced.},
  archive      = {J_NEUCOM},
  author       = {Enver Engür and Banu Soylu},
  doi          = {10.1016/j.neucom.2024.127354},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127354},
  shortjournal = {Neurocomputing},
  title        = {A linear multivariate decision tree with branch-and-bound components},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiplicative update rules for accelerating deep learning
training and increasing robustness. <em>NEUCOM</em>, <em>576</em>,
127352. (<a href="https://doi.org/10.1016/j.neucom.2024.127352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Even nowadays, where Deep Learning (DL) has achieved state-of-the-art performance in a wide range of research domains, accelerating training and building robust DL models remains a challenging task. To this end, generations of researchers have pursued developing robust methods for training DL architectures that can be less sensitive to weight distributions, model architectures, and loss landscapes. However, such methods are limited to adaptive learning rate optimizers, initialization schemes, and clipping gradients without investigating the fundamental rule of parameters update. Although multiplicative updates have contributed significantly to the early development of machine learning and hold strong theoretical claims, to the best of our knowledge, this is the first work that investigates them in a unified manner in the context of DL optimization. In this work, we propose an optimization framework that fits a wide range of optimization algorithms and enables one to apply alternative update rules. To this end, we propose a novel multiplicative update rule and we extend their capabilities by combining it with a traditional additive update term, under a novel hybrid update method. We claim that the proposed framework accelerates training while leading to more robust models in contrast to traditionally used additive update rule, and we experimentally demonstrate its effectiveness in a wide range of task and optimization methods. Such tasks range from convex and non-convex optimization to difficult image classification benchmarks applying a wide range of traditionally used optimization methods and Deep Neural Network (DNN) architectures, providing quantitative and qualitative experimental results.},
  archive      = {J_NEUCOM},
  author       = {Manos Kirtas and Nikolaos Passalis and Anastasios Tefas},
  doi          = {10.1016/j.neucom.2024.127352},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127352},
  shortjournal = {Neurocomputing},
  title        = {Multiplicative update rules for accelerating deep learning training and increasing robustness},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Spiking neural p systems with neuron permeability.
<em>NEUCOM</em>, <em>576</em>, 127351. (<a
href="https://doi.org/10.1016/j.neucom.2024.127351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural P systems (SNP systems) are a class of distributed parallel and interpretable computing models developed in recent years, which are abstracted from the mechanism of spiking neurons and the nervous system . At present, the development of SNP variants has become a hot spot . To enhance the plasticity of SNP systems, inspired by the biological neural mechanism of the variable permeability of neurons, spiking neural P systems with neuron permeability (NP-SNP systems) are discovered and proposed as a novel variant of SNP systems. In NP-SNP systems, neurons have variable permeability directly related to membrane thickness. Membrane permeability changes with the change of membrane thickness. The proposed permeability spike rules are used to quantify changes in permeability. A specific NP-SNP system for generating arbitrary natural numbers is constructed. It is proved that the computing power of NP-SNP systems possesses Turing universality from number-generation, number-acceptance and computing functions. Devoted to the NP-complete problem, the NP-SNP system deterministically solves the Subset Sum problem in linear time. Compared with five variants, NP-SNP systems show advantages in less time steps and deterministic solutions.},
  archive      = {J_NEUCOM},
  author       = {Liping Wang and Xiyu Liu and Zheng Han and Yuzhen Zhao},
  doi          = {10.1016/j.neucom.2024.127351},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127351},
  shortjournal = {Neurocomputing},
  title        = {Spiking neural p systems with neuron permeability},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unveiling community structures in static networks through
graph variational bayes with evolution information. <em>NEUCOM</em>,
<em>576</em>, 127349. (<a
href="https://doi.org/10.1016/j.neucom.2024.127349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of graph variational Bayes theory, some representative community detection methods have been proposed. Although these methods are well designed, they are limited by the inherent constraints of static networks. Therefore, how to re-examine the information in static networks from a new perspective becomes a challenge. To this end, in this paper, we propose EG-VGAE and its variant EGC-VGAE, going beyond the constraints of static networks from a new perspective. Specifically, we first demonstrate that the evolution relations on static networks can be simulated reasonably. And then, our EG-VGAE method combines evolution information with static network information to realize a fine-grained propagation of local low-frequency signals to global low-frequency signals, thereby improving the accuracy of community assignment for each node. Building on this progress, our method EGC-VGAE imposes the smoothness constraint on adjacent slices, significantly enhancing the sensitivity of the method to evolution information and mitigating the impact of network noise. The comprehensive experimental results on real static networks well validate that our methods outperform state-of-the-art methods in most cases. The code is available at https://github.com/GDM-SCNU/EG-VGAE .},
  archive      = {J_NEUCOM},
  author       = {Junwei Cheng and Chaobo He and Kunlin Han and Gangbin Chen and Wanying Liang and Yong Tang},
  doi          = {10.1016/j.neucom.2024.127349},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127349},
  shortjournal = {Neurocomputing},
  title        = {Unveiling community structures in static networks through graph variational bayes with evolution information},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey and taxonomy on privacy-preserving
deep learning. <em>NEUCOM</em>, <em>576</em>, 127345. (<a
href="https://doi.org/10.1016/j.neucom.2024.127345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) has been shown to be very effective for many application domains of machine learning (ML), including image classification , voice recognition , natural language processing , and bioinformatics. The success of DL techniques is directly related to the availability of large amounts of training data . However, in many cases, the data are sensitive to the users and should be protected to preserve the privacy. Privacy-preserving deep learning (PPDL) has thus become a very active research field to ensure the training process and use of DL models are productive without exposing or leaking information about the data. This paper aims to provide a comprehensive survey of PPDL. We concentrate on the risks that affect data privacy in DL and conduct a detailed investigation into the models that ensure privacy. Finally, we propose a set of evaluation criteria, detailing the advantages and disadvantages of the solutions. Based on the analyzed strengths and weaknesses, the paper has highlighted some important research problems and application cases that have not been studied and these point to certain open research directions.},
  archive      = {J_NEUCOM},
  author       = {Anh-Tu Tran and The-Dung Luong and Van-Nam Huynh},
  doi          = {10.1016/j.neucom.2024.127345},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127345},
  shortjournal = {Neurocomputing},
  title        = {A comprehensive survey and taxonomy on privacy-preserving deep learning},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An extended neural ordinary differential equation network
with grey system and its applications. <em>NEUCOM</em>, <em>576</em>,
127343. (<a href="https://doi.org/10.1016/j.neucom.2024.127343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neural ordinary differential equation (NODE) has attracted much attention for its applicability in dynamic system modeling and continuous time series analysis. When the sample size is limited, models often exhibit weak generalizability and robustness and are susceptible to overfitting. To address this, a novel multivariate grey neural differential equation model is proposed based on the grey model and NODE. The new model leverages the small-sample modeling capabilities of grey systems to enhance the overall generalizability. When the neural network structure changes, the proposed model can degenerate into other grey models, enhancing inclusiveness and adaptability. Two energy forecasting cases show that the new model achieves average MAPE values of 0.82% and 1.13% on the test sets. These values are significantly better than those of the other 10 benchmark models. Furthermore, the proposed model exhibits superior performance in terms of the MAE, RMSE, STD, and APE metrics compared to those of all contrastive models. This study demonstrates that the new model effectively enhances its predictive capabilities on limited nonlinear data, showcasing higher prediction accuracy, stronger adaptability, and better stability.},
  archive      = {J_NEUCOM},
  author       = {Fangxue Zhang and Xinping Xiao and Mingyun Gao},
  doi          = {10.1016/j.neucom.2024.127343},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127343},
  shortjournal = {Neurocomputing},
  title        = {An extended neural ordinary differential equation network with grey system and its applications},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep latent space model for interpretable representation
learning on directed graphs. <em>NEUCOM</em>, <em>576</em>, 127342. (<a
href="https://doi.org/10.1016/j.neucom.2024.127342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation learning is a fundamental research problem for modeling relational data and benefits a number of downstream applications. Traditional Bayesian-based random graph models, such as the stochastic blockmodels (SBMs) and latent space models (LSMs), have proved effective to learn interpretable representations. To leverage both the good interpretability of random graph models and the powerful representation learning ability of deep learning-based methods such as graph neural networks (GNNs), some research proposes deep generative methods by combining the SBMs and GNNs. However, these combined methods have not fully considered the statistical properties of graphs which limits the model interpretability and applicability on directed graphs . To address these limitations in existing research, in this paper, we propose a Deep Latent Space Model (DLSM) for interpretable representation learning on directed graphs, by combining the LSMs and GNNs via a novel “lattice VAE” architecture. The proposed model generates multiple latent variables as node representations to adapt to the structure of directed graphs and improve model interpretability. Extensive experiments on representative real-world datasets demonstrate that our model achieves the state-of-the-art performances on link prediction and community detection with good interpretability.},
  archive      = {J_NEUCOM},
  author       = {Hanxuan Yang and Qingchao Kong and Wenji Mao},
  doi          = {10.1016/j.neucom.2024.127342},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127342},
  shortjournal = {Neurocomputing},
  title        = {A deep latent space model for interpretable representation learning on directed graphs},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on uncertainty quantification in deep learning for
financial time series prediction. <em>NEUCOM</em>, <em>576</em>, 127339.
(<a href="https://doi.org/10.1016/j.neucom.2024.127339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investors make decisions about buying and selling a financial asset based on available information. The traditional approach in Deep Learning when trying to predict the behavior of an asset is to take a price history, train a model, and forecast one single price in the near future. This is called the frequentist perspective. Uncertainty Quantification is an alternative in which models manage a probability distribution for prediction. It provides investors with more information than the traditional frequentist way, so they can consider the risk of making or not making a certain decision. We systematically reviewed the existing literature on Uncertainty Quantification methods in Deep Learning to predict the behavior of financial assets, such as foreign exchange, stock market, cryptocurrencies and others. The article discusses types of model, categories of financial assets, prediction characteristics and types of uncertainty. We found that, in general terms, references focus on price accuracy as a metric, although other metrics, such as trend accuracy, might be more appropriate. Very few authors analyze both epistemic and aleatoric uncertainty, and none analyze in depth how to decouple them. The time period analyzed includes the years 2001 to 2022.},
  archive      = {J_NEUCOM},
  author       = {Txus Blasco and J. Salvador Sánchez and Vicente García},
  doi          = {10.1016/j.neucom.2024.127339},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127339},
  shortjournal = {Neurocomputing},
  title        = {A survey on uncertainty quantification in deep learning for financial time series prediction},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Matrix factorization with a sigmoid-like loss control.
<em>NEUCOM</em>, <em>576</em>, 127338. (<a
href="https://doi.org/10.1016/j.neucom.2024.127338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix factorization is one of the fundamental approaches of recommender systems . With the popular L 2 L2 loss, learning models tend to overfit significantly deviated predictions. However, predicting the actual rating of 5 as 1 or 2 makes no essential difference in the application. In this paper, we design a sigmoid-like function to control the loss of each individual prediction, which has two advantages. First, it reduces the loss corresponding to significantly deviated predictions. Therefore, the impact of these predictions, some of which may be caused by outliers, is also reduced. Second, it is independent of two classical over-fitting control techniques using regular terms and validation data, respectively. Hence, it can be combined with them to form a more powerful method. Experiments are undertaken on six benchmark datasets in comparison with different losses. Results show that the proposed loss function has good performance in terms of MAE , RMSE, and NDCG, however not so good in terms of HR and MAP .},
  archive      = {J_NEUCOM},
  author       = {Yuan-Yuan Xu and Hui Xiao and Heng-Ru Zhang and Wei-Zhi Wu and Fan Min},
  doi          = {10.1016/j.neucom.2024.127338},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127338},
  shortjournal = {Neurocomputing},
  title        = {Matrix factorization with a sigmoid-like loss control},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal redundant transmission scheduling for remote state
estimation via reinforcement learning approach. <em>NEUCOM</em>,
<em>576</em>, 127337. (<a
href="https://doi.org/10.1016/j.neucom.2024.127337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the optimal redundant transmission scheduling for remote state estimation. Multiple smart sensors observe some systems, and transmit the local state estimates via independent channels to a remote estimator (RE), where packet losses may occur with some particular probabilities. To improve the estimation performance, some redundant channels are adopted for the data transmission. Since the number of redundant channels is fixed, the optimal redundant scheduling for multiple sensors is worth investigating to determine how to allocate the redundant channels. To address this problem, the redundant transmission scheduling is modeled as a Markov decision process (MDP) to minimize the estimation error for all systems. By constructing a sufficient condition , one ensures that the MDP has an optimal deterministic and stationary policy. Meanwhile, the threshold structure of the redundant transmission scheduling policy is verified to further decrease the complexity of the calculation. Reinforcement learning (RL) is used for this problem, and a near-optimal policy is obtained by dueling double-deep Q-networks (D3QN) algorithm. Finally, an illustrative simulation is presented to demonstrate its effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Yijin Jia and Lixin Yang and Yao Zhao and Jun-Yi Li and Weijun Lv},
  doi          = {10.1016/j.neucom.2024.127337},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127337},
  shortjournal = {Neurocomputing},
  title        = {Optimal redundant transmission scheduling for remote state estimation via reinforcement learning approach},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MDBSCAN: A multi-density DBSCAN based on relative density.
<em>NEUCOM</em>, <em>576</em>, 127329. (<a
href="https://doi.org/10.1016/j.neucom.2024.127329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DBSCAN is a widely used clustering algorithm based on density metrics that can efficiently identify clusters with uniform density. However, if the densities of different clusters are varying, the corresponding clustering results may be not good. To address this issue, we propose a multi-density DBSCAN based on the relative density (MDBSCAN), which can achieve better results on clusters with multiple densities. The intuition of our work is simple but effective, we first divide the dataset into two parts: low density and high density, and then we take a divide and conquer method to deal with the respective parts to avoid them interfering with each other. Specifically, the proposed MDBSCAN consists of three steps: (i) extract the low-density data points in the dataset by relative density. (ii) find natural clusters among the identified low-density data points. (iii) clustering the remaining data points (except the data points of natural clusters in a dataset) by using DBSCAN and assigning the noises (generated by DBSCAN) to the nearest clusters. To verify the effectiveness of the proposed MDBSCAN algorithm, we conduct experiments on ten synthetic datasets and six real-world datasets. Experimental results demonstrate that the proposed MDBSCAN algorithm outperforms the original DBSCAN and six extends of DBSCAN, especially including two state-of-the-art algorithms (DRL-DBSCAN and AMD-DBSCAN) in most cases.},
  archive      = {J_NEUCOM},
  author       = {Jiaxin Qian and You Zhou and Xuming Han and Yizhang Wang},
  doi          = {10.1016/j.neucom.2024.127329},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127329},
  shortjournal = {Neurocomputing},
  title        = {MDBSCAN: A multi-density DBSCAN based on relative density},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel healthy food recommendation to user groups based on
a deep social community detection approach. <em>NEUCOM</em>,
<em>576</em>, 127326. (<a
href="https://doi.org/10.1016/j.neucom.2024.127326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing food recommendation models have typically suggested foods or recipes to single users. However, in reality, users may be members of a group, family, or community, requiring food recommendation systems to support the whole group. Food recommendations to groups are a more challenging task than food recommendations to individuals, as each person’s preferences in the group should be addressed before giving the recommendations. Suggesting healthy food is also important in a food recommendation system, given that unhealthy diets can lead to different diseases. To address these challenges, a new healthy group food recommendation system based on deep social community detection and user popularity is developed in this study. To this end, an innovative deep community detection approach based on feature learning and deep neural networks is developed using the calculated time-aware user similarity measure. In addition, a health-aware rate prediction measurement, which considers both group preferences and health factors, is developed. Different experiments are designed on two real-food social networks to specify the efficiency of the suggested model, and the results indicate that it enhanced the single-user and group satisfaction metrics.},
  archive      = {J_NEUCOM},
  author       = {Mehrdad Rostami and Kamal Berahmand and Saman Forouzandeh and Sajad Ahmadian and Vahid Farrahi and Mourad Oussalah},
  doi          = {10.1016/j.neucom.2024.127326},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127326},
  shortjournal = {Neurocomputing},
  title        = {A novel healthy food recommendation to user groups based on a deep social community detection approach},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning methods for early detection of alzheimer’s
disease using structural MR images: A survey. <em>NEUCOM</em>,
<em>576</em>, 127325. (<a
href="https://doi.org/10.1016/j.neucom.2024.127325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an extensive review of the most recent works on Alzheimer’s disease (AD) prediction, focusing on Moderate Cognitive Impairment (MCI) conversion prediction. We aimed to identify the most useful brain-magnetic resonance imaging (MRI) biomarkers and deep learning frameworks used for prediction. To achieve this, we analyzed more than 130 studies and reviewed 7 articles. A closer examination revealed that the hippocampus is an important region of interest (ROI) affected early by AD, and many related features help detect the disease in its early stages. However, when considered alone, this ROI is not sufficient to ensure high prediction performance. Therefore, several other brain regions can also provide additional information to improve prediction accuracy. Concerning state-of-the-art deep neural networks , the U-Net represents the most efficient architecture for hippocampus segmentation. The RESU-Net architecture achieved the highest Dice Similarity Coefficient (DSC) value, equal to 94%.For MCI conversion prediction, the best results were obtained by two models identifying significant landmarks from the entire brain for classification. The multi-stream convolutional neural network achieved the best Area Under the Curve (AUC) and specificity of 94.39% and 99.70%, respectively. Finally, a region ensemble model delivered the highest accuracy of 85.90%, highlighting the need for further research to address this challenging problem.},
  archive      = {J_NEUCOM},
  author       = {Sonia Ben Hassen and Mohamed Neji and Zain Hussain and Amir Hussain and Adel M. Alimi and Mondher Frikha},
  doi          = {10.1016/j.neucom.2024.127325},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127325},
  shortjournal = {Neurocomputing},
  title        = {Deep learning methods for early detection of alzheimer’s disease using structural MR images: A survey},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An unclosed structures-preserving embedding model for signed
networks. <em>NEUCOM</em>, <em>576</em>, 127320. (<a
href="https://doi.org/10.1016/j.neucom.2024.127320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signed network embedding has sparked substantial attention since it learns a low-dimensional representation of signed networks. However, most existing methods overestimate the triadic interaction among nodes based on structural balance theory, leaving numerous unclosed structures in a distorted status, which hampers the accurate prediction of future link polarity and exacerbates polarization within networks. To address this issue, we propose the three link statuses preserving embedding model of signed networks, 3LP-SNE, which considers the no-link as a ”special link status” between positive and negative links. Our model captures the structural discrepancies inherent in three link statuses from fundamental binary relations , thereby preserving more complex structures. Specifically, we construct a mapping of three link statuses and distance intervals between nodes combining a three-way decision and a hyperbolic generative model of signed networks. Based on this, the three link statuses preserving is transformed into corresponding distance intervals preserving. Finally, a weighted likelihood function is designed for handling inter-class imbalanced problem and a corresponding optimization algorithm is developed to prevent the maximization of the likelihood function from converging into numerous local optima. The results of the link sign prediction task indicate the value of considering the no-link status and demonstrate the efficacy of our model in preserving primitive structures of signed networks.},
  archive      = {J_NEUCOM},
  author       = {Liang Du and Hao Jiang and Dongsheng Ye and Hao Li},
  doi          = {10.1016/j.neucom.2024.127320},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127320},
  shortjournal = {Neurocomputing},
  title        = {An unclosed structures-preserving embedding model for signed networks},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep cross-modal subspace clustering with contrastive
neighbour embedding. <em>NEUCOM</em>, <em>576</em>, 127318. (<a
href="https://doi.org/10.1016/j.neucom.2024.127318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep cross-modal clustering has been developing rapidly and attracted considerable attention in recent years. It aims to pursue a consistent subspace from different modalities with deep neural networks and achieves remarkable clustering performance. However, most existing methods do not simultaneously consider the inherently diverse information of each modality and the neighbour geometric structure over cross-modal data, which inevitably degrades the cluster structure revealed by the common subspace. In this paper, we propose a novel method named Deep Cross-Modal Subspace Clustering with Contrastive Neighbour Embedding (DCSC-CNE) to address the above challenge. DCSC-CNE maintains the inherent independence of each modality while concurrently uncovering consistent information across diverse modalities. In addition, we introduce a contrastive neighbour graph in the proposed deep cross-modal subspace clustering framework by performing contrastive learning between positive and negative samples, to highlight the underlying neighbour geometry of the original data and learn discriminative latent (subspace) representations. In this way, DCSC-CNE integrates the consistent-inherent learning and the contrastive neighbour embedding into a unified deep learning framework. Experimental results demonstrate that the proposed method can significantly improve the cross-modal subspace clustering performance compared with state-of-the-art methods on six benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Zihao Zhang and Qianqian Wang and Chengquan Pei and Quanxue Gao},
  doi          = {10.1016/j.neucom.2024.127318},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127318},
  shortjournal = {Neurocomputing},
  title        = {Deep cross-modal subspace clustering with contrastive neighbour embedding},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DHU-net: High-capacity binary data hiding network based on
improved u-net. <em>NEUCOM</em>, <em>576</em>, 127314. (<a
href="https://doi.org/10.1016/j.neucom.2024.127314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to limited data-hiding capacity and low extraction accuracy, most existing data hiding schemes have difficulty in high capacity hiding and lossless extraction of binary data. This paper proposes a novel binary data hiding network (DHU-Net) based on improved U-Net and flow encoding, which deepens the network structure and facilitates lossless extraction of high-capacity binary data. The BN layer is added to address overfitting and prevent vanishing gradient or exploding gradient. Furthermore, a novel binary-to-spatial domain mapping method is proposed to map the binary data to the spatial domain. Experimental results show that our scheme can achieve lossless extraction of binary data while maintaining low distortion and sufficient security. DHU-Net provides a promising solution for secure and efficient transmission of binary data through data hiding.},
  archive      = {J_NEUCOM},
  author       = {Xintao Duan and Chun Li and Bingxin Wei and Guoming Wu and Chuan Qin and Haewoon Nam},
  doi          = {10.1016/j.neucom.2024.127314},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127314},
  shortjournal = {Neurocomputing},
  title        = {DHU-net: High-capacity binary data hiding network based on improved U-net},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph-enhanced context aware framework for session-based
recommendation. <em>NEUCOM</em>, <em>576</em>, 127267. (<a
href="https://doi.org/10.1016/j.neucom.2024.127267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation (SBR) aims to recommend the next item according to the short-term historical interaction by the anonymous user. It is a popular method to transform sessions into graph architectures, and apply graph neural networks (GNN) to extract features and make recommendation in SBR. The previous GNN-based methods only focus on the propagation mechanism based on the primitive item graph, ignoring the hierarchical context in items and sessions. Besides, the problem of data sparsity is exacerbated in SBR due to the short-term length of session. Contrastive learning (CL) based on self-supervised augmentation shows potentials to tackle this problem. The existing CL-based SBR methods only consider from user aspect in the CL task, which is similar to the cross-entropy loss and ignores the explicit information of items. To address the above defects, we propose a novel Graph-Enhanced Context Aware Framework (GECAF), which can fully investigate the item context and session context through a more fine-grained graph construction . Especially, GECAF propose an item-based contrastive learning method to enrich semantic information in the item context. Extensive experiments on three datasets show the effectiveness of our model, which achieves state-of-art performance for the session-based recommendation.},
  archive      = {J_NEUCOM},
  author       = {Xinyi Zeng and Zequn Zhang and Shuchao Li and Zhi Guo and Yu Tian and Li Jin and Xian Sun},
  doi          = {10.1016/j.neucom.2024.127267},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127267},
  shortjournal = {Neurocomputing},
  title        = {Graph-enhanced context aware framework for session-based recommendation},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tri-relational multi-faceted graph neural networks for
automatic question tagging. <em>NEUCOM</em>, <em>576</em>, 127250. (<a
href="https://doi.org/10.1016/j.neucom.2024.127250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic question tagging is a crucial task in Community Question Answering (CQA) systems such as Zhihu or Quora, as it can significantly enhance the user experience by improving the efficiency of question answering and expert recommendations. Graph-based collaborative filtering models show promising performance on this task, as they can exploit not only the semantics of text content but also the existing relations between questions and tags. However, existing approaches typically encode each question into a single vector, which may not be able to capture the diverse semantic facets of questions in CQA systems. To address this challenge, we propose a novel question-tagging framework, named Tri-Relational Multi-Faceted Graph Neural Networks (TRMFG) for Automatic Question Tagging. In TRMFG, a tri-relational graph structure is designed to better model the question-tag relations. We also propose tri-relational question-tag GNN to extract hidden latent representations of questions and tags. Specially, the Multi-Faceted Question GNN helps capture the diverse semantics of questions from relevant tags. Then we build a multiple matching component to capture more complex matching patterns of the questions based on the diverse semantics. Our experimental results on three benchmark datasets demonstrate that TRMFG significantly improves question tagging performance for CQA, outperforming the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Nuojia Xu and Jun Hu and Quan Fang and Dizhan Xue and Yongxi Li and Shengsheng Qian},
  doi          = {10.1016/j.neucom.2024.127250},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127250},
  shortjournal = {Neurocomputing},
  title        = {Tri-relational multi-faceted graph neural networks for automatic question tagging},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Improving mode exploring capability of generative
adversarial nets by self-organizing map. <em>NEUCOM</em>, <em>576</em>,
127244. (<a href="https://doi.org/10.1016/j.neucom.2024.127244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of Generative Adversarial Nets (GANs) has pushed the research of generative models to a new climax. Backing this progress are the massive improvements in terms of architecture, loss function design, and regularization . Nevertheless, in the face of complex and diverse data distribution , various GAN variants are still plagued by incomplete mode coverage or even mode collapse. In this paper, we propose a new approach to train the GANs with one generator and a mixture of discriminators to overcome the mode collapse problem. In our model, each discriminator not only distinguishes real and fake samples but also differentiates modes in datasets. In essence, it combines a classical clustering idea called Self-Organizing Map and multiple discriminators into a unified optimization objective. Specifically, we define a topological structure over the multiple discriminators in order to diversify the generated samples and to capture multi-modes. We term this method Self-Organizing Map Generative Adversarial Nets (SOMGAN). By utilizing the parameter sharing trick, the proposed model requires trivial extra computation compared with GANs with a single discriminator. In our experiment, the method covers diverse data modes and gives outstanding performance in qualitative and quantitative evaluations . Since the topological constraint of discriminators is irrelevant to the generator, the SOM-based framework can be embedded into arbitrary GAN frameworks to maximize the generative capacity of the target model.},
  archive      = {J_NEUCOM},
  author       = {Wei Li and Yongxing He and Yongchuan Tang},
  doi          = {10.1016/j.neucom.2024.127244},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127244},
  shortjournal = {Neurocomputing},
  title        = {Improving mode exploring capability of generative adversarial nets by self-organizing map},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weakly supervised object localization via knowledge
distillation based on foreground–background contrast. <em>NEUCOM</em>,
<em>576</em>, 127213. (<a
href="https://doi.org/10.1016/j.neucom.2023.127213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised object localization (WSOL) is a challenging task that aims to localize objects in images using only image-level labels. Despite the widespread use of WSOL methods based on class activation mapping (CAM), such methods do not consider that the network may overly focus on local regions of the most interesting objects during localization, thus neglecting the overall information. To address this issue, we introduces an additional attention branch for convolutional neural networks (CNNs) that utilizes the attention mechanism of multi-layer perceptron (MLP) to enhance the network’s learning of global information and supervise the feature learning of CNNs online through knowledge distillation , thereby improving the localization accuracy of WSOL. Specifically, we designs a new loss function using the generated features to combine with contrastive learning , effectively dividing the foreground and background of the image to provide more accurate pseudo-labels for subsequent classification and localization tasks. In the experiments, we tested our method on the CUB-200-2011 dataset and compared it with existing methods. The experimental results show that our method achieves good performance in WSOL tasks.},
  archive      = {J_NEUCOM},
  author       = {Siteng Ma and Biao Hou and Zhihao Li and Zitong Wu and Xianpeng Guo and Chen Yang and Licheng Jiao},
  doi          = {10.1016/j.neucom.2023.127213},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127213},
  shortjournal = {Neurocomputing},
  title        = {Weakly supervised object localization via knowledge distillation based on foreground–background contrast},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Elastic step DQN: A novel multi-step algorithm to alleviate
overestimation in deep q-networks. <em>NEUCOM</em>, <em>576</em>,
127170. (<a href="https://doi.org/10.1016/j.neucom.2023.127170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Q-Networks algorithm (DQN) was the first reinforcement learning algorithm using deep neural network to successfully surpass human level performance in a number of Atari learning environments. However, divergent and unstable behaviour have been long standing issues in DQNs. The unstable behaviour is often characterised by overestimation in the Q Q -values, commonly referred to as the overestimation bias. To address the overestimation bias and the divergent behaviour, a number of heuristic extensions have been proposed. Notably, multi-step updates have been shown to drastically reduce unstable behaviour while improving agent’s training performance. However, agents are often highly sensitive to the selection of the multi-step update horizon ( n n ), and our empirical experiments show that a poorly chosen static value for n n can in many cases lead to worse performance than single-step DQN. Inspired by the success of n n -step DQN and the effects that multi-step updates have on overestimation bias, this paper proposes a new algorithm that we call ‘Elastic Step DQN’ (ES-DQN) to alleviate overestimation bias in DQNs. ES-DQN dynamically varies the step size horizon in multi-step updates based on the similarity between states visited. Our empirical evaluation shows that ES-DQN out-performs n n -step with fixed n n updates, Double DQN and Average DQN in several OpenAI Gym environments while at the same time alleviating the overestimation bias.},
  archive      = {J_NEUCOM},
  author       = {Adrian Ly and Richard Dazeley and Peter Vamplew and Francisco Cruz and Sunil Aryal},
  doi          = {10.1016/j.neucom.2023.127170},
  journal      = {Neurocomputing},
  month        = {4},
  pages        = {127170},
  shortjournal = {Neurocomputing},
  title        = {Elastic step DQN: A novel multi-step algorithm to alleviate overestimation in deep Q-networks},
  volume       = {576},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fusion detection and ReID embedding with hybrid attention
for multi-object tracking. <em>NEUCOM</em>, <em>575</em>, 127328. (<a
href="https://doi.org/10.1016/j.neucom.2024.127328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-object tracking (MOT) involves the prediction of object identities and their corresponding bounding boxes within video or image sequences. While numerous models have been proposed for MOT, there is still a lack of discrimination of object features and severe ID switches during the tracking stage. This paper presents a novel fusion detection and re-identification (ReID) embedding with hybrid attention for multi-object tracking to address this issue. It incorporates two major cores: a hybrid attention module (HAM) and an embedding association module (EAM). Firstly, the HAM comprises spatial-aware attention, scale-aware attention, and task-aware attention, aiming to obtain more informative features. By integrating these mechanisms, the proposed model can effectively handle variations in object scales and spatial relationships to promote discrimination and balance two tasks (detection and ReID). Secondly, we introduce an embedding association module to address the unreliable similarity matching during the tracking. Specifically, the EAM not only considers the appearance similarity but also ponders on geometric attributes to improve the ability to track in the presence of object occlusions and brief disappearances. Extensive experiments are conducted on the public MOT Challenge datasets, demonstrating that our method performs better than other advanced methods.},
  archive      = {J_NEUCOM},
  author       = {Sixian Chan and Chenhao Qiu and Dijuan Wu and Jie Hu and Ali Asghar Heidari and Huiling Chen},
  doi          = {10.1016/j.neucom.2024.127328},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127328},
  shortjournal = {Neurocomputing},
  title        = {Fusion detection and ReID embedding with hybrid attention for multi-object tracking},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic DNN weight pruning framework based on symmetric
accelerated stochastic ADMM. <em>NEUCOM</em>, <em>575</em>, 127327. (<a
href="https://doi.org/10.1016/j.neucom.2024.127327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weight pruning is widely employed in compressing Deep Neural Networks (DNNs) because of the increasing computation and storage requirement. However, related work failed to efficiently combine the structure of the DNN loss function with the Alternating Direction Method of Multipliers (ADMM). This paper presents a systematic weight pruning framework of DNNs using the advanced symmetric accelerated stochastic ADMM (SAS-ADMM). Specifically, the weight pruning problem of DNNs is formulated as an optimization problem that consists of the DNN loss function and a L 1 L1 regularization term . SAS-ADMM is widely used to solve the problem by dividing it into two small-dimensional and relatively easier subproblems. Besides, an optimizer based on SAS-ADMM is presented to make the DNNs after pruning converge. Experimental results demonstrate that our method achieves a faster convergence rate in a better or similar weight pruning rate than previous work. For the CIFAR-10 data set, our method reduces the number of ResNet-32 and ResNet-56 parameters by a factor of 6.61 × × and 9.93 × × while maintaining accuracy. In similar experiments of AlexNet on the ImageNet data set, we achieve 20.9 × × weight reduction, which only takes half of the time compared with prior work.},
  archive      = {J_NEUCOM},
  author       = {Ming Yuan and Jianchao Bai and Feng Jiang and Lin Du},
  doi          = {10.1016/j.neucom.2024.127327},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127327},
  shortjournal = {Neurocomputing},
  title        = {A systematic DNN weight pruning framework based on symmetric accelerated stochastic ADMM},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reconstructing creative thoughts: Hopfield neural networks.
<em>NEUCOM</em>, <em>575</em>, 127324. (<a
href="https://doi.org/10.1016/j.neucom.2024.127324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From a brain processing perspective, the perception of creative thinking is rooted in the underlying cognitive process , which facilitates exploring and cultivating novel avenues and problem-solving strategies. However, it is challenging to emulate the intricate complexity of how the human brain presents a novel way to uncover unique solutions. One potential approach to mitigating this complexity is incorporating creative cognition into the evolving artificial intelligence systems and associated neural models. Hopfield neural network (HNN) are commonly acknowledged as a simplified neural model, renowned for their biological plausibility to store and retrieve information, specifically patterns of neurons. Our findings suggest utilizing modern HNN to emulate creative thinking by making meaningful associations between seemingly disparate concepts. This semantic link is represented as a radio knob that can be set to determine whether the network solves problems creatively or shuts down; the threshold is a parameter. We used the term &quot;first knob of creativity&quot; to describe a certain pattern and utilized the &quot;second knob of creativity&quot; to aid in the examination of alternatives within the network. By manipulating the knobs, it is possible to selectively suppress specific patterns, facilitating the creative functioning of the HNN and identifying other patterns with which input can be linked.},
  archive      = {J_NEUCOM},
  author       = {Denisa Checiu and Mathias Bode and Radwa Khalil},
  doi          = {10.1016/j.neucom.2024.127324},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127324},
  shortjournal = {Neurocomputing},
  title        = {Reconstructing creative thoughts: Hopfield neural networks},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Passivity and robust passivity of impulsive inertial neural
networks with proportional delays under the non-reduced order approach.
<em>NEUCOM</em>, <em>575</em>, 127322. (<a
href="https://doi.org/10.1016/j.neucom.2024.127322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper primarily addresses the problems of passivity and robust passivity of impulsive inertial neural networks (IINNs) with proportional delays. By constructing the Lyapunov functional directly on the original system using the non-reduced order approach, some passivity and robust passivity criteria for IINNs are addressed. In comparison with the order reduction method utilized in the existing articles, the non-reduced order method is more in line with real requirements and can better analyze the dynamic behavior of inertial neural networks (INNs). Meanwhile, the results in this paper are all in algebraic form, which are easy to verify. To demonstrate the effectiveness of the results derived, numerical examples are presented at the end.},
  archive      = {J_NEUCOM},
  author       = {Jun Zhang and Song Zhu},
  doi          = {10.1016/j.neucom.2024.127322},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127322},
  shortjournal = {Neurocomputing},
  title        = {Passivity and robust passivity of impulsive inertial neural networks with proportional delays under the non-reduced order approach},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical feature selection based on neighborhood
interclass spacing from fine to coarse. <em>NEUCOM</em>, <em>575</em>,
127319. (<a href="https://doi.org/10.1016/j.neucom.2024.127319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In hierarchical classification learning , the hierarchical feature selection algorithm plays an important role in overcoming the curse of dimensionality. Existing hierarchical feature selection algorithms, based on the granular computing framework, all use three basic search strategies to search for similar and dissimilar classes. These strategies compute the importance of features to the global label for feature selection. However, existing methods based on the sibling strategy can only stay at the fine-grained level for feature selection, often without considering that the fine-grained level is also continuously separated from the coarse-grained level. Thus, these methods do not take into account the features hidden below the coarse granularity , resulting in the selection of a top-heavy subset of features and the loss of many important features. Therefore, this paper proposes a Hierarchical Feature Selection Based on Neighborhood Interclass Spacing From Fine to Coarse (HFSNIS) algorithm, which aims to change the feature selection to the coarse-grained hierarchy. The framework of the HFSNIS algorithm is as follows: First, each fine-grained leaf node is coarsened to the coarsest hierarchy of granularity from fine to coarse, where the non-root ancestor node is located. Next, the search for similar and dissimilar nearest neighbors is performed at the coarsest granularity hierarchy. Finally, the features are filtered using the Neighborhood Interclass Spacing model to obtain a subset of features. Therefore, this HFSNIS algorithm based on the Coarsest Search Strategy (CSS) can reselect features that were previously ignored in the fine-grained hierarchy, resulting in a better feature subset. Finally, the proposed algorithm outperforms seven state-of-the-art feature selection algorithms on six datasets.},
  archive      = {J_NEUCOM},
  author       = {Zilong Lin and Yaojin Lin},
  doi          = {10.1016/j.neucom.2024.127319},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127319},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical feature selection based on neighborhood interclass spacing from fine to coarse},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Discriminative and robust least squares regression for
semi-supervised image classification. <em>NEUCOM</em>, <em>575</em>,
127316. (<a href="https://doi.org/10.1016/j.neucom.2024.127316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the ability to leverage information from both unlabeled and labeled data, semi-supervised classification has found extensive applications in various practical scenarios. However, there are two major drawbacks: (1) Traditional graph construction leads to high algorithmic complexity , which limits efficiency. (2) The decision boundary might be blurred by boundary points in common cases. To cope with these issues, inspired by classical Least Squares Regression (LSR), we present a novel semi-supervised classification algorithm termed as Discriminative and Robust LSR (DRLSR) for semi-supervised image classification . First of all, a manifold regularization term is designed and introduced to an LSR-based semi-supervised method to preserve local manifold structures and smooth structures of the subspace, which strengthens the discrimination ability. Meanwhile, preservation of local manifold structures also contributes to restrain decision boundaries from being blurred by boundary points, which strengthens robustness of the algorithm. After that, an efficient alternative optimization method is applied to our algorithm. Evidence of the effectiveness of DRLSR are compelled by extensive experimental results.},
  archive      = {J_NEUCOM},
  author       = {Jingyu Wang and Cheng Chen and Feiping Nie and Xuelong Li},
  doi          = {10.1016/j.neucom.2024.127316},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127316},
  shortjournal = {Neurocomputing},
  title        = {Discriminative and robust least squares regression for semi-supervised image classification},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Neighbouring-slice guided multi-view framework for brain
image segmentation. <em>NEUCOM</em>, <em>575</em>, 127315. (<a
href="https://doi.org/10.1016/j.neucom.2024.127315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated segmentation of brain images is a critical task in neuroscience for brain registration, atlas generation, etc. Deep learning techniques have been widely investigated for segmenting brain images, where most existing methods only consider each brain slice independently in a single view, limiting their ability to explore the correlation among adjacent slices and spatial brain structures. This paper proposes a Neighbouring-slice Guided Multi-view Framework for automated segmentation of brain images. To fully utilize the information between neighbouring slices, we design a dual-decoder network to segment targets (e.g., regions/tumors) in brain images and the edge of each brain targets simultaneously, by calculating the difference between adjacent slices. Considering the fact that some brain images cannot be fully recognized in a single view, we integrate the neighbouring-slice strategy in a multi-view segmentation framework to fully explore spatial structures in 3D brains. The proposed framework is validated on the automated segmentation of diverse brain tumors and brain regions including CTX (cerebellar cortex), CP (caudoputamen), HPF (hippocampal formation), BS (brain stem), CB (cerebellum), and CBX (cerebellar cortex), in LSFM (Light-sheet Fluorescence Microscopy) and MRI (Magnetic Resonance Imaging) modalities, demonstrating superior performance in comparison with state-of-the-arts. The codes are released at: https://github.com/NeuronXJTU/NGMV .},
  archive      = {J_NEUCOM},
  author       = {Xuemeng Hu and Zhongyu Li and Yi Wu and Jingyi Liu and Xiang Luo and Jing Ren},
  doi          = {10.1016/j.neucom.2024.127315},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127315},
  shortjournal = {Neurocomputing},
  title        = {Neighbouring-slice guided multi-view framework for brain image segmentation},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Personalized and privacy-enhanced federated learning
framework via knowledge distillation. <em>NEUCOM</em>, <em>575</em>,
127290. (<a href="https://doi.org/10.1016/j.neucom.2024.127290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a distributed learning framework in which all participants jointly train a global model to ensure data privacy. In the existing federated learning framework, all clients share the same global model and cannot customize the model architecture according to their needs. In this paper, we propose FLKD (federated learning with knowledge distillation), a personalized and privacy-enhanced federated learning framework. The global model will serve as a medium for knowledge transfer in FLKD, and the client can customize the local model while training with the global model by mutual learning. Furthermore, the participation of the heterogeneous local models changes the training strategy of the global model, which means that FLKD has a natural immune effect against gradient leakage attacks. We conduct extensive empirical experiments to support the training and evaluation of our framework. Results of experiments show that FLKD provides an effective way to solve the problem of model heterogeneity and can effectively defend against gradient leakage attacks.},
  archive      = {J_NEUCOM},
  author       = {Fangchao Yu and Lina Wang and Bo Zeng and Kai Zhao and Rongwei Yu},
  doi          = {10.1016/j.neucom.2024.127290},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127290},
  shortjournal = {Neurocomputing},
  title        = {Personalized and privacy-enhanced federated learning framework via knowledge distillation},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aperiodically synchronization of multi-links delayed complex
networks with semi-markov jump and their numerical simulations to
single-link robot arms. <em>NEUCOM</em>, <em>575</em>, 127286. (<a
href="https://doi.org/10.1016/j.neucom.2024.127286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the p p th moment exponential synchronization problem of multi-links stochastic delayed complex networks with semi-Markov jump via aperiodically intermittent control. Combining random disturbances, time-varying delay and semi-Markov jump with multi-links systems, our work is more relevant than previous work. Based on Lyapunov method and graph theory, a novel inequality for disposing of the problem of p p th exponential synchronization is established under the aperiodically intermittent control and some sufficient criteria are derived. The theoretical results supply a new perspective showing the synchronization criterion and the topological structure of multi-links systems related closely. Furthermore, the value of our results is exhibited by applying them to the single-link robot arms in engineering. Eventually, a numerical simulation is provided to demonstrate the validity of our results.},
  archive      = {J_NEUCOM},
  author       = {Chang Gao and Beibei Guo and Yu Xiao and Junchen Bao},
  doi          = {10.1016/j.neucom.2024.127286},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127286},
  shortjournal = {Neurocomputing},
  title        = {Aperiodically synchronization of multi-links delayed complex networks with semi-markov jump and their numerical simulations to single-link robot arms},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The design of self-healing memristive network circuit based
on VTA DA neurons and its application. <em>NEUCOM</em>, <em>575</em>,
127283. (<a href="https://doi.org/10.1016/j.neucom.2024.127283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a self-healing memristive network circuit, which simulates the resilience mechanism of VTA DA neurons . The proposed memristive network circuit mainly consists of four modules: input (synapse) module, damage detection module, threshold trigger module and negative feedback module. The input module is composed of a memristive synaptic circuit, which can react to a harmful initial input rather than a normal initial input. Apart from reacting to initial input, the input module also can receive a feedback signal released by the negative feedback module, and the process of receiving feedback signal is the key of realizing the self-healing function. The damage detection module can output a low level pulse that acts as an input signal of the threshold trigger module when the harmful initial input exists. The threshold trigger module will activate the negative feedback module when the trigger point which corresponds to the positive threshold voltage of memristor is reached. As the last module of the self-healing function, the negative feedback module can transmit the feedback signal, also be called a repairing signal, to the damaged memristor of the input module. The PSPICE simulation results indicate that the proposed memristive network circuit can realize the self-healing function which corresponds to the resilience mechanism of the VTA DA neurons. Meanwhile, when the proposed memristive network circuit has been applied to the damaged electronic machines or robots, the self-healing function of it can make the machines be reusable.},
  archive      = {J_NEUCOM},
  author       = {Qiuzhen Wan and Jiong Liu and Peng Qin and Kunliang Sun and Qinghui Hong},
  doi          = {10.1016/j.neucom.2024.127283},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127283},
  shortjournal = {Neurocomputing},
  title        = {The design of self-healing memristive network circuit based on VTA DA neurons and its application},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Camera-based physiological measurement: Recent advances and
future prospects. <em>NEUCOM</em>, <em>575</em>, 127282. (<a
href="https://doi.org/10.1016/j.neucom.2024.127282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camera-based measurement of vital signs utilizes imaging equipment to measure physiological changes by analyzing human body images . The contactless physiological measurement provides benefits across various fields, from healthcare and clinical trial to telemedicine and exercise scenarios. On the basis of advances in medicine, optics, and computer vision, these technologies have made significant progress. Research in this area has grown exponentially in recent years. In this review, we provide a comprehensive and meticulous overview of camera-based measurements of physiological vital signs, including four aspects: data acquisition, methodology, vital signs and applications. It covers the measurement of heart rate, heart rate variability, respiratory rate, blood pressure, and oxygen saturation , using various technologies including motion detection, signal processing, and deep learning . We also present newly released datasets and applications in new areas. At last, future promising prospects and potential research directions are also discussed.},
  archive      = {J_NEUCOM},
  author       = {Jieying Wang and Caifeng Shan and Lin Liu and Zongshen Hou},
  doi          = {10.1016/j.neucom.2024.127282},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127282},
  shortjournal = {Neurocomputing},
  title        = {Camera-based physiological measurement: Recent advances and future prospects},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MKNBL: Joint multi-channel knowledge-aware network and broad
learning for sparse knowledge graph-based recommendation.
<em>NEUCOM</em>, <em>575</em>, 127277. (<a
href="https://doi.org/10.1016/j.neucom.2024.127277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address data sparsity and cold start problems in recommender systems , existing studies have utilized knowledge graph (KG) as side information to enhance the performance of recommendation. However, existing methods often explore side information only from one perspective, leading to limited expressive power in the representations of users and items. Some researchers have also combined broad learning system (BLS) with collaborative filtering (CF) to achieve efficient training. Yet the improvement of these approaches is influenced by the availability of data. These approaches perform poorly in cases of data sparsity. To solve these limitations, this study proposes a two-stage KG-based recommendation method (MKNBL) that integrates multi-channel knowledge-aware network (MKN) and BLS. The first stage focuses on exploring valuable side information. We adopt MKN to learn multi-view knowledge from KG. This enables recommender systems to widely utilize KG as side information to mitigate the limitations of data sparsity and cold start problems. The second stage focuses on efficient data enhancement learning. We employ BLS to enhance the valuable information discovered in the previous step, aiming to achieve better recommendation accuracy. Finally, we validate the high diversity and accuracy of MKNBL through experiments. Compared with other state-of-the-art (SOTA) methods, MKNBL achieves improvements of 7.50%, 3.06%, 5.35% and 3.07% in mean absolute error (MAE) in the Movielens-1M, Last.FM, Book-Crossing and Amazon datasets, respectively.},
  archive      = {J_NEUCOM},
  author       = {Li-e Wang and Yuelan Qi and Zhigang Sun and Xianxian Li},
  doi          = {10.1016/j.neucom.2024.127277},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127277},
  shortjournal = {Neurocomputing},
  title        = {MKNBL: Joint multi-channel knowledge-aware network and broad learning for sparse knowledge graph-based recommendation},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy-preserving small target defect detection of heat
sink based on DeceFL and DSUNet. <em>NEUCOM</em>, <em>575</em>, 127276.
(<a href="https://doi.org/10.1016/j.neucom.2024.127276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface defect detection is directly related to the quality of products and crucial for industrial production. Currently, convolutional neural network (CNN)-based structures have been widely used for surface defect detection. However, the locality restriction of convolutional operation poses challenges for surface defect detection, particularly when it comes to detecting small target defects. In addition, there is a risk of leakage during data communication arising from participant attacks. To address the above issues, the Dilated Swin Transformer UNet (DSUNet) model with privacy protection is proposed in this paper. Firstly, the DSUNet model adapting a hybrid CNN-Transformer architecture is designed to effectively address the challenge of detecting small defects, which can capture global and remote semantic information. Secondly, a decentralized federated learning framework (DeceFL) is introduced to protect data privacy. Finally, in order to enhance the interpretability of the model, the regional focus of the defect detection network is visualized through the Grad-CAM method. Comprehensive experiments on the heat sink surface defect dataset are conducted to demonstrate the effectiveness of our proposed model in the field of surface defect detection. The DSUNet achieves an accuracy of 97.98% on the dataset of heat sink surface defect, outperforming the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Feng Guo and Yong Zhang and Rukai Lan and Shaolin Ran and Yingjie Liang},
  doi          = {10.1016/j.neucom.2024.127276},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127276},
  shortjournal = {Neurocomputing},
  title        = {Privacy-preserving small target defect detection of heat sink based on DeceFL and DSUNet},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GraphMoCo: A graph momentum contrast model for large-scale
binary function representation learning. <em>NEUCOM</em>, <em>575</em>,
127273. (<a href="https://doi.org/10.1016/j.neucom.2024.127273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of cybersecurity, the ability to compute similarity scores at the function level for binary code is of utmost importance . Considering that a single binary file may contain an extensive amount of functions, an effective learning framework must exhibit both high accuracy and efficiency when handling substantial volumes of data. Nonetheless, conventional methods encounter several limitations. Firstly, accurately annotating different pairs of functions with appropriate labels poses a significant challenge, thereby making it difficult to employ supervised learning methods without risk of overtraining. Secondly, while SOTA models often rely on pre-trained encoders or fine-grained graph comparison techniques, these approaches suffer from drawbacks related to time and memory consumption. Thirdly, the momentum update algorithm utilized in graph-based contrastive learning models can result in information leakage . Surprisingly, none of the existing articles address this issue. This research focuses on addressing the challenges associated with large-scale Binary Code Similarity Detection (BCSD). To overcome the aforementioned problems, we propose GraphMoCo: a graph momentum contrast model that leverages multimodal structural information for efficient binary function representation learning on a large scale. We adopt an unsupervised learning strategy. Our approach eliminates the need for manual labeling. By leveraging the intrinsic structural information at multiple levels of the binary code, our model could achieve higher accuracy with a simple CNN-based model. By introducing the preshuffle mechanism, the issue of information leakage in graph momentum update algorithm is mitigated. The evaluation results indicate that GraphMoCo exhibits superior performance compared to SOTA approaches in the function pair search task, showing an average improvement of 7% on AUC, and 10% on MRR and Recall@1. Furthermore, GraphMoCo achieves a MAP of 0.93 on the more challenging dataset 2, which comprises a larger function pool. In a real-world scenario, specifically in known vulnerability searching, GraphMoCo achieves a MRR that surpasses existing SOTA models by 5%.},
  archive      = {J_NEUCOM},
  author       = {Runjin Sun and Shize Guo and Jinhong Guo and Wei Li and Xingyu Zhang and Xi Guo and Zhisong Pan},
  doi          = {10.1016/j.neucom.2024.127273},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127273},
  shortjournal = {Neurocomputing},
  title        = {GraphMoCo: A graph momentum contrast model for large-scale binary function representation learning},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Physics-constrained attack against convolution-based human
motion prediction. <em>NEUCOM</em>, <em>575</em>, 127272. (<a
href="https://doi.org/10.1016/j.neucom.2024.127272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human motion prediction has achieved a brilliant performance with the help of convolution-based neural networks . However, currently, there is no work evaluating the potential risk in human motion prediction when facing adversarial attacks . The adversarial attack will encounter problems against human motion prediction in naturalness and data scale. To solve the problems above, we propose a new adversarial attack method that generates the worst-case perturbation by maximizing the human motion predictor’s prediction error with physical constraints. Specifically, we introduce a novel adaptable scheme that facilitates the attack to suit the scale of the target pose and two physical constraints to enhance the naturalness of the adversarial example . The evaluating experiments on three datasets show that the prediction errors of all target models are enlarged significantly, which means current convolution-based human motion prediction models are vulnerable to the proposed attack. Based on the experimental results, we provide insights on how to enhance the adversarial robustness of the human motion predictor and how to improve the adversarial attack against human motion prediction. The code is available at https://github.com/ChengxuDuan/advHMP .},
  archive      = {J_NEUCOM},
  author       = {Chengxu Duan and Zhicheng Zhang and Xiaoli Liu and Yonghao Dang and Jianqin Yin},
  doi          = {10.1016/j.neucom.2024.127272},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127272},
  shortjournal = {Neurocomputing},
  title        = {Physics-constrained attack against convolution-based human motion prediction},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linear quadratic stochastic optimal control with state- and
control-dependent noises: A deterministic data approach.
<em>NEUCOM</em>, <em>575</em>, 127269. (<a
href="https://doi.org/10.1016/j.neucom.2024.127269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates an infinite-horizon linear quadratic stochastic optimal control (LQSOC) problem with state- and control-dependent noises, in which two system matrices are unknown. First, a deterministic system is introduced and a relationship among its system trajectory , its control and the matrices to be solved is formulated. Subsequently, based on the deterministic system, an adaptive dynamic programming (ADP) algorithm is established to tackle the LQSOC problem. Then, the convergence analysis is presented by proving the equivalence between the proposed algorithm and an existing policy iteration algorithm. Finally, the effectiveness of the obtained algorithm is verified by a perturbed turbocharged diesel engine optimal control design example.},
  archive      = {J_NEUCOM},
  author       = {Heng Zhang and Zhiguo Yan},
  doi          = {10.1016/j.neucom.2024.127269},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127269},
  shortjournal = {Neurocomputing},
  title        = {Linear quadratic stochastic optimal control with state- and control-dependent noises: A deterministic data approach},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Contrastive hawkes graph neural networks with dynamic
sampling for event prediction. <em>NEUCOM</em>, <em>575</em>, 127265.
(<a href="https://doi.org/10.1016/j.neucom.2024.127265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As prevalent graph-structured data evolves, representation learning for dynamic graphs has received widespread attention in recent years. Graph neural network on the dynamic graph learns dynamic features of nodes through time and structure exploration, and then performs downstream node-level (or edge-level or graph-level) task inference. Most research works model a sequence of graph snapshots for a set of discrete times (with the same interval), but such methods are difficult to handle for a dynamic graph that changes rapidly over time. In the case of a continuous-time dynamic graph, we design a Contrastive Hawkes Graph neural network with Dynamic Sampling (CHGDS) to model explicit historical importance and explore diverse neighbors. CHGDS establishes the time effect of nodes by Hawkes graph convolution, distinguishing the influence of different historical events on the current node. With dynamic sampling, our method balances time and space exploration of multi-hop neighbors. During the training phase, a contrastive learning strategy is adopted to enhance the robustness of dynamic node features. Experimental results on three continuous time dynamic graph datasets demonstrate up to 2% improvement of our model over the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Zongshen Mu and Yueting Zhuang and Siliang Tang},
  doi          = {10.1016/j.neucom.2024.127265},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127265},
  shortjournal = {Neurocomputing},
  title        = {Contrastive hawkes graph neural networks with dynamic sampling for event prediction},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Periocular embedding learning with consistent knowledge
distillation from face. <em>NEUCOM</em>, <em>575</em>, 127263. (<a
href="https://doi.org/10.1016/j.neucom.2024.127263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The periocular area, which refers to the peripheral area of the ocular, is a valid biometric for situations where facial recognition is not possible due to occlusion or masking. However, periocular biometrics alone can reduce discriminative information, particularly in wild environments. To address this, we propose Consistent Knowledge Distillation (CKD) that transfers discriminatory information from face images to periocular embeddings using temperature-based consistency. CKD achieves state-of-the-art results on challenging unconstrained periocular recognition benchmarks, improving performance by 49%–54% in relative gain. Furthermore, we provide insight into how CKD effectively extracts and transfers global inter-class relationship information by showing that CKD is equivalent to a learned-label smoothing approach with a novel sparsity-oriented regularizer.},
  archive      = {J_NEUCOM},
  author       = {Yoon Gyo Jung and Jaewoo Park and Cheng Yaw Low and Jacky Chen Long Chai and Leslie Ching Ow Tiong and Andrew Beng Jin Teoh},
  doi          = {10.1016/j.neucom.2024.127263},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127263},
  shortjournal = {Neurocomputing},
  title        = {Periocular embedding learning with consistent knowledge distillation from face},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain decomposed classification algorithms based on linear
discriminant analysis: An optimality theory and applications.
<em>NEUCOM</em>, <em>575</em>, 127261. (<a
href="https://doi.org/10.1016/j.neucom.2024.127261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear discriminant analysis (LDA) is a popular technique for supervised classification problems, and it works quite well when the number of classes is small, but the accuracy deteriorates when the number of classes becomes large. In this paper, we propose a domain decomposed method and an iteratively deflated method to improve the classification accuracy . In the domain decomposed LDA, we decompose the given dataset into subsets and apply LDA separately to each subset for the training part of the algorithm. In the testing step, we project the samples into multiple subspaces, contrary to the full space as in the traditional LDA. From the multiple low-dimensional projections we determine the class or classes that the sample belongs to. An optimality theory is developed to show why the new method offers better classification under a technical assumption. In the iteratively deflated method, the traditional LDA method serves as the initial iteration from which we select separable classes to be deflated from the training set, and the remaining samples in the dataset are used for the next iteration. As the process goes on we generate a sequence of projection matrices that are used to determine which class or classes a sample belongs to using certain classification criteria. With the proper choices of the quantile radii in the separable criteria for the training and testing phases, we show that the proposed method is much more accurate than the traditional LDA. To test and compare the two proposed methods, we consider the popular datasets CIFAR-10/100 and a gene expression dataset of cancer patients , and show that the new approaches outperform the traditional LDA by a large margin.},
  archive      = {J_NEUCOM},
  author       = {Jingwei Li and Xiao-Chuan Cai},
  doi          = {10.1016/j.neucom.2024.127261},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127261},
  shortjournal = {Neurocomputing},
  title        = {Domain decomposed classification algorithms based on linear discriminant analysis: An optimality theory and applications},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive multi-channel bayesian graph neural network.
<em>NEUCOM</em>, <em>575</em>, 127260. (<a
href="https://doi.org/10.1016/j.neucom.2024.127260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen a surge in interest in graph neural networks (GNNs) due to their superior performance in a range of graph and network mining applications. Graph embedding attempts to convert nodes in graph data to a low-dimensional vector representation by capturing the edges between them. However, because the bulk of GNNs currently use unstable graph structures, they perform well on graphs with a high degree of homogeneity and badly on those with a low degree of homogeneity. As a result, GNNs that rely solely on the original graph structure may give unsatisfactory results. In this research, we introduce an adaptive multi-channel Bayesian graph neural network (AMBGN 1 ) for estimating new graph structures and adaptively fusing some depth-related information between the original topological structures . The key idea is to follow the GNN mechanism by estimating the ideal graph structure using Bayesian inference and extracting specific and common embeddings from estimated graph structures, topological structures, and their combinations. We are able to maximize both estimated graph structure learning and node embedding in an iterative framework by using the attention approach to learn the significant weights of these three node embeddings. Our extensive research on a number of benchmark datasets with varied degrees of homogeneity demonstrated that AMBGN reliably estimates the graph structure and effectively learns the most relevant node information in both graph representations , confirming the usefulness of AMBGN.},
  archive      = {J_NEUCOM},
  author       = {Dong Yang and Zhaowei Liu and Yingjie Wang and Jindong Xu and Weiqing Yan and Ranran Li},
  doi          = {10.1016/j.neucom.2024.127260},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127260},
  shortjournal = {Neurocomputing},
  title        = {Adaptive multi-channel bayesian graph neural network},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Product promotion copywriting from multimodal data: New
benchmark and model. <em>NEUCOM</em>, <em>575</em>, 127253. (<a
href="https://doi.org/10.1016/j.neucom.2024.127253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our latest project, we devise a comprehensive corpus for product promotion text generation, named Video-Enabled Product Promotion Corpus (VPPC), which integrates multimodal and multi-structural information of products such as visual spatial details and fine structural specifics. It is crucial to highlight that this is one of the largest datasets available in the field of video captioning. Notably, conventional multimodal text generation often focuses on regular descriptions of entities and events, which doesn not suffice the real-world requirements of product promotion copywriting, as it necessitates a more lively language style and a high degree of authenticity. Regrettably, there is an evident lack of reusable evaluation frameworks and sufficient datasets at the current stage. To address these challenges, we have proposed a unique baseline approach and authenticity evaluation metric , both tailored to meet the realistic demands of our dataset. The results are promising, as our method surpasses previous approaches across all evaluation metrics.},
  archive      = {J_NEUCOM},
  author       = {Jinjin Ren and Liming Lin and Wei Zheng},
  doi          = {10.1016/j.neucom.2024.127253},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127253},
  shortjournal = {Neurocomputing},
  title        = {Product promotion copywriting from multimodal data: New benchmark and model},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-embedding domain video steganography algorithm based
on TU partitioning and intra prediction mode. <em>NEUCOM</em>,
<em>575</em>, 127247. (<a
href="https://doi.org/10.1016/j.neucom.2024.127247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With High Efficiency Video Coding (HEVC) becoming a popular video coding standard in the world, combing the HEVC with data hiding methods is a complex task. In this paper, a multi-embedded video steganography algorithm based on Intra Prediction Mode (IPM) and Transform Unit (TU) partition is proposed. By analyzing the coding characteristics of the TU partition and the IPM, we select embedded regions that are relatively independent as much as possible. Then, suitable distortion functions are designed for different embedding domains. Using the minimum distortion framework of the STC model to embed messages. The experimental results indicate that the proposed method achieves a maximum embedding capacity 1.5 times larger than that of traditional single domain embedding methods, while maintaining good visual quality.},
  archive      = {J_NEUCOM},
  author       = {Heyu Xing and Lihua Tian and Mingyuan Cao and Chen Li},
  doi          = {10.1016/j.neucom.2024.127247},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127247},
  shortjournal = {Neurocomputing},
  title        = {A multi-embedding domain video steganography algorithm based on TU partitioning and intra prediction mode},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relation-oriented few-shot knowledge graph prototype
networks. <em>NEUCOM</em>, <em>575</em>, 127242. (<a
href="https://doi.org/10.1016/j.neucom.2024.127242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph (KG) embedding has been widely researched, but it suffers from some problems in the few-shot scenarios. The topological and semantic connection among entities cannot satisfy the assumption of samples’ independent identically distribution. Additionally, these relations between entity pairs are various and complex. But most of the previous methods are node-oriented, which is weak in modeling complex relations. In order to solve the above problems, we propose a few-shot relation prototype network (FRPN). In our method, each relation is regarded as a learning object , instead of just entity pairs’ concatenation. A relation-oriented two-channel embedding mechanism is designed to achieve multi-scale information aggregation at the entity level and the relation level respectively. For the entity level, it aggregates information at different scales according to the relation type and the neighbors under each relation. For the relation level, our model obtains each kind of relation’s prototype from the ontology and the entity layer. The multi-scale aggregation contributes to KG embedding in the few-shot scenario. Compared with existing models, our model has significantly improved the performance on both the link prediction and triple classification tasks in two few-shot datasets.},
  archive      = {J_NEUCOM},
  author       = {Yingying Xue and Aibo Song and Jiahui Jin and Hui Peng and Jingyi Qiu and Xiaolin Fang and Xiaorui Zhai},
  doi          = {10.1016/j.neucom.2024.127242},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127242},
  shortjournal = {Neurocomputing},
  title        = {Relation-oriented few-shot knowledge graph prototype networks},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uncertainty-aware pseudo-label filtering for source-free
unsupervised domain adaptation. <em>NEUCOM</em>, <em>575</em>, 127190.
(<a href="https://doi.org/10.1016/j.neucom.2023.127190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-free unsupervised domain adaptation (SFUDA) aims to enable the utilization of a pre-trained source model in an unlabeled target domain without access to source data. Self-training is a way to solve SFUDA, where confident target samples are iteratively selected as pseudo-labeled samples to guide target model learning. However, prior heuristic noisy pseudo-label filtering methods all involve introducing extra models, which are sensitive to model assumptions and may introduce additional errors or mislabeling. In this work, we propose a method called Uncertainty-aware Pseudo-label-filtering Adaptation (UPA) to efficiently address this issue in a coarse-to-fine manner. Specially, we first introduce a sample selection module named Adaptive Pseudo-label Selection (APS), which is responsible for filtering noisy pseudo labels. The APS utilizes a simple sample uncertainty estimation method by aggregating knowledge from neighboring samples and confident samples are selected as clean pseudo-labeled. Additionally, we incorporate Class-Aware Contrastive Learning (CACL) to mitigate the memorization of pseudo-label noise by learning robust pair-wise representation supervised by pseudo labels. Through extensive experiments conducted on three widely used benchmarks, we demonstrate that our proposed method achieves competitive performance on par with state-of-the-art SFUDA methods.},
  archive      = {J_NEUCOM},
  author       = {Xi Chen and Haosen Yang and Huicong Zhang and Hongxun Yao and Xiatian Zhu},
  doi          = {10.1016/j.neucom.2023.127190},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127190},
  shortjournal = {Neurocomputing},
  title        = {Uncertainty-aware pseudo-label filtering for source-free unsupervised domain adaptation},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel energy management method for multiple residential
energy systems with energy exchange. <em>NEUCOM</em>, <em>575</em>,
127185. (<a href="https://doi.org/10.1016/j.neucom.2023.127185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy saving and emission reduction are the worldwide outstanding problems in the development of economy and society, which lead to wide attention of residential energy management. This paper presents a novel energy management method for multiple residential energy systems with energy exchange based on action-dependent heuristic dynamic programming (ADHDP). The major contributions are displayed as follows: (1) a novel energy management model is established for multiple residential energy systems with real-time electricity price and time-varying residential loads; (2) a novel ADHDP based energy management method is presented to obtain the energy scheduling scheme of multiple residential energy systems; (3) the continuous control action of the overall system is transformed into discrete control space which avoids training the action network. First, the structure and system models of multiple residential energy systems are introduced, and the energy management problem is formulated. Then, a brief introduction of ADHDP method is provided. Based on this, an energy management method is presented and an effective discretization method of control action is developed for solving the presented energy management problem with less computational burden. Simulation results show that the presented method can reduce the energy cost effectively. Finally, the comparison results verify the superiorities over the traditional energy management methods.},
  archive      = {J_NEUCOM},
  author       = {Hongyang Li and Qinglai Wei},
  doi          = {10.1016/j.neucom.2023.127185},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127185},
  shortjournal = {Neurocomputing},
  title        = {A novel energy management method for multiple residential energy systems with energy exchange},
  volume       = {575},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bioinspired actor-critic algorithm for reinforcement
learning interpretation with levy–brown hybrid exploration strategy.
<em>NEUCOM</em>, <em>574</em>, 127291. (<a
href="https://doi.org/10.1016/j.neucom.2024.127291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, reinforcement learning , the interpretability of the algorithm is a challenge. The lack of interpretability limits the use of reinforcement learning limited when facing agents in the physical world. To improve the interpretability of reinforcement learning, this study proposes a Levy-Brown hybrid strategy to improve the working of the traditional Actor-Critic algorithm. The proposed strategy is bioinspired from the Brown motion and Levy motion in nature; therefore, it can explain the process of data acquisition in the learning process from biological principles. The main idea of this new strategy is to map the Gaussian strategy to the biological Brown motion, and introduce the biological Levy strategy to improve the exploration efficiency. By combining the two strategies, it effectively takes advantage of the Levy strategy to improve exploration speed and the Brown strategy to improve exploration stability. The experiments demonstrate the advantages of the proposed Levy-Brown hybrid strategy, which effectively make best use of the advantages and overcomes the disadvantages of the two strategies. The code is available at https://www.researchgate.net/publication/377014427_LevyBrown_Hyribd_strategy .},
  archive      = {J_NEUCOM},
  author       = {Xiao Wang and Dazi Li},
  doi          = {10.1016/j.neucom.2024.127291},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127291},
  shortjournal = {Neurocomputing},
  title        = {Bioinspired actor-critic algorithm for reinforcement learning interpretation with Levy–Brown hybrid exploration strategy},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fixed-time passivity of multi-weighted coupled
quaternion-valued neural networks. <em>NEUCOM</em>, <em>574</em>,
127289. (<a href="https://doi.org/10.1016/j.neucom.2024.127289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses fixed-time passivity (FIXTP) for multi-weighted coupled quaternion-valued neural networks (CQVNNs), where the FIXTP does not require that the output and input are real-valued. By means of the quaternion-valued sign function and some related properties, several sufficient conditions are given to guarantee the FIXTP of CQVNNs. Moreover, considering that passivity is a useful tool to tackle the synchronization for multi-weighted coupled neural networks , the relationship between FIXTP and fixed-time synchronization (FIXTS) for CQVNNs is also revealed, which extends the application scope of the passivity. In addition, some FIXTS criteria for CQVNNs are derived on basis of FIXTP, which has not been done by others. Finally, a simulation example is given to check the validity of the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Wanlu Wei and Jin-Liang Wang},
  doi          = {10.1016/j.neucom.2024.127289},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127289},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time passivity of multi-weighted coupled quaternion-valued neural networks},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time synchronization of delayed fuzzy inertial neural
networks via intermittent control. <em>NEUCOM</em>, <em>574</em>,
127288. (<a href="https://doi.org/10.1016/j.neucom.2024.127288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the finite-time synchronization (FTS) issue of delayed fuzzy inertial neural networks (DFINNs) via intermittent control. The considered network model takes the inertia term and fuzzy logic into account, which complements some of the existing models. By an appropriate variable substitution, the second-order DFINNs are turned into first-order equation forms. Then, based on the finite-time stability theory, intermittent control strategies are adopted to ensure the FTS of DFINNs and the corresponding criteria are derived thereafter. Besides, the estimation of settling-time for FTS is presented. Finally, the numerical simulations and the image encryption application are presented to illustrate the validity of main results and the control method .},
  archive      = {J_NEUCOM},
  author       = {Leimin Wang and Yaqian Hu and Cheng Hu and Yingjiang Zhou and Shiping Wen},
  doi          = {10.1016/j.neucom.2024.127288},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127288},
  shortjournal = {Neurocomputing},
  title        = {Finite-time synchronization of delayed fuzzy inertial neural networks via intermittent control},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event-triggered global consensus of second-order multi-agent
systems with asymmetric input saturation. <em>NEUCOM</em>, <em>574</em>,
127287. (<a href="https://doi.org/10.1016/j.neucom.2024.127287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the event-triggered global consensus issue of second-order multi-agent systems (MASs) with asymmetric input saturation, where the zero saturation bounds are allowed. First, for the leaderless situation, we propose an event-triggered mechanism and give the criterion for realizing global consensus. Different from the traditional event-triggered strategy in an effort to exclude the Zeno behavior , a preset minimum triggering interval is introduced. That is, the control input will not be updated within this interval after the latest trigger time, and the event-triggered condition is activated after this interval. Moreover, the above results are extended to the leader–follower case. Finally, some numerical examples illustrate the effectiveness of the developed schemes.},
  archive      = {J_NEUCOM},
  author       = {Jiewen Ji and Zhicheng Zhang and Zhiqiang Zuo and Yijing Wang},
  doi          = {10.1016/j.neucom.2024.127287},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127287},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered global consensus of second-order multi-agent systems with asymmetric input saturation},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multivariate markov chain model for interpretable dense
action anticipation. <em>NEUCOM</em>, <em>574</em>, 127285. (<a
href="https://doi.org/10.1016/j.neucom.2024.127285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense action anticipation, as opposed to next action anticipation, deals with predicting multiple actions over a long horizon of a few minutes. Recent approaches for dense action anticipation are based on deep learning , which lacks interpretability in that the models cannot explain the decisions made through a causal relationship between past observations and predictions. In this paper, we propose a Goal oriented multivariate Markov chain (GoMMC) for interpretable dense action anticipation, which can capture the influence between various objects and their interactions, allowing for a probabilistic selection of actions performed in the long term. Experiments on 50Salads and Breakfast datasets show that the proposed model performs better than deep learning models when ground truth information on past objects and actions is available.},
  archive      = {J_NEUCOM},
  author       = {Yihui Qiu and Deepu Rajan},
  doi          = {10.1016/j.neucom.2024.127285},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127285},
  shortjournal = {Neurocomputing},
  title        = {A multivariate markov chain model for interpretable dense action anticipation},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An optimized CNN-BiLSTM network for bearing fault diagnosis
under multiple working conditions with limited training samples.
<em>NEUCOM</em>, <em>574</em>, 127284. (<a
href="https://doi.org/10.1016/j.neucom.2024.127284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at limitations in fully exploiting the temporal correlation features of the original signals, expensive cost in parameter tuning, and difficulties in obtaining sufficient training data under multiple working conditions, this paper proposes an optimized Convolutional Neural Network (CNN) with Bi-directional Long Short-Term Memory (BiLSTM) scheme for bearing fault diagnosis under multiple working conditions with limited training samples . A CNN-BiLSTM network is developed to obtain precise fault features and high detection accuracy by extracting high-dimensional and temporal correlation features of raw vibration signals . An improved particle swarm optimization (PSO) algorithm is leveraged to optimize the training hyperparameters of the CNN-BiLSTM network for further advances in fault diagnosis performance. The optimized CNN-BiLSTM network is regarded as a pre-trained model and transferred to new working conditions to achieve satisfactory fault diagnosis results based on limited training samples. Several comprehensive experiments are implemented to confirm the excellent performance of the proposed schemes, especially efficiently addressing the challenges of model training and fault diagnosis in new working conditions with scarce samples.},
  archive      = {J_NEUCOM},
  author       = {Baoye Song and Yiyan Liu and Jingzhong Fang and Weibo Liu and Maiying Zhong and Xiaohui Liu},
  doi          = {10.1016/j.neucom.2024.127284},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127284},
  shortjournal = {Neurocomputing},
  title        = {An optimized CNN-BiLSTM network for bearing fault diagnosis under multiple working conditions with limited training samples},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Person group detection with global trajectory extraction in
a disjoint camera network. <em>NEUCOM</em>, <em>574</em>, 127281. (<a
href="https://doi.org/10.1016/j.neucom.2024.127281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person group detection refers to the grouping of people with similar spatio-temporal trajectories. In this work, we address the problem of automatically detecting groups of people from disjoint camera views, which has an essential application in public safety but has not been seriously studied. The main challenge of this task is that the sparse distribution of cameras in a large surveillance area makes it difficult to infer and match people’s trajectories across cameras. To address this challenge, we propose a CCRF (Cyclic Conditional Random Fields) based model for cross-camera trajectory extraction, which takes both visual appearance and heterogeneous spatio-temporal information (including camera locations, video capture times, and the map of the surveillance area) as input and infers multiple candidate cross-camera trajectories for each person. Then, for each pair of people, we propose to use a dynamic trajectory warping (DTW) method to measure the similarity of their trajectories. DTW uses visual features to optimize the selection of trajectories and addresses the problem of trajectory length matching. Since there is no existing dataset that can directly support our research, we enrich our previously built Person Trajectory Dataset by adding the person group annotation and then verify the effectiveness of the proposed method on this dataset. The dataset and code are released at https://github.com/zhangxin1995/PTD_GROUP .},
  archive      = {J_NEUCOM},
  author       = {Xin Zhang and Xiaohua Xie and Li Wen and Jianhuang Lai},
  doi          = {10.1016/j.neucom.2024.127281},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127281},
  shortjournal = {Neurocomputing},
  title        = {Person group detection with global trajectory extraction in a disjoint camera network},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse optimization guided pruning for neural networks.
<em>NEUCOM</em>, <em>574</em>, 127280. (<a
href="https://doi.org/10.1016/j.neucom.2024.127280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network pruning is a critical field aimed at reducing the infrastructure costs of neural networks by removing parameters. Traditional methods follow a fixed paradigm including pretraining, pruning, and fine-tuning. Despite the close relationship among these three stages, most pruning methods treat them as independent processes. In this paper, we propose a novel two-stage pruning method, which includes pretraining a network that is instructive for subsequent pruning, and a unified optimization model that integrates pruning and fine-tuning. Specifically, in the first stage, we design a group sparse regularized model for pretraining. This model not only safeguards the network from irreversible damage but also offers valuable insights for the pruning process. In the second stage, we introduce an element-wise sparse regularization into pruning model. This model enables us to pinpoint sparse weights more precisely than pretrained network. It automatically derives effective pruning criteria, and omits the step of fine-tuning. To implement the two-stage process in practice, we utilize stochastic gradient algorithm for the pretraining and design a threshold algorithm for pruning stage. Extensive experiments confirm the competitive performance of our proposed method in terms of both accuracy and memory cost when compared to various benchmarks. Furthermore, ablation experiments validate the effectiveness of the proposed pretraining model’s guidance for the pruning process.},
  archive      = {J_NEUCOM},
  author       = {Yong Shi and Anda Tang and Lingfeng Niu and Ruizhi Zhou},
  doi          = {10.1016/j.neucom.2024.127280},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127280},
  shortjournal = {Neurocomputing},
  title        = {Sparse optimization guided pruning for neural networks},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spikeformer: Training high-performance spiking neural
network with transformer. <em>NEUCOM</em>, <em>574</em>, 127279. (<a
href="https://doi.org/10.1016/j.neucom.2024.127279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although spiking neural networks (SNNs) have made great progress on both performance and efficiency over the last few years, their unique working pattern makes it hard to train high-performance low-latency SNNs and their development still lags behind traditional artificial neural networks (ANNs). To compensate this gap, many extraordinary works have been proposed, but these works are mainly based on the same network structure (i.e. CNN) and their performance is worse than their ANN counterparts, which limits the applications of SNNs. To this end, we propose a Transformer-based SNN, termed ”Spikeformer”, which outperforms its ANN counterpart on both static dataset and neuromorphic datasets. First, to deal with the problem of “data hungry” and the unstable training period exhibited in the vanilla model, we design the Convolutional Tokenizer (CT) module, which stabilizes training and improves the accuracy of the original model on DVS-Gesture by more than 16%. Besides, we integrate Spatio-Temporal Attention (STA) into Spikeformer to better incorporate the attention mechanism inside Transformer and the spatio-temporal information inherent to SNN. With our proposed method, we achieve 98.96%/75.89% top-1 accuracy on DVS-Gesture/ImageNet datasets with 16/4 simulation time steps. On DVS-CIFAR10, we further conduct energy consumption analysis and obtain 81.4%/80.3% top-1 accuracy with 4/1 time step(s), achieving 1.7/6.4 × × energy efficiency over its ANN counterpart. Moreover, our Spikeformer outperforms its ANN counterpart by 3.13% and 0.12% on DVS-Gesture and ImageNet respectively, indicating that Spikeformer may be a more suitable architecture for training SNNs compared to CNN . We believe that this work shall promote the development of SNNs to be in step with ANNs as much as possible. Code will be publicly available.},
  archive      = {J_NEUCOM},
  author       = {Yudong Li and Yunlin Lei and Xu Yang},
  doi          = {10.1016/j.neucom.2024.127279},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127279},
  shortjournal = {Neurocomputing},
  title        = {Spikeformer: Training high-performance spiking neural network with transformer},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel method of rolling bearings fault diagnosis based on
singular spectrum decomposition and optimized stochastic configuration
network. <em>NEUCOM</em>, <em>574</em>, 127278. (<a
href="https://doi.org/10.1016/j.neucom.2024.127278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis of rolling bearings is essential for the safe operation of rotating machinery. However, in the production process, the rolling bearings have a complex working environment embedded with weak fault signals and a large number of interfering signals, which is a considerable challenge to automatically and accurately detect bearing fault type from the actual vibration signal . Therefore, a novel fault diagnosis scheme is proposed based on singular spectrum decomposition (SSD) and an optimized stochastic configuration network (SCN). Firstly, SSD is used to pre-process the original rolling bearings vibration signal to obtain several singular spectral components (SSCs) and the practical component is selected according to the maximum correlation coefficient for signal reconstruction. Furthermore, time domain and power spectrum entropy (PSE) features of the reconstructed signal are extracted to obtain a fault information-rich feature sets. In addition, the parameters of the SCN are optimized by marine predators algorithm (MPA) to enhance the learning ability and generalization performance of the SCN. Finally, the feature sets are input into MPA-SCN to achieve fault classification. Experimental results exhibit that the proposed method has higher accuracy in rolling bearings fault diagnosis compared with other methods, which provides a high-efficiency solution for rolling bearings fault diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Shenquan Wang and Ganggang Lian and Chao Cheng and Hongtian Chen},
  doi          = {10.1016/j.neucom.2024.127278},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127278},
  shortjournal = {Neurocomputing},
  title        = {A novel method of rolling bearings fault diagnosis based on singular spectrum decomposition and optimized stochastic configuration network},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Almost sure finite-time synchronization of markov jump
complex dynamical networks with asynchronous switching. <em>NEUCOM</em>,
<em>574</em>, 127275. (<a
href="https://doi.org/10.1016/j.neucom.2024.127275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The almost sure finite-time synchronization for Markovian jump complex dynamical networks (CDNs) with time-varying delay is studied. The designed controller is supposed to be asynchronous with the CDNs states. The existing almost sure synchronization result of networks is explored within a finite time interval. The sampled-data control approach is employed to improve the control precision. Some sufficient criteria are obtained under the definition of almost sure finite-time synchronization for the CDNs with Markovian switching topology . To determine the asynchronous controller gain, the linear matrix inequality-based conditions are proposed. Then, two examples are given to illustrate the effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Jun Guo and Yao Wang and Yuming Bo},
  doi          = {10.1016/j.neucom.2024.127275},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127275},
  shortjournal = {Neurocomputing},
  title        = {Almost sure finite-time synchronization of markov jump complex dynamical networks with asynchronous switching},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-level semantic-assisted unsupervised heterogeneous
network representation learning model. <em>NEUCOM</em>, <em>574</em>,
127274. (<a href="https://doi.org/10.1016/j.neucom.2024.127274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous networks , which model various real-world scenarios, have gained significant attention in recent years due to their rich semantic information. Existing heterogeneous network representation models often focus on capturing semantic information through meta-paths, but they overlook the semantic information of higher-order neighborhoods based on meta-paths and the clusters to which nodes belong. Moreover, while many existing methods perform well with labeled data, unsupervised network representation learning becomes essential for dealing with large amounts of unlabeled data in practical applications. To address these issues, this paper proposes an unsupervised heterogeneous network representation learning model with multi-level semantic assistance. The model leverages mutual information maximization to construct a loss function for unsupervised learning . It captures first-level semantics of nodes through graph convolutional networks and meta-path fusion mechanisms to create initial node representations. Then, it utilizes mutual information to acquire second-level semantics, i.e., higher-order neighborhood information based on meta-paths, by maximizing the mutual information between the initial node representations and the global graph representation based on meta-paths. Additionally, a cluster-aware mechanism is designed to capture third-level semantic information by maximizing the mutual information between the initial node representation and the representation of the cluster to which the node belongs, considering the cluster information of the node. Comprehensive experiments on three real datasets demonstrate the effectiveness and efficiency of the proposed method in node classification and clustering tasks . Moreover, the method exhibits better robustness when the network is destroyed to some extent.},
  archive      = {J_NEUCOM},
  author       = {Qun Liu and Chengxin Peng and Shuyin Xia and Guoyin Wang},
  doi          = {10.1016/j.neucom.2024.127274},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127274},
  shortjournal = {Neurocomputing},
  title        = {A multi-level semantic-assisted unsupervised heterogeneous network representation learning model},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Blind face restoration: Benchmark datasets and a baseline
model. <em>NEUCOM</em>, <em>574</em>, 127271. (<a
href="https://doi.org/10.1016/j.neucom.2024.127271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blind Face Restoration (BFR) aims to generate high-quality face images from low-quality inputs. However, existing BFR methods often use private datasets for training and evaluation, making it challenging for future approaches to compare fairly. To address this issue, we introduce two benchmark datasets, BFRBD128 and BFRBD512, for evaluating state-of-the-art methods in five scenarios: blur, noise, low resolution, JPEG compression artifacts , and full degradation. We use seven standard quantitative metrics and two task-specific metrics, AFLD and AFICS . Additionally, we propose an efficient baseline model called Swin Transformer U-Net (STUNet), which outperforms state-of-the-art methods in various BFR tasks. The codes, datasets, and trained models are publicly available at: https://github.com/bitzpy/Blind-Face-Restoration-Benchmark-Datasets-and-a-Baseline-Model .},
  archive      = {J_NEUCOM},
  author       = {Puyang Zhang and Kaihao Zhang and Wenhan Luo and Changsheng Li and Guoren Wang},
  doi          = {10.1016/j.neucom.2024.127271},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127271},
  shortjournal = {Neurocomputing},
  title        = {Blind face restoration: Benchmark datasets and a baseline model},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain-control prompt-driven zero-shot relational triplet
extraction. <em>NEUCOM</em>, <em>574</em>, 127270. (<a
href="https://doi.org/10.1016/j.neucom.2024.127270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot relational triplet extraction is a vital solution to the problem of fact extracted from unstructured text without labeled training data . In the task, the data is divided into seen and unseen relations for training and prediction, respectively. A strategy that trains a generative model based on seen data first and generates training samples for unseen data has been shown to be effective in solving this task. However, this strategy is severely limited by error propagation caused by generated noisy data. To address this issue, prompts may provide a feasible route since they have been widely utilized in cross-domain tasks. In this paper, three preliminary experiments reveal the effectiveness of prompts for the task of triplet extraction and its internal mechanism. Specifically, the method using prompts can control the domain. 1 Further, we propose a simple but effective model for zero-shot relational triplet extraction, which leverages zero-shot text classification to first determine the prompts of unseen relations aiming to optimize both its domain and length, and then extracts triplets via prompt-driven strategy. Extensive experiments are conducted on two public datasets, demonstrating that the proposed model achieves a better performance than baselines.},
  archive      = {J_NEUCOM},
  author       = {Liang Xu and Changxia Gao and Xuetao Tian},
  doi          = {10.1016/j.neucom.2024.127270},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127270},
  shortjournal = {Neurocomputing},
  title        = {Domain-control prompt-driven zero-shot relational triplet extraction},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guaranteed-performance consensus control for multi-agent
systems with external disturbances via event-triggered strategy.
<em>NEUCOM</em>, <em>574</em>, 127268. (<a
href="https://doi.org/10.1016/j.neucom.2024.127268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the leader-following guaranteed performance consensus problem for multi-agent systems(MASs) controlled by event-triggered under external disturbances. First, a disturbance observer is designed for each follower, which can be used to efficiently estimate external disturbances. Second, to reduce the waste of communication resources, a new distributed event-triggered strategy based on the state estimation of neighboring agents is presented, which does not need continuous communication among agents. And the growing estimation error is reset by communication updates. The analysis illustrates that Zeno behavior can be effectively averted by formulating a lower bound on the number of normals for the minimum inter-event interval. Also, based on the above proposed state feedback consensus protocol with guaranteed performance, sufficient conditions are derived to guarantee that a MASs can achieve leader-following consensus. In addition, the consensus criterion with guaranteed performance is put forward in the form of a linear matrix inequality. The cost of guaranteed performance with leader-following structural properties is also established. At last, an example of numerical simulation is presented to confirm the derived analytical solution.},
  archive      = {J_NEUCOM},
  author       = {Na Zhao and Xisheng Zhan and Jie Wu and Tao Han and Huaicheng Yan},
  doi          = {10.1016/j.neucom.2024.127268},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127268},
  shortjournal = {Neurocomputing},
  title        = {Guaranteed-performance consensus control for multi-agent systems with external disturbances via event-triggered strategy},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meta-learning for efficient unsupervised domain adaptation.
<em>NEUCOM</em>, <em>574</em>, 127264. (<a
href="https://doi.org/10.1016/j.neucom.2024.127264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The standard machine learning assumption that training and test data are drawn from the same probability distribution does not hold in many real-world applications due to the inability to reproduce testing conditions at training time. Existing unsupervised domain adaption (UDA) methods address this problem by learning a domain-invariant feature space that performs well on available source domain(s) (labeled training data) and the specific target domain (unlabeled test data). In contrast, instead of simply adapting to domains, this paper aims for an approach that learns to adapt effectively to new unlabeled domains. To do so, we leverage meta-learning to optimize a neural network such that an unlabeled adaptation of its parameters to any domain would yield a good generalization on this latter. The experimental evaluation shows that the proposed approach outperforms standard approaches even when a small amount of unlabeled test data is used for adaptation, demonstrating the benefit of meta-learning prior knowledge from various domains to solve UDA problems.},
  archive      = {J_NEUCOM},
  author       = {Anna Vettoruzzo and Mohamed-Rafik Bouguelia and Thorsteinn Rögnvaldsson},
  doi          = {10.1016/j.neucom.2024.127264},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127264},
  shortjournal = {Neurocomputing},
  title        = {Meta-learning for efficient unsupervised domain adaptation},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A stochastic optimization technique for hyperparameter
tuning in reservoir computing. <em>NEUCOM</em>, <em>574</em>, 127262.
(<a href="https://doi.org/10.1016/j.neucom.2024.127262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new approach to reservoir computing (RC) optimization. Reservoir computing (RC) is a framework for building recurrent neural networks (RNNs) that alleviates the well-known learning difficulties in such neural networks by training only the output layer. While the weights of the input and the nonlinear hidden layers are randomly generated, the adjustment of critical hyperparameters, such as the input and the feedback scaling factor , is essential for optimal performance in RC. While recent hardware implementations of RC are crucial for high-speed processing, standard gradient-based hyperparameter optimization is often irrelevant due to potentially uncertain or time-varying internal functions and parameters. In this work, we propose and analyze a stochastic optimization approach using gradient approximations based solely on noisy measurements of the loss function to circumvent this problem. Our numerical and experimental results confirm that the proposed method can provide near-optimal RC hyperparameters with substantial complexity reduction compared to competing methods, validating its potential for RC optimization.},
  archive      = {J_NEUCOM},
  author       = {Nickson Mwamsojo and Frederic Lehmann and Kamel Merghem and Yann Frignac and Badr-Eddine Benkelfat},
  doi          = {10.1016/j.neucom.2024.127262},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127262},
  shortjournal = {Neurocomputing},
  title        = {A stochastic optimization technique for hyperparameter tuning in reservoir computing},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Adaptive dual graph regularization for clustered multi-task
learning. <em>NEUCOM</em>, <em>574</em>, 127259. (<a
href="https://doi.org/10.1016/j.neucom.2024.127259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key challenge of multi-task learning is how to exploit the structure across all tasks. In practice, relevant tasks are partially associated with similar meaningful feature subgroups, which implies an overlapped task-feature co-cluster structure. Besides discovering relationships at the task level, collaboratively identifying relevant meaningful structure relationship among features is beneficial to properly capture the structure of tasks. Toward this aim, we propose a clustered multi-task learning approach that collaboratively learns the cluster structure for both task and feature level effects. Specifically, an adaptive dual graph regularization , which respectively formulates the similarity of tasks and features, is introduced to guide the learning process to discover task-feature co-cluster relationship in a flexible way. Additionally, without any prior knowledge, the similarity weight of dual graph regularization can be automatically inferred through adaptive graph learning during model training. Experimental studies validate the effectiveness of our approach in terms of improving predictive performance and capturing clear cluster structure among tasks. The source code of the proposed method is available at GitHub: https://github.com/CLiu272/AdualGraph .},
  archive      = {J_NEUCOM},
  author       = {Cheng Liu and Rui Li and Sentao Chen and Lin Zheng and Dazhi Jiang},
  doi          = {10.1016/j.neucom.2024.127259},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127259},
  shortjournal = {Neurocomputing},
  title        = {Adaptive dual graph regularization for clustered multi-task learning},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed analytics for big data: A survey.
<em>NEUCOM</em>, <em>574</em>, 127258. (<a
href="https://doi.org/10.1016/j.neucom.2024.127258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, a constant and fast information growing has characterized digital applications in the majority of real-life scenarios. Thus, a new information asset, namely Big Data, has been defined and lead to different challenges, mainly related to data storage, management and analysis. Focusing on the last challenge, several Big Data analytics techniques have been developed, based on Machine Learning and Deep Learning paradigms. When dealing with Big Data, traditional approaches often take a lot of time to produce even a single predictive model , due to the extremely high demand of computational resources . The design of approaches specifically oriented to Big Data is required to overcome these computational issues. Most solutions rely on the deployment of Big Data analytics infrastructures on a cluster of machines and/or on parallelization techniques. When deployment and parallelization apply to Machine Learning and Deep Learning, we can refer to the terms Distributed Machine Learning and Distributed Deep Learning, respectively. We here discuss the main principles and features of Distributed Machine Learning and Distributed Deep Learning frameworks. The main contribution of this work is a survey of solutions proposed in the literature, through the investigation of selected features and capabilities. In particular, the survey provides a comparative analysis according to the following classification criteria: implemented parallelization technique, supporting device, supported architecture, implemented communication mode, working mode, and class of algorithms. The paper also gives an overview of the most commonly used criteria and metrics for the performance evaluation of analyzed frameworks; finally, some emerging but promising optimization techniques are reviewed apart from our classification.},
  archive      = {J_NEUCOM},
  author       = {Francesco Berloco and Vitoantonio Bevilacqua and Simona Colucci},
  doi          = {10.1016/j.neucom.2024.127258},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127258},
  shortjournal = {Neurocomputing},
  title        = {Distributed analytics for big data: A survey},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). K-NN attention-based video vision transformer for action
recognition. <em>NEUCOM</em>, <em>574</em>, 127256. (<a
href="https://doi.org/10.1016/j.neucom.2024.127256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action Recognition aims to understand human behavior and predict a label for each action. Recently, Vision Transformer (ViT) has achieved remarkable performance on action recognition, which models the long sequences token over spatial and temporal index in a video. The fully-connected self-attention layer is the fundamental key in the vanilla Transformer. However, the redundant architecture of the vision Transformer model ignores the locality of video frame patches, which involves non-informative tokens and potentially leads to increased computational complexity . To solve this problem, we propose a k k -NN attention-based Video Vision Transformer ( k k -ViViT) network for action recognition. We adopt k k -NN attention to Video Vision Transformer (ViViT) instead of original self-attention, which can optimize the training process and neglect the irrelevant or noisy tokens in the input sequence. We conduct experiments on the UCF101 and HMDB51 datasets to verify the effectiveness of our model. The experimental results illustrate that the proposed k k -ViViT achieves superior accuracy compared to several state-of-the-art models on these action recognition datasets.},
  archive      = {J_NEUCOM},
  author       = {Weirong Sun and Yujun Ma and Ruili Wang},
  doi          = {10.1016/j.neucom.2024.127256},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127256},
  shortjournal = {Neurocomputing},
  title        = {K-NN attention-based video vision transformer for action recognition},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An approximation algorithm for bus evacuation problem.
<em>NEUCOM</em>, <em>574</em>, 127252. (<a
href="https://doi.org/10.1016/j.neucom.2024.127252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large-scale disasters, evacuation using public transport, such as buses, is always essential, especially with limitations on the time window and resources available. Unfortunately, a Bus Evacuation Problem (BEP) is NP-hard in nature. This means it is impossible to find an optimal evacuation plan within a reasonable time window. Therefore, it is efficacious and requisite to use an approximation algorithm such that a sub-optimal plan can be derived quickly in large-scale disasters. In the literature, an approximation algorithm for BEP has been presented. However, there is not only a lack of rigorous proof of the approximation ratio, but also the computation time of the approximation algorithm is influenced by the number of evacuees. In this work, firstly the approximation ratio is derived as 2 n b + 7 2nb+7 , where n b nb is the number of buses, which is fundamentally more precise than the existing work. Further, the approximation ratio can be reduced to n b + 6 nb+6 through a new proof provided in this work. More importantly, a new approximation algorithm is proposed in this work, with an aggregated network flow model that can be quickly solved as a linear programming problem in polynomial time . The approximation ratio of the new algorithm is proven to be n b + 1 nb+1 when there is a pile of buses, and the computation time is insensitive to the number of evacuees. Finally, 10 sets of random cases and a real-life disaster, the flooding in Xingguo, China in 2019 are studied to illustrate the efficiency and practical applicability of the proposed approximation algorithm.},
  archive      = {J_NEUCOM},
  author       = {Yuanyuan Feng and Yi Cao and Shuanghua Yang and Lili Yang and Tangjian Wei},
  doi          = {10.1016/j.neucom.2024.127252},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127252},
  shortjournal = {Neurocomputing},
  title        = {An approximation algorithm for bus evacuation problem},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blind video quality assessment based on spatio-temporal
feature resolver. <em>NEUCOM</em>, <em>574</em>, 127249. (<a
href="https://doi.org/10.1016/j.neucom.2024.127249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a method to measure video quality, blind video quality assessment (BVQA) plays an important role in video related applications . Feature extraction, as a vital component of BVQA, significantly impacts the performance and speed of the method. In the process of designing BVQA method, we make the feature extraction process independent of the whole quality evaluation method. First, a Spatio-Temporal Feature Resolver (STFR) is obtained by training. Then, the STFR is employed to directly extract the spatio-temporal features of the video sequences. Finally, the extracted features are mapped to quality scores using Support Vector Regression (SVR). STFR only needs to be trained in an undistorted video sequence, and can be directly applied to video sequences of various scenes, which has a universality. To evaluate the effectiveness of the proposed method, the experimental results on four published video quality databases show that the proposed BVQA method not only achieves more accurately than the existing BVQA methods, but also exhibits significant competitiveness in computational speed.},
  archive      = {J_NEUCOM},
  author       = {Xiaodong Bi and Xiaohai He and Shuhua Xiong and Zeming Zhao and Honggang Chen and Raymond Edward Sheriff},
  doi          = {10.1016/j.neucom.2024.127249},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127249},
  shortjournal = {Neurocomputing},
  title        = {Blind video quality assessment based on spatio-temporal feature resolver},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robot skill learning system of multi-space fusion based on
dynamic movement primitives and adaptive neural network control.
<em>NEUCOM</em>, <em>574</em>, 127248. (<a
href="https://doi.org/10.1016/j.neucom.2024.127248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops a robot skill learning system with multi-space fusion, simultaneously considering motion/stiffness generation and trajectory tracking. To begin with, surface electromyography (sEMG) signals from the human arm is captured based on the MYO armband to estimate endpoint stiffness. Gaussian Process Regression (GPR) is combined with dynamic movement primitive (DMP) to extract more skills features from multi-demonstrations. Then, the traditional DMP formulation is improved based on the Riemannian metric to encode the robot’s quaternions with non-Euclidean properties. Furthermore, an adaptive neural network (NN)-based finite-time admittance controller is designed to track the trajectory generated by the motion model and to reflect the learned stiffness characteristics. In this controller, a radial basis function neural network (RBFNN) is employed to compensate for the uncertainty of the robot dynamics. Finally, experimental validation is conducted using the ROKAE collaborative robot, confirming the effectiveness of the proposed approach. In summary, the presented framework is suitable for human-robot skill transfer method that require simultaneous consideration of position and stiffness in Euclidean space, as well as orientation on Riemannian manifolds.},
  archive      = {J_NEUCOM},
  author       = {Chengguo Liu and Guangzhu Peng and Yu Xia and Junyang Li and Chenguang Yang},
  doi          = {10.1016/j.neucom.2024.127248},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127248},
  shortjournal = {Neurocomputing},
  title        = {Robot skill learning system of multi-space fusion based on dynamic movement primitives and adaptive neural network control},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning-based monte carlo simulation scheme for
stochastic differential equations driven by fractional brownian motion.
<em>NEUCOM</em>, <em>574</em>, 127245. (<a
href="https://doi.org/10.1016/j.neucom.2024.127245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic differential equations (SDEs) are widely used models to describe the evolution of stochastic processes . Among them, SDEs driven by fractional Brownian motion (fBm) have been shown to be capable of describing systems with temporal dependencies. In this paper, we develop a neural network based Monte Carlo methodology in which we can efficiently simulate SDEs that are governed by fBm. Particularly, we focus on large time step simulations. A property of fBm that complicates the development of such Monte Carlo schemes is the long-range temporal correlation. To this end, we build the network based on the encoder–decoder framework and employ the attention mechanism to learn the temporal relationships in the historical paths of such SDEs. In addition, a loss function based on the quantile loss is used, where the quantile levels to be predicted are determined by means of the stochastic collocation method. Experimental results show that this kind of loss function is superior to conventional loss functions in terms of solution accuracy, and the resulting scheme can learn and simulate SDEs driven by fBm accurately and highly efficiently.},
  archive      = {J_NEUCOM},
  author       = {Fei Gao and Cornelis W. Oosterlee and Jiangshe Zhang},
  doi          = {10.1016/j.neucom.2024.127245},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127245},
  shortjournal = {Neurocomputing},
  title        = {A deep learning-based monte carlo simulation scheme for stochastic differential equations driven by fractional brownian motion},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A learnable population filter for dynamic multi-objective
optimization. <em>NEUCOM</em>, <em>574</em>, 127241. (<a
href="https://doi.org/10.1016/j.neucom.2024.127241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel learnable population filter is proposed to solve the dynamic multi-objective problems (DMOPs), whose main idea is to pick out potential valuable individuals in the changing situation via the trained filter to facilitate the population convergence in a new environment. In particular, by selecting training samples from three different optional pools, rich information in the previous searching experiences can be sufficiently used to cope with the dynamic behaviors in DMOPs, thereby handling the imperfect history data availability caused by the environmental uncertainty to some extents. Then, the screened population in the new environment, which is regarded to have reliable quality that benefits accelerating the evolution, is used to initialize the static optimizer. In addition, partial random solutions are employed as supplement to the initial population to further enhance the diversity. It is shown from the benchmark evaluations that the proposed method outperforms some other popular algorithms on both convergence and diversity by seamlessly combining the mainstream strategies in dealing with the dynamic behaviors, which is a competitive method that conforms to the novel evolutionary transfer optimization (ETO) trend. Moreover, effectiveness of the core components is validated through extensive ablation studies, which brings a new sight in developing the learnable DMOP solvers.},
  archive      = {J_NEUCOM},
  author       = {Zheng Fang and Han Li and Liwei Hu and Nianyin Zeng},
  doi          = {10.1016/j.neucom.2024.127241},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127241},
  shortjournal = {Neurocomputing},
  title        = {A learnable population filter for dynamic multi-objective optimization},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event-triggered control strategy based on absolute velocity
and relative position measurements for second-order nonlinear
multi-agent systems under DoS attacks. <em>NEUCOM</em>, <em>574</em>,
127239. (<a href="https://doi.org/10.1016/j.neucom.2024.127239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consensus control in multi-agent systems (MASs) has wide-ranging applications in various domains. As the scope of applications continues to expand, ensuring the secure control of these systems to counter a diverse range of network attacks becomes highly necessary. Among these threats, Denial of Service (DoS) attacks have emerged as a major network security threat, capable of rendering targeted agents or networks unable to provide normal services. This paper presents an effective control protocol aiming to achieve leader-following consensus in a second-order MAS with event-triggered control mechanism and nonlinear dynamics under DoS attacks. The protocol utilizes absolute velocity and relative position measurements. The maximum attack frequency and duration of the DoS attacks have been obtained. Furthermore, the possibility of Zeno behavior is eliminated. Theoretical analysis demonstrates that, even under DoS attacks, consensus can be maintained among the leaders and followers within the MASs. In conclusion, the effectiveness of the proposed distributed security control protocol is validated through a case study involving a multi-vehicle cooperative system with unmanned cars.},
  archive      = {J_NEUCOM},
  author       = {Guoliang Tan and Hongwei Ren and Bo Zhang and Feiqi Deng},
  doi          = {10.1016/j.neucom.2024.127239},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127239},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered control strategy based on absolute velocity and relative position measurements for second-order nonlinear multi-agent systems under DoS attacks},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph neural network with curriculum learning for imbalanced
node classification. <em>NEUCOM</em>, <em>574</em>, 127229. (<a
href="https://doi.org/10.1016/j.neucom.2023.127229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Network (GNN) stands as an emerging methodology for graph-based learning tasks, particularly for node classification . This study elucidates the susceptibility of GNN to discrepancies arising from imbalanced node labels. Conventional solutions for imbalanced classification, such as resampling, falter in node classification task , primarily due to their negligence of graph structure. Worse still, they often exacerbate the model’s inclination towards overfitting or underfitting, especially in the absence of adequate priori knowledge . To circumvent these limitations, we introduce a novel G raph N eural N etwork framework with C urriculum L earning (GNN-CL). This framework integrates two pivotal components. Initially, leveraging the principles of smoothness and homophily, we endeavor to procure dependable interpolation nodes and edges via adaptive graph oversampling. For another, we combine the Graph Classification Loss with the Metric Learning Loss, thereby refining the spatial proximity of nodes linked to the minority class in the feature space. Drawing inspiration from curriculum learning, the parameters of these components are dynamically modulated during the training phase to accentuate generalization and discrimination capabilities. Comprehensive evaluations on several widely used graph datasets affirm the superiority of our proposed model, which consistently outperforms the existing state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xiaohe Li and Zide Fan and Feilong Huang and Xuming Hu and Yawen Deng and Lei Wang and Xinyu Zhao},
  doi          = {10.1016/j.neucom.2023.127229},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127229},
  shortjournal = {Neurocomputing},
  title        = {Graph neural network with curriculum learning for imbalanced node classification},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FedAVE: Adaptive data value evaluation framework for
collaborative fairness in federated learning. <em>NEUCOM</em>,
<em>574</em>, 127227. (<a
href="https://doi.org/10.1016/j.neucom.2023.127227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative fairness in federated learning rewards high-contribution clients with high-performance models when multiple clients train a machine learning model cooperatively. Existing approaches ignore the information on data distribution when evaluating the clients’ data quality, resulting in a mismatch between the reward allocation and the real data quality of clients under different data heterogeneity settings. To address this problem, we propose a novel Federated learning framework with Adaptive data Value Evaluation mechanism (FedAVE) to ensure collaborative fairness without affecting the predictive performance of models. First, an adaptive reputation calculation module is designed to generate reputations that match the clients’ contributions based on the information of their data distribution, respectively. Second, a dynamic gradient reward distribution module is devised to allocate a certain number of aggregated model parameter updates/gradients as the rewards corresponding to the reputations and the data distribution information. Extensive experiments on three public benchmarks show that the proposed FedAVE outperforms all baseline methods in terms of fairness, and achieves comparable performance to the state-of-the-art methods in terms of accuracy. Code available at https://github.com/wangzihuixmu/FedAVE .},
  archive      = {J_NEUCOM},
  author       = {Zihui Wang and Zhaopeng Peng and Xiaoliang Fan and Zheng Wang and Shangbin Wu and Rongshan Yu and Peizhen Yang and Chuanpan Zheng and Cheng Wang},
  doi          = {10.1016/j.neucom.2023.127227},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127227},
  shortjournal = {Neurocomputing},
  title        = {FedAVE: Adaptive data value evaluation framework for collaborative fairness in federated learning},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Context-aware graph embedding with gate and attention for
session-based recommendation. <em>NEUCOM</em>, <em>574</em>, 127221. (<a
href="https://doi.org/10.1016/j.neucom.2023.127221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prior solutions on session-based recommendation (SBR) are mainly limited by two major issues: (1) the sequence and transition relationships of items need further integration; (2) the context clues from the neighboring sessions remain largely under-explored. To overcome these issues, this paper proposes a novel Context-aware Graph Embedding Network (CGENet) with gate and attention mechanisms , that not only can effectively exploit the collaborative relationship between the sequence and transition patterns in each session, but also benefit greatly from topological context patterns among different sessions. Specifically, the proposed CGENet consists of three different parts, i.e., Transition Pattern Learning (TPL) module, Sequential Pattern Learning (SPL) module, and Context Pattern Learning (CPL) module. The TPL module is built on Graph Isomorphic Network (GIN) with multiple information highways to capture the transition relationships between items. To maximize the value of sequence-position information, a Gated Multilayer Perceptron (gMLP) is introduced into the SPL module to model the long-term dependencies between sequence tokens. Under the standardized guidance of the graph attention layer, the CPL module can further explore the topological contexts from neighboring sessions, thereby enhancing its ability to predict user preferences more effectively. Extensive experiments on three benchmark datasets demonstrate the superiority of the proposed CGENet compared to the state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Biqing Zeng and Junlong Chi and Peilin Hong and Guangming Lu and David Zhang and Bingzhi Chen},
  doi          = {10.1016/j.neucom.2023.127221},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127221},
  shortjournal = {Neurocomputing},
  title        = {Context-aware graph embedding with gate and attention for session-based recommendation},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-vehicle trajectory prediction and control at
intersections using state and intention information. <em>NEUCOM</em>,
<em>574</em>, 127220. (<a
href="https://doi.org/10.1016/j.neucom.2023.127220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional deep learning approaches for prediction of future trajectory of multiple road agents rely on knowing information about their past trajectory. In contrast, this work utilizes information of only the current state and intended direction to predict the future trajectory of multiple vehicles at intersections. Incorporating intention information has two distinct advantages: (1) It allows to not just predict the future trajectory but also control the multiple vehicles. (2) By manipulating the intention, the interaction among the vehicles is adapted accordingly to achieve desired behavior . Both these advantages would otherwise not be possible using only past trajectory information Our model utilizes message passing of information between the vehicle nodes for a more holistic overview of the environment, resulting in better trajectory prediction and control of the vehicles. This work also provides a thorough investigation and discussion into the disparity between offline and online metrics for the task of multi-agent control. We particularly show why conducting only offline evaluation would not suffice, thereby necessitating online evaluation. We demonstrate the superiority of utilizing intention information rather than past trajectory in online scenarios. Lastly, we show the capability of our method in adapting to different domains through experiments conducted on two distinct simulation platforms i.e. SUMO and CARLA. The code for this work can be found on the project page here: https://dekai21.github.io/Multi_Agent_Intersection/ .},
  archive      = {J_NEUCOM},
  author       = {Dekai Zhu and Qadeer Khan and Daniel Cremers},
  doi          = {10.1016/j.neucom.2023.127220},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127220},
  shortjournal = {Neurocomputing},
  title        = {Multi-vehicle trajectory prediction and control at intersections using state and intention information},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-space hierarchical learning for goal-guided
conversational recommendation. <em>NEUCOM</em>, <em>574</em>, 127219.
(<a href="https://doi.org/10.1016/j.neucom.2023.127219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proactively and naturally guiding the dialog from the non-recommendation context (e.g., Chit-chat) to the recommendation scenario (e.g., Music) is crucial for the Conversational Recommender System (CRS). Prior studies mainly focus on planning the next dialog goal (e.g., chat on a movie star) conditioned on the previous dialog. However, we find the dialog goals can be simultaneously observed at different levels, which can be utilized to improve CRS. In this paper, we propose D ual-space H ierarchical L earning ( DHL ) to leverage multi-level goal sequences and their hierarchical relationships for conversational recommendation. Specifically, we exploit multi-level goal sequences from both the representation space and the optimization space . In the representation space, we propose the hierarchical representation learning where a cross attention module derives mutually enhanced multi-level goal representations. In the optimization space, we devise the hierarchical weight learning to reweight lower-level goal sequences, and introduce bi-level optimization for stable update. Additionally, we propose a soft labeling strategy to guide optimization gradually. Experiments on two real-world datasets verify the effectiveness of our approach. Code and data are available here .},
  archive      = {J_NEUCOM},
  author       = {Can Chen and Hao Liu and Zeming Liu and Xue Liu and Dejing Dou},
  doi          = {10.1016/j.neucom.2023.127219},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127219},
  shortjournal = {Neurocomputing},
  title        = {Dual-space hierarchical learning for goal-guided conversational recommendation},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). MPQ-YOLO: Ultra low mixed-precision quantization of YOLO
for edge devices deployment. <em>NEUCOM</em>, <em>574</em>, 127210. (<a
href="https://doi.org/10.1016/j.neucom.2023.127210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {You Only Look Once (YOLO), known for its real-time performance and outstanding accuracy, has emerged as a prominent framework for object detection tasks. However, deploying YOLO on resource-constrained edge devices poses challenges due to its substantial memory requirements. In this paper, we propose MPQ-YOLO, an ultra-low mixed-precision quantization framework designed for edge device deployment. The core idea is to integrate 1-bit Backbone quantization and 4-bit Head quantization with dedicated training techniques. Specifically, we analyze the effect of numerical distribution on the performance of binary neural networks (BNNs), and based on this, we design a backbone with only 1-bit convolution. Then, we introduce a trainable scale and Progressive Network Quantization (PNQ) training strategy to bridge the Backbone and Head for end-to-end quantization training. The former is applied to both weights and activations within the 4-bit Head, enabling effective gradient propagation. The latter mitigates oscillation caused by mixed precision training, promoting smoother training and faster model convergence. Extensive experiments on VOC and COCO datasets demonstrate that MPQ-YOLO achieves a good trade-off between model compression and detection performance. Specifically, compared to the full-precision model, MPQ-YOLO achieves compression of up to 16.3 × × and 14.2 × × in terms of computational complexity and model size, respectively, while maintaining relatively high detection accuracy, i.e., 74.7% on VOC and 51.5% on COCO. To the best of our knowledge, MPQ-YOLO is the first YOLO framework with dual low mixed-precision quantization. Moreover, compared to the existing layer-wise mixed-precision quantization methods which cause redundant data processing and massive data movement, MPQ-YOLO offers a more hardware-designer-friendly and straightforward solution through efficient resource utilization and reuse.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Liu and Tao Wang and Jiaming Yang and Chenwei Tang and Jiancheng Lv},
  doi          = {10.1016/j.neucom.2023.127210},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127210},
  shortjournal = {Neurocomputing},
  title        = {MPQ-YOLO: Ultra low mixed-precision quantization of YOLO for edge devices deployment},
  volume       = {574},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Broadcasting-based cucker–smale flocking control for
multi-agent systems. <em>NEUCOM</em>, <em>573</em>, 127266. (<a
href="https://doi.org/10.1016/j.neucom.2024.127266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the flocking control issue of multi-agent systems, where each agent utilizes the broadcasting communication manner and takes the Cucker–Smale style dynamic model. In the setting of broadcasting scenario, each agent broadcasts the state information only at certain moments determined by its own clock, and recalculates the control input only when its clock ticks or it receives information from the neighbors. In the Cucker–Smale model, a nonlinear weight function about the communication distance is set to portray the mutual influence degree between agents. With the help of the properties of sub-stochastic matrix, a comprehensive analysis of the asymptotic convergence of the model is performed and the algebraic conditions for achieving flocking control are established. In addition, the obtained theoretical results are further extended to the bipartite flocking control issue for multi-agent systems with both cooperative and competitive interactions. At last, numerical simulations are provided to verify the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Zhuangzhuang Ma and Bowen Li and Lei Shi and Yuhua Cheng and Jinliang Shao},
  doi          = {10.1016/j.neucom.2024.127266},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127266},
  shortjournal = {Neurocomputing},
  title        = {Broadcasting-based Cucker–Smale flocking control for multi-agent systems},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep model compression based on the training history.
<em>NEUCOM</em>, <em>573</em>, 127257. (<a
href="https://doi.org/10.1016/j.neucom.2024.127257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Convolutional Neural Networks (DCNNs) have shown promising performances in several visual recognition problems which motivated the researchers to propose popular architectures such as LeNet, AlexNet, VGGNet, ResNet , and many more. These architectures come at a cost of high computational complexity and parameter storage. To get rid of storage and computational complexity, deep model compression methods have been evolved. We propose a “History Based Filter Pruning (HBFP)” method that utilizes network training history for filter pruning. Specifically, we prune the redundant filters by observing similar patterns in the filter’s ℓ 1 ℓ1 -norms (absolute sum of weights) over the training epochs. We iteratively prune the redundant filters of a CNN in three steps. First, we train the model and select the filter pairs with redundant filters in each pair. Next, we optimize the network to ensure an increased measure of similarity between the filters in a pair. This optimization of the network facilitates us to prune one filter from each pair based on its importance without much information loss. Finally, we retrain the network to regain the performance, which is dropped due to filter pruning. We test our approach on popular architectures such as LeNet-5 on MNIST dataset; VGG-16, ResNet-56, and ResNet-110 on CIFAR-10 dataset, and ResNet-50 on ImageNet. The proposed pruning method outperforms the state-of-the-art in terms of FLOPs reduction (floating-point operations) by 97.98 % , 83.42 % , 78.43 % , 74.95 % , and 75.45 % for LeNet-5, VGG-16, ResNet-56, ResNet-110, and ResNet-50, respectively, while maintaining the less error rate. The source code is available at: https://github.com/shabbeersh/HBFP .},
  archive      = {J_NEUCOM},
  author       = {S.H. Shabbeer Basha and Mohammad Farazuddin and Viswanath Pulabaigari and Shiv Ram Dubey and Snehasis Mukherjee},
  doi          = {10.1016/j.neucom.2024.127257},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127257},
  shortjournal = {Neurocomputing},
  title        = {Deep model compression based on the training history},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AIP-net: An anchor-free instance-level human part detection
network. <em>NEUCOM</em>, <em>573</em>, 127254. (<a
href="https://doi.org/10.1016/j.neucom.2024.127254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human part detection has significant research and application in computer vision fields such as human–robot interaction, motion capture, facial recognition, and human key point detection. However, the current human body part detection method encounters challenges when detecting multi-scale objects and capturing the correlation relationship between human instances and human parts. To address these problems, a new anchor-free instance-level human part detection network (AIP-Net) is proposed. AIP-Net is a “two-level” structure that consists of two lightweight anchor-free detectors: a body detector and a parts detector. AIP-Net gradually focuses the human body on the human part from top to down, effectively avoiding the interference of extraneous background and enhancing the correlation relationship between human instances and body parts. Additionally, we design a body-part multidimensional context (BPMC) model in the parts detector branch to enhance the capability of the network. We trained the AIP-Ne end-to-end and achieved a state-of-the-art (SOTA) performance of 36.2 mean average precision (mAP) on COCO Human Parts Dataset. Moreover, we successfully utilized the AIP-Net in the human–robot interaction(HRI) platform and validated its practicality.},
  archive      = {J_NEUCOM},
  author       = {Yuhang Xu and Ye Zhang and Yuquan Leng and Qing Gao},
  doi          = {10.1016/j.neucom.2024.127254},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127254},
  shortjournal = {Neurocomputing},
  title        = {AIP-net: An anchor-free instance-level human part detection network},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid optical convolutional neural network with convolution
kernels trained in the spatial domain. <em>NEUCOM</em>, <em>573</em>,
127251. (<a href="https://doi.org/10.1016/j.neucom.2024.127251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although many hybrid convolutional neural networks using optical convolution processors have been demonstrated for high energy efficiency and fast image processing speed, the need for accurate modeling of the optical convolution hardware and large Fourier kernel sizes result in a long and energy-intensive training process. Here, we demonstrate a hybrid convolutional neural network based on an optimized optical convolution processor—the system uses kernels trained in the spatial domain and compensates the optical path mismatch that arises from the reflection of digital micromirror devices for convolution computation. The spatial-domain convolution kernels are Fourier transformed and then binarized before being programmed into a digital micromirror device in the optical convolution processor. This method minimizes overhead from the optical convolution process in the training of the hybrid convolutional neural network, and it can improve the energy efficiency and reduce the training time of the hybrid optical convolutional neural network. For convolution computation using digital micromirror devices with grayscale images, bit-plane-wise convolution is also presented. We tested the hybrid neural network on MNIST, Fashion-MNIST, and CIFAR-10 color datasets and obtained classification accuracies of 98.7%, 85.8%, and 57.8%, respectively.},
  archive      = {J_NEUCOM},
  author       = {Jinhwa Gene and Suntak Park and Hyung Cheol Shin and Jong Moo Sohn},
  doi          = {10.1016/j.neucom.2024.127251},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127251},
  shortjournal = {Neurocomputing},
  title        = {Hybrid optical convolutional neural network with convolution kernels trained in the spatial domain},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust one-class classification using deep kernel spectral
regression. <em>NEUCOM</em>, <em>573</em>, 127246. (<a
href="https://doi.org/10.1016/j.neucom.2024.127246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing one-class classification (OCC) methods typically presume the existence of a pure target training set and generally face difficulties when the training set is contaminated with non-target objects. This work addresses this aspect of the OCC problem and formulates an effective method that leverages the advantages of kernel-based methods to achieve robustness against training label noise while enabling direct deep learning of features from the data to optimise a Fisher-based loss function in the Hilbert space . As such, the proposed OCC approach can be trained in an end-to-end fashion while, by virtue of a Tikhonov regularisation in the Hilbert space, it provides high robustness against the training set contamination. Extensive experiments conducted on multiple datasets in different application scenarios demonstrate that the proposed methodology is robust and performs better than the state-of-the-art algorithms for OCC when the training set is corrupted by contamination.},
  archive      = {J_NEUCOM},
  author       = {Salman Mohammad and Shervin Rahimzadeh Arashloo},
  doi          = {10.1016/j.neucom.2024.127246},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127246},
  shortjournal = {Neurocomputing},
  title        = {Robust one-class classification using deep kernel spectral regression},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal-channel cascaded transformer for imagined
handwriting character recognition. <em>NEUCOM</em>, <em>573</em>,
127243. (<a href="https://doi.org/10.1016/j.neucom.2024.127243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuroelectric signals recorded by micro-electrodes reflect the spontaneous and rhythmic activities of brain neurons. Numerous deep learning frameworks have been designed for various neuroelectric signal decoding tasks, most of which are based on convolutional neural network (CNN) and recurrent neural network (RNN). However, neither CNNs or RNNs can perceive the global dependencies of neural activities in both time and channel dimensions. To address this issue, this paper presents a temporal-channel cascaded transformer network to decode the neural activities of imagined handwriting movements, which can perform imagined handwriting character recognition from spiking activity recorded by two micro-electrode arrays (MEAs). Specifically, we design a temporal-channel cascaded framework and a dense residual transformer encoder structure, which can promote the hierarchical learning and fusion of the temporal and channel features. In addition, a mutual learning strategy of multiple class tokens is proposed to improve classification performance. We conduct performance evaluation experiments on a single-character handwriting-imagination dataset and a sentence handwriting-imagination dataset, which are collected from the public Handwriting BCI dataset. The comparison results demonstrate the superiority of the proposed framework and strategy. Especially in the imagined single-character recognition task, the recognition accuracy of our model can achieve 95.78%, which provides an improvement of + 2 % +2% over the existing state of the art models.},
  archive      = {J_NEUCOM},
  author       = {Wenhui Zhou and Yuhan Wang and Liangyan Mo and Changsheng Li and Mingyue Xu and Wanzeng Kong and Guojun Dai},
  doi          = {10.1016/j.neucom.2024.127243},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127243},
  shortjournal = {Neurocomputing},
  title        = {Temporal-channel cascaded transformer for imagined handwriting character recognition},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Physics-informed neural network combined with
characteristic-based split for solving forward and inverse problems
involving navier–stokes equations. <em>NEUCOM</em>, <em>573</em>,
127240. (<a href="https://doi.org/10.1016/j.neucom.2024.127240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach for solving the shallow-water transport equation using a physics-informed neural network (PINN) combined with characteristic-based split (CBS). Simulation of the tide in East Coast of China is performed to verify the applicability of the present method in a practical problem. Furthermore, we propose a boundary condition that accounts for the second-order partial derivative term, which is more appropriate for solving the diffusion equation with open domains than the commonly used assumption of zero boundary values. Our numerical results demonstrate that this boundary condition leads to improved convergence of the network. In addition, we introduce a parameter estimation method that requires information from the field at only two different times, yet yields accurate parameter estimates. We observe that excessive participation of variables in gradient backpropagation can lead to neural networks getting trapped in local optima. We use PINN combined with CBS method to solve 3-D incompressible flow . As the number of variables involved in gradient backpropagation increases, the accuracy of the solution decreases, which can partially support our viewpoint. The source codes for the numerical examples in this work are available at https://github.com/double110/PINN-cbs-.git .},
  archive      = {J_NEUCOM},
  author       = {Shuang Hu and Meiqin Liu and Senlin Zhang and Shanling Dong and Ronghao Zheng},
  doi          = {10.1016/j.neucom.2024.127240},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127240},
  shortjournal = {Neurocomputing},
  title        = {Physics-informed neural network combined with characteristic-based split for solving forward and inverse problems involving Navier–Stokes equations},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning group-wise spatial attention and label dependencies
for multi-task thoracic disease classification. <em>NEUCOM</em>,
<em>573</em>, 127228. (<a
href="https://doi.org/10.1016/j.neucom.2023.127228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the multi-label thoracic abnormality classification with chest X-ray images. In clinical settings, Chest X-ray imaging is a general diagnostic tool applied to visualize numerous thoracic pathological changes. While deep learning techniques have been extensively tested in this field, certain challenges persist. The data in existing thoracic abnormality datasets is insufficient, and some diseases are extremely imbalanced. Meanwhile, the dependencies between different labels are often ignored. To tackle these issues head-on, this paper introduces two crucial modules: the group-wise spatial attention (GWSA) module and the label co-occurrence dependency (LCD) module, integrated with DenseNet121 backbone. Specifically, GWSA enhances the spatial features within distinct groups while keeping the between-group feature discrimination. LCD models the correlations between different thoracic abnormalities to refine the predicted probabilities. In conjunction with the DenseNet121 backbone, these two modules reach an average AUC score of 0.818 on Chest X-ray14 dataset, achieving state-of-the-art. Source code is available at https://github.com/YujiaKCL/Chest-Xray14-GWSA-LCD .},
  archive      = {J_NEUCOM},
  author       = {Yujia Xu and Hak-Keung Lam and Xinqi Bao and Yuhan Wang},
  doi          = {10.1016/j.neucom.2023.127228},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127228},
  shortjournal = {Neurocomputing},
  title        = {Learning group-wise spatial attention and label dependencies for multi-task thoracic disease classification},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on vulnerability of federated learning: A learning
algorithm perspective. <em>NEUCOM</em>, <em>573</em>, 127225. (<a
href="https://doi.org/10.1016/j.neucom.2023.127225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) has emerged as a powerful paradigm for training Machine Learning (ML), particularly Deep Learning (DL) models on multiple devices or servers while maintaining data localized at owners’ sites. Without centralizing data, FL holds promise for scenarios where data integrity, privacy and security and are critical. However, this decentralized training process also opens up new avenues for opponents to launch unique attacks, where it has been becoming an urgent need to understand the vulnerabilities and corresponding defense mechanisms from a learning algorithm perspective. This review paper takes a comprehensive look at malicious attacks against FL, categorizing them from new perspectives on attack origins and targets, and providing insights into their methodology and impact. In this survey, we focus on threat models targeting the learning process of FL systems. Based on the source and target of the attack, we categorize existing threat models into four types, Data to Model (D2M), Model to Data (M2D), Model to Model (M2M) and composite attacks. For each attack type, we discuss the defense strategies proposed, highlighting their effectiveness, assumptions and potential areas for improvement. Defense strategies have evolved from using a singular metric to excluding malicious clients , to employing a multifaceted approach examining client models at various phases. In this survey paper, our research indicates that the to-learn data, the learning gradients, and the learned model at different stages all can be manipulated to initiate malicious attacks that range from undermining model performance, reconstructing private local data, and to inserting backdoors. We have also seen these threat are becoming more insidious. While earlier studies typically amplified malicious gradients, recent endeavors subtly alter the least significant weights in local models to bypass defense measures. This literature review provides a holistic understanding of the current FL threat landscape and highlights the importance of developing robust, efficient, and privacy-preserving defenses to ensure the safe and trusted adoption of FL in real-world applications. The categorized bibliography can be found at: https://github.com/Rand2AI/Awesome-Vulnerability-of-Federated-Learning .},
  archive      = {J_NEUCOM},
  author       = {Xianghua Xie and Chen Hu and Hanchi Ren and Jingjing Deng},
  doi          = {10.1016/j.neucom.2023.127225},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127225},
  shortjournal = {Neurocomputing},
  title        = {A survey on vulnerability of federated learning: A learning algorithm perspective},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conformity-aware adoption maximization in competitive social
networks. <em>NEUCOM</em>, <em>573</em>, 127224. (<a
href="https://doi.org/10.1016/j.neucom.2023.127224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization (IM) problem is an extensively studied problem in social networks. It aims to find a small set of users in the social network to initiate the diffusion process and maximize the expected influence spread. Existing works on conformity-aware IM focus on the interaction between influence and conformity in a single-influence setting and ignore the role of conformity in a competitive and multiple-influence setting. This paper proposes a conformity-aware independent cascade (C-IC) model that considers the competition among multiple influences as well as the role of conformity in a user’s decision-making. It is proved that the adoption of an influence under the C-IC model is monotone and submodular. Meanwhile, we formulate two adoption maximization (AM) problems, O-AM and S-AM, which are both NP-hard. Because estimating the adoption through diffusion simulations is very time-consuming, we propose a reverse adoption estimation (RAE) method based on a reverse multiple influence sampling (RMIS) technology for the C-IC model and integrate it into the D-SSA-fix (Nguyenet al., 2018) framework, DSSA for short, to compute a solution with approximation guarantee. To further boost the performance, we present a fast one-hop adoption estimation (OAE) method and develop a heuristic algorithm based on OAE, called GOAE. Extensive experiments on eight real-world social networks show that the C-IC model is superior to a non-conformity diffusion model and that RAE+DSSA and GOAE are efficient and effective. In most cases, GOAE finds comparable solutions to RAE+DSSA and CELF with less time and memory overhead. GOAE is five to six orders of magnitude faster than CELF and RAE+DSSA is up to three orders of magnitude faster than CELF on NetHEPT. GOAE runs up to four to five orders of magnitude faster than RAE+DSSA with at most two orders of magnitude less memory usage. GOAE is more scalable than RAE+DSSA in terms of the number of seeds and the size of the social network.},
  archive      = {J_NEUCOM},
  author       = {Yonggang Liu and Yikun Hu and Siyang Yu and Xu Zhou and Keqin Li},
  doi          = {10.1016/j.neucom.2023.127224},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127224},
  shortjournal = {Neurocomputing},
  title        = {Conformity-aware adoption maximization in competitive social networks},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal weighted graph representation for information
extraction from visually rich documents. <em>NEUCOM</em>, <em>573</em>,
127223. (<a href="https://doi.org/10.1016/j.neucom.2023.127223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel system for information extraction from visually rich documents (VRD) using a weighted graph representation . The proposed method aims to improve the performance of the information extraction task by capturing the relationships between various VRD components. The VRD is modeled as a weighted graph , in which visual, textual, and spatial features of text regions are encoded in nodes and edges representing the relationships between neighboring text regions. The information extraction task from VRD is performed as a node classification task through the use of a graph convolutional networks , where the VRD graphs are fed into the network. The approach is evaluated across diverse documents, encompassing invoices and receipts, revealing achievement levels equal to or surpassing robust baselines.},
  archive      = {J_NEUCOM},
  author       = {Hamza Gbada and Karim Kalti and Mohamed Ali Mahjoub},
  doi          = {10.1016/j.neucom.2023.127223},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127223},
  shortjournal = {Neurocomputing},
  title        = {Multimodal weighted graph representation for information extraction from visually rich documents},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AMIFN: Aspect-guided multi-view interactions and fusion
network for multimodal aspect-based sentiment analysis. <em>NEUCOM</em>,
<em>573</em>, 127222. (<a
href="https://doi.org/10.1016/j.neucom.2023.127222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA), which aims to analyze users’ sentiment towards the targeted aspect, has recently gained increasing attention due to its importance in supporting corresponding decision-makings in various tasks. Most existing ABSA studies primarily depend on only textual modality, but ignore the fact that in many cases the targeted aspect doesn’t appear in the sentence. Thus, multimodal ABSA is expected to alleviate this dilemma. However, most existing MABSA approaches still suffer from the following limitations: (1) ignoring the possible aspect-image irrelevant issue; (2) ignoring the coarse-grained interaction between the sentence and its associated image; (3) failing to simultaneously leverage multiple types of useful knowledge information. To address these issues, we propose an aspect-guided multi-view interactions and fusion network (AMIFN) for MABSA. Specifically, we utilize the multi-head attention mechanism to generate aspect-guided textual representation, which is used as the extended aspect semantic for guiding the subsequent aspect-related interactions. When exploring aspect-guided visual representation, we employ the image gate to dynamically filter potential noise introduced by the associated image to generate the final image representation. Meanwhile, the coarse-grained sentence-image interaction, which contains context and semantics information, and the syntactic dependencies, are leveraged for graph construction to obtain aspect-guided text-image interaction representations. Finally, the extracted multi-view interaction representations are integrated for sentiment classification. Extensive experimental results on three multimodal benchmark datasets demonstrate the superiority and rationality of AMIFN.},
  archive      = {J_NEUCOM},
  author       = {Juan Yang and Mengya Xu and Yali Xiao and Xu Du},
  doi          = {10.1016/j.neucom.2023.127222},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127222},
  shortjournal = {Neurocomputing},
  title        = {AMIFN: Aspect-guided multi-view interactions and fusion network for multimodal aspect-based sentiment analysis},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). High dimensional mislabeled learning. <em>NEUCOM</em>,
<em>573</em>, 127218. (<a
href="https://doi.org/10.1016/j.neucom.2023.127218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional mislabeled learning is essential in AI theory and applications but rarely investigated. In this study, we present a novel learning technique to detect and rectify high-dimensional mislabeled data using proposed Feature Self-Organizing Map (fSOM) along with relevant theoretical findings. When combined with the reproducible multi-class SVM learning approach, this method forms the backbone of our proposed psychiatric map (pMAP) diagnosis algorithm . This algorithm specifically addresses the real-world challenge in psychiatry of differentiating between Schizophrenia and Bipolar disorder using SNP data. The pMAP diagnosis not only offers a more precise and dependable mechanism for identifying misdiagnoses compared to state-of-the-art deep learning and machine learning models but also unveils previously unreported latent psychiatry subtypes. Furthermore, this research sheds new light on the pathology of psychiatric disorders. By mapping the evolution and internal transitions of psychiatric states and analyzing the relative entropies between various psychiatric maps, we unveil avenues to both augment and refine traditional psychiatric research. To our knowledge, this represents the inaugural study in high-dimensional mislabeled learning, poised to inspire further exploration in the domain.},
  archive      = {J_NEUCOM},
  author       = {Henry Han and Dongdong Li and Wenbin Liu and Huiyun Zhang and Jiacun Wang},
  doi          = {10.1016/j.neucom.2023.127218},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127218},
  shortjournal = {Neurocomputing},
  title        = {High dimensional mislabeled learning},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the ideal number of groups for isometric gradient
propagation. <em>NEUCOM</em>, <em>573</em>, 127217. (<a
href="https://doi.org/10.1016/j.neucom.2023.127217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, various normalization layers have been proposed to stabilize the training of deep neural networks . Among them, group normalization is a generalization of layer normalization and instance normalization by allowing a degree of freedom in the number of groups it uses. However, to determine the optimal number of groups, trial-and-error-based hyperparameter tuning is required, and such experiments are time-consuming. In this study, we discuss a reasonable method for setting the number of groups. First, we find that the number of groups influences the gradient behavior of the group normalization layer. Based on this observation, we derive the ideal number of groups, which calibrates the gradient scale to facilitate gradient descent optimization. This paper is the first to propose an optimal number of groups that is theoretically grounded, architecture-aware, and can provide a proper value in a layer-wise manner for all layers. The proposed method exhibited improved performance over existing methods in numerous neural network architectures , tasks, and datasets.},
  archive      = {J_NEUCOM},
  author       = {Bum Jun Kim and Hyeyeon Choi and Hyeonah Jang and Sang Woo Kim},
  doi          = {10.1016/j.neucom.2023.127217},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127217},
  shortjournal = {Neurocomputing},
  title        = {On the ideal number of groups for isometric gradient propagation},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RanMerFormer: Randomized vision transformer with token
merging for brain tumor classification. <em>NEUCOM</em>, <em>573</em>,
127216. (<a href="https://doi.org/10.1016/j.neucom.2023.127216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brains are the control center of the nervous system in human bodies, and brain tumor is one of the most deadly diseases. Currently, magnetic resonance imaging (MRI) is the most effective way to brain tumors early detection in clinical diagnoses due to its superior imaging quality for soft tissues. Manual analysis of brain MRI is error-prone which depends on empirical experience and the fatigue state of the radiologists to a large extent. Computer-aided diagnosis (CAD) systems are becoming more and more impactful because they can provide accurate prediction results based on medical images with advanced techniques from computer vision. Therefore, a novel CAD method for brain tumor classification named RanMerFormer is presented in this paper. A pre-trained vision transformer is used as the backbone model. Then, a merging mechanism is proposed to remove the redundant tokens in the vision transformer, which improves computing efficiency substantially. Finally, a randomized vector functional-link serves as the head in the proposed RanMerFormer, which can be trained swiftly. All the simulation results are obtained from two public benchmark datasets, which reveal that the proposed RanMerFormer can achieve state-of-the-art performance for brain tumor classification. The trained RanMerFormer can be applied in real-world scenarios to assist in brain tumor diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Jian Wang and Si-Yuan Lu and Shui-Hua Wang and Yu-Dong Zhang},
  doi          = {10.1016/j.neucom.2023.127216},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127216},
  shortjournal = {Neurocomputing},
  title        = {RanMerFormer: Randomized vision transformer with token merging for brain tumor classification},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time series classification with their image representation.
<em>NEUCOM</em>, <em>573</em>, 127214. (<a
href="https://doi.org/10.1016/j.neucom.2023.127214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study is concerned with the problem of classification of multivariate time series using convolutional neural networks (CNNs). As CNNs regard inputs in the form of images, an original image-like format of temporal data is proposed. Along this line, several design alternatives are studied by forming images with the two corresponding coordinates built by the original temporal data and their differences and second differences. An overall design process is presented with a focus on investigating time series-image transformations. Experimental studies involving publicly available data sets are reported, along with a slew of comparative analyses.},
  archive      = {J_NEUCOM},
  author       = {Władysław Homenda and Agnieszka Jastrzębska and Witold Pedrycz and Mariusz Wrzesień},
  doi          = {10.1016/j.neucom.2023.127214},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127214},
  shortjournal = {Neurocomputing},
  title        = {Time series classification with their image representation},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Reliable and robust scheduling of airport operation
resources by simulation optimization feedback and conflict resolution.
<em>NEUCOM</em>, <em>573</em>, 127212. (<a
href="https://doi.org/10.1016/j.neucom.2023.127212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable and robust airport flight ground service resources collaborative scheduling has emerged as an issue of major concern at congested airports, which has great significance on airport service quality and operation efficiency. Due to the uncertainty of the service process of multiple vehicles in airport ground operations, the combination of simulation and optimization (sim-opt) techniques has been proven to be an effective means to solve the collaborative scheduling problem. However, existing models still have limitations on the reliability of feasible solutions and the robustness of evaluations. In this work, we developed a conflict resolution based sim-opt framework that combines the search capability of mathematical optimization models with the ability of simulation models to describe uncertainty. The dynamic window is introduced to divide the flight zone into multiple sub-intervals, which allows for iterative search and evaluation of the optimal schedule solution while reducing model calculation time. Additionally, a matching algorithm based on slack and tight constraints is proposed to optimize the possible resource requirements of each vehicle, thereby improving the initial schedule solution’s search depth and reliability. Furthermore, a conflict resolution feedback mechanism between adjacent windows is constructed to optimize the scheduling plan, reducing misjudgment and omission of the optimal solution and enhancing the sim-opt framework’s robustness. Finally, experiments on real airport datasets of three different scales demonstrate that our proposed method efficiently allocates resources with a smaller flight delay time as well as reducing total vehicle cost time during the flight ground service process.},
  archive      = {J_NEUCOM},
  author       = {Chang Liu and YanRu Chen and YuanYuan Zhang and Hao Wang and Qian Luo and LiangYin Chen},
  doi          = {10.1016/j.neucom.2023.127212},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127212},
  shortjournal = {Neurocomputing},
  title        = {Reliable and robust scheduling of airport operation resources by simulation optimization feedback and conflict resolution},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning-powered biomedical photoacoustic imaging.
<em>NEUCOM</em>, <em>573</em>, 127207. (<a
href="https://doi.org/10.1016/j.neucom.2023.127207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photoacoustic Imaging (PAI) is an emerging hybrid imaging modality that combines optical imaging and ultrasound imaging , offering advantages such as high resolution, strong contrast, and safety. Despite demonstrating superior imaging capabilities, PAI still has certain limitations in its clinical application, such as the trade-off between imaging depth and spatial resolution, and the need for further improvement in imaging speed. Deep Learning , as a novel machine learning technique , has gained significant attention for its ability to improve medical image data and has been widely applied in PAI in recent years to overcome these limitations. In this review, we first introduce the principles of photoacoustic imaging, followed by the development and applications of popular deep neural network structures such as U-Net and GAN networks. Furthermore, we comprehensively discuss the recent advancements in the application of deep learning in photoacoustic imaging. Finally, a summary and discussion are provided.},
  archive      = {J_NEUCOM},
  author       = {Xiang Wei and Ting Feng and Qinghua Huang and Qian Chen and Chao Zuo and Haigang Ma},
  doi          = {10.1016/j.neucom.2023.127207},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127207},
  shortjournal = {Neurocomputing},
  title        = {Deep learning-powered biomedical photoacoustic imaging},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revealing the underlying patterns: Investigating dataset
similarity, performance, and generalization. <em>NEUCOM</em>,
<em>573</em>, 127205. (<a
href="https://doi.org/10.1016/j.neucom.2023.127205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised deep learning models require significant amount of labeled data to achieve an acceptable performance on a specific task. However, when tested on unseen data, the models may not perform well. Therefore, the models need to be trained with additional and varying labeled data to improve the generalization. In this work, our goal is to understand the models, their performance and generalization. We establish image-image, dataset-dataset, and image-dataset distances to gain insights into the model’s behavior . Our proposed distance metric when combined with model performance can help in selecting an appropriate model/architecture from a pool of candidate architectures. We have shown that the generalization of these models can be improved by only adding a small number of unseen images (say 1, 3 or 7) into the training set. Our proposed approach reduces training and annotation costs while providing an estimate of model performance on unseen data in dynamic environments.},
  archive      = {J_NEUCOM},
  author       = {Akshit Achara and Ram Krishna Pandey},
  doi          = {10.1016/j.neucom.2023.127205},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127205},
  shortjournal = {Neurocomputing},
  title        = {Revealing the underlying patterns: Investigating dataset similarity, performance, and generalization},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Module-based multiple feature integration descriptor for
image retrieval. <em>NEUCOM</em>, <em>573</em>, 127202. (<a
href="https://doi.org/10.1016/j.neucom.2023.127202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combining various features offers distinct advantages by capitalizing on their complementary attributes to provide more refined image representations. However, effectively integrating these heterogeneous features and harnessing their strengths remains challenging. To address this, we propose a novel unsupervised approach termed Module-based Multiple Feature Integration Descriptor ( MMFID ) for image retrieval , drawing inspiration from the information processing mechanisms observed in the biological visual cortex . This method systematically and efficiently integrates various features within a unified framework. Within this framework, we propose an adaptive luminance mask tailored for deep structural and semantic features . It facilitates the spatial fusion of global visual cues with deep features. Additionally, we propose two parallel branches to enhance feature distinctiveness: one focuses on saliency region enhancement, while the other emphasizes semantic information integration . To achieve seamless integration, we devise a multi-module fusion strategy that harmonizes classical visual features with deep structural and semantic features. This strategy effectively exploits the complementary nature of these diverse features. Comprehensive experimental results demonstrate the competitive performance of our MMFID method across five benchmark retrieval datasets, surpassing several state-of-the-art methods based on pre-trained models.},
  archive      = {J_NEUCOM},
  author       = {Qiaoping He},
  doi          = {10.1016/j.neucom.2023.127202},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127202},
  shortjournal = {Neurocomputing},
  title        = {Module-based multiple feature integration descriptor for image retrieval},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancement of guided thermal image super-resolution
approaches. <em>NEUCOM</em>, <em>573</em>, 127197. (<a
href="https://doi.org/10.1016/j.neucom.2023.127197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Guided image processing techniques are widely used to extract meaningful information from a guiding image and facilitate the enhancement of the guided one. This paper specifically addresses the challenge of guided thermal image super-resolution, where a low-resolution thermal image is enhanced using a high-resolution visible spectrum image. We propose a new strategy that enhances outcomes from current guided super-resolution methods. This is achieved by transforming the initial guiding data into a representation resembling a thermal-like image, which is more closely in sync with the intended output. Experimental results with upscale factors of × × 8 and × × 16, demonstrate the outstanding performance of our approach in guided thermal image super-resolution obtained by mapping the original guiding information to a thermal-like image representation.},
  archive      = {J_NEUCOM},
  author       = {Patricia L. Suárez and Dario Carpio and Angel D. Sappa},
  doi          = {10.1016/j.neucom.2023.127197},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127197},
  shortjournal = {Neurocomputing},
  title        = {Enhancement of guided thermal image super-resolution approaches},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantized dynamic event-triggered control for
fixed/preset-time bipartite synchronization of memristor-based
discontinuous multi-layer signed networks. <em>NEUCOM</em>,
<em>573</em>, 127196. (<a
href="https://doi.org/10.1016/j.neucom.2023.127196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the fixed/preset-time bipartite synchronization (FTBS/PTBS) of memristor-based discontinuous multi-layer signed networks via quantized dynamic event-triggered control (ETC). Firstly, a memristor-based neural network model incorporating multi-layer coupling structures, signed networks and discontinuous activations is built. Subsequently, by designing two quantized dynamic ETC strategies without the linear feedback term, the FTBS and PTBS of the considered networks are discussed, and it is proved that Zeno behavior can be ruled out. In contrast to the previous static ETC mechanism, the introduced internal dynamic variable can significantly decrease the triggering times and further save communication resources. Lastly, three numerical examples are offered to verify the correctness and practicability of the theoretical analysis.},
  archive      = {J_NEUCOM},
  author       = {Xuejiao Qin and Haijun Jiang and Jianlong Qiu and Cheng Hu and Shanshan Chen and Yue Ren},
  doi          = {10.1016/j.neucom.2023.127196},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127196},
  shortjournal = {Neurocomputing},
  title        = {Quantized dynamic event-triggered control for fixed/preset-time bipartite synchronization of memristor-based discontinuous multi-layer signed networks},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incorporating attribute-level aligned comparative network
for generalized zero-shot learning. <em>NEUCOM</em>, <em>573</em>,
127188. (<a href="https://doi.org/10.1016/j.neucom.2023.127188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key challenge of zero-shot learning (ZSL) is to sufficiently disentangle each latent attribute from the class-level semantic annotations of images, thereby achieving a desirable semantic transfer to unseen classes with the disentangled attributes. However, most existing studies tackle the ZSL task with a strict class-level alignment strategy that may yield insufficient disentanglement: (1) this strategy simply aligns holistic visual feature with its associated class-level semantic vector for each image; (2) the class-level semantic vectors have limited diversity and complex compositions of attributes. To address these issues, we propose an incorporating attribute-level aligned comparative network, i.e., IAAC-net, that develops the alignment strategy of ZSL to the attribute level. IAAC-net aims to establish diversified attribute-level and refined class-level alignments to facilitate attribute disentanglement and simultaneously improve zero-shot generalization. By further proposing a confusion-aware loss, the model is forced to rectify the disentanglement of indistinguishable attributes, which leads to a more accurate attribute disentanglement. The proposed IAAC-net yields significant improvements over the strong baselines, leading to new state-of-the-art performances on three popular challenging benchmarks, i.e., CUB, SUN, and AWA2.},
  archive      = {J_NEUCOM},
  author       = {Yuan Chen and Yuan Zhou},
  doi          = {10.1016/j.neucom.2023.127188},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127188},
  shortjournal = {Neurocomputing},
  title        = {Incorporating attribute-level aligned comparative network for generalized zero-shot learning},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AutoGAN-DSP: Stabilizing GAN architecture search with
deterministic score predictors. <em>NEUCOM</em>, <em>573</em>, 127187.
(<a href="https://doi.org/10.1016/j.neucom.2023.127187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Network (GAN) has been widely used in many research areas of computer vision, anomaly detection , translation, optimal control, etc. However, in most cases, its network architectures have been hand-picked based on human experiences. To this end, neural Architecture Search (NAS) that automatically finds architectures have attracted much attention to automate the architecture search. In this work, we show that the NAS for Generative Adversarial Network (GAN), also denoted Generative Adversarial Neural Architecture Search (GANAS), often suffers from unstable search due to its innate randomness in the performance evaluation process. We address the stability issue by introducing deterministic score predictors and develop a unified framework to simultaneously conduct the architecture search and the predictor training. Further we develop a novel 2-phase architecture and parameter selection process to balance computational cost and architecture performance. Through extensive experiments, we demonstrate that our proposed AutoGAN-DSP outperforms other RL-based GANAS schemes as well as stabilizing the search performance. Our code and datasets are available on GitHub ( https://github.com/APinCan/GAN_Architecture_Search_with_Predictors ).},
  archive      = {J_NEUCOM},
  author       = {Haesung Jo and Changhee Joo},
  doi          = {10.1016/j.neucom.2023.127187},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127187},
  shortjournal = {Neurocomputing},
  title        = {AutoGAN-DSP: Stabilizing GAN architecture search with deterministic score predictors},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NeuroDAVIS: A neural network model for data visualization.
<em>NEUCOM</em>, <em>573</em>, 127182. (<a
href="https://doi.org/10.1016/j.neucom.2023.127182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of dimensionality reduction and visualization of high-dimensional datasets remains a challenging problem since long. Modern high-throughput technologies produce large datasets having multiple views with relatively new data types . Visualization of these datasets require efficient algorithms that can uncover hidden patterns in the data without affecting the local and global structures, and bring out the inherent non-linearity within the data. To this end, however, very few such methodologies exist, which can realize this task. In this work, we have introduced a novel unsupervised deep neural network model, called NeuroDAVIS, for data visualization. NeuroDAVIS is capable of extracting important features from the data, without assuming any data distribution , visualize effectively in low dimension, and preserve both local and global structures simultaneously. It has been shown theoretically that neighbourhood relationship of the data in high dimension remains preserved in lower dimension. The performance of NeuroDAVIS has been evaluated on a wide variety of synthetic and real high-dimensional datasets including numeric, textual, image and biological data. NeuroDAVIS has been highly competitive against t-Distributed Stochastic Neighbor Embedding (t-SNE), Uniform Manifold Approximation and Projection (UMAP), Principal Component Analysis (PCA) and Random Projection (RP) with respect to visualization quality, preservation of data size, shape, and both local and global structure. It has outperformed Fast interpolation-based t-SNE (Fit-SNE), a variant of t-SNE, for most of the datasets. For the biological datasets, besides t-SNE, UMAP, Fit-SNE, PCA and RP, NeuroDAVIS has also performed well as compared to other state-of-the-art algorithms, like Potential of Heat-diffusion for Affinity-based Trajectory Embedding (PHATE) and the siamese neural network-based method, called IVIS. Downstream classification and clustering analyses have also revealed favourable results for NeuroDAVIS-generated embeddings.},
  archive      = {J_NEUCOM},
  author       = {Chayan Maitra and Dibyendu B. Seal and Rajat K. De},
  doi          = {10.1016/j.neucom.2023.127182},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127182},
  shortjournal = {Neurocomputing},
  title        = {NeuroDAVIS: A neural network model for data visualization},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Practical finite-time and fixed-time containment for
second-order nonlinear multi-agent systems with IDAs and markov
switching topology. <em>NEUCOM</em>, <em>573</em>, 127180. (<a
href="https://doi.org/10.1016/j.neucom.2023.127180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the finite-time containment problem and the fixed-time containment problem accompanied by injection and deception attacks (IDAs) and Markov switching topology for second-order nonlinear multi-agent systems (MASs) are investigated, respectively. By introducing a radial basis function neural network (RBFNN), the approximation property of radial basis neural networks is used to solve the unmeasurable difficulties of nonlinear functions and injection attacks. Finite-time and fixed-time distributed control protocols are proposed for switching topologies and attack-induced state deception and control injection, and finite-time and fixed-time containment as well as obtaining their corresponding sufficient conditions are achieved, respectively. Correspondingly, two examples are shown to demonstrate the feasibility of the control protocols.},
  archive      = {J_NEUCOM},
  author       = {Rongxiang Lu and Jie Wu and Xisheng Zhan and Huaicheng Yan},
  doi          = {10.1016/j.neucom.2023.127180},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127180},
  shortjournal = {Neurocomputing},
  title        = {Practical finite-time and fixed-time containment for second-order nonlinear multi-agent systems with IDAs and markov switching topology},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KeyCLD: Learning constrained lagrangian dynamics in keypoint
coordinates from images. <em>NEUCOM</em>, <em>573</em>, 127175. (<a
href="https://doi.org/10.1016/j.neucom.2023.127175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present KeyCLD, a framework to learn Lagrangian dynamics from images. Learned keypoints represent semantic landmarks in images and can directly represent state dynamics. We show that interpreting this state as Cartesian coordinates , coupled with explicit holonomic constraints , allows expressing the dynamics with a constrained Lagrangian. KeyCLD is trained unsupervised end-to-end on sequences of images. Our method explicitly models the mass matrix, potential energy and the input matrix, thus allowing energy based control. We demonstrate learning of Lagrangian dynamics from images on the cl_bnmsqnk pendulum, cartpole and acrobot environments. KeyCLD can be learned on these systems, whether they are unactuated, underactuated or fully actuated. Trained models are able to produce long-term video predictions, showing that the dynamics are accurately learned. We compare with Lag-VAE, Lag-caVAE and HGN, and investigate the benefit of the Lagrangian prior and the constraint function. KeyCLD achieves the highest valid prediction time on all benchmarks. Additionally, a very straightforward energy shaping controller is successfully applied on the fully actuated systems.},
  archive      = {J_NEUCOM},
  author       = {Rembert Daems and Jeroen Taets and Francis wyffels and Guillaume Crevecoeur},
  doi          = {10.1016/j.neucom.2023.127175},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127175},
  shortjournal = {Neurocomputing},
  title        = {KeyCLD: Learning constrained lagrangian dynamics in keypoint coordinates from images},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anchor-graph regularized orthogonal concept factorization
for document clustering. <em>NEUCOM</em>, <em>573</em>, 127173. (<a
href="https://doi.org/10.1016/j.neucom.2023.127173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept factorization (CF) has attracted widespread attention for its promising performance in document clustering . Among various CF variants, graph-regularized CF is the most impressive type, which can improve clustering effectiveness by exploring structural information. Nevertheless, their clustering efficiency is restricted by the following considerations: (1) the introduction of the full-sample graph is accompanied by an increase in computational complexity ; (2) most of them require intensive multiplications in optimization, which impair the optimization efficiency. To address these issues, in this work, we propose an anchor-graph regularized orthogonal concept factorization (AROCF) method to enhance the clustering efficiency and effectiveness in document clustering tasks . Firstly, AROCF approximates the full-sample graph with a small-scale anchor graph to reduce the complexity of graph construction from quadratic to linear. Then, one of the factor matrices is constrained as the cluster indicator matrix in our method, which can avoid extra efficiency loss in K-means after optimization. Finally, an orthogonal constraint is employed to restrict the freedom of factorization to increase the clustering effectiveness. To optimize the AROCF model, we develop a fast optimization strategy by combining the trace and orthogonality of matrices. Extensive experiments on various document datasets demonstrate the effectiveness and efficiency of AROCF.},
  archive      = {J_NEUCOM},
  author       = {Ben Yang and Zhiyuan Xue and Jinghan Wu and Xuetao Zhang and Feiping Nie and Badong Chen},
  doi          = {10.1016/j.neucom.2023.127173},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127173},
  shortjournal = {Neurocomputing},
  title        = {Anchor-graph regularized orthogonal concept factorization for document clustering},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). STAR: A session-based time-aware recommender system.
<em>NEUCOM</em>, <em>573</em>, 127104. (<a
href="https://doi.org/10.1016/j.neucom.2023.127104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-Based Recommenders (SBRs) are designed to predict users’ next actions based on their previous interactions within a session, without access to historical information about users. Modern SBRs leverage deep neural networks to capture users’ current interests and map them to a latent space, enabling prediction of their next preference. While state-of-the-art SBR models achieve satisfactory results, they often overlook the temporal details of events within sessions, focusing instead on the sequence of events. To address this limitation, we propose the STAR framework, which incorporates session temporal information to enhance the performance of SBRs. By incorporating time intervals between events within sessions, we construct more informative representations for both items and sessions. Our mechanism revises session representation by embedding time intervals without using discretization . Empirical results on the Yoochoose and Diginetica datasets demonstrate that our proposed method outperforms state-of-the-art baseline models in Recall and MRR criteria. Our approach highlights the potential of session temporal information in enhancing the performance of SBRs by capturing the momentary interests of anonymous users and their mindset shifts during sessions.},
  archive      = {J_NEUCOM},
  author       = {Reza Yeganegi and Saman Haratizadeh and Morteza Ebrahimi},
  doi          = {10.1016/j.neucom.2023.127104},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127104},
  shortjournal = {Neurocomputing},
  title        = {STAR: A session-based time-aware recommender system},
  volume       = {573},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dual-population multiobjective co-evolutionary matching
ensemble learning for product multi-indicator prediction in continuous
annealing. <em>NEUCOM</em>, <em>572</em>, 127226. (<a
href="https://doi.org/10.1016/j.neucom.2023.127226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving simultaneous and precise prediction of multiple product performance indicators is crucial to ensure stable production in the continuous annealing process. However, the majority of existing quality prediction modeling methods concentrate on developing single-output regression models that are limited to single-indicator prediction scenarios. When dealing with the multi-indicator prediction scenarios, these methods usually require the construction of a separate model for each performance indicator, which leads to more computational and storage resources and more complex maintenance in practical applications. To address this issue, a dual-population multiobjective co-evolutionary matching ensemble learning method called DP-CEMEL is developed. It utilizes dual-population co-optimization to enable the joint learning of the algorithm on input–output relationships and inter-indicator correlations. More specifically, a two-stage learning based individual encoding and decoding method and a performance boosting degree (PBD) based individual evaluation strategy are designed to achieve co-optimization of the dual populations to evolve a set of individuals (i.e., base learners) with good accuracy and low complexity. Then, a PBD based matching ensemble method is applied to get the final multi-indicator prediction model by the optimal matching and ensemble of the evolved individuals. Experimental results on both benchmark data and practical strip production data demonstrate that the proposed DP-CEMEL attains competitive or better performance compared to other state-of-the-art learning methods.},
  archive      = {J_NEUCOM},
  author       = {Yao Wang and Xianpeng Wang},
  doi          = {10.1016/j.neucom.2023.127226},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127226},
  shortjournal = {Neurocomputing},
  title        = {A dual-population multiobjective co-evolutionary matching ensemble learning for product multi-indicator prediction in continuous annealing},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contextual dependency vision transformer for
spectrogram-based multivariate time series analysis. <em>NEUCOM</em>,
<em>572</em>, 127215. (<a
href="https://doi.org/10.1016/j.neucom.2023.127215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series (MTS) analysis plays an important role in various real-world applications. Existing Transformer-based methods address this problem based on hierarchical semantic representations across different scales. However, most of them ignore exploiting the helpful multiple temporal and variable relationships within the hierarchical semantic representations. To this end, this paper proposes a novel method named Contextual Dependency Vision Transformer (CD-ViT), which generates multi-grained semantic information based on spectrogram and explores mutual dependencies between multi-variable and multi-temporal representations. CD-ViT contains two key modules, i.e. , the Hierarchical Variable-dependency Transformer (HVT) module and the Bidirectional Temporal-dependency Interaction (BTI) module. Specifically, the HVT module progressively establishes mutual dependencies between multiple variables, from fine to coarse scales, with shared parameters. The BTI module employs two bidirectional flows to fuse multi-temporal tokens through zoom-in and zoom-out operations. Comprehensive experiments on widely used datasets, including UEA, Olszewski, UCI, MIMIC III, and ETT, demonstrate that the proposed approach achieves significant improvement on three popular tasks, i.e. , classification, regression, and forecasting. The code is available at https://github.com/Kali-github/CD-ViT .},
  archive      = {J_NEUCOM},
  author       = {Jieru Yao and Longfei Han and Kaihui Yang and Guangyu Guo and Nian Liu and Xiankai Huang and Zhaohui Zheng and Dingwen Zhang and Junwei Han},
  doi          = {10.1016/j.neucom.2023.127215},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127215},
  shortjournal = {Neurocomputing},
  title        = {Contextual dependency vision transformer for spectrogram-based multivariate time series analysis},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dendritic filtering determines the frequency-dependent spike
train correlations. <em>NEUCOM</em>, <em>572</em>, 127211. (<a
href="https://doi.org/10.1016/j.neucom.2023.127211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal correlation between neural discharge sequences induced by correlated synaptic inputs distributes widely in large population of neurons. However, how synaptic input frequency affects the spike train correlation remains largely unclear. To address this question, we use a pair of unconnected ball-and-stick (BS) model neurons of integrate-and-fire (IF) type to simulate the correlated spike trains when receiving the shared synaptic inputs with specific frequency at the distal dendrite. We derive the relevant simplified point (SP) neuron model analytically to well reproduce the BS model dynamics with suprathreshold inputs. We show that the output correlation is negatively correlated to input frequency, and this frequency-dependent correlation is modulated by dendritic morphologies and synaptic positions. Our results highlight the dependence of spike train correlation on input frequency and suggest that the dendritic filtering is a primary factor in shaping this correlation-frequency relationship using SP models and morphologically realistic model neurons. These predictions should be considered when understanding the neural population correlations. No data was used for the research described in the article.},
  archive      = {J_NEUCOM},
  author       = {Xuelin Huang and Xile Wei and Jiang Wang and Guosheng Yi},
  doi          = {10.1016/j.neucom.2023.127211},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127211},
  shortjournal = {Neurocomputing},
  title        = {Dendritic filtering determines the frequency-dependent spike train correlations},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time set stabilization of probabilistic boolean
control networks via output-feedback control. <em>NEUCOM</em>,
<em>572</em>, 127208. (<a
href="https://doi.org/10.1016/j.neucom.2023.127208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the finite-time output-feedback set stabilization problem for probabilistic Boolean control networks (PBCNs) , a crucial aspect of set convergence. Firstly, an algorithm is presented to effectively identify the largest output-feedback control invariant subset in a given set. Next, a sufficient condition is put forward to bridge set stabilization and the question at hand via the minimum transient period. Additionally, sufficient and necessary criteria are proposed, addressing the solvability of finite-time output-feedback set stabilization, followed by two corresponding algorithms for effectively designing all feasible output-feedback stabilizers. Finally, a biological example is successfully explored to demonstrate our theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Jian Yang and Shuting Zhang and Jungang Lou and Jianquan Lu and Jie Zhong},
  doi          = {10.1016/j.neucom.2023.127208},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127208},
  shortjournal = {Neurocomputing},
  title        = {Finite-time set stabilization of probabilistic boolean control networks via output-feedback control},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). KD-SCFNet: Towards more accurate and lightweight salient
object detection via knowledge distillation. <em>NEUCOM</em>,
<em>572</em>, 127206. (<a
href="https://doi.org/10.1016/j.neucom.2023.127206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing salient object detection (SOD) models are difficult to apply due to the complex and huge model structures. Although some lightweight models are proposed, the accuracy is barely satisfactory. In this paper, we design a novel semantics-guided contextual fusion network (SCFNet) that focuses on the interactive fusion of multi-level features for accurate and efficient salient object detection. Furthermore, we apply knowledge distillation to SOD task and provide a sizeable dataset KD-SOD80K. In detail, we transfer the rich knowledge from a seasoned teacher to the untrained SCFNet through unlabeled images, enabling SCFNet to learn a strong generalization ability to detect salient objects more accurately. The knowledge distillation based SCFNet (KD-SCFNet) achieves comparable accuracy to the state-of-the-art heavyweight methods with less than 1M parameters and 174 FPS real-time detection speed. Extensive experiments demonstrate the robustness and effectiveness of the proposed distillation method and SOD framework.},
  archive      = {J_NEUCOM},
  author       = {Jin Zhang and Yanjiao Shi and Jinyu Yang and Qianqian Guo},
  doi          = {10.1016/j.neucom.2023.127206},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127206},
  shortjournal = {Neurocomputing},
  title        = {KD-SCFNet: Towards more accurate and lightweight salient object detection via knowledge distillation},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). AdaER: An adaptive experience replay approach for continual
lifelong learning. <em>NEUCOM</em>, <em>572</em>, 127204. (<a
href="https://doi.org/10.1016/j.neucom.2023.127204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual lifelong learning is an machine learning framework inspired by human learning, where learners are trained to continuously acquire new knowledge in a sequential manner. However, the non-stationary nature of streaming training data poses a significant challenge known as catastrophic forgetting, which refers to the rapid forgetting of previously learned knowledge when new tasks are introduced. While some approaches, such as experience replay (ER), have been proposed to mitigate this issue, their performance remains limited, particularly in the class-incremental scenario which is considered natural and highly challenging. In this paper, we present a novel algorithm, called adaptive-experience replay (AdaER), to address the challenge of continual lifelong learning. AdaER consists of two stages: memory replay and memory update. In the memory replay stage, AdaER introduces a contextually-cued memory recall (C-CMR) strategy, which selectively replays memories that are most conflicting with the current input data in terms of both data and task. Additionally, AdaER incorporates an entropy-balanced reservoir sampling (E-BRS) strategy to enhance the performance of the memory buffer by maximizing information entropy. To evaluate the effectiveness of AdaER, we conduct experiments on established supervised continual lifelong learning benchmarks, specifically focusing on class-incremental learning scenarios. The results demonstrate that AdaER outperforms existing continual lifelong learning baselines, highlighting its efficacy in mitigating catastrophic forgetting and improving learning performance.},
  archive      = {J_NEUCOM},
  author       = {Xingyu Li and Bo Tang and Haifeng Li},
  doi          = {10.1016/j.neucom.2023.127204},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127204},
  shortjournal = {Neurocomputing},
  title        = {AdaER: An adaptive experience replay approach for continual lifelong learning},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relation-aware graph structure embedding with co-contrastive
learning for drug–drug interaction prediction. <em>NEUCOM</em>,
<em>572</em>, 127203. (<a
href="https://doi.org/10.1016/j.neucom.2023.127203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation-aware graph structure embedding (RaGSE) is promising for predicting multi-relational drug–drug interactions (DDIs). Most existing methods based on RaGSE commence by constructing a multi-relational DDI graph. They then learn the RaGSEs for drugs by aggregating their neighbor’s features under different relations. Nevertheless, new drugs lack neighbors in the DDI graph. This limitation hinders the ability of these methods to effectively learn RaGSEs for new drugs, resulting in suboptimal performance when evaluating DDIs that involve new drugs. To alleviate this issue, we propose a novel DDI prediction method based on relation-aware graph structure embedding with co-contrastive learning, RaGSECo. The proposed RaGSECo constructs two heterogeneous graphs: a multi-relational DDI graph and a multi-attribute drug–drug similarity (DDS) graph. The two graphs are used respectively for learning and propagating the RaGSEs of drugs, aiming to ensure all drugs, including new ones, can possess effective RaGSEs. Additionally, we present a novel co-contrastive learning module to learn feature representations for drug pairs (DPs). This module learns DP representations from two distinct views (interaction and similarity views) and encourages these views to supervise each other collaboratively to obtain more discriminative DP representations. We evaluate the effectiveness of our RaGSECo on three different tasks using two real datasets. Experimental outcomes unequivocally indicate that our RaGSECo surpasses several state-of-the-art methods in performance.},
  archive      = {J_NEUCOM},
  author       = {Mengying Jiang and Guizhong Liu and Biao Zhao and Yuanchao Su and Weiqiang Jin},
  doi          = {10.1016/j.neucom.2023.127203},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127203},
  shortjournal = {Neurocomputing},
  title        = {Relation-aware graph structure embedding with co-contrastive learning for drug–drug interaction prediction},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enclosing control of hybrid multi-agent systems.
<em>NEUCOM</em>, <em>572</em>, 127199. (<a
href="https://doi.org/10.1016/j.neucom.2023.127199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the enclosing control of hybrid multi-agent systems under directed networks. Firstly, we establish some criteria for continuous-time and discrete-time multi-agent systems to achieve enclosing control. Secondly, according to the communication modes among agents, four distributed enclosing control protocols are proposed for hybrid multi-agent systems. Then, under the proposed protocols, we give the corresponding sufficient conditions to guarantee enclosing control. Finally, the correctness of our results is verified by simulations.},
  archive      = {J_NEUCOM},
  author       = {Yapeng Jia and Qi Zhao and Dong Zhang and Yuanshi Zheng},
  doi          = {10.1016/j.neucom.2023.127199},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127199},
  shortjournal = {Neurocomputing},
  title        = {Enclosing control of hybrid multi-agent systems},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-free intelligent critic design with error analysis for
neural tracking control. <em>NEUCOM</em>, <em>572</em>, 127198. (<a
href="https://doi.org/10.1016/j.neucom.2023.127198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core of the optimal tracking control problem for nonlinear systems is how to ensure that the controlled system tracks the desired trajectory . The utility functions in previous studies have different properties which affect the final tracking effect of the intelligent critic algorithm. In this paper, we introduce a novel utility function and propose a Q-function based policy iteration algorithm to eliminate the final tracking error. In addition, neural networks are used as function approximator to approximate the performance index and control policy. Considering the impact of the approximation error on the tracking performance, an approximation error bound for each iteration of the novel Q-function is established. Under the given conditions, the approximation Q-function converges to the finite neighborhood of the optimal value. Moreover, it is proved that weight estimation errors of neural networks are uniformly ultimately bounded. Finally, the effectiveness of the algorithm is verified by the simulation example.},
  archive      = {J_NEUCOM},
  author       = {Ning Gao and Ding Wang and Mingming Zhao and Lingzhi Hu},
  doi          = {10.1016/j.neucom.2023.127198},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127198},
  shortjournal = {Neurocomputing},
  title        = {Model-free intelligent critic design with error analysis for neural tracking control},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PHEE: Identifying influential nodes in social networks with
a phased evaluation-enhanced search. <em>NEUCOM</em>, <em>572</em>,
127195. (<a href="https://doi.org/10.1016/j.neucom.2023.127195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to identify a small fraction of users with the best capacity to influence other users is central to the research of social network analysis . This problem is termed influence maximization (IM) and is known for its extensive applications. IM can be formulated as a combinatorial optimization problem , which has been shown to be NP -hard under some diffusion models . Therefore, seeking for high-accuracy IM algorithms with acceptable running time has attracted much attention in literature. However, most of existing IM algorithms only adopt a uniform mechanism in the whole solution search process, which lacks of flexible response when the algorithms trap in local optimum. This paper proposes a phased evaluation-enhanced (PHEE) approach for IM, which utilizes two distinct strategies to search the optimal solutions: The first one is a random range division-based evolutionary algorithm for improving solution quality; the second is a fast convergence strategy for searching an optimal solution. Two PHEE-based algorithms, MDD-PHEE and GCI-PHEE, are generated and are evaluated on 10 real-world social networks of different sizes and types. Experimental results demonstrate the effectiveness of PHEE; in particular, MDD-PHEE obtains the best influence spread on all networks compared with the state-of-the-art algorithms, and has a better performance than the time-consuming algorithm CELF on four datasets.},
  archive      = {J_NEUCOM},
  author       = {Enqiang Zhu and Haosen Wang and Yu Zhang and Kai Zhang and Chanjuan Liu},
  doi          = {10.1016/j.neucom.2023.127195},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127195},
  shortjournal = {Neurocomputing},
  title        = {PHEE: Identifying influential nodes in social networks with a phased evaluation-enhanced search},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TMS-net: A multi-feature multi-stream multi-level
information sharing network for skeleton-based sign language
recognition. <em>NEUCOM</em>, <em>572</em>, 127194. (<a
href="https://doi.org/10.1016/j.neucom.2023.127194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign Language Recognition (SLR) is an increasingly popular research topic due to its extensive potential applications , such as education, healthcare, emergency response, and social interaction . Sign language is a complex and dynamic language comprising hand gestures, facial expressions, and body motions. This high level of variability poses a significant obstacle for SLR tasks, which must accurately identify and respond to numerous gestures. To address these challenges, an end-to-end skeleton-based multi-feature multi-stream multi-level information sharing network (three multi information sharing network (TMS-Net)) is proposed. Specifically, in order to input more rich information to TMS-Net, we use joint feature pair with global features, bone feature pair with local features , and angle feature pair with scale invariance . In terms of network structure, to efficiently extract multiple features from inputs, we build a multi-stream structure and design a multi-level information sharing mechanism based on this structure to ensure the full utilization of skeleton feature information. From the experiment results of the WLASL-2000 dataset (56.4%), AUTSL dataset (96.62%) and MSASL(65.13%), TMS-Net surpass the state-of-the-art (SOTA) methods with single modality as input. In addition, a SLR-based human–robot interaction (HRI) experiment using our proposed TMS-Net is conducted, which proves the practical performance of the TMS-Net.},
  archive      = {J_NEUCOM},
  author       = {Zhiwen Deng and Yuquan Leng and Junkang Chen and Xiang Yu and Yang Zhang and Qing Gao},
  doi          = {10.1016/j.neucom.2023.127194},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127194},
  shortjournal = {Neurocomputing},
  title        = {TMS-net: A multi-feature multi-stream multi-level information sharing network for skeleton-based sign language recognition},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised person re-identification: A review of recent
works. <em>NEUCOM</em>, <em>572</em>, 127193. (<a
href="https://doi.org/10.1016/j.neucom.2023.127193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Re-identification (Re-ID) is a process that seeks to identify concern individuals from successive non-overlapping photographs. The area of computer vision has recently seen an uptick in the amount of attention focused on deep neural networks , especially given the popularity of smart monitoring systems and the development of sophisticated learning algorithms. We classified existing Re-ID technologies into closed-world and open-world contexts based on the used components. The closed-world scenario has been commonly used under a variety of data analysis hypotheses, and it brought precise results when applied to a variety of datasets utilizing deep learning techniques . We began with a comprehensive overview of closed-world person Re-ID considering deep metric learning, an extensive representation of features learning , ranking optimization, and in-depth analysis. Due to the accomplishment of performance in the packed scenario, the Re-ID focuses research has lately turned to a bare environment setting, which brings new issues. This setting is more akin to what we&#39;d find in real-world circumstances. We summarized the unsupervised Re-ID literature as well as current research trends and proposed future studies.},
  archive      = {J_NEUCOM},
  author       = {Meskat Jahan and Manajir Hassan and Sahadat Hossin and Md. Iftekhar Hossain and Mahmudul Hasan},
  doi          = {10.1016/j.neucom.2023.127193},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127193},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised person re-identification: A review of recent works},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). FDML: Feature disentangling and multi-view learning for
face forgery detection. <em>NEUCOM</em>, <em>572</em>, 127192. (<a
href="https://doi.org/10.1016/j.neucom.2023.127192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in realistic facial manipulation techniques have led to a growing interest in forgery detection due to security concerns. The presence of source-dependent information in both the forged images and the learned representations inevitably confuses the detector. To alleviate this issue, we present a Feature Disentangling and Multi-view Learning (FDML) framework to distill forgery-relevant intrinsic features from entangled information in a progressive manner, i.e., from image-level to feature-level. Towards image-level, the input image is first transformed into two complementary views, one using learnable filters to adaptively mine subtle frequency-aware clues, and the other using a novel data augmentation operation called SceneMix to weaken source-specific factors. The intermediate features output from these two branches are fully integrated through a trainable two-branch Hybrid Attention Module (HAM), guiding the effective performance of fused features. For feature-level, to automatically separate forgery-relevant features from source-relevant features and reduce the interference of irrelevant factors in decision making, two feature disentangling schemes are proposed, and finally only forgery-relevant features are used for prediction, which greatly improves the detection performance. Extensive experiments show that our framework achieves competitive performances compared with state-of-the-art works.},
  archive      = {J_NEUCOM},
  author       = {Miaomiao Yu and Hongying Li and Jiaxin Yang and Xiaofei Li and Shuohao Li and Jun Zhang},
  doi          = {10.1016/j.neucom.2023.127192},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127192},
  shortjournal = {Neurocomputing},
  title        = {FDML: Feature disentangling and multi-view learning for face forgery detection},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing the robustness of QMIX against state-adversarial
attacks. <em>NEUCOM</em>, <em>572</em>, 127191. (<a
href="https://doi.org/10.1016/j.neucom.2023.127191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Reinforcement Learning (MARL) trains the decision models of cooperative agents by making them gain the highest rewards. The Centralized Training with Decentralized Execution approach (CTDE) can effectively address some challenging issues faced by MARL, including convergence, stability, and scalability, but it cannot handle the robustness issue. However, the performance of a model trained by MARL can be seriously impacted by state-adversarial attacks that are viewed as the perturbations applied to an agent’s observation. Most recent research has concentrated on robust Single-Agent Reinforcement Learning (SARL) against state-adversarial attacks. However, there has not yet been too much work on robust MARL. QMIX is one of the popular cooperative MARL algorithms based on CTDE, but there is no study about its robustness. This work shows that QMIX is also sensitive to state-adversarial attacks. Inspired by four existing techniques of enhancing the robustness of SARL, we propose four methods to enhance the robustness of QMIX against five types of attacks. Our experiments illustrate the strengths and weaknesses of these methods against the five attacks, and an in-depth analysis is provided as well.},
  archive      = {J_NEUCOM},
  author       = {Weiran Guo and Guanjun Liu and Ziyuan Zhou and Ling Wang and Jiacun Wang},
  doi          = {10.1016/j.neucom.2023.127191},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127191},
  shortjournal = {Neurocomputing},
  title        = {Enhancing the robustness of QMIX against state-adversarial attacks},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-granularity CNN pruning framework via deformable
soft mask with joint training. <em>NEUCOM</em>, <em>572</em>, 127189.
(<a href="https://doi.org/10.1016/j.neucom.2023.127189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model pruning is a commonly used technique for compressing DNNs and reducing computation requirements to accelerate inference. However, the required granularity of pruning varies across different application scenarios, making it difficult and cumbersome to customize different pruning methods for each hardware or computing platform. Therefore, a unified framework is necessary to accommodate various levels of granularity of pruning. Furthermore, some available methods require additional fine-tuning or model retraining to restore accuracy, which can result in significant time costs. With this motivation, this paper proposes a Multi-Granularity Pruning Framework, namely MGPF, to obtain sparse models of different granularity without fine-tuning the remaining connections. Specifically, a deformable soft mask is introduced as the pruning initiator to achieve different levels of pruning granularity, such as weight pruning, channel pruning, and filter pruning, etc. The model parameters and soft masks are jointly trained, and we just apply L1 regularization on soft masks for sparsity to ensure that the model can be repaired during training without fine-tuning or retraining. After pruning, the soft masks are absorbed into the model parameters in the form of element product without changing the model structures. Experimental results on three image classification benchmarks CIFAR-10/100 and ImageNet-1K demonstrate the effectiveness of our method for various CNN architectures, datasets, and pruning rates. Particularly, for ResNet-50 on ImageNet-1K, we achieve a higher accuracy under the pruning rate of 98% for unstructured pruning which leads the advanced method by 12%.},
  archive      = {J_NEUCOM},
  author       = {Peng Zhang and Cong Tian and Liang Zhao and Zhenhua Duan},
  doi          = {10.1016/j.neucom.2023.127189},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127189},
  shortjournal = {Neurocomputing},
  title        = {A multi-granularity CNN pruning framework via deformable soft mask with joint training},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privileged multi-view one-class support vector machine.
<em>NEUCOM</em>, <em>572</em>, 127186. (<a
href="https://doi.org/10.1016/j.neucom.2023.127186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-class support vector machine (OCSVM) is a typical one-class classification approach , which learns the classifier by using only the target samples. At present, most OCSVM works hypothesize that the samples have only one view, while multi-view OCSVM has not been taken into account. In this paper, a novel multi-view one-class support vector machine method with privileged information learning (MOCPIL) is put forward. MOCPIL embodies both the consensus principle and complementarity principle in multi-view learning. Privileged information is additional data that is available only in the training process, but not in the testing process. By introducing the idea of privileged information learning, MOCPIL implements the complementarity principle by treating one view as the training data and the other view as the privileged data. Moreover, MOCPIL implements the consensus principle by requiring that different views of the same object should give similar predicting outputs. The learning problem of MOCPIL is a quadratic programming (QP) problem, which is able to be solved by off-the-shelf QP solvers. To the best of our knowledge, this is the first study to tackle the multi-view learning problem based on OCSVM. The performance of MOCPIL is evaluated through extensive experiments. The experimental results have shown that MOCPIL explicitly outperforms the existing multi-view one-class classification methods.},
  archive      = {J_NEUCOM},
  author       = {Yanshan Xiao and Guitao Pan and Bo Liu and Liang Zhao and Xiangjun Kong and Zhifeng Hao},
  doi          = {10.1016/j.neucom.2023.127186},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127186},
  shortjournal = {Neurocomputing},
  title        = {Privileged multi-view one-class support vector machine},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differentially private distributed online optimization via
push-sum one-point bandit dual averaging. <em>NEUCOM</em>, <em>572</em>,
127184. (<a href="https://doi.org/10.1016/j.neucom.2023.127184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the distributed online optimization problem in multi-agent systems considering privacy preservation . Each agent exchanges local information with neighboring agents on the strongly connected time-varying directed graphs . Since the process of information transmission is prone to information leakage , a distributed push-sum dual averaging algorithm based on the differential privacy mechanism is proposed to protect the privacy of the data. In addition, to handle situations where the gradient information of the node cost function is unknown, the one-point gradient estimation is designed to calculate the true gradient information and guide the update of the decision variables. With the appropriate choice of the stepsizes and the exploration parameters, the algorithm can effectively protect the privacy of agents while achieving sublinear regret with the convergence rate O ( T 3 4 ) O(T34) . Furthermore, this paper also explores the effect of one-point estimation parameters on the regret in the online setting and investigates the relation between the convergence effect of individual regret and differential privacy levels. Finally, several federated learning experiments were conducted to verify the efficacy of the algorithm.},
  archive      = {J_NEUCOM},
  author       = {Zhongyuan Zhao and Ju Yang and Wang Gao and Yan Wang and Mengli Wei},
  doi          = {10.1016/j.neucom.2023.127184},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127184},
  shortjournal = {Neurocomputing},
  title        = {Differentially private distributed online optimization via push-sum one-point bandit dual averaging},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analytically tractable heteroscedastic uncertainty
quantification in bayesian neural networks for regression tasks.
<em>NEUCOM</em>, <em>572</em>, 127183. (<a
href="https://doi.org/10.1016/j.neucom.2023.127183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tractable approximate Gaussian inference (TAGI) method allows for analytical parameter inference in Bayesian neural networks . In its current form, TAGI can only model homoscedastic aleatory uncertainty that is quantified by a constant error variance across the input covariate-domain. In this paper, we present the approximate Gaussian variance inference (AGVI) method that enables analytical inference of the error variance term as a Gaussian random variable . The combined framework regrouping TAGI and AGVI, referred to as TAGI-V, enables modeling heteroscedastic aleatory uncertainty in Bayesian neural networks . TAGI-V outperforms the homoscedastic version of TAGI in terms of predictive performance for the benchmark regression datasets. In comparison with other approximate inference methods, TAGI-V is an order of magnitude faster and exhibits a comparable or superior predictive performance.},
  archive      = {J_NEUCOM},
  author       = {Bhargob Deka and Luong Ha Nguyen and James-A. Goulet},
  doi          = {10.1016/j.neucom.2023.127183},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127183},
  shortjournal = {Neurocomputing},
  title        = {Analytically tractable heteroscedastic uncertainty quantification in bayesian neural networks for regression tasks},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal transformer with adaptive modality weighting for
multimodal sentiment analysis. <em>NEUCOM</em>, <em>572</em>, 127181.
(<a href="https://doi.org/10.1016/j.neucom.2023.127181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Sentiment Analysis (MSA) constitutes a pivotal technology in the realm of multimedia research. The efficacy of MSA models largely hinges on the quality of multimodal fusion. Notably, when conveying information pertinent to specific tasks or applications, not all modalities hold equal importance. Previous research, however, has either disregarded the importance of modalities altogether or solely focused on the importance of linguistic and non-linguistic modalities while neglecting the importance between non-linguistic modalities. To facilitate effective multimodal information fusion based on the relative importance of modalities, a novel multimodal fusion mode named Multimodal Transformer with Adaptive Modality Weighting (MTAMW) is proposed in this paper. Specifically, we introduce a multimodal adaptive weight matrix that allocates appropriate weights to each modality based on its contribution to sentiment analysis. Furthermore, a multimodal attention mechanism is introduced, utilizing multiple Softmax functions to compute attention weights, thereby efficiently fusion multimodal information via a single-stream Transformer. By meticulously considering the relative importance of each modality during the fusion process, more effective multimodal information fusion is achievable. Extensive experiments on benchmark datasets show that it is superior to or comparable to state-of-the-art methods on MSA tasks. The codes for our experiments are available at https://github.com/Vamos66/MTAMW .},
  archive      = {J_NEUCOM},
  author       = {Yifeng Wang and Jiahao He and Di Wang and Quan Wang and Bo Wan and Xuemei Luo},
  doi          = {10.1016/j.neucom.2023.127181},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127181},
  shortjournal = {Neurocomputing},
  title        = {Multimodal transformer with adaptive modality weighting for multimodal sentiment analysis},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guaranteed cost tracking control of constrained input
nonlinear uncertain systems using event-based ADP. <em>NEUCOM</em>,
<em>572</em>, 127179. (<a
href="https://doi.org/10.1016/j.neucom.2023.127179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the guaranteed cost robust tracking control problem of nonlinear systems subjected to input constraint and unmatched uncertainty. The event-based adaptive dynamic programming (ADP) approach is utilized to address this problem. First, the tracking error and reference trajectory are combined to form an augmented uncertain system. Then, by decomposing the uncertainty into the matched and unmatched parts, the original tracking problem is converted into the optimal regulation problem of an auxiliary system . The cost function for the auxiliary system is defined, and the associated Hamilton–Jacobi–Bellman (HJB) equation is solved using a single critic neural network (NN). Moreover, a novel event-triggering rule is formulated, and it is shown that the designed event-based controller guarantees that the tracking error is uniformly ultimately bounded. The derivation of event-based guaranteed cost and its relation with the time-based counterpart is presented. The exclusion of the infamous Zeno behavior is guaranteed. The uniform ultimate boundedness of the critic weight estimation error is shown. Finally, the effectiveness of the proposed event-triggered ADP method is illustrated through simulations of the spring–mass–damper system and Van der Pol’s oscillator with unmatched uncertainty.},
  archive      = {J_NEUCOM},
  author       = {Raju Dahal and Indrani Kar},
  doi          = {10.1016/j.neucom.2023.127179},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127179},
  shortjournal = {Neurocomputing},
  title        = {Guaranteed cost tracking control of constrained input nonlinear uncertain systems using event-based ADP},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed economic dispatch algorithm in smart grid based
on event-triggered and fixed-time consensus methods. <em>NEUCOM</em>,
<em>572</em>, 127178. (<a
href="https://doi.org/10.1016/j.neucom.2023.127178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a distributed economic dispatch algorithm based on event-triggered and fixed-time consensus is proposed for optimal dispatching among generators in smart grid. Aiming to quickly achieve economic dispatch in distributed smart grid and significantly reduce the frequency of communication between generators, the algorithm can address the supply–demand balance between the generation side and the consumption side, as well as the capacity constraints of the generators. Different from the relevant work, the proposed incremental cost can converge in fixed-time and the settling time is independent of the initial state of the generators. It will provide more flexibility for the system. Meanwhile, a fully distributed event-triggered strategy is adopted, which can reduce the interactive information between generators and avoid the waste of communication resources. Furthermore, the proposed algorithm is robust to the time-varying communication network topology . Finally, several examples are presented that validate the effectiveness of the algorithm.},
  archive      = {J_NEUCOM},
  author       = {Lianghao Ji and Linlong Zhang and Cuijuan Zhang and Shasha Yang and Xing Guo and Huaqing Li},
  doi          = {10.1016/j.neucom.2023.127178},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127178},
  shortjournal = {Neurocomputing},
  title        = {Distributed economic dispatch algorithm in smart grid based on event-triggered and fixed-time consensus methods},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DKPE: Deep KeyPhrase expansion. <em>NEUCOM</em>,
<em>572</em>, 127177. (<a
href="https://doi.org/10.1016/j.neucom.2023.127177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keyphrase provides accurate information of document content that is highly compact, concise, full of meanings, and widely used for discourse comprehension, organization, and text retrieval. Though previous studies have made substantial efforts for automated keyphrase extraction and generation, surprisingly, few studies have been made for KeyPhrase Expansion . This task aims to add more keyphrases for documents (e.g. scientific publications) via taking advantage of document content along with a very limited number of known keyphrases, which can widely be used to improve the keyphrases-involved NLP tasks. In this paper, we introduce a novel problem concerning KeyPhrase Expansion and propose a novel keyphrase expansion method with an encoder–decoder framework. We name it Deep KeyPhrase Expansion ( DKPE ) since it attempts to capture the deep semantic meaning of the document content together with known keyphrases via a deep learning framework. Specifically, the encoder and the decoder in DKPE play different roles to make full use of the known keyphrases. The former considers the keyphrase-guiding factors, which aggregates information of known keyphrases into context. On the contrary, the latter considers the keyphrase-inhibited factor to inhibit semantically repeated keyphrase generation. Extensive experiments on benchmark datasets demonstrate the efficacy of our proposed model.},
  archive      = {J_NEUCOM},
  author       = {Huaming Du and Zhilong Xie and Jia Song and Yaoxing Yuan and Jiacan Li and Xingyan Chen and Huangen Chen and Yu Zhao and Fuzhen Zhuang and Qing Li},
  doi          = {10.1016/j.neucom.2023.127177},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127177},
  shortjournal = {Neurocomputing},
  title        = {DKPE: Deep KeyPhrase expansion},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effect of three-stage cascade of opinion dynamics models in
coupled networks. <em>NEUCOM</em>, <em>572</em>, 127176. (<a
href="https://doi.org/10.1016/j.neucom.2023.127176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information technology has contributed to the spread of public opinion across multiple coupled networks, and the scope of information spread has expanded. Owing to the impact of personal subjective cognition, information attenuation occurs during the process of opinion transmission in social networks, particularly in multi-layer social networks. In this paper, we construct a three-stage cascade opinion dynamics model, based on the Hegselmann–Krause (HK) model, to analyze the effect of information dissemination attenuation on group decision behavior in coupled social networks. This model considers three-stage cascade information transmission and two competitive opinion leader subgroups in two different social network environments, and can describe a public opinion dissemination environment more closely. The results show that the combination of the network structure and the level of trust of the public can effectively guide the spread of public opinion, which provides valuable insights into the role of social media in shaping public opinion and its impact on various fields. These findings can be useful for advertisers and policymakers to control public opinion and reach a consensus in group decision-making.},
  archive      = {J_NEUCOM},
  author       = {Jia Chen and Youyuan Li and Gang Kou and Haomin Wang},
  doi          = {10.1016/j.neucom.2023.127176},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127176},
  shortjournal = {Neurocomputing},
  title        = {Effect of three-stage cascade of opinion dynamics models in coupled networks},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KPDet: Keypoint-based 3D object detection with parametric
radius learning. <em>NEUCOM</em>, <em>572</em>, 127171. (<a
href="https://doi.org/10.1016/j.neucom.2023.127171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D object detection requires accurate recognition of object category, size, rotation angle , and location in 3D space. Currently, many 3D object detection methods rely on the compact Bird’s Eye View (BEV) or point-wise representations to generate proposals. However, these proposal generation paradigms neglect the spatial distribution of objects, which causes difficulty in estimating the centers of objects. In this paper, we propose a keypoint-based 3D object detector, KPDet, which employs the keypoints in the neighborhood of object centers as the representation for proposal generation. The proposed KPDet first uses voxel-keypoint mapping to aggregate informative features on the subsampled keypoints from voxel-wise features, then calibrates the misalignment between the keypoints and object centers through the Object-aware Feature Pooling (OFP) module. These aligned keypoints with their corresponding features are applied to generate proposals. Since the keypoints are essential components, we further present the Structural Point Abstraction (SPA) module, which captures the anisotropic features of keypoints via constructed structural points to enhance the geometric information . In addition, based on the well-studied multi-task learning framework, we also propose a Parametric Radius Learning (PRL) strategy to adjust the sampling radius of the point-based feature aggregation process during the training procedure. Extensive experiments on the KITI and Waymo Open Dataset show that KPDet could achieve promising results compared with previous works.},
  archive      = {J_NEUCOM},
  author       = {Yuhao Huang and Sanping Zhou and Xinrui Yan and Nanning Zheng},
  doi          = {10.1016/j.neucom.2023.127171},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127171},
  shortjournal = {Neurocomputing},
  title        = {KPDet: Keypoint-based 3D object detection with parametric radius learning},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Training and meta-training an ensemble of binary neural
networks with quantum computing. <em>NEUCOM</em>, <em>572</em>, 127169.
(<a href="https://doi.org/10.1016/j.neucom.2023.127169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of NNs requires an expensive search in the space of the neural network architecture . This search performs heuristics called Neural Architecture Search (NAS), but an efficient algorithmic NAS remains an open problem. The development of quantum computing allows the use of quantum features, without a classical counterpart, as a proposal to solve some problems more efficiently. NAS through quantum algorithms is one such proposal, although none of the solutions presented so far is suitable for Noisy Intermediate Scale Quantum (NISQ) devices due to the complexity of the algorithms. This work reduces the use of quantum resources, which increases the possibility of running NAS on a NISQ device. The proposed method does not rely on random weights initialization and allows training a set of architectures simultaneously. The trained quantum model corresponds to an ensemble of classical ANNs , represented by a quantum superposition of an exponential number of ANNs.},
  archive      = {J_NEUCOM},
  author       = {Daivid V. Leal and Israel F. Araujo and Adenilton J. da Silva},
  doi          = {10.1016/j.neucom.2023.127169},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127169},
  shortjournal = {Neurocomputing},
  title        = {Training and meta-training an ensemble of binary neural networks with quantum computing},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Multi-omics fusion based on attention mechanism for
survival and drug response prediction in digestive system tumors.
<em>NEUCOM</em>, <em>572</em>, 127168. (<a
href="https://doi.org/10.1016/j.neucom.2023.127168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, digestive system tumors (DST) have become the primary cause of cancer-related deaths worldwide. Improving tumor prognosis and drug response prediction holds significant importance in personalized medicine. In order to construct an effective and interpretable model that integrates multiple omics data, the Multi-omics Fusion Graph Attention Network (MFGAN) is proposed for survival prediction and drug response prediction in DST. In this method, the similarity matrix of each kind of omics data is calculated and a new graph structure is learned by Graph Transformer (GT). Next, to learn the features of every kind of omics data from the TCGA and GDSC databases, the Graph Attention Network (GAN) is used. Lastly, the View Correlation Discovery Network (VCDN) combines different types of omics data features to predict survival risk and drug response. Among them, the survival prediction results showed an improvement of up to 9% relative to other methods in terms of the c-index metric, with a minimum improvement of 2.6%. In terms of drug response prediction performance, there was an improvement of 4%. The ablation experiment demonstrates MFGAN’s feature integration capability, and the functional enrichment analysis for significant genes explains the functional characteristics of the model. Furthermore, the prediction of unknown tumor drug response demonstrates the model’s prediction ability. The proposed high-prediction comprehensive model could have important potential value for the personalized medicine of DST.},
  archive      = {J_NEUCOM},
  author       = {Lin Zhou and Ning Wang and Zhengzhi Zhu and Hongbo Gao and Nannan Lu and Huiping Su and Xinmiao Wang},
  doi          = {10.1016/j.neucom.2023.127168},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127168},
  shortjournal = {Neurocomputing},
  title        = {Multi-omics fusion based on attention mechanism for survival and drug response prediction in digestive system tumors},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evidence, my dear watson: Abstractive dialogue summarization
on learnable relevant utterances. <em>NEUCOM</em>, <em>572</em>, 127132.
(<a href="https://doi.org/10.1016/j.neucom.2023.127132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstractive dialogue summarization requires distilling and rephrasing key information from noisy multi-speaker documents. Combining pre-trained language models with input augmentation techniques has recently led to significant research progress. However, existing solutions still struggle to select relevant chat segments, primarily relying on open-domain and unsupervised annotators not tailored to the actual needs of the summarization task. In this paper, we propose DearWatson , a task-aware utterance-level annotation framework for improving the effectiveness and interpretability of pre-trained dialogue summarization models. Precisely, we learn relevant utterances in the source document and mark them with special tags, that then act as supporting evidence for the generated summary. Quantitative experiments are conducted on two datasets made up of real-life messenger conversations. The results show that DearWatson allows model attention to focus on salient tokens, achieving new state-of-the-art results in three evaluation metrics , including semantic and factuality measures. Human evaluation proves the superiority of our solution in semantic consistency and recall. Finally, extensive ablation studies confirm each module’s importance, also exploring different annotation strategies and parameter-efficient fine-tuning of large generative language models.},
  archive      = {J_NEUCOM},
  author       = {Paolo Italiani and Giacomo Frisoni and Gianluca Moro and Antonella Carbonaro and Claudio Sartori},
  doi          = {10.1016/j.neucom.2023.127132},
  journal      = {Neurocomputing},
  month        = {3},
  pages        = {127132},
  shortjournal = {Neurocomputing},
  title        = {Evidence, my dear watson: Abstractive dialogue summarization on learnable relevant utterances},
  volume       = {572},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-supervision transformer combining bounding box and
mask for data-limited pose estimation. <em>NEUCOM</em>, <em>571</em>,
127209. (<a href="https://doi.org/10.1016/j.neucom.2023.127209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In scenarios where acquiring accurate annotated pose data is difficult, obtaining sufficient training samples becomes a challenge. Given these data constraints, it is challenging to provide optimal end-to-end supervision with limited pose information. To address this limitation, we propose a novel approach, named MSPose, which combines diverse data sources from human instances to provide multi-level supervision in human pose estimation. This approach mitigates the impact of scarce training data and enhances pose estimation precision by synergistically incorporating human bounding box and mask information. Our proposed method achieves multi-level model activation for the human body region, structure, and joints. This hierarchical pixel activation is facilitated by integrating human bounding box and mask signals as supplementary supervision during training. Importantly, we exclude auxiliary branches to ensure complete freedom during inference. Our experimental validation on a quarter of the COCO and MPII datasets demonstrates the competitiveness of our method compared to state-of-the-art methods. Compared to TokenPose-T, our MSPose-T achieves a 6.1 points improvement in average precision and a corresponding 3.1 points increase on the full COCO validation set. On the MPII dataset, MSPose achieves the highest Mean score of 1.9 points. Our approach achieves these improvements while maintaining consistent parameters and GFLOPs, highlighting the advantage of our approach.},
  archive      = {J_NEUCOM},
  author       = {Xinyang Yuan and Peng Cheng and Songchen Han},
  doi          = {10.1016/j.neucom.2023.127209},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127209},
  shortjournal = {Neurocomputing},
  title        = {Multi-supervision transformer combining bounding box and mask for data-limited pose estimation},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Hybrid cross-modal interaction learning for multimodal
sentiment analysis. <em>NEUCOM</em>, <em>571</em>, 127201. (<a
href="https://doi.org/10.1016/j.neucom.2023.127201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis (MSA) predicts the sentiment polarity of an unlabeled utterance that carries multiple modalities, such as text, vision and audio, by analyzing labeled utterances. Existing fusion methods mainly focus on establishing the relationship of characteristics among different modalities to enhance their emotion recognition abilities. However, they always ignore the all-round interaction between different modalities, especially the cross-modal interaction, which is critical to the sentiment decision of multimodal data. To address these issues, we propose a novel hybrid cross-modal interaction learning (HCIL) framework for hybrid learning of intra-modal, inter-modal, interactive-modal and cross-modal interactions, with which the model can fully utilize the sentiment information of multimodalities and enhance the sentiment assistance between modalities. Specifically, we propose two core substructures to learn discriminative multimodal features. One is the comparative learning interaction structure that can track the class dynamics in the intra-modal, reduce the modal gap in the inter-modal and establish emotional communication in the interactive-modal; the other is the cross-modal prediction structure, which can build the sentiment relationship between cross-modal pairs, especially exploring the auxiliary sentiment effect of audio on the vision and text. Furthermore, we adopt a hierarchical feature fusion structure to generate the multimodal feature for the final sentiment prediction . Extensive experiments on three benchmark datasets showed that our HCIL approach can obtain significant performance on the MSA task and that the design of a cross-modal interaction structure can directly promote the improvement of sentiment classification performance.},
  archive      = {J_NEUCOM},
  author       = {Yanping Fu and Zhiyuan Zhang and Ruidi Yang and Cuiyou Yao},
  doi          = {10.1016/j.neucom.2023.127201},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127201},
  shortjournal = {Neurocomputing},
  title        = {Hybrid cross-modal interaction learning for multimodal sentiment analysis},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prescribed-time prescribed performance control for
stochastic nonlinear input-delay systems with arbitrary bounded initial
error. <em>NEUCOM</em>, <em>571</em>, 127200. (<a
href="https://doi.org/10.1016/j.neucom.2023.127200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of adaptive prescribed-time prescribed performance control (PTPPC) for stochastic nonlinear input-delay systems with arbitrary bounded initial error is discussed in this paper. With the help of prescribed-time prescribed performance function (PTPPF) and a novel switching model-based error transformation function, the proposed method can ensure that the tracking error reaches the specified accuracy within an arbitrary prescribed time, and another significant advantage is that it removes the restriction that the initial error must be within the constrained boundary of existing prescribed performance control (PPC) methods. In addition, an auxiliary system is introduced to manipulate the input delay, which eliminates the limitations of computational complexity and small delays in the Padé approximation method. By combining backstepping with neural network approximation technology, a novel controller is raised, under which the tracking accuracy and convergence time can be pledged, and the whole signals of closed-loop system are bounded in probability. Simulation experiments testify the effectiveness of the control approach.},
  archive      = {J_NEUCOM},
  author       = {Yan Yao and Jieqing Tan and Yangang Yao and Xu Zhang and Peng Chen},
  doi          = {10.1016/j.neucom.2023.127200},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127200},
  shortjournal = {Neurocomputing},
  title        = {Prescribed-time prescribed performance control for stochastic nonlinear input-delay systems with arbitrary bounded initial error},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convergence of deep ReLU networks. <em>NEUCOM</em>,
<em>571</em>, 127174. (<a
href="https://doi.org/10.1016/j.neucom.2023.127174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore convergence of deep neural networks with the popular ReLU activation function , as the depth of the networks tends to infinity. To this end, we introduce the notion of activation domains and activation matrices of a ReLU network. By replacing applications of the ReLU activation function by multiplications with activation matrices on activation domains, we obtain an explicit expression of the ReLU network. We then identify the convergence of the ReLU networks as convergence of a class of infinite products of matrices. Sufficient and necessary conditions for convergence of these infinite products of matrices are studied. As a result, we establish necessary conditions for ReLU networks to converge that the sequence of weight matrices converges to the identity matrix and the sequence of the bias vectors converges to zero as the depth of ReLU networks increases to infinity. Moreover, we obtain sufficient conditions in terms of the weight matrices and bias vectors at hidden layers for pointwise convergence of deep ReLU networks. These results provide mathematical insights to convergence of deep neural networks . Experiments are conducted to mathematically verify the results and to illustrate their potential usefulness in initialization of deep neural networks.},
  archive      = {J_NEUCOM},
  author       = {Yuesheng Xu and Haizhang Zhang},
  doi          = {10.1016/j.neucom.2023.127174},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127174},
  shortjournal = {Neurocomputing},
  title        = {Convergence of deep ReLU networks},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). FAUC-s: Deep AUC maximization by focusing on hard samples.
<em>NEUCOM</em>, <em>571</em>, 127172. (<a
href="https://doi.org/10.1016/j.neucom.2023.127172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep AUC maximization (DAM) is a popular method to deal with complex imbalanced classification problems. It learns a deep neural network by minimizing a surrogate AUC loss. The mostly used surrogates are the pairwise square loss and its variants. However, they are usually used in regression problems and are sensitive to noise samples. The easy samples suffer larger losses than those without correct classification, which is unreasonable in optimization problems . In this paper, we propose a focus AUC loss based on samples (FAUC-S) by constructing a differentiable weight function that identifies hard and easy samples, which makes easy samples have small losses, and hard samples have large losses. It is more reasonable than the traditional AUC loss while having the same advantages on large-scale datasets. In experiments, we use an end-to-end compositional DAM to investigate the effect of different weight functions on the AUC loss and compare it with other methods. Experimental results on several benchmark datasets demonstrate that FAUC-S achieves superior performance in terms of AUC compared to existing state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Shoukun Xu and Yanrui Ding and Yanhao Wang and Junru Luo},
  doi          = {10.1016/j.neucom.2023.127172},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127172},
  shortjournal = {Neurocomputing},
  title        = {FAUC-S: Deep AUC maximization by focusing on hard samples},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-attention deep ConvLSTM with sparse-learned channel
dependencies for wearable sensor-based human activity recognition.
<em>NEUCOM</em>, <em>571</em>, 127157. (<a
href="https://doi.org/10.1016/j.neucom.2023.127157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a novel deep-learning architecture with sparse learning for human activity recognition . The proposed model contains 1D CNNs and LSTM layers with a self-attention mechanism to enhance a substantial number of time points in time-series data for human activity recognition systems. Based on the recent success of squeeze-and-excite (SE) networks, the proposed deep learning model utilizes the SE module to enhance channel-wise interdependencies , which in turn leads to a boost in performance. In addition, we utilized sparse learning to retrain only weak nodes and freeze stronger nodes in a fully connected layer prior to classification layer. Furthermore, we utilized an entropy-inspired formula to find sparsely located weaker nodes and validated our model on various datasets, including Opportunity, UCI-HAR, and WISDM . Herein, we present an extensive analysis and survey of state-of-the-art studies, in addition to our proposed research. For a fair comparison , we evaluated our deep learning architecture using various performance metrics and achieved better results; the proposed model outperformed state-of-the-art algorithms for human activity recognition.},
  archive      = {J_NEUCOM},
  author       = {Shan Ullah and Mehdi Pirahandeh and Deok-Hwan Kim},
  doi          = {10.1016/j.neucom.2023.127157},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127157},
  shortjournal = {Neurocomputing},
  title        = {Self-attention deep ConvLSTM with sparse-learned channel dependencies for wearable sensor-based human activity recognition},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Corrigendum to “methods to balance the exploration and
exploitation in differential evolution from different scales: A survey”
[neurocomputing 561 (2023) 126899]. <em>NEUCOM</em>, <em>571</em>,
127156. (<a href="https://doi.org/10.1016/j.neucom.2023.127156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Yanyun Zhang and Guanyu Chen and Li Cheng and Quanyu Wang and Qi Li},
  doi          = {10.1016/j.neucom.2023.127156},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127156},
  shortjournal = {Neurocomputing},
  title        = {Corrigendum to “Methods to balance the exploration and exploitation in differential evolution from different scales: A survey” [Neurocomputing 561 (2023) 126899]},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fitting model with optimal multiple image hiding effect.
<em>NEUCOM</em>, <em>571</em>, 127146. (<a
href="https://doi.org/10.1016/j.neucom.2023.127146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image hiding is a field of research that focuses on covert storage and transmission techniques. It involves embedding a secret image within a container image to create a classified-carrying image that resembles a normal image. Nevertheless,the current image hiding methods based on Invertible neural networks suffer from a critical issue of information loss during the hiding process. This leads to a substantial degradation in the quality of the secret image extracted,thereby preventing the simultaneous achievement of secure transmission, high-capacity transmission, and high fidelity of the secret image in an insecure network environment. To address this issue,we introduce a novel image hiding architecture called FMIN (Fitting Models Based on Invertible Network). FMIN incorporates our innovative fitting model, which fits the loss information and generates a variable z simulating the loss information at the receiver side. This variable z is used as an input to the revealing process,enabling the high-quality extraction of multiple secret images from a single classified loaded image. Additionally,we introduce a novel decoupled training strategy aimed at enhancing the stability of image hiding model during training. Experimental results demonstrate that the image hiding method based on the proposed FMIN architecture in this paper significantly outperforms other SOTA image hiding methods for single-image and multiple-images hiding.},
  archive      = {J_NEUCOM},
  author       = {Lin Huo and Lang Huang and Zheng Gan and Rui Pei Chen},
  doi          = {10.1016/j.neucom.2023.127146},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127146},
  shortjournal = {Neurocomputing},
  title        = {A fitting model with optimal multiple image hiding effect},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Functional connectivity via total correlation: Analytical
results in visual areas. <em>NEUCOM</em>, <em>571</em>, 127143. (<a
href="https://doi.org/10.1016/j.neucom.2023.127143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies invoke the superiority of the multivariate Total Correlation concept over the conventional pairwise measures of functional connectivity in biological networks . Those seminal works certainly show that empirical measures of Total Correlation lead to connectivity patterns that differ from what is obtained using the most popular measure, linear correlation , or its higher order and nonlinear alternative Mutual Information . However, they do not provide analytical results that explain the differences beyond the obvious multivariate versus bivariate definitions. Moreover, the accuracy of the empirical estimators could not be addressed directly because no controlled scenario with known analytical result was provided either. This point is critical because empirical estimation of information theory measures is always challenging. As opposed to previous empirical approaches, in this work we present analytical results to prove the advantages of Total Correlation over Mutual Information to describe the functional connectivity . In particular, we do it in neural networks for early vision (retina–LGN–cortex) which are realistic but simple enough to get analytical results. The presented analytical setting is also useful to check empirical estimates of Total Correlation . Therefore, once certain estimate can be trusted, one can explore the behavior with natural signals where the analytical results (that assume Gaussian signals), may not be valid. In this regard, as applications (a) we explore the effect of connectivity and feedback in the analytical retina–LGN–cortex network with natural images, and (b) we assess the functional connectivity in visual areas V1–V2–V3–V4 from actual fMRI recordings.},
  archive      = {J_NEUCOM},
  author       = {Qiang Li and Greg Ver Steeg and Jesus Malo},
  doi          = {10.1016/j.neucom.2023.127143},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127143},
  shortjournal = {Neurocomputing},
  title        = {Functional connectivity via total correlation: Analytical results in visual areas},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KI-MAG: A knowledge-infused abstractive question answering
system in medical domain. <em>NEUCOM</em>, <em>571</em>, 127141. (<a
href="https://doi.org/10.1016/j.neucom.2023.127141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstractive question-answering (QA) has emerged as a prominent area in Natural Language Processing (NLP) due to its ability to produce concise and human-like responses, particularly with the advancement of Large Language Models . Despite its potential, abstractive QA suffers from challenges like the need for extensive training data and the generation of incorrect entities and out-of-context words in the responses. In safety–critical domains like medical and clinical settings, such issues are unacceptable and may compromise the accuracy and reliability of generated answers. We proposed KI-MAG (Knowledge-Infused Medical Abstractive Generator) model, a novel Knowledge-Infused Abstractive Question Answering System specifically designed for the medical domain. KI-MAG aims to address the aforementioned limitations and enhance the correctness of generated responses while mitigating data sparsity concerns. The KI-MAG system produces more precise and informative answers by incorporating relevant medical entities into the model’s generation process. Furthermore, we adopt a synthetic data generation approach using question–answer pairs to overcome the challenge of limited training data in the medical domain. These synthetic pairs augment the original dataset, resulting in better model generalization and improved performance. Our extensive experimental evaluations demonstrate the effectiveness of the KI-MAG system. Compared to traditional abstractive QA models, our approach exhibits a substantial increase of approximately 15% in Blue-1, Blue-2, Blue-3, and Blue-4 scores, indicating a remarkable improvement in answer accuracy and overall quality of responses. Overall, our Knowledge-Infused Abstractive Question Answering System in the Medical Domain (KI-MAG) presents a promising solution to enhance the performance and reliability of abstractive QA models in safety–critical medical applications where precision and correctness of answers are of utmost importance .},
  archive      = {J_NEUCOM},
  author       = {Aizan Zafar and Sovan Kumar Sahoo and Harsh Bhardawaj and Amitava Das and Asif Ekbal},
  doi          = {10.1016/j.neucom.2023.127141},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127141},
  shortjournal = {Neurocomputing},
  title        = {KI-MAG: A knowledge-infused abstractive question answering system in medical domain},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sampling-based epoch differentiation calibrated graph
convolution network for point-of-interest recommendation.
<em>NEUCOM</em>, <em>571</em>, 127140. (<a
href="https://doi.org/10.1016/j.neucom.2023.127140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In location-based social networks, calibrating a point-of-interest (POI) recommendation system is as important as its accuracy for improving user satisfaction. POI recommendation calibration is primarily classified as categorical or geographical calibration. Categorical calibration ensures that the recommended items are distributed proportionally among the past interest categories of the target user. When a target user checks 80 Chinese, 10 Japanese, and 10 French restaurants, a recommendation list with a ratio of 8:1:1 for Chinese, Japanese, and French restaurants can be reasonably expected. In addition to categorical calibration, geographical calibration has been proposed to increase user interest in the recommended results. Users have a high probability of revisiting locations in their subareas. Therefore, the POIs recommended in multiple subareas of interest are more suitable than those from one small and frequently visited subarea. However, improving the calibration and accuracy are conflicting tasks. To achieve high calibration while maintaining accuracy, previous studies proposed reranking-based techniques to rerank the candidate list and return POIs with high calibration. However, optimizing the calibration by reranking is independent of the basic-candidate-item generation model, resulting in a suboptimal system. To tackle the problem, we propose a novel sampling-based differentiation technique to merge the task of improving calibration into the GCN model training process and directly generate the final recommendation list. The model is flexible and can be applied to different domains, where a domain can be a subarea or category. In a three-layer GCN, the layer one represents the historical check-ins of the user, whereas layer three includes the candidate POIs from which the target user aggregates information. We trained the model to make the distribution of the POI domains at layer three approximated the distribution at layer one. Experimental results on Philadelphia and Tucson datasets confirmed that the proposed method outperforms all state-of-the-art GCN+ geo-reranking and GCN+ MCF baselines, improving Recall@ 5 from 0.0394 to 0.0412 (4.57%) and Jensen–Shannon measure (JS)@ 5 from 0.5931 to 0.6734 (13.54%) on the Philadelphia dataset and improving Recall@ 5 from 0.0495 to 0.0517 (4.40%) and JS@ 5 from 0.5869 to 0.6598 (12.42%) on the Tucson dataset for categorical calibration. The model was also tested in the geographical domain and a similar trend was observed.},
  archive      = {J_NEUCOM},
  author       = {Fan Mo and Xin Fan and Chongxian Chen and Changhao Bai and Hayato Yamana},
  doi          = {10.1016/j.neucom.2023.127140},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127140},
  shortjournal = {Neurocomputing},
  title        = {Sampling-based epoch differentiation calibrated graph convolution network for point-of-interest recommendation},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Knowledge-guided pre-training and fine-tuning: Video
representation learning for action recognition. <em>NEUCOM</em>,
<em>571</em>, 127136. (<a
href="https://doi.org/10.1016/j.neucom.2023.127136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video-based action recognition is an important task in the computer vision community, aiming to extract rich spatial–temporal information to recognize human actions from videos. Many approaches adopt self-supervised learning in large-scale unlabeled datasets and exploit transfer learning in the downstream action recognition task. Though much progress has been made for action recognition with video representation learning , two main issues remain for most existing methods. Firstly, the pre-training with self-supervised pretext tasks usually learns neutral and not much informative representations for the downstream action recognition task. Secondly, the valuable learned knowledge from large-scaled pre-training datasets will be gradually forgotten in the fine-tuning stage. To address such issues, in this paper, we propose a novel video representation learning method with knowledge-guided pre-training and fine-tuning for action recognition, which incorporates external human parsing knowledge for generating informative representation in the pre-training, and preserves the pre-trained knowledge in the fine-tuning stage to avoid catastrophic forgetting via self-distillation. Our model, with contributions from the external human parsing knowledge, video-level contrastive learning , and knowledge preserving self-distillation, achieves state-of-the-art performance on two popular benchmarks, i.e. , UCF101 and HMDB51, verifying the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Guanhong Wang and Yang Zhou and Zhanhao He and Keyu Lu and Yang Feng and Zuozhu Liu and Gaoang Wang},
  doi          = {10.1016/j.neucom.2023.127136},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127136},
  shortjournal = {Neurocomputing},
  title        = {Knowledge-guided pre-training and fine-tuning: Video representation learning for action recognition},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-level neural prompt for zero-shot weakly supervised
group activity recognition. <em>NEUCOM</em>, <em>571</em>, 127135. (<a
href="https://doi.org/10.1016/j.neucom.2023.127135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group activity recognition aims at understanding the overall activity involved multi-person interaction with each other as a whole in the complex variations in both spatial and temporal transition in untrimmed video. While remarkably significance in applications, existing methods are often impractical for the following two reasons: (1) they rely on heavy annotations and off-the-shelf object detectors even in test stage; (2) they are trained to predict a closed-set predetermined group categories, which limits their generality to wider unseen categories. Motivated by this, we propose a novel zero-shot weakly supervised group activity recognition neural model, ZSTGroupCLIP, which is not only free from the restriction of heavy annotations, but also captures the generalizable elements that are vital for open-set exploration. Specifically, our model based on visual–textual joint representation learning seeks discriminative visual cues for aligning both the group vision and category text branches by multi-level neural prompt. Moreover, to further learn group-related contextual representations under weakly supervision, we learn layer-wise prompts across early layer of group encoder for progressive context modeling. Through extensive experimental validations and comparisons to several baseline methods on two benchmarks, Volleyball and NBA datasets, our method achieves outstanding performance.},
  archive      = {J_NEUCOM},
  author       = {Yinghui Zhang and Bo Sun and Jun He and Lejun Yu and Xiaochong Zhao},
  doi          = {10.1016/j.neucom.2023.127135},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127135},
  shortjournal = {Neurocomputing},
  title        = {Multi-level neural prompt for zero-shot weakly supervised group activity recognition},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive event-triggered pseudolinear consensus filter for
multi-UAVs bearings-only target tracking. <em>NEUCOM</em>, <em>571</em>,
127127. (<a href="https://doi.org/10.1016/j.neucom.2023.127127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An improved version of the pseudolinear filter is proposed, namely an adaptive event-triggered instrumental variable-based pseudolinear information consensus filter, with a special focus on three-dimensional(3D) unbiased target tracking with multiple unmanned aerial vehicles (UAVs) bearings-only measurements under communication faults. To deal with the unknown communication faults, a credibility-based weighted average consensus rule is constructed, which considers the network topology and the information quality of UAVs. Furthermore, an adaptive event-triggered mechanism is designed to reduce the computation burden and communication bandwidth . The selective-angle-measurement strategy (SAMS)-based instrumental variable is integrated into the pseudolinear information consensus filter to achieve unbiased estimates. It is proved that the estimates of all UAVs will eventually achieve consistency, and its estimation errors are bounded. Finally, numerical simulations are given to verify the advantages of the proposed filtering algorithm in terms of enhanced accuracy and faster convergence rates.},
  archive      = {J_NEUCOM},
  author       = {Fanjing Huang and Panlong Wu and Xingxiu Li and Jimin Li and Ruohan Zhao},
  doi          = {10.1016/j.neucom.2023.127127},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127127},
  shortjournal = {Neurocomputing},
  title        = {Adaptive event-triggered pseudolinear consensus filter for multi-UAVs bearings-only target tracking},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Curricular-balanced long-tailed learning. <em>NEUCOM</em>,
<em>571</em>, 127121. (<a
href="https://doi.org/10.1016/j.neucom.2023.127121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The real-world data distribution is essentially long-tailed, which poses a significant challenge to the deep model. Classification models minimizing cross-entropy loss struggle to classify the tail classes, although cross-entropy training is successful on balanced data. We reveal that minimizing cross-entropy loss under long-tailed distribution leads to the Tail Collapse phenomenon, which fundamentally limits the performance of neural networks . To correct the optimization behavior of cross-entropy training, we propose a new Curricular Balanced Loss (CurB Loss) to alleviate the imbalance. The CurB loss has two factors: the re-weighting factor and the curriculum learning factor. We design the re-weighting factor based on the margin-based training that can theoretically reach the optimums of networks. Then, we incorporate the idea of Curriculum Learning into the re-weighting loss in an adaptive manner. We design the curriculum learning factor to make the model gradually emphasize the hard classes. The empirical results demonstrate the complementary of the two factors. Our method outperforms previous state-of-the-art methods by 0.9%, 2.7%, 1.2% on CIFAR10-LT, CIFAR-100-LT and ImageNet-LT, demonstrating the effectiveness of CurB Loss for long-tailed visual recognition.},
  archive      = {J_NEUCOM},
  author       = {Xiang Xiang and Zihan Zhang and Xilin Chen},
  doi          = {10.1016/j.neucom.2023.127121},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127121},
  shortjournal = {Neurocomputing},
  title        = {Curricular-balanced long-tailed learning},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Filter unsupervised spectral feature selection method for
mixed data based on a new feature correlation measure. <em>NEUCOM</em>,
<em>571</em>, 127111. (<a
href="https://doi.org/10.1016/j.neucom.2023.127111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Unsupervised Feature Selection (UFS) methods have attracted considerable interest in different research areas due to their wide application in problems where unlabeled data appears. Nevertheless, few UFS methods can process datasets described by both numerical and non-numerical features (mixed data). This paper introduces a new filter UFS method based on a new feature correlation measure for mixed data to select a relevant and non-redundant feature subset. The proposed method addresses the feature selection problem in two stages through a strategy that combines Spectral Feature Selection to identify relevant features and a Pair-wise Redundancy Analysis to remove those features with a high correlation with others. According to our experiments, the proposed feature selection method based on the introduced feature correlation measure provides better quality results than previous filter UFS methods for mixed data reported in the literature.},
  archive      = {J_NEUCOM},
  author       = {Saúl Solorio-Fernández and J. Ariel Carrasco-Ochoa and José Fco. Martínez-Trinidad},
  doi          = {10.1016/j.neucom.2023.127111},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127111},
  shortjournal = {Neurocomputing},
  title        = {Filter unsupervised spectral feature selection method for mixed data based on a new feature correlation measure},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A quantum-enhanced solution method for multi classification
problems. <em>NEUCOM</em>, <em>571</em>, 127106. (<a
href="https://doi.org/10.1016/j.neucom.2023.127106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing data size of multi classification problems, the running efficiency of classical algorithms is seriously affected. In the paper, in order to improve the implementation efficiency of the algorithm, we propose a quantum-enhanced solution method for multi classification problems. The method mainly introduces the quantum-enhanced technology into the classical algorithm. Aiming at the two steps of solving Euclid distance and kernel function in the classical algorithm, the paper relates the classical inner product principle with the amplitude evolution of quantum states. On the basis of quantizing the sample data, a general quantum circuit that can calculate the inner product is designed and constructed. The circuit can make full use of the advantages of quantum parallel computing to achieve exponential acceleration of computing efficiency. Aiming at solving linear equations in the classical algorithm, a quantum circuit based on the quantum singular value estimation is designed and constructed. The circuit makes use of the acceleration advantage of quantum computing in matrix computing to achieve polynomial acceleration of matrix computing. The experimental results show that the method can not only find the optimal solution for multi classification problems, but also greatly improve the operation efficiency of the algorithm. Compared with the classical methods, the method has at least polynomial improvement in time complexity and spatial complexity.},
  archive      = {J_NEUCOM},
  author       = {Yijun Zhang and Xiaodong Mu and Peng Zhang and Dao Zhao},
  doi          = {10.1016/j.neucom.2023.127106},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127106},
  shortjournal = {Neurocomputing},
  title        = {A quantum-enhanced solution method for multi classification problems},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advances in artificial neural networks, machine learning and
computational intelligence. <em>NEUCOM</em>, <em>571</em>, 127098. (<a
href="https://doi.org/10.1016/j.neucom.2023.127098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Nicolò Navarin ( Guest editors ) and Dounia Mulders and Luca Oneto},
  doi          = {10.1016/j.neucom.2023.127098},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127098},
  shortjournal = {Neurocomputing},
  title        = {Advances in artificial neural networks, machine learning and computational intelligence},
  volume       = {571},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Deep contrastive clustering via hard positive sample
debiased. <em>NEUCOM</em>, <em>570</em>, 127147. (<a
href="https://doi.org/10.1016/j.neucom.2023.127147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep graph clustering aims to reveal the underlying information of the graph and provide accurate embedding for the node clustering task , in which contrastive learning plays an important role. However, the commonly used contrastive loss function incorrectly classifies elements outside the diagonal of the cross view as negative samples, which contain a large number of positive sample pairs. In order to overcome the above problems, we propose a new deep graph contrastive clustering method , which combines hard positive sample debiasing and sample pair weighting, and improves the recognition ability of the network by removing the potential positive sample pairs and hard sample pair weighting in the negative sample pair of the loss function. More specifically, we developed a symmetric graph neural network to encode node representations. Using two sets of node representations, the correctness of negative cases is increased by clustering to generate high-confidence pseudo-label pairs for labels and confidence. The similarity distribution differences are weighted by adapting to different dataset samples to improve the sample recognition ability. To verify the efficacy of our DCHD, we compare it to existing state-of-the-art methods for node clustering tasks on six real-world datasets. Overall, the experimental results show that our proposed method outperforms current state-of-the-art graph clustering methods.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Zhang and Huiying Xu and Xinzhong Zhu and Yuhang Chen},
  doi          = {10.1016/j.neucom.2023.127147},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127147},
  shortjournal = {Neurocomputing},
  title        = {Deep contrastive clustering via hard positive sample debiased},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-modal anchor adaptation learning for multi-modal
summarization. <em>NEUCOM</em>, <em>570</em>, 127144. (<a
href="https://doi.org/10.1016/j.neucom.2023.127144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on analyzing the relationship between the input of source text and source image, and then through the integration and generalization of the multi-modal information (e.g., texts and images), outputs the multi-modal summarization including text and image. However, existing multi-modal summarization methods face several challenges: (1) Different modalities exist in different semantic spaces, and expressing the multi-modal information of source modalities in a similar semantic representation space is crucial. (2) For the result of text summarization, it is crucial to explore how to capture both the differences and similarities within the source modalities, which can reduce redundancy to improve the quality of text summarization. In order to overcome the challenge above, Multi-Modal Anchor Adaptation Learning for Multi-Modal Summarization (MA-Sum) has been proposed. Specifically, MA-Sum employs a novel and highly efficient image anchor selection method, which selects the object sample containing the richest image information as the image anchor. Simultaneously, it carefully selects the text sentence closely intertwined with the image semantics to serve as the language anchor. Therefore, the multi-modal anchor can be seen as a bridge for multi-modal alignment to alleviate the semantic gap between textual and visual. Moreover, based on the distance between the anchors and the semantic information in the respective modal, the positive and negative semantic information of each modal will be distinguished. Based on negative semantic information, the counterfactual learning mechanism is constructed to optimize the result of multi-modal summarization. Finally, the process of multi-modal features interaction is optimized by image summary which is chosen by using multi-modal anchors. According to the experimental results, compared with the state-of-art multi-modal summarization, our proposed MA-Sum can be optimized in terms of summarization consistency and completeness, so as to obtain the optimal multi-modal summarization metric.},
  archive      = {J_NEUCOM},
  author       = {Zhongfeng Chen and Zhenyu Lu and Huan Rong and Chuanjun Zhao and Fan Xu},
  doi          = {10.1016/j.neucom.2023.127144},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127144},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal anchor adaptation learning for multi-modal summarization},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Soft hybrid knowledge distillation against deep neural
networks. <em>NEUCOM</em>, <em>570</em>, 127142. (<a
href="https://doi.org/10.1016/j.neucom.2023.127142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional knowledge distillation approaches are typically designed for specific tasks, as they primarily distilling deep features from intermediate layers of a neural network , generally with ingeniously designed knowledge representations, which increase the difficulty of model development and interpretation. In contrast, we empirically show that a soft logits knowledge distillation is enough to significantly narrow the teacher–student model performance gap. In this paper, the S oft H ybrid K nowledge D istillation (SHKD) is proposed to generate representative features from the input and output location of models, and applicable to various teacher and student architectures. Specifically, the additional mixup task is first applied to the same batch of training images, which enriches the high-order feature information transferred by the model. And then, a top-k guided specification filter is added to the teacher model, to reduce the bias induced throughout the knowledge transfer process. Finally, the SHKD utilizes the same and different teacher–student model pairs of the deep neural network , which can be easily adjusted to the computational resources available in the current world. Extensive experiments are conducted to examine the efficiency, and show that the SHKD outperforms state-of-the-art knowledge distillation methods. With the SHKD, the high performance of models will be maintained, and the gap between the teacher model and the student model can be reduced, making the construction of deep neural networks more convenient to the unknown scenarios. The source code is available at https://github.com/lambett/SHKD .},
  archive      = {J_NEUCOM},
  author       = {Jian Zhang and Ze Tao and Shichao Zhang and Zike Qiao and Kehua Guo},
  doi          = {10.1016/j.neucom.2023.127142},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127142},
  shortjournal = {Neurocomputing},
  title        = {Soft hybrid knowledge distillation against deep neural networks},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Covariance intersection based event-triggered distributed
state estimation under channel independent DoS attacks. <em>NEUCOM</em>,
<em>570</em>, 127139. (<a
href="https://doi.org/10.1016/j.neucom.2023.127139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the event-triggered distributed state estimation problem for a class of discrete time-varying systems in the presence of denial-of-service (DoS) attacks, where each sensor node selectively shares its local information with neighbors. In contrast to the previous studies where the DoS attacks are considered on sensor-to-filter channels, we deal with the situation that DoS attacks jam each filter-to-filter communication channel independently. To reduce the communication rate and save network resources, a novel event-triggered communication strategy is presented that takes into account the impact of DoS attacks and is specialized for each communication channel. Based on the covariance intersection fusion rule and weight rearrangement method, a distributed state estimation algorithm is proposed. Further, the consistency of estimates and mean-square boundedness of estimation errors are proved under system collective observability and some other mild assumptions. Lastly, a numerical simulation is conducted to demonstrate the developed results and the effectiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Yanyan Hu and Xuechun Zhang and Xufeng Lin},
  doi          = {10.1016/j.neucom.2023.127139},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127139},
  shortjournal = {Neurocomputing},
  title        = {Covariance intersection based event-triggered distributed state estimation under channel independent DoS attacks},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An incremental feature selection approach for dynamic
feature variation. <em>NEUCOM</em>, <em>570</em>, 127138. (<a
href="https://doi.org/10.1016/j.neucom.2023.127138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In numerous domains, there is ample evidence indicating that a significant portion of real-world data exhibits temporal variations, such as medical research and meteorological studies. Particularly in the era of big data, not only does the size of data change dynamically but also its dimensions at an unprecedented pace. Consequently, employing traditional methods to handle such dynamic data becomes highly impractical. To address this limitation, this paper proposes an incremental feature selection algorithm tailored for dynamic feature variations. For scenarios involving an increase in features, the novel algorithm efficiently identifies a target subset with effective features. In order to showcase the efficacy of the proposed algorithm, this paper conduct experiments using four commonly used classifiers and five UCI data sets. The experimental results further validate both the feasibility and efficiency of the new approach.},
  archive      = {J_NEUCOM},
  author       = {Feng Wang and Xinhao Wang and Wei Wei and Jiye Liang},
  doi          = {10.1016/j.neucom.2023.127138},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127138},
  shortjournal = {Neurocomputing},
  title        = {An incremental feature selection approach for dynamic feature variation},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis of tabular data based on graph neural network using
supervised contrastive loss. <em>NEUCOM</em>, <em>570</em>, 127137. (<a
href="https://doi.org/10.1016/j.neucom.2023.127137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many applications in the industry, tabular data are the most commonly used data type . Tabular data have the advantage of being easy to understand and interpret. Machine learning algorithms are mainly used to deduce a mapping function that maps input data to output in tabular data. Machine learning methods for dealing with tabular data are classified into two categories: similarity-based approach and feature-based approach. The feature-based approach explores a mapping function by clarifying the relationships between features, while the similarity-based approach uses similarities of observations to explore a mapping function. Both aspects have their pros and cons. Feature-based models are easy to understand and intuitive to use and deploy but generally cannot utilize the relationships between observations. Similarity-based models are most suited for exploiting the relationships among observations, but their availability is usually limited. In order to take advantage of both aspects, we propose an algorithm to combine feature-based and similarity-based approaches using a graph neural network . Additionally, to complement the shortcomings of cross-entropy loss, the proposed method applies supervised contrastive learning . Through supervised contrastive learning, the proposed method boosts the efficiency of learning the generalized representation for each class. Experimental results show that the proposed method provides more precise results for classification tasks , implying that it may improve the generalization capability.},
  archive      = {J_NEUCOM},
  author       = {Seungyeon Lee and Minyoung Park and Younggeun Ahn and Gyeong Bok Jung and Dohyun Kim},
  doi          = {10.1016/j.neucom.2023.127137},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127137},
  shortjournal = {Neurocomputing},
  title        = {Analysis of tabular data based on graph neural network using supervised contrastive loss},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed nash equilibrium searching for multi-agent games
under false data injection attacks. <em>NEUCOM</em>, <em>570</em>,
127134. (<a href="https://doi.org/10.1016/j.neucom.2023.127134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, for the multi-agent system, the Nash equilibrium (NE) search problem for non-cooperative game with state constraints under false data injection (FDI) attack is studied. The FDI attack can directly destroy the connectivity between agents, resulting in the performance degradation or even failure for most NE search algorithms. We propose a new distributed NE search method to improve the performance of NE algorithms under FDI attacks. The NE algorithm is designed to find the solution of NE under network attack and make the system recover after the attack. However, most of the existing results only studied the NE algorithm of the non-attacking system, and the existing results rarely take into account whether the system state exceeds the safety limit, which can cause the system to crash. This paper solves the state constraints problem of the multi-agent game under the FDI attack. Finally, the reliability of the algorithm is verified by a numerical result.},
  archive      = {J_NEUCOM},
  author       = {Yixuan Lv and Yan-Jun Liu and Lei Liu and Dengxiu Yu and Yang Chen},
  doi          = {10.1016/j.neucom.2023.127134},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127134},
  shortjournal = {Neurocomputing},
  title        = {Distributed nash equilibrium searching for multi-agent games under false data injection attacks},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Theoretical analysis of co-existing periodic orbits in
sparse binary neural networks. <em>NEUCOM</em>, <em>570</em>, 127131.
(<a href="https://doi.org/10.1016/j.neucom.2023.127131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A sparse binary neural network is a discrete-time recurrent neural network characterized by local binary connections and signum-type neuron models. The dynamics is described by an autonomous difference equation of binary state variables. Depending on the parameters, the network generates various periodic orbits of binary vectors. Multiple periodic orbits can co-exist and the network exhibits one of them depending on initial condition. Real/potential applications of the periodic orbits include control signals of switching circuits and basic signals for time-series approximation . The network is well suited for theoretical analysis and simple hardware implementation. This paper considers shift-type periodic orbits in the networks. As the main theoretical results, we clarify the number, period, and stability of the periodic orbits for key parameters. As a first step to the applications in the future, we present an FPGA-based hardware prototype and confirm typical periodic orbits experimentally.},
  archive      = {J_NEUCOM},
  author       = {Toshimichi Saito and Hiroki Nonaka and Taiji Okano},
  doi          = {10.1016/j.neucom.2023.127131},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127131},
  shortjournal = {Neurocomputing},
  title        = {Theoretical analysis of co-existing periodic orbits in sparse binary neural networks},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convergence speed of dynamic consensus with delay
compensation. <em>NEUCOM</em>, <em>570</em>, 127130. (<a
href="https://doi.org/10.1016/j.neucom.2023.127130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A well-known drawback in distributed average consensus of multi-agent systems is that the exchanged information is usually delayed due to the time elapsed during the data transmission process. Using classical dynamic average consensus, delays may lead to poor performance or even instability. In this paper, we propose a novel dynamic consensus method that counteracts the negative effects of delays by means of delay compensation techniques. The interest of our dynamic consensus method with delay compensation is that it converges under mild conditions on graph connectivity and bounded reference signals, no matter how large the delays are, as long as delays are fixed and known. We also provide a formal characterization of the convergence speed of our method. Additionally, our results apply to fixed directed strongly connected, and undirected topologies.},
  archive      = {J_NEUCOM},
  author       = {Rosario Aragues and Antonio González and Gonzalo López–Nicolás and Carlos Sagues},
  doi          = {10.1016/j.neucom.2023.127130},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127130},
  shortjournal = {Neurocomputing},
  title        = {Convergence speed of dynamic consensus with delay compensation},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A critical analysis of image-based camera pose estimation
techniques. <em>NEUCOM</em>, <em>570</em>, 127125. (<a
href="https://doi.org/10.1016/j.neucom.2023.127125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camera, and associated with its objects within the field of view, localization could benefit many computer vision fields, such as autonomous driving , robot navigation , and augmented reality (AR). After decades of progress, camera localization, also called camera pose estimation could compute the 6DoF pose of objects for a camera in a given image, with respect to different images in a sequence or formats. Structure feature-based localization methods have achieved great success when integrated with image matching or with a coordinate regression stage. Absolute and relative pose regression methods using transfer learning can support end-to-end localization to directly regress a camera pose but achieve a less accurate performance. Despite the rapid development of multiple branches in this area, a comprehensive, in-depth and comparative analysis is lacking to summarize, classify and compare, structure feature-based and regression-based camera localization methods. Existing surveys either focus on larger SLAM (Simultaneous Localization and Mapping) systems or on only part of the camera localization method, lack detailed comparisons and descriptions of the methods or datasets used, neural network designs such as loss designs, and input formats, etc. In this survey, we first introduce specific application areas and the evaluation metrics for camera localization pose according to different sub-tasks (learning-based 2D-2D task, 2D-3D task, and 3D-3D task). Then, we review common methods for structure feature-based camera pose estimation approaches, absolute pose regression and relative pose regression approaches by critically modelling the methods to inspire further improvements in their algorithms such as loss functions, and neural network structures . Furthermore, we summarize what are the popular datasets used for camera localization and compare the quantitative and qualitative results of these methods with detailed performance metrics. Finally, we discuss future research possibilities and applications.},
  archive      = {J_NEUCOM},
  author       = {Meng Xu and Youchen Wang and Bin Xu and Jun Zhang and Jian Ren and Zhao Huang and Stefan Poslad and Pengfei Xu},
  doi          = {10.1016/j.neucom.2023.127125},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127125},
  shortjournal = {Neurocomputing},
  title        = {A critical analysis of image-based camera pose estimation techniques},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal energy allocation based on SINR under DoS attack.
<em>NEUCOM</em>, <em>570</em>, 127116. (<a
href="https://doi.org/10.1016/j.neucom.2023.127116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to signal to interference plus noise ratio (SINR) of channel, we consider optimal attack schedule against remote state estimation in cyber–physical systems (CPSs) under denial of service (DoS) attack. Each physical process has a smart sensor that acquires the measurement of the system and transmits its local state estimation to the remote estimation terminal through a wireless channel. At each time step, a DoS attacker can send a jamming attack to one of the two channels. On the side of the attacker, this paper aims to search an optimal strategy , which maximizes the estimation error of the remote estimator. We propose an algorithm to obtain the optimal attack schedule policy by using of Markov decision process (MDP). A numerical example is provided to demonstrate the effectiveness of the proposed methods.},
  archive      = {J_NEUCOM},
  author       = {Suzhen Zhang and Lianghong Peng and Xiaoyan Chang},
  doi          = {10.1016/j.neucom.2023.127116},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127116},
  shortjournal = {Neurocomputing},
  title        = {Optimal energy allocation based on SINR under DoS attack},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Language relatedness evaluation for multilingual neural
machine translation. <em>NEUCOM</em>, <em>570</em>, 127115. (<a
href="https://doi.org/10.1016/j.neucom.2023.127115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilingual neural machine translation (MNMT) has attracted more and more attention in recent days because it can use a single neural machine translation (NMT) model to translate between multiple languages. As several languages are involved in MNMT, recent studies have shown that using part of these languages rather than all of them to train the model leads to comparable results. However, previous work on this topic mainly focuses on language clustering and features defined by linguists. The semantic relationship and language distance are not fully considered. How to select the most related language pairs to current low-resource pair to optimize the performance of MNMT is still an open question. In this paper, we propose to take language relatedness computation as a ranking problem, where features such as language distance, linguistic typological information and semantic relatedness features are incorporated into a random decision forest to improve the language relatedness evaluation (LRE) for MNMT. Since the model only focuses on monolingual LRE in general cross-lingual natural language processing tasks , we also propose two features related to machine translation (data size and bilingual relatedness) to predict the final language pairs. Experimental results on IWSLT and WMT datasets show that our proposed LRE method can achieve significant improvements compared with other models. We also conducted several groups of experiments on IWSLT and WMT datasets to further evaluate the effectiveness of the proposed method on MNMT. The results show that the MNMT model trained on language pairs predicted by the LRE method outperforms other language selection methods.},
  archive      = {J_NEUCOM},
  author       = {Chenggang Mi and Shaoliang Xie},
  doi          = {10.1016/j.neucom.2023.127115},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127115},
  shortjournal = {Neurocomputing},
  title        = {Language relatedness evaluation for multilingual neural machine translation},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Supervised adaptive similarity consistent latent
representation hashing. <em>NEUCOM</em>, <em>570</em>, 127113. (<a
href="https://doi.org/10.1016/j.neucom.2023.127113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal hashing has attracted significant attention in multimedia data similarity given its appealing computational cost and retrieval performance . Supervised hashing benefits from the auxiliary learning of a similarity matrix , which is usually predefined by inner product features or category labels. However, a predefined similarity matrix fails to reflect the real similarity relationship between image-text pairs. In addition, existing methods fix the weights to a value or update them by introducing sensitive dataset-related hyper-parameters. To overcome these problems, we propose a method to perform supervised adaptive similarity consistent latent representation hashing (SCLRH) that adaptively learns the similarity matrix during hashing learning. In SCLRH, we assume that multimodal data are observed and reconstructed from different perspectives of a common consistent latent representation. Instead of using a predefined similarity matrix, SCLRH adaptively learns this matrix to reflect the underlying manifold structure and describes the fine-grained similarity between consistent latent representations. In addition, SCLRH introduces a self-weighted learning strategy to update the weights based on the contributions of different modalities without involving additional hyper-parameters. Experimental results on three benchmark datasets demonstrate the superiority of the proposed SCLRH for cross-modal retrieval.},
  archive      = {J_NEUCOM},
  author       = {Hongbin Wang and Rui Chen and Zhenqiu Shu and Yafei Zhang and Huafeng Li},
  doi          = {10.1016/j.neucom.2023.127113},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127113},
  shortjournal = {Neurocomputing},
  title        = {Supervised adaptive similarity consistent latent representation hashing},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-stage GNN-based fraud detection with camouflage
identification and enhanced semantics aggregation. <em>NEUCOM</em>,
<em>570</em>, 127108. (<a
href="https://doi.org/10.1016/j.neucom.2023.127108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural network (GNN) has got lots of attention recently in the fraud detection task due to its message-passing mechanism, which can aggregate neighbors feature in the information network. While promising, currently most GNN-based fraud detectors fail to identify camouflage caused by fraud with graph structure information and embed entity in deep layer with rich semantics effectively. To solve these problems, we propose a two-stage GNN-based approach with camouflage identification and enhanced semantics aggregation (CIES-GNN) for fraud detection. In the proposed approach, camouflage is identified by reconstructing subgraphs with both node feature and structure information. Detailedly, hidden edges between fraudsters are found by reconstructing a dense subgraph of fraudster nodes, and redundant connections between benign nodes and fraudster nodes are eliminated by reconstructing subgraphs in a label-balance distribution. Moreover, to embed entity in deep layer without semantics obfuscation, the node information is embedded in an enhanced semantics aggregation module, which fuses higher-order information in intra-relation and aggregates semantics in inter-relation respectively. Experiments on two real-world datasets demonstrate that the proposed CIES-GNN outperforms state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Jun Zhang and Jianguang Lu and Xianghong Tang},
  doi          = {10.1016/j.neucom.2023.127108},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127108},
  shortjournal = {Neurocomputing},
  title        = {Two-stage GNN-based fraud detection with camouflage identification and enhanced semantics aggregation},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Addressing posterior collapse by splitting decoders in
variational recurrent autoencoders. <em>NEUCOM</em>, <em>570</em>,
127103. (<a href="https://doi.org/10.1016/j.neucom.2023.127103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational recurrent autoencoder model (VRAE) is an appealing technique for capturing the variabilities underlying complex sequential data, which is realized by introducing high-level latent random variables as hidden states. Existing models suffer from the well-known ‘posterior collapse’ problem, meaning that a powerful autoregressive decoder equipped in the model itself could capture all the variabilities and hence leave the latent variables learning nothing from the data. From the perspective of model training, the posterior collapse problem can result in a very low Kullback–Leibler divergence (KL-divergence) value, which means the posteriors of the latent variables tend to be just the priors. In this paper, we address this problem by proposing a Bayesian variational recurrent neural network (BVRNN) model, in which two additional decoders are added into the original VRAE. These extra decoders can force the latent variables to learn meaningful knowledge during the training process. We conduct experiments on MNIST and Fashion-MNIST dataset. The experimental results show that the proposed model outperforms several baseline models . We further adapt the proposed model to a very challenging task in natural language processing , namely Named-Entity Recognition (NER). Experimental results show that our model is competitive to the state-of-the-art models on NER.},
  archive      = {J_NEUCOM},
  author       = {Jianyong Sun and Fan Song and Qiaohong Li},
  doi          = {10.1016/j.neucom.2023.127103},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127103},
  shortjournal = {Neurocomputing},
  title        = {Addressing posterior collapse by splitting decoders in variational recurrent autoencoders},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Side-constrained graph fusion for semi-supervised multi-view
clustering. <em>NEUCOM</em>, <em>570</em>, 127102. (<a
href="https://doi.org/10.1016/j.neucom.2023.127102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In these years, semi-supervised learning arouses ongoing attentions due to its appealing avail and economic expenditure of guiding model training. Semi-supervised multi-view clustering takes advantages of heterogeneous features and a small number of side constraints (i.e., must-link constraints and cannot-link constraints) to partition data points. However, most of existing approaches are very limited in absorbing available side constraints since it is difficult to optimize cannot-link constraints in a provable way, and thus greatly waste the value of prior information. To address it, we innovatively pose a side-constrained multi-view graph clustering method, where the pairwise constraints are flexibly incorporated into the multiple graph fusion framework. The technique definitely formulates the pairwise constraints in the graph clustering model by designing a semi-supervised graph regularization term . In this way, the structured optimal graph that satisfies multiple perspectives and specified pairwise relations is obtained. By virtue of graph fusion, the self-adaptive weight of each single-view is optimally determined without partiality. We demonstrate theoretical feasibility of the proposed method. Extensive experimental results in four multi-view data sets witness our superiority compared to the state-of-the-art approaches.},
  archive      = {J_NEUCOM},
  author       = {Han Zhang and Maoguo Gong and Yannian Gu and Feiping Nie and Xuelong Li},
  doi          = {10.1016/j.neucom.2023.127102},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127102},
  shortjournal = {Neurocomputing},
  title        = {Side-constrained graph fusion for semi-supervised multi-view clustering},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-level graph contrastive learning. <em>NEUCOM</em>,
<em>570</em>, 127101. (<a
href="https://doi.org/10.1016/j.neucom.2023.127101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation learning has attracted a surge of interest recently, which targets learning discriminant representation for each node in the graph. Most of these representation methods focus on supervised learning and heavily depend on label information. However, annotating graphs are expensive in the real-world, especially in specialized domains (i.e. biology), as it requires the annotators with the domain knowledge to label the graph. To approach this problem, self-supervised learning provides a feasible solution for graph representation learning. In this paper, we propose a Multi-Level Graph Contrastive Learning (MLGCL) framework for learning robust representation of graph data by contrasting space views of graphs. Specifically, we introduce a novel contrastive view — space view. The original graph is a first-order approximation structure in the topological space where nodes are linked by feature similarity, relationship, etc. While the k k -nearest neighbor ( k k NN) graph with community structure generated by encoding features preserves high-order proximity in feature space, it not only provides a complementary graph to the original graph from the feature space view but also is suitable for GNNs encoder. Furthermore, we develop a multi-level contrastive mode to preserve the local similarity and semantic similarity of graph-structured data simultaneously. Extensive experiments indicate MLGCL achieves promising results compared with the existing state-of-the-art graph representation learning methods on seven node classification datasets and three graph classification datasets.},
  archive      = {J_NEUCOM},
  author       = {Pengpeng Shao and Jianhua Tao},
  doi          = {10.1016/j.neucom.2023.127101},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127101},
  shortjournal = {Neurocomputing},
  title        = {Multi-level graph contrastive learning},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Input-to-state stability of stochastic complex networks
based on aperiodically intermittent sampled control. <em>NEUCOM</em>,
<em>570</em>, 127100. (<a
href="https://doi.org/10.1016/j.neucom.2023.127100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of input-to-state stability (ISS) of stochastic complex networks (SCNs). In this paper, an aperiodically intermittent control strategy based on sampled control is designed. By means of graph theory and Lyapunov method, two stability criteria on ISS are derived in this paper. After giving the estimate between E ∑ i = 1 m | x i ( t ) − x i ( δ ( t ) ) | 2 and E ∑ i = 1 m | x i ( t ) | 2 , a stability criterion is proposed on ISS of the SCN under aperiodically intermittent sampled control (AISC). When AISC degenerates into sampled control, another stability criterion on ISS of SCN is acquired. Finally, a numerical example is utilized to illustrate the effectiveness and feasibility of the proposed results.},
  archive      = {J_NEUCOM},
  author       = {Tianrui Chen and Jiacai Chen},
  doi          = {10.1016/j.neucom.2023.127100},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127100},
  shortjournal = {Neurocomputing},
  title        = {Input-to-state stability of stochastic complex networks based on aperiodically intermittent sampled control},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved generative adversarial network with deep metric
learning for missing data imputation. <em>NEUCOM</em>, <em>570</em>,
127062. (<a href="https://doi.org/10.1016/j.neucom.2023.127062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete data are ubiquitous in real-world computer vision tasks . Imputing missing data is crucial for modeling machine learning algorithms . Although existing methods, such as MisGAN, have achieved considerable success, two problems remain: (1) generating a complete image from random noise weakens the model’s imputation capability; (2) owing to the influence of random noise, the training of the generator is unstable. Therefore, this study proposes a novel approach that uses deep metric learning to enable MisGAN to perform multi-tasking missing data imputation. First, an image feature extraction network is applied to extract the semantic representation of the images. Then, deep metric learning is performed to learn good features embedding by maximizing inter-class variation and minimizing intra-class variation. Such an embedding replaces the random noise and is fed into MisGAN to obtain an improved generated complete image. Several experiments are conducted on datasets, demonstrating that the proposed method can significantly outperform baseline methods .},
  archive      = {J_NEUCOM},
  author       = {Mohammed Ali Al-taezi and Yu Wang and Pengfei Zhu and Qinghua Hu and Abdulrahman Al-badwi},
  doi          = {10.1016/j.neucom.2023.127062},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127062},
  shortjournal = {Neurocomputing},
  title        = {Improved generative adversarial network with deep metric learning for missing data imputation},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lightweight spiking neural network training based on spike
timing dependent backpropagation. <em>NEUCOM</em>, <em>570</em>, 127059.
(<a href="https://doi.org/10.1016/j.neucom.2023.127059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks are energy efficient and biological interpretability , communicating through sparse, asynchronous spikes, which makes them suitable for neuromorphic hardware. However, due to the nature of binary weights and spike trains in time-coded binarized spiking neural networks , their forward propagation may cause neurons to not fire spikes, and their backward propagation has non-differentiable problems. Moreover, the current use of deep and complex network structures generates a large number of redundant parameters. Therefore, we need effective methods to improve energy efficiency without reducing accuracy. We propose a dynamic threshold model that can reduce the number of dead neurons. We combine the backpropagation algorithm and the spike timing dependent plasticity algorithm to avoid the non-differentiable problem. We propose a neuron pruning strategy based on adaptive firing time threshold. This pruning strategy prunes 267 neurons in a network of 600 neurons, reducing the network size and obtaining a more compact network structure. The energy efficiency is improved by 0.55 × × , while the classification accuracy is lost by 1.1%.},
  archive      = {J_NEUCOM},
  author       = {Yu Gong and Tao Chen and Shu Wang and Shukai Duan and Lidan Wang},
  doi          = {10.1016/j.neucom.2023.127059},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127059},
  shortjournal = {Neurocomputing},
  title        = {Lightweight spiking neural network training based on spike timing dependent backpropagation},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exponential synchronization of uncertain chaotic inertial
neural networks by guaranteed cost intermittent control.
<em>NEUCOM</em>, <em>570</em>, 127049. (<a
href="https://doi.org/10.1016/j.neucom.2023.127049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper utilizes the guaranteed cost intermittent control to achieve exponential synchronization of uncertain chaotic inertial neural networks (UCINNs). Concretely, the second-order UCINNs are first transformed into the first-order neural network form by variable substitution. Then, under the new guaranteed cost intermittent lemma, the Lyapunov stability theory, as well as the designed intermittent controller, sufficient conditions in the form of linear matrix inequalities (LMIs) are derived to ensure exponential synchronization of UCINNs. Moreover, the optimal control gain and the upper bound of the cost function are obtained by introducing auxiliary variables. Lastly, numerical simulation confirms the viability and effectiveness of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Zeyu Ruan and Jun Mei and Yan Li and Shukai Duan and Lidan Wang},
  doi          = {10.1016/j.neucom.2023.127049},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127049},
  shortjournal = {Neurocomputing},
  title        = {Exponential synchronization of uncertain chaotic inertial neural networks by guaranteed cost intermittent control},
  volume       = {570},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning for hybrid disassembly line balancing
problems. <em>NEUCOM</em>, <em>569</em>, 127145. (<a
href="https://doi.org/10.1016/j.neucom.2023.127145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the economy and technology, the rate of product replacement has accelerated, resulting in a large number of products being discarded. Disassembly is an important way to recycle waste products, which is also helpful to reduce manufacturing costs and environmental pollution. The combination of a single-row linear disassembly line and a U-shaped disassembly line presents distinctive advantages within various application scenarios. The Hybrid Disassembly Line Balancing Problem (HDLBP) that considers the requirement of multi-skilled workers is addressed in this paper. A mathematical model is established to maximize the recovery profit according to the characteristics of the proposed problem. To facilitate the search for optimal solution, a new strategy for agents in reinforcement learning to interact with complex and changeable environments in real-time is developed, and deep reinforcement learning is used to complete the distribution of multi-products and disassembly tasks. On this basis, we propose a Soft Actor–Critic (SAC) algorithm to effectively address this problem. Compared with the Deep Deterministic Policy Gradient (DDPG) algorithm, Advantage Actor–Critic (A2C) algorithm, and Proximal Policy Optimization (PPO) algorithm, the results show that the SAC can get the approximate optimal result on small-scale cases. The performance of SAC is also better than DDPG, PPO , and A2C in solving large-scale disassembly cases.},
  archive      = {J_NEUCOM},
  author       = {Jiacun Wang and GuiPeng Xi and XiWang Guo and Shixin Liu and ShuJin Qin and Henry Han},
  doi          = {10.1016/j.neucom.2023.127145},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127145},
  shortjournal = {Neurocomputing},
  title        = {Reinforcement learning for hybrid disassembly line balancing problems},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-free distributed integral sliding mode predictive
control for multi-agent systems with communication delay.
<em>NEUCOM</em>, <em>569</em>, 127133. (<a
href="https://doi.org/10.1016/j.neucom.2023.127133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the problem of distributed cooperative tracking control for networked nonlinear multi-agent systems (MASs) with communication delays. The difficulty of distributed control of subsystems across several geographic areas is addressed by utilizing MASs in this study. To overcome modeling difficulties, a model-free control algorithm is employed. To handle networked delay, a network predictive control approach is utilized. To address these issues in a unified manner, a novel distributed model-free integral sliding mode predictive control strategy is proposed. This approach requires simple data to make predictions to achieve distributed tracking performance while also actively compensating for delays. The effectiveness of the proposed method is demonstrated through simulations and experimental results.},
  archive      = {J_NEUCOM},
  author       = {Ji Zhang and Guoping Liu},
  doi          = {10.1016/j.neucom.2023.127133},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127133},
  shortjournal = {Neurocomputing},
  title        = {Model-free distributed integral sliding mode predictive control for multi-agent systems with communication delay},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fully distributed consensus of linear multi-agent systems
via dynamic event-triggered control. <em>NEUCOM</em>, <em>569</em>,
127129. (<a href="https://doi.org/10.1016/j.neucom.2023.127129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the fully distributed consensus control problem for general linear multi-agent systems via dynamic event-triggered scheme. To address the need to reduce network communication burdens and avoid involving any global features of multi-agent networks, a novel fully distributed controller based on the open-loop state estimator of agents is presented. To improve anti-interference ability and practicability of the proposed approach, an event-triggered strategy which can guarantee a precise lower bound of triggering intervals for each follower is designed with a virtual internal variable. Then, the stability of the multi-agent systems is analyzed without any global network information. Several simulation experiments are conducted to illustrate theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Tongtong Chen and Fuyong Wang and Meiling Feng and Chengyi Xia and Zengqiang Chen},
  doi          = {10.1016/j.neucom.2023.127129},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127129},
  shortjournal = {Neurocomputing},
  title        = {Fully distributed consensus of linear multi-agent systems via dynamic event-triggered control},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Zero-shot multitask intent and emotion prediction from
multimodal data: A benchmark study. <em>NEUCOM</em>, <em>569</em>,
127128. (<a href="https://doi.org/10.1016/j.neucom.2023.127128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Empathy involves comprehending and sharing the emotions of another person. In the realm of conversational AI , empathy pertains to the AI’s capacity to understand and respond suitably to the user’s emotions and needs. Conversational AI with empathetic capabilities can heighten the user experience by making interactions more personalized and natural. At present, machine learning algorithms are commonly utilized in existing conversational AI systems to recognize emotions and corresponding empathetic intents from annotated data. Nonetheless, this approach is not without limitations, being expensive and time-consuming. Our present work takes a holistic approach to empathy in conversational AI, where we propose a novel zero-shot multitask framework, the Zero-shot Intent Emotion Detection (ZIED) network, identifies both emotions and intents in a multimodal setting. We developed an end-to-end model that concurrently captures textual, audio, and visual representations and integrates the different modalities using cross-attention mechanisms. Our experimental results, based on the EmoInt-MD dataset, show that incorporating all three modalities results in the best performance for both emotion and empathetic intent detection. We observed a noteworthy improvement of over 6% and 4% for intent and emotion, respectively, for various ratios of seen and unseen classes.},
  archive      = {J_NEUCOM},
  author       = {Gopendra Vikram Singh and Mauajama Firdaus and Dushyant Singh Chauhan and Asif Ekbal and Pushpak Bhattacharyya},
  doi          = {10.1016/j.neucom.2023.127128},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127128},
  shortjournal = {Neurocomputing},
  title        = {Zero-shot multitask intent and emotion prediction from multimodal data: A benchmark study},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FedBoosting: Federated learning with gradient protected
boosting for text recognition. <em>NEUCOM</em>, <em>569</em>, 127126.
(<a href="https://doi.org/10.1016/j.neucom.2023.127126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional machine learning methodologies require the centralization of data for model training, which may be infeasible in situations where data sharing limitations are imposed due to concerns such as privacy and gradient protection. The Federated Learning (FL) framework enables the collaborative learning of a shared model without necessitating the centralization or sharing of data among the data proprietors. Nonetheless, in this paper, we demonstrate that the generalization capability of the joint model is suboptimal for Non-Independent and Non-Identically Distributed (Non-IID) data, particularly when employing the Federated Averaging (FedAvg) strategy as a result of the weight divergence phenomenon. Consequently, we present a novel boosting algorithm for FL to address both the generalization and gradient leakage challenges, as well as to facilitate accelerated convergence in gradient-based optimization. Furthermore, we introduce a secure gradient sharing protocol that incorporates Homomorphic Encryption (HE) and Differential Privacy (DP) to safeguard against gradient leakage attacks. Our empirical evaluation demonstrates that the proposed Federated Boosting (FedBoosting) technique yields significant enhancements in both prediction accuracy and computational efficiency in the visual text recognition task on publicly available benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Hanchi Ren and Jingjing Deng and Xianghua Xie and Xiaoke Ma and Yichuan Wang},
  doi          = {10.1016/j.neucom.2023.127126},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127126},
  shortjournal = {Neurocomputing},
  title        = {FedBoosting: Federated learning with gradient protected boosting for text recognition},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel and efficient model pruning method for deep
convolutional neural networks by evaluating the direct and indirect
effects of filters. <em>NEUCOM</em>, <em>569</em>, 127124. (<a
href="https://doi.org/10.1016/j.neucom.2023.127124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deploying deep convolutional neural networks (DCNNs) on devices with low memory resources or in applications with strict latency requirements remains a challenge. The weight-based filter pruning is an effective technique that has been widely applied to DCNNs compression and acceleration due to its lighter computation consumption and better flexibility. However, many existing methods select the filter to be pruned by evaluating the direct effect of the filter on the current pruning layer, resulting in insufficient performance of the pruned model. In this paper, we point out that the key issue for the filter level pruning criteria to improve performance is how to evaluate the importance of filters and propose a new weight-based filter pruning method. The proposed method comprehensively considers the direct and indirect effects of filters, which can better reflect the filter importance, allowing the safe removal of unimportant filters. Extensive experiments demonstrate that the proposed weight-based method achieves a better performance than previous works, which are reaching the level of data-based methods.},
  archive      = {J_NEUCOM},
  author       = {Yongbin Zheng and Peng Sun and Qiang Ren and Wanying Xu and Di Zhu},
  doi          = {10.1016/j.neucom.2023.127124},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127124},
  shortjournal = {Neurocomputing},
  title        = {A novel and efficient model pruning method for deep convolutional neural networks by evaluating the direct and indirect effects of filters},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comparative optimization procedure to evaluate pattern
recognition algorithms on hannes prosthesis. <em>NEUCOM</em>,
<em>569</em>, 127123. (<a
href="https://doi.org/10.1016/j.neucom.2023.127123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stability and repeatability of Pattern Recognition (PR) myoelectric control for upper limb prosthetic devices remain unresolved challenges in multi-DoFs systems. In this study, we tested several state-of-the-art classifiers to compare their offline performance in different configurations. Parameters such as realization costs, overall encumbrance, and algorithm complexity were considered for the analysis. The results showed that NLR performed comparably to LDA but with fewer EMG sensors. This study demonstrated that sensor numbers can be reduced to a few units for various algorithms, with NLR being the most tolerant due to its non-linearity. In conclusion, NLR can effectively control the multi-DoFs Hannes system in real-time, offering similar performances to other algorithms while reducing the system&#39;s complexity and encumbrance as compared to LDA. It also offers improved tolerance to reduced available information and lower implementation costs.},
  archive      = {J_NEUCOM},
  author       = {A. Marinelli and M. Canepa and D. Di Domenico and E. Gruppioni and M. Laffranchi and L. De Michieli and M. Chiappalone and M. Semprini and N. Boccardo},
  doi          = {10.1016/j.neucom.2023.127123},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127123},
  shortjournal = {Neurocomputing},
  title        = {A comparative optimization procedure to evaluate pattern recognition algorithms on hannes prosthesis},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GlocalFuse-depth: Fusing transformers and CNNs for all-day
self-supervised monocular depth estimation. <em>NEUCOM</em>,
<em>569</em>, 127122. (<a
href="https://doi.org/10.1016/j.neucom.2023.127122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, self-supervised monocular depth estimation has drawn much attention since it frees of depth annotations and achieves remarkable results on standard benchmarks. However, most of existing methods only focus on either daytime or nighttime images , their performance degrades on the other domain because of the large gap between daytime and nighttime images. To address this problem, we propose a two-branch network named GlocalFuse-Depth for self-supervised depth estimation of all-day images in this paper. The daytime and nighttime images in input image pair are fed into the two branches: CNN branch and Transformer branch, respectively, where both local details and global dependency can be effectively captured. Besides, a novel fusion module is proposed to fuse multi-dimensional features from the two branches. Extensive experiments demonstrate that GlocalFuse-Depth achieves state-of-the-art results for all-day images of the Oxford RobotCar dataset, which proves the superiority of our method.},
  archive      = {J_NEUCOM},
  author       = {Zezheng Zhang and Ryan K.Y. Chan and Kenneth K.Y. Wong},
  doi          = {10.1016/j.neucom.2023.127122},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127122},
  shortjournal = {Neurocomputing},
  title        = {GlocalFuse-depth: Fusing transformers and CNNs for all-day self-supervised monocular depth estimation},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stabilized activation scale estimation for precise
post-training quantization. <em>NEUCOM</em>, <em>569</em>, 127120. (<a
href="https://doi.org/10.1016/j.neucom.2023.127120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there have been more and more studies on Post-Training Quantization (PTQ). Many outstanding works have emerged, which has greatly promoted the availability of PTQ methods. However, in terms of low-bit quantization, there is still a wide gap between PTQ and the current state-of-the-art Quantization-Aware Training (QAT) methods. In this work, we find that the current way of obtaining the activation scale is not completely reasonable in PTQ, which leads to the fact that the weight cannot be well adapted to the biased quantized activation during inference. Based on experiments and analysis, we propose a method called StablePTQ. It obtains a stable activation scale and mixes rich input into the block reconstruction to achieve an improving quantization accuracy. StablePTQ achieves remarkable improvements in several different bit quantization especially W2A4, and can be applied to other quantization algorithms as a plug-and-play approach. The source code of StablePTQ is avaiable at .},
  archive      = {J_NEUCOM},
  author       = {Zhenyang Hao and Xinggang Wang and Jiawei Liu and Zhihang Yuan and Dawei Yang and Wenyu Liu},
  doi          = {10.1016/j.neucom.2023.127120},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127120},
  shortjournal = {Neurocomputing},
  title        = {Stabilized activation scale estimation for precise post-training quantization},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consistency–exclusivity guided unsupervised multi-view
feature selection. <em>NEUCOM</em>, <em>569</em>, 127119. (<a
href="https://doi.org/10.1016/j.neucom.2023.127119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised multi-view feature selection (UMFS) is an effective dimension reduction for multi-view data. It aims to obtain the important feature subset from multi-view data, which can significantly minimize the impacts of noises, outliers and redundancy. Although previous UMFS methods achieve remarkable achievements, they fail to fully take into account the consistency or the exclusivity hidden in multi-view data. To address this, this article presents a consistency–exclusivity guided unsupervised multi-view feature selection (CE-UMFS) method. Specifically, we design a multi-view matrix factorization model to simultaneously explore the consistency and exclusivity in multi-view data. Meanwhile, we employ the Hilbert–Schmidt independence criterion (HSIC) to preserve the exclusivity of different views. Furthermore, we impose a nuclear norm on the consistent representation matrix to explore the consistency across views. At last, promising experimental results demonstrate the superiority of the proposed method compared with some state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Shixuan Zhou and Peng Song},
  doi          = {10.1016/j.neucom.2023.127119},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127119},
  shortjournal = {Neurocomputing},
  title        = {Consistency–exclusivity guided unsupervised multi-view feature selection},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DERGCN: Dynamic-evolving graph convolutional networks for
human trajectory prediction. <em>NEUCOM</em>, <em>569</em>, 127117. (<a
href="https://doi.org/10.1016/j.neucom.2023.127117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian trajectory prediction is an increasingly important research area in applied autonomous driving and social robotics. Effectively modeling the intricate interactions between pedestrians is paramount for improving trajectory prediction accuracy. However, when using Graph Neural Networks(GNNs) to model these interactions, fixed interactions tend to remain, preventing the graph model from making adaptive adjustments and thus resulting in significant discrepancies between the predicted and true trajectories. In this study, we propose a Dynamic-Evolving Relative Graph Convolutional Network(DERGCN) to predict the future trajectories of pedestrians. The network model captures the dynamically evolving pedestrian interactions and incorporates an evolving mechanism to simulate them. In addition, with a relative temporal encoding strategy employed to improve the dynamics of the graph further, our policy network yielded an improved predictive performance when tested on two challenging datasets.},
  archive      = {J_NEUCOM},
  author       = {Jing Mi and Xuxiu Zhang and Honghai Zeng and Lin Wang},
  doi          = {10.1016/j.neucom.2023.127117},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127117},
  shortjournal = {Neurocomputing},
  title        = {DERGCN: Dynamic-evolving graph convolutional networks for human trajectory prediction},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adv-4-adv: Thwarting changing adversarial perturbations via
adversarial domain adaptation. <em>NEUCOM</em>, <em>569</em>, 127114.
(<a href="https://doi.org/10.1016/j.neucom.2023.127114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whereas adversarial training can be useful against specific adversarial perturbations, they have also been proven ineffective in generalizing towards attacks deviating from those used for training. However, we observe that this ineffectiveness is intrinsically connected to domain adaptability , another crucial issue in deep learning for which adversarial domain adaptation appears to be a promising solution. Consequently, we propose Adv-4-Adv as a novel adversarial training method that aims to retain robustness against unseen adversarial perturbations. Essentially, Adv-4-Adv treats attacks incurring different perturbations as distinct domains, and by leveraging the power of adversarial domain adaptation, it aims to remove the domain/attack-specific features. This forces a trained model to learn a robust domain-invariant representation, which in turn enhances its generalizability . Extensive evaluations on Fashion-MNIST, SVHN, CIFAR-10, and CIFAR-100 demonstrate that a model trained by Adv-4-Adv based on examples crafted by simple attacks (e.g., FGSM) can be generalized to more advanced attacks (e.g., PGD), and the performance exceeds state-of-the-art proposals on these datasets.},
  archive      = {J_NEUCOM},
  author       = {Tianyue Zheng and Zhe Chen and Shuya Ding and Chao Cai and Jun Luo},
  doi          = {10.1016/j.neucom.2023.127114},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127114},
  shortjournal = {Neurocomputing},
  title        = {Adv-4-adv: Thwarting changing adversarial perturbations via adversarial domain adaptation},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical graph attention networks for multi-modal rumor
detection on social media. <em>NEUCOM</em>, <em>569</em>, 127112. (<a
href="https://doi.org/10.1016/j.neucom.2023.127112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wide spread of rumors across online microblogs has caused a series of adverse impacts on our daily lives. Traditional multi-modal rumor detection models ignore the investigation of deep fusion of different granularity within inter-modality and intra-modality, leading to the information loss and model inexplicability. In this paper, we propose a novel Hierarchical Graph Attention network based framework for Multi-Modal Rumor Detection (HGA-MMRD). More specifically, for a given multi-modal post, we first construct a fine-grained text-image graph which consists of three sub-graphs where the nodes include four types of information (e.g., words, entities, objects from images, and image patches), while six types of edges are built to capture the different semantic interactions of the intra-modality and the inter-modality simultaneously. In order to fuse multi-modal information at different levels, we adopt a hierarchical graph attention network to model each sub-graph of the fine-grained text-image graph, and employ a global feature alignment module to fuse an entire image and a text. Our extensive experimental results and visualization demonstrate that our HGA-MMRD outperforms state-of-the-art methods on five benchmark datasets (i.e., two English datasets and three Chinese datasets) in rumor detection.},
  archive      = {J_NEUCOM},
  author       = {Fan Xu and Lei Zeng and Qi Huang and Keyu Yan and Mingwen Wang and Victor S. Sheng},
  doi          = {10.1016/j.neucom.2023.127112},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127112},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical graph attention networks for multi-modal rumor detection on social media},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A visible-infrared clothes-changing dataset for person
re-identification in natural scene. <em>NEUCOM</em>, <em>569</em>,
127110. (<a href="https://doi.org/10.1016/j.neucom.2023.127110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (Re-ID) has been widely used in intelligent surveillance systems, aiming at retrieving specific pedestrian images across different cameras. Although existing person Re-ID methods have achieved inspiring success, there are still limitations in practical monitoring system applications. To narrow the gap with the practical application, we introduce the cross-modality person Re-ID problem in the clothes-changing scene. Meanwhile, we construct the first Visible-Infrared Clothes-Changing (NEU-VICC) dataset, which contained 16632 RGB images and 8374 infrared images of 107 pedestrians. The critical challenge of the cross-modality person Re-ID problem in the clothes-changing scene lies in the vast modality discrepancy and the intra-class discrepancy caused by changing clothes. So, we propose a novel Semantic-Constraint Clothes-Changing Augmentation Network (SC 3 ANet) based on current cross-modality person Re-ID methods to solve this problem. Specifically, we design a semantic-constraint clothes-changing module that guides the model to learn clothes-irrelevant features by randomly changing pedestrians&#39; clothes. In addition, we devise a dual-granularity constraint loss module to mitigate inter-modality and intra-class differences. Experiments on our NEU-VICC dataset show that the SC 3 ANet achieves the best results. The dataset and code are available at: https://github.com/VDT-2048/NEU-VICC.},
  archive      = {J_NEUCOM},
  author       = {Xianbin Wei and Kechen Song and Wenkang Yang and Yunhui Yan and Qinggang Meng},
  doi          = {10.1016/j.neucom.2023.127110},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127110},
  shortjournal = {Neurocomputing},
  title        = {A visible-infrared clothes-changing dataset for person re-identification in natural scene},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-message passing framework based on heterogeneous
graphs in conversational emotion recognition. <em>NEUCOM</em>,
<em>569</em>, 127109. (<a
href="https://doi.org/10.1016/j.neucom.2023.127109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important development direction of natural language processing , emotion recognition in conversation (ERC) remains a challenge in sentiment analysis . Given the large-scale dialogue datasets and their wide application in the fields of recommendation systems and human–machine dialogue systems , researchers have begun to pay more attention to the issue of ERC. In recent research, the task of ERC has been largely based on the graph structure to model the speaker level. However, most existing studies simply splice multimodal features, and the heterogeneity of multimodal features tends to be overlooked. Hence, this paper proposes a multivariate messaging framework to embed heterogeneous information into multimodal relational graphs . In the process of aggregating graph node information, we take into account the homogeneity of nodes and assign different weights to different nodes so as to better aggregate semantic information. In order to improve the robustness of the model, we utilize the mechanism of sharing weights among neighbors to reduce the number of network parameters and improve the generalization ability of the model. In so doing, the node information is aggregated through the constructed graph network, and the final semantic vector representation is obtained. Experiments over two benchmark datasets for ERC show that our proposed model achieves improved performance in accuracy and F1 value.},
  archive      = {J_NEUCOM},
  author       = {Tao Meng and Yuntao Shou and Wei Ai and Jiayi Du and Haiyan Liu and Keqin Li},
  doi          = {10.1016/j.neucom.2023.127109},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127109},
  shortjournal = {Neurocomputing},
  title        = {A multi-message passing framework based on heterogeneous graphs in conversational emotion recognition},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Occlusion-robust FAU recognition by mining latent space of
masked autoencoders. <em>NEUCOM</em>, <em>569</em>, 127107. (<a
href="https://doi.org/10.1016/j.neucom.2023.127107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial action units (FAUs) are critical for fine-grained facial expression analysis. Although FAU detection has been actively studied using ideally high-quality facial images , it was not thoroughly studied under heavily occluded conditions. In this paper, we propose the first occlusion-robust FAU recognition method to maintain FAU detection performance under heavy occlusions. Our novel approach takes advantage of rich information from the latent space of masked autoencoder (MAE) and transforms it into FAU features. Bypassing the occlusion reconstruction step, our model efficiently extracts FAU features of occluded faces by mining the latent space of a pretrained masked autoencoder. Both node and edge-level knowledge distillation are also employed to guide our model to find a mapping between latent space vectors and FAU features. Facial occlusion conditions, including random small patches and large blocks, are thoroughly studied. Experimental results on BP4D and DISFA datasets show that our method can achieve state-of-the-art performances under the studied facial occlusion, significantly outperforming existing baseline methods . In particular, even under heavy occlusion, the proposed method can achieve comparable performance as state-of-the-art methods under normal conditions.},
  archive      = {J_NEUCOM},
  author       = {Minyang Jiang and Yongwei Wang and Martin J. McKeown and Z. Jane Wang},
  doi          = {10.1016/j.neucom.2023.127107},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127107},
  shortjournal = {Neurocomputing},
  title        = {Occlusion-robust FAU recognition by mining latent space of masked autoencoders},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep style transfer to deal with the domain shift problem on
spheroid segmentation. <em>NEUCOM</em>, <em>569</em>, 127105. (<a
href="https://doi.org/10.1016/j.neucom.2023.127105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spheroids are the most widely used 3D models for studying the effects of different micro-environmental characteristics on tumor behaviour , and for testing different preclinical and clinical treatments. Image analysis of spheroids is crucial to understand the formation and behaviour of such tumors, but when performed manually is a time-consuming task. Deep convolutional models can help in the analysis of spheroid images since they provide accurate results for the segmentation of tumors, a task that is necessary to further study features of spheroids. However, the images from tumor spheroids greatly vary depending on the experimental conditions, and also on the equipment (microscopes) and conditions (focus and magnification) employed to capture the images. This issue, known as domain shift, hinders the applicability of deep learning models for spheroid segmentation. In this work, we address this problem by studying style transfer methods based on both convolutional neural networks and generative adversarial networks to transfer the style from the images used for training segmentation models to the images from a new domain. This approach successfully handled the domain shift problem in the context of spheroid segmentation for 6 different deep learning models. Finally, we developed a high-level API that facilitates the of our approach to other contexts where the domain-shift problem might occur.},
  archive      = {J_NEUCOM},
  author       = {Manuel García-Domínguez and César Domínguez and Jónathan Heras and Eloy Mata and Vico Pascual},
  doi          = {10.1016/j.neucom.2023.127105},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127105},
  shortjournal = {Neurocomputing},
  title        = {Deep style transfer to deal with the domain shift problem on spheroid segmentation},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonlinear control of neurodegenerative diseases. A case
study on optical illusion networks disrupted by diabetic retinopathy.
<em>NEUCOM</em>, <em>569</em>, 127099. (<a
href="https://doi.org/10.1016/j.neucom.2023.127099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an efficient computational framework for the design of optimal drug delivery control strategies that can successfully treat a family of neurodegenerative diseases that originate from channelopathies and synaptopathies. To this end, we extend our previously introduced scalable and adaptable modelling framework that models heterogeneous Hodgkin–Huxley (HH) neuronal networks to account for the modular organisation of the neurons in the brain, e.g. interconnecting sub-networks of heterogeneous neurons. Based on this framework, we introduce a novel design of lateral inhibition networks to successfully reproduce 2D optical illusions that are known to occur in the human retina. We model the dynamic behaviour of Diabetic Retinopathy (DR), a neurodegenerative disease that progressively hinders the inherent ability of patients to distinguish optical illusions. We implement nonlinear control on accurate models of diabetic lateral inhibition neuronal networks to recover their functionality and investigate the effects of virtual drug administration. We utilise the healthy and diabetic optical illusions generated by these networks as a ‘computational’ phenotype to design therapies based on an adaptive terminal error iterative learning controller (TE-ILC). Therefore, we provide a comprehensive computational framework that is able to imitate the dynamics of healthy and diseased neuronal networks and we propose an adaptive nonlinear control strategy based on the error between output images that correspond to healthy and diseased conditions.},
  archive      = {J_NEUCOM},
  author       = {A.G. Giannari and A. Astolfi},
  doi          = {10.1016/j.neucom.2023.127099},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127099},
  shortjournal = {Neurocomputing},
  title        = {Nonlinear control of neurodegenerative diseases. a case study on optical illusion networks disrupted by diabetic retinopathy},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamically retrieving knowledge via query generation for
informative dialogue generation. <em>NEUCOM</em>, <em>569</em>, 127036.
(<a href="https://doi.org/10.1016/j.neucom.2023.127036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge-driven dialogue systems have recently made remarkable breakthroughs. Compared with general dialogue systems, superior knowledge-driven dialogue systems can generate more informative and knowledgeable responses with pre-provided knowledge. However, in practical applications, the knowledge-driven dialogue systems cannot be supplied with relevant knowledge beforehand. Hence, to enhance the practicality of the knowledge-driven dialogue systems, it is crucial to devise a method to dynamically retrieve pertinent knowledge based on the context. In addressing this challenge, we introduce a knowledge-driven dialogue system called DRKQG (Dynamically Retrieving Knowledge via Query Generation for informative dialogue response). Specifically, this system is composed of two main modules: a query generation module and a response generation module. Initially, a time-aware mechanism is employed to capture contextual information, enabling the generation of a query for knowledge retrieval through a search engine. Subsequently, we incorporate the copy mechanism and transformers, empowering the response generation module to create responses based on both the context and retrieved knowledge. Experimental results at LIC2022, Language and Intelligence Technology Competition, show that our module outperforms the baseline model by a large margin on automatic evaluation metrics , while human evaluation by the Baidu Linguistics team shows that our system achieves impressive results in Factually Correct and Knowledgeable.},
  archive      = {J_NEUCOM},
  author       = {Zhongtian Hu and Lifang Wang and Yangqi Chen and Yushuang Liu and Ronghan Li and Meng Zhao and Xinyu Lu and Zejun Jiang},
  doi          = {10.1016/j.neucom.2023.127036},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127036},
  shortjournal = {Neurocomputing},
  title        = {Dynamically retrieving knowledge via query generation for informative dialogue generation},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-DIANet: A sharing-learnable multi-task network based on
dense information aggregation. <em>NEUCOM</em>, <em>569</em>, 127035.
(<a href="https://doi.org/10.1016/j.neucom.2023.127035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing neural networks that balance shared features and task-specific ones is a major challenge in multi-task learning. To solve this issue, we aggregate information from both multi-scale and multi-level perspectives for a more comprehensive understanding of the multi-task features, which enables the network to learn a better sharing way. Specifically, we first introduce a basic Multi-scale-focused Dense Information Aggregation Network, where learnable fusion modules are used to connect two task-biased subnets and control the feature sharing. The fusion modules, consisting of densely cascaded dilated convolutions and scale-wise attention blocks, adaptively aggregate multi-scale information for each task. To further exploit multi-level information, the modules at different levels are mutually connected in a dense manner and guided by auxiliary supervision. By combining these two aspects of information aggregation, a Dual Dense Information Aggregation Network with a strong ability to learn appropriate sharing is finally proposed. Comprehensive experiments are reported on NYUDv2, SUN RGB-D, and Mini-Taskonomy to show the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Kejie Lyu and Yingming Li and Zhongfei Zhang},
  doi          = {10.1016/j.neucom.2023.127035},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127035},
  shortjournal = {Neurocomputing},
  title        = {Dual-DIANet: A sharing-learnable multi-task network based on dense information aggregation},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convolutional transformer network for fine-grained action
recognition. <em>NEUCOM</em>, <em>569</em>, 127027. (<a
href="https://doi.org/10.1016/j.neucom.2023.127027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained action recognition is one of the critical problems in video processing, which aims to recognize similar actions of subtle interactions between humans and objects. Inspired by the remarkable performance of the Transformer in natural language processing , Transformer has been applied to the fine-grained action recognition task. However, Transformer needs abundant training data and extra supervision to achieve comparable results with convolutional neural networks (CNNs). To address these issues, we propose a Convolutional Transformer Network (CTN), which integrates the merits of CNN ( e.g. , sharing weights, capturing low-level features in videos and locality) and the benefits of Transformer ( e.g ., dynamic attention and learning long-range dependencies). In this paper, we propose two modifications to the original Transformer: (i) We propose a video-to-tokens module that can extract tokens from extracted spatial-temporal features in videos by 3D convolutions instead of the direct token embedding from raw input video clips; (ii) We completely replace the linear mapping in multi-head self-attention layer with depth-wise convolutional mapping, which applies a depth-wise separable convolution operation on embedded token maps. With these two modifications, our approach can extract effective spatial-temporal features from videos and process the long sequences of tokens encountered in videos. Experimental results demonstrate that our proposed CTN can achieve state-of-the-art accuracy on two fine-grained action recognition datasets ( i.e ., Epic-Kitchens and Diving 48) with a small computational increase.},
  archive      = {J_NEUCOM},
  author       = {Yujun Ma and Ruili Wang and Ming Zong and Wanting Ji and Yi Wang and Baoliu Ye},
  doi          = {10.1016/j.neucom.2023.127027},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127027},
  shortjournal = {Neurocomputing},
  title        = {Convolutional transformer network for fine-grained action recognition},
  volume       = {569},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced method for reinforcement learning based dynamic
obstacle avoidance by assessment of collision risk. <em>NEUCOM</em>,
<em>568</em>, 127097. (<a
href="https://doi.org/10.1016/j.neucom.2023.127097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Naturally inspired designs of training environments for reinforcement learning (RL) often suffer from highly skewed encounter probabilities, with a small subset of experiences being encountered frequently, while extreme experiences remain rare. Despite recent algorithmic advancements, research has demonstrated that such environments present significant challenges for reinforcement learning algorithms. In this study, we first demonstrate that traditional designs in training environments for RL-based dynamic obstacle avoidance show extremely unbalanced probabilities for obstacle encounters in a way that high-risk scenarios with multiple threatening obstacles are rare. To address this limitation, we propose a traffic-type-independent training environment that allows us to exert control over the difficulty of obstacle encounter experiences. This allows us to customarily shift obstacle encounter probabilities towards high-risk experiences, which are assessed via two metrics: The number of obstacles involved and an existing collision risk metric. Our findings reveal that shifting the training focus towards higher-risk experiences, from which the agent learns, significantly improves the final performance of the agent. To validate the generalizability of our approach, we designed and evaluated two realistic use cases: a mobile robot and a maritime ship facing the threat of approaching obstacles. In both applications, we observed consistent results, underscoring the broad applicability of our proposed approach across various application contexts and independent of the agent’s dynamics. Furthermore, we introduced Gaussian noise to the sensor signals and incorporated different non-linear obstacle behaviors , which resulted in only marginal performance degradation . This demonstrates the robustness of the trained agent in handling environmental uncertainties.},
  archive      = {J_NEUCOM},
  author       = {Fabian Hart and Ostap Okhrin},
  doi          = {10.1016/j.neucom.2023.127097},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127097},
  shortjournal = {Neurocomputing},
  title        = {Enhanced method for reinforcement learning based dynamic obstacle avoidance by assessment of collision risk},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of the recent trends in deep learning for
literature based discovery in the biomedical domain. <em>NEUCOM</em>,
<em>568</em>, 127079. (<a
href="https://doi.org/10.1016/j.neucom.2023.127079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every day, enormous amounts of biomedical texts discussing various biomedical topics are produced. Revealing strong semantic connections hidden in those unstructured data is essential for many interesting applications such as knowledge base development for the biomedical domain as well as drug repurposing and drug–disease associations. Literature based discovery (LBD) is a well-known paradigm that refers to the issues of finding new hidden knowledge in scientific literature by connecting pieces of semantically-related information belonging to independent documents. This challenging research area has been extensively investigated by the research community and different proposals adopting natural language processing , text mining, machine learning and recently deep learning have been developed. This paper exploits a very focused task, it surveys a collection of research papers published in the recent years that have adopted Deep Learning for literature based discovery as an effective technique to discover new relationships between existing knowledge in biomedical domain. The study provides an analysis of the key characteristics of each work surveyed, including the Literature based discovery application area , the deep learning method used, the type of analyzed data, and the results obtained. Recognizing the significance of Pre-trained Language Models (PLMs), another primary aim of this paper is to offer an extensive overview of the latest developments in pre-trained language models within the field of biomedicine. This focus will primarily be on how they are applied to downstream tasks associated with Literature-Based Discovery in the biomedical domain. Additionally, the survey highlights the key drawbacks of the current state-of-the-art proposals, as well as the challenges that require further study by the research community.},
  archive      = {J_NEUCOM},
  author       = {Eugenio Cesario and Carmela Comito and Ester Zumpano},
  doi          = {10.1016/j.neucom.2023.127079},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127079},
  shortjournal = {Neurocomputing},
  title        = {A survey of the recent trends in deep learning for literature based discovery in the biomedical domain},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid methodology for anomaly detection in cyber–physical
systems. <em>NEUCOM</em>, <em>568</em>, 127068. (<a
href="https://doi.org/10.1016/j.neucom.2023.127068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid adoption of Industry 4.0 has seen Information Technology (IT) networks increasingly merged with Operational Technology (OT) networks, which have traditionally been isolated on air-gapped and fully trusted networks. This increased attack surface has resulted in compromises of Cyber–Physical Systems (CPS) with significant economic and life safety consequences. This paper proposes a hybrid model of anomaly detection of security threats to CPS by blending the signature-based and threshold-based Intrusion Detection Systems (IDS) commonly used in IT networks, with a Machine Learning (ML) model designed to detect behaviour-based anomalies in OT networks. This hybrid model achieves more rapid detection of known threats through signature-based and threshold-based detection strategies, and more accurate detection of unknown threats via behaviour-based anomaly detection using ML algorithms .},
  archive      = {J_NEUCOM},
  author       = {Nicholas Jeffrey and Qing Tan and José R. Villar},
  doi          = {10.1016/j.neucom.2023.127068},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127068},
  shortjournal = {Neurocomputing},
  title        = {A hybrid methodology for anomaly detection in Cyber–Physical systems},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual states based reinforcement learning for fast MR scan
and image reconstruction. <em>NEUCOM</em>, <em>568</em>, 127067. (<a
href="https://doi.org/10.1016/j.neucom.2023.127067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete phase encoding with few phases is an effective under-sampling manner of fast Magnetic Resonance (MR) scan. The key is how to choose important slice-specific phases. Reinforcement Learning (RL) is powerful for sequential decision-making and therefore is feasible for slice-specific phase selection. Existing RL-based methods employ time-consuming reconstruction-oriented Deep Neural Networks (DNN) to generate/transit states from which phase selection and reward computation are performed. The advantage is that the selected phases and the corresponding partial k -space data match the DNN for image reconstruction. The disadvantage lies in the impossibility of deciding/selecting a phase in as short as several milliseconds required in the timings of a typical pulse sequence. To simultaneously keep the matching advantage and avoid the inefficiency disadvantage, we propose a dual-state-based RL framework. A visible Parameter-Free (PF) state obtained by inverse Fast Fourier transform and a hidden DNN state obtained by applying a time-consuming reconstruction-oriented DNN on the visible state are called dual states. Visible states are used as input of phase decision networks and hidden states are used for computing reward to evaluate the decision networks. Because the time-consuming hidden states are merely involved in training process and only efficient visible states are computed in inference process, the proposed method is very efficient. Moreover, we demonstrate that incorporating the phase-indicator vector (containing sequentially selected phases) as an additional input to the transformer used for reconstructing from undersampled MR images can significantly improve image reconstruction accuracy . Experiments on fastMRI dataset demonstrate effectiveness and efficiency of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yiming Liu and Yanwei Pang and Xuebin Sun and Yonghong Hou and Zhenghan Yang and Zhenchang Wang},
  doi          = {10.1016/j.neucom.2023.127067},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127067},
  shortjournal = {Neurocomputing},
  title        = {Dual states based reinforcement learning for fast MR scan and image reconstruction},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Progressive network based on detail scaling and texture
extraction: A more general framework for image deraining.
<em>NEUCOM</em>, <em>568</em>, 127066. (<a
href="https://doi.org/10.1016/j.neucom.2023.127066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many feature extraction components have been proposed for image deraining tasks, aiming to improve feature learning . However, few models have addressed the integration of multi-scale features from derain images. The fusion of multiple features at different scales in one model has the potential to significantly enhance the authenticity and detail of rainy images restoration. This study introduces a migratable multi-scale feature blending model, which is a progressive learning model based on detail dilation and texture extraction. First, the degraded image is sent to the detail dilation module, which is designed to increase the detailed outline and obtain the coarse image features . Second, the extracted feature maps are sent to the multi-scale feature extraction (MFE) module and the multi-scale hybrid strategy (MHS) module for improved texture restoration. Third, the simple convolution modules are replaced by an optimized transformer model to more efficiently extract contextual features and multi-scale information in images. Finally, a progressive learning strategy is employed to incrementally restore the degraded images. Empirical results show that our proposed module for progressive restoration achieves near state-of-the-art performance in several rain removal tasks. In particular, our model exhibits better rain removal realism compared to state-of-the-art models. The source code is available at https://github.com/JackAILab/DTPNet .},
  archive      = {J_NEUCOM},
  author       = {Jiehui Huang and Zhenchao Tang and Xuedong He and Jun Zhou and Defeng Zhou and Calvin Yu-Chian Chen},
  doi          = {10.1016/j.neucom.2023.127066},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127066},
  shortjournal = {Neurocomputing},
  title        = {Progressive network based on detail scaling and texture extraction: A more general framework for image deraining},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cpp-AIF: A multi-core c++ implementation of active inference
for partially observable markov decision processes. <em>NEUCOM</em>,
<em>568</em>, 127065. (<a
href="https://doi.org/10.1016/j.neucom.2023.127065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active Inference is a computational framework used in neuroscience and cognitive science that characterises perception, planning and action in terms of probabilistic inference and the minimisation of variational free energy. cpp-AIF is a header-only C++ library that provides a powerful and flexible tool for implementing Active Inference for Partially Observable Markov Decision Processes through multi-core computing. Compared with existing software, cpp-AIF is cross-platform and improves performance, memory management, and usability.},
  archive      = {J_NEUCOM},
  author       = {Francesco Gregoretti and Giovanni Pezzulo and Domenico Maisto},
  doi          = {10.1016/j.neucom.2023.127065},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127065},
  shortjournal = {Neurocomputing},
  title        = {Cpp-AIF: A multi-core c++ implementation of active inference for partially observable markov decision processes},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DODFMiner: An automated tool for named entity recognition
from official gazettes. <em>NEUCOM</em>, <em>568</em>, 127064. (<a
href="https://doi.org/10.1016/j.neucom.2023.127064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Official gazettes are documents published by governments to publicize their actions, spanning long periods of time and making an important transparency mechanism. These documents have information on laws, contracts, and bidding processes, as well as on civil servants and their careers in public service. Automatic information extraction of these documents may contribute to public transparency, with two tasks being especially useful: the classification of the different segments of these documents, the so called acts; and the Named Entity Recognition (NER) within the acts. The variety of official gazettes and their patterns brings up the necessity of constructing different tools for specific gazettes. In this paper, we propose DODFMiner, a command-line interface tool to classify acts and extract named entities from the Official Gazette of the Federal District . The tool follows a 3-step approach: the pre-processing of the input data; text classification using rule-based systems with regular expressions; and NER with Machine Learning algorithms . It allows users to input JSON files and receive CSV as output, providing information that allows users to track government procurements through years, contracts duration and total amount, among others. We also propose a set of experiments to support the choice of models included in the tool, covering the classification and NER steps. Text classification achieved a mean F1-score of 0.778, while to the NER, we compared 3 different architectures, CRF with a mean F1-score of 0.851, CNN-biLSTM-CRF with 0.787 and CNN-CNN-LSTM with 0.841.},
  archive      = {J_NEUCOM},
  author       = {Gabriel M.C. Guimarães and Felipe X.B. da Silva and Andrei L. Queiroz and Ricardo M. Marcacini and Thiago P. Faleiros and Vinicius R.P. Borges and Luís P.F. Garcia},
  doi          = {10.1016/j.neucom.2023.127064},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127064},
  shortjournal = {Neurocomputing},
  title        = {DODFMiner: An automated tool for named entity recognition from official gazettes},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RoFormer: Enhanced transformer with rotary position
embedding. <em>NEUCOM</em>, <em>568</em>, 127063. (<a
href="https://doi.org/10.1016/j.neucom.2023.127063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Position encoding has recently been shown to be effective in transformer architecture. It enables valuable supervision for dependency modeling between elements at different positions of the sequence. In this paper, we first investigate various methods to integrate positional information into the learning process of transformer-based language models . Then, we propose a novel method named Rotary Position Embedding (RoPE) to effectively leverage the positional information. Specifically, the proposed RoPE encodes the absolute position with a rotation matrix and meanwhile incorporates the explicit relative position dependency in the self-attention formulation. Notably, RoPE enables valuable properties, including the flexibility of sequence length , decaying inter-token dependency with increasing relative distances , and the capability of equipping linear self-attention with relative position encoding. Finally, we evaluate the enhanced transformer with rotary position embedding, also called RoFormer, on various long text classification benchmark datasets. Our experiments show that it consistently overcomes its alternatives. Furthermore, we provide a theoretical analysis to explain some experimental results. RoFormer is already integrated into Huggingface: https://huggingface.co/docs/transformers/model_doc/roformer .},
  archive      = {J_NEUCOM},
  author       = {Jianlin Su and Murtadha Ahmed and Yu Lu and Shengfeng Pan and Wen Bo and Yunfeng Liu},
  doi          = {10.1016/j.neucom.2023.127063},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127063},
  shortjournal = {Neurocomputing},
  title        = {RoFormer: Enhanced transformer with rotary position embedding},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 4Ward: A relayering strategy for efficient training of
arbitrarily complex directed acyclic graphs. <em>NEUCOM</em>,
<em>568</em>, 127058. (<a
href="https://doi.org/10.1016/j.neucom.2023.127058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to their ease of implementation, multilayer perceptrons (MLPs) have become ubiquitous in deep learning applications. The graph underlying an MLP is indeed multipartite, i.e. each layer of neurons only connects to neurons belonging to the adjacent layer . In contrast, in vivo brain connectomes at the level of individual synapses suggest that biological neuronal networks are characterized by scale-free degree distributions or exponentially truncated power law strength distributions, hinting at potentially novel avenues for the exploitation of evolution-derived neuronal networks. In this paper, we present “4Ward”, a method and Python library capable of generating flexible and efficient neural networks (NNs) from arbitrarily complex directed acyclic graphs. 4Ward is inspired by layering algorithms drawn from the graph drawing discipline to implement efficient forward passes, and provides significant time gains in computational experiments with various Erdős-Rényi graphs. 4Ward not only overcomes the sequential nature of the learning matrix method, by parallelizing the computation of activations, but also addresses the scalability issues encountered in the current state-of-the-art and provides the designer with freedom to customize weight initialization and activation functions . Our algorithm can be of aid for any investigator seeking to exploit complex topologies in a NN design framework at the microscale.},
  archive      = {J_NEUCOM},
  author       = {Tommaso Boccato and Matteo Ferrante and Andrea Duggento and Nicola Toschi},
  doi          = {10.1016/j.neucom.2023.127058},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127058},
  shortjournal = {Neurocomputing},
  title        = {4Ward: A relayering strategy for efficient training of arbitrarily complex directed acyclic graphs},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rotation-equivariant correspondence matching based on a
dual-activation mixer. <em>NEUCOM</em>, <em>568</em>, 127053. (<a
href="https://doi.org/10.1016/j.neucom.2023.127053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning-based correspondence matching methods have become the mainstream techniques in many computer vision and robotics applications due to their robustness to large illumination and viewpoint changes. However, it is difficult for conventional convolutional neural networks (CNNs) to extract rotation-equivariant local features . Recent work has shown that CNNs combined with group-equivariant architectures are surprisingly effective at matching correspondences even when the images are rotated to a dramatic extent. However, the inherent shape (square) of convolution kernels causes the performance bottleneck of such rotation-equivariant CNNs. To address this issue, we propose an adaptive dual rotation-equivariant correspondence matching algorithm , which performs stably at all angles. We mathematically analyze the effectiveness of our proposed rotation-equivariant correspondence matching approach and its performance with respect to different convolution kernels. Extensive experiments on the Rotated-HPatches, SIM2E, and MegaDepth datasets demonstrate the effectiveness of our proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Shuai Su and Ronghao Dang and Rui Fan and Chengju Liu and Qijun Chen},
  doi          = {10.1016/j.neucom.2023.127053},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127053},
  shortjournal = {Neurocomputing},
  title        = {Rotation-equivariant correspondence matching based on a dual-activation mixer},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stable approximate q-learning under discounted cost for
data-based adaptive tracking control. <em>NEUCOM</em>, <em>568</em>,
127048. (<a href="https://doi.org/10.1016/j.neucom.2023.127048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the stability of tracking error dynamics under the data-based discounted iterative Q-learning is investigated. First, a novel performance index with a discount factor is introduced into the iterative Q-learning-based tracking control . Then, considering the approximation errors caused by the Q-function approximator, the finite error bound between the iterative and optimal Q-functions is established. Moreover, based on the new stability analysis, the selection rule of the discount factor is developed, which ensures that the corresponding optimal control policy is admissible. Next, to ensure the stability of the tracking error dynamics under iterative control policies, the stability condition about the approximate Q-function is established. It is guaranteed that iterative control policies derived from the critic network drive the tracking error to zero. Additionally, considering the adopted policy function approximator, the upper bound function of the approximation errors is developed. It is ensured that the trained action network stabilizes the tracking error dynamics. Finally, a simulation example is utilized to implement the data-based discounted iterative Q-learning and verify the present theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Zhantao Liang and Mingming Ha and Derong Liu and Yonghua Wang},
  doi          = {10.1016/j.neucom.2023.127048},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127048},
  shortjournal = {Neurocomputing},
  title        = {Stable approximate Q-learning under discounted cost for data-based adaptive tracking control},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive learning control of robot manipulators via
incremental hybrid neural network. <em>NEUCOM</em>, <em>568</em>,
127045. (<a href="https://doi.org/10.1016/j.neucom.2023.127045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel hybrid neural network based learning control method is proposed to improve trajectory tracking accuracy for complex robot manipulators in this paper. Firstly, a hybrid neural network is presented to improve the model accuracy and data efficiency, which is integrated by the Differential Newton-Euler Algorithm (DiffNEA) and Radial Basis Function Neural Network (RBFNN). In this hybrid neural network, the DiffNEA takes in charge of modeling the known rigid dynamics, while RBFNN takes in charge of capturing the unmodeled phenomena and external disturbances. Secondly, an incremental design method is proposed to determine optimal structure and parameters of the hybrid neural network. Thirdly, an adaptive learning controller based on the aforementioned hybrid neural network is designed to further reject the effects of unmodeled dynamics and external disturbances on trajectory tacking performance. Finally, experimental results are presented to validate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Siyong Xu and Zhong Wu},
  doi          = {10.1016/j.neucom.2023.127045},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127045},
  shortjournal = {Neurocomputing},
  title        = {Adaptive learning control of robot manipulators via incremental hybrid neural network},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic event-triggered-based online IRL algorithm for the
decentralized control of the input and state constrained large-scale
unmatched interconnected system. <em>NEUCOM</em>, <em>568</em>, 127042.
(<a href="https://doi.org/10.1016/j.neucom.2023.127042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposed a novel adaptive decentralized control (ADC) method for the continuous-time state-constrained and input-constrained large-scale unmatched interconnection system by the means of the adaptive critic design in the edge dynamic event-triggered (EDET) mechanism. The barrier function is used to transform the state-constrained system to the common system without constrained states. To overcome the influence of the unmatched interconnection terms, the auxiliary systems are devised for each subsystem of the large-scale system. Moreover, the non-quadratic utility functions are introduced to constrain the input of the auxiliary systems. The decentralized control scheme of the large-scale unmatched interconnection system can be realized by solving the optimal control schemes of the auxiliary systems. Then with the help of the single critic neural network (NN), the approximate optimal control policies are acquired by designing the approximate cost functions. After that, an integral reinforcement learning (IRL)-based scheme is proposed to solve the integral Bellman equation rather than the complex coupled Hamilton–Jacobi-Bellman equation (HJBE). Simultaneously, the EDET mechanism is introduced to reduce the computation efforts and communication loads. The asymptotic stability of the constrained large-scale unmatched interconnection system is proved. In addition, the infamous Zeno behavior is effectively avoided. Finally, two simulation cases are given to verify the effectiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Xinyang Luan and Hanguang Su and Huaguang Zhang and Xiaodong Liang and Yuling Liang and Jiawei Wang},
  doi          = {10.1016/j.neucom.2023.127042},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127042},
  shortjournal = {Neurocomputing},
  title        = {Dynamic event-triggered-based online IRL algorithm for the decentralized control of the input and state constrained large-scale unmatched interconnected system},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DHGAT: Hyperbolic representation learning on dynamic graphs
via attention networks. <em>NEUCOM</em>, <em>568</em>, 127038. (<a
href="https://doi.org/10.1016/j.neucom.2023.127038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperbolic graph embedding has garnered significant attention in a wide range of downstream applications. This is because hyperbolic geometry provides a valuable mapping tool, whereby the scale-free or hierarchical properties of complex networks can be naturally reflected as hyperbolic metric properties. Despite this, most advancements have focused on learning hyperbolic representations of static graphs, the potential advantages of hyperbolic metrics in dynamic graphs embedding have not been fully exploited. To fully harness the properties of hyperbolic space , we propose DHGAT 1 , a dynamic hyperbolic graph attention network with a novel architecture that designs a spatiotemporal self-attention mechanism based on hyperbolic distance. DHGAT maps dynamic graphs into the hyperbolic space, generates spatiotemporal self-attention of nodes, and directly aggregates weighted node representations without the tangent space. This is achieved by using the Einstein gyromidpoints, which reduces distortions and preserves manifold properties. The results of experiments on real-world datasets demonstrate that DHGAT performs exceptionally well in multi-step link prediction tasks, particularly in predicting new links compared to the baselines.},
  archive      = {J_NEUCOM},
  author       = {Hao Li and Hao Jiang and Dongsheng Ye and Qiang Wang and Liang Du and Yuanyuan Zeng and Liu yuan and Yingxue Wang and Cheng Chen},
  doi          = {10.1016/j.neucom.2023.127038},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127038},
  shortjournal = {Neurocomputing},
  title        = {DHGAT: Hyperbolic representation learning on dynamic graphs via attention networks},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Introducing shape priors in siamese networks for image
classification. <em>NEUCOM</em>, <em>568</em>, 127034. (<a
href="https://doi.org/10.1016/j.neucom.2023.127034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficiency of deep neural networks is increasing, and so is the amount of annotated data required for training them. We propose a solution improving the learning process of a classification network with less labeled data. Our approach is to inform the classifier of the elements it should focus on to make its decision by supplying it with some shape priors. These shape priors are expressed as binary masks, giving a rough idea of the shape of the relevant elements for a given class. We resort to Siamese architecture and feed it with image/mask pairs. By inserting shape priors, only the relevant features are retained. This provides the network with significant generalization power without requiring a specific domain adaptation step. This solution is tested on some standard cross-domain digit classification tasks and on a real-world video surveillance application. Extensive tests show that our approach outperforms the classical classifier by generating a good latent space with less training data . Code is available at https://github.com/halqasir/MG-Siamese .},
  archive      = {J_NEUCOM},
  author       = {Hiba Alqasir and Damien Muselet and Christophe Ducottet},
  doi          = {10.1016/j.neucom.2023.127034},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127034},
  shortjournal = {Neurocomputing},
  title        = {Introducing shape priors in siamese networks for image classification},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predicting stock market trends with self-supervised
learning. <em>NEUCOM</em>, <em>568</em>, 127033. (<a
href="https://doi.org/10.1016/j.neucom.2023.127033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting stock market trends is the basic daily routine task that investors should perform in the stock trading market. Traditional market trends prediction models are generally based on hand-crafted factors or features, which heavily rely on expensive expertise knowledge. Moreover, it is difficult to discover hidden features contained in the stock time series data , which are otherwise helpful for predicting stock market trends. In this paper, we propose a novel stock market trends prediction framework SMART with a self-supervised stock technical data sequence embedding model S3E. Specifically, the model encodes stock technical data sequences into embeddings, which are further trained with multiple self-supervised auxiliary tasks. With the learned sequence embeddings, we make stock market trends predictions based on an LSTM and a feed-forward neural network. We conduct extensive experiments on China A-Shares market and NASDAQ market to show that our model is highly effective for stock market trends prediction. We further deploy SMART in a leading financial service provider in China and the result demonstrates the effectiveness of the proposed method in real-world applications.},
  archive      = {J_NEUCOM},
  author       = {Zelin Ying and Dawei Cheng and Cen Chen and Xiang Li and Peng Zhu and Yifeng Luo and Yuqi Liang},
  doi          = {10.1016/j.neucom.2023.127033},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127033},
  shortjournal = {Neurocomputing},
  title        = {Predicting stock market trends with self-supervised learning},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simion zoo: A training workbench for reinforcement learning
allowing distributed experimentation. <em>NEUCOM</em>, <em>568</em>,
127030. (<a href="https://doi.org/10.1016/j.neucom.2023.127030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simion Zoo is a Reinforcement Learning (RL) workbench developed for training of novel users that can be deployed over computer farms allowing extensive experimentation over distributed resources. In this paper, we present this software platform and share some of the insights gained during the development. This workbench provides a complete set of tools to design, run, carry out statistical analysis of the results, report preparation, and have qualitative visual assessment of the simulation evolution of continuous RL control experiments. The main features that set apart Simion Zoo from other software packages for introduction to RL experimentation are its easy-to-use GUI, its support for distributed execution including deployment over graphics processing units (GPUs), and the possibility to explore concurrently the RL hyper-parameter space, which is key to successful RL experimentation.},
  archive      = {J_NEUCOM},
  author       = {Borja Fernandez-Gauna and Manuel Graña},
  doi          = {10.1016/j.neucom.2023.127030},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127030},
  shortjournal = {Neurocomputing},
  title        = {Simion zoo: A training workbench for reinforcement learning allowing distributed experimentation},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Stabilization and synchronization control for discrete-time
complex networks via the auxiliary role of edges subsystem.
<em>NEUCOM</em>, <em>568</em>, 127029. (<a
href="https://doi.org/10.1016/j.neucom.2023.127029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel discrete-time interconnected model composed of nodes and edges subsystems is proposed, to depict the complex dynamical networks (CDNs) consisted of nodes and dynamic edges which are coupled mutually. Firstly, we propose a vector model to describe the dynamic characteristic of edges rather than the matrix form, the proposed discrete-time CDNs have dynamics attached on not only the nodes but also the edges. Then, to reveal the essential mechanism between network structure and stabilization (synchronization), the control strategies and the coupling modes between two subsystems are designed such that the stabilization and synchronization can be achieved. Finally, a simulation example is given to prove the effectiveness of the proposed methods.},
  archive      = {J_NEUCOM},
  author       = {Lizhi Liu and Zilin Gao and Yinhe Wang and Yongfu Li},
  doi          = {10.1016/j.neucom.2023.127029},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127029},
  shortjournal = {Neurocomputing},
  title        = {Stabilization and synchronization control for discrete-time complex networks via the auxiliary role of edges subsystem},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review on speech emotion recognition: A survey, recent
advances, challenges, and the influence of noise. <em>NEUCOM</em>,
<em>568</em>, 127015. (<a
href="https://doi.org/10.1016/j.neucom.2023.127015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Affective Computing systems can detect the emotional state and mindset of an individual. Speech Emotion Recognition (SER) is a unimodal affect computing system based on emotional speech data. It is an active area of research in pattern recognition, computer vision, and deep learning . There is a great deal of literature on SER, but only a few of these works consider how SER performs under noisy conditions. A few surveys exist to review SER, but they either need to cover all aspects of SER in noisy environments or discuss the details thoroughly. In recent years, researchers have had a growing interest in using SER in real-world conditions and have seen improvements in recognition rate. This review compiles the methods and approaches used in noisy SER in the literature up to the mid of 2023. It covers topics such as noisy SER methods, datasets used for SER under noisy conditions, noise used, and toolkits used for noisy SER recognition. Additionally, it focuses on classifiers , features used, and limitations of existing research in noisy SER systems. The review also seeks to answer &quot;Does noise affects performance?&quot; to which the answer is a resounding yes, as demonstrated by the results obtained from this survey.},
  archive      = {J_NEUCOM},
  author       = {Swapna Mol George and P. Muhamed Ilyas},
  doi          = {10.1016/j.neucom.2023.127015},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127015},
  shortjournal = {Neurocomputing},
  title        = {A review on speech emotion recognition: A survey, recent advances, challenges, and the influence of noise},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decentralized optimal control of large-scale partially
unknown nonlinear mismatched interconnected systems based on dynamic
event-triggered control. <em>NEUCOM</em>, <em>568</em>, 127013. (<a
href="https://doi.org/10.1016/j.neucom.2023.127013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel decentralized control method is proposed for nonlinear mismatched large-scale interconnected systems subjected to partially unknown dynamics by designing auxiliary control for each subsystem. It is demonstrated that the control sequence consisting of the optimal control policies of auxiliary control can stabilize the system asymptotically, leading to decentralized control of the large-scale system. An integral reinforcement learning (IRL) method is firstly proposed, replacing the traditional policy iterative algorithm to analyze the optimal control problem of each edge subsystem with partially unknown dynamics. After that, the edge-based dynamic event-triggered control algorithm is proposed based on the static event-triggered control method, and an internal dynamic variable characterized by a first-order filter is defined. A single critic neural network (NN) is then designed to learn the approximate optimal control strategy under the dynamic event-triggered mechanism adaptively. The stability analysis is proposed to demonstrate that the state of the event-based pulse system is ultimately uniformly bounded (UUB) and the Zeno behavior is eliminated successfully. Finally, the effectiveness of the proposed algorithm is verified by two simulation examples to realize decentralized control of mismatched large-scale systems.},
  archive      = {J_NEUCOM},
  author       = {Hanguang Su and Xinyang Luan and Huaguang Zhang and Xiaodong Liang and Jinzhu Yang and Jiawei Wang},
  doi          = {10.1016/j.neucom.2023.127013},
  journal      = {Neurocomputing},
  month        = {2},
  pages        = {127013},
  shortjournal = {Neurocomputing},
  title        = {Decentralized optimal control of large-scale partially unknown nonlinear mismatched interconnected systems based on dynamic event-triggered control},
  volume       = {568},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detection of dangerously approaching vehicles over onboard
cameras by speed estimation from apparent size. <em>NEUCOM</em>,
<em>567</em>, 127057. (<a
href="https://doi.org/10.1016/j.neucom.2023.127057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving requires information such as the velocity of other vehicles to prevent potential hazards. This work proposes a real-time deep learning-based framework to estimate vehicle speeds from image captures through an onboard camera. Vehicles are detected and tracked by the proposed deep neural networks and a tracking algorithm, which analyzes the trajectories. Finally, a linear regression model estimates the speed of a vehicle based on its position and size in the camera frame. This proposal has been tested with two sequences of the Prevention dataset with satisfactory results. The system can estimate the speed of multiple vehicles simultaneously. It can be integrated easily with onboard computer systems , thus allowing to development of a low-cost solution for speed estimation in an everyday vehicle. The potential applications include vehicle safety systems, driver assistance, and autonomous driving technologies.},
  archive      = {J_NEUCOM},
  author       = {Iván García-Aguilar and Jorge García-González and Daniel Medina and Rafael Marcos Luque-Baena and Enrique Domínguez and Ezequiel López-Rubio},
  doi          = {10.1016/j.neucom.2023.127057},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127057},
  shortjournal = {Neurocomputing},
  title        = {Detection of dangerously approaching vehicles over onboard cameras by speed estimation from apparent size},
  volume       = {567},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hyperbolic function-based fixed/preassigned-time stability
of nonlinear systems and synchronization of delayed fuzzy
cohen–grossberg neural networks. <em>NEUCOM</em>, <em>567</em>, 127056.
(<a href="https://doi.org/10.1016/j.neucom.2023.127056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the fixed-time (FIT) and preassigned-time (PRT) stability of nonlinear models and the FIT/PRT synchronization of discontinuous delayed fuzzy Cohen–Grossberg neural networks (DFCGNNs) are explored, respectively. Firstly, by means of hyperbolic-cosine function and Gudermannian function, a novel FIT stability theorem is established by utilizing Lyapunov method. Then, based on the developed stability theorem, several new discontinuous control schemes with hyperbolic-cosine function are developed to discuss the FIT synchronization of DFCGNNs. Furthermore, the PRT synchronization is also explored by slightly modifying FIT control schemes, where the synchronization time is predetermined. Eventually, two numerical examples are provided to validate the theoretical research.},
  archive      = {J_NEUCOM},
  author       = {Xinguo Ma and Cheng Hu and Juan Yu and Leimin Wang and Haijun Jiang},
  doi          = {10.1016/j.neucom.2023.127056},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127056},
  shortjournal = {Neurocomputing},
  title        = {Hyperbolic function-based fixed/preassigned-time stability of nonlinear systems and synchronization of delayed fuzzy Cohen–Grossberg neural networks},
  volume       = {567},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed adaptive event-triggered asymptotic tracking
control of linear uncertain multiagent systems by using output only.
<em>NEUCOM</em>, <em>567</em>, 127055. (<a
href="https://doi.org/10.1016/j.neucom.2023.127055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the robust tracking control problem of multiagent systems with linear uncertainties, most of the existing studies require full state feedback. Moreover, the designed control strategy also uses global information, such as the number of agents or the eigenvalues of the Laplacian matrix , which does not satisfy the distributed requirement for multiagent design. To address these problems, first, a Luenburger observer is designed to observe the full state of the system by using the output information. Second, the constant gain in the traditional distributed observer for estimating exosystem state information is replaced with a time-varying gain that comes from the output of a newly designed filter, which avoids the use of the global information mentioned above. Finally, based on the above observer and adaptive dynamic feedback, an event-triggered output feedback control strategy is given. This control strategy is not only piecewise constant, which is easy to implement, but also makes the robust tracking control error converge asymptotically to zero. Furthermore, it is theoretically proven that each agent does not have Zeno behaviour , and the effectiveness of the designed control strategy is verified with a simulation example.},
  archive      = {J_NEUCOM},
  author       = {Linsha Tang and Chaoli Wang and Dong Liang and Zhengtao Ding},
  doi          = {10.1016/j.neucom.2023.127055},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127055},
  shortjournal = {Neurocomputing},
  title        = {Distributed adaptive event-triggered asymptotic tracking control of linear uncertain multiagent systems by using output only},
  volume       = {567},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anchor ball regression model for large-scale 3D skull
landmark detection. <em>NEUCOM</em>, <em>567</em>, 127051. (<a
href="https://doi.org/10.1016/j.neucom.2023.127051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent deep learning models have exhibited impressive performance in the area of 3D skull landmark detection, but most of them aimed to detect a fixed number of landmarks. This paper focuses on automatically detecting an arbitrary number of landmarks on CT volumes, which meets the real clinical needs. To achieve robust performance for detecting arbitrary molar landmarks, we propose a novel 3D landmark detection model named Anchor Ball Regression Model (ABRM), which combines landmark detection and landmark classification losses for network training. For landmark detection, a novel landmark regression loss is proposed by predicting offsets to anchor balls instead of directly predicting landmarks. For landmark classification, an online hard negative mining loss is used to reduce absent landmarks’ learning errors, and a small regularization constraint loss is performed for voxels outside the anchor balls. The network backbone of ABRM is obtained by manually pruning popular 3D-CNNs. We also present an available large-scale benchmark dataset in this paper, which, to the best of our knowledge, is the largest dataset for 3D skull landmark detection. The dataset comprises of 658 CT volumes, with 14 landmarks labeled by two junior and one senior doctors. The ABRM presents a good robust performance and outperforms other models on this dataset. The codes and dataset are accessible at https://github.com/ithet1007/mmld_code .},
  archive      = {J_NEUCOM},
  author       = {Tao He and Guikun Xu and Li Cui and Wei Tang and Jie Long and Jixiang Guo},
  doi          = {10.1016/j.neucom.2023.127051},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127051},
  shortjournal = {Neurocomputing},
  title        = {Anchor ball regression model for large-scale 3D skull landmark detection},
  volume       = {567},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). How does layer normalization improve batch normalization in
self-supervised sound source localization? <em>NEUCOM</em>,
<em>567</em>, 127040. (<a
href="https://doi.org/10.1016/j.neucom.2023.127040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised sound source localization is usually challenged by the unexpected large input and incorrect direction of normalization in current solutions. A promising way for this challenge is to avoid feature deformation by incorporating more effective normalization, which is the motivation of this study. Based on the mathematical derivation of Layer Normalization (LN) in scale independence, in this work, a correspondence consolidation method is proposed to reinforce the audio–visual correspondence. By ensembling input feature normalization and LN-based simsiam Predictor, a joint gradient stabilization can be further achieved for more accurate sound source localization. Substantial experiments conducted on SoundNet-Flickr and VGG-Sound Source datasets have verified a superior performance in comparison to the other state-of-the-art works.},
  archive      = {J_NEUCOM},
  author       = {Tianyu Liu and Peng Zhang and Wei Huang and Yufei Zha and Tao You and Yanning Zhang},
  doi          = {10.1016/j.neucom.2023.127040},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127040},
  shortjournal = {Neurocomputing},
  title        = {How does layer normalization improve batch normalization in self-supervised sound source localization?},
  volume       = {567},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Collaborative representation based cross-domain semantic
transfer for vehicle re-identification. <em>NEUCOM</em>, <em>567</em>,
127039. (<a href="https://doi.org/10.1016/j.neucom.2023.127039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle re-identification (re-ID) has received increasing attention due to its tremendous potential in practical intelligent transportation scenarios. The main difficulties of vehicle re-ID are generally induced by insufficient annotations, varying viewpoints and illuminations, and mismatched visual-semantic cues. Previous studies on vehicle re-ID have generally focused on exploring better visual representations of the target samples while ignoring semantic complementarity from external sources. In this paper, we propose an unsupervised semantic transfer method based on collaborative matrix representation (STCMR) for vehicle re-ID that obtains rich semantic representations by learning knowledge from external annotated data. STCMR contains three components: an asymmetrical collaborative matrix representation term, a low-rank regularized relaxed attribute term, and a dual-graph Laplacian regularization term. In particular, we first build two reliable feature matrices to better transfer external annotated semantics from the source domain to the target re-ID domain. We then propose a robust collaborative matrix representation term to decompose the feature matrices into user-defined, domain-shared, and domain-unique parts in an asymmetrical manner. To tackle samples with incomplete semantics, we design a low-rank regularized attribute relaxed term that fully exploits existing annotations to complete missing entries in a soft constraint manner. Finally, we exploit the local geometric structure consistency in source and target domains by a dual-graph Laplacian regularization term to adaptively estimate the relationships of source domain samples. In addition, we further propose an alternating iterative algorithm to solve the optimization problem. Experimental results conducted on the VehicleID and VeRi-776 datasets validate the effectiveness of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yun Li and Fan Yang and Yudou Tian and Xuejun Wang and Qi Chen and Peiguang Jing},
  doi          = {10.1016/j.neucom.2023.127039},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127039},
  shortjournal = {Neurocomputing},
  title        = {Collaborative representation based cross-domain semantic transfer for vehicle re-identification},
  volume       = {567},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fault-tolerant tracking control for nonlinear systems with
multiplicative actuator faults in view of zero-sum differential games.
<em>NEUCOM</em>, <em>567</em>, 127037. (<a
href="https://doi.org/10.1016/j.neucom.2023.127037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of zero-sum differential games, this paper addresses the fault-tolerant tracking control (FTTC) problem for nonlinear systems with multiplicative actuator faults . By augmenting the nominal system, the trajectory tracking problem is transformed into an optimal regulation problem. A fault observer is designed to estimate the multiplicative actuator fault factor. In order to better reflect system performance, a comprehensive performance index function including the trajectory tracking error, the control input, and the multiplicative actuator fault is constructed. By considering the control input and the multiplicative actuator fault as two players in the zero-sum differential game (ZSDG), the FTTC problem is thus transformed into a ZSDG problem. Then, a fault-tolerant control based on ZSDG is designed by solving the Hamilton–Jacobi-Isaacs (HJI) equation. Since the HJI equation is difficult to solve, a critic neural network is constructed to obtain its approximation , which constitutes the Nash equilibrium of the ZSDG. The closed-loop faulty system is guaranteed to be uniformly ultimately bounded via the Lyapunov’s direct method. The effectiveness of the developed FTTC method is demonstrated by two simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Cong Tan and Mingduo Lin and Hongbing Xia and Bo Zhao},
  doi          = {10.1016/j.neucom.2023.127037},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127037},
  shortjournal = {Neurocomputing},
  title        = {Fault-tolerant tracking control for nonlinear systems with multiplicative actuator faults in view of zero-sum differential games},
  volume       = {567},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural dynamics solver for time-dependent infinity-norm
optimization based on ACP framework with robot application.
<em>NEUCOM</em>, <em>567</em>, 127032. (<a
href="https://doi.org/10.1016/j.neucom.2023.127032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In general, infinity-norm optimization (INO) is commonly deemed as a subset of nonlinear optimization. In the last decade, there have been relatively few reports on solving INO problems, specifically from the time-dependent aspect originating from the real-time motion planning of robots. Therefore, to compensate for the vacancy, this paper proposes a class of neural dynamics (ND) solvers utilizing an ACP framework that combines artificial systems (A), computational experiments (C), and parallel execution (P), respectively. Specifically, two improved ND solvers are constructed by exploiting simplified sign-bi-power and saturation activation functions for solving time-dependent INO (TDINO) problems subject to equality and inequality constraints. Moreover, the corresponding theoretical analysis and proof are conducted, which ensures that residual errors of the proposed improved ND solvers based on the ACP framework converge in a short time. Compared with a SOTA (state-of-the-art) zeroing neural network model presented recently, the average error of the proposed ones is reduced by 52%, the speed of error convergence is increased by 152%, and the transient state is extended by 4% on average. Finally, simulation results of an illustrative example and an application in the robot are provided, which illustrates the effectiveness, superiority, and feasibility of the proposed ND solvers.},
  archive      = {J_NEUCOM},
  author       = {Dexiu Ma and Mei Liu and Mingsheng Shang},
  doi          = {10.1016/j.neucom.2023.127032},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127032},
  shortjournal = {Neurocomputing},
  title        = {Neural dynamics solver for time-dependent infinity-norm optimization based on ACP framework with robot application},
  volume       = {567},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A constrastive semi-supervised deep learning framework for
land cover classification of satellite time series with limited labels.
<em>NEUCOM</em>, <em>567</em>, 127031. (<a
href="https://doi.org/10.1016/j.neucom.2023.127031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a new semi-supervised learning framework to cope with satellite image time series (SITS) classification in a data paucity scenario, considering extreme low levels of supervision. The proposed methodology, referred as S 3 3 ITS (Semi-Supervised Satellite Image Time Series classification method), is based on temporal convolutional neural networks and it takes advantage of both labelled and unlabelled information. S 3 3 ITS enforces the data to be projected in a discriminative manifold via contrastive learning , in order to produce a data representation where samples belonging to the same category are closer than the ones belonging to different ones. Pseudo-labelling is employed on unlabelled samples to take the most out of the available unlabelled information. Experiments on two study sites described by SITS of Sentinel-2 images highlight the quality of the proposed method with respect to common SITS-based classification methods and recent machine learning approaches especially tailored for the semi-supervised classification of multi-variate time series data .},
  archive      = {J_NEUCOM},
  author       = {Dino Ienco and Raffaele Gaetano and Roberto Interdonato},
  doi          = {10.1016/j.neucom.2023.127031},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127031},
  shortjournal = {Neurocomputing},
  title        = {A constrastive semi-supervised deep learning framework for land cover classification of satellite time series with limited labels},
  volume       = {567},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Surpassing early stopping: A novel correlation-based
stopping criterion for neural networks. <em>NEUCOM</em>, <em>567</em>,
127028. (<a href="https://doi.org/10.1016/j.neucom.2023.127028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the training of neural networks , selecting the right stopping criterion is crucial to prevent overfitting and conserve computing power. While the early stopping and the maximum number of epochs stopping methods are simple to implement, they have limitations in identifying the point during training where the training and the validation loss start to diverge. To overcome these limitations, we propose a general correlation-based stopping criterion called the Correlation-Driven Stopping Criterion (CDSC). The CDSC stops the training process when the rolling Pearson correlation of the loss metrics between the training and validation datasets decreases below a pre-defined threshold. To show the effectiveness of the newly proposed Correlation-Driven Stopping Criterion, its effectiveness was compared with the effectiveness of the early stopping and the maximum number of epochs stopping methods across multiple common machine learning problems and neural network models . Our study shows that the proposed Correlation-Driven Stopping Criterion can enhance the out-of-sample performance of all tested neural network models while conserving computing power.},
  archive      = {J_NEUCOM},
  author       = {Tamás Miseta and Attila Fodor and Ágnes Vathy-Fogarassy},
  doi          = {10.1016/j.neucom.2023.127028},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127028},
  shortjournal = {Neurocomputing},
  title        = {Surpassing early stopping: A novel correlation-based stopping criterion for neural networks},
  volume       = {567},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards better transition modeling in recurrent neural
networks: The case of sign language tokenization. <em>NEUCOM</em>,
<em>567</em>, 127018. (<a
href="https://doi.org/10.1016/j.neucom.2023.127018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks (RNNs) are a popular family of models widely used when facing sequential data such as videos. However, RNNs make assumptions about state transitions that could be damageable. This paper presents two theoretical limitations of RNNs along with popular extensions proposed to mitigate those issues. The effectiveness of these methods is assessed in practice on the specific task of sign language (SL) video tokenization, as it remains challenging. Evaluated strategies enhance transition modeling with RNNs functioning as state machines. However, this performance gain diminishes in more complex architectures, indicating there is still room for improvement. Such improvement would help to build powerful SL tokenizers usable in future pipelines in natural language processing .},
  archive      = {J_NEUCOM},
  author       = {Pierre Poitier and Jérôme Fink and Benoît Frénay},
  doi          = {10.1016/j.neucom.2023.127018},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127018},
  shortjournal = {Neurocomputing},
  title        = {Towards better transition modeling in recurrent neural networks: The case of sign language tokenization},
  volume       = {567},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Topologies in distributed machine learning: Comprehensive
survey, recommendations and future directions. <em>NEUCOM</em>,
<em>567</em>, 127009. (<a
href="https://doi.org/10.1016/j.neucom.2023.127009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread use of distributed machine learning (DML), many IT companies have established networks dedicated to DML. Different communication architectures of DML have different traffic patterns and different requirements on network performance, which is closely related to network topology . However, traditional network topologies usually pursue general goals and are agnostic to the special communication pattern of the applications. The mismatch between network topology and the applications will directly affect the training performance. Although some studies have analyzed the effect of topology on training performance, the topologies and communication architectures involved are not comprehensive, and it is still not known which topology is appropriate for which communication architecture. This survey investigates typical topologies and analyzes whether they meet the requirements of three commonly used communication architectures (i.e., Parameter Server (PS), Tree and Ring architectures) of DML. Specifically, the topology requirements of each communication architecture and two common topology requirements (i.e., high scalability and fault tolerance) for DML are studied firstly. Next, whether these topologies meet the topology requirements is analyzed. Then, this paper discusses potential technologies and approaches to construct the appropriate scheme for each topology requirement, and then presents DMLNet , a novel network topology that suits the three communication architectures. Finally, several potential directions for future research are outlined.},
  archive      = {J_NEUCOM},
  author       = {Ling Liu and Pan Zhou and Gang Sun and Xi Chen and Tao Wu and Hongfang Yu and Mohsen Guizani},
  doi          = {10.1016/j.neucom.2023.127009},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127009},
  shortjournal = {Neurocomputing},
  title        = {Topologies in distributed machine learning: Comprehensive survey, recommendations and future directions},
  volume       = {567},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligence modelling human mental fatigue: A
comprehensive survey. <em>NEUCOM</em>, <em>567</em>, 126999. (<a
href="https://doi.org/10.1016/j.neucom.2023.126999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mental fatigue refers to the decline in cognitive abilities that can occur as a result of prolonged mental exertion. Neuroscientists have been studying mental fatigue for a while. They clearly understand some underlying mechanisms of mental fatigue, such as brain chemistry and neural activity changes. However, defining mental fatigue is still an open research question. Despite this, neuroscience and cognitive psychology has made significant progress in understanding the causes and consequences of mental fatigue. In contrast, computer scientists presumably have a limited understanding of mental fatigue. This lack of understanding leads to inadequate models of mental fatigue in computer science. However, the ever evolving field of artificial intelligence (AI) shows a great potential to answer the open challenges in mental fatigue modelling. For instance, AI with fuzzy rules, machine learning or deep learning algorithms , as well as the methods of model explanation can be a valuable tool for creating accurate models of mental fatigue. Artificial intelligence models can learn from large amounts of data and accurately predict mental fatigue. However, modelling efforts are often more focused on acquiring parameters than studying and validating them within the model. Models developed in this way suffer problems with reliability making it challenging to understand the underlying causes of mental fatigue. Therefore, it is essential balance between these parameters’ correct acquisition, validation and interaction to create more accurate models of mental fatigue. In our survey, we have observed that an unspecified modelling impact the model at four scale : experimental design , data acquisition and processing , choice of indicators or parameters and reasoning . We provide some useful guidelines through criticisms for modelling, which would be closer to reality.},
  archive      = {J_NEUCOM},
  author       = {Alexandre Lambert and Aakash Soni and Assia Soukane and Amar Ramdane Cherif and Arnaud Rabat},
  doi          = {10.1016/j.neucom.2023.126999},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126999},
  shortjournal = {Neurocomputing},
  title        = {Artificial intelligence modelling human mental fatigue: A comprehensive survey},
  volume       = {567},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scarcity-GAN: Scarce data augmentation for defect detection
via generative adversarial nets. <em>NEUCOM</em>, <em>566</em>, 127061.
(<a href="https://doi.org/10.1016/j.neucom.2023.127061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation is a crucial and challenging task for improving defect detection with limited data. Many generative models have been proposed and shown promising performance on this task. However, existing models are unable to capture the fine features of defects when training data is scarce, resulting in the inability to synthesize defects and a lack of diversity in the synthesized defects. Additionally, most models do not consider the location of synthesized defects in the image, thus limiting the ability for augmenting defect data through data generation. In this paper, we propose a new augmentation model named Scarce Data Augmentation Generative Adversarial Nets (Scarcity-GAN) to address the scarce data augmentation problem. Firstly, we design a new clustering module which selects data containing similar features to the target defect from extra datasets, in order to help the GAN learn the features of the target defect. Secondly, we modify the vanilla generator with an Encoder–Decoder model. The generator takes two inputs: one is the defect-free images, which are encoded by the Encoder to obtain defect-free features, and the other is the extra defect feature maps in the target defect set after clustering. Next, we design a Fusion Patch-Embedding module to merge the two different features, ensuring that the synthesized defects are located on the object accurately. We also design a new loss function for the generator, and then prove that it makes our model get converged. Last, we conduct extensive experiments to demonstrate the significant performance improvement and generalizability of Scarcity-GAN on two scarce datasets: industrial O-ring and Metal Iron Sheet datasets; and one general dataset: the public CODEBRIM dataset. The experimental results show that our Scarcity-GAN outperforms the SOTA augmentation models on different scarce datasets.},
  archive      = {J_NEUCOM},
  author       = {Chaobin Xu and Wei Li and Xiaohui Cui and Zhenyu Wang and Fengling Zheng and Xiaowu Zhang and Bin Chen},
  doi          = {10.1016/j.neucom.2023.127061},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127061},
  shortjournal = {Neurocomputing},
  title        = {Scarcity-GAN: Scarce data augmentation for defect detection via generative adversarial nets},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge distillation for object detection based on
inconsistency-based feature imitation and global relation imitation.
<em>NEUCOM</em>, <em>566</em>, 127060. (<a
href="https://doi.org/10.1016/j.neucom.2023.127060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) is a method that transfers information from a larger network (teacher) to a smaller network (student) to obtain stronger performance without extra computational load . It has made great success in image classification , but only attains trivial improvement in object detection. In this paper, we propose a knowledge distillation scheme for object detection with Inconsistency-Based Feature Imitation (IBFI) and Global Relation Imitation (GRI) schemes. IBFI calculates the difference between the outputs of classification head and regression head to balance the classification and localization abilities of the detector. GRI enables the student to mimic the teacher’s relational information. Extensive experiments have been conducted on popular datasets including MS COCO and PASCAL VOC to validate the effectiveness of our scheme. We achieve 39.9% mAP on MS COCO by using RetinaNet + ResNet-50, which surpasses the baseline by 2.5%.},
  archive      = {J_NEUCOM},
  author       = {Peng Ju and Yi Zhang},
  doi          = {10.1016/j.neucom.2023.127060},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127060},
  shortjournal = {Neurocomputing},
  title        = {Knowledge distillation for object detection based on inconsistency-based feature imitation and global relation imitation},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intent recognition model based on sequential information and
sentence features. <em>NEUCOM</em>, <em>566</em>, 127054. (<a
href="https://doi.org/10.1016/j.neucom.2023.127054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In human–computer dialogue systems , intent recognition is crucial for determining the intentions or purposes of users during interactions with the system, enabling the system to provide appropriate responses or actions. This paper proposes an intent recognition model that integrates sequential information and sentence structural features. Specifically, the approach utilizes a CNN to capture local salient features in the text, followed by a BILSTM to extract sequential information within the local context. The sequential information is then fed into a multi-head attention mechanism to focus on more relevant sequential details. Additionally, the original data is processed by BERT to extract sentence structural features. Finally, the sequential information features and sentence structural features are concatenated and fused to achieve enhanced intent recognition performance. This approach effectively leverages contextual and semantic information within the text, leading to improved accuracy in intent recognition. Experimental results demonstrate the effectiveness of the proposed method in intent recognition and its high relevance for practical applications.},
  archive      = {J_NEUCOM},
  author       = {Tiefeng Wu and Miao Wang and Yunfang Xi and Zhichao Zhao},
  doi          = {10.1016/j.neucom.2023.127054},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127054},
  shortjournal = {Neurocomputing},
  title        = {Intent recognition model based on sequential information and sentence features},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scene graph generation: A comprehensive survey.
<em>NEUCOM</em>, <em>566</em>, 127052. (<a
href="https://doi.org/10.1016/j.neucom.2023.127052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning techniques have led to remarkable breakthroughs in the field of object detection and have spawned a lot of scene-understanding tasks in recent years. Scene graph has been the focus of research because of its powerful semantic representation and applications to scene understanding. Scene Graph Generation (SGG) refers to the task of automatically mapping an image or a video into a semantic structural scene graph, which requires the correct labeling of detected objects and their relationships. In this paper, a comprehensive survey of recent achievements is provided. This survey attempts to connect and systematize the existing visual relationship detection methods, to summarize, and interpret the mechanisms and the strategies of SGG in a comprehensive way. Deep discussions about current existing problems and future research directions are given at last. This survey will help readers to develop a better understanding of the current researches.},
  archive      = {J_NEUCOM},
  author       = {Hongsheng Li and Guangming Zhu and Liang Zhang and Youliang Jiang and Yixuan Dang and Haoran Hou and Peiyi Shen and Xia Zhao and Syed Afaq Ali Shah and Mohammed Bennamoun},
  doi          = {10.1016/j.neucom.2023.127052},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127052},
  shortjournal = {Neurocomputing},
  title        = {Scene graph generation: A comprehensive survey},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic review of image-level camouflaged object
detection with deep learning. <em>NEUCOM</em>, <em>566</em>, 127050. (<a
href="https://doi.org/10.1016/j.neucom.2023.127050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged object detection (COD) aims to search and identify disguised objects that are hidden in their surrounding environment, thereby deceiving the human visual system . As an interesting and challenging task, COD has received increasing attention from the community in the past few years, especially for image-level camouflaged object segmentation task . So far, some advanced image-level COD models have been proposed, mainly dominated by deep learning-based solutions. To have an in-depth understanding of existing image-level COD methods in the deep learning era, in this paper, we give a comprehensive review on model structure and paradigm classification, public benchmark datasets, evaluation metrics , model performance benchmark, and potential future development directions. Specifically, we first review 96 existing deep COD algorithms . Subsequently, we summarize and analyze the existing five widely used COD datasets and evaluation metrics. Furthermore, we benchmark a set of representative models and provide a detailed analysis of the comparison results from both quantitative and qualitative perspectives. Moreover, we further discuss the challenges of COD and the corresponding solutions. Finally, based on the understanding of this field, future development trends and potential research directions are prospected. In conclusion, the purpose of this paper is to provide researchers with a review of the latest COD methods, increase their understanding of COD research, and gain some enlightenment.},
  archive      = {J_NEUCOM},
  author       = {Yanhua Liang and Guihe Qin and Minghui Sun and Xinchao Wang and Jie Yan and Zhonghan Zhang},
  doi          = {10.1016/j.neucom.2023.127050},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127050},
  shortjournal = {Neurocomputing},
  title        = {A systematic review of image-level camouflaged object detection with deep learning},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Torchosr — a PyTorch extension package for open set
recognition models evaluation in python. <em>NEUCOM</em>, <em>566</em>,
127047. (<a href="https://doi.org/10.1016/j.neucom.2023.127047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article presents the torchosr module – a Python package compatible with PyTorch library – offering functionality and models dedicated to Open Set Recognition in Deep Neural Networks . Included software offers two frequently used base recognition methods in the field and a set of functions for handling datasets, enabling the generation of derived datasets, where some classes are considered unknown and used only in the testing process. Code base is enhanced with a set of helper functions, facilitating model validation process. The main goal of the proposal is to simplify and promote the correct experimental evaluation, where experiments are carried out on a large number of derivative sets with various Openness , related to the cardinality of known and unknown classes, and class-to-category assignments. The authors hope that methods available in the package will become a source of a correct and open-source implementation of the relevant baseline and state-of-the-art solutions in the domain.},
  archive      = {J_NEUCOM},
  author       = {Joanna Komorniczak and Paweł Ksieniewicz},
  doi          = {10.1016/j.neucom.2023.127047},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127047},
  shortjournal = {Neurocomputing},
  title        = {Torchosr — A PyTorch extension package for open set recognition models evaluation in python},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time quasi-synchronization of multi-layer
heterogeneous networks with distributed hybrid control. <em>NEUCOM</em>,
<em>566</em>, 127046. (<a
href="https://doi.org/10.1016/j.neucom.2023.127046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the finite-time quasi-synchronization of a multi-layer heterogeneous network with a leader node is studied. A novel distributed control approach that incorporates impulsive control is introduced to achieve finite-time quasi-synchronization of the whole network. The control protocol is distributed, the impulses are synchronized, and the maximum time interval of impulses is bounded. Within this framework and based on the maximum impulsive interval, a finite-time quasi-synchronization criterion for the multi-layer heterogeneous network is established. A close relationship between the settling time and the maximum impulsive interval is discovered. Simulations are shown for illustration and verification.},
  archive      = {J_NEUCOM},
  author       = {Jiashuo Sun and Linying Xiang},
  doi          = {10.1016/j.neucom.2023.127046},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127046},
  shortjournal = {Neurocomputing},
  title        = {Finite-time quasi-synchronization of multi-layer heterogeneous networks with distributed hybrid control},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relphormer: Relational graph transformer for knowledge graph
representations. <em>NEUCOM</em>, <em>566</em>, 127044. (<a
href="https://doi.org/10.1016/j.neucom.2023.127044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformers have achieved remarkable performance in widespread fields, including natural language processing , computer vision and graph mining. However, vanilla Transformer architectures have not yielded promising improvements in the Knowledge Graph (KG) representations, where the translational distance paradigm dominates this area. Note that vanilla Transformer architectures struggle to capture the intrinsically heterogeneous structural and semantic information of knowledge graphs. To this end, we propose a new variant of Transformer for knowledge graph representations dubbed Relphormer. Specifically, we introduce Triple2Seq which can dynamically sample contextualized sub-graph sequences as the input to alleviate the heterogeneity issue. We propose a novel structure-enhanced self-attention mechanism to encode the relational information and keep the semantic information within entities and relations. Moreover, we utilize masked knowledge modeling for general knowledge graph representation learning , which can be applied to various KG-based tasks including knowledge graph completion, question answering, and recommendation. Experimental results on six datasets show that Relphormer can obtain better performance compared with baselines. 2},
  archive      = {J_NEUCOM},
  author       = {Zhen Bi and Siyuan Cheng and Jing Chen and Xiaozhuan Liang and Feiyu Xiong and Ningyu Zhang},
  doi          = {10.1016/j.neucom.2023.127044},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127044},
  shortjournal = {Neurocomputing},
  title        = {Relphormer: Relational graph transformer for knowledge graph representations},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adjustable privacy using autoencoder-based learning
structure. <em>NEUCOM</em>, <em>566</em>, 127043. (<a
href="https://doi.org/10.1016/j.neucom.2023.127043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inference centers need more data to have a more comprehensive and beneficial learning model, and for this purpose, they need to collect data from data providers. On the other hand, data providers are cautious about delivering their datasets to inference centers in terms of privacy considerations. In this paper, by modifying the structure of the autoencoder , we present a method that manages the utility-privacy trade-off well. To be more precise, the data is first compressed using the encoder, then confidential and non-confidential features are separated and uncorrelated using the classifier . The confidential feature is appropriately combined with noise, and the non-confidential feature is enhanced, and at the end, data with the original data format is produced by the decoder. The suggested architecture additionally enables data providers to modify the degree of privacy needed for private features and the level of utility for non-private features. The proposed method has been examined for both image and categorical databases, and the results show a significant performance improvement compared to previous methods.},
  archive      = {J_NEUCOM},
  author       = {Mohammad A. Jamshidi and Hadi Veisi and Mohammad M. Mojahedian and Mohammad R. Aref},
  doi          = {10.1016/j.neucom.2023.127043},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127043},
  shortjournal = {Neurocomputing},
  title        = {Adjustable privacy using autoencoder-based learning structure},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). WSNMF: Weighted symmetric nonnegative matrix factorization
for attributed graph clustering. <em>NEUCOM</em>, <em>566</em>, 127041.
(<a href="https://doi.org/10.1016/j.neucom.2023.127041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, Symmetric Nonnegative Matrix Factorization (SNMF), a derivative of Nonnegative Matrix Factorization (NMF), has surfaced as a promising technique for graph clustering . Nevertheless, when applied to attributed graph clustering, it confronts notable challenges. These include the disregard for attributed information, the oversight of geometric data point structures, and the inability to discriminate irrelevant features and data outliers. In response, we introduce an innovative extension of SNMF termed Weighted Symmetric Nonnegative Matrix Factorization (WSNMF). This method introduces node attribute similarity to compute a weight matrix, effectively bridging the gap for attributed graph clustering. Our approach incorporates graph regularization and sparsity constraints to uphold the geometric structure of data points and discern irrelevant features and data outliers. Additionally, we present an updating rule to address optimization complexities and validate algorithmic convergence. Rigorous experimentation on real-world and synthetic networks, employing well-established metrics including F-measure, RI, Modularity, Density, and entropy, substantiates the performance enhancement offered by WSNMF.},
  archive      = {J_NEUCOM},
  author       = {Kamal Berahmand and Mehrnoush Mohammadi and Razieh Sheikhpour and Yuefeng Li and Yue Xu},
  doi          = {10.1016/j.neucom.2023.127041},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127041},
  shortjournal = {Neurocomputing},
  title        = {WSNMF: Weighted symmetric nonnegative matrix factorization for attributed graph clustering},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AGCL: Adaptive graph contrastive learning for graph
representation learning. <em>NEUCOM</em>, <em>566</em>, 127019. (<a
href="https://doi.org/10.1016/j.neucom.2023.127019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised graph representation learning has attracted great attention as it can learn low-dimensional and compact node embeddings from high-dimensional and sparse graph data without labels. However, two major drawbacks exist in most previous methods, i.e., limited applications of the global graph structure and the problem of the false-negative samples. To address the above problems, we propose a novel Adaptive Graph Contrastive Learning (AGCL) method that utilizes multiple graph filters to capture both the local and the global view information and propose a novel adaptive graph contrastive learning framework to alleviate the false-negative sample problem. AGCL first utilizes a Graph Convolution Network (GCN) filter and our designed Diffusion-based filters to smooth the initial node features. Then, AGCL measures the node pair similarity and then iteratively selects the similar and the dissimilar node pairs as the positive and the negative samples to do the graph contrastive learning. Finally, AGCL leverages various aggregators to obtain node embeddings from multiple views. In addition, we further propose AGCL-Light which can reduce the complexity of updating the training samples , which pre-selects a similar node subset for each node for the subsequent updates. Extensive experiments on nine benchmark datasets demonstrate that our models outperform previous state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Jiajun Yu and Adele Lu Jia},
  doi          = {10.1016/j.neucom.2023.127019},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127019},
  shortjournal = {Neurocomputing},
  title        = {AGCL: Adaptive graph contrastive learning for graph representation learning},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Link prediction in bipartite networks via effective
integration of explicit and implicit relations. <em>NEUCOM</em>,
<em>566</em>, 127016. (<a
href="https://doi.org/10.1016/j.neucom.2023.127016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction in bipartite networks aims to identify or predict possible links between nodes of different types based on known network information. However, most existing studies predominantly focus on monopartite networks, neglecting the intrinsic properties unique to bipartite networks, such as the intricate high-order relationships between nodes. Both explicit relations (representing low-order information) and implicit relations (representing high-order information) play essential roles in predicting the evolution of bipartite networks, and they are indispensable and mutually reinforce each other. To fully leverage their potential in addressing the link prediction problem, we propose a novel framework from the perspective of network representation. This framework not only effectively integrates explicit relations and implicit relations, but also preserves the local and global structure of bipartite networks. Specifically, the probability of a link between two nodes of different types is determined by the linear sum of the contribution values of the mutually connected nodes in their respective common neighbors. Implicit relations are then used to preserve the local structure during the network representation. Furthermore, we implement optimization using a relaxed majorization-minimization algorithm, offering the advantage of uncovering high-quality local minima. Our proposed framework has undergone extensive testing on eight real-world datasets, and the results unequivocally demonstrate its significant superiority over state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xue Chen and Chaochao Liu and Xiaobo Li and Ying Sun and Wei Yu and Pengfei Jiao},
  doi          = {10.1016/j.neucom.2023.127016},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127016},
  shortjournal = {Neurocomputing},
  title        = {Link prediction in bipartite networks via effective integration of explicit and implicit relations},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust learning of parsimonious deep neural networks.
<em>NEUCOM</em>, <em>566</em>, 127011. (<a
href="https://doi.org/10.1016/j.neucom.2023.127011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a simultaneous learning and pruning algorithm capable of identifying and eliminating irrelevant structures in a neural network during the early stages of training. Simultaneous learning and pruning presents serious challenges such as premature pruning of units that can lead to poor performance. Our method is capable of overcoming such challenges and is robust, i.e., it gives consistent pruning levels and prediction accuracy regardless of weight initialization or the size of the starting network. Thus, it allows for substantial computational cost savings during training, besides that of inference, and it can enable the training of very deep networks when transfer learning to obtain fully trained deep networks that can be pruned after training is not possible. Our approach is based on variational inference principles using Gaussian scale mixture priors on the neural network weights. The variational posterior distribution of Bernoulli random variables multiplying the units/filters is learned, similarly to adaptive dropout. We construct a novel hyper-prior distribution over the prior parameters to impose properties crucial for their optimal selection and the overall robustness of our algorithm. It is shown in the context of our algorithm that the parameters of the posterior distributions practically converge to either 0 or 1, establishing a deterministic final network. Convergence is proved analytically based on dynamical systems theory and from the theoretical results, practical pruning conditions are established. The proposed algorithm is evaluated on the MNIST, CIFAR-10 and ImageNet data sets and the commonly used fully connected, convolutional and residual architectures LeNet, VGG16 and ResNet . The simulations show that our method typically achieves better pruning levels while maintaining test-accuracy on par with state-of the-art methods for structured pruning in a manner robust with respect to network initialization and initial size.},
  archive      = {J_NEUCOM},
  author       = {Valentin Frank Ingmar Guenter and Athanasios Sideris},
  doi          = {10.1016/j.neucom.2023.127011},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127011},
  shortjournal = {Neurocomputing},
  title        = {Robust learning of parsimonious deep neural networks},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SFAMNet: A scene flow attention-based micro-expression
network. <em>NEUCOM</em>, <em>566</em>, 126998. (<a
href="https://doi.org/10.1016/j.neucom.2023.126998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tremendous progress has been made in facial Micro-Expression (ME) spotting and recognition; however, most works have focused on either spotting or recognition tasks on the 2D videos. Until recently, the estimation of the 3D motion field ( a.k.a scene flow) for the ME has only become possible after the release of the multi-modal ME dataset. In this paper, we propose the first Scene Flow Attention-based Micro-expression Network, namely SFAMNet. It takes the scene flow computed using the RGB-D flow algorithm as the input and predicts the spotting confidence score and emotion labels. Specifically, SFAMNet is an attention-based end-to-end multi-stream multi-task network devised to spot and recognize the ME. Besides that, we present a data augmentation strategy to alleviate the small sample size problem during network learning. Extensive experiments are performed on three tasks: (i) ME spotting; (ii) ME recognition; and (iii) ME analysis on the multi-modal CAS(ME) 3 3 dataset. Empirical results indicate that depth is vital in capturing the ME information and the effectiveness of the proposed approach. Our source code is publicly available at https://github.com/genbing99/SFAMNet .},
  archive      = {J_NEUCOM},
  author       = {Gen-Bing Liong and Sze-Teng Liong and Chee Seng Chan and John See},
  doi          = {10.1016/j.neucom.2023.126998},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126998},
  shortjournal = {Neurocomputing},
  title        = {SFAMNet: A scene flow attention-based micro-expression network},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated detection of vertebral fractures from x-ray
images: A novel machine learning model and survey of the field.
<em>NEUCOM</em>, <em>566</em>, 126946. (<a
href="https://doi.org/10.1016/j.neucom.2023.126946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vertebral fractures are a common problem and the most prevalent of thoracolumbar compression and burst fractures. However, vertebral fractures are difficult to diagnose: an experienced orthopedist or radiologist is required to detect and determine the type of vertebral fracture. Thus, artificial intelligence methods for diagnosing vertebral fractures are clinically useful. On the basis of a review of 12 studies in the literature, the earliest of which was published in 2020, we propose a machine learning model that detects and determines the type of vertebral fracture on the basis of X-ray data. In this method, YOLOv4 and ResUNet are used to segment vertebral bodies from X-ray images. In evaluation experiments, our method had a precision of 99%, 74%, and 94% in identifying healthy vertebrae, compression fractures, and burst fractures, respectively.},
  archive      = {J_NEUCOM},
  author       = {Li-Wei Cheng and Hsin-Hung Chou and Yu-Xuan Cai and Kuo-Yuan Huang and Chin-Chiang Hsieh and Po-Lun Chu and I-Szu Cheng and Sun-Yuan Hsieh},
  doi          = {10.1016/j.neucom.2023.126946},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126946},
  shortjournal = {Neurocomputing},
  title        = {Automated detection of vertebral fractures from X-ray images: A novel machine learning model and survey of the field},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of coverless steganography. <em>NEUCOM</em>,
<em>566</em>, 126945. (<a
href="https://doi.org/10.1016/j.neucom.2023.126945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the enhancement of people’s security awareness, transmitting secret information securely has gradually become a demand for the public. Steganography is a technology of representing secret information within another carrier, aiming at transmitting secret information without causing suspicion. Most of the traditional steganographic algorithms hide secret information by modifying the statistical characteristics, which will leave traces to the carriers. Although these modifications are too tiny to be distinguished by human eyes, they can be detected by steganalysis algorithms. Differently, coverless steganography, also written as steganography without embedding, accomplish the process of information hiding by constructing the relationship between secret information and carriers. Due to no modification to the carriers, all of the steganalysis algorithms are expired. In this paper, more than 90 papers are included to provide a review in coverless steganographic algorithms, covering the major development process of coverless image and video steganographic algorithms. The main contribution of the existing methods is summarized. Besides, the current general issues of capacity, robustness, and security are discussed adequately for both image and video algorithms. Especially, the security of coverless steganography is discussed for the first time from theoretical analysis to actual investigation in this review.},
  archive      = {J_NEUCOM},
  author       = {Laijin Meng and Xinghao Jiang and Tanfeng Sun},
  doi          = {10.1016/j.neucom.2023.126945},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126945},
  shortjournal = {Neurocomputing},
  title        = {A review of coverless steganography},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). WALLAX: A memristor-based gaussian random number generator.
<em>NEUCOM</em>, <em>566</em>, 126933. (<a
href="https://doi.org/10.1016/j.neucom.2023.126933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating Gaussian random numbers is essential in many applications such as cryptography, games, and computer simulations . Although software Gaussian Random Number Generators (GRNG) are widely used, hardware designs have been explored for their faster speed and lower computational cost. However, hardware GRNGs usually occupy large silicon areas when implemented in Complementary Metal Oxide Semiconductor (CMOS) technology, especially for their essential Uniform Random Number Generator (URNG) part. Here, we present a memristor-based GRNG, named WALLAX, conceived from the Wallace method to generate random numbers iteratively. This GRNG circuit benefits not only from the fully parallel analog-based Vector Matrix Multiplication (VMM) feature of memristive crossbars but also harness the intrinsic stochastic switching behaviour of the memristive devices to efficiently produce truly random numbers. The vector-matrix multiplication of WALLAX is implemented on the memristive crossbar, while its random fetching step is realized by a URNG based on the stochastic switching nature of memristors. WALLAX successfully passes all the tests in the NIST 800-22 randomness test suite with 1 0 5 105 numbers generated and five goodness-of-fit tests with various pool sizes and effectively reduces the power and area consumption by 68.78% and 70.0% compared to digital implementations of the same GRNG method. The impact brought by memristor non-idealities is investigated by simulating the proposed structure with 1000 pools under various scenarios. Wire resistance and the stuck of state, each result in a 2.2% and 12.3% reduction in test pass rate within the tested range, respectively.},
  archive      = {J_NEUCOM},
  author       = {Xuening Dong and Amirali Amirsoleimani and Mostafa Rahimi Azghadi and Roman Genov},
  doi          = {10.1016/j.neucom.2023.126933},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126933},
  shortjournal = {Neurocomputing},
  title        = {WALLAX: A memristor-based gaussian random number generator},
  volume       = {566},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A review of IoT applications in healthcare.
<em>NEUCOM</em>, <em>565</em>, 127017. (<a
href="https://doi.org/10.1016/j.neucom.2023.127017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating Internet of Things (IoT) technologies in the healthcare industry represents a transformative shift with tangible benefits . This paper provides a detailed examination of IoT adoption in healthcare, focusing on specific sensor types and communication methods. It underscores successful real-world applications, including remote patient monitoring, individualized treatment strategies, and streamlined healthcare delivery . Furthermore, it delves into the intricate challenges to realizing the full potential of IoT in healthcare. This includes addressing data security concerns, ensuring seamless interoperability, and optimizing the use of IoT-generated data. The paper seeks to inspire practitioners and researchers by highlighting the practical implications of IoT in healthcare, emphasizing the ways IoT can enhance patient care, resource allocation , and overall healthcare efficiency.},
  archive      = {J_NEUCOM},
  author       = {Chunyan Li and Jiaji Wang and Shuihua Wang‎ and Yudong Zhang},
  doi          = {10.1016/j.neucom.2023.127017},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127017},
  shortjournal = {Neurocomputing},
  title        = {A review of IoT applications in healthcare},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Code smell detection based on supervised learning models: A
survey. <em>NEUCOM</em>, <em>565</em>, 127014. (<a
href="https://doi.org/10.1016/j.neucom.2023.127014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised learning-based code smell detection has become one of the dominant approaches to identify code smell. Existing works optimize the process of code smell detection from multiple aspects, such as high-quality dataset, feature selection, and model, etc. Although the accuracy is improved continuously, researchers are confused about what model are the most suitable ones to detect code smell when considering dataset construction and feature selection. Furthermore, existing surveys for code smell mainly analyze the impact of code smell, categorize the concerns of code smell, and repair code smell. There is a lack of systematic analysis and classification of code smell detection based on supervised learning. To this end, we collect 86 papers of code smell detection based on supervised learning ranging from January 2010 to April 2023. A total of 7 research questions is empirically evaluated from different aspects, such as datasets construction, data pre-processing, feature selection, and model training, etc. We conclude that existing works suffer from issues such as sample imbalance, different attention to types of code smell, and limited feature selection. Finally, we suggest possible future research directions.},
  archive      = {J_NEUCOM},
  author       = {Yang Zhang and Chuyan Ge and Haiyang Liu and Kun Zheng},
  doi          = {10.1016/j.neucom.2023.127014},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127014},
  shortjournal = {Neurocomputing},
  title        = {Code smell detection based on supervised learning models: A survey},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attention round for post-training quantization.
<em>NEUCOM</em>, <em>565</em>, 127012. (<a
href="https://doi.org/10.1016/j.neucom.2023.127012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantization methods for convolutional neural network models can be broadly categorized into post-training quantization (PTQ) and quantization aware training (QAT). While PTQ offers the advantage of requiring only a small portion of the data for quantization, the resulting quantized model may not be as effective as QAT. To address this limitation, this paper proposes a novel quantization function named Attention Round. Unlike traditional quantization function that map 32 bit floating-point value w w to nearby quantization levels , Attention Round allows w w to be mapped to all possible quantization levels in the entire quantization space, expanding the quantization optimization space . The possibilities of mapping w w to different quantization levels are inversely correlated with the distance between w w and the quantization levels, regulated by a Gaussian decay function. Furthermore, to tackle the challenge of mixed precision quantization, this paper introduces a lossy coding length measure to assign quantization precision to different layers of the model, eliminating the need for solving a combinatorial optimization problem . Experimental evaluations on various models demonstrate the effectiveness of the proposed method. Notably, for ResNet18 and MobileNetV2 , the PTQ approach achieves comparable quantization performance to QAT while utilizing only 1024 training data and 10 min for the quantization process .},
  archive      = {J_NEUCOM},
  author       = {Huabin Diao and Gongyan Li and Shaoyun Xu and Chao Kong and Wei Wang},
  doi          = {10.1016/j.neucom.2023.127012},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127012},
  shortjournal = {Neurocomputing},
  title        = {Attention round for post-training quantization},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Neuromorphic imaging and classification with graph
learning. <em>NEUCOM</em>, <em>565</em>, 127010. (<a
href="https://doi.org/10.1016/j.neucom.2023.127010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bio-inspired neuromorphic cameras asynchronously record pixel brightness changes and generate sparse event streams. They can capture dynamic scenes with little motion blur and more details in extreme illumination conditions . Due to the multidimensional address-event structure, most existing vision algorithms cannot properly handle asynchronous event streams. While several event representations and processing methods have been developed to address such an issue, they are typically driven by a large number of events, leading to substantial overheads in runtime and memory. In this paper, we propose a new graph representation of the event data and couple it with a Graph Transformer to perform accurate neuromorphic classification. Extensive experiments show that our approach leads to better results and excels at the challenging realistic situations where only a small number of events and limited computational resources are available, paving the way for neuromorphic applications embedded into mobile facilities.},
  archive      = {J_NEUCOM},
  author       = {Pei Zhang and Chutian Wang and Edmund Y. Lam},
  doi          = {10.1016/j.neucom.2023.127010},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127010},
  shortjournal = {Neurocomputing},
  title        = {Neuromorphic imaging and classification with graph learning},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving robustness for vision transformer with a simple
dynamic scanning augmentation. <em>NEUCOM</em>, <em>565</em>, 127000.
(<a href="https://doi.org/10.1016/j.neucom.2023.127000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision Transformer (ViT) has demonstrated promising performance in computer vision tasks , comparable to state-of-the-art neural networks . Yet, this new type of deep neural network architecture is vulnerable to adversarial attacks limiting its capabilities in terms of robustness. This article presents a novel contribution aimed at further improving the accuracy and robustness of ViT, particularly in the face of adversarial attacks. We propose an augmentation technique called ‘Dynamic Scanning Augmentation’ that leverages dynamic input sequences to adaptively focus on different patches, thereby maintaining performance and robustness. Our detailed investigations reveal that this adaptability to the input sequence induces significant changes in the attention mechanism of ViT, even for the same image. We introduce four variations of Dynamic Scanning Augmentation, outperforming ViT in terms of both robustness to adversarial attacks and accuracy against natural images, with one variant showing comparable results. By integrating our augmentation technique, we observe a substantial increase in ViT’s robustness, improving it from 17% to 92% measured across different types of adversarial attacks. These findings, together with other comprehensive tests, indicate that Dynamic Scanning Augmentation enhances accuracy and robustness by promoting a more adaptive type of attention. In conclusion, this work contributes to the ongoing research on Vision Transformers by introducing Dynamic Scanning Augmentation as a technique for improving the accuracy and robustness of ViT. The observed results highlight the potential of this approach in advancing computer vision tasks and merit further exploration in future studies.},
  archive      = {J_NEUCOM},
  author       = {Shashank Kotyan and Danilo Vasconcellos Vargas},
  doi          = {10.1016/j.neucom.2023.127000},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {127000},
  shortjournal = {Neurocomputing},
  title        = {Improving robustness for vision transformer with a simple dynamic scanning augmentation},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid intelligent modeling approach for predicting the
solar thermal panel energy production. <em>NEUCOM</em>, <em>565</em>,
126997. (<a href="https://doi.org/10.1016/j.neucom.2023.126997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is no doubt that the European Union is undergoing an ecological transition, with renewable energies accounting for an increasing share of energy consumption in the Member States. In Spain, solar energy is one of these rapidly expanding renewable sources. This study analyzes the solar energy production of a panel in the Spanish region of Galicia. It has been demonstrated that the solar energy produced by this panel can be predicted using a hybrid stepwise system. The missing value imputation is a key step in the process. This involves combining regression and clustering techniques on different subdivisions of the complete dataset, starting with a smaller and less complete dataset and performing appropriate imputations to create a larger and more complete collection. Finally, the dataset is divided into more relevant subsets for regression analysis to calculate the amount of solar energy generated. The imputing missing values using an Artificial Neural Network resulted in a more valid dataset for further processing than eliminating rows with corrupted or empty values. Also, properly applying clustering techniques gives better results than working on the whole dataset.},
  archive      = {J_NEUCOM},
  author       = {Ángel Arroyo and Nuño Basurto and Roberto Casado-Vara and Míriam Timiraos and José Luis Calvo-Rolle},
  doi          = {10.1016/j.neucom.2023.126997},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126997},
  shortjournal = {Neurocomputing},
  title        = {A hybrid intelligent modeling approach for predicting the solar thermal panel energy production},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint learning of motion deblurring and defocus deblurring
networks with a real-world dataset. <em>NEUCOM</em>, <em>565</em>,
126996. (<a href="https://doi.org/10.1016/j.neucom.2023.126996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When recovering the sharp image from a blurry observation, moving objects, e.g. , people and vehicles, usually attract more perceptual attention. However, existing motion deblurring methods primarily focus on removing the global camera motion blur, while neglecting the object motion blur. In this paper, we propose a j oint l earning framework for m otion deblurring and d efocus deblurring (JLMD), where a motion deblurring network can be trained for removing object motion blur, and a defocus deblurring network can be also obtained as a byproduct. Especially, we propose to circumvent the hardship in obtaining all-sharp ground truth for object motion blurry images by leveraging the complementary nature between object motion blur and defocus blur. The JLMD framework incorporates three key components. Firstly, a mask generation module is deployed to predict the boundary of motion blur. Secondly, a mutual supervision mechanism is elaborated, which enables the defocus blurry image and the motion blurry image to serve as the ground truth for each other. Thirdly, a content preservation loss is designed to encourage non-blurry regions to stay unchanged. Furthermore, we introduce a Defocus and Motion Deblurring Dataset (DMDD), which is the first real-world dataset specifically dedicated to object motion blurry images. Extensive experiments validate that our method is more effective in removing object motion blur than state-of-the-art methods, while it is at least comparable or superior in removing global camera motion blur and defocus blur. The source code and dataset are available at https://github.com/liyucs/JLMD .},
  archive      = {J_NEUCOM},
  author       = {Yu Li and Xinya Shu and Dongwei Ren and Qince Li and Wangmeng Zuo},
  doi          = {10.1016/j.neucom.2023.126996},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126996},
  shortjournal = {Neurocomputing},
  title        = {Joint learning of motion deblurring and defocus deblurring networks with a real-world dataset},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neuron importance based verification of neural networks via
divide and conquer. <em>NEUCOM</em>, <em>565</em>, 126995. (<a
href="https://doi.org/10.1016/j.neucom.2023.126995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks are widely used in various applications such as image classification , speech recognition and natural language processing . As intelligent systems often rely on neural networks to make critical decisions, it is crucial to ensure that the behavior of a neural network is trustworthy. Along with the increase in the scale and complexity of neural networks, it becomes a challenging problem to verify their safety, since the large-scale state space may make the verification of safety properties infeasible or unsolvable. In order to achieve efficient safety verification of neural networks, this paper proposes a divide-and-conquer verification method based on neuron importance analysis. The method converts the safety constraints to be verified into an optimization problem composed of output neurons, and recursively measures the influence of neurons in the network on the final objective function to calculate their importance. The neurons with the greatest importance are split to refine the constraints, so that the original verification problem is transformed into a set of sub-problems for solution. The method is implemented as a tool named NIAVerify, which is evaluated through experiments of property verification on ReLU-based fully-connected benchmark networks trained on two classic datasets. Experimental results show that NIAVerify can achieve significant state space reduction and the verification efficiency is 44.80% higher than the existing verification method.},
  archive      = {J_NEUCOM},
  author       = {Yansong Dong and Yuehao Liu and Liang Zhao and Cong Tian and Zhenhua Duan},
  doi          = {10.1016/j.neucom.2023.126995},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126995},
  shortjournal = {Neurocomputing},
  title        = {Neuron importance based verification of neural networks via divide and conquer},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aspect category sentiment analysis based on prompt-based
learning with attention mechanism. <em>NEUCOM</em>, <em>565</em>,
126994. (<a href="https://doi.org/10.1016/j.neucom.2023.126994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect category sentiment analysis (ACSA) excels at identifying the aspect categories and corresponding sentiments involved in a sentence, regardless of whether the aspect terms are explicitly mentioned or not. However, current methods tend to overinflate the original data, resulting in the introduction of unnecessary information, and fail to capture the inter-task relationship sufficiently. This paper presents a new method termed the prompt-based joint model (PBJM) to address these complications. PBJM treats the sentiment polarity prediction as binary classification and leverages a natural language prompt template , a concise sentence that guides the model to perform aspect category identification subtask and curtails the need for data augmentation . The two subtasks are jointly trained in pre-trained language models (PLMs) to capture their correlation. Further, the attention mechanism for aspect categories enables the model to concentrate selectively on significant features such as phrases and words during the predictions. In addition, the verbalizer employs a set of parameters to balance the weight of each label word while projecting between the label space and the label words space. Through experiments on four datasets, our model demonstrated remarkable performance in detecting category-sentiment pairs.},
  archive      = {J_NEUCOM},
  author       = {Zhichao Ping and Guoming Sang and Zhi Liu and Yijia Zhang},
  doi          = {10.1016/j.neucom.2023.126994},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126994},
  shortjournal = {Neurocomputing},
  title        = {Aspect category sentiment analysis based on prompt-based learning with attention mechanism},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint specifics and dual-semantic hashing learning for
cross-modal retrieval. <em>NEUCOM</em>, <em>565</em>, 126993. (<a
href="https://doi.org/10.1016/j.neucom.2023.126993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its low memory and computational requirements, hashing techniques are widely applied for cross-modal retrieval. However, there are still two unresolved issues: 1) the class-wise similarity of samples for each modality is not well exploited, and 2) most methods ignore the discriminative capacity of modality-specific information. To solve these two issues, we propose a novel supervised cross-modal hashing method called Joint Specifics and Dual-Semantic Hashing Learning for Cross-Modal Retrieval (SDSHL). SDSHL consists of three methods, i.e., Semantic Embedded Triple Matrix Factorization (SETMF), Modality Specific Dual Semantic Learning (MSDSL) and Modality Consistent Dual Semantic Learning (MCDSL). SETMF utilizes triple matrix factorization to fully explore modality features. MSDSL applies clustering to find the class-wise similarity for each modality, preserving modality-specific information well. MCDSL adopts asymmetric distance-distance difference minimization to capture modality-consistent information among modalities. By using SDSHL, the discrepancies between features and labels are reduced, while both modality-specific and modality-consistent information is well preserved in a shared hash code. Comprehensive experimentation on three benchmark datasets demonstrates the superior performance of SDSHL.},
  archive      = {J_NEUCOM},
  author       = {Shaohua Teng and Shengjie Lin and Luyao Teng and Naiqi Wu and Zefeng Zheng and Lunke Fei and Wei Zhang},
  doi          = {10.1016/j.neucom.2023.126993},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126993},
  shortjournal = {Neurocomputing},
  title        = {Joint specifics and dual-semantic hashing learning for cross-modal retrieval},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic hypergraph convolutional network for multimodal
sentiment analysis. <em>NEUCOM</em>, <em>565</em>, 126992. (<a
href="https://doi.org/10.1016/j.neucom.2023.126992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis (MSA) aims to detect the sentiments from language (text), audio, and visual (facial expressions) modalities. The main challenge in MSA is how to efficiently model intra-modality and inter-modality dynamics. With the advent of graph convolution network (GCN), graph-based models are proposed to solve the challenge. However, general graphs contain only two nodes per edge, which limits the exploitation of high-order interactions. Moreover, current graph-based models mainly aggregate the features of each node during fusion, while the features of connected edges are not well mined. In this paper, we introduce dynamic hypergraph convolution networks to MSA for the first time and propose a Multimodal Dynamic Hypergraph Network (MDH) to learn intra- and inter-modality dynamics. Hypergraphs provide a natural approach to capture transcendental pairwise relations, and their potential for MSA remains unexplored. MDH mainly consists of three components: Unimodal Encoder, Dynamic Hypergraph Enhancement Network (DHEN), and HyperFusion module. Specifically, DHEN is composed of Cross-modal Affine, Hypergraph Construction, and Hypergraph Aggregation modules. As for the intra-modality dynamics, MDH utilizes Hypergraph Construction and Aggregation modules to model the interactions within time steps for each modality. As for the inter-modality dynamics, MDH implements Cross-modal Affine and HyperFusion modules to learn the relationships of the modalities. In addition, multi-task learning has been implemented to optimize the learning process for multimodal tasks. Experiments show that MDH outperforms graph-based models on CMU-MOSI and CMU-MOSEI datasets, as well as obtains new state-of-the-art results on CH-SIMS dataset. Furthermore, we conduct external experiments to explore the effectiveness of MDH and the effect of model depth with different graph networks.},
  archive      = {J_NEUCOM},
  author       = {Jian Huang and Yuanyuan Pu and Dongming Zhou and Jinde Cao and Jinjing Gu and Zhengpeng Zhao and Dan Xu},
  doi          = {10.1016/j.neucom.2023.126992},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126992},
  shortjournal = {Neurocomputing},
  title        = {Dynamic hypergraph convolutional network for multimodal sentiment analysis},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neighborhood multigranulation rough sets for cost-sensitive
feature selection on hybrid data. <em>NEUCOM</em>, <em>565</em>, 126990.
(<a href="https://doi.org/10.1016/j.neucom.2023.126990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a vital preprocessing step in real applications of data mining and machine learning . With the prevalence of high-dimensional hybrid data sets in real-world scenarios, along with the presence of test costs and misclassification costs, the need for effective feature selection methods has become more prominent. However, existing feature selection approaches mainly focus on cost-sensitive data from a single granularity perspective, and they are primarily applicable to single-typed data sets. To address these limitations, this paper presents a novel feature selection approach specifically designed for hybrid data, considering variable test costs and misclassification costs. The proposed method is based on neighborhood multigranulation rough sets (NMRS), which provides more comprehensive and multi-angle data analysis for cost-sensitive hybrid data. First, a novel multigranulation model is developed to effectively process cost-sensitive hybrid data. Building upon this model, a cost-based multi-criteria measure is proposed to evaluate the significance of features. This measure takes into account the comprehensive information of candidate features, including their power in algebraic view, information view, and associated costs. Furthermore, a heuristic feature selection algorithm based on NMRS is proposed to handle hybrid data with the test costs and misclassification costs. This algorithm leverages the benefits of the proposed multigranulation model and cost-based measure to identify the most discriminative features efficiently. Finally, the experimental results on twelve different datasets show that the proposed heuristic algorithm outperforms other compared algorithms, especially in total cost and classification accuracy .},
  archive      = {J_NEUCOM},
  author       = {Wenhao Shu and Qiang Xia and Wenbin Qian},
  doi          = {10.1016/j.neucom.2023.126990},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126990},
  shortjournal = {Neurocomputing},
  title        = {Neighborhood multigranulation rough sets for cost-sensitive feature selection on hybrid data},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Overlapping community detection using expansion with
contraction. <em>NEUCOM</em>, <em>565</em>, 126989. (<a
href="https://doi.org/10.1016/j.neucom.2023.126989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous disjoint community detection methods have reached the state-of-the-art. Some overlapping community detection methods have been proposed in recent years, but they lack the ability to adjust the degree of overlap while maintaining detection quality. To well handle this issue, we in this paper propose a novel method, namely expansion with contraction method for overlapping community detection (ECOCD). Specifically, ECOCD obtains the disjoint communities through non-negative matrix factorization and proceeds to expansion with contraction process (including the expansion process and the contraction process). In each iteration of the process, we randomly select a community and then continuously conduct the expansion and contraction processes on this community. The former process absorbs nodes by the degree of affiliation that is newly defined, while the latter removes nodes by permanence. Moreover, we theoretically analyze the computational complexity of ECOCD. The advantage of ECOCD is that it is applicable to various networks with different properties by adjusting the degree of overlap, and enjoys high quality of overlapping community detection as well. Our experiments on both synthetic and real-world networks further verify this. Extensive experiments show that ECOCD is superior to the eleven state-of-the-art overlapping community detection methods in terms of four metrics, validating the effectiveness, efficiency and robustness of ECOCD.},
  archive      = {J_NEUCOM},
  author       = {Zhijian Zhuo and Bilian Chen and Shenbao Yu and Langcai Cao},
  doi          = {10.1016/j.neucom.2023.126989},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126989},
  shortjournal = {Neurocomputing},
  title        = {Overlapping community detection using expansion with contraction},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spiking neural network with plasticity in the time domain
recovers temporal information from a noisy pattern using reference
spikes. <em>NEUCOM</em>, <em>565</em>, 126988. (<a
href="https://doi.org/10.1016/j.neucom.2023.126988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurons in the brain communicate with each other by sending trains of spikes that can encode information using the timings of the spikes. Spiking Neural Networks (SNNs) are biologically plausible neural networks that can model this transfer of information and that, by incorporating plasticity, can detect repeating patterns that may be embedded in a train of spikes with a noisy background. Although existing model networks are capable of learning to detect the occurrence of repeated patterns, they are not tailored to recover the entirety of the time sequence of the spikes in the pattern. Here we present a network that, in addition to typical parameters of plasticity such as weights and time delays , uses a new plasticity on the time domain that can recover most of the spikes in a pattern. This new plasticity acts by modifying the timings of reference spikes that come from a hypothesized upstream network that could potentially encode preexisting memories. The model is shown to be robust under several noise perturbation scenarios, and its overall performance demonstrates the benefits of using reference spikes to improve the temporal information processing ability of SNNs.},
  archive      = {J_NEUCOM},
  author       = {Zeyuan Wang and Luis Cruz},
  doi          = {10.1016/j.neucom.2023.126988},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126988},
  shortjournal = {Neurocomputing},
  title        = {Spiking neural network with plasticity in the time domain recovers temporal information from a noisy pattern using reference spikes},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Personalized robotic control via constrained multi-objective
reinforcement learning. <em>NEUCOM</em>, <em>565</em>, 126986. (<a
href="https://doi.org/10.1016/j.neucom.2023.126986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning is capable of providing state-of-art performance in end-to-end robotic control tasks. Nevertheless, many real-world control tasks necessitate the balancing of multiple conflicting objectives while simultaneously ensuring that the learned policies adhere to constraints. Additionally, individual users may typically prefer to explore the personalized and diversified robotic control modes via specific preferences. Therefore, this paper presents a novel constrained multi-objective reinforcement learning algorithm for personalized end-to-end robotic control with continuous actions, allowing a trained single model to approximate the Pareto optimal policies for any user-specified preferences. The proposed approach is formulated as a constrained multi-objective Markov decision process , incorporating a nonlinear constraint design to facilitate the agent in learning optimal policies that align with specified user preferences across the entire preference space. Meanwhile, a comprehensive index based on hypervolume and entropy is presented to measure the convergence, diversity and evenness of the learned control policies. The proposed scheme is evaluated on nine multi-objective end-to-end robotic control tasks with continuous action space, and its effectiveness is demonstrated in comparison with the competitive baselines, including classical and state-of-the-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Xiangkun He and Zhongxu Hu and Haohan Yang and Chen Lv},
  doi          = {10.1016/j.neucom.2023.126986},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126986},
  shortjournal = {Neurocomputing},
  title        = {Personalized robotic control via constrained multi-objective reinforcement learning},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 3D-KCPNet: Efficient 3DCNNs based on tensor mapping theory.
<em>NEUCOM</em>, <em>565</em>, 126985. (<a
href="https://doi.org/10.1016/j.neucom.2023.126985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the deep neural networks (DNNs) with satisfied expression ability usually require large scale to gain adequate performance, and deploying large-scale DNNs on resource-limited environments is still a challenge, neural network compression becomes a hot topic nowadays. Among the multiple compression methods, tensor decomposition reveals many specific advantages, such as regular data structure comes from linear algebra, convenient approach of training from scratch, ideal compression ratio, etc. Nevertheless, for some compact neural modules such as two-dimensional/three-dimensional (2D/3D) convolutional kernels, traditional tensor decomposition in the way of approximation has encountered intractable obstacles. Fortunately, some works utilize the tensor mapping approach, which just regards the data structure of tensor decomposition as neural layers, to reconstruct the convolutional kernel into a new lightweight module with several thinner convolutional kernels. The only two flies in the ointment are there lack necessary theories of tensor mapping, and there is still no tensor mapping way to compress high-order three-dimensional convolutional neural networks (3DCNNs). In this paper, we first deeply analyze the tensor mapping theory including convergence and precision, which separately establishes the rationality of tensor mapping and its superiority over the traditional tensor approximation, according to the Lottery Ticket Hypothesis. Then we propose an efficient method termed as 3D-KCPNet, to compress 3DCNNs based on the novel Kronecker canonical polyadic (KCP) tensor decomposition. The proposed method can not only compress the 3D convolutional kernels, but also convert a 3D convolution to efficient 1 × 1 × 1 and 2D depthwise convolutions. The experiments on the video recognition datasets VIVA Challenge, UCF11, UCF50, and UCF101 show that the accuracy of 3D-KCPNet can surpass its original baseline model and the corresponding tensor approximation model.},
  archive      = {J_NEUCOM},
  author       = {Rui Lv and Dingheng Wang and Jiangbin Zheng and Zhao-Xu Yang},
  doi          = {10.1016/j.neucom.2023.126985},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126985},
  shortjournal = {Neurocomputing},
  title        = {3D-KCPNet: Efficient 3DCNNs based on tensor mapping theory},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A framework-based transformer and knowledge distillation for
interior style classification. <em>NEUCOM</em>, <em>565</em>, 126972.
(<a href="https://doi.org/10.1016/j.neucom.2023.126972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interior style classification is an interesting problem which has potential applications both commercial and academic communities. This task aims to devise interior design styles automatically. Thus, interior designers will explore customers’ tastes and then precisely provide suggestions for decor inspiration based on their preferences. Recently, Convolutional Neural Networks (CNNs) have been considered the de-facto standard in computer vision tasks . Therefore, several current works have tended to address interior style classification using CNN-based architectures. Moreover, transformer-based architectures and attention-based encoder–decoder models have been proven successfully in computer vision and natural language processing tasks . Sequentially, more studies have been arguing the efficiency of combining CNN-based architectures and transformer-based architectures for normal image classification problems. In this project, we focus on finding an architecture network that is suitable for the interior style classification problem. We propose a robustness method to address interior style design classification, named ISC-DeIT. The proposed method is based on Data-efficient image transformer architectures and knowledge distillation , which can be trained on small datasets effectively. Especially, a proposed additional module is plugged to leverage learning feature representations for improving predictive accuracy . Experiments were carried out on a new curated dataset with five interior styles including Art-Decor, Hitech, Indochina, Industrial, and Scandinavian. Empirical results of ISC- DeiT indicated that the ability of prediction for interior style classification of the proposed method has been increased significantly, compared with other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Anh H. Vo and Bao T. Nguyen},
  doi          = {10.1016/j.neucom.2023.126972},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126972},
  shortjournal = {Neurocomputing},
  title        = {A framework-based transformer and knowledge distillation for interior style classification},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revisiting pretraining for semi-supervised learning in the
low-label regime. <em>NEUCOM</em>, <em>565</em>, 126971. (<a
href="https://doi.org/10.1016/j.neucom.2023.126971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning (SSL) addresses the lack of labeled data by exploiting large unlabeled data through pseudolabeling. However, in the extremely low-label regime, pseudo labels could be incorrect, a.k.a. the confirmation bias, and the pseudo labels will in turn harm the network training. Recent studies combined finetuning (FT) from pretrained weights with SSL to mitigate the challenges and claimed superior results in the low-label regime. In this work, we first show that the better pretrained weights brought in by FT account for the state-of-the-art performance, and importantly that they are universally helpful to off-the-shelf semi-supervised learners. We further argue that direct finetuning from pretrained weights is suboptimal due to covariate shift and propose a contrastive target pretraining step to adapt model weights towards target dataset. We carried out extensive experiments on both classification and segmentation tasks by doing target pretraining then followed by semi-supervised finetuning. The promising results validate the efficacy of target pretraining for SSL, in particular in the low-label regime.},
  archive      = {J_NEUCOM},
  author       = {Xun Xu and Jingyi Liao and Lile Cai and Manh Cuong Nguyen and Kangkang Lu and Wanyue Zhang and Yasin Yazici and Chuan Sheng Foo},
  doi          = {10.1016/j.neucom.2023.126971},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126971},
  shortjournal = {Neurocomputing},
  title        = {Revisiting pretraining for semi-supervised learning in the low-label regime},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unified view of multi-grade fuzzy-set models in j-CO-QL+.
<em>NEUCOM</em>, <em>565</em>, 126968. (<a
href="https://doi.org/10.1016/j.neucom.2023.126968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity of reality has driven the evolution of Fuzzy-Set Theory from the initial proposal made by Zadeh in 1965, towards more complex models. Moving from a quick survey of the evolution of Fuzzy-Set Theory, this paper highlights the aspects that are common to many Fuzzy-Set Models, in order to define a meta-model that is capable of providing a unified view to a wide variety of fuzzy-set models. In particular, this work focuses the attention on the family of “Multi-grade Fuzzy Sets”, which are fuzzy sets characterized by more than one degree. The lack of tools capable of querying the large amount of data that are nowadays available in NoSQL databases, has pushed us to devise the J-CO Framework: it is a platform-independent tool that is capable to manage, transform and query collections of JSON documents; the J-CO Framework relies on J-CO-QL + , which is a high-level, general-purpose language with soft-querying capabilities. The latest advancements of J-CO-QL + allow for defining and exploiting user-defined Multi-grade Fuzzy-Set Models and Operators. In the paper, a case-study demonstrates the effectiveness of the J-CO Framework in performing a non-trivial soft query based on a Multi-grade Fuzzy-Set Model defined by the user.},
  archive      = {J_NEUCOM},
  author       = {Paolo Fosci and Giuseppe Psaila},
  doi          = {10.1016/j.neucom.2023.126968},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126968},
  shortjournal = {Neurocomputing},
  title        = {A unified view of multi-grade fuzzy-set models in J-CO-QL+},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Credible gaussian sum cubature kalman filter based on
non-gaussian characteristic analysis. <em>NEUCOM</em>, <em>565</em>,
126922. (<a href="https://doi.org/10.1016/j.neucom.2023.126922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Toward the pose estimation problem of unmanned aerial vehicles (UAVs) flight over water, a credible Gaussian-sum cubature Kalman filter (CGSCKF) based on non-Gaussian characteristic analysis for nonlinear non-Gaussian system is proposed. In the framework of the proposed scheme, a data characteristic analysis based on multi-peak distribution degree , skewness and kurtosis is applied to evaluate the non-Gaussian intensity of noise, and a Gaussian mixture reduction (GMR) method based on the improved monarch butterfly optimization (IMBO) is proposed to improve the filtering accuracy in the case of weak non-Gaussian noise (Gaussian-like noise). In addition, considering the problem of inconsistency between the practical and the theoretic system model, the process noise and measurement noise are estimated online, and the credibility of filtering result, which is obtained by Gaussian-sum cubature Kalman filter (GSCKF), is measured by comparing the filtering error covariance with the true error covariance. Some comparison simulations and experiments with classical algorithms are provided, justifying that the proposed scheme has better performance in the pose estimation of UAV.},
  archive      = {J_NEUCOM},
  author       = {Quanbo Ge and Yang Cheng and Gang Yao and Sheng Chen and Yi Zhu},
  doi          = {10.1016/j.neucom.2023.126922},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126922},
  shortjournal = {Neurocomputing},
  title        = {Credible gaussian sum cubature kalman filter based on non-gaussian characteristic analysis},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). High-compressed deepfake video detection with contrastive
spatiotemporal distillation. <em>NEUCOM</em>, <em>565</em>, 126872. (<a
href="https://doi.org/10.1016/j.neucom.2023.126872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deepfake detection in high-resolution videos has made significant progress in recent years, but detecting high-compressed deepfake videos remains challenging due to the low quality of synthesized videos. Existing video-level approaches fail to fully exploit the spatiotemporal inconsistencies in low-quality high-compressed deepfake videos, leading to poor generalization and robustness. In this work, we propose a Contrastive Spatio-Temporal Distilling (CSTD) approach that leverages spatial-frequency cues and temporal-contrastive alignment to improve high-compressed deepfake video detection. Our approach employs a two-stage spatiotemporal video encoder to fully exploit spatiotemporal inconsistency information. A fine-grained spatial-frequency distillation module is used to retrieve invariant forgery cues in spatial and frequency domains in high-compressed deepfake videos. Additionally, a mutual-information temporal-contrastive distillation module is introduced to enhance the temporal correlated information and transfer the temporal structural knowledge from the teacher model to the student model. We demonstrate the effectiveness and robustness of our method on low-quality high-compressed deepfake videos on public benchmarks against state-of-the-art competitors using extensive experiments and visualizations.},
  archive      = {J_NEUCOM},
  author       = {Yizhe Zhu and Chunhui Zhang and Jialin Gao and Xin Sun and Zihan Rui and Xi Zhou},
  doi          = {10.1016/j.neucom.2023.126872},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126872},
  shortjournal = {Neurocomputing},
  title        = {High-compressed deepfake video detection with contrastive spatiotemporal distillation},
  volume       = {565},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Confidence-based interactable neural-symbolic visual
question answering. <em>NEUCOM</em>, <em>564</em>, 126991. (<a
href="https://doi.org/10.1016/j.neucom.2023.126991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual question answering (VQA) task demands proficiency in processing multi-modal information, and the ability to reason effectively using the information. One promising method for this task is neural-symbolic (NS) learning, which leverages the strengths of both neural network (NN) learning and symbolic reasoning to achieve efficient VQA. However, current NS approaches do not account for the uncertain nature of NN learning and can only provide a single answer to a question without any indication of its confidence, thereby limiting their ability to handle incorrect reasoning. To address this limitation, we propose a confidence-based neural-symbolic (CBNS) approach, which evaluates the confidence of the NN inferences based on uncertainty quantification and makes confidence-based reasoning. The proposed approach comprises three main components: (1) a probabilistic question parser that generates multiple program candidates, each with a corresponding confidence evaluation; (2) a probabilistic scene perception module that provides object-based scene representation and confidence evaluations for each attribute of objects in an image; and (3) a confidence-based program executor that provides answers with confidence evaluations throughout the inference process by leveraging the confidence evaluations of the scene representation and programs. Additionally, we present a data augmentation method to improve the training efficiency of NS learning. The proposed approach allows user interactions and feedback on the weak links based on confidence evaluations. Experiments on CLEVR and GQA datasets demonstrate that the proposed approach was effective in identifying the correctness of predictions and led to a promising performance improvement with a significantly reduced computation cost.},
  archive      = {J_NEUCOM},
  author       = {Yajie Bao and Tianwei Xing and Xun Chen},
  doi          = {10.1016/j.neucom.2023.126991},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126991},
  shortjournal = {Neurocomputing},
  title        = {Confidence-based interactable neural-symbolic visual question answering},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advanced sentence-embedding method considering token
importance based on explainable artificial intelligence and text
summarization model. <em>NEUCOM</em>, <em>564</em>, 126987. (<a
href="https://doi.org/10.1016/j.neucom.2023.126987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although pretrained language models achieve high performance on various natural language processing tasks , they still require further improvements in the sentence embedding task. Many studies have improved performance in this task using pre-trained language models and contrastive learning , but these approaches are limited because they are based on naive average pooling and CLS tokens. Therefore, we propose an advanced sentence-embedding method based on weighted pooling that considers token importance. Specifically, the token importance is calculated by combining an explainable artificial-intelligence module with a text summarization model, and the final sentence embedding is derived through weighted pooling token embedding and token importance. Thus, we derive a sentence embedding that considers both the local information of the token embedding and the global information of the entire sentence. Experimental results reveal that our proposed sentence embedding outperforms other models on both text similarity tasks and text classification . Moreover, the proposed method’s robustness is verified through the results of an ablation study.},
  archive      = {J_NEUCOM},
  author       = {Yuho Cha and Younghoon Lee},
  doi          = {10.1016/j.neucom.2023.126987},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126987},
  shortjournal = {Neurocomputing},
  title        = {Advanced sentence-embedding method considering token importance based on explainable artificial intelligence and text summarization model},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An AER-based spiking convolution neural network system for
image classification with low latency and high energy efficiency.
<em>NEUCOM</em>, <em>564</em>, 126984. (<a
href="https://doi.org/10.1016/j.neucom.2023.126984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural network is used to solve the problems of power consumption and computation requirement of the traditional artificial neural network . This paper proposes an event-driven multilayer spiking convolutional neural network (SCNN) hardware system for the image classification task . The proposed hardware system consists of a microcontroller unit (MCU) and an SCNN processor. Input images are temporally encoded to spike trains in the form of address event representation (AER) by MCU, and sent to the SCNN processor to execute AER-based spike-centric convolution in order to reduce redundant operations and get the classification result efficiently. By rearranging the storage structure of weights of synapses and membrane potential (MP) of spiking neurons, multi-channel parallel MP updating is realized to reduce latency. In addition, FIFOs are inserted between the spiking layers to construct a pipeline structure. The hardware architecture of the proposed system is implemented on the Xilinx ZYNQ-7000 platform. At the operating frequency of 100 MHz, the proposed SCNN processor has a speed of 400classifications/s and 80uJ/inference.},
  archive      = {J_NEUCOM},
  author       = {Yueqi Zhang and Lichen Feng and Hongwei Shan and Liying Yang and Zhangming Zhu},
  doi          = {10.1016/j.neucom.2023.126984},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126984},
  shortjournal = {Neurocomputing},
  title        = {An AER-based spiking convolution neural network system for image classification with low latency and high energy efficiency},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decentralized graph-based multi-agent reinforcement learning
using reward machines. <em>NEUCOM</em>, <em>564</em>, 126974. (<a
href="https://doi.org/10.1016/j.neucom.2023.126974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-agent reinforcement learning (MARL), it is challenging for a collection of agents to learn complex temporally extended tasks. The difficulties lie in computational complexity and how to learn the high-level ideas behind reward functions. We study the graph-based Markov Decision Process (MDP), where the dynamics of neighboring agents are coupled. To learn complex temporally extended tasks, we use a reward machine (RM) to encode each agent’s task and expose reward function internal structures. RM has the capacity to describe high-level knowledge and encode non-Markovian reward functions. We propose a decentralized learning algorithm to tackle computational complexity, called decentralized graph-based reinforcement learning using reward machines (DGRM), that equips each agent with a localized policy, allowing agents to make decisions independently based on the information available to the agents. DGRM uses the actor-critic structure, and we introduce the tabular Q-function for discrete state problems. We show that the dependency of the Q-function on other agents decreases exponentially as the distance between them increases. To further improve efficiency, we also propose the deep DGRM algorithm, using deep neural networks to approximate the Q-function and policy function to solve large-scale or continuous state problems. The effectiveness of the proposed DGRM algorithm is evaluated by three case studies , two wireless communication case studies with independent and dependent reward functions, respectively, and COVID-19 pandemic mitigation. Experimental results show that local information is sufficient for DGRM and agents can accomplish complex tasks with the help of RM. DGRM improves the global accumulated reward by 119% compared to the baseline in the case of COVID-19 pandemic mitigation.},
  archive      = {J_NEUCOM},
  author       = {Jueming Hu and Zhe Xu and Weichang Wang and Guannan Qu and Yutian Pang and Yongming Liu},
  doi          = {10.1016/j.neucom.2023.126974},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126974},
  shortjournal = {Neurocomputing},
  title        = {Decentralized graph-based multi-agent reinforcement learning using reward machines},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic compensator-based near-optimal control for unknown
nonaffine systems via integral reinforcement learning. <em>NEUCOM</em>,
<em>564</em>, 126973. (<a
href="https://doi.org/10.1016/j.neucom.2023.126973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a dynamic compensator-based near-optimal control approach for unknown nonaffine nonlinear systems is developed by using integral reinforcement learning . Since system dynamics is unknown, it is difficult to obtain the optimal control policy via neuro-dynamic programming. To address this problem, a general dynamic compensator is introduced as the virtual control input to augment the unknown nonaffine nonlinear system as a partially unknown affine system. For the augmented system, a novel quadratic value function is designed with the system states, the actual control input and the virtual control input. The optimal control of the augmented system can be regarded as the near-optimal control for the original system since the novel optimal value function is an upper bound of the original optimal value function. In order to avoid the identification of system dynamics, the integral reinforcement learning framework is utilized to derive the optimal control based on the solution of Hamilton–Jacobi–Bellman equation via the critic-only structure. Meanwhile, the weight learning rule of the critic neural network is presented with the experience replay technique to relax the persistence of excitation condition. Moreover, the uniform ultimate boundedness of weight estimation errors and the stability of the closed-loop system are guaranteed by using the Lyapunov’s direct method. Finally, simulation results of two examples demonstrate the effectiveness of the developed dynamic compensator-based near-optimal control method .},
  archive      = {J_NEUCOM},
  author       = {Jinquan Lin and Bo Zhao and Derong Liu and Yonghua Wang},
  doi          = {10.1016/j.neucom.2023.126973},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126973},
  shortjournal = {Neurocomputing},
  title        = {Dynamic compensator-based near-optimal control for unknown nonaffine systems via integral reinforcement learning},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-attention and depthwise separable convolution
network for medical image segmentation. <em>NEUCOM</em>, <em>564</em>,
126970. (<a href="https://doi.org/10.1016/j.neucom.2023.126970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic medical image segmentation method is highly needed to help experts in lesion segmentation . The deep learning technology emerging has profoundly driven the development of medical image segmentation . While U-Net and attention mechanisms are widely utilized in this field, the application of attention, albeit successful in natural scene image segmentation, tends to inflate the number of model parameters and neglects the potential for feature fusion between different convolutional layers . In response to these challenges, we present the Multi-Attention and Depthwise Separable Convolution U-Net (MDSU-Net), designed to enhance feature extraction. The multi-attention aspect of our framework integrates dual attention and attention gates, adeptly capturing rich contextual details and seamlessly fusing features across diverse convolutional layers. Additionally, our encoder integrates a depthwise separable convolution layer , streamlining the model’s complexity without sacrificing its efficacy, ensuring versatility across various segmentation tasks . The results demonstrate that our method outperforms state-of-the-art across three diverse medical image datasets.},
  archive      = {J_NEUCOM},
  author       = {Yuxiang Zhou and Xin Kang and Fuji Ren and Huimin Lu and Satoshi Nakagawa and Xiao Shan},
  doi          = {10.1016/j.neucom.2023.126970},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126970},
  shortjournal = {Neurocomputing},
  title        = {A multi-attention and depthwise separable convolution network for medical image segmentation},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis of synchronous localization systems for UAVs urban
applications. <em>NEUCOM</em>, <em>564</em>, 126969. (<a
href="https://doi.org/10.1016/j.neucom.2023.126969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned-Aerial-Vehicles (UAVs) represent an active research topic over multiple fields for performing inspection, delivery and surveillance applications among other operations. However, achieving the utmost efficiency requires drones to perform these tasks without the need of human intervention, which demands a robust and accurate localization system for achieving a safe and efficient autonomous navigation . Nevertheless, currently used satellite-based localization systems like GPS are insufficient for high-precision applications, especially in harsh scenarios like indoor and deep urban environments. In these contexts, Local Positioning Systems (LPS) have been widely proposed for satisfying the localization requirements of these vehicles. However, the performance of LPS is highly dependent on the actual localization architecture and the spatial disposition of the deployed sensor distribution . Therefore, before the deployment of an extensive localization network, an analysis regarding localization architecture and sensor distribution should be taken into consideration for the task at hand. Nonetheless, no actual study is proposed either for comparing localization architectures or for attaining a solution for the Node Location Problem (NLP), a problem of NP-Hard complexity. Therefore, in this paper, we propose a comparison among synchronous LPS for determining the most suited system for localizing UAVs over urban scenarios. We employ the Cràmer–Rao-Bound (CRB) for evaluating the performance of each localization system, based on the provided error characterization of each synchronous architecture. Furthermore, in order to attain the optimal sensor distribution for each architecture, a Black-Widow-Optimization (BWO) algorithm is devised for the NLP and the application at hand. The results obtained denote the effectiveness of the devised technique and recommend the implementation of Time Difference Of Arrival (TDOA) over Time of Arrival (TOA) systems, attaining up to 47% less localization uncertainty due to the unnecessary synchronization of the target clock with the architecture sensors in the TDOA architecture.},
  archive      = {J_NEUCOM},
  author       = {Javier Díez-González and Rubén Ferrero-Guillén and Paula Verde and Alberto Martínez-Gutiérrez and José-Manuel Alija-Pérez and Hilde Perez},
  doi          = {10.1016/j.neucom.2023.126969},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126969},
  shortjournal = {Neurocomputing},
  title        = {Analysis of synchronous localization systems for UAVs urban applications},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive finite-time prescribed performance tracking control
for hydraulic servo systems with friction compensation. <em>NEUCOM</em>,
<em>564</em>, 126967. (<a
href="https://doi.org/10.1016/j.neucom.2023.126967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hydraulic systems present numerous challenges in the development of high-performance tracking controllers due to their highly nonlinear characteristics and heavy modeling uncertainties. Addressing this issue, this paper presents a friction compensation-based finite-time tracking control strategy with prescribed performance constraints. The system model is first derived, taking into consideration the nonlinear behaviors and potential uncertainties encountered in practical scenarios. Then, an adaptive finite-time prescribed performance controller is synthesized based on the backstepping framework. A novel form of finite-time performance function is introduced to constrain the tracking error, which provides the closed-loop system with a less complex guarantee of finite-time convergence and can also deliver the required transient performance and steady-state accuracy. Additionally, given the impact of uncertainty terms and the difficulty in obtaining the virtual command derivative, we employ neural networks (NNs) to estimate unknown dynamics and introduce command filters to acquire the intermediate signals, simplifying the backstepping control design process. Theoretical analysis indicates that the proposed control strategy can achieve the desired tracking performance and ensure the stability of the entire closed-loop system. Comparative numerical simulations are presented to confirm the usefulness of the suggested approach.},
  archive      = {J_NEUCOM},
  author       = {Yu Wan and Wenlong Yue and Xuehui Gao and Qiang Chen and Ruiyin Xu},
  doi          = {10.1016/j.neucom.2023.126967},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126967},
  shortjournal = {Neurocomputing},
  title        = {Adaptive finite-time prescribed performance tracking control for hydraulic servo systems with friction compensation},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Span-based dependency-enhanced graph convolutional network
for aspect sentiment triplet extraction. <em>NEUCOM</em>, <em>564</em>,
126966. (<a href="https://doi.org/10.1016/j.neucom.2023.126966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect sentiment triplet extraction task detects three elements of fine-grained sentiment analysis from given sentence, including aspect and opinion terms and their sentiment polarity. Existing methods mainly include tagging-based and span-based methods, where the former show defects on handling overlapped triplets, and the latter could theoretically handle all overlapped triplets but lack of tailored inter-word dependency so that suffer from insufficient span semantic. In this paper, we propose a span-based dependency-enhanced graph convolutional network, which leverages contextual semantic and latent dependency to enrich span representations. Specifically, we devise a latent graph convolutional network to emphasize critical inter-word dependencies and cut off redundant connections in a learnable gating manner, improving the information flow during inter-word interaction. In addition, considering the problem of multi-word term sentiment consistency, we detect effective aspect and opinion terms derived from the output of span enumeration, and introduce term-level interactions by coupling, which meanwhile enables our model to deal with various types of triplets including many-to-one and one-to-many overlapped triplets. Extensive experiments over four benchmark datasets verify that the proposed method outperforms all the baselines with an average F1 improvement of up to 6.13%, and meanwhile shows fine interpretability. The experimental results demonstrate that effectively enhancing token-level and term-level interactions can significantly improve the aspect sentiment triplet extraction performance.},
  archive      = {J_NEUCOM},
  author       = {Zhigang Jin and Manyue Tao and Xiaodong Wu and Hao Zhang},
  doi          = {10.1016/j.neucom.2023.126966},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126966},
  shortjournal = {Neurocomputing},
  title        = {Span-based dependency-enhanced graph convolutional network for aspect sentiment triplet extraction},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal bipartite consensus for discrete-time multi-agent
systems with event-triggered mechanism based on adaptive dynamic
programming. <em>NEUCOM</em>, <em>564</em>, 126965. (<a
href="https://doi.org/10.1016/j.neucom.2023.126965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes optimal bipartite consensus issue for discrete-time multi-agent system (DTMAS) using event-triggered control (ETC) and quantized event-triggered control (QETC). Firstly, a novel event-triggered control strategy is introduced along with specific conditions to ensure the stability for DTMAS. Due to the intractability of the Hamilton–Jacobi–Bellman (HJB) equation, through two neural networks (NNs), the value function and optimal control are approximated by the adaptive dynamic programming (ADP) method. The weight matrix of the action neural network is updated only when triggered, while also taking into account the quantization effect of the information. The stability of the weights errors and the convergence of the system dynamic are demonstrated using Lyapunov stability theory. Finally, the practicality of the improved method is confirmed a numerical example .},
  archive      = {J_NEUCOM},
  author       = {Wanli Jin and Huaguang Zhang and Zhongyang Ming},
  doi          = {10.1016/j.neucom.2023.126965},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126965},
  shortjournal = {Neurocomputing},
  title        = {Optimal bipartite consensus for discrete-time multi-agent systems with event-triggered mechanism based on adaptive dynamic programming},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal tracking control for unknown nonlinear systems with
uncertain input saturation: A dynamic event-triggered ADP algorithm.
<em>NEUCOM</em>, <em>564</em>, 126964. (<a
href="https://doi.org/10.1016/j.neucom.2023.126964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to proposing a novel dynamic event-triggered adaptive dynamic programming (ADP) algorithm to tackle the tracking control problem of unknown nonlinear systems with uncertain input saturation. Initially, an augmented system is established to address the investigated optimal tracking control issue with a discounted cost function. An online identifier based on neural networks (NNs) is designed to recover the unknown system dynamics. Furthermore, the controller design consists of two parts, including the optimal control policy for the nominal system and the NN-based feedforward compensator. In particular, the latter leverages adaptive NN techniques to cope with uncertain input constraints which can be deemed as uncertain saturation nonlinearities. A critic NN is constructed to obtain the approximate optimal control policy for the nominal system. Moreover, rather than traditional time-triggered and static event-triggered control schemes, an adaptive dynamic event-triggering condition is designed to determine the system sampling as well as the controller execution to further reduce transmission and computation burden. The introduction of an internal dynamic variable in possession of a positive constant lower bound can realize the dynamic adjustment of triggering threshold and effectively exclude Zeno behavior . Notice that the weights of identifier NN and critic NN are updated simultaneously, only at the event-triggering instants. Subsequently, the Lyapunov-based theoretical analysis is conducted to confirm the uniform ultimate boundedness of the tracking error and all the NN weight estimation errors . Eventually, the feasibility and effectiveness of the developed algorithm are validated by means of two simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Lu Chen and Fei Hao},
  doi          = {10.1016/j.neucom.2023.126964},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126964},
  shortjournal = {Neurocomputing},
  title        = {Optimal tracking control for unknown nonlinear systems with uncertain input saturation: A dynamic event-triggered ADP algorithm},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event-triggered critic learning impedance control of lower
limb exoskeleton robots in interactive environments. <em>NEUCOM</em>,
<em>564</em>, 126963. (<a
href="https://doi.org/10.1016/j.neucom.2023.126963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an event-triggered critic learning impedance control algorithm for a lower limb rehabilitation exoskeleton robot in an interactive environment, where the control objective is specified by a desired impedance model. In comparison to many other traditional impedance controller design algorithms , in this paper, the impedance control problem is transformed into an optimal control problem . Firstly, the interactive environment accounts for the interaction between the exoskeleton, the human, and the environment, and is modeled by a linear time-invariant exogenous system. Secondly, in contrast to time-triggered control design mechanisms, the event-triggered controller is updated only when the system states deviate from prescribed threshold values. To obtain the event-triggered optimal controller, a critic neural network is developed through the framework of reinforcement learning . A modified gradient descent method is introduced to update the weights of the critic network with an additional stable term employed to eliminate the need for an initial admissible control. Meanwhile, with the simultaneous application of historical and transient state data to the critic neural network , the persistent excitation conditions are relaxed. The Lyapunov method is used to rigorously demonstrate the stability of the overall system. Finally, the effectiveness of the proposed algorithm is demonstrated via simulation.},
  archive      = {J_NEUCOM},
  author       = {Yaohui Sun and Zhinan Peng and Jiangping Hu and Bijoy Kumar Ghosh},
  doi          = {10.1016/j.neucom.2023.126963},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126963},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered critic learning impedance control of lower limb exoskeleton robots in interactive environments},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stabilization analysis of incommensurate fractional-order
memristor-based neural networks via delay-dependent distributed
controller. <em>NEUCOM</em>, <em>564</em>, 126962. (<a
href="https://doi.org/10.1016/j.neucom.2023.126962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the stabilization analysis problem of a class of incommensurate fractional-order memristor-based neural networks with multiple time-varying delays (IFOMNNs-MTDs). In previously published studies of IFOMNNs-MTDs, the controller is usually designed as a general delay-independent feedback controller . Due to the simple form of the feedback controller, less system information is used and less adjustable parameters are considered, which limits the flexibility and control effect of controller. Specially, the use of delay information is insufficient in the existing results, which will make the controller insensitive to the influence of delay factors and affect the control performance. Thereby, the accurate analysis of the dynamic characteristics of IFOMNNs-MTDs by designing appropriate controller needs further study. This paper aims to propose a new delay-dependent controller to improve the stabilization analysis of IFOMNNs-MTDs. Firstly, a delay-dependent distributed controller with distributed control gain and time-delay state summation term is proposed, which accords with the transmission law of activation function weights and is helpful to consider the historical information (i.e., time delay factors) of system. Thereby, the flexibility and control effect of controller are improved by adding control parameters and improving the use of system information. Secondly, a new less-conservatism stabilization criterion of IFOMNNs-MTDs is established by using the designed controller. Moreover, the controller gain can be searched in a large range by using the established criterion. Finally, a numerical simulation is provided to verify the validity of the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Shasha Xiao and Zhanshan Wang and Qiufu Wang},
  doi          = {10.1016/j.neucom.2023.126962},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126962},
  shortjournal = {Neurocomputing},
  title        = {Stabilization analysis of incommensurate fractional-order memristor-based neural networks via delay-dependent distributed controller},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scroll and coexisting attractors in a hopfield neural
network under electromagnetic induction and external stimuli.
<em>NEUCOM</em>, <em>564</em>, 126961. (<a
href="https://doi.org/10.1016/j.neucom.2023.126961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of external stimuli to biological neurons is a valuable tool for investigating neuronal properties, understanding neural circuitry , and developing therapeutic interventions for neurological disorders . In this article, we propose a discrete fractional Hopfield neural network model consisting of four neurons to explore the influence of external stimuli in the presence of electromagnetic induction and radiation. To incorporate the electromagnetic induction between connected neurons, we construct and employ a discrete fractional sine memristor . Additionally, we introduce a multi-level pulse function to the sine memristor element to examine the chaotic dynamics of the neural network model. The qualitative behavior of the network model is demonstrated through stability analysis and bifurcation diagrams showcasing chaos. The study also focuses on understanding the coexisting behavior of the neural network model in the presence and absence of external stimuli. Moreover, we investigate the generation of multi-scroll attractors by varying the level of the pulse function, which is introduced to electromagnetic induction. Numerical simulations reveal that increasing the level of the multi-pulse function doubles the number of scrolls in the attractors when external stimuli are present. The findings presented in this article contribute to our understanding of discrete fractional memristors and shed light on the dynamical behavior of neurons and their electrical activity in the brain. Innovation within the discrete fractional-order Hopfield neural networks realm entails the creation and utilization of fresh ideas, methodologies, and strategies that harness fractional-order dynamics to confront diverse hurdles and enhance the effectiveness of Hopfield networks . Discrete fractional-order Hopfield neural networks have the capacity to propel an array of applications forward, spanning artificial intelligence , machine learning , control systems, and optimization, showcasing their potential for substantial progress in various domains.},
  archive      = {J_NEUCOM},
  author       = {D. Vignesh and Jun Ma and Santo Banerjee},
  doi          = {10.1016/j.neucom.2023.126961},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126961},
  shortjournal = {Neurocomputing},
  title        = {Multi-scroll and coexisting attractors in a hopfield neural network under electromagnetic induction and external stimuli},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sequential reversible jump MCMC for dynamic bayesian neural
networks. <em>NEUCOM</em>, <em>564</em>, 126960. (<a
href="https://doi.org/10.1016/j.neucom.2023.126960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenge to automatically design machine learning-based models for datasets with varying dimensions (features) remains open, especially in the context of unstructured and noisy data. Bayesian neural networks employ Markov chain Monte Carlo (MCMC) and variational inference methods for training (sampling) model parameters. However, the progress of MCMC methods in deep learning has been slow due to high computational requirements and uninformative priors of model parameters. Reversible jump MCMC allows sampling of model parameters of variable lengths ; hence, it has the potential to train Bayesian neural networks effectively. In this paper, we implement reversible jump MCMC sampling for training dynamic Bayesian neural networks that feature cascaded neural networks with dynamic hidden and input neurons. Our dynamic Bayesian neural network can model unstructured data of varying dimensions and provide uncertainty quantification in model predictions. We apply the methodology to selected regression and classification problems from the literature. The results show that our method provides an effective approach for the dynamic exploration of models while featuring uncertainty quantification that not only caters to model parameters but also extends to model topology. This opens up the road for uncertainty quantification in dynamic deep learning models for dynamic and unstructured data streams.},
  archive      = {J_NEUCOM},
  author       = {Nhat Minh Nguyen and Minh-Ngoc Tran and Rohitash Chandra},
  doi          = {10.1016/j.neucom.2023.126960},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126960},
  shortjournal = {Neurocomputing},
  title        = {Sequential reversible jump MCMC for dynamic bayesian neural networks},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TFF-CNN: Distributed optical fiber sensing intrusion
detection framework based on two-dimensional multi-features.
<em>NEUCOM</em>, <em>564</em>, 126959. (<a
href="https://doi.org/10.1016/j.neucom.2023.126959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed fiber optic vibration sensing system has been widely used in safety monitoring with distinct advantages, and the feature extraction and classification methods of fiber optic signals directly determine the real-time performance and reliability of the monitoring system . The existing research feature extraction methods are unidimensional and time consuming, which cannot balance the goals of high accuracy and low time consumption for safety monitoring systems. In this paper, we propose an efficient recognition framework for fusing signal time–frequency features, called TFF-CNN, based on Gramian Angular Difference Fields(GADF) and FFT co-generation matrix(FFT T ) to manually extract two-dimensional time–frequency image features of fiber optic signals, taking the significant advantages of CNN in image processing and combining a two-channel model and a fusion module that simulates human decision-making behavior . The accuracy of TFF-CNN is 99.30 % and the detection response time is only 0.6 s. Compared with other methods in this field, TFF-CNN has the advantages of low false alarm rate and short time consumption, which is more suitable for deployment in security monitoring field with distributed fiber optic sensing system. Index Terms : Distributed optical fiber vibration sensing system(DVS), Two-dimensional multi-feature, CNN , intrusion detection, real-time monitoring.},
  archive      = {J_NEUCOM},
  author       = {Xing Hu and Gengjun Qiu and Hamid Reza Karimi and Dawei Zhang},
  doi          = {10.1016/j.neucom.2023.126959},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126959},
  shortjournal = {Neurocomputing},
  title        = {TFF-CNN: Distributed optical fiber sensing intrusion detection framework based on two-dimensional multi-features},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised performance analysis of 3D face alignment with
a statistically robust confidence test. <em>NEUCOM</em>, <em>564</em>,
126941. (<a href="https://doi.org/10.1016/j.neucom.2023.126941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of analyzing the performance of 3D face alignment (3DFA), or facial landmark localization. This task is usually supervised, based on annotated datasets. Nevertheless, in the particular case of 3DFA, the annotation process is rarely error-free, which strongly biases the results. Alternatively, unsupervised performance analysis (UPA) is investigated. The core ingredient of the proposed methodology is the robust estimation of the rigid transformation between predicted landmarks and model landmarks. It is shown that the rigid mapping thus computed is affected neither by non-rigid facial deformations, due to variabilities in expression and in identity, nor by landmark localization errors, due to various perturbations. The guiding idea is to apply the estimated rotation, translation and scale to a set of predicted landmarks in order to map them onto a mathematical home for the shape embedded in these landmarks (including possible errors). UPA proceeds as follows: (i) 3D landmarks are extracted from a 2D face using the 3DFA method under investigation; (ii) these landmarks are rigidly mapped onto a canonical (frontal) pose, and (iii) a statistically-robust confidence score is computed for each landmark. This allows to assess whether the mapped landmarks lie inside (inliers) or outside (outliers) a confidence volume . An experimental evaluation protocol, that uses publicly available datasets and several 3DFA software packages associated with published articles, is described in detail. The results show that the proposed analysis is consistent with supervised metrics and that it can be used to measure the accuracy of both predicted landmarks and of automatically annotated 3DFA datasets, to detect errors and to eliminate them. Source code and supplemental materials for this paper are publicly available at https://team.inria.fr/robotlearn/upa3dfa/ .},
  archive      = {J_NEUCOM},
  author       = {Mostafa Sadeghi and Xavier Alameda-Pineda and Radu Horaud},
  doi          = {10.1016/j.neucom.2023.126941},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126941},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised performance analysis of 3D face alignment with a statistically robust confidence test},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hessian-based zeroing neurodynamic approach for
quaternion-variable time-varying constrained optimization problems.
<em>NEUCOM</em>, <em>564</em>, 126937. (<a
href="https://doi.org/10.1016/j.neucom.2023.126937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a quaternion-variable zeroing neurodynamic (ZND) is designed, in order to address a class of quaternion-variable time-varying convex optimization problems (TCOP) with equality constraints and general inequality constraints . Through utilizing the Karush–Kuhn–Tucker (KKT) condition, the TCOP is transformed into a time-varying equation system for solving. During this process, the introduction of two approaches distinguishes our works in solving TCOPs. On the one hand, the penalty approach is utilized to reduce the influence of time-varying inequality constraints, and thus, makes the ZND more suitable for TCOPs with general and complex inequality constraints. On the other hand, the approach to simplify the KKT condition significantly simplifies the structure of the proposed ZND by reducing the neurons’ number. The proposed ZND realizes efficient convergence while keeping the structure as simple as possible, making it easy to apply in engineering tasks. Besides, to improve its efficiency further, a nonlinear activated function is utilized to achieve a faster convergent rate, by which the convergent rate of the ZND is accelerated to finite-time convergence. Apart from that, the ZND here also owes superior robustness. To the best of our knowledge, this is the first time to extend the ZND for solving TCOP to the quaternion domain. Finally, numerical examples and a robot manipulator control experiment further explain the effectiveness of the proposed ZND.},
  archive      = {J_NEUCOM},
  author       = {Haojin Li and Sitian Qin},
  doi          = {10.1016/j.neucom.2023.126937},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126937},
  shortjournal = {Neurocomputing},
  title        = {A hessian-based zeroing neurodynamic approach for quaternion-variable time-varying constrained optimization problems},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Influence maximization algorithm based on group trust and
local topology structure. <em>NEUCOM</em>, <em>564</em>, 126936. (<a
href="https://doi.org/10.1016/j.neucom.2023.126936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization is one of the important contents of social network analysis . Many classical influence propagation models assume that there is a stable information propagation phenomenon between adjacent users, and do not consider the influence of internal structure information of the network on the actual information propagation. Therefore, an influence maximization algorithm based on group trust and local topology structure is proposed. In order to make full use of the important role of group in information propagation, the concepts of intra-group connectivity, inter-group diffusion and group trust are defined based on the characteristics such as group tightness. Then, an influence propagation algorithm based on the local topological structure of the group is proposed to extract the local structure information of different topological positions in the group, and calculate the propagation probability between users. Finally, the seed nodes were selected according to the credibility ranking of the group for influence propagation. Experiments on multiple data sets show that compared with other algorithms, the algorithm can achieve higher propagation efficiency and wider influence effect, which verifies the rationality and effectiveness of the method.},
  archive      = {J_NEUCOM},
  author       = {Chang Guo and Weimin Li and Fangfang Liu and Kexin Zhong and Xing Wu and Yougang Zhao and Qun Jin},
  doi          = {10.1016/j.neucom.2023.126936},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126936},
  shortjournal = {Neurocomputing},
  title        = {Influence maximization algorithm based on group trust and local topology structure},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hiding from thermal imaging pedestrian detectors in the
physical world. <em>NEUCOM</em>, <em>564</em>, 126923. (<a
href="https://doi.org/10.1016/j.neucom.2023.126923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermal imaging detection has been applied in many scenarios. However, its security has not been fully explored. We propose a physical attack method with small bulbs on a board to fool thermal imaging pedestrian detectors. We first designed an optimized Gaussian-function-based patch that caused the average precision (AP) of YOLOv3 to drop by 64.12% in the digital world, while a patch with randomly placed Gaussian functions and a blank patch caused the AP to drop by only 33.01% and 29.69%, respectively. We then manufactured a physical board and attacked YOLOv3 in the real world. In recorded videos, an optimized physical board caused the AP of YOLOv3 to drop by 34.48%, while a board with randomly placed bulbs and a blank board caused the AP to drop by only 17.06% and 14.91%, respectively. With the ensemble attack techniques, the designed physical board attack had good transferability to unseen CNN-based detectors. Furthermore, we successfully evaded the pedestrian detectors working on both visible light images and thermal images by covering printed adversarial paper on the manufactured board. Finally, we tested five typical methods to defend our bulb-based attack but achieved limited success. The results indicated the effectiveness of the attack method.},
  archive      = {J_NEUCOM},
  author       = {Xiaopei Zhu and Xiao Li and Jianmin Li and Zheyao Wang and Xiaolin Hu},
  doi          = {10.1016/j.neucom.2023.126923},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126923},
  shortjournal = {Neurocomputing},
  title        = {Hiding from thermal imaging pedestrian detectors in the physical world},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Source-free unsupervised domain adaptation: Current research
and future directions. <em>NEUCOM</em>, <em>564</em>, 126921. (<a
href="https://doi.org/10.1016/j.neucom.2023.126921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of Transfer Learning , Source-Free Unsupervised Domain Adaptation (SFUDA) emerges as a practical and novel task that enables a pre-trained model to adapt to a new unlabeled domain without access to the original training data . The advancement of SFUDA has profoundly reshaped the algorithmic design of domain adaptation methods. Given the novelty and limited exploration of SFUDA, conducting a comprehensive survey is imperative to showcase methodological advancements, identify existing gaps, and uncover potential trends in this field. This paper provides an extensive review of SFUDA, encompassing methods and applications. First, based on the learning objectives during adaptation, different SFUDA methods fall into three categories: (i) Self-Tuning , (ii) Feature Alignment , and (iii) Sample Generation , with further sub-categorization within each category. Additionally, the strengths and limitations of each category are discussed, and various application areas where SFUDA can yield significant benefits are summarized. Finally, drawing from extensive observations and insights, potential future directions for SFUDA research are analyzed, with a focus on identifying emerging trends and key areas for further exploration.},
  archive      = {J_NEUCOM},
  author       = {Ningyuan Zhang and Jie Lu and Keqiuyin Li and Zhen Fang and Guangquan Zhang},
  doi          = {10.1016/j.neucom.2023.126921},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126921},
  shortjournal = {Neurocomputing},
  title        = {Source-free unsupervised domain adaptation: Current research and future directions},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intrusion detection for industrial internet of things based
on deep learning. <em>NEUCOM</em>, <em>564</em>, 126886. (<a
href="https://doi.org/10.1016/j.neucom.2023.126886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection technology can actively detect abnormal behaviors in the network and is important to the security of Industrial Internet of Things (IIOT). However, there are some issues with the current intrusion detection technology for IIOT, such as extreme imbalance in the number of samples of different classes in the dataset, redundant and meaningless features in the samples, and the inability of traditional intrusion detection methods to meet the requirements of detection accuracy in the increasingly complex IIOT. In view of the extreme imbalance of classes, this paper applies the hierarchical clustering algorithm to the under-sampling technology, which reduces the number of majority samples while reducing the loss of information of majority samples, and solves the problem of missing detection and false detection of minority samples caused by sample imbalance. In order to avoid feature redundancy and interference, this paper proposes an optimal feature selection algorithm based on greedy thought. This algorithm can obtain the optimal feature subset of each type of data in the data set, thus eliminating redundant and interfering features. Aiming at the problem of insufficient detection ability of traditional detection methods, this paper proposes a deep neural network intrusion detection model based on the parallel connection of global and local subnetworks . This model obtains the overall benchmark detection of the dataset through the deep neural network , and then strengthens the detection effect of each subclass through the parallel connection of subnetworks, greatly improving the performance of the intrusion detection algorithm . The experimental results show that the method described in this paper can improve the intrusion detection for IIOT.},
  archive      = {J_NEUCOM},
  author       = {Yaoyao Lu and Senchun Chai and Yuhan Suo and Fenxi Yao and Chen Zhang},
  doi          = {10.1016/j.neucom.2023.126886},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126886},
  shortjournal = {Neurocomputing},
  title        = {Intrusion detection for industrial internet of things based on deep learning},
  volume       = {564},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fair graph representation learning: Empowering NIFTY via
biased edge dropout and fair attribute preprocessing. <em>NEUCOM</em>,
<em>563</em>, 126948. (<a
href="https://doi.org/10.1016/j.neucom.2023.126948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing complexity and amount of data available in modern applications strongly demand Trustworthy Learning algorithms that can be fed directly with complex and large graphs data. In fact, on one hand, machine learning models must meet high technical standards (e.g., high accuracy with limited computational requirements), but, at the same time, they must be sure not to discriminate against subgroups of the population (e.g., based on gender or ethnicity). Graph Neural Networks (GNNs) are currently the most effective solution to meet the technical requirements , even if it has been demonstrated that they inherit and amplify the biases contained in the data as a reflection of societal inequities. In fact, when dealing with graph data, these biases can be hidden not only in the node attributes but also in the connections between entities. Several Fair GNNs have been proposed in the literature, with uNIfying Fairness and stabiliTY (NIFTY) (Agarwal et al., 2021) being one of the most effective. In this paper, we will empower NIFTY’s fairness with two new strategies. The first one is a Biased Edge Dropout, namely, we drop graph edges to balance homophilous and heterophilous sensitive connections, mitigating the bias induced by subgroup node cardinality . The second one is Attributes Preprocessing, which is the process of learning a fair transformation of the original node attributes. The effectiveness of our proposal will be tested on a series of datasets with increasingly challenging scenarios. These scenarios will deal with different levels of knowledge about the entire graph, i.e., how many portions of the graph are known and which sub-portion is labelled at the training and forward phases.},
  archive      = {J_NEUCOM},
  author       = {Danilo Franco and Vincenzo Stefano D’Amato and Luca Pasa and Nicolò Navarin and Luca Oneto},
  doi          = {10.1016/j.neucom.2023.126948},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126948},
  shortjournal = {Neurocomputing},
  title        = {Fair graph representation learning: Empowering NIFTY via biased edge dropout and fair attribute preprocessing},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing glomeruli segmentation through cross-species
pre-training. <em>NEUCOM</em>, <em>563</em>, 126947. (<a
href="https://doi.org/10.1016/j.neucom.2023.126947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The importance of kidney biopsy, a medical procedure in which a small tissue sample is extracted from the kidney for examination, is increasing due to the rising incidence of kidney disorders. This procedure helps diagnosing several kidney diseases which are cause of kidney function changes, as well as guiding treatment decisions, and evaluating the suitability of potential donor kidneys for transplantation. In this work, a deep learning system for the automatic segmentation of glomeruli in biopsy kidney images is presented. A novel cross-species transfer learning approach, in which a semantic segmentation network is trained on mouse kidney tissue images and then fine-tuned on human data, is proposed to boost the segmentation performance . The experiments conducted using two deep semantic segmentation networks, MobileNet and SegNeXt, demonstrated the effectiveness of the cross-species pre-training approach leading to an increased generalization ability of both models.},
  archive      = {J_NEUCOM},
  author       = {Paolo Andreini and Simone Bonechi and Giovanna Maria Dimitri},
  doi          = {10.1016/j.neucom.2023.126947},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126947},
  shortjournal = {Neurocomputing},
  title        = {Enhancing glomeruli segmentation through cross-species pre-training},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IEFM and IDS: Enhancing 3D environment perception via
information encoding in indoor point cloud semantic segmentation.
<em>NEUCOM</em>, <em>563</em>, 126944. (<a
href="https://doi.org/10.1016/j.neucom.2023.126944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The point cloud semantic segmentation plays a significant role in the understanding of 3D environment. However, current 3D point cloud segmentation methods pay little attention in the inevitable blurring and loss of point information within deep network, which considerably impairs the segmentation performance , particularly in the complex and colorful indoor scenes. To overcome the inevitable loss of point information (position, color and normal vector), in this paper, we propose a brand-new Information Encoding and Fusion Module (IEFM), comprising a point Information Encoding Method (IEM) and an optimized Multi-Encoding Fusion Method (EFM). In terms of constructing the innovative bias standardization of point information and effectively merging other information encodings into position encoding, IEFM adaptively complements the loss of the point information and thereby achieving enhanced environment perception ability. Additionally, although the proposed IEFM is capable of managing multi-class point information, the encoding interference resulting from the coexistence of multiple information is quite unavoidable, leading to detrimental consequences for the overall semantic segmentation performance. Therefore, to reduce the information encoding interference problem, we further innovatively propose the Information Distribution Strategy (IDS), in terms of hierarchically distribute kinds of point information, so that the interference of multiple information encodings will be extremely mitigated and achieving more accurate indoor point cloud semantic segmentation. Benefiting from the modular design, the proposed IEFM and IDS can be easily inserted in existing point-based point cloud segmentation models. The experimental results have shown the effectiveness of our proposed methods across multiple state-of-the-art models and benchmarks (S3DIS and ScanNet), achieving competitive performance of 77.4% mIoU on the large-scale S3DIS benchmark.},
  archive      = {J_NEUCOM},
  author       = {Kaixiang Huang and Jin Wang and Jingru Yang and Ying Yang and Guodong Lu and Yuzhen Chen and Huan Yu and Qifeng Zhang},
  doi          = {10.1016/j.neucom.2023.126944},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126944},
  shortjournal = {Neurocomputing},
  title        = {IEFM and IDS: Enhancing 3D environment perception via information encoding in indoor point cloud semantic segmentation},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Commonsense-based adversarial learning framework for
zero-shot stance detection. <em>NEUCOM</em>, <em>563</em>, 126943. (<a
href="https://doi.org/10.1016/j.neucom.2023.126943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot stance detection (ZSSD) aims to identify the stance for a diverse range of topics with limited or no training data . It is more suitable for evolving real-world topics that are constantly evolving. However, ZSSD faces major challenges which are the lack of unseen target information and the inability to generalize training information to unseen targets effectively. To overcome these challenges, we propose a commonsense-based adversarial learning framework that comprises a commonsense graph encoder and a feature separation adversarial network. Specifically, our approach utilizes an external commonsense graph encoder to learn unseen target information. Moreover, we design a novel feature separation adversarial network to learn target-invariant and target-specific features, which enhances the model’s ability to reason beyond the seen targets. Experiments on two benchmark datasets show that our proposed framework achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Hao Zhang and Yizhou Li and Tuanfei Zhu and Chuang Li},
  doi          = {10.1016/j.neucom.2023.126943},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126943},
  shortjournal = {Neurocomputing},
  title        = {Commonsense-based adversarial learning framework for zero-shot stance detection},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synchronizations control of fractional-order
multidimension-valued memristive neural networks with delays.
<em>NEUCOM</em>, <em>563</em>, 126942. (<a
href="https://doi.org/10.1016/j.neucom.2023.126942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, systems of the fractional-order multidimension-valued memristive neural networks (FMVMNNs) with leakage delay and time-varying delays are studied in continuous-time and discrete-time cases. Comparative studies on synchronizations control between discrete-time FMVMNNs and the continuous-time system are investigated directly rather than through the decomposition method . By employing Lyapunov theory and fractional derivative inequalities, sufficient criteria about the quasi-synchronization and global ultimate Mittag-Leffler lag quasi-synchronization are obtained in multidimension-valued linear matrix inequality form, while succinct conclusions of asymptotical synchronization and global Mittag-Leffler synchronization are derived in vector form. The obtained criteria have many advantages in a less computation, lower conservatism, more generality and higher flexibility. Finally, four examples are given to demonstrate the effectiveness and availability of the derived conclusions.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Mao and Xiaomei Wang and Yuxi Lu and Hongying Qin},
  doi          = {10.1016/j.neucom.2023.126942},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126942},
  shortjournal = {Neurocomputing},
  title        = {Synchronizations control of fractional-order multidimension-valued memristive neural networks with delays},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ReSLAM: Reusable SLAM with heterogeneous cameras.
<em>NEUCOM</em>, <em>563</em>, 126940. (<a
href="https://doi.org/10.1016/j.neucom.2023.126940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art SLAM methods are designed to work only with the type of camera employed to create the map, and little attention has been paid to the reusability of the maps created. In other words, the maps generated by current methods can only be reused with the same camera employed to create them. This paper presents a novel SLAM approach that allows maps generated with one camera to be used by other cameras with different resolutions and optics. Our system allows, for instance, creating highly detailed maps processed off-line with high-end computers, to be reused later by low-powered devices (e.g. a drone or robot) using a different camera. The first map, called base map, can be reused with other cameras and dynamically adapted by creating an augmented map. The principal idea of our method is a bottom-up pyramidal representation of the images that allows us to match keypoints between different camera types seamlessly. The experiments conducted validate our proposal, showing that it outperforms the state-of-the-art approaches, namely ORBSLAM, OpenVSLAM and UcoSLAM.},
  archive      = {J_NEUCOM},
  author       = {Francisco J. Romero-Ramirez and Rafael Muñoz-Salinas and Manuel J. Marín-Jiménez and Angel Carmona-Poyato and Rafael Medina-Carnicer},
  doi          = {10.1016/j.neucom.2023.126940},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126940},
  shortjournal = {Neurocomputing},
  title        = {ReSLAM: Reusable SLAM with heterogeneous cameras},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy adaptive resilient control against unknown false data
injection attacks for high-order nonlinear systems with actuator
failures. <em>NEUCOM</em>, <em>563</em>, 126939. (<a
href="https://doi.org/10.1016/j.neucom.2023.126939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An adaptive resilient control technique for high-order nonlinear systems with actuator failures is presented in this work. The unknown false data injection (FDI) attacks make all controlled system states unavailable. To counteract this negative impact of FDI attacks, a new coordinate transformation is constructed during the procedure of recursive design. Moreover, the effect of the actuator faults is completely eliminated by skillfully designing the controller and the adaptive laws. On the basis of the backstepping technology and the Nussbaum gain technique, an adaptive resilient control strategy is presented by using compromised state variables, which ensures all the signals of the closed-loop system is bounded when the sensor is attacked. Compared with the existing results, the proposed control approach not only solves the resilient control problem of high-order nonlinear systems whose powers are positive odd numbers, but also eliminates the assumption that the attack weights are positive. In the end, a simulation result is presented to verify the feasibility of the designed scheme.},
  archive      = {J_NEUCOM},
  author       = {Jipeng Zhao and Guang-Hong Yang},
  doi          = {10.1016/j.neucom.2023.126939},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126939},
  shortjournal = {Neurocomputing},
  title        = {Fuzzy adaptive resilient control against unknown false data injection attacks for high-order nonlinear systems with actuator failures},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Debiased momentum contrastive learning for multimodal video
similarity measures. <em>NEUCOM</em>, <em>563</em>, 126938. (<a
href="https://doi.org/10.1016/j.neucom.2023.126938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing potential of multimodal short videos has contributed to a new type of recommendation. It depends on effectively measuring the similarities between the short video pairs, which consist of video frames and descriptions. Previous studies proposed using contrastive learning with in-batch negative sampling. However, such a strategy would take other semantically similar samples in the batch as negatives, leading to a biased issue. This paper proposes a debiased momentum contrastive learning (DMCL) on the unified multimodal Transformer model (VideoSim) for video similarity measures. The proposed DMCL alleviates the bias issue of negative sampling by introducing implicit knowledge of the model itself as soft labels. Instead of simply taking other samples in the batch as negatives, the proposed DMCL applies soft labels as supervision from the ground truth and the contextual semantic similarities between video-text pairs to alleviate the bias caused by negative sampling. In addition, DMCL expands the negative samples by a momentum queue strategy, which allows storing more multimodal representations to contrast more negatives. The experimental results of measuring multimodal video similarity show that the proposed DMCL outperforms all baselines in terms of Spearman’s rank correlation. Ablation studies and extensive analysis further demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Kuanghong Liu and Jin Wang and Xuejie Zhang},
  doi          = {10.1016/j.neucom.2023.126938},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126938},
  shortjournal = {Neurocomputing},
  title        = {Debiased momentum contrastive learning for multimodal video similarity measures},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EPRD: Exploiting prior knowledge for evidence-providing
automatic rumor detection. <em>NEUCOM</em>, <em>563</em>, 126935. (<a
href="https://doi.org/10.1016/j.neucom.2023.126935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the prevalence of social media platforms , rumors have been a serious social problem. Notably, existing rumor detection methods simply provide detection labels while ignoring their explanation. However, illustrating the reasons why a suspicious statement is a rumor is essential. To address this realistic scenario, we propose a novel Evidence-Providing Rumor Detection model called EPRD. EPRD incorporates a wide variety of information from both prior knowledge sources and current comments. It also learns bilaterally friendly representations for interpretable rumor detection. EPRD first retrieves evidence from prior knowledge sources and checks the relationship between the given statement and its evidence. Our model then constructs two heterogeneous graph objects to simulate the propagation layout of the current comments and evidence relationships. Finally, EPRD integrates the GraphSAGE component and attention mechanism to detect rumors. To the best of our knowledge, we propose the first model that incorporates prior knowledge to verify rumors and boost credibility. Experiments on two real-world Twitter datasets demonstrate that EPRD consistently exhibits the best rumor detection performance. Moreover, EPRD outperforms other baselines in the early rumor detection task.},
  archive      = {J_NEUCOM},
  author       = {Jiawen Li and Ronghui Li and Shiwen Ni and Hung-Yu Kao},
  doi          = {10.1016/j.neucom.2023.126935},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126935},
  shortjournal = {Neurocomputing},
  title        = {EPRD: Exploiting prior knowledge for evidence-providing automatic rumor detection},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Progressive dual-domain-transfer cycleGAN for unsupervised
MRI reconstruction. <em>NEUCOM</em>, <em>563</em>, 126934. (<a
href="https://doi.org/10.1016/j.neucom.2023.126934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised MRI reconstruction methods perform well when provided with matched undersampled and fully sampled data pairs. However, acquiring paired data can be expensive and impractical in several clinical settings, such as cine MRI. As a result, recent studies have focused on reducing the reliance on paired data. Yet, most unsupervised approaches have attempted to directly convert the undersampled data domain into the fully sampled data domain, potentially leading to subpar reconstruction performance due to significant domain discrepancies. In this study, we propose a progressive dual-domain-transfer cycleGAN (PDD-GAN) to effectively address this issue. Our proposed method develops a dual-domain framework in an unsupervised manner , enabling the learning of representations from both image and frequency domains. Simultaneously, we break down the direct domain transfer problem into a multi-stage issue and solve it progressively, correcting reconstruction errors and preserving anatomical information at each transfer step. We conduct comprehensive experiments demonstrating that our approach outperforms several state-of-the-art supervised and unsupervised models on two public datasets. The code is publicly available at https://github.com/Coolwen1997/PDD-GAN .},
  archive      = {J_NEUCOM},
  author       = {Bowen Li and Zhiwen Wang and Ziyuan Yang and Wenjun Xia and Yi Zhang},
  doi          = {10.1016/j.neucom.2023.126934},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126934},
  shortjournal = {Neurocomputing},
  title        = {Progressive dual-domain-transfer cycleGAN for unsupervised MRI reconstruction},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Context learning from a ship trajectory cluster for anomaly
detection. <em>NEUCOM</em>, <em>563</em>, 126920. (<a
href="https://doi.org/10.1016/j.neucom.2023.126920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a context information extraction process over Automatic Identification System (AIS) real-world ship data, building a system with the capability to extract representative points of a trajectory cluster. With the trajectory cluster, the study proposes the use of trajectory segmentation algorithms to extract representative points of each trajectory and then use the k-means algorithm to obtain a series of centroids over all the representative points. These centroids, combined, form a new representative trajectory of the cluster. This new representative trajectory of the input cluster represents new contextual information extracted from the original set of trajectories, being possible to apply anomaly detection approaches over the new obtained context. The results show a suitable approach with several compression algorithms that are compared with a metric based on the Perpendicular Euclidean Distance.},
  archive      = {J_NEUCOM},
  author       = {David Sánchez Pedroche and Jesús García Herrero and José Manuel Molina López},
  doi          = {10.1016/j.neucom.2023.126920},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126920},
  shortjournal = {Neurocomputing},
  title        = {Context learning from a ship trajectory cluster for anomaly detection},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward explainable artificial intelligence: A survey and
overview on their intrinsic properties. <em>NEUCOM</em>, <em>563</em>,
126919. (<a href="https://doi.org/10.1016/j.neucom.2023.126919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence and its derivative technologies are not only playing a role in the fields of medicine, economy, policing, transportation, and natural science computing today but also in future industries such as electric vehicles and meta-universe. However, because of the black-box nature of most common artificial neural networks (DNNs), there needs to be more understanding of what is happening behind these astounding performances. The abstract reasoning process in the networks raises concerns about the security of AI systems. Because of this, more and more researchers are turning their attention to the explainability of black-box neural networks to find some attributions that explain the reasoning performed by the networks by studying the black-box nature of the networks. Deep neural networks and their explainability act as a mutually beneficial symbiosis, facilitating each other’s development. This survey reviews the deep network explainable methods applicable for the field of computing vision proposed within the last decade and categorizes these methods in terms of their starting point to explain deep neural networks. Focusing on their intrinsics, we review the methods that are applicable for object classification, object detection, and looked forward that of object tracking. In each cluster, we show that the methods share some similarities but have their own highlight. Furthermore, we shed light on the future development of the field of explainable AI .},
  archive      = {J_NEUCOM},
  author       = {Jian-Xun Mi and Xilai Jiang and Lin Luo and Yun Gao},
  doi          = {10.1016/j.neucom.2023.126919},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126919},
  shortjournal = {Neurocomputing},
  title        = {Toward explainable artificial intelligence: A survey and overview on their intrinsic properties},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep unsupervised part-whole relational visual saliency.
<em>NEUCOM</em>, <em>563</em>, 126916. (<a
href="https://doi.org/10.1016/j.neucom.2023.126916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Supervised Salient Object Detection (SSOD) excessively relies on large-scale annotated pixel-level labels which consume intensive labour acquiring high quality labels. In such precondition, deep Unsupervised Salient Object Detection (USOD) draws public attention. Under the framework of the existing deep USOD methods, they mostly generate pseudo labels by fusing several hand-crafted detectors’ results. On top of that, a Fully Convolutional Network (FCN) will be trained to detect salient regions separately. While the existing USOD methods have achieved some progress, there are still challenges for them towards satisfactory performance on the complex scene, including (1) poor object wholeness owing to neglecting the hierarchy of those salient regions; (2) unsatisfactory pseudo labels causing by unprimitive fusion of hand-crafted results. To address these issues, in this paper, we introduce the property of part-whole relations endowed by a Belief Capsule Network (BCNet) for deep USOD, which is achieved by a multi-stream capsule routing strategy with a belief score for each stream within the CapsNets architecture. To train BCNet well, we generate high-quality pseudo labels from multiple hand-crafted detectors by developing a consistency-aware fusion strategy. Concretely, a weeding out criterion is first defined to filter out unreliable training samples based on the inter-method consistency among four hand-crafted saliency maps. In the following, a dynamic fusion mechanism is designed to generate high-quality pseudo labels from the remaining samples for BCNet training. Experiments on five public datasets illustrate the superiority of the proposed method. Codes have been released on: https://github.com/Mirlongue/Deep-Unsupervised-Part-Whole-Relational-Visual-Saliency .},
  archive      = {J_NEUCOM},
  author       = {Yi Liu and Xiaohui Dong and Dingwen Zhang and Shoukun Xu},
  doi          = {10.1016/j.neucom.2023.126916},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126916},
  shortjournal = {Neurocomputing},
  title        = {Deep unsupervised part-whole relational visual saliency},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving multi-objective weapon-target assignment considering
reliability by improved MOEA/d-AM2M. <em>NEUCOM</em>, <em>563</em>,
126906. (<a href="https://doi.org/10.1016/j.neucom.2023.126906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The weapon-target assignment problem is a challenging optimization issue, but reliability is seldom considered in the majority of existing literature. To address the high-reliability weapon-target assignment problem, this paper integrates weapon reliability and mission reliability into a multi-objective optimization model (MOD) and presents an improved algorithm termed MOEA/D-iAM2M to the problem. This algorithm effectively combines the strengths of adaptive search space decomposition-based MOEA (MOEA/D-AM2M) and two-stage hybrid learning-based MOEA (HLMEA), resulting in a faster convergence rate and a more extensive distribution of the Pareto solution set. Furthermore, a reference point is incorporated into MOEA/D-iAM2M to facilitate the adaptive weight adjustment. Numerical experiments are carried out to confirm the effectiveness of the proposed MOEA/D-iAM2M. This research is significant in the field of optimization and has practical value in the defense industry.},
  archive      = {J_NEUCOM},
  author       = {Xiaojian Yi and Huiyang Yu and Tao Xu},
  doi          = {10.1016/j.neucom.2023.126906},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126906},
  shortjournal = {Neurocomputing},
  title        = {Solving multi-objective weapon-target assignment considering reliability by improved MOEA/D-AM2M},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning applications on cybersecurity: A practical
approach. <em>NEUCOM</em>, <em>563</em>, 126904. (<a
href="https://doi.org/10.1016/j.neucom.2023.126904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most difficult challenges for computer systems has been security. On the other hand, new developments in machine learning are having an impact on almost every aspect of computer science, including cybersecurity. To analyze this impact, we have created three distinct cybersecurity-related problems to show the advantages of deep learning techniques . We examined their potential applications for SPAM filtering, detecting malicious software , and adult-content detection. We experimented with various techniques, such as Long Short-Term Memory (LSTMs) for spam filtering , Deep Neural Networks (DNNs) for malware detection , Convolutional Neural Networks (CNNs) combined with Transfer Learning for adult content detection and image augmentation methods. We are able to achieve an Area Under ROC Curve greater than 0.94 in every scenario, proving that excellent performance with a good relation between cost and effectiveness may be created without the need of complex designs.},
  archive      = {J_NEUCOM},
  author       = {Alberto Miranda-García and Agustín Zubillaga Rego and Iker Pastor-López and Borja Sanz and Alberto Tellaeche and José Gaviria and Pablo G. Bringas},
  doi          = {10.1016/j.neucom.2023.126904},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126904},
  shortjournal = {Neurocomputing},
  title        = {Deep learning applications on cybersecurity: A practical approach},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). STDM-transformer: Space-time dual multi-scale transformer
network for skeleton-based action recognition. <em>NEUCOM</em>,
<em>563</em>, 126903. (<a
href="https://doi.org/10.1016/j.neucom.2023.126903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based methods have currently demonstrated impressive results in the field of skeleton-based action recognition. Nevertheless, how to effectively model multi-scale features with transformers remains a challenging problem, which is crucial to distinguish various actions. In this paper, we propose a Space–time Dual Multi-scale transformer (STDM-transformer) to explore the multi-scale collaborative representation employing both fine and coarse scale motion information. In contrast to existing approaches which typically propagate information between scales in a single fusion manner, our Space–time Dual Multi-scale method stratifies the space–time multi-scale into dual levels. One level is to construct fine-grained local motion interactions. In detail, the space–time multi-scale partition strategy and the novel intra-inter space–time transformer module are proposed to extract and aggregate the feature in part scale and body scale, respectively. The other is aimed at modeling coarse-grained global motion contexts, in which the layer-wise multi-scale progressive fusion strategy is designed. Extensive experimental results demonstrate that the proposed STDM-transformer achieves the SOTA performance on large-scale datasets.},
  archive      = {J_NEUCOM},
  author       = {Zhifu Zhao and Ziwei Chen and Jianan Li and Xuemei Xie and Kai Chen and Xiaotian Wang and Guangming Shi},
  doi          = {10.1016/j.neucom.2023.126903},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126903},
  shortjournal = {Neurocomputing},
  title        = {STDM-transformer: Space-time dual multi-scale transformer network for skeleton-based action recognition},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An intelligent conversational agent for educating the
general public about HIV. <em>NEUCOM</em>, <em>563</em>, 126902. (<a
href="https://doi.org/10.1016/j.neucom.2023.126902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article presents a Spanish conversational agent that focuses on raising awareness about HIV. The agent aims to provide natural communication, personalized information based on user requests, and a centralized source of information about HIV. The core of the agent’s logic is formed by a natural language understanding conversational model, supported by a knowledge base of medical responses and real conversations with users. An empirical study was conducted with 71 users to evaluate the agent’s effectiveness as a sexual health educational tool. The results show that HIV knowledge raised by 18.44% after using the agent. That, and the positive user experience support the agent’s role as a tool for raising HIV prevention and awareness.},
  archive      = {J_NEUCOM},
  author       = {Joan C. Moreno and Victor Sánchez-Anguix and Juan M. Alberola and Vicente Julián and Vicent Botti},
  doi          = {10.1016/j.neucom.2023.126902},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126902},
  shortjournal = {Neurocomputing},
  title        = {An intelligent conversational agent for educating the general public about HIV},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). STF-trans: A two-stream spatiotemporal fusion transformer
for very high resolution satellites images. <em>NEUCOM</em>,
<em>563</em>, 126868. (<a
href="https://doi.org/10.1016/j.neucom.2023.126868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatiotemporal satellite image fusion is regarded as an effective approach to address the limitations of a single optical sensor and generate data with high spatial and temporal resolutions. Thanks to the recent advances of Deep Learning , spatiotemporal fusion has gained a significant performance improvement . However, most models require at least three inputs, including a high resolution one at a prior date, to make the prediction at the desired date. Such a requirement is not always guaranteed in practice, in particular due to the high cost of high resolution image and bad atmospheric conditions . In the last few years, Transformers have achieved tremendous performance on several computer vision tasks compared to convolutional neural networks . Inspired by the new trend, we proposed an end-to-end two-stream SpatioTemporal fusion technique based on encoder–decoder transformer architecture, termed STF-Trans. To deal with a complexity and high-cost of data preparation, the proposed approach aims to fuse a coarse-resolution image with high temporal resolution, and a very high resolution Google Earth image, to produce a very high resolution image at the desired date. The proposed technique employs a two-stream convolutional network to capture both temporal and spatial features from the inputs, and then the encoder–decoder transformer captures long-range dependency of the latter and generates a more efficient image representation from the shallow features. Finally, a shallow network maps the features into the desired fused image. The experimental results show that the proposed method outperforms the current state-of-the-art techniques at both quantitative and qualitative evaluations.},
  archive      = {J_NEUCOM},
  author       = {Tayeb Benzenati and Abdelaziz Kallel and Yousri Kessentini},
  doi          = {10.1016/j.neucom.2023.126868},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126868},
  shortjournal = {Neurocomputing},
  title        = {STF-trans: A two-stream spatiotemporal fusion transformer for very high resolution satellites images},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Saliency guided debiasing: Detecting and mitigating biases
in LMs using feature attribution. <em>NEUCOM</em>, <em>563</em>, 126851.
(<a href="https://doi.org/10.1016/j.neucom.2023.126851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bias in machine learning models has gained increasing attention in recent years, as these models can reflect and even amplify biases present in the data used to train them. One approach to mitigating bias is identifying and down-weight features that contribute disproportionately to model predictions, which can be accomplished using saliency techniques. Current debiasing methods often lead to the loss of contextual information, where the model tends to respond incorrectly even when the gender information is present in the context; hence, even though the bias reduces, performance (coreference resolution, fluency) also reduces. This paper explores data augmentation and saliency techniques to mitigate bias in natural language generation . Specifically, we explore applying the saliency technique of SHAP (SHapley Additive exPlanations) over a model trained on debiasing using data augmentation (switching gendered words with counterparts) and then applying hard debiasing to remove the influential biased token. We build a dialogue context test setup to evaluate bias and context relevance using the presence of gendered words in the model-generated responses. The response is evaluated based on the gender information from context to ensure the model follows the gender in context. We demonstrate that this approach can effectively reduce the impact of biased features on model predictions while preserving overall model accuracy. Additionally, we discuss potential limitations and future directions for research in this area. Our findings suggest that saliency offers an avenue to address machine learning bias.},
  archive      = {J_NEUCOM},
  author       = {Ratnesh Kumar Joshi and Arindam Chatterjee and Asif Ekbal},
  doi          = {10.1016/j.neucom.2023.126851},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126851},
  shortjournal = {Neurocomputing},
  title        = {Saliency guided debiasing: Detecting and mitigating biases in LMs using feature attribution},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Noise is the fatal poison: A noise-aware network for noisy
dataset classification. <em>NEUCOM</em>, <em>563</em>, 126829. (<a
href="https://doi.org/10.1016/j.neucom.2023.126829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many benchmark datasets have been found to contain noisy labels caused by unavoidable human mistakes. Many researchers propose new noise-aware loss functions to achieve robust classification performance. However, we discover that existing noise-aware loss functions cannot fully heal the damage caused by the noise. On the other hand, some methods filter out low confidence samples and train new models, whereas the filtered samples contain both noisy and hard samples that are critical for the robustness of models. Based on the above two discoveries, we devised the Noise-aware Network (NA-Net) for robust training with noisy labels. Each layer of NA-Net contains three groups of convolution kernels responsible for mix samples, clean samples, and noisy samples, termed as mix-kernels, clean-kernels, and noise-kernels, respectively. Mix-kernels are used for finding the clean samples with a newly devised noise-immune (NI) loss function; clean-kernels are targeted at learning better features without being misguided by noise; noise-kernels are trained by the remaining samples to rectify wrong labels for the next iteration. Meanwhile, for increasing the classification performance of mix-kernels, the extracted feature maps of clean-kernels without being poisoned are combined as the input of mix-kernels of the next layer. Also, the knowledge distillation strategy is adopted to distill the knowledge from clean-kernels to the noise-kernels. Extensive experiments demonstrate that the mutual promotion of three groups of kernels in NA-Net achieves state-of-the-art performance on both artificial noisy datasets and real-world datasets.},
  archive      = {J_NEUCOM},
  author       = {Xiaotian Yu and Shengxuming Zhang and Lingxiang Jia and Yuexuan Wang and Mingli Song and Zunlei Feng},
  doi          = {10.1016/j.neucom.2023.126829},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126829},
  shortjournal = {Neurocomputing},
  title        = {Noise is the fatal poison: A noise-aware network for noisy dataset classification},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human–robot collaborative interaction with human perception
and action recognition. <em>NEUCOM</em>, <em>563</em>, 126827. (<a
href="https://doi.org/10.1016/j.neucom.2023.126827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a human–robot interaction system (HRIS) that utilizes human perception and action recognition to enable the robot to understand human intentions and flexibly interact with humans. A monocular multi-person three-dimensional (3D) pose estimation method is first proposed to perceive multi-person two-dimensional (2D) and 3D poses in interaction scenarios. Furthermore, a 3D skeleton poses tracking approach is adopted to locate the identity of each person in consecutive frames and enhance interactive stability. Then, an action recognition model is developed, which exploits tracked pose features to recognize the intentions of humans. An action-controlled interaction system is built with a modular approach to ensure flexibility in meeting multiple task requirements and facilitating flexible interaction. In the system, a distance-based safety solution is designed to avoid collisions between humans and robots. Finally, experimental results are presented to demonstrate the feasibility and effectiveness of the proposed methods and system.},
  archive      = {J_NEUCOM},
  author       = {Xinyi Yu and Xin Zhang and Chengjun Xu and Linlin Ou},
  doi          = {10.1016/j.neucom.2023.126827},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126827},
  shortjournal = {Neurocomputing},
  title        = {Human–robot collaborative interaction with human perception and action recognition},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing code summarization with action word prediction.
<em>NEUCOM</em>, <em>563</em>, 126777. (<a
href="https://doi.org/10.1016/j.neucom.2023.126777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code summarization refers to automatically generating concise description in natural language from a code snippet. Good code summaries could effectively facilitate program comprehension and software maintenance. In recent years, various learning-based code summarization techniques have achieved impressive performance. Most of these models treat code summarization as an end-to-end model and directly generate the summaries, which ignores the fact that action words are crucial to code summaries. An essential characteristic of code summaries is the concentration of action word distribution. For instance, in the Funcom dataset, the top forty most-common action words account for 72% of all samples. To incorporate this valuable prior domain knowledge into code summarization models, we develop a method for assisting code summarization through an additional action word prediction module, where an action predictor is employed to predict the primary action in the code summary, which is then used as a prompt to enhance the performance of the summary generation model. Our approach can be conveniently integrated into the existing models. We evaluate our approach on two Java datasets and a C/C++ dataset. The results show that our approach can efficiently improve the performance of the code summarization models. Furthermore, our action word prediction module can enhance the performance of a large pre-trained language model by prompting it with the predicted action words. This work suggests that a precise action word prediction model can significantly improve the performance of code summarization through the proposed action word guidance mechanism.},
  archive      = {J_NEUCOM},
  author       = {Mingchen Li and Huiqun Yu and Guisheng Fan and Ziyi Zhou and Zijie Huang},
  doi          = {10.1016/j.neucom.2023.126777},
  journal      = {Neurocomputing},
  month        = {1},
  pages        = {126777},
  shortjournal = {Neurocomputing},
  title        = {Enhancing code summarization with action word prediction},
  volume       = {563},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
