<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EJOR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ejor---608">EJOR - 608</h2>
<ul>
<li><details>
<summary>
(2024a). Corrigendum to “labeling methods for partially ordered
paths” [european journal of operational research 318 (2024) 19–30].
<em>EJOR</em>, <em>319</em>(3), 1020. (<a
href="https://doi.org/10.1016/j.ejor.2024.08.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Ricardo Euler and Pedro Maristany de las Casas},
  doi          = {10.1016/j.ejor.2024.08.004},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {1020},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Corrigendum to “Labeling methods for partially ordered paths” [European journal of operational research 318 (2024) 19–30]},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time-to-build, regulation, and investment. <em>EJOR</em>,
<em>319</em>(3), 999–1019. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the effects of uncertainty in time-to-build and regulation, which hinders immediate revenue generation after investment, on a firm’s optimal investment decision. We show that in the absence of regulation, uncertainty in time-to-build always accelerates investment and enhances pre-investment firm value. We also show that in the absence of time-to-build, uncertainty in regulation can mitigate the distortion of investment induced by regulation. Furthermore, in the presence of both time-to-build and regulation, there can exist harmless regulation that does not induce any distortion in the investment decision and does not harm firm value. Lastly, in the presence of both time-to-build and regulation, not only uncertainty in time-to-build but also its presence can accelerate investment.},
  archive      = {J_EJOR},
  author       = {Haejun Jeon},
  doi          = {10.1016/j.ejor.2024.07.037},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {999-1019},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Time-to-build, regulation, and investment},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interactive preference analysis: A reinforcement learning
framework. <em>EJOR</em>, <em>319</em>(3), 983–998. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated investment managers are increasingly popular in personal wealth management due to their cost effectiveness, objectivity, and accessibility. However, it still suffers from several dilemmas, e.g., cold start, over-specialization, and black boxes. To solve these issues, we develop an online reinforcement learning framework based on the multi-armed bandit algorithm to offer personalized investment advice. We provide a comprehensive theoretical procedure for developing this framework. This framework not only enables us to capture the evolving preferences of investors effectively but also has a strong explainability power to provide more implications regarding why one financial product is preferred. We further evaluate our basic model through a large-scale, real-world data set from a leading wealth management platform. The results show a stronger effectiveness of the proposed framework compared to other well-recognized benchmark models. Furthermore, we extend our basic model to address the potential agency problem between the robo-advisor and the investors. Another extension is also provided through an optimization scheme to account for the investors’ demands for diversification in multiple aspects.},
  archive      = {J_EJOR},
  author       = {Xiao Hu and Siqin Kang and Long Ren and Shaokeng Zhu},
  doi          = {10.1016/j.ejor.2024.06.033},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {983-998},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Interactive preference analysis: A reinforcement learning framework},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient use of collision detection for volume maximization
problems. <em>EJOR</em>, <em>319</em>(3), 967–982. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes improved local search heuristics based on collision detection for solving volume maximization problems, with a particular focus on single item volume maximization. The objective is to find the biggest item of a predefined shape that can be extracted from a larger container. Both the item and the container are three-dimensional objects and can have irregular shapes. Our goal is to find high-quality solutions for these problems within a reasonable amount of time, even for complex instances where the object and container are represented by thousands of triangles. We consider an approach where the position and orientation of an item are optimized heuristically, while the scale of the item is maximized using a fast inflation procedure. This inflation procedure uses bisection search and collision detection to determine the largest possible scale that satisfies all geometric constraints for a given position and orientation of the item within the container. We introduce improvements to this approach to reduce the required amount of geometric computations required. Finally, we compare our results against a matheuristic method from the literature on an expanded data set, which shows the improved collision detection approach is more than 100 times faster and highlights the impact of our improvements.},
  archive      = {J_EJOR},
  author       = {Jonas Tollenaere and Hatice Çalık and Tony Wauters},
  doi          = {10.1016/j.ejor.2024.05.048},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {967-982},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Efficient use of collision detection for volume maximization problems},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A three-dimensional spatial resource-constrained project
scheduling problem: Model and heuristic. <em>EJOR</em>, <em>319</em>(3),
943–966. (<a href="https://doi.org/10.1016/j.ejor.2024.07.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a class of complex engineering projects executed in limited construction sites, spatial resources with three dimensions usually become a bottleneck that hampers their smooth implementation. Serious time-space conflicts frequently occur when multiple activities are carried out in parallel during some time periods. We propose a new project scheduling problem with three-dimensional spatial resource constraints (3D-sRCPSP), and a four-dimensional time-space is adopted to build the model for our 3D-sRCPSP. Firstly, in order to express the impacts of constrained sites on scheduling activities, two types of spatial constraints are refined and modeled: non-overlapping among active subspaces and not exceeding the total space, and then an integer programming model for the 3D-sRCPSP is formalized. Secondly, a novel heuristic algorithm is developed to solve the 3D-sRCPSP, which is embedded with 36 priority rules (PRs) and 3 instructive space allocation strategies. Besides 25 PRs for the traditional RCPSP, 11 new forms of PRs are extracted based on the features of 3D spatial resources. Thirdly, extensive numerical experiments are implemented to validate our model and heuristics. The instances are obtained by configuring the specific parameters of 3D spatial resources for benchmarks from PSPLIB library. One distinctive finding is that some existing PRs that perform well in the traditional RCPSP do not act best in the 3D-sRCPSP. On the other hand, the optimal solutions of very small-scale instances can be obtained by Gourbi solver, but our customized heuristic algorithm is more effective than Gourbi for general instances with medium/large sizes. Overall, the designed heuristics can effectively eliminate time-space conflicts in the planning stage of a project. Finally, as extension studies, the decision tree model is constructed to adaptively select the best PRs for each instance according to the indicators of project instances. These results can help project managers schedule activities and allocate spatial resources more accurately when encountering narrow construction sites.},
  archive      = {J_EJOR},
  author       = {Jingwen Zhang and Lubo Li and Erik Demeulemeester and Haohua Zhang},
  doi          = {10.1016/j.ejor.2024.07.018},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {943-966},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A three-dimensional spatial resource-constrained project scheduling problem: Model and heuristic},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal transfer prices and technology in decentralized
business groups. <em>EJOR</em>, <em>319</em>(3), 920–942. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized (parent-affiliates) business groups encompass independent firms sharing production resources under common administrative or financial control. Due to the complexity of integrated decision-making, business groups often delegate pricing and technology decisions to separated units. With the growing prevalence of transfer technology in multi-plant operations, there arises a demand for modeling frameworks capturing the joint impact of transfer prices and technology on affiliates’ production. In this paper, we propose an operational methodology to integrate transfer prices and technology, as incentive mechanisms driving affiliates’ production decisions. This consists of a single-leader-multi-follower game where a parent firm (the leader) operates in a single-product market and delegates production to profit-maximizing affiliate firms (the followers). In addition to providing data-driven support for integrated decision-making, our framework reveals how managerial structures respond to the growing significance of intangible technology. In this line, based on the parent’s control of the value chain we present two specifications and solution approaches: full delegation and partial delegation. For the former, we provide an exact characterization of the equilibrium solution; whereas for business groups operating under full delegation, we provide tight lower and upper bounds, computable by state-of-the-art optimization solvers. Our empirical tests rely on a customized version of the Orbis data set. Figures show that our methodology not only integrates the substitutability between transfer prices and technology, as well as their dependency on the parent’s control of the value chain, but also gives rise to a flexible computational approach that is applicable to a wide range of decentralized business groups.},
  archive      = {J_EJOR},
  author       = {Stefano Nasini and Marijn Verschelde and Bruno Merlevede},
  doi          = {10.1016/j.ejor.2024.07.007},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {920-942},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal transfer prices and technology in decentralized business groups},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing pit stop strategies in formula 1 with dynamic
programming and game theory. <em>EJOR</em>, <em>319</em>(3), 908–919.
(<a href="https://doi.org/10.1016/j.ejor.2024.07.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization of pit stop strategies in motorsports is not trivial. Most existing studies neglect competition, or account for it using simulation or historical data, but not in a game theory sense. In this work, we present a model, based on Formula 1, in which two drivers optimize their pit stop strategies. Each car decides at each lap whether to continue on-track, or to take a pit stop to change tires to one of the three tire compounds available. Since the drivers’ decisions affect each other due to interactions such as overtaking, the problem is formulated as a zero-sum feedback Stackelberg game using Dynamic Programming, in which in each lap the race leader (follower) decides first (second). In addition, drivers decide simultaneously their starting tire compounds. The formulation allows for the inclusion of uncertain events, such as yellow flags, or randomness in lap times. We show the existence of the game equilibrium, and provide an algorithm to find it. Then, we solve numerical instances of the problem with hundreds of millions of states. We observe how drivers’ different objective functions induce different race strategies. In particular, if players maximize the probability of winning, instead of the time-gap with their opponent, their actions tend to be more risk taking. Our instances show that a strategic driver who faces another who ignores competition, increases the winning odds by more than 15% compared to when both race strategically. Finally, yellow flags tend to increase the winning chances of the driver with the worst performance.},
  archive      = {J_EJOR},
  author       = {Felipe Aguad and Charles Thraves},
  doi          = {10.1016/j.ejor.2024.07.011},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {908-919},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing pit stop strategies in formula 1 with dynamic programming and game theory},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal day-ahead offering strategy for large producers
based on market price response learning. <em>EJOR</em>, <em>319</em>(3),
891–907. (<a href="https://doi.org/10.1016/j.ejor.2024.06.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In day-ahead electricity markets based on uniform marginal pricing, small variations in the offering and bidding curves may substantially modify the resulting market outcomes. In this work, we deal with the problem of finding the optimal offering curve for a risk-averse profit-maximizing generating company (GENCO) in a data-driven context. In particular, a large GENCO’s market share may imply that its offering strategy can alter the marginal price formation, which can be used to increase profit. We tackle this problem from a novel perspective. First, we propose an optimization-based methodology to summarize each GENCO’s step-wise supply curves into a subset of representative price-energy blocks. Then, the relationship between the resulting market price and the energy block offering prices is modeled through a probabilistic forecasting tool: a Distributional Neural Network, which also allows us to generate stochastic scenarios for the sensibility of the market towards the GENCO strategy via a set of linear constraints. Finally, this predictive model is embedded in the stochastic optimization model employing a constraint learning approach. Results show how allowing the GENCO to deviate from its true marginal costs renders significant changes in its profits and the marginal price of the market. Additionally, these results have also been tested in an out-of-sample validation setting, showing how this optimal offering strategy can effective in a real-world market context.},
  archive      = {J_EJOR},
  author       = {Antonio Alcántara and Carlos Ruiz},
  doi          = {10.1016/j.ejor.2024.06.038},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {891-907},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal day-ahead offering strategy for large producers based on market price response learning},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Remaining useful life prediction for two-phase degradation
model based on reparameterized inverse gaussian process. <em>EJOR</em>,
<em>319</em>(3), 877–890. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-phase degradation is a prevalent degradation mechanism observed in modern systems, typically characterized by a change in the degradation rate or trend of a system’s performance at a specific time point. Ignoring this change in degradation models can lead to considerable biases in predicting the remaining useful life (RUL) of the system, and potentially leading to inappropriate condition-based maintenance decisions. To address this issue, we propose a novel two-phase degradation model based on a reparameterized inverse Gaussian process. The model considers variations in both change points and model parameters among different systems to account for subject-to-subject heterogeneity. The unknown parameters are estimated using both maximum likelihood and Bayesian approaches. Additionally, we propose an adaptive replacement policy based on the distribution of RUL. By sequentially obtaining new degradation data, we dynamically update the estimation of model parameters and of the RUL distribution, allowing for adaptive replacement policies. A simulation study is conducted to assess the performance of our methodologies. Finally, a Lithium-ion battery example is provided to validate the proposed model and adaptive replacement policy. Technical details and additional results of case study are available as online supplementary materials.},
  archive      = {J_EJOR},
  author       = {Liangliang Zhuang and Ancha Xu and Yijun Wang and Yincai Tang},
  doi          = {10.1016/j.ejor.2024.06.032},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {877-890},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Remaining useful life prediction for two-phase degradation model based on reparameterized inverse gaussian process},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Strategic flood impact mitigation in developing countries’
urban road networks: Application to hanoi. <em>EJOR</em>,
<em>319</em>(3), 862–876. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to climate change, the frequency and scale of flood events worldwide are increasing dramatically. Flood impacts are especially acute in developing countries, where they often revert years of progress in sustainable development and poverty reduction. This paper introduces an optimization-based decision support tool for selecting cost-efficient flood mitigation investments in developing countries’ urban areas. The core of the tool is a scenario-based, multi-period, bi-objective Mixed Integer Linear Programming model which minimizes infrastructure damage and traffic congestion in urban road networks. The tool was developed in collaboration with Vietnamese stakeholders (e.g., local communities and government authorities), and integrates data and inputs from other disciplines, including social science, transport economics, climatology and hydrology. A metaheuristic, combining a Greedy Randomized Adaptive Search Procedure with a Variable Neighborhood Descent algorithm, is developed to solve large scale problem instances. An extensive computational campaign on randomly generated instances demonstrates the efficiency of the metaheuristic in solving realistic problems with hundreds of interdependent flood mitigation interventions. Finally, the applicability of the interdisciplinary approach is demonstrated on a real case study to generate a 20-year plan of mitigation investments for the urban area of Hanoi. Policy implications and impacts of the study are also discussed.},
  archive      = {J_EJOR},
  author       = {Siao-Leu Phouratsamay and Maria Paola Scaparra and Trung Hieu Tran and Gilbert Laporte},
  doi          = {10.1016/j.ejor.2024.06.035},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {862-876},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Strategic flood impact mitigation in developing countries’ urban road networks: Application to hanoi},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The deck-of-cards-based ordinal regression method and its
application for the development of an ecovillage. <em>EJOR</em>,
<em>319</em>(3), 845–861. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the deck-of-cards-based Ordinal Regression (DOR), a new multicriteria decision-aiding procedure that conjugates the deck-of-cards method with an ordinal regression approach to define a multicriteria value function representing the preferences of the decision maker (DM). The deck-of-cards method allows the DM to express the ranking order of a set of reference alternatives along with the intensity of preferences between reference alternatives. An ordinal regression procedure is then used to define a multicriteria value function that represents the ranking of the reference alternatives as well as the preference intensity. This approach can be applied to define value functions with different formulations, such as weighted sum, additive value, or Choquet integral. The value function thus obtained can be used to comprehensively evaluate alternatives of a multi-criteria decision problem. The value function provided by DOR can also be applied to a multi-objective optimisation problem. In this study, we applied DOR to handle urban and regional planning decisions in which facilities are required to be selected, located, and planned. In particular, we consider the interactions between criteria and synergies between facilities in an enriched version of the so-called space–time model. We applied this methodology to a real-world problem to plan the development of a sustainable ecovillage in the province of Turin (Italy), thus supporting the president of the cooperative owning the ecovillage in his decisions regarding which structures to select, where to locate them, and when to plan their realisation.},
  archive      = {J_EJOR},
  author       = {Maria Barbati and Salvatore Greco and Isabella M. Lami},
  doi          = {10.1016/j.ejor.2024.07.010},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {845-861},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The deck-of-cards-based ordinal regression method and its application for the development of an ecovillage},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust optimal design of a tree-based water distribution
network with intermittent demand. <em>EJOR</em>, <em>319</em>(3),
834–844. (<a href="https://doi.org/10.1016/j.ejor.2024.07.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the design of a tree-shaped water distribution system for small, dispersed rural communities. It revisits the topic that was discussed in the literature and is nowadays implemented in the field. It proposes a new approach to pipe selection based on robust optimization to account for the uncertainty inherent in intermittent demands. It also proposes a fast projected reduced Newton method of calculating stationary flows to test the performance of the networks thus designed by Monte-Carlo simulation. Numerical experiments conducted on real study cases have shown promising results both in terms of quality and performance of the generated robust solutions and in terms of computation time for simulations.},
  archive      = {J_EJOR},
  author       = {F. Babonneau and D. Gilbert and O. Piller and J.P. Vial},
  doi          = {10.1016/j.ejor.2024.07.020},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {834-844},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust optimal design of a tree-based water distribution network with intermittent demand},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse portfolio optimization via ℓ1 over ℓ2 regularization.
<em>EJOR</em>, <em>319</em>(3), 820–833. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse portfolio optimization, which significantly boosts the out-of-sample performance of traditional mean–variance methods, is widely studied in the fields of optimization and financial economics. In this paper, we explore the ℓ 1 ℓ1 / ℓ 2 ℓ2 fractional regularization constructed by the ratio of the ℓ 1 ℓ1 and ℓ 2 ℓ2 norms on the mean–variance model to promote sparse portfolio selection. We present an ℓ 1 ℓ1 / ℓ 2 ℓ2 regularized sparse portfolio optimization model and provide financial insights regarding short positions and estimation errors. Then, we develop an efficient alternating direction method of multipliers (ADMM) method to solve it numerically. Due to the nonconvexity and noncoercivity of the ℓ 1 ℓ1 / ℓ 2 ℓ2 term, we give the convergence analysis for the proposed ADMM based on the nonconvex optimization framework. Furthermore, we discuss an extension of the model to incorporate a more general ℓ 1 ℓ1 / ℓ q ℓq regularization, where q &gt; 1 q&amp;gt;1 . Moreover, we conduct numerical experiments on four stock datasets to demonstrate the effectiveness and superiority of the proposed model in promoting sparse portfolios while achieving the desired level of expected return.},
  archive      = {J_EJOR},
  author       = {Zhongming Wu and Kexin Sun and Zhili Ge and Zhihua Allen-Zhao and Tieyong Zeng},
  doi          = {10.1016/j.ejor.2024.07.017},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {820-833},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Sparse portfolio optimization via ℓ1 over ℓ2 regularization},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Investment allocation in an adjustment-cost production
technology framework for two-stage network structures. <em>EJOR</em>,
<em>319</em>(3), 808–819. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective resource allocation can assist organizations in utilizing infinite resources, thereby improving efficiency and productivity. For an organization, investment is an essential production resource, and how to appropriately allocate investment is one of the most important decisions they need to make. This study aims to rationally allocate investment across each stage of two-stage network structure under two scenarios. We first propose general investment allocation model with adjustment costs to efficiently allocate investments across each stage. Then, given a fixed total investment, we use the DEA-based fixed cost allocation method to achieve the optimal allocation across stages, and we also incorporate two cooperative and noncooperative relationships between two stages. Additionally, capital stock efficiency is defined to analyze the relationship between optimal and actual capital stocks, clarifying the degree to which the optimal capital stock is reached. Finally, the proposed approach is applied to 14 A-share listed companies in China, and suggestions on the optimal amount of investment allocation and capital stock required are provided to facilitate organizational production.},
  archive      = {J_EJOR},
  author       = {Qingxian An and Kefan Zhu and Beibei Xiong},
  doi          = {10.1016/j.ejor.2024.07.012},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {808-819},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Investment allocation in an adjustment-cost production technology framework for two-stage network structures},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Branch-price-and-cut algorithms for the team orienteering
problem with interval-varying profits. <em>EJOR</em>, <em>319</em>(3),
793–807. (<a href="https://doi.org/10.1016/j.ejor.2024.07.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the team orienteering problem (TOP), wherein each vertex requires two visits, and the service profit of each vertex depends on the time interval between these two visits. Motivated by scenarios like perishable product delivery, home health care scheduling, and earth observation satellite scheduling, the paper addresses two variants: the periodic orienteering problem with a focus on the number of days (NoDs) and the team orienteering problem with attention to a combination of time windows (CoTWs). It develops mixed-integer linear programming (MILP) models for both variants and devises exact Branch-Price-and-Cut (BPC) algorithms tailored to their block diagonal structures. Furthermore, this paper proposes two strategies to improve algorithm performance. A simplification strategy streamlines the directed graph network by removing redundant vertices and arcs without compromising optimality, thereby accelerating the solution of pricing problems. Additionally, a matheuristic algorithm is proposed to obtain integer solutions quickly. Computational results demonstrate the effectiveness of these algorithms, showcasing their superiority over CPLEX. The BPC algorithm, coupled with the simplification strategy, exhibits an average computational time reduction of 70 % compared to the basic strategy. The effectiveness of the matheuristic algorithm is also confirmed. Finally, the findings presented herein offer valuable insights for refining and applying BPC algorithms.},
  archive      = {J_EJOR},
  author       = {Jiaojiao Li and Jianghan Zhu and Guansheng Peng and Jianjiang Wang and Lu Zhen and Erik Demeulemeester},
  doi          = {10.1016/j.ejor.2024.07.015},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {793-807},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Branch-price-and-cut algorithms for the team orienteering problem with interval-varying profits},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Who should invest in blockchain technology under different
pricing models in supply chains? <em>EJOR</em>, <em>319</em>(3),
777–792. (<a href="https://doi.org/10.1016/j.ejor.2024.07.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, members of supply chain have rushed to invest in blockchain technology to improve product traceability for more profits in their operations. When both the manufacturer and retailer can afford the cost of blockchain, a question arises: who should invest in blockchain technology? To benefit from blockchain investment, the retailer such as Walmart, which has a higher power in the choice of pricing models than the manufacturer, will examine the blockchain investment motives of supply chain members and carefully design the pricing model: a wholesale pricing model or an agency pricing model. In this paper, we establish game-theoretic models to explore the interaction between the retailer&#39;s choice of the pricing model and supply chain members&#39; choice of the blockchain investor. Our results show that a bit surprisingly, the demand of privacy-sensitive customers decreases even if they do not use blockchain traceability services provided by supply chain members. We also obtain the retailer&#39;s equilibrium pricing model choice together with the supply chain members&#39; blockchain investment decisions, which depends on the commission rate. An interesting insight is that when the commission rate is medium, supply chain members will be locked in a prisoner&#39;s dilemma where both the manufacturer and retailer want to free ride on the blockchain investment to maximize their own profits, which ultimately leads to the loss of both parties due to no blockchain investment. Finally, we design a cost-sharing contract under the Nash negotiation framework when the two parties face conflict in the choice of blockchain investor.},
  archive      = {J_EJOR},
  author       = {Chang Fang and Mingxiang Chi and Shuyi Fan and Tsan-Ming Choi},
  doi          = {10.1016/j.ejor.2024.07.006},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {777-792},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Who should invest in blockchain technology under different pricing models in supply chains?},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-period ordering decisions in the presence of retail
promotions. <em>EJOR</em>, <em>319</em>(3), 763–776. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the impact of retail promotions on inventory decisions in a multi-period ordering setting. A laboratory experiment was designed to examine how awareness of promotional information could improve ordering decisions and reduce supply chain costs. Drawing on data from 140 participants in Australia and Sri Lanka, our study reveals several key findings and practical insights. (i) Awareness of upcoming promotions significantly improves ordering decisions by minimizing ordering costs while maintaining service levels. (ii) Access to detailed promotional information (e.g., the extent of price discounts) does not noticeably improve these decisions. (iii) Transit times serve as a moderating factor; longer transit times can lead to supply line underweighting, thereby escalating ordering costs. (iv) A lack of promotional awareness results in adverse behaviors, including bracing and demand chasing. These findings and practical insights underscore the critical role of timely and effective communication of promotional information in improving multi-period ordering decisions.},
  archive      = {J_EJOR},
  author       = {H. Niles Perera and Behnam Fahimnia},
  doi          = {10.1016/j.ejor.2024.07.009},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {763-776},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-period ordering decisions in the presence of retail promotions},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A matheuristic with re-lot-sizing strategies for flexible
job-shop rescheduling problem with lot-streaming and machine
reconfigurations. <em>EJOR</em>, <em>319</em>(3), 747–762. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a flexible job-shop rescheduling problem with lot-streaming and machine reconfigurations (FJRP-LSMR) for the total weighted tardiness minimization, where production setups between sublots are performed by assembling selected auxiliary modules to reconfigure machines. When a given long-term schedule is interrupted by dynamic events, such as machine breakdowns and job insertions, a rescheduling process is triggered to determine the lot-sizing plan, sublot sequences, and machine configurations simultaneously. A matheuristic with re-lot-sizing strategies (MH R L S RLS ) is proposed to address the FJRP-LSMR, which takes the genetic algorithm as the main framework and introduces a mixed integer linear programming (MILP) based lot-sizing optimization (LSO R L S RLS ) function to improve lot-sizing plans. Two re-lot-sizing strategies, namely complete re-lot-sizing and partial re-lot-sizing, are defined to reset more sublot sizes in rescheduling processes, thus the solution space that can be visited by the MILP model is greatly expanded for further improvements. Four groups of test instances and a complex real-world industrial case are adopted to evaluate the performance of the proposed methods. Extensive experimental results demonstrate that, with the help of re-lot-sizing strategies, the LSO R L S RLS can find high-quality lot-sizing plans within a short period of time, and the proposed MH R L S RLS shows the best performance in the optimality, stability, and convergence.},
  archive      = {J_EJOR},
  author       = {Jiaxin Fan and Chunjiang Zhang and Fajun Yang and Weiming Shen and Liang Gao},
  doi          = {10.1016/j.ejor.2024.07.030},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {747-762},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A matheuristic with re-lot-sizing strategies for flexible job-shop rescheduling problem with lot-streaming and machine reconfigurations},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Influence of encoding and neighborhood in landscape analysis
and tabu search performance for job shop scheduling problem.
<em>EJOR</em>, <em>319</em>(3), 739–746. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fitness landscape analysis is used to understand search spaces of combinatorial problems that can hardly be solved exactly, such as the job shop scheduling problem. We analyze the influence of the solution encodings and the neighborhood operators on usual metrics for landscape analysis, and try to correlate the results to the performance of a local search method such as tabu search using these encodings and operators for a wide range of instances of the job shop scheduling problem.},
  archive      = {J_EJOR},
  author       = {Israël Tsogbetse and Julien Bernard and Hervé Manier and Marie-Ange Manier},
  doi          = {10.1016/j.ejor.2024.07.028},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {739-746},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Influence of encoding and neighborhood in landscape analysis and tabu search performance for job shop scheduling problem},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Centrally-chosen versus user-selected swaps: How the
selection of swapping stations impacts standby battery inventories.
<em>EJOR</em>, <em>319</em>(3), 726–738. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swapping depleted batteries of electric vehicles promises much better driving-to-total-travel-time ratios than plug-in charging. Nonetheless, large-scale battery swapping systems have not successfully established yet. One obstacle, on top of the high infrastructure cost, is certainly the additional invest into extra standby batteries that await their swaps at stations. Existing research is focused on systems in which users decide individually where they want to swap batteries. This system requires significant standby battery inventories to protect against uncertain swapping demand. This paper evaluates another system where users must register their trips on a central platform, so that battery swaps can be coordinated based on central optimization results. To benchmark central optimization and user choice regarding their impact on standby battery inventories, we formulate the min-battery swapping problem: For a given set of vehicle trips, this optimization problem minimizes the number of standby batteries, distributes them in a given station network, and derives detailed swapping plans to feasibly power all trips. First, we present a thorough analysis of computational complexity. Then, we provide an efficient mixed-integer programming formulation that is adaptable to different swapping policies and (when fed into a default solver) solves instances with up to 200 trips to proven optimality in just a few seconds. Our computational study reveals that central optimization promises a significant reduction of standby battery inventories. This potential is shown to increase if swaps of not yet fully-charged batteries are allowed and swaps are pooled at a reduced number of swapping stations.},
  archive      = {J_EJOR},
  author       = {Arne Schulz and Nils Boysen and Dirk Briskorn},
  doi          = {10.1016/j.ejor.2024.07.022},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {726-738},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Centrally-chosen versus user-selected swaps: How the selection of swapping stations impacts standby battery inventories},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A matheuristic for the resource-constrained project
scheduling problem. <em>EJOR</em>, <em>319</em>(3), 711–725. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a matheuristic solution algorithm to solve the well-known resource-constrained project scheduling problem (RCPSP). The problem makes use of a restricted neighbourhood method using an activity selection and a search space restriction module and implements them as two alternative search algorithms. The first algorithm makes use of the best-performing components of the branch-and-bound procedures from the literature, and embeds them into a greedy neighbourhood search. The second matheuristic implements the exact branch-and-bound procedures into a known and well-performing meta-heuristic search algorithm. Computational experiments have been carried out on seven different datasets consisting of 10,000+ project instances. Experiments reveal that the choice of exact algorithm is key in finding high-quality solutions, and illustrate that the trade-off between selecting an activity set size and search space restriction depends on the specific implementation. The computational tests demonstrate that the matheuristic discovered 24 new best known solutions that could not be found by either a meta-heuristic or an exact method individually. Moreover, a new benchmark dataset has been proposed that can be used to develop new matheuristic search procedures to solve the problem consisting of 461 instances from the literature.},
  archive      = {J_EJOR},
  author       = {Mario Vanhoucke and José Coelho},
  doi          = {10.1016/j.ejor.2024.07.016},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {711-725},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A matheuristic for the resource-constrained project scheduling problem},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An exact method for trilevel hub location problem with
interdiction. <em>EJOR</em>, <em>319</em>(3), 696–710. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the problem of designing a hub network that is robust against deliberate attacks (interdictions). The problem is modeled as a three-level, two-player Stackelberg game, in which the network designer (defender) acts first to locate hubs to route a set of flows through the network. The attacker (interdictor) acts next to interdict a subset of the located hubs in the designer’s network, followed again by the defender who routes the flows through the remaining hubs in the network. We model the defender’s problem as a trilevel optimization problem, wherein the attacker’s response is modeled as a bilevel hub interdiction problem. We study such a trilevel problem on three variants of hub location problems studied in the literature namely: p p -hub median problem, p p -hub center, and p p -hub maximal covering problems. We present a cutting plane based exact method to solve the problem. The cutting plane method uses supervalid inequalities, which is obtained from the solution of the lower level interdiction problem. To solve the lower level hub interdiction problem efficiently, we propose a penalty-based reformulation of the problem. Using the reformulation, we present a branch-and-cut based exact approach to solve the problem efficiently. We conduct experiments to show the computational advantages of the above algorithm. To the best of our knowledge, the cutting plane approach proposed in this paper is among the first exact method to solve trilevel location–interdiction problems. Our computational results show interesting implications of incorporating interdiction risks in the hub location problem.},
  archive      = {J_EJOR},
  author       = {Prasanna Ramamoorthy and Sachin Jayaswal and Ankur Sinha and Navneet Vidyarthi},
  doi          = {10.1016/j.ejor.2024.07.013},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {696-710},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An exact method for trilevel hub location problem with interdiction},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Agency models in online platforms: A review of recent
developments and future prospects. <em>EJOR</em>, <em>319</em>(3),
679–695. (<a href="https://doi.org/10.1016/j.ejor.2024.02.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, the ascendancy of the platform economy has led to a significant shift by numerous online merchants, transitioning from the conventional wholesale model to the agency model. Within the agency model, suppliers control pricing decisions, and in exchange for leveraging the online marketplace to access consumers, they apportion a segment of the revenue to the retailers. Reports indicate that third-party sellers are the primary source of Amazon&#39;s income via the agency model. This model has emerged as a prevalent distribution agreement for many physical goods within the digital marketplace. Furthermore, its influence extends to the realm of digital content distribution, as evidenced by its adoption by both Apple and Google in their respective application stores. Notwithstanding the widespread adoption of the agency model in practice, there has been a notable deficiency in the scholarly examination of contemporary advancements in this area. Consequently, this study conducts a systematic review of the agency model. Specifically, we identify and focus on three critical issues regarding the agency model in the literature: the impact of the agency model on channel distribution, how to effectively manage the operations and information management strategy when employing the agency model. Our investigation furnishes an exhaustive synopsis of the latest advances concerning the agency framework and encapsulates pertinent insights for management. We conclude this article by proposing directions for future research.},
  archive      = {J_EJOR},
  author       = {Yinliang (Ricky) Tan and Chuanbin Yu and Yang Liu and Quan Zheng},
  doi          = {10.1016/j.ejor.2024.02.021},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {3},
  pages        = {679-695},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Agency models in online platforms: A review of recent developments and future prospects},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Degree centrality, von neumann–morgenstern expected utility
and externalities in networks. <em>EJOR</em>, <em>319</em>(2), 669–677.
(<a href="https://doi.org/10.1016/j.ejor.2024.06.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to connect the social network literature on centrality measures with the economic literature on von Neumann–Morgenstern expected utility functions using cooperative game theory. The social network literature studies various concepts of network centrality, such as degree, betweenness, connectedness, and so on. This resulted in a great number of network centrality measures, each measuring centrality in a different way. In this paper, we aim to explore which centrality measures can be supported as von Neumann–Morgenstern expected utility functions, reflecting preferences over different network positions in different networks. Besides standard axioms on lotteries and preference relations, we consider neutrality to ordinary risk . We show that this leads to a class of centrality measures that is fully determined by the degrees (i.e. the numbers of neighbours) of the positions in a network. Although this allows for externalities, in the sense that the preferences of a position might depend on the way how other positions are connected, these externalities can be taken into account only by considering the degrees of the network positions. Besides bilateral networks, we extend our result to general cooperative TU-games to give a utility foundation of a class of TU-game solutions containing the Shapley value.},
  archive      = {J_EJOR},
  author       = {René van den Brink and Agnieszka Rusinowska},
  doi          = {10.1016/j.ejor.2024.06.042},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {669-677},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Degree centrality, von Neumann–Morgenstern expected utility and externalities in networks},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Numeraire choice, shadow profit, and inefficiency
measurement. <em>EJOR</em>, <em>319</em>(2), 658–668. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a programming approach to inducing inefficiency measures for convex technologies. It takes the technology and the numeraire as given and uses variational arguments to isolate shadow prices that make a decision maker’s observed behavior as efficient as possible. The focus is on how the numeraire determines the element of the efficient frontier to which a decision maker’s performance is compared, the resulting technical inefficiency measure, and whether that measure offers a cardinal representation of the technology. We use the results to study an inefficiency measure, the polyhedral measure , that generalizes an array of existing measures.},
  archive      = {J_EJOR},
  author       = {Robert G. Chambers},
  doi          = {10.1016/j.ejor.2024.06.041},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {658-668},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Numeraire choice, shadow profit, and inefficiency measurement},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized robust goal programming model. <em>EJOR</em>,
<em>319</em>(2), 638–657. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a concise and generalized robust goal programming (RGP) model that simultaneously considers three types of goal functions – right-side penalties, left-side penalties, and both-side penalties – under uncertainties on both the left-hand side and right-hand side. It integrates common uncertainty sets for a comprehensive goal programming model. Experimental results reveal that our model consistently outperforms existing RGP models by incurring fewer penalties, demonstrating enhanced resilience and robustness. This advantage becomes evident when problem coefficients such as costs, profits, and human resource requirements deviate significantly from their default target levels due to real-world conditions. The proposed model not only extends the robustness of traditional goal programming and weighted fuzzy goal programming but also offers improved risk management across various practical scenarios.},
  archive      = {J_EJOR},
  author       = {Hao-Chun Lu and Shing Chih Tsai},
  doi          = {10.1016/j.ejor.2024.06.037},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {638-657},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Generalized robust goal programming model},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The impact of the correlation coefficient of interarrival
and service times on queueing performance: The m/m/1 case.
<em>EJOR</em>, <em>319</em>(2), 625–637. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned on an M / M / 1 M/M/1 queue with correlated interarrival and service times. In particular, we assume that the interarrival time and service time of a customer have a bivariate exponential distribution. By utilizing a Markov modulated fluid flow (MMFF) process associated with the age process of the customer in service, we obtain a number of queueing quantities in closed form. Using the solutions, the impact of the correlation coefficient of the interarrival and service times on a variety of queueing quantities is explored quantitatively and qualitatively. Specifically, we establish a monotonic relationship between the decay rates of queueing quantities and the correlation coefficient of the interarrival and service times. We also show that the decay rates are increasing in the correlation coefficient. In addition, queues with the maximum/minimum correlation coefficient are analyzed. Two examples are presented to demonstrate the importance of using the correlation coefficient in queueing performance/economic analysis.},
  archive      = {J_EJOR},
  author       = {Haoran Wu and Qi-Ming He and Li Xia},
  doi          = {10.1016/j.ejor.2024.07.032},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {625-637},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The impact of the correlation coefficient of interarrival and service times on queueing performance: The M/M/1 case},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal trading with regime switching: Numerical and
analytic techniques applied to valuing storage in an electricity
balancing market. <em>EJOR</em>, <em>319</em>(2), 611–624. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately valuing storage in the electricity market recognizes its role in enhancing grid flexibility, integrating renewable energy, managing peak loads, providing ancillary services and improving market efficiency. In this paper we outline an optimal trading problem for an Energy Storage Device trading on the electricity balancing (or regulating) market. To capture the features of the balancing (or regulating) market price we combine stochastic differential equations with Markov regime switching to create a novel model, and outline how this can be calibrated to real market data available from NordPool. By modelling a battery that can be filled or emptied instantaneously, this simplifying assumption allows us to generate numerical and quasi analytic solutions. We implement a case study to investigate the behaviour of the optimal strategy, how it is affected by price and underlying model parameters. Using numerical (finite-difference) techniques to solve the dynamic programming problem, we can estimate the value of operating an Energy Storage Device in the market given fixed costs to charge or discharge. Finally we use properties of the numerical solution to propose a simple quasi-analytic approximation to the problem. We find that analytic techniques can be used to give a benchmark value for the storage price when price variations during the day are relatively small.},
  archive      = {J_EJOR},
  author       = {Paul Johnson and Dávid Zoltán Szabó and Peter Duck},
  doi          = {10.1016/j.ejor.2024.06.026},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {611-624},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal trading with regime switching: Numerical and analytic techniques applied to valuing storage in an electricity balancing market},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sequentially extending space-filling experimental designs by
optimally permuting and stacking columns of the design matrix.
<em>EJOR</em>, <em>319</em>(2), 600–610. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers make available computationally expensive designs for computer experiments for widespread use by cataloging them and providing online links. This paper presents an algorithm that augments space-filling designs (SFDs) by optimally permuting and stacking columns of the design matrix to minimize the maximum absolute pairwise correlation among columns in the new extended design. The algorithm enables researchers to augment an SFD sequentially with batches of additional design points, which improves column orthogonality and adds more degrees of freedom for fitting metamodels. We show this method improves the correlation and space-filling properties of the resulting designs and allows us to extend some classes of designs to higher dimensions that are not easily obtainable. Moreover, the resulting extended designs compare well with many leading software-generated SFDs created from scratch in the extended design space.},
  archive      = {J_EJOR},
  author       = {J.D. Parker Jr. and T.W. Lucas and W.M. Carlyle},
  doi          = {10.1016/j.ejor.2024.06.020},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {600-610},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Sequentially extending space-filling experimental designs by optimally permuting and stacking columns of the design matrix},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The impact of retailer regret in two-stage supply chains:
Various structures and buyer power. <em>EJOR</em>, <em>319</em>(2),
587–599. (<a href="https://doi.org/10.1016/j.ejor.2024.07.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a two-stage supply chain (SC) without a buy-back contract, retailers may encounter two types of regrets stemming from demand uncertainty, under-ordering regret and over-ordering regret. We examine the effect of retailer regret on decision making within a competitive environment characterized by many-to-many relationships considering retailers’ buyer power under different SC structures (i.e., various numbers of retailers and suppliers). Furthermore, we compare the impact of regret with and without retailers’ buyer power. We find that: (1) The two types of regret influence the retailers’ order decisions in different directions, and retailers with high-margin (low-margin) are more sensitive to over-ordering (under-ordering) regret, while both types of regret contribute to an elevation in the wholesale price. (2) The effect of regret on SC profits varies depending on the structure of the SC and it may shift from being beneficial to harmful as the number of retailers increases. (3) Regret exhibits a similar influence on equilibrium decisions irrespective of the presence of buyer power, while the effect of regret on SC profits does not vary under different structures when there is no buyer power. The competition among retailers and suppliers in a decentralized SC alters the impact of regret on equilibrium and profit, particularly when retailers possess buyer power. To avoid the adverse effect of retailer regret, we recommend SC retailers take the SC structure and buyer power into account to maximize SC performance. Such findings are crucial to the development of any decentralized SC without buy-back contracts.},
  archive      = {J_EJOR},
  author       = {Wei Gu and Yajin Liu and Yanan Song and Jennifer Shang and T.C.E. Cheng},
  doi          = {10.1016/j.ejor.2024.07.005},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {587-599},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The impact of retailer regret in two-stage supply chains: Various structures and buyer power},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Supervised learning for integrated forecasting and inventory
control. <em>EJOR</em>, <em>319</em>(2), 573–586. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the use of supervised learning with custom loss functions for multi-period inventory control with feature-driven demand. This method directly considers feature information such as promotions and trends to make periodic order decisions, does not require distributional assumptions on demand, and is sample efficient. The application of supervised learning in inventory control has thus far been limited to problems for which the optimal policy structure is known and takes the form of a simple decision rule, such as the newsvendor problem. We present an approximation approach to expand its use to inventory problems where the optimal policy structure is unknown. We test our approach on lost sales, perishable goods, and dual-sourcing inventory problems. It performs on par with state-of-the-art heuristics under stationary demand. It outperforms them for non-stationary perishable goods settings where demand is driven by features, and for non-stationary lost sales and dual-sourcing settings where demand is smooth and feature-driven.},
  archive      = {J_EJOR},
  author       = {Joost F. van der Haar and Arnoud P. Wellens and Robert N. Boute and Rob J.I. Basten},
  doi          = {10.1016/j.ejor.2024.07.004},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {573-586},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Supervised learning for integrated forecasting and inventory control},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Navigating supplier encroachment: Game-theoretic insights
for outsourcing strategies. <em>EJOR</em>, <em>319</em>(2), 557–572. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has become increasingly typical for the upstream suppliers to invest in direct sales channels and compete with the downstream manufacturer. The oft-called phenomenon of supplier encroachment allows the supplier to benefit from both the wholesale to the manufacturer and the sale to end customers. However, from the manufacturer’s perspective, encroachment may suggest the supplier’s lack of reliability, which can contribute to the breakdown of supplier–manufacturer collaboration. In response to the supplier’s encroachment, the manufacturer can change its supplier(s); while the encroaching supplier might face consequences (e.g., the manufacturer dropping the supplier to seek new partnerships). The existence of future outsourcing alternatives for the manufacturer and the future consequences for the supplier has not been studied in the extant literature. In this paper we propose a two-period game-theoretic approach to supplier encroachment; where the downstream manufacturer outsources the production to a group of suppliers that are characterized by a low-quality supplier without encroachment capabilities, and a high-quality supplier with encroachment capabilities, i.e., capable of launching its own independent product. We show that (a) an increase in the quality of the encroaching supplier’s independent product can convince the manufacturer to redirect its wholesale order from the non-encroaching supplier to the encroaching supplier and simultaneously boost the manufacturer’s profits, (b) as the quality of the non-encroaching supplier is improved, the manufacturer may opt to drop the non-encroaching supplier and redirect its wholesale order to the encroaching supplier instead, and (c) an improvement in the qualities of the encroaching and non-encroaching suppliers might decrease their corresponding profits. Accordingly, we offer actionable guidelines for practitioners; in particular, we help practitioners navigate the competitive outsourcing landscape under threat of encroachment and advise them on the counter-productive impacts of quality improvements.},
  archive      = {J_EJOR},
  author       = {Shobeir Amirnequiee and Hubert Pun and Joe Naoum-Sawaya},
  doi          = {10.1016/j.ejor.2024.07.003},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {557-572},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Navigating supplier encroachment: Game-theoretic insights for outsourcing strategies},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A matheuristic for integrated medium-term home healthcare
planning. <em>EJOR</em>, <em>319</em>(2), 543–556. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to staff shortages and budget restrictions, home healthcare service providers struggle to construct efficient schedules to service the growing number of people that require medical services at home. Previous research on home healthcare planning concentrates on planning periods of one to seven days, often does not focus on including real-life characteristics, and generally develops a heuristic procedure dealing with decisions sequentially or an exact approach that may not always scale very well. In this study, we propose an integrated solution approach that considers various real-life characteristics, such as service patterns, skill levels, continuity of care, and working time limits, to construct a detailed home healthcare schedule for a four-week planning horizon. The proposed approach integrates rostering , assignment , routing , and scheduling decisions, as joint optimisation of interdependent decisions enables better overall planning. The solution approach is a matheuristic based on large neighbourhood search and efficiently solves large, realistic instances. The proposed integrated algorithm approximates the optimal solutions of small instances with an average gap of merely 0.18%. It also outperforms a sequential solution method that mimics the planning procedure currently applied in practice, resulting in average cost improvements of 28.69%. A sensitivity analysis indicates that adhering to strict continuity of care constraints results in only a minimal increase in costs for service providers when decision-making is integrated. Furthermore, the efficiency of a medium-term home healthcare schedule can be significantly improved if patients are flexible concerning their availabilities and if working a small amount of overtime is allowed.},
  archive      = {J_EJOR},
  author       = {Arne Delaet and Katrien Ramaekers and Patrick Hirsch and Yves Molenbruch and Kris Braekers},
  doi          = {10.1016/j.ejor.2024.07.001},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {543-556},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A matheuristic for integrated medium-term home healthcare planning},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural network assisted branch and bound algorithm for
dynamic berth allocation problems. <em>EJOR</em>, <em>319</em>(2),
531–542. (<a href="https://doi.org/10.1016/j.ejor.2024.06.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the key challenges in maritime operations at container terminals is the need to improve or optimize berth operation schedules, thus allowing terminal operators to maximize the efficiency of quay usage. Given a set of vessels and a set of berths, the goal of the dynamic berth allocation problem is to determine the allocation of each vessel to a berth and the berthing time that minimizes the total service time. This problem can be solved using exact solution methods such as branch and bound (BB) algorithms or heuristic methods, however, exact methods do not scale to large-scale terminal operations. To this end, this paper proposes a BB algorithm in which branching decisions are made with a deep neural network. The proposed exact algorithm utilizes the search order of nodes based on the output of the neural network, with the goal of speeding up the search. Three types of solution representations are compared, along with machine learning models are created for each of them. Computational results confirm the effectiveness of the proposed method, which leads to computation times that are on average around half of those without the neural network.},
  archive      = {J_EJOR},
  author       = {Shinya Korekane and Tatsushi Nishi and Kevin Tierney and Ziang Liu},
  doi          = {10.1016/j.ejor.2024.06.040},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {531-542},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Neural network assisted branch and bound algorithm for dynamic berth allocation problems},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Augmented patterns for decomposition of scheduling and
assignment problems. <em>EJOR</em>, <em>319</em>(2), 517–530. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scheduling and assignment are relevant decisions widespread in complex organizations that produce goods or deliver services. Industrial companies and service providers periodically make these decisions that take into account their specific context in terms of objectives and constraints. As a consequence, a multitude of mathematical models for solving specific scheduling and assignment problems have been investigated in the literature. This paper tackles the problem differently by proposing a general two-phase decomposition framework in which the first phase grasps the key elements of the problem, while the second phase customizes the solution to the specific application addressed. Both phases are based on a mathematical model. The first model considers a set of kernel constraints and generates a set of patterns that link scheduling to assignment decisions. This model is flexible in the criteria used to generate the patterns and considers the finite and heterogeneous capacity of the critical resources to schedule and assign. The second model benefits from the patterns identified by the first phase, that reduce the solution space; this reduction is fundamental because the second model considers all the problem features. To show the generality of the approach, the methodology was applied in diverse application contexts by formulating the augmented pattern generation model with objective functions and constraints custom to the application context. Computational results, obtained from a pool of small to large instances generated from a case study in the Home Care sector, are also presented.},
  archive      = {J_EJOR},
  author       = {Paola Cappanera and Andrea Matta and Maria Grazia Scutellà and Martino Singuaroli},
  doi          = {10.1016/j.ejor.2024.06.004},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {517-530},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Augmented patterns for decomposition of scheduling and assignment problems},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An effective subgradient algorithm via mifflin’s line search
for nonsmooth nonconvex multiobjective optimization. <em>EJOR</em>,
<em>319</em>(2), 505–516. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a descent subgradient algorithm for unconstrained nonsmooth nonconvex multiobjective optimization problems. To find a descent direction, we present an iterative process that efficiently approximates the ɛ ɛ ɛ -subdifferential of each objective function. To this end, we develop a new variant of Mifflin’s line search in which the subgradients are arbitrary and its finite convergence is proved under a semismooth assumption. To reduce the number of subgradient evaluations, we employ a backtracking line search that identifies the objectives requiring an improvement in the current approximation of the ɛ ɛ ɛ -subdifferential. Meanwhile, for the remaining objectives, new subgradients are not computed. Unlike bundle-type methods, the proposed approach can handle nonconvexity without the need for algorithmic adjustments. Moreover, the quadratic subproblems have a simple structure, and hence the method is easy to implement. We analyze the global convergence of the proposed method and prove that any accumulation point of the generated sequence satisfies a necessary Pareto optimality condition. Furthermore, our convergence analysis addresses a theoretical challenge in a recently developed subgradient method. Through numerical experiments, we observe the practical capability of the proposed method and evaluate its efficiency when applied to a diverse range of nonsmooth test problems.},
  archive      = {J_EJOR},
  author       = {Morteza Maleknia and Majid Soleimani-damaneh},
  doi          = {10.1016/j.ejor.2024.07.019},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {505-516},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An effective subgradient algorithm via mifflin’s line search for nonsmooth nonconvex multiobjective optimization},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large-scale robust regression with truncated loss via
majorization-minimization algorithm. <em>EJOR</em>, <em>319</em>(2),
494–504. (<a href="https://doi.org/10.1016/j.ejor.2024.04.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of regression methods employing truncated loss functions is widely praised for its robustness in handling outliers and representing the solution in the sparse form of the samples. However, due to the non-convexity of the truncated loss, the commonly used algorithms such as difference of convex algorithm (DCA) fail to maintain sparsity when dealing with non-convex loss functions, and adapting DCA for efficient optimization also incurs additional development costs. To address these challenges, we propose a novel approach called truncated loss regression via majorization-minimization algorithm (TLRM). TLRM employs a surrogate function to approximate the original truncated loss regression and offers several desirable properties: (i) Eliminating outliers before the training process and encapsulating general convex loss regression within its structure as iterative subproblems, (ii) Solving the convex loss problem iteratively thereby facilitating the use of a well-established toolbox for convex optimization. (iii) Converging to a truncated loss regression and providing a solution with sample sparsity. Extensive experiments demonstrate that TLRM achieves superior sparsity without sacrificing robustness, and it can be several tens of thousands of times faster than traditional DCA on large-scale problems. Moreover, TLRM is also applicable to datasets with millions of samples, making it a practical choice for real-world scenarios. The codebase for methods with truncated loss functions is accessible at https://i-do-lab.github.io/optimal-group.org/Resources/Code/TLRM.html .},
  archive      = {J_EJOR},
  author       = {Ling-Wei Huang and Yuan-Hai Shao and Xiao-Jing Lv and Chun-Na Li},
  doi          = {10.1016/j.ejor.2024.04.028},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {494-504},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Large-scale robust regression with truncated loss via majorization-minimization algorithm},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerated double-sketching subspace newton. <em>EJOR</em>,
<em>319</em>(2), 484–493. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a second-order stochastic algorithm called Accelerated Double-Sketching Subspace Newton (ADSSN) to solve large-scale optimization problems with high dimensional feature spaces and substantial sample sizes. The proposed ADSSN has two computational superiority. First, ADSSN achieves a fast local convergence rate by exploiting Nesterov’s acceleration technique. Second, by taking full advantage of the double sketching strategy, ADSSN provides a lower computational cost for each iteration than competitive approaches. Moreover, these advantages hold for actually all sketching techniques, which enables practitioners to design custom sketching methods for specific applications. Finally, numerical experiments are carried out to demonstrate the efficiency of ADSSN compared with accelerated gradient descent and two single sketching counterparts.},
  archive      = {J_EJOR},
  author       = {Jun Shang and Haishan Ye and Xiangyu Chang},
  doi          = {10.1016/j.ejor.2024.04.002},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {484-493},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Accelerated double-sketching subspace newton},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scheduling robotic cells with fixed processing times or time
windows: Classification, solution approaches, polynomial algorithms and
complexity. <em>EJOR</em>, <em>319</em>(2), 468–483. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic cell scheduling has received considerable attention from researchers. Several existing review papers have presented then-existing studies on robotic cell scheduling and related fields from different perspectives. Since the latest review, numerous new results have emerged, contributing significant advancements in recent years. Furthermore, certain features of these problems have not been appropriately addressed. This paper aims to provide an up-to-date review and present our particular perspectives to address recent publications on scheduling robotic cells with fixed processing times or time windows. First, we identify various characteristics of robotic cell scheduling and explain their impact on the structure and complexity. Based on these characteristics, the related robotic cell scheduling studies are classified and compared in various dimensions. Second, we present complexity results, along with both exact and approximation solution techniques, for the robotic cell scheduling problem with time windows or fixed processing times. These results are presented in tabular forms to visually reveal the relationships between different problem configurations and their respective solution approaches. Finally, we discern emerging trends in the realm of robotic cell scheduling research, subsequently indicating prospective directions for future investigations.},
  archive      = {J_EJOR},
  author       = {Jianguang Feng and Ada Che and Chengbin Chu and Eugene Levner and Vladimir Kats},
  doi          = {10.1016/j.ejor.2024.01.041},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {468-483},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Scheduling robotic cells with fixed processing times or time windows: Classification, solution approaches, polynomial algorithms and complexity},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A framework for fair decision-making over time with
time-invariant utilities. <em>EJOR</em>, <em>319</em>(2), 456–467. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fairness is a major concern in contemporary decision problems. In these situations, the objective is to maximize fairness while preserving the efficacy of the underlying decision-making problem. This paper examines repeated decisions on problems involving multiple stakeholders and a central decision maker. Repetition of the decision-making provides additional opportunities to promote fairness while increasing the complexity from symmetry to finding solutions. This paper presents a general mathematical programming framework for the proposed fairness-over-time (FOT) decision-making problem. The framework includes a natural abstraction of how a stakeholder’s acquired utilities can be aggregated over time. In contrast with a natural, descriptive formulation, we demonstrate that if the aggregation function possesses certain basic properties, a strong reformulation can be written to remove symmetry from the problem, making it amenable to branch-and-cut solvers. Finally, we propose a particular relaxation of this reformulation that can assist in the construction of high-quality approximate solutions to the original problem and can be solved using simultaneous row and column generation techniques.},
  archive      = {J_EJOR},
  author       = {Andrea Lodi and Sriram Sankaranarayanan and Guanyi Wang},
  doi          = {10.1016/j.ejor.2023.11.030},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {456-467},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A framework for fair decision-making over time with time-invariant utilities},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Frequency regulation with storage: On losses and profits.
<em>EJOR</em>, <em>319</em>(2), 442–455. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-carbon societies will need to store vast amounts of electricity to balance intermittent generation from wind and solar energy, for example, through frequency regulation. Here, we derive an analytical solution to the decision-making problem of storage operators who sell frequency regulation power to grid operators and trade electricity on day-ahead markets. Mathematically, we treat future frequency deviation trajectories as functional uncertainties in a receding horizon robust optimization problem. We constrain the expected terminal state-of-charge to be equal to some target to allow storage operators to make good decisions not only for the present but also the future. Thanks to this constraint, the amount of electricity traded on day-ahead markets is an implicit function of the regulation power sold to grid operators. The implicit function quantifies the amount of power that needs to be purchased to cover the expected energy loss that results from providing frequency regulation. We show how the marginal cost associated with the expected energy loss decreases with roundtrip efficiency and increases with frequency deviation dispersion. We find that the profits from frequency regulation over the lifetime of energy-constrained storage devices are roughly inversely proportional to the length of time for which regulation power must be committed.},
  archive      = {J_EJOR},
  author       = {Dirk Lauinger and François Vuille and Daniel Kuhn},
  doi          = {10.1016/j.ejor.2024.03.022},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {442-455},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Frequency regulation with storage: On losses and profits},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Security-constrained unit commitment: A decomposition
approach embodying kron reduction. <em>EJOR</em>, <em>319</em>(2),
427–441. (<a href="https://doi.org/10.1016/j.ejor.2023.06.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the day-ahead scheduling of electricity production units throughout a network imposing N-1 security constraints, which ensures uneventful operation under any single-branch failure. For realistic electric energy systems, this optimization problem, which is mixed-integer linear or nonlinear but convex, involves millions of continuous variables, millions of constraints, and thousands of binary variables. This problem is intractable if state-of-the-art branch-and-cut solvers are used. As a solution methodology, we propose a Benders-type decomposition technique with a dynamically enriched master problem. Such master problem incorporates scheduling (binary) decisions and decisions pertaining to under-contingency operating conditions. The subproblems represent the operation of the system under no failure and single-branch failure. As the algorithm progresses, the master problem incorporates additional under-contingency operating conditions, which increases its computational burden. We use Kron reduction to compact (reducing variables and constraints) the description of the under-contingency operating conditions in the master problem without losing accuracy, which renders major computational gains. The methodology proposed allows solving, within reasonable computing times, instances intractable with state-of-the-art branch-and-cut solvers and decomposition algorithms.},
  archive      = {J_EJOR},
  author       = {Gonzalo E. Constante-Flores and Antonio J. Conejo},
  doi          = {10.1016/j.ejor.2023.06.013},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {427-441},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Security-constrained unit commitment: A decomposition approach embodying kron reduction},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A regularized interior point method for sparse optimal
transport on graphs. <em>EJOR</em>, <em>319</em>(2), 413–426. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the authors address the Optimal Transport (OT) problem on graphs using a proximal stabilized Interior Point Method (IPM). In particular, strongly leveraging on the induced primal–dual regularization, the authors propose to solve large scale OT problems on sparse graphs using a bespoke IPM algorithm able to suitably exploit primal–dual regularization in order to enforce scalability. Indeed, the authors prove that the introduction of the regularization allows to use sparsified versions of the normal Newton equations to inexpensively generate IPM search directions. A detailed theoretical analysis is carried out showing the polynomial convergence of the inner algorithm in the proposed computational framework. Moreover, the presented numerical results showcase the efficiency and robustness of the proposed approach when compared to network simplex solvers.},
  archive      = {J_EJOR},
  author       = {S. Cipolla and J. Gondzio and F. Zanetti},
  doi          = {10.1016/j.ejor.2023.11.027},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {413-426},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A regularized interior point method for sparse optimal transport on graphs},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mathematical optimization modelling for group counterfactual
explanations. <em>EJOR</em>, <em>319</em>(2), 399–412. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfactual Analysis has shown to be a powerful tool in the burgeoning field of Explainable Artificial Intelligence. In Supervised Classification, this means associating with each record a so-called counterfactual explanation: an instance that is close to the record and whose probability of being classified in the opposite class by a given classifier is high. While the literature focuses on the problem of finding one counterfactual for one record, in this paper we take a stakeholder perspective, and we address the more general setting in which a group of counterfactual explanations is sought for a group of instances. We introduce some mathematical optimization models as illustration of each possible allocation rule between counterfactuals and instances, and we identify a number of research challenges for the Operations Research community.},
  archive      = {J_EJOR},
  author       = {Emilio Carrizosa and Jasone Ramírez-Ayerbe and Dolores Romero Morales},
  doi          = {10.1016/j.ejor.2024.01.002},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {399-412},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mathematical optimization modelling for group counterfactual explanations},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Operations research approaches for improving coordination,
cooperation, and collaboration in humanitarian relief chains: A
framework and literature review. <em>EJOR</em>, <em>319</em>(2),
384–398. (<a href="https://doi.org/10.1016/j.ejor.2023.11.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the considerable number of actors in the humanitarian space, coordination is essential for successful disaster response. Furthermore, the sheer size of challenges and limited resources increasingly highlight the need for improved cooperation and collaboration in humanitarian supply chains. A significant number of studies in the literature explore the 3Cs (coordination, cooperation and collaboration), using conceptual, empirical and analytical methods. This paper aims to provide an overview and analysis of the Operations Research (OR) approaches that support decision making for improved 3Cs in humanitarian relief chains and to identify future research directions. To achieve this aim, we first present a holistic view of the discussions in the literature and derive a conceptual framework for 3C mechanisms in humanitarian operations. Based on our framework, we analyse studies that develop OR methods to address the design and management of 3C mechanisms in humanitarian relief chains. We also identify current gaps and future research directions.},
  archive      = {J_EJOR},
  author       = {Birce Adsanver and Burcu Balcik and Valérie Bélanger and Marie-Ève Rancourt},
  doi          = {10.1016/j.ejor.2023.11.031},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {384-398},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Operations research approaches for improving coordination, cooperation, and collaboration in humanitarian relief chains: A framework and literature review},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Managing grand challenges: Extending the scope of problem
structuring methods and behavioural operational research. <em>EJOR</em>,
<em>319</em>(2), 373–383. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing Grand Challenges (GC), such as navigating climate change or aging societies, is increasingly gaining prominence across the globe. Those researching and addressing such challenges argue that progress requires collaborative, integrated, and coordinated responses from a wide range of stakeholders including organisations, governments, communities, etc. To successfully navigate these challenges, approaches need to be able to engage with stakeholders in two ways. Firstly, in terms of eliciting a comprehensive understanding of the challenge as viewed through the many stakeholder lenses and thus managing the resultant complexity of that data and secondly through attending to the myriad socio-political considerations. Problem Structuring Methods (PSM) through their focus on managing messy, complex, wicked problems are well situated to assist in this endeavour, particularly when coupled with the growing body of work in the field of Behavioural OR (BOR). This paper illustrates how PSM with BOR can address Grand Challenges by mapping the characteristics together and proposing a framework depicting the potential contribution.},
  archive      = {J_EJOR},
  author       = {Fran Ackermann},
  doi          = {10.1016/j.ejor.2024.01.024},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {373-383},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Managing grand challenges: Extending the scope of problem structuring methods and behavioural operational research},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Current and future trends in vertical transportation.
<em>EJOR</em>, <em>319</em>(2), 361–372. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the middle of the 19th century, the invention of a safety device that prevented elevators from falling enabled the construction of tall buildings and skyscrapers. In the middle of the 20th century, control systems started to serve the given calls automatically by relay technology, and later by electro-mechanical systems. In the 1970s-80 s, software-based control systems invaded elevator technology. Passenger service levels improved with the application of mathematical methods such as artificial intelligence. When the old relay boards of the skyscrapers in New York were modernized by software-based group controls, passenger waiting times dropped to less than half. In this millennium, the need to reduce elevator core space has further increased, since a significant number of buildings already exceed 300 m. The challenge in constructing tall buildings is that elevator groups can occupy the rentable area of a building. At the elevator planning stage, elevator core space can be decreased by zoning the building. The latest trends include systems with several elevator cars running in the same shaft. With modern control systems, passenger journey times can be decreased and handling capacity increased. This article deals with mathematical methods used in elevator dispatching problems. Building traffic simulation is utilized to search for an elevator arrangement that saves the most space in an example building. The design criteria of the ISO 8100–32 standard are used in selecting the elevator arrangements.},
  archive      = {J_EJOR},
  author       = {Marja-Liisa Siikonen},
  doi          = {10.1016/j.ejor.2024.05.016},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {361-372},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Current and future trends in vertical transportation},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fifty years of operational research: 1972–2022.
<em>EJOR</em>, <em>319</em>(2), 347–360. (<a
href="https://doi.org/10.1016/j.ejor.2023.05.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In July 2022, I received the EURO Gold medal at the 32 nd EURO Conference held in Espoo, Finland. This paper is based on the presentation I made at the medal award ceremony. It covers 10 topics on which I have worked throughout my career. These are the seriation problem, rotating work schedules, deterministic vehicle routing, stochastic vehicle routing, examination timetabling, districting, waste management, metro network design, green transportation, and humanitarian logistics.},
  archive      = {J_EJOR},
  author       = {Gilbert Laporte},
  doi          = {10.1016/j.ejor.2023.05.038},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {347-360},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fifty years of operational research: 1972–2022},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guest editorial to the special issue of the 32nd european
conference on operational research in espoo (finland). <em>EJOR</em>,
<em>319</em>(2), 345–346. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Antti Punkka and Dolores Romero Morales},
  doi          = {10.1016/j.ejor.2024.07.008},
  journal      = {European Journal of Operational Research},
  month        = {12},
  number       = {2},
  pages        = {345-346},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Guest editorial to the special issue of the 32nd european conference on operational research in espoo (Finland)},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Risk-aversion versus risk-loving preferences in
nonparametric frontier-based fund ratings: A buy-and-hold backtesting
strategy. <em>EJOR</em>, <em>319</em>(1), 332–344. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The eventual risk-loving nature of preferences of investors has largely been ignored in the existing frontier-based fund rating literature. This contribution develops a series of nonparametric frontier-based methods to rate mutual funds accounting for both mixed risk-loving and mixed risk-aversion preferences. These new methods are proposed by defining the corresponding shortage functions that can allow for increases in all moments, or increases in odd moments and reductions in even moments. The empirical part designs a buy-and-hold backtesting to test the out-of-sample performance of the proposed rating methods corresponding to different risk preferences on the actual MF selection. The evidence indicates that the backtesting strategies based on the output frontier-based rating models with risk-loving preferences exhibit an overwhelming dominance compared to most existing frontier-based and traditional financial ratings.},
  archive      = {J_EJOR},
  author       = {Tiantian Ren and Kristiaan Kerstens and Saurav Kumar},
  doi          = {10.1016/j.ejor.2024.06.013},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {332-344},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Risk-aversion versus risk-loving preferences in nonparametric frontier-based fund ratings: A buy-and-hold backtesting strategy},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A bilevel programming approach to price decoupling in
pay-as-clear markets, with application to day-ahead electricity markets.
<em>EJOR</em>, <em>319</em>(1), 316–331. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the recent crisis of the European electricity markets, we propose the concept of Segmented Pay-as-Clear (SPaC) market, introducing a new family of market clearing problems that achieve a degree of decoupling between groups of participants. This requires a relatively straightforward modification of the standard PaC model and retains its crucial features by providing both long- and short-term sound price signals. The approach is based on dynamically partitioning demand across the segmented markets, where the partitioning is endogenous, i.e., controlled by the model variables, and is chosen to minimise the total system cost. The thusly modified model leads to solving Bilevel Programming problems, or more generally Mathematical Programs with Complementarity Constraints; these have a higher computational complexity than those corresponding to the standard PaC, but in the same ballpark as the models routinely used in real-world Day Ahead Markets (DAMs) to represent “nonstandard” requirements, e.g., the unique buying price in the Italian DAM. Thus, SPaC models should still be solvable in a time compatible with market operation with appropriate algorithmic tools. Like all market models, SPaC is not immune to strategic bidding techniques, but some theoretical results indicate that, under the right conditions, the effect of these could be limited. An initial experimental analysis of the proposed models, carried out through Agent Based simulations, seems to indicate a good potential for significant system cost reductions and an effective decoupling of the two markets.},
  archive      = {J_EJOR},
  author       = {Antonio Frangioni and Fabrizio Lacalandra},
  doi          = {10.1016/j.ejor.2024.06.018},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {316-331},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A bilevel programming approach to price decoupling in pay-as-clear markets, with application to day-ahead electricity markets},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mathematical optimisation in the honeycomb cardboard
industry: A model for the two-dimensional variable-sized cutting stock
problem. <em>EJOR</em>, <em>319</em>(1), 303–315. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a mixed-integer linear programming model for a two-dimensional variable-sized cutting stock problem with guillotine cuts that arises in the honeycomb cardboard sector. This research is developed in collaboration with a company based in Spain. The aim is not only to define the cutting patterns but also to establish the dimensions (width and length) of the panels to be produced, in such a way that the amount of material used is minimised. This particular problem belongs to the family of Cutting Stock Problems involving a Variable-Sized Stock, where the size of the panels in stock is not known in advance and is determined by the model itself. Cutting Stock Problems with Variable Sized Stock have recently been introduced in two papers, one of them in the textile sector and the other in the cardboard sector. This paper proposes a model for the latter sector that allows cutting patterns with more than one type of item, a feature that has not been considered beforehand. This, therefore, provides considerable flexibility to the model and broadens its range of applications. Moreover, the model has been validated on real data with high variability in its characteristics. The results indicate that the material used can be drastically reduced compared to the company’s current operation.},
  archive      = {J_EJOR},
  author       = {Paula Terán-Viadero and Antonio Alonso-Ayuso and F. Javier Martín-Campo},
  doi          = {10.1016/j.ejor.2024.06.022},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {303-315},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mathematical optimisation in the honeycomb cardboard industry: A model for the two-dimensional variable-sized cutting stock problem},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving constrained consumption–investment problems by
decomposition algorithms. <em>EJOR</em>, <em>319</em>(1), 292–302. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumption–investment problems with maximizing utility agents are usually considered from a theoretical viewpoint, aiming at closed-form solutions for the optimal policy. However, such an approach requires that the model be relatively simple: even the inclusion of nonnegativity constraints can prevent the derivation of explicit solutions. In such cases, it is necessary to solve the problem numerically, but standard dynamic programming algorithms can only solve small problems due to the curse of dimensionality. In this paper, we adapt the Stochastic Dual Dynamic Programming (SDDP) algorithm to solve dynamic constrained consumption–investment problems with stochastic labor income numerically. Unlike classical dynamic programming approaches, SDDP allows us to analyze problems with multiple assets, and an internal sampling procedure allows the problems to have a very large, or even infinite, number of scenarios. We start with a simpler problem for which a closed-form solution is known and compare it to the optimal policy obtained by SDDP. We then illustrate the flexibility of our approach by solving a defined contribution pension fund problem with multiple assets, for which no closed-form solution is available.},
  archive      = {J_EJOR},
  author       = {Bernardo K. Pagnoncelli and Tito Homem-de-Mello and Guido Lagos and Pablo Castañeda and Javier García},
  doi          = {10.1016/j.ejor.2024.06.027},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {292-302},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solving constrained consumption–investment problems by decomposition algorithms},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multicriteria optimization techniques for understanding the
case mix landscape of a hospital. <em>EJOR</em>, <em>319</em>(1),
263–291. (<a href="https://doi.org/10.1016/j.ejor.2024.05.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various medical and surgical units operate in a typical hospital and to treat their patients these units compete for infrastructure like operating rooms (OR) and ward beds. How that competition is regulated affects the capacity and output of a hospital. This article considers the impact of treating different patient case mix (PCM). As each case mix has an economic consequence and a unique profile of hospital resource usage, this consideration is important. To better understand the case mix landscape and to identify those which are optimal from a capacity utilisation perspective, an improved multicriteria optimization (MCO) approach is proposed. As there are many patient types in a typical hospital, the task of generating an archive of non-dominated (i.e., Pareto optimal) case mix is computationally challenging. To generate a better archive, an improved parallelised epsilon constraint method (ECM) is introduced. Our parallel random corrective approach is significantly faster than prior methods and is not restricted to evaluating points on a structured uniform mesh. As such we can generate more solutions. The application of KD-Trees is another new contribution. We use them to perform proximity testing and to store the high dimensional Pareto frontier (PF). For generating, viewing, navigating, and querying an archive, the development of a suitable decision support tool (DST) is proposed and demonstrated.},
  archive      = {J_EJOR},
  author       = {Robert L Burdett and Paul Corry and Prasad Yarlagadda and David Cook and Sean Birgan},
  doi          = {10.1016/j.ejor.2024.05.030},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {263-291},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multicriteria optimization techniques for understanding the case mix landscape of a hospital},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The deck of cards method to build interpretable fuzzy sets
in decision-making. <em>EJOR</em>, <em>319</em>(1), 246–262. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the construction of interpretable fuzzy sets by following a socio-technical-based approach, where two key actors, the (decision) analyst, and the decision-maker, interact in a co-constructive way for building a membership function that accurately represents the decision-maker’s individualized semantics, even when considering heterogeneous scales. In the proposed approach, the membership function is not provided directly but rather built from the (social) interaction of these two actors, where the technicalities of the methods are presented to the decision-maker by the analyst in a very simple way. This means that the decision-maker’s preferences will be constructed through a process in order to she/he will get more knowledge about her/his own problem. The interpretability of each membership function is now a fundamental aspect of the way the decision-maker was involved in the process. Since technical aspects are based on the Deck of Cards Method, a well-known tool for assessing the parameters of multiple criteria decision-making problems, the obtained membership functions will receive the name of DoC-MFs, from Deck of Cards-based Membership Functions. This paper also presents examples and a case study in the field of sustainability to show the applicability of the proposed methodology.},
  archive      = {J_EJOR},
  author       = {Diego García-Zamora and Bapi Dutta and José Rui Figueira and Luis Martínez},
  doi          = {10.1016/j.ejor.2024.06.039},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {246-262},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The deck of cards method to build interpretable fuzzy sets in decision-making},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A bilateral deliberation mechanism for conflict resolving
with multi-actor and multi-criteria. <em>EJOR</em>, <em>319</em>(1),
234–245. (<a href="https://doi.org/10.1016/j.ejor.2024.06.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-actor multi-criteria analysis (MAMCA) is widely used to support group decision-making processes that involve various stakeholders. These stakeholders usually have divergent attributes and heterogeneous preferences, which leads to conflicting views on certain pre-set criteria. To deal with this issue, we propose a four-step conflict resolution approach to diagnose and mitigate such conflicts. This approach integrates a correlation-based technique with a search function to identify the criteria that cause the conflict between stakeholders and measure to what extent each criterion contributes to such a conflict. On this basis, we design a bilateral deliberation mechanism to resolve group conflict by resolving conflict between pairs of stakeholders. The experimental results indicate that, from the perspectives of effectiveness and fairness, the bilateral deliberation mechanism outperforms the traditional conflict mitigation approach that requires all stakeholders to participate in a conversation together. Moreover, the bilateral deliberation mechanism is adequate for important decision-making events where any concessions made will be very costly for participants.},
  archive      = {J_EJOR},
  author       = {Shucheng Luo and Zeshui Xu and Bin Zhu},
  doi          = {10.1016/j.ejor.2024.06.028},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {234-245},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A bilateral deliberation mechanism for conflict resolving with multi-actor and multi-criteria},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Double hedonic price-characteristics frontier estimation for
IoT service providers in the industry 5.0 era: A nonconvex perspective
accommodating ratios. <em>EJOR</em>, <em>319</em>(1), 222–233. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of advanced digital technologies, including the Internet of Things (IoT), image processing, artificial intelligence (AI), blockchain, robotics and cognitive computing that have been embedded in Industry 5.0, is considerably improving the sustainability, resilience, and human-centric performance of industrial organizations. Despite the increasing use of Industry 5.0 technologies in smart product platforming in industrial organizations, a critical issue remains how to assess the providers/suppliers of such technologies in highly competitive markets to fulfil personalized products and services. Following Lancaster&#39;s characteristics approach to consumer theory, in this study we contribute to assess digital technologies service providers in the Industry 5.0 era by focusing on both theoretical and empirical evidence inquiring about the convexity of conventional nonparametric frontier estimation methods. To do so, a nonparametric double frontier estimation of the hedonic price characteristics relation is developed from both the buyer&#39;s and seller&#39;s perspectives. Moreover, a separable directional distance function-based optimization model is developed for the efficiency estimation. Furthermore, a comparable estimation of the convex and nonconvex hedonic price function is proposed. We also explicitly test the impact of convexity in evaluating the efficiency of IoT service providers in the Industry 5.0 context. In this study, we also show that the hypothesis of convexity in assessing the efficiency of IoT service providers is rejected using the Li-test comparing entire densities in the case of the seller&#39;s perspective without ratio data. Differences are less pronounced for the buyer&#39;s perspective and in the case with ratio data.},
  archive      = {J_EJOR},
  author       = {Kristiaan Kerstens and Majid Azadi and Reza Kazemi Matin and Reza Farzipoor Saen},
  doi          = {10.1016/j.ejor.2024.05.047},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {222-233},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Double hedonic price-characteristics frontier estimation for IoT service providers in the industry 5.0 era: A nonconvex perspective accommodating ratios},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mixed-model sequencing with stochastic failures: A case
study for automobile industry. <em>EJOR</em>, <em>319</em>(1), 206–221.
(<a href="https://doi.org/10.1016/j.ejor.2024.06.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the automotive industry, the sequence of vehicles to be produced is determined ahead of the production day. However, there are some vehicles, failed vehicles, that cannot be produced due to some reasons such as material shortage or paint failure. These vehicles are pulled out of the sequence, and the vehicles in the succeeding positions are moved forward, potentially resulting in challenges for logistics or other scheduling concerns. This paper proposes a two-stage stochastic program for the mixed-model sequencing (MMS) problem with stochastic product failures, and provides improvements to the second-stage problem. To tackle the exponential number of scenarios, we employ the sample average approximation approach and two solution methodologies. On one hand, we develop an L-shaped decomposition-based algorithm, where the computational experiments show its superiority over solving the extensive equivalent formulation with an off-the-shelf solver. Moreover, we provide a tabu search algorithm in addition to a greedy heuristic to tackle case study instances inspired by our car manufacturer partner. Numerical experiments show that the proposed solution methodologies generate high-quality solutions by utilizing a sample of scenarios. Particularly, a robust sequence that is generated by considering car failures can decrease the expected work overload by more than 20% for both small- and large-sized instances.},
  archive      = {J_EJOR},
  author       = {I. Ozan Yilmazlar and Mary E. Kurz and Hamed Rahimian},
  doi          = {10.1016/j.ejor.2024.06.019},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {206-221},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mixed-model sequencing with stochastic failures: A case study for automobile industry},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonparametric multi-product dynamic pricing with demand
learning via simultaneous price perturbation. <em>EJOR</em>,
<em>319</em>(1), 191–205. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of multi-product dynamic pricing with demand learning and propose a nonparametric online learning algorithm based on the simultaneous perturbation stochastic approximation (SPSA) method. The algorithm uses only two price experimentations at each iteration, regardless of problem dimension, and could be especially efficient for solving high-dimensional problems. Under moderate conditions, we prove that the price estimates converge in mean-squared error (MSE) to the optimal price. Furthermore, we show that by suitably choosing input parameters, our algorithm achieves an expected cumulative regret of order O T OT over T T periods, which is the best possible growth rate in the literature. The exact constants in the rate can be identified explicitly. We investigate the extensions of the algorithm to application scenarios characterized by non-stationary demand and inventory constraints. Simulation experiments reveal that our algorithm is effective for a range of test problems and performs favorably compared with a recently proposed alternative method for high-dimensional problems.},
  archive      = {J_EJOR},
  author       = {Xiangyu Yang and Jianghua Zhang and Jian-Qiang Hu and Jiaqiao Hu},
  doi          = {10.1016/j.ejor.2024.06.017},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {191-205},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nonparametric multi-product dynamic pricing with demand learning via simultaneous price perturbation},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time train timetabling with virtual coupling operations
on a y-type metro line. <em>EJOR</em>, <em>319</em>(1), 168–190. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spatiotemporal imbalance of passenger flows is a prominent characteristic of urban rail transit systems. To match the provided transportation capacity with passenger distribution, this study considers an integer linear programming model to optimize train operation on a Y-type line, including the train timetable, rolling stock circulation plan and virtual coupling/uncoupling strategy that enables trains to switch between different compositions or configurations during operations. To enhance solution efficiency, certain integer decision variables in the model are relaxed to be continuous, and it is proved that this does not affect the optimal value of the model. To account for the dynamic nature of passenger flows, a “prediction + optimization” method with the rolling optimization framework, which utilizes real-time predicted passenger flow data to enable train operations to be performed and adjusted in response, is proposed. Three variants of the proposed model are embedded to meet the real-time requirements of operations. Numerical experiments verify the effectiveness and applicability of our proposed approach, with real-world data from Shanghai Metro Line 5. The computational results demonstrate that our method performs well under operation scenarios with both normal and abnormal passenger flows. Compared to fixed train composition, virtual coupling can perform much better in both peak and off-peak periods.},
  archive      = {J_EJOR},
  author       = {Hongyang Wang and Lixing Yang and Jinlei Zhang and Qin Luo and Zhongsheng Fan},
  doi          = {10.1016/j.ejor.2024.06.021},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {168-190},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Real-time train timetabling with virtual coupling operations on a Y-type metro line},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using anticipatory orders to manage disruption risk over a
short product life cycle. <em>EJOR</em>, <em>319</em>(1), 153–167. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the impact of supply disruptions on sourcing strategies when product life cycles are short and future demand depends on current sales. We introduce the concept of order policies with anticipatory orders where some or all of orders with the unreliable supplier in future periods are moved to an earlier period. Using a 2-period model, we show that despite incurring additional holding cost when inventory is carried to a future period, anticipatory orders from the unreliable supplier are valuable when dealing with disruption risk when future demand depends on current sales. We find that anticipatory orders are less pronounced when future demand is more independent of current sales. We show that anticipatory orders from the unreliable supplier continue to be optimal for a range of disruption probabilities even when we include a responsive and reliable supplier.},
  archive      = {J_EJOR},
  author       = {Sunil Chopra and Vadim Glinskiy and Florian Lücker},
  doi          = {10.1016/j.ejor.2024.05.040},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {153-167},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Using anticipatory orders to manage disruption risk over a short product life cycle},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A learning-based granular variable neighborhood search for a
multi-period election logistics problem with time-dependent profits.
<em>EJOR</em>, <em>319</em>(1), 135–152. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planning the election campaign for leaders of a political party is a complex problem. The party representatives, running mates, and campaign managers have to design an efficient routing and scheduling plan to visit multiple locations while respecting time and budget constraints. Given the limited time of election campaigns in most countries, every minute should be used effectively, and there is very little room for error. In this paper, we formalize this problem as the multiple Roaming Salesman Problem (mRSP), a new variant of the recently introduced Roaming Salesman Problem (RSP), where a predefined number of political representatives visit a set of cities during a planning horizon to maximize collected rewards, subject to budget and time constraints. Cities can be visited more than once and associated rewards are time-dependent (increasing over time) according to the day of the visit and the recency of previous visits. We develop a compact Mixed Integer Linear Programming (MILP) formulation complemented with effective valid inequalities. Since commercial solvers can obtain optimal solutions only for small-sized instances, we develop a Learning-based Granular Variable Neighborhood Search and demonstrate its capability of providing high-quality solutions in short CPU times on real-world instances. The adaptive nature of our algorithm refers to its ability to dynamically adjust the neighborhood structure based on the progress of the search. Our algorithm generates the best-known results for many instances.},
  archive      = {J_EJOR},
  author       = {Masoud Shahmanzari and Renata Mansini},
  doi          = {10.1016/j.ejor.2024.06.009},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {135-152},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A learning-based granular variable neighborhood search for a multi-period election logistics problem with time-dependent profits},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable policies for the dynamic traveling multi-maintainer
problem with alerts. <em>EJOR</em>, <em>319</em>(1), 121–134. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Downtime of industrial assets such as wind turbines and medical imaging devices is costly. To avoid such downtime costs, companies seek to initiate maintenance just before failure, which is challenging because: (i) Asset failures are notoriously difficult to predict, even in the presence of real-time monitoring devices which signal degradation; and (ii) Limited resources are available to serve a network of geographically dispersed assets. In this work, we study the dynamic traveling multi-maintainer problem with alerts ( K K -DTMPA) under perfect condition information with the objective to devise scalable solution approaches to maintain large networks with K K maintenance engineers. Since such large-scale K K -DTMPA instances are computationally intractable, we propose an iterative deep reinforcement learning (DRL) algorithm optimizing long-term discounted maintenance costs. The efficiency of the DRL approach is vastly improved by a reformulation of the action space (which relies on the Markov structure of the underlying problem) and by choosing a smart, suitable initial solution. The initial solution is created by extending existing heuristics with a dispatching mechanism. These extensions further serve as compelling benchmarks for tailored instances. We demonstrate through extensive numerical experiments that DRL can solve single maintainer instances up to optimality, regardless of the chosen initial solution. Experiments with hospital networks containing up to 35 assets show that the proposed DRL algorithm is scalable. Lastly, the trained policies are shown to be robust against network modifications such as removing an asset or an engineer or yield a suitable initial solution for the DRL approach.},
  archive      = {J_EJOR},
  author       = {Peter Verleijsdonk and Willem van Jaarsveld and Stella Kapodistria},
  doi          = {10.1016/j.ejor.2024.05.049},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {121-134},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Scalable policies for the dynamic traveling multi-maintainer problem with alerts},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel dynamic programming heuristic for the quadratic
knapsack problem. <em>EJOR</em>, <em>319</em>(1), 102–120. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Quadratic Knapsack Problem (QKP) is a well-studied combinatorial optimization problem with practical applications in various fields such as finance, logistics, and telecommunications. Despite its longstanding interest, the QKP remains challenging due to its strong NP -hardness. Moreover, recent studies have introduced new instances where all existing algorithms have failed to produce good-quality results. In this paper, we aim to address these challenging QKP instances by proposing a novel approach to enhance the regular value function used in dynamic programming (DP) literature. Our proposed method considers the contribution of each item not only with respect to the items already selected, but also estimates its potential contribution with respect to items yet to be considered. Additionally, we introduce a propagation technique and a “remove-and-fill-up” local search procedure to further improve the solution quality. Through extensive computational experiments, our heuristic algorithm demonstrates superior performance compared to existing heuristics, producing optimal or near-optimal solutions for even the most demanding QKP instances. Empirical evidence, supported by an automated instance space analysis using unbiased metrics, showcases the remarkable improvements achieved, with solutions surpassing on average the solution quality of existing algorithms by up to 98%, and up to 77% reduction of the computational time.},
  archive      = {J_EJOR},
  author       = {M. Eliass Fennich and Franklin Djeumou Fomeni and Leandro C. Coelho},
  doi          = {10.1016/j.ejor.2024.06.034},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {102-120},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A novel dynamic programming heuristic for the quadratic knapsack problem},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On bi-objective combinatorial optimization with
heterogeneous objectives. <em>EJOR</em>, <em>319</em>(1), 89–101. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The heterogeneity among objectives in multi-objective optimization can be viewed from several perspectives. In this paper, we are interested in the heterogeneity arising in the underlying landscape of the objective functions, in terms of multi-modality and search difficulty. Building on recent efforts leveraging the so-called single-objective NK-landscapes to model such a setting, we conduct a three-fold empirical analysis on the impact of objective heterogeneity on the landscape properties and search difficulty of bi-objective optimization problems. Firstly, for small problems, we propose two techniques based on studying the distribution of the solutions in the objective space. Secondly, for large problems, we investigate the ability of existing landscape features to capture the degree of heterogeneity among the two objectives. Thirdly, we study the behavior of two state-of-the-art multi-objective evolutionary algorithms, namely MOEA/D and NSGA-II, when faced with a range of problems with different degrees of heterogeneity. Although one algorithm is found to consistently outperform the other, the dynamics of both algorithms vary similarly with respect to objective heterogeneity. Our analysis suggests that novel approaches are needed to understand the fundamental properties of heterogeneous bi-objective optimization problems and to tackle them more effectively.},
  archive      = {J_EJOR},
  author       = {Raphaël Cosson and Roberto Santana and Bilel Derbel and Arnaud Liefooghe},
  doi          = {10.1016/j.ejor.2024.06.029},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {89-101},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On bi-objective combinatorial optimization with heterogeneous objectives},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mixed-integer linear programming for project scheduling
under various resource constraints. <em>EJOR</em>, <em>319</em>(1),
79–88. (<a href="https://doi.org/10.1016/j.ejor.2024.06.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Project scheduling is an important management task in many companies across different industries. Generally, projects require resources, such as personnel or funds, whose availabilities are limited, giving rise to the challenging problem of resource-constrained project scheduling. In this paper, we consider the scheduling of a project consisting of precedence-related activities that require time and two types of resources for execution: storage resources representing, e.g., the project budget; and renewable resources representing, e.g., personnel or equipment. Storage resources are consumed by activities at their start or produced upon their completion, while renewable resources are allocated to activities at their start and released upon their completion. The resource-constrained project scheduling problem with consumption and production of resources (RCPSP-CPR) consists of determining a minimum-makespan schedule such that all precedence relations are respected, the demand for each renewable resource never exceeds its capacity, and the stock level of each storage resource never falls below a prescribed minimum. Due to the consideration of storage resources, the feasibility variant of this problem is NP-complete. We propose a novel compact mixed-integer linear programming (MILP) model based on a novel type of sequencing variables. These variables enable us to identify which activities are processed in parallel and whether a sequencing of activities is necessary to respect the resource capacities. Our computational results indicate that our novel model significantly outperforms state-of-the-art MILP models for all considered scarcity settings of the storage resources. Additionally, our results indicate a superior performance for instances of the well-known resource-constrained project scheduling problem (RCPSP).},
  archive      = {J_EJOR},
  author       = {Nicklas Klein and Mario Gnägi and Norbert Trautmann},
  doi          = {10.1016/j.ejor.2024.06.036},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {79-88},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mixed-integer linear programming for project scheduling under various resource constraints},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scheduling maintenance activities subject to stochastic
job-dependent machine deterioration. <em>EJOR</em>, <em>319</em>(1),
62–78. (<a href="https://doi.org/10.1016/j.ejor.2024.06.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a maintenance scheduling problem on a single machine with a fixed job sequence involving job-dependent, stochastic deterioration. If the machine breaks down, then a time-consuming emergency maintenance activity needs to be conducted. Instead, planned maintenance activities can be conducted between jobs in order to improve the machine’s state and, thus, prevent the machine from breaking down. We distinguish two types of machines differing in the flexibility regarding the point of time when the maintenance activities need to be scheduled. The goal is to minimize the total expected completion time of jobs. We formalize two optimization problems, analyze their computational complexities, develop exact solution approaches, and conduct a computational study. Here, we show that our approaches can solve large instances to optimality within short run times and we analyze the advantage gained by planning maintenance activities depending on the actual state of the machine.},
  archive      = {J_EJOR},
  author       = {Dirk Briskorn and Jochen Gönsch and Antonia Thiemeyer},
  doi          = {10.1016/j.ejor.2024.06.030},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {62-78},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Scheduling maintenance activities subject to stochastic job-dependent machine deterioration},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stable set reformulations for the degree preserving spanning
tree problem. <em>EJOR</em>, <em>319</em>(1), 50–61. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let G = ( V , E ) G=(V,E) be a connected undirected graph and assume that a spanning tree is available for it. Any vertex in this tree is called degree preserving if it has the same degree in the graph and in the tree. Building upon this concept, the Degree Preserving Spanning Tree Problem (DPSTP) asks for a spanning tree of G G with as many degree preserving vertices as possible. DPSTP is very much intertwined with the most important application for it, so far, i.e., the online monitoring of arc flows in a water distribution network, what serves us as an additional motivation for our investigation. We show that degree preserving vertices correspond to a stable set of a properly defined DPSTP conflict graph. This, in turn, allows us to use valid inequalities for the Stable Set Polytope (SSP) and thus strengthen the DPSTP formulations previously suggested in the literature. In doing so, the Branch-and-cut and Benders Decomposition algorithms suggested for these formulations are greatly enhanced. Additionally, as a further contribution, we also introduce a new and very challenging set of DPSTP test instances, given by graphs that closely resemble water distribution networks. For these instances, the new algorithms very clearly outperform all previous DPSTP algorithms. They not only run faster than their competitors but are also less dependent on good initial DPSTP primal bounds. For previous DPSTP test sets, the new algorithms lag behind the best existing algorithm for them, which is based on Lagrangian relaxation. However, as compared to additional DPSTP previous algorithms that do not benefit from SSP inequalities, the new ones come much closer to the Lagrangian relaxation one.},
  archive      = {J_EJOR},
  author       = {Abílio Lucena and Alexandre Salles da Cunha},
  doi          = {10.1016/j.ejor.2024.06.031},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {50-61},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stable set reformulations for the degree preserving spanning tree problem},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An exact algorithm for the multi-trip vehicle routing
problem with time windows and multi-skilled manpower. <em>EJOR</em>,
<em>319</em>(1), 31–49. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the challenges of non-emergency patient transportation services in the healthcare industry, this study investigated a multi-trip vehicle routing problem incorporating multi-skilled manpower with downgrading. We aimed to find an optimal plan for vehicle routing and multi-skilled manpower scheduling in tandem with the objective of minimizing the total cost, including travel and staff costs, without violating time windows and lunch break constraints. To address this, two mathematical models were formulated: an arc-flow model and a trip-based set-covering model. In addition, a branch-and-price-and-cut algorithm, based on the set-covering model, was proposed to solve practical-scale instances. To determine the feasibility of the integer solutions, we introduce a feasibility check model. To address the multi-trip characteristics of the proposed problem, a novel two-phase column generation algorithm was introduced to solve the subproblem. This approach differs from traditional one-phase labeling algorithms and involves a tailored labeling algorithm for obtaining non-dominated labels in the first phase and a strategy to identify the trip with the minimum reduced cost for each label in the second phase. Furthermore, novel and efficient staff-based inequalities were developed by improving the k-path inequalities. Extensive numerical experiments were conducted to demonstrate the solution performance of the proposed algorithm and reveal managerial insights for non-emergency ambulance operations. The results demonstrate that our algorithm can successfully solve instances with up to 50 patients to optimality within two hours. Moreover, we demonstrated the value of jointly optimizing vehicle routing and staff planning, which can result in significant cost savings of up to 19.4%.},
  archive      = {J_EJOR},
  author       = {Nan Huang and Hu Qin and Yuquan Du and Li Wang},
  doi          = {10.1016/j.ejor.2024.06.025},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {31-49},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An exact algorithm for the multi-trip vehicle routing problem with time windows and multi-skilled manpower},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A machine learning approach to two-stage adaptive robust
optimization. <em>EJOR</em>, <em>319</em>(1), 16–30. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an approach based on machine learning to solve two-stage linear adaptive robust optimization (ARO) problems with binary here-and-now variables and polyhedral uncertainty sets. We encode the optimal here-and-now decisions, the worst-case scenarios associated with the optimal here-and-now decisions, and the optimal wait-and-see decisions into what we denote as the strategy. We solve multiple similar ARO instances in advance using the column and constraint generation algorithm and extract the optimal strategies to generate a training set. We train machine learning models that predict high-quality strategies for the here-and-now decisions, the worst-case scenarios associated with the optimal here-and-now decisions, and the wait-and-see decisions. The models can be applied to problems with varying dimensions. We also introduce novel methods to expedite training data generation and reduce the number of different target classes the machine learning algorithm needs to be trained on. We apply the proposed approach to the facility location, the multi-item inventory control and the unit commitment problems. Our approach solves ARO problems drastically faster than the state-of-the-art algorithms with high accuracy.},
  archive      = {J_EJOR},
  author       = {Dimitris Bertsimas and Cheol Woo Kim},
  doi          = {10.1016/j.ejor.2024.06.012},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {16-30},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A machine learning approach to two-stage adaptive robust optimization},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of recent advances in time-dependent vehicle
routing. <em>EJOR</em>, <em>319</em>(1), 1–15. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In late 2015 three of the co-authors of this paper published the first review on time-dependent routing problems. Since then, there have been several important algorithmic developments in the field. These include travel time prediction methods, real-time re-optimization by operating directly on the road graph, efficient exploration of solution neighborhoods, dynamic discretization discovery and Machine Learning -inspired methods. The aim of this survey is to present such research lines, together with indications on their further developments.},
  archive      = {J_EJOR},
  author       = {Tommaso Adamo and Michel Gendreau and Gianpaolo Ghiani and Emanuela Guerriero},
  doi          = {10.1016/j.ejor.2024.06.016},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A review of recent advances in time-dependent vehicle routing},
  volume       = {319},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive stochastic lookahead policies for dynamic
multi-period purchasing and inventory routing. <em>EJOR</em>,
<em>318</em>(3), 1028–1041. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore a problem faced by agri-food e-commerce platforms in purchasing different, perishable products and collecting them from multiple producers and delivering them to a single warehouse, aiming to maintain adequate inventory levels to meet current and future customer demand, while avoiding waste. Customer demand and suppliers’ purchase prices and supply volumes are uncertain and revealed on a periodical basis. Every period, purchasing, inventory, and routing decisions are made to satisfy demand and to build inventory for future periods. For effective decisions integrating all three decision components and anticipating future developments, we propose a stochastic lookahead method that, in every period, samples future scenarios for demand, supply volumes, and prices. It then solves a two-stage stochastic program to obtain the decision for the current period. To make this approach computationally tractable, we reduce the routing decision in the two-stage program and use an approximate routing cost instead. Given the reduced decision, we then create the final decision via a conventional routing heuristic. We learn the routing cost approximation adaptively via repeated training simulations. In comprehensive experiments, we show that all three components, stochastic lookahead, routing cost approximation, and adaptive learning, are very effective individually, but especially in combination. We also provide a comprehensive analysis of the problem parameters and obtain valuable insights in problem and methodology.},
  archive      = {J_EJOR},
  author       = {Daniel Cuellar-Usaquén and Marlin W. Ulmer and Camilo Gomez and David Álvarez-Martínez},
  doi          = {10.1016/j.ejor.2024.06.011},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {1028-1041},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Adaptive stochastic lookahead policies for dynamic multi-period purchasing and inventory routing},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Agency or reselling? Supplier’s online channel strategies
with platform financing. <em>EJOR</em>, <em>318</em>(3), 1014–1027. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online finance implemented by e-commerce platforms assists small and medium-sized enterprises in overcoming capital shortages and advancing channel development. We investigate the interplay between channel strategy and platform financing within a dual-channel supply chain comprising a capital-constrained supplier, an e-commerce platform, and an offline retailer. The supplier has access to various sales services (i.e., reselling and agency selling) as well as financing services from the e-commerce platform. Using a game-theoretical model, we analyze the financing conditions under two channel strategies and explore the supplier’s optimal channel strategy. Our research results reveal several key insights. Firstly, whether to choose platform financing under varying channel strategies depends on the supplier’s capital constraints and the platform’s interest rate. High capital constraints allow the supplier to benefit from platform financing. Secondly, the determination of the supplier’s optimal channel strategy primarily hinges upon factors such as the supplier’s production cost and financial constraints, as well as the interest and commission rates set by the platform. Additionally, the e-commerce platform imposes stricter financial requirements on the supplier to offer financing under the agency selling strategy compared to the reselling strategy. Furthermore, in the case of relatively high (or low) production costs, choosing the reselling strategy (or the agency selling strategy) to secure retailer finance (or agency finance) can realize a Pareto improvement. Our findings underscore the significant role of platform finance and provide valuable insights for suppliers in developing channel strategies that effectively integrate both operational and financial considerations.},
  archive      = {J_EJOR},
  author       = {Yang Liu and Jizhou Lu and Nina Yan},
  doi          = {10.1016/j.ejor.2024.06.010},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {1014-1027},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Agency or reselling? supplier’s online channel strategies with platform financing},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Performance evaluation using multi-stage production
frameworks: Assessing the tradeoffs among the economic, environmental,
and social well-being. <em>EJOR</em>, <em>318</em>(3), 1000–1013. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming to achieve sustainable development, a constantly growing number of countries have strived to promote economic growth while simultaneously mitigating environmental degradation and maximizing social welfare. However, despite the importance attributed to social well-being in contemporary discourse, its role has not received much attention in the performance evaluation literature. We propose a novel, multi-stage framework based on three dimensions of performance allowing us to assess the tradeoffs between the economic, environmental, and social efficiency in 28 OECD member countries from 2000 to 2019. We construct several scenarios representing policymakers&#39; preferences by altering the weights assigned to the different performance pillars, allowing us to assess the environmental and social repercussions of economic growth. Our findings suggest that policies promoting relatively balanced growth patterns can offer opportunities for higher performance across all three pillars. At the same time, prioritizing development along any single dimension can trigger a relatively significant drop in progress in terms of the other two pillars. We also demonstrate that the sustainable development potential has varied across time and space. Comparisons suggest that the European OECD member countries have outperformed their non-European counterparts in terms of the economic performance, health outcomes, life expectancy, and carbon dioxide (CO 2 ) emissions. Our results can provide policymakers with insights into strategies for promoting economic growth that account for sustainable development objectives.},
  archive      = {J_EJOR},
  author       = {Yiran Niu and Jean-Philippe Boussemart and Zhiyang Shen and Michael Vardanyan},
  doi          = {10.1016/j.ejor.2024.05.046},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {1000-1013},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Performance evaluation using multi-stage production frameworks: Assessing the tradeoffs among the economic, environmental, and social well-being},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Should live broadcasting platforms adopt artificial
intelligence? A sales effort perspective. <em>EJOR</em>,
<em>318</em>(3), 979–999. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analytically investigate a supply chain (SC) that is composed of a manufacturer and a live broadcasting platform, and examine whether the latter should adopt artificial intelligence (AI) considering sales effort. We consider several important factors that affect the SC partners’ decision-making including live broadcasting power, consumer expectations of the product, and unfit probability that the consumer is unsatisfied with the bought product. Specifically, the “live broadcasting power” refers to the power of influencers’ personal influence and fans group to enhance product sales. The results are as follows: First, the optimal production quantity of the offline channel (platform) exhibits a positive (negative) correlation with the retail price of the offline channel in the agency mode with AI. Nevertheless, in the resale mode, the retail price of the offline channel has no influence on the two channels’ optimal production quantities. Second, with low marginal cost of adopting AI, the live broadcasting platform should (not) adopt AI under high (low) live broadcasting power. With high marginal cost of adopting AI, the live broadcasting platform should (not) adopt AI under low or high (moderate) live broadcasting power. In addition, the manufacturer without AI should select the agency mode (resale mode) under high (low) live broadcasting power, while the manufacturer with AI should always collaborate with the live broadcasting platform implementing the agency mode. Finally, the agency and resale modes can achieve coordination between the two firms. We also consider the partial unfit probability, hybrid mode, and “webrooming” behavior to extend our study, and numerically demonstrate our analytical findings’ robustness.},
  archive      = {J_EJOR},
  author       = {Xiaoping Xu and Yuting Wang and T.C.E. Cheng and Tsan-Ming Choi},
  doi          = {10.1016/j.ejor.2024.05.021},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {979-999},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Should live broadcasting platforms adopt artificial intelligence? a sales effort perspective},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The digital economy and advertising diffusion models:
Critical mass and the stalling equilibrium. <em>EJOR</em>,
<em>318</em>(3), 966–978. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the digital economy it is frequently observed that products become more valuable the larger is the number of people that use it. To account for such network effects, we introduce a new diffusion equation in a dynamic model of the firm with the aim to obtain the advertising policy that maximizes firm profits. Also an advertising budget is introduced. First, we find that introduction of the network effect leads to a critical mass of the sales level. Only if the sales are greater or equal to this level, is it optimal for the firm to have a substantial sales level in the long run. Second, introduction of an advertising budget could result in the existence of a Stalling equilibrium. This new type of equilibrium, at which the advertising amount is at its upper bound, serves as the critical mass threshold separating growth and decline. Third, the advertising policy is continuous in the sales level either when the discount rate is large and the rate of forgetfulness is low, when the Stalling equilibrium exists, or when the rate of forgetfulness is that high that the firm is always in decline. Furthermore, existence of the Stalling equilibrium involves an important message to the management of the firm in that a slight increase of the advertising budget would open up an avenue of growth in sales.},
  archive      = {J_EJOR},
  author       = {Gustav Feichtinger and Dieter Grass and Richard F. Hartl and Peter M. Kort and Andrea Seidl},
  doi          = {10.1016/j.ejor.2024.05.043},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {966-978},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The digital economy and advertising diffusion models: Critical mass and the stalling equilibrium},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven resource allocation for multi-target attainment.
<em>EJOR</em>, <em>318</em>(3), 954–965. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We delve into a class of multi-target attainment problems, which commonly arise in practical applications such as operations management, marketing, policy making, and healthcare services. The aim is to efficiently allocate a fixed amount of resources to achieve predetermined target payoffs for multiple tasks. We transform this stochastic problem into a tractable optimization problem that, when optimized, approximately maximizes the probability of attaining all the targets as data accumulates. This transformation is leveraged to devise a batch-based resource allocation rule that demonstrates strong theoretical and numerical performance guarantees.},
  archive      = {J_EJOR},
  author       = {Dohyun Ahn},
  doi          = {10.1016/j.ejor.2024.05.045},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {954-965},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Data-driven resource allocation for multi-target attainment},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collusion by mistake: Does algorithmic sophistication drive
supra-competitive profits? <em>EJOR</em>, <em>318</em>(3), 927–953. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A burgeoning literature shows that self-learning algorithms may, under some conditions, reach seemingly-collusive outcomes: after repeated interaction, competing algorithms earn supra-competitive profits, at the expense of efficiency and consumer welfare. This paper offers evidence that such behavior can stem from insufficient exploration during the learning process and that algorithmic sophistication might increase competition. In particular, we show that allowing for more thorough exploration does lead otherwise seemingly-collusive Q-learning algorithms to play more competitively. We first provide a theoretical illustration of this phenomenon by analyzing the competition between two stylized Q-learning algorithms in a Prisoner’s Dilemma framework. Second, via simulations, we show that some more sophisticated algorithms exploit the seemingly-collusive ones. Following these results, we argue that the advancement of algorithms in sophistication and computational capabilities may, in some situations, provide a solution to the challenge of algorithmic seeming collusion, rather than exacerbate it.},
  archive      = {J_EJOR},
  author       = {Ibrahim Abada and Xavier Lambin and Nikolay Tchakarov},
  doi          = {10.1016/j.ejor.2024.06.006},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {927-953},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Collusion by mistake: Does algorithmic sophistication drive supra-competitive profits?},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The many shapley values for explainable artificial
intelligence: A sensitivity analysis perspective. <em>EJOR</em>,
<em>318</em>(3), 911–926. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive models are increasingly used for managerial and operational decision-making. The use of complex machine learning algorithms, the growth in computing power, and the increase in data acquisitions have amplified the black-box effects in data science. Consequently, a growing body of literature is investigating methods for interpretability and explainability. We focus on methods based on Shapley values, which are gaining attention as measures of feature importance for explaining black-box predictions. Our analysis follows a hierarchy of value functions, and proves several theoretical properties that connect the indices at the alternative levels. We bridge the notions of totally monotone games and Shapley values, and introduce new interaction indices based on the Shapley-Owen values. The hierarchy evidences synergies that emerge when combining Shapley effects computed at different levels. We then propose a novel sensitivity analysis setting that combines the benefits of both local and global Shapley explanations, which we refer to as the “glocal” approach. We illustrate our integrated approach and discuss the managerial insights it provides in the context of a data-science problem related to health insurance policy-making.},
  archive      = {J_EJOR},
  author       = {Emanuele Borgonovo and Elmar Plischke and Giovanni Rabitti},
  doi          = {10.1016/j.ejor.2024.06.023},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {911-926},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The many shapley values for explainable artificial intelligence: A sensitivity analysis perspective},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constructing order-2 information granules of linguistic
expressions with the aid of the principle of justifiable granularity.
<em>EJOR</em>, <em>318</em>(3), 892–910. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To capture collective opinions/evaluations in a collection of individual linguistic expressions, this study proposes an approach to construct order-2 information granules by extending the numerical data-based principles of justifiable granularity to a linguistic data-based one. First, the two key criteria of the principle of justifiable granularity, namely coverage and specificity, are formally defined in the context of order-2 information granules. Second, three order-2 information granules construction models by maximizing the product of coverage and specificity are developed for coping with one-dimensional direct linguistic expressions, linguistic preference relations, and multi-dimensional direct linguistic expressions, respectively. Third, considering that the developed order-2 information granules construction models exhibit a non-linear uncertain objective function and equality constraints, the constrained multi-swarm PSO without velocity is improved with the use of the ε constrained handling technique for effectively solving the models. Case studies on the considered three types of linguistic expressions show the applicability of the proposed models and ensuing algorithm. The superiority of the improved algorithm in handling the proposed models is demonstrated by comparison with the original one. The effectiveness of the proposed models in terms of abnormal corrective ability and balance of coverage and specificity is verified by comparing with a family of Top- n methods. The originality of this study lies in the construction of an operational entity, namely order-2 information granule, that reflects the group opinion without specifying the formalism of individual linguistic expressions, which provides an effective and efficient way to aggregate ubiquitous linguistic information for subsequent computation, reasoning and decision-making.},
  archive      = {J_EJOR},
  author       = {Ting Huang and Witold Pedrycz and Qiang Zhang and Xiaoan Tang and Shanlin Yang},
  doi          = {10.1016/j.ejor.2024.04.017},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {892-910},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Constructing order-2 information granules of linguistic expressions with the aid of the principle of justifiable granularity},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Investment–consumption optimization with transaction cost
and learning about return predictability. <em>EJOR</em>,
<em>318</em>(3), 877–891. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate an investment–consumption optimization problem in continuous-time settings, where the expected rate of return from a risky asset is predictable with an observable factor and an unobservable factor. Based on observable information, a decision-maker learns about the unobservable factor while making investment–consumption decisions. Both factors are supposed to follow a mean-reverting process. Also, we relax the assumption for perfect liquidity of the risky asset through incorporating proportional transaction costs that are incurred in trading the risky asset. In such way, a form of friction posing liquidity risk to the investor is examined. Dynamic programming principle coupled with an Hamilton–Jacobi–Bellman (HJB) equation are adopted to discuss the problem. Applying an asymptotic method with small transaction costs being taken as a perturbation parameter, we determine the frictional value function by solving the first and second corrector equations. For the numerical implementation of the proposed approach, a Monte-Carlo-simulation-based approximation algorithm is adopted to solve the second corrector equation. Finally, numerical examples and their economic interpretations are discussed.},
  archive      = {J_EJOR},
  author       = {Ning Wang and Tak Kuen Siu},
  doi          = {10.1016/j.ejor.2024.06.024},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {877-891},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Investment–consumption optimization with transaction cost and learning about return predictability},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Russell and slack-based measures of efficiency: A unifying
framework. <em>EJOR</em>, <em>318</em>(3), 867–876. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some of the popular technical efficiency measures are not able to account for potential slacks in inputs or outputs and may misrepresent the degree of inefficiency pertinent to firms, industries, and countries when compared to their peers. A wide range of methods have been proposed in the literature over the last four decades to address this important issue. The precise relationship among many of these methods is not always clear. In this paper we briefly review this literature and propose a unifying framework for such measures, one which embraces many other important approaches in efficiency measurement (including slack-based measures, Russell efficiency measures, etc.) as special cases in this general framework. A numerical example is also presented to illustrate the differences among the special cases of the efficiency measures, complemented with the computational code in R for practitioners interested in using these models.},
  archive      = {J_EJOR},
  author       = {Valentin Zelenyuk and Shirong Zhao},
  doi          = {10.1016/j.ejor.2024.06.014},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {867-876},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Russell and slack-based measures of efficiency: A unifying framework},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A theory of multivariate stress testing. <em>EJOR</em>,
<em>318</em>(3), 851–866. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a theoretical framework for stressing multivariate stochastic models. We consider a stress to be a change of measure, placing a higher weight on multivariate scenarios of interest. In particular, a stressing mechanism is a mapping from random vectors to Radon–Nikodym densities. We postulate desirable properties for stressing mechanisms addressing alternative objectives. Consistently with our focus on dependence, we require throughout invariance to monotonic transformations of risk factors. We study in detail the properties of two families of stressing mechanisms, based respectively on mixtures of univariate stresses and on transformations of statistics we call Spearman and Kendall’s cores. Furthermore, we characterize the aggregation properties of those stressing mechanisms, which motivate their use in deriving new capital allocation methods, with properties different to those typically found in the literature. The proposed methods are applied to stress testing and capital allocation, using the simulation model of a UK-based non-life insurer.},
  archive      = {J_EJOR},
  author       = {Pietro Millossovich and Andreas Tsanakas and Ruodu Wang},
  doi          = {10.1016/j.ejor.2024.06.002},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {851-866},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A theory of multivariate stress testing},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Benders decomposition with delayed disaggregation for the
active passive vehicle routing problem. <em>EJOR</em>, <em>318</em>(3),
836–850. (<a href="https://doi.org/10.1016/j.ejor.2024.05.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a new exact solution approach for the Active Passive Vehicle Routing Problem, a vehicle routing problem with complicated temporal synchronisation requirements between vehicles. A key contribution is the introduction of a new principle, Delayed Disaggregation , for Benders Decomposition to produce disaggregated optimality cuts when traditional block-diagonality fails. The technique is applied to a new Mixed Integer Programming formulation of the Active Passive Vehicle Routing Problem. The formulation is built on coupled movements between active and passive vehicles, and solved using Combinatorial Benders Decomposition. The synchronisation constraints result in an interesting subproblem for which we present a tailored algorithm. The new method outperformed the existing Branch-and-Price method by two orders of magnitude and solves 74 instances to optimality for the first time. We investigate the performance impact of route enumeration, a heuristic and valid inequalities on the base Benders algorithm.},
  archive      = {J_EJOR},
  author       = {Yannik Rist and Christian Tilk and Michael Forbes},
  doi          = {10.1016/j.ejor.2024.05.041},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {836-850},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Benders decomposition with delayed disaggregation for the active passive vehicle routing problem},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A preventive maintenance policy and a method to approximate
the failure process for multi-component systems. <em>EJOR</em>,
<em>318</em>(3), 825–835. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous maintenance policies have been proposed in the reliability mathematics and engineering literature. Nevertheless, little has been reported on their practical applications in industries. This gap is largely due to restrictive assumptions of the maintenance policies. Two of the main assumptions are that maintenance is conducted on typical components and that the reliability of an item under maintenance is known (where the item can be a component or a system composed of multiple components). These assumptions do not often hold in the real world: maintenance is often performed on a collection of components such as an integrated circuit plate and the reliability of each individual component may not be known. To reduce these gaps, this paper develops a new maintenance policy for a collection of components and an approximate method to estimate the reliability of this collection based on the failure data collected from the field. The maintenance policy considers that a system is composed of three subsystems with different levels of maintenance effectiveness (i.e, minimal, imperfect, and perfect). The approximate estimate of the reliability of each subsystem is derived based on the failure data that are time between failures of the system but not those of the components that cause the system to fail. An algorithm for simulating the superposition of generalised renewal processes is then proposed. Numerical examples are used to illustrate the proposed approximation method.},
  archive      = {J_EJOR},
  author       = {Shaomin Wu and Majid Asadi},
  doi          = {10.1016/j.ejor.2024.05.039},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {825-835},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A preventive maintenance policy and a method to approximate the failure process for multi-component systems},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-additive network pricing with non-cooperative mobility
service providers. <em>EJOR</em>, <em>318</em>(3), 802–824. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses a mobility network pricing problem in a competitive environment. We consider a multimodal transportation network where the links are operated by multiple profit-maximizing, mobility service providers (MSPs). We take the perspective of a network regulator that aims to increase ridership in a target mobility network by providing non-additive, path-based subsidies to travelers. We model paths’ attractiveness using generalized cost functions that combine path travel time and path cost, and we use linear elastic travel demand functions to capture the proportion of demand served by a path. MSPs are non-cooperative and adjust link fares according to the subsidy policy implemented by the regulator. The goal of the network regulator is to solve a budget-constrained mobility network pricing problem under MSP competition. This game-theoretical framework is modeled as a single-leader multi-follower game (SLMFG) wherein the leader player represents the network regulator and multiple follower players represent the MSPs. We conduct a theoretical analysis of this SLMFG by identifying necessary and sufficient conditions for the existence of solutions to the parameterized generalized Nash equilibrium problem (GNEP) that is played amongst MSPs. We show that this GNEP is jointly convex and we use this property to develop an exact numerical approach to solve the SLMFG based on customized branch-and-bound algorithms. Numerical results reveal the impact of MSP competition in this mobility network pricing problem and shed novel insights into the design of optimal path-based subsidy policies.},
  archive      = {J_EJOR},
  author       = {Wentao Huang and Sisi Jian and David Rey},
  doi          = {10.1016/j.ejor.2024.05.042},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {802-824},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Non-additive network pricing with non-cooperative mobility service providers},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An effective multi-level memetic search with neighborhood
reduction for the clustered team orienteering problem. <em>EJOR</em>,
<em>318</em>(3), 778–801. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Clustered Team Orienteering Problem (CluTOP) extends the classic Clustered Orienteering Problem by considering the use of multiple vehicles. The problem is known to be NP-hard and can be used to formulate many real-life applications. This work presents a highly effective multi-level memetic search for CluTOP that combines a backbone-based edge assembly crossover to generate promising offspring solutions with an effective bilevel synergistic local search procedure at both cluster and customer levels to improve offspring solutions. Other novel features of the proposed approach include a joint use of three specific hash functions to identify the tabu status of candidate solutions at the cluster level, a multi-neighborhood search with inter-route and intra-route optimization at the customer level, a pre-processing neighborhood reduction strategy to avoid examining non-promising candidate solutions, and a strategy for controlled exploration of infeasible solutions. Extensive experimental results on 1848 benchmark instances convincingly demonstrate high competitiveness of the approach in terms of both solution quality and computational time, compared to the state-of-the-art heuristics from the literature. In particular, the proposed algorithm improves upon the existing best-known solutions for 294 instances, while matching the previous best-known results for all but 3 of the remaining instances. To gain further insights into the algorithm’s performance, additional experiments are conducted to analyze its main components.},
  archive      = {J_EJOR},
  author       = {Mu He and Qinghua Wu and Una Benlic and Yongliang Lu and Yuning Chen},
  doi          = {10.1016/j.ejor.2024.06.015},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {778-801},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An effective multi-level memetic search with neighborhood reduction for the clustered team orienteering problem},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Some new clique inequalities in four-index hub location
models. <em>EJOR</em>, <em>318</em>(3), 768–777. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hub location problems can be modeled in several ways, one of which is the path-based family of models that make use of four-index variables. Clique inequalities are frequently used to describe solution characteristics for optimization problems with binary variables. In this study, new valid inequalities of the clique type are introduced for the path-based family of hub location models. Some of their properties and corresponding lifting are discussed, and a separation heuristic algorithm is proposed. We also report a set of computational experiments to evaluate the usefulness of the proposals when embedded in a commercial solver.},
  archive      = {J_EJOR},
  author       = {Mercedes Landete and Juanjo Peiró},
  doi          = {10.1016/j.ejor.2024.06.008},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {768-777},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Some new clique inequalities in four-index hub location models},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The generator distribution problem for base stations during
emergency power outage: A branch-and-price-and-cut approach.
<em>EJOR</em>, <em>318</em>(3), 752–767. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the need for uninterrupted service provision in the telecommunications industry, this paper presents a novel problem concerning the transportation of diesel generators during an unplanned power outage. Given a set of base stations, each equipped with a capacitated back-up battery pack, the problem consists in finding an optimal delivery and pick-up schedule that minimises corresponding costs. The problem is significantly complicated by the fact that the delivery quantity is a decision variable, and the pick-up times depend on the delivery time, delivery quantity and constraints related to battery-charging requirements. To address the issue, we develop problem-specific pick-up time functions that can be effectively incorporated into the proposed algorithm. The problem is formulated as an arc-based model and a set-packing model. To solve it to optimality, we design a tailored branch-and-price-and-cut algorithm, including novel customised dominance criteria in the labelling algorithm and adopting heuristics that exploit the problem features and effectively improve the algorithmic performance. The efficacy of the proposed algorithm is validated based on the extensive computational study and compared with a commercial solver. The proposed acceleration techniques are found to be potent with regard to computational times, and useful managerial insights are provided as part of sensitivity analyses.},
  archive      = {J_EJOR},
  author       = {Hu Qin and Anton Moriakin and Gangyan Xu and Jiliu Li},
  doi          = {10.1016/j.ejor.2024.06.007},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {752-767},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The generator distribution problem for base stations during emergency power outage: A branch-and-price-and-cut approach},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the automatic generation of metaheuristic algorithms for
combinatorial optimization problems. <em>EJOR</em>, <em>318</em>(3),
740–751. (<a href="https://doi.org/10.1016/j.ejor.2024.06.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic algorithms have become one of the preferred approaches for solving optimization problems. Finding the best metaheuristic for a given problem is often difficult due to the large number of available approaches and possible algorithmic designs. Moreover, high-performing metaheuristics often combine general-purpose and problem-specific algorithmic components. We propose here an approach for automatically designing metaheuristics using a flexible framework of algorithmic components, from which algorithms are instantiated and evaluated by an automatic configuration method. The rules for composing algorithmic components are defined implicitly by the properties of each algorithmic component, in contrast to previous proposals, which require a handwritten algorithmic template or grammar. As a result, extending our framework with additional components, even problem-specific or user-defined ones, automatically updates the design space. Furthermore, since the generated algorithms are made up of components, they can be easily interpreted. We provide an implementation of our proposal and demonstrate its benefits by outperforming previous research in three distinct problems from completely different families: a facility layout problem, a vehicle routing problem and a clustering problem.},
  archive      = {J_EJOR},
  author       = {Raúl Martín-Santamaría and Manuel López-Ibáñez and Thomas Stützle and J. Manuel Colmenar},
  doi          = {10.1016/j.ejor.2024.06.001},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {740-751},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the automatic generation of metaheuristic algorithms for combinatorial optimization problems},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid genetic algorithm with type-aware chromosomes for
traveling salesman problems with drone. <em>EJOR</em>, <em>318</em>(3),
719–739. (<a href="https://doi.org/10.1016/j.ejor.2024.05.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are emerging transportation problems known as the Traveling Salesman Problem with Drone (TSPD) and the Flying Sidekick Traveling Salesman Problem (FSTSP) that involve using a drone in conjunction with a truck for package delivery. This study presents a hybrid genetic algorithm for solving TSPD and FSTSP by incorporating local search and dynamic programming. Similar algorithms exist in the literature. Our algorithm, however, considers more sophisticated chromosomes and less computationally complex dynamic programming to enable broader exploration by the genetic algorithm and efficient exploitation through dynamic programming and local search. The key contribution of this paper is the discovery of how decision-making processes for solving TSPD and FSTSP should be divided among the layers of genetic algorithm, dynamic programming, and local search. In particular, our genetic algorithm generates the truck and the drone sequences separately and encodes them in a type-aware chromosome, wherein each customer is assigned to either the truck or the drone. We apply local search to each chromosome, which is decoded by dynamic programming for fitness evaluation. Our new algorithm is shown to outperform existing algorithms on most benchmark instances in both quality and time. Our algorithms found the new best solutions for 538 TSPD instances out of 920 and 74 FSTSP instances out of 132.},
  archive      = {J_EJOR},
  author       = {Sasan Mahmoudinazlou and Changhyun Kwon},
  doi          = {10.1016/j.ejor.2024.05.009},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {719-739},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A hybrid genetic algorithm with type-aware chromosomes for traveling salesman problems with drone},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fifty years of location theory - a selective review.
<em>EJOR</em>, <em>318</em>(3), 701–718. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper surveys the history of location models. Starting with the earliest contributions in mathematics, it follows the journey of the topic through its reincarnations in geography and finally in operations research. While we attempted to highlight the major milestones, we do not claim this survey to be comprehensive. Being the 50th anniversary of EURO , we highlighted the contribution of some of the most active European groups.},
  archive      = {J_EJOR},
  author       = {Vladimir Marianov and H.A. Eiselt},
  doi          = {10.1016/j.ejor.2024.01.036},
  journal      = {European Journal of Operational Research},
  month        = {11},
  number       = {3},
  pages        = {701-718},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fifty years of location theory - A selective review},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unexpected opportunities in misspecified predictive
regressions. <em>EJOR</em>, <em>318</em>(2), 686–700. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article documents surprising learning patterns that can occur under model misspecification. An agent resorts to predictive regressions and fails to take into account autocorrelation in the dependent variable. Remarkably, when the dependent and independent variables are uncorrelated, we find cases for which the resulting out-of-sample R 2 R2 is well above zero, which benefits the agent, in spite of the erroneous model. We refer to them as instances of unexpected opportunity. When both variables exhibit high levels of persistence, we reveal the existence of counter-intuitive configurations for which the R 2 R2 increases when the absolute correlation between the series decreases. Our theoretical results are confirmed by extensive simulations and complemented by an empirical exercise of equity premium prediction for which we use 15 predictors commonly referenced in the economic literature.},
  archive      = {J_EJOR},
  author       = {Guillaume Coqueret and Romain Deguest},
  doi          = {10.1016/j.ejor.2024.05.044},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {686-700},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Unexpected opportunities in misspecified predictive regressions},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross validation based transfer learning for cross-sectional
non-linear shrinkage: A data-driven approach in portfolio optimization.
<em>EJOR</em>, <em>318</em>(2), 670–685. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhanced covariance estimation approaches, such as (non-)linear shrinkage, are well established in the literature. Non-linear shrinkage estimators generally minimize a certain loss function regarding statistical assumptions about the future covariance matrix. At the same time, the problem of covariance estimation is traditionally considered from a rather restrictive view since the only available data to determine the estimation parameters is given by the return history of the actual portfolio constituents. In this study, we propose a novel and purely data-driven perspective on covariance estimation. We present a non-linear shrinkage estimator that determines the estimation parameters using cross validation to be historically optimal on a disjoint dataset of assets according to the given objective, such as minimum variance or maximum risk-adjusted return. We then transfer the historically optimal estimation parameters learned on the disjoint dataset to the actual covariance estimation problem. Thereby, the sample eigenvalues are corrected in a purely data-driven way, agnostic to theoretically derived parameters. Another benefit of focusing on disjoint data is that we address the problem of limited data availability in high-dimensional estimation problems when the number of assets exceeds the history length. Our empirical evaluation, based on a total of six stock market indices and various problem dimensions, shows that our approach outperforms existing cross-sectional estimators in minimizing variance and maximizing risk-adjusted return. While our study is limited to the cross-section, the method of parameter selection using cross validation and transfer learning can also be combined with other estimators, such as time-series methods.},
  archive      = {J_EJOR},
  author       = {Torsten Mörstedt and Bernhard Lutz and Dirk Neumann},
  doi          = {10.1016/j.ejor.2024.05.006},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {670-685},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cross validation based transfer learning for cross-sectional non-linear shrinkage: A data-driven approach in portfolio optimization},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A robust optimization approach for a two-player force-design
game. <em>EJOR</em>, <em>318</em>(2), 656–669. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new approach to force design that relies on robust decision making with a min–max objective, rather than assumptions about the goals and strategy of an opponent. This idea is explored mathematically in the framework of a round-based two-player Stackelberg game representing an arms race, which features the acquisition of assets by both players and an evaluation of the defensive capability against attack from an opponent using a portfolio of possible tactics. Mathematical analysis has been carried out to determine the structure of optimal strategies for this type of game. This allows the strategy of the first player to be represented as a decision tree with possible moves by the second player consisting of convex combinations of extreme points. Using this insight into the structure of solutions, the optimal strategy for the game can be computed using a large linear program. The effectiveness of this approach is demonstrated using numerical examples.},
  archive      = {J_EJOR},
  author       = {Jeffrey Christiansen and Andreas T. Ernst and Janosch Rieger},
  doi          = {10.1016/j.ejor.2024.04.018},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {656-669},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A robust optimization approach for a two-player force-design game},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ensuring neonatal human milk provision: A framework for
estimating potential demand for donor human milk. <em>EJOR</em>,
<em>318</em>(2), 642–655. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using donor human milk (DHM) for preterm infants, where the mother&#39;s milk is unavailable, protects infants against potentially fatal necrotising enterocolitis. When used optimally, DHM can support mothers to establish breastfeeding. Understanding the relationship between clinical choices for DHM provision and the resulting demand is important. For policymakers, it informs decision-making around the provision of DHM based on cost-benefit analyses. For milk banks, it helps plan for required capacity, donor recruitment and supply-side collections. This study presents a framework for estimating DHM potential demand for infants born preterm, which allows for various sources of secondary population data, different feeding protocols and policy options for DHM provision. A Monte Carlo Simulation (MCS) is developed which follows the framework, simulating annual births (based on historical data) and incorporating uncertainty related to infant and maternal populations. A case study on human milk banking serves as the basis for the application of the framework and the modelling approach. Our model estimates the overall demand for DHM in England and Wales, the local level demand for NHS Trusts in England and provides an indication of the associated uncertainties. Our study provides a useful tool to enrich the strategic and operational level decision-making environment, benefitting both policymakers and milk bankers by providing a better understanding of the impact of policy decisions on the future development of the milk bank infrastructure.},
  archive      = {J_EJOR},
  author       = {Marta Staff and Navonil Mustafee and Natalie Shenker and Gillian Weaver},
  doi          = {10.1016/j.ejor.2024.05.023},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {642-655},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Ensuring neonatal human milk provision: A framework for estimating potential demand for donor human milk},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated feeder routing for underground electricity
distribution networks based on aerial images. <em>EJOR</em>,
<em>318</em>(2), 629–641. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process towards a carbon-neutral society requires a substantial amount of investment into electricity distribution networks for integrating more sustainable technologies such as photovoltaic systems, electric vehicles, heat pumps, and others. In order to execute the large number of network expansion measures associated with this effort, strategic and operational planning of distribution networks benefit from higher degrees of automation. A key component in these planning processes is the routing of feeder segments, i. e., the task of finding feasible and cost-efficient paths for underground power lines between two geographic locations, such as residential buildings and transformer stations. In this paper, we present FEEDAIR , a novel and innovative approach to automate feeder routing based exclusively on aerial images. FEEDAIR integrates deep neural networks, which encode geoinformation from aerial images, and A* search, which identifies effective feeder routes based on this encoding. We train and evaluate FEEDAIR using a large data set of more than 7000 real-world electricity distribution network feeder segments. Thereby, we compare FEEDAIR to state-of-the-art approaches from related work and find that the feeder segments generated by FEEDAIR are on par or superior with regard to several characteristics and metrics. FEEDAIR achieves this performance by relying exclusively on aerial images, whereas competing approaches require data on geocoded land cover and estimated construction cost, which is not as widely available and is frequently based on potentially subjective expert opinion.},
  archive      = {J_EJOR},
  author       = {Justus Ameling and Gunther Gust},
  doi          = {10.1016/j.ejor.2024.05.035},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {629-641},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Automated feeder routing for underground electricity distribution networks based on aerial images},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Condition-based reallocation and maintenance for a
1-out-of-2 pairs balanced system. <em>EJOR</em>, <em>318</em>(2),
618–628. (<a href="https://doi.org/10.1016/j.ejor.2024.05.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a system consisting of multiple functionally exchangeable units, differences in units’ degradation levels can significantly affect the system’s performance. Dynamic reallocation of these units can improve performance and prolong the lifetime of the system. This study is the first to quantify the benefit of incorporating reallocation into a condition-based maintenance framework for a 1-out-of-2 pairs balanced system—a system with two pairs of units that functions if there is at least one functioning pair. The balance condition requires that the two units in the same pair should be active or inactive at the same time. Unit degradation is modeled as a Gamma process and is inspected periodically. A Markov decision process model is developed to determine the optimal integrated reallocation and maintenance policy that minimizes the long-run average cost per unit time. A numerical study illustrates that the proposed integrated reallocation and maintenance policy significantly outperforms other limited policies, including reallocate-only and maintain-only policies.},
  archive      = {J_EJOR},
  author       = {Xiaofei Chai and Onur A. Kilic and Jasper Veldman and Ruud H. Teunter and Xian Zhao},
  doi          = {10.1016/j.ejor.2024.05.028},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {618-628},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Condition-based reallocation and maintenance for a 1-out-of-2 pairs balanced system},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving large-scale electricity market pricing problems in
polynomial time. <em>EJOR</em>, <em>318</em>(2), 605–617. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In centralized wholesale electricity markets worldwide, market operators use mixed-integer linear programming to solve the allocation problem. Prices are typically determined based on the duals of relaxed versions of this optimization problem. The resulting outcomes are efficient, but market operators must pay out-of-market uplifts to some market participants and incur a considerable budget deficit that was criticized by regulators. As the share of renewables increases, the number of market participants will grow, leading to larger optimization problems and runtime issues. At the same time, non-convexities will continue to matter, e.g., due to ramping constraints of the generators required to address the variability of renewables or non-convex curtailment costs. We draw on recent theoretical advances in the approximation of competitive equilibrium to compute allocations and prices in electricity markets using convex optimization. The proposed mechanism promises approximate efficiency, no budget deficit, and computational tractability. We present experimental results for this new mechanism in the context of electricity markets, and compare the runtimes, the average efficiency loss of the method, and the uplifts paid with standard pricing rules. We find that the computations with the new algorithm are considerably faster for relevant problem sizes. In general, the computational advantages come at the cost of efficiency losses and a price markup for the demand side. Interestingly, both are small with realistic problem instances. Importantly, the market operator does not incur a budget deficit and the uplifts paid to market participants are significantly lower compared to standard pricing rules.},
  archive      = {J_EJOR},
  author       = {Mete Şeref Ahunbay and Martin Bichler and Teodora Dobos and Johannes Knörr},
  doi          = {10.1016/j.ejor.2024.05.020},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {605-617},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solving large-scale electricity market pricing problems in polynomial time},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved equilibrium efficient frontier data envelopment
analysis approach for evaluating decision-making units with fixed-sum
outputs. <em>EJOR</em>, <em>318</em>(2), 592–604. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, significant development has been made in efficiency evaluation for Decision-Making Units (DMUs) with fixed-sum outputs. The Generalized Equilibrium Efficient Frontier Data Envelopment Analysis (GEEFDEA) approach introduced by Yang et al. (2015) is one of the most representative methods. In the GEEFDEA approach, all DMUs are adjusted to become efficient under the same set of weights, indicating that the Equilibrium Efficient Frontier (EEF) constructed consists of only one hyperplane. However, in practical scenarios under the Variable Return to Scale (VRS) assumption, the production frontier always consists of multiple hyperplanes, presenting a more complex shape. To fill this research gap, we propose an improved Equilibrium Efficient Frontier Data Envelopment Analysis approach. Our approach allows DMUs to have different weights for inputs, variable-sum outputs, and fixed-sum outputs, resulting in an EEF with multiple hyperplanes. It is noted that our new approach uses a non-linear model to obtain the EEF. We show that the model can be linearized in the case of a single fixed-sum output. In situations involving multiple fixed-sum outputs, we propose an algorithm based on the Expectation Maximization (EM) mechanism to solve the model to obtain an EEF. Finally, we illustrate the advantages of our new approach through a numerical example and a case study in the global motor vehicle industry.},
  archive      = {J_EJOR},
  author       = {Junfei Chu and Yanhua Dong and Zhe Yuan},
  doi          = {10.1016/j.ejor.2024.06.003},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {592-604},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An improved equilibrium efficient frontier data envelopment analysis approach for evaluating decision-making units with fixed-sum outputs},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Which algorithm to select in sports timetabling?
<em>EJOR</em>, <em>318</em>(2), 575–591. (<a
href="https://doi.org/10.1016/j.ejor.2024.06.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Any sports competition needs a timetable, specifying when and where teams meet each other. The recent International Timetabling Competition (ITC2021) on sports timetabling showed that, although it is possible to develop general algorithms, the performance of each algorithm varies considerably over the problem instances. This paper provides a problem type analysis for sports timetabling, resulting in powerful insights into the strengths and weaknesses of eight state-of-the-art algorithms. Based on machine learning techniques, we propose an algorithm selection system that predicts which algorithm is likely to perform best based on the type of competition and constraints being used (i.e., the problem type) in a given sports timetabling problem instance. Furthermore, we visualize how the problem type relates to algorithm performance, providing insights and possibilities to further enhance several algorithms. Finally, we assess the empirical hardness of the instances. Our results are based on large computational experiments involving about 50 years of CPU time on more than 500 newly generated problem instances.},
  archive      = {J_EJOR},
  author       = {David Van Bulck and Dries Goossens and Jan-Patrick Clarner and Angelos Dimitsas and George H.G. Fonseca and Carlos Lamas-Fernandez and Martin Mariusz Lester and Jaap Pedersen and Antony E. Phillips and Roberto Maria Rosati},
  doi          = {10.1016/j.ejor.2024.06.005},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {575-591},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Which algorithm to select in sports timetabling?},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Competition or cooperation: Strategy analysis for a social
commerce platform. <em>EJOR</em>, <em>318</em>(2), 560–574. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a market where identical products are sold to consumers via two competing platforms: one traditional and the other social-commerce-based. The social commerce platform operates a virtual community using two strategies: a competition strategy whereby the social commerce platform attracts and engages consumers through its virtual community, leading them to directly purchase products from its e-commerce channel, and a cooperation strategy whereby the social commerce platform integrates links to the traditional platform’s online channel within its community. We fully characterize the optimal decisions and corresponding profits and consumer surplus under each strategy. Our findings indicate that while platforms increase prices in a market with full coverage, they (weakly) decrease them in a market with partial coverage if consumer unit travel costs increase. Additionally, we explain how the revenue-sharing rate and spillover effect of a virtual community affect the cooperation strategy and discover that they have a nonmonotonic impact on the effort level of the social commerce platform. Importantly, we show that when the downstream market is partially covered, the cooperation strategy could result in a win-win-win situation for platforms, consumers, and social welfare. When the downstream market is fully covered, however, the cooperation strategy may result in a lose-win-lose, lose-win-win, or lose-lose-win situation for the social commerce platform, traditional platform, and consumers. Implementing the cooperation strategy might reduce social welfare. We also consider three extensions – sequential pricing, the traditional platform investing in its own virtual community, and a cooperation strategy with cost sharing – to check the robustness of the main results.},
  archive      = {J_EJOR},
  author       = {Haiqing Song and Rui Wang and Yanli Tang},
  doi          = {10.1016/j.ejor.2024.05.014},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {560-574},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Competition or cooperation: Strategy analysis for a social commerce platform},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data envelopment analysis: From non-monotonic to monotonic
scale elasticities. <em>EJOR</em>, <em>318</em>(2), 549–559. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of returns to scale (RTS) or local scale elasticities in data envelopment analysis (DEA)—stemming from variable returns to scale (VRS) technology—has been recently criticized because of its misbehavior in the case of decreasing returns to scale (DRS). Here, the instrument should imply a downsizing force for improving productivity. In classical VRS technologies, however, it can hide respective improvement potentials: the more, the larger a company is. The non-monotonic behavior of local scale elasticities can address this effect. This study shows this phenomenon does not apply when using multiplicative DEA models. Therefore, we propose a new global scaling index that works in the classical VRS technology. We prove the new index is weakly monotonic and illustrate our theoretical findings in a banking context.},
  archive      = {J_EJOR},
  author       = {Andreas Dellnitz and Madjid Tavana},
  doi          = {10.1016/j.ejor.2024.05.018},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {549-559},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Data envelopment analysis: From non-monotonic to monotonic scale elasticities},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A queueing-based approach for integrated routing and
appointment scheduling. <em>EJOR</em>, <em>318</em>(2), 534–548. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to address the integrated routing and appointment scheduling (RAS) problem for a single service provider. The RAS problem is an operational challenge faced by operators that provide services requiring home attendance, such as grocery delivery, home healthcare, or maintenance services. While considering the inherently random nature of service and travel times, the goal is to minimize a weighted sum of the operator’s travel times and idle time, and the client’s waiting times. To handle the complex search space of routing and appointment scheduling decisions, we propose a queueing-based approach to effectively deal with the appointment scheduling decisions. We use two well-known approximations from queueing theory: first, we use an approach based on phase-type distributions to accurately approximate the objective function, and second, we use an heavy-traffic approximation to derive an efficient procedure to obtain good appointment schedules. Combining these two approaches results in a fast and sufficiently accurate hybrid approximation, thus essentially reducing RAS to a routing problem. Moreover, we propose the use of a simple yet effective large neighborhood search metaheuristic to explore the space of routing decisions. The effectiveness of our proposed methodology is tested on benchmark instances with up to 40 clients, demonstrating an efficient and accurate methodology for integrated routing and appointment scheduling.},
  archive      = {J_EJOR},
  author       = {René Bekker and Bharti Bharti and Leon Lan and Michel Mandjes},
  doi          = {10.1016/j.ejor.2024.05.038},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {534-548},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A queueing-based approach for integrated routing and appointment scheduling},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A disaggregated integer l-shaped method for stochastic
vehicle routing problems with monotonic recourse. <em>EJOR</em>,
<em>318</em>(2), 520–533. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new integer L-shaped method for solving two-stage stochastic integer programs whose first-stage solutions can decompose into disjoint components, each one having a monotonic recourse function. In a minimization problem, the monotonicity property stipulates that the recourse cost of a component must always be higher or equal to that of any of its subcomponents. The method exploits new types of optimality cuts and lower bounding functionals that are valid under this property. The stochastic vehicle routing problem is particularly well suited to be solved by this approach, as its solutions can be decomposed into a set of routes. We consider the variant with stochastic demands in which the recourse policy consists of performing a return trip to the depot whenever a vehicle does not have sufficient capacity to accommodate a newly realized customer demand. This work shows that this policy can lead to a non-monotonic recourse function, but that the monotonicity holds when the customer demands are modeled by several commonly used families of probability distributions. We also present new problem-specific lower bounds on the recourse that strengthen the lower bounding functionals and significantly speed up the solving process. Computational experiments on instances from the literature show that the new approach achieves state-of-the-art results.},
  archive      = {J_EJOR},
  author       = {Lucas Parada and Robin Legault and Jean-François Côté and Michel Gendreau},
  doi          = {10.1016/j.ejor.2024.05.012},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {520-533},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A disaggregated integer L-shaped method for stochastic vehicle routing problems with monotonic recourse},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Worst-case conditional value at risk for asset liability
management: A framework for general loss functions. <em>EJOR</em>,
<em>318</em>(2), 500–519. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Asset–liability management (ALM) is a challenging task faced by pension funds due to the uncertain nature of future asset returns, employees’ wages, and interest rates. To address this challenge, this paper presents a new mathematical model that uses a Worst-case Conditional Value-at-Risk (WCVaR) constraint to ensure that, with high probability, the funding ratio remains above a regulator-mandated threshold under the worst-case density function that plausibly explains historical sample data. A tractable reformulation of this WCVaR constraint is developed based on the definition of the Worst-case Lower Partial Moment (WLPM) for a general loss function. Additionally, a data-driven moment-based ambiguity set is constructed to capture uncertainty in the moments of the density functions of random variables in the ALM problem. The proposed approach is evaluated using real-world data from the Canada Pension Plan (CPP) and is shown to outperform classical ALM models, based on either CVaR or WCVaR with fixed moments, on out-of-sample data. The proposed framework for handling correlated uncertainty using WCVaR with nonlinear loss functions can be used in other application areas.},
  archive      = {J_EJOR},
  author       = {Alireza Ghahtarani and Ahmed Saif and Alireza Ghasemi},
  doi          = {10.1016/j.ejor.2024.05.034},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {500-519},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Worst-case conditional value at risk for asset liability management: A framework for general loss functions},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The rail-road dial-a-ride problem. <em>EJOR</em>,
<em>318</em>(2), 486–499. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses an original static Dial-A-Ride service designed for sparsely populated areas. The service relies on vehicles capable of switching between the road and an existing vacant railway network, which induces railway scheduling constraints that must be integrated into the solution algorithm. In the context of the static Dial-A-Ride Problem (DARP), a set of known users must be picked up and dropped off to desired locations while adhering to time windows at nodes and maximal riding time constraints. In our problem, there are additional constraints related to the vehicles when they operate on the rail, creating interdependencies between trips. We develop a generic solution method based on the Adaptive Large Neighbourhood Search (ALNS) framework, combined with a set covering approach to target DARPs with shared resource constraints and synchronization. The method is benchmarked on instances created from a specific region in France. The numerical results show the effectiveness of our approach in integrating resource constraints and the utility of using road-rail vehicles to maximize the number of users served.},
  archive      = {J_EJOR},
  author       = {Jean Jodeau and Nabil Absi and Rémy Chevrier and Dominique Feillet},
  doi          = {10.1016/j.ejor.2024.05.036},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {486-499},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The rail-road dial-a-ride problem},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A competitive heuristic algorithm for vehicle routing
problems with drones. <em>EJOR</em>, <em>318</em>(2), 469–485. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a heuristic algorithm capable of handling multiple variants of the vehicle routing problem with drones (VRPD). Assuming that the drone may be launched from a node and recovered at another, these variants are characterized by three axes, (1) minimizing the transportation cost or minimizing the makespan, (2) the drone is either allowed or not allowed to land while awaiting recovery, and (3) single or multiple trucks each equipped with a drone. In our algorithm, we represent a VRPD solution as a set of customer sequences and evaluate it via local search procedures solving for each sequence a problem that we refer to as the fixed route drone dispatch problem (FRDDP). Given a sequence of customers to be served by a single truck and its drone, the FRDDP selects a subset of customers to be served by the drone and determines drone launch and recovery nodes, while ensuring that each such customer is positioned between two nodes in the initial sequence. We introduce a heuristic dynamic program (HDP) to solve the FRDDP with reduced computational complexity compared to an exact solution algorithm for the problem. We reinforce our algorithm by developing filtering strategies based on the HDP. We benchmark the performance of our algorithm on nine benchmark sets pertaining to four VRPD variants resulting in 932 instances. Our algorithm computes 651 of 680 optimal solutions and identifies 189 new best-known solutions.},
  archive      = {J_EJOR},
  author       = {Xuan Ren and Aurélien Froger and Ola Jabali and Gongqian Liang},
  doi          = {10.1016/j.ejor.2024.05.031},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {469-485},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A competitive heuristic algorithm for vehicle routing problems with drones},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Drone resupply with multiple trucks and drones for on-time
delivery along given truck routes. <em>EJOR</em>, <em>318</em>(2),
457–468. (<a href="https://doi.org/10.1016/j.ejor.2024.05.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drones have been increasingly used for deliveries; however, delivering packages directly to customers is still challenging, particularly in densely populated urban areas. To overcome this, drone resupply has been proposed, where drones carry packages to trucks en route, and then trucks make the final deliveries. Existing studies have only considered the case of one truck and one drone. In this study, we investigate drone resupply with multiple trucks and drones for the on-time delivery of late-available packages. Considering practical operations in urban areas, we focus on a situation where trucks deliver packages along given routes. This raises the drone resupply scheduling problem, which aims to maximise the total value of the late-available packages that can be delivered on time. We formally define the problem and analyse its optimality properties. Then, we develop an exact solution approach based on a time-expanded network flow model and design a greedy heuristic algorithm. We validate the efficiency and effectiveness of the proposed solutions through computational studies. Operational insights and guidance are derived for the application of drones in on-time delivery.},
  archive      = {J_EJOR},
  author       = {Wenqian Liu and Lindong Liu and Xiangtong Qi},
  doi          = {10.1016/j.ejor.2024.05.025},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {457-468},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Drone resupply with multiple trucks and drones for on-time delivery along given truck routes},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A congested facility location problem with strategic
customers. <em>EJOR</em>, <em>318</em>(2), 442–456. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses a user-equilibrium congested facility location problem with delay-, accessibility-, and price-sensitive customers. A profit-maximizing service provider first makes location, service rate, and pricing decisions, and then strategic customers decide which facilities to patronize (if any). By incorporating the customers’ choice behavior as a set of equilibrium constraints into the service provider’s decision problem, the problem is modeled as a mixed integer non-linear program which is then reformulated as a mixed integer second-order cone program. The proposed model, tested on several standard instances, is shown to be efficiently solvable using commercial software packages.},
  archive      = {J_EJOR},
  author       = {Ata Jalili Marand and Pooya Hoseinpour},
  doi          = {10.1016/j.ejor.2024.05.026},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {442-456},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A congested facility location problem with strategic customers},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerated evaluation of blocking flowshop scheduling with
total flow time criteria using a generalized critical machine-based
approach. <em>EJOR</em>, <em>318</em>(2), 424–441. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the considerable advances in the research of the blocking flowshop scheduling problem (BFSP), several unresolved challenges persist. Algorithmic complexity presents hurdles. Although the insertion-based method is considered to generate superior solutions, its high computational demand diminishes the efficiency of algorithms, especially within large-scale sequences. The existing accelerated evaluation methods cannot utilize the existing information to quickly calculate the total flow time or the total tardiness time of the changed sequence after the job insertion, but recalculates it from scratch. This does not significantly reduce computational effort and needs to be further improved. In this paper, we delve into the intrinsic features of these challenges, proposing a generalized accelerated critical machine-based evaluation tailored for the total flow time and tardiness criteria of the BFSP with and without sequence-dependent setup times. First, we propose three theorems, one corollary, and their proofs based on the critical machine. Second, we propose the accelerated evaluation procedure based on these theorems to calculate the objectives related to the total flow time. Third, we also extend the proposed accelerated evaluation method to the BFSP with sequence-dependent setup times, aiming to significantly reduce the time complexity. Finally, we conduct four experiments on five well-known benchmarks (a total of 3540 test instances). Through statistical analysis, it becomes evident that our computational efforts have significantly decreased in computing both the total flow time and the total tardiness time. This performance enhancement is superior to the effectiveness of existing acceleration techniques.},
  archive      = {J_EJOR},
  author       = {Yuyan Han and Yuting Wang and Quan-ke Pan and Ling Wang and M. Fatih Tasgetiren},
  doi          = {10.1016/j.ejor.2024.05.015},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {424-441},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Accelerated evaluation of blocking flowshop scheduling with total flow time criteria using a generalized critical machine-based approach},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic resource matching in manufacturing using deep
reinforcement learning. <em>EJOR</em>, <em>318</em>(2), 408–423. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matching plays an important role in the logical allocation of resources across a wide range of industries. The benefits of matching have been increasingly recognized in manufacturing industries. In particular, capacity sharing has received much attention recently. In this paper, we consider the problem of dynamically matching demand-capacity types of manufacturing resources. We formulate the multi-period, many-to-many manufacturing resource-matching problem as a sequential decision process. The formulated manufacturing resource-matching problem involves large state and action spaces, and it is not practical to accurately model the joint distribution of various types of demands. To address the curse of dimensionality and the difficulty of explicitly modeling the transition dynamics, we use a model-free deep reinforcement learning approach to find optimal matching policies. Moreover, to tackle the issue of infeasible actions and slow convergence due to initial biased estimates caused by the maximum operator in Q-learning, we introduce two penalties to the traditional Q-learning algorithm: a domain knowledge-based penalty based on a prior policy and an infeasibility penalty that conforms to the demand–supply constraints. We establish theoretical results on the convergence of our domain knowledge-informed Q-learning providing performance guarantee for small-size problems. For large-size problems, we further inject our modified approach into the deep deterministic policy gradient (DDPG) algorithm, which we refer to as domain knowledge-informed DDPG (DKDDPG). In our computational study, including small- and large-scale experiments, DKDDPG consistently outperformed traditional DDPG and other RL algorithms, yielding higher rewards and demonstrating greater efficiency in time and episodes.},
  archive      = {J_EJOR},
  author       = {Saunak Kumar Panda and Yisha Xiang and Ruiqi Liu},
  doi          = {10.1016/j.ejor.2024.05.027},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {408-423},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic resource matching in manufacturing using deep reinforcement learning},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A risk-averse distributionally robust project scheduling
model to address payment delays. <em>EJOR</em>, <em>318</em>(2),
398–407. (<a href="https://doi.org/10.1016/j.ejor.2024.05.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Delays in payments have become a common risk factor for industrial projects, especially in recent years, since the financial position of firms has been threatened by pandemics, wars, inflation, and major supply chain disruptions. These delays create a time lag between expenses and payments, potentially leading to cash shortages that can have significant negative effects on the project success. To address cash shortage issues, project contractors often explore alternative financing options. The amount of money the contractor needs to borrow and when the loan is taken out considerably affects the overall project cost. In this paper, we present a distributionally robust model for effective cash flow management that minimizes the financing cost by accurately estimating the amount and timing of the expenses and revenues throughout the project life cycle. For the proposed model, we develop a heuristic algorithm that solves the problem efficiently. The performance of the heuristic is compared to the best-known solutions generated within a time limit by an off-the-shelf exact solver. Our results show that our algorithm is very competitive and can generate better solutions in substantially less time.},
  archive      = {J_EJOR},
  author       = {Maria Elena Bruni and Öncü Hazır},
  doi          = {10.1016/j.ejor.2024.05.037},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {398-407},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A risk-averse distributionally robust project scheduling model to address payment delays},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scheduling with jobs at fixed positions. <em>EJOR</em>,
<em>318</em>(2), 388–397. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study classical single machine scheduling problems with the additional constraint that a set of special jobs must be scheduled at certain positions in the job sequence. In other words, a special job must start when a certain number of jobs have finished on the machine. We analyze several classical objective functions for this more general setting with the additional constraint of fixed positioned jobs. We show that for some of them they are still polynomially solvable. Then, we focus on the objective of minimizing the number of tardy jobs. Considering the case of just one special job, this allows for a polynomial-time algorithm.},
  archive      = {J_EJOR},
  author       = {Florian Jaehn},
  doi          = {10.1016/j.ejor.2024.05.029},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {388-397},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Scheduling with jobs at fixed positions},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On solving close enough orienteering problems with
overlapped neighborhoods. <em>EJOR</em>, <em>318</em>(2), 369–387. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Close Enough Traveling Salesman Problem (CETSP) is a well-known variant of the classic Traveling Salesman Problem whereby the agent may complete its mission at any point within a target neighborhood. Heuristics based on overlapped neighborhoods, known as Steiner Zones (SZ), have gained attention in addressing CETSPs. While SZs offer effective approximations to the original graph, their inherent overlap imposes constraints on the search space, potentially conflicting with global optimization objectives. Here we show how such limitations can be converted into advantages in the Close Enough Orienteering Problem (CEOP) by aggregating prizes across overlapped neighborhoods. We further extend the classic CEOP with Non-uniform Neighborhoods (CEOP- N N ) by introducing non-uniform cost considerations for prize collection. To tackle C EOP (and CEOP- N N ), we develop a new approach featuring a Ra ndomized S teiner Z on e Discretization (RSZD) scheme coupled with a hybrid algorithm based on Particle Swarm Optimization (PSO) and Ant Colony S ystem (ACS) — CRaSZe-AntS. The RSZD scheme identifies sub-regions for PSO exploration, and ACS determines the discrete visiting sequence. We evaluate the RSZD’s discretization performance on CEOP instances derived from established CETSP instances and compare CRaSZe-AntS against the most relevant state-of-the-art heuristic focused on single-neighborhood optimization for CEOP instances. We also compare the performance of the interior search within SZs and the boundary search on individual neighborhoods in the context of CEOP- N N . Our experimental results show that CRaSZe-AntS can yield comparable solution quality with significantly reduced computation time compared to the single neighborhood strategy, where we observe an averaged 140.44% increase in prize collection and 55.18% reduction of algorithm execution time. CRaSZe-AntS is thus highly effective in solving emerging CEOP- N N , examples of which include truck-and-drone delivery scenarios.},
  archive      = {J_EJOR},
  author       = {Qiuchen Qian and Yanran Wang and David Boyle},
  doi          = {10.1016/j.ejor.2024.05.032},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {369-387},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On solving close enough orienteering problems with overlapped neighborhoods},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fifty years of operations research in defense.
<em>EJOR</em>, <em>318</em>(2), 355–368. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The OR (Operations Research) in defense literature is reviewed. Various OR methodologies are outlined, e.g. decision theory, game theory, mergers of differential equations and game theory, and adversarial risk analysis. What is being defended is specified, warfare is described, and common tools and characteristics of the literature are illustrated. The literature is reviewed by classifying it as follows. The system structure of what is being defended is classified into single target, series systems, parallel systems, series-parallel systems, networks, multiple targets, interdependent systems, degraded systems, and other types of systems. Defense strategies are classified into protection, redundancy, false targets, separation of system targets, individual versus overarching defense and, special versus general protection and attack, proactive versus reactive defense, and defending with negative or positive incentives. Attack strategies are classified into attack against a single target, attack against multiple targets, consecutive attacks, and random attack. Defense and attack circumstances are classified into combination of intentional and unintentional impacts, incomplete information, information sharing, cyber war, variable resources, expendable versus nonexpendable resources, multiple defenders, multiple attackers, and multiple defenders and multiple attackers. Reflections are provided on open problems, gaps between the current state of research and real world needs, and prospective research directions.},
  archive      = {J_EJOR},
  author       = {Kjell Hausken},
  doi          = {10.1016/j.ejor.2023.12.023},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {2},
  pages        = {355-368},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fifty years of operations research in defense},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blockchain adoption and optimal reinsurance design.
<em>EJOR</em>, <em>318</em>(1), 341–353. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study blockchain adoption in insurance–reinsurance markets. We consider operational costs related to claim verification and record-keeping. Traditionally, the majority of these costs scale linearly with the volume of claims. Instead, with a consortium blockchain these costs, per firm, become independent of claim volume and decrease with the adoption rate since they are distributed. In a consortium of insurance firms, we quantify how the equilibrium adoption decisions depend on the reinsurance contract characteristics, the risk aversion of insurance companies, the distributions of their potential losses and the blockchain cost structure. Under the optimal contract, the reinsurance firm internalizes the benefits of adoption on other insurance firms, thereby acting as a central planner. We then characterize the adoption gap between decentralized (Nash) and centralized blockchain consortia.},
  archive      = {J_EJOR},
  author       = {Hamed Amini and Romain Deguest and Engin Iyidogan and Andreea Minca},
  doi          = {10.1016/j.ejor.2024.03.033},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {341-353},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Blockchain adoption and optimal reinsurance design},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bi-level optimisation of subsidy and capacity investment
under competition and uncertainty. <em>EJOR</em>, <em>318</em>(1),
327–340. (<a href="https://doi.org/10.1016/j.ejor.2024.03.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a bi-level real options framework for deriving the equilibrium Government subsidisation and firm-level capacity investment policy in a duopoly market structure. We find that strategic interactions with the Government may impact a firm’s capacity investment decision significantly and that the equilibrium subsidisation policy depends on both the market structure and the type of duopolistic competition. Interestingly, the provision of greater subsidy to the leader raises the follower’s incentive to invest earlier and in a bigger project. The loss in value of the leader, due to the follower’s entry, relative to the monopolist increases with economic uncertainty and, although a subsidy can mitigate this loss, its effect becomes less pronounced as economic uncertainty increases. We also find that a profit (welfare)-maximising Government does not offer (offers) a subsidy in a highly uncertain environment or upon low tax rate, while higher tax rate does not always decelerate investment. Finally, we find that while competition is always desirable for a social planner, a profit-maximising Government may benefit more under pre-emptive competition.},
  archive      = {J_EJOR},
  author       = {Zixuan Zhang and Michail Chronopoulos and Ioannis Kyriakou and Dimitrina S. Dimitrova},
  doi          = {10.1016/j.ejor.2024.03.028},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {327-340},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bi-level optimisation of subsidy and capacity investment under competition and uncertainty},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Worst-case risk measures of stop-loss and limited loss
random variables under distribution uncertainty with applications to
robust reinsurance. <em>EJOR</em>, <em>318</em>(1), 310–326. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stop-loss and limited loss random variables are two important transforms of a loss random variable and appear in many modeling problems in insurance, finance, and other fields. Risk levels of a loss variable and its transforms are often measured by risk measures. When only partial information on a loss variable is available, risk measures of the loss variable and its transforms cannot be evaluated effectively. To deal with the situation of distribution uncertainty, the worst-case values of risk measures of a loss variable over an uncertainty set, describing all the possible distributions of the loss variable, have been extensively used in robust risk management for many fields. However, most of these existing results on the worst-case values of risk measures of a loss variable cannot be applied directly to the worst-case values of risk measures of its transforms. In this paper, we derive the expressions of the worst-case values of distortion risk measures of stop-loss and limited loss random variables over an uncertainty set introduced in Bernard et al. (2023). This set represents a decision maker’s belief in the distribution of a loss variable. We find the distributions under which the worst-case values are attainable. These results have potential applications in a variety of fields. To illustrate their applications, we discuss how to model optimal stop-loss reinsurance problems and how to determine optimal stop-loss retentions under distribution uncertainty. Explicit and closed-form expressions for the worst-case TVaRs of stop-loss and limited loss random variables and optimal stop-loss retentions are given under special forms of the uncertainty set. Numerical results are presented under more general forms of the uncertainty set.},
  archive      = {J_EJOR},
  author       = {Jun Cai and Fangda Liu and Mingren Yin},
  doi          = {10.1016/j.ejor.2024.03.016},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {310-326},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Worst-case risk measures of stop-loss and limited loss random variables under distribution uncertainty with applications to robust reinsurance},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How power structure and markup schemes impact supply chain
channel efficiency under price-dependent stochastic demand.
<em>EJOR</em>, <em>318</em>(1), 297–309. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although considerable attention has been separately given to factors such as power structures, price-dependent demand, and markup pricing schemes, there has been limited exploration of the combined effects of these factors on supply chain efficiency and the leader’s advantage. We propose a game theoretic model in which a manufacturer sells a single product to a newsvendor retailer who sets both optimal order quantity and selling price under uncertain price-dependent demand. Furthermore, we examine a supply network wherein a single retailer fulfills orders using a global manufacturer for regular orders and a local manufacturer to clear any shortages. Through numerical analysis, we show that the retailer always prefers to charge a percentage markup. In a two-player game, channel efficiency is higher when the retailer is the leader under linear demand; however, under iso-elastic demand, the manufacturer being a leader brings a higher channel efficiency. When a local manufacturer is involved as a second manufacturer, channel efficiency is higher when the retailer remains a follower, as this induces more fierce wholesale price competition between the two manufacturers. Additionally, when demand uncertainty is high in the two-player game with linear demand, the retailer as a follower can achieve higher profits, whilst high uncertainty under iso-elastic demand decreases both players’ profits. Moreover, it becomes advantageous for the retailer to have a local manufacturer as demand uncertainty increases, even when the local manufacturer announces the wholesale price first.},
  archive      = {J_EJOR},
  author       = {Eunji Lee and Stefan Minner},
  doi          = {10.1016/j.ejor.2024.05.019},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {297-309},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {How power structure and markup schemes impact supply chain channel efficiency under price-dependent stochastic demand},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multiobjective beam angle optimization framework for
intensity-modulated radiation therapy. <em>EJOR</em>, <em>318</em>(1),
286–296. (<a href="https://doi.org/10.1016/j.ejor.2024.05.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiation therapy treatment planning is inherently a multiobjective problem, aiming to obtain the best tradeoffs between irradiating the tumor with the prescribed dose and sparing as much as possible the surrounding healthy organs. Many different multiobjective approaches have been proposed for the optimization of radiation intensities for fixed beam irradiation directions. However, multiobjective beam angle optimization is seldom considered. The purpose of this paper is to introduce a new multiobjective optimization framework that explicitly and simultaneously considers the optimization of intensities and also beam directions. Whilst multiobjective optimization of radiation intensities considering a fixed set of beam directions gives rise to a single Pareto front, beam angle optimization gives rise to the appearance of multiple Pareto fronts, each one associated with a given beam angle set. Our framework proposes a beam angle set choice based on the evaluation of non-dominated solutions belonging to different Pareto fronts, using a tree-based approach and a performance indicator to assess the quality of each Pareto front. The proposed approach, illustrated by head-and-neck cancer cases, allows for more flexibility in the calculation of solutions and a better understanding of the existing compromises between different objectives.},
  archive      = {J_EJOR},
  author       = {Juliana Campos de Freitas and Daniela Renata Cantane and Humberto Rocha and Joana Dias},
  doi          = {10.1016/j.ejor.2024.05.004},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {286-296},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A multiobjective beam angle optimization framework for intensity-modulated radiation therapy},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A robust approach to food aid supply chains. <em>EJOR</em>,
<em>318</em>(1), 269–285. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the great challenges in reaching zero hunger is to secure the availability of sufficient nourishment in the worst of times such as humanitarian emergencies. Food aid operations during a humanitarian emergency are typically subject to a high level of uncertainty. In this paper, we develop a novel robust optimization model for food aid operations during a humanitarian emergency, where we include uncertainty in the procurement prices, which is one of the primary sources of uncertainty in practice. Due to the multi-period and dynamic nature of food aid operations, we extend this robust optimization model to an adaptive robust optimization model, in which part of the decisions is taken after some of the uncertainty has been revealed. Moreover, we analyze a folding horizon approach for the nominal, robust, and adaptive robust optimization models in which decisions can be altered in later time periods. We compare the different approaches based on a food operations case in Syria. We show that the (adaptive) robust optimization approach outperforms the nominal approach in the non-folding horizon case, while the nominal approach performs best in the folding horizon case. Consequently, in case decisions have to be made early on, we show that applying robust optimization to food aid operations can make a difference. However, in case small adaptations can be made to the decisions taken in later time periods, then food aid operations can use a relatively simple approach in practice and apply a folding horizon approach each month to optimize decisions.},
  archive      = {J_EJOR},
  author       = {Danique de Moor and Joris Wagenaar and Robert Poos and Dick den Hertog and Hein Fleuren},
  doi          = {10.1016/j.ejor.2024.04.034},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {269-285},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A robust approach to food aid supply chains},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A data-driven distributionally robust optimization approach
for the core acquisition problem. <em>EJOR</em>, <em>318</em>(1),
253–268. (<a href="https://doi.org/10.1016/j.ejor.2024.05.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reusing electric vehicles (EV) batteries that reach the end of their useful first life is an environmental and cost-competitive option; however, the process of recycling EV batteries is not yet mature. Due to complex electrochemical reactions and physical conditions, the quality of used EV batteries (cores) is highly uncertain. The remanufacturer needs to make the acquisition decision under quality distributional ambiguity. Perfect quality distribution of cores cannot be known to the remanufacturer in practice. We develop distributionally robust optimization models based on phi-divergence measures and the imprecise Dirichlet model (DRO-IDM) to derive robust decisions. First, we find that the bounds of quality probability intervals are identified solely based on the collected data by introducing the imprecise Dirichlet model. The derived finite-sample boundary can reduce the scope of the uncertainty set and avoid the no-direction search issue. Second, our models can hedge against distributional uncertainty, reduce the probability of a robust solution that deviates from the optimal solution, and correct bias in decision making. Third, we extend the DRO-IDM to develop data-driven models, that can reassess the value of multisource quality information to improve the estimation accuracy of core quality and maximize the remanufacturer’s profit. Our study provides new insights for remanufacturers: the new remanufacturing process proposed in our work can assist remanufacturers in utilizing the values of cores without disassembly; the information-aware algorithm can offer the remanufacturing sector a valuable tool for efficiently filtering out invalid information in optimizing acquisition decisions; this capability empowers decision-makers to leverage multiple sources of information and expedite the process of digital transformation in remanufacturing; our approach can also provide a manner of integrating information fusion and distribution learning into remanufacturing.},
  archive      = {J_EJOR},
  author       = {Cheng-Hu Yang and Xiao-Li Su and Xin Ma and Srinivas Talluri},
  doi          = {10.1016/j.ejor.2024.05.007},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {253-268},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A data-driven distributionally robust optimization approach for the core acquisition problem},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Determinism versus uncertainty: Examining the worst-case
expected performance of data-driven policies. <em>EJOR</em>,
<em>318</em>(1), 242–252. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores binary decision making, a critical domain in areas such as finance and supply chain management, where decision makers must often choose between a deterministic-cost option and an uncertain-cost option. Given the limited historical data on the uncertain cost and its unknown probability distribution, this research aims to ascertain how decision makers can optimize their decisions. To this end, we evaluate the worst-case expected performance of all possible data-driven policies, including the sample average approximation policy, across four scenarios differentiated by the extent of knowledge regarding the lower and upper bounds of the first moment of the uncertain cost distribution. Our analysis, using worst-case expected absolute regret and worst-case expected relative regret metrics, consistently shows that no data-driven policy outperforms the straightforward strategy of choosing either a deterministic-cost or uncertain-cost option in these scenarios. Notably, the optimal choice between these two options depends on the specific lower and upper bounds of the first moment. Our research contributes to the literature by revealing the minimal worst-case expected performance of all possible data-driven policies for binary decision-making problems.},
  archive      = {J_EJOR},
  author       = {Xuecheng Tian and Shuaian Wang and Gilbert Laporte and Ying Yang},
  doi          = {10.1016/j.ejor.2024.04.031},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {242-252},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Determinism versus uncertainty: Examining the worst-case expected performance of data-driven policies},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pricing and capacity allocation in opaque selling.
<em>EJOR</em>, <em>318</em>(1), 230–241. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the supply and demand mismatch problem, intermediaries have emerged as an opaque channel for service providers to dispose of leftover capacity. This paper focuses on pricing and capacity allocation in opaque selling. We develop a Stackelberg game model, where two capacity-constrained service providers first decide the capacity allocated to an intermediary who then determines the opaque price based on its capacity. We examine the conditions under which the service providers should cooperate with the intermediary, and find that the opaque price and capacity allocation decisions are affected by product type, service providers’ capacity, and commission rate. Moreover, we find that the service providers may fall into the prisoner&#39;s dilemma when distributing through the intermediary. It indicates that although opaque selling can bring service providers more profit, it may not help them achieve the optimal profit. In view of this, we propose an alliance policy to eliminate the prisoners’ dilemma and examine when the service providers should ally. Results show that this policy can improve the profits of the service providers and the whole supply chain if the commission rate is adequately low. Our findings suggest that opaque selling can be less beneficial than previously shown and demonstrate the importance of an alliance policy.},
  archive      = {J_EJOR},
  author       = {Zihao Zhang and Mengying Zhang},
  doi          = {10.1016/j.ejor.2024.05.022},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {230-241},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pricing and capacity allocation in opaque selling},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Whitelisting versus advertising-recovery: Strategies to
overcome advertising blocking by consumers. <em>EJOR</em>,
<em>318</em>(1), 217–229. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significance of online advertising as a primary revenue stream for digital media cannot be understated. However, the rising adoption of ad-blocking software by users has adversely affected these revenues. In response to this challenge, digital publishers are exploring various strategies not only to maintain their revenues, but also to enhance them through online advertising, in addition to paid subscriptions. We discuss three potential strategies to overcome ad-blocking. The first is the subscription fee strategy, termed the benchmark strategy in the paper, wherein users pay a subscription fee to access content without encountering any ads. The second strategy is whitelisting, which involves publishers seeking users’ consent to display acceptable ads that support the website. The third approach is ad-recovery, which employs a third-party service to continue displaying ads even to users employing ad-blocking software. We utilize a duopolistic game-theoretical framework and identify conditions under which digital publishers might adopt either symmetric or asymmetric strategies to counter ad-blocking usage. We find that both firms tend to opt for whitelisting when the advertising revenue parameter is relatively low, and the proportion of consenting ad-block users is relatively high. On the other hand, when the advertising revenue parameter is high, and the proportion of consenting ad-block users is low, both firms benefit from an ad-recovery strategy. Further, under some conditions, firms utilize asymmetric strategies. The analysis suggests that a number of consumer- and firm-level factors represent important determinants of the digital marketing strategies of media firms.},
  archive      = {J_EJOR},
  author       = {Ashutosh Singh and S. Sajeesh and Pradeep Bhardwaj},
  doi          = {10.1016/j.ejor.2024.05.017},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {217-229},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Whitelisting versus advertising-recovery: Strategies to overcome advertising blocking by consumers},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consensus adjustment for multi-attribute group decision
making based on cross-allocation. <em>EJOR</em>, <em>318</em>(1),
200–216. (<a href="https://doi.org/10.1016/j.ejor.2024.05.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consensus adjustment is crucial in group decision making (GDM), aiming to reduce discrepancies in decision makers’ (DMs’) judgments for final decision results. The consensus adjustments made by DMs are interactive rather than independent. However, few studies investigate the consensus adjustment problem from the perspective of interactions among DMs. This study first constructs a model to determine the total minimum consensus adjustment under the requirements of consensus threshold and individual-collective judgment bias. Then, a consensus adjustment approach based on cross-allocation scheme is proposed to address the inconsistency between individual and collective minimum adjustments, which concerns all DMs’ individual favorable allocation results under the total minimum consensus adjustment. The cross-allocation scheme ensures unanimous support for the same allocation result among all rational DMs, thereby eliminating the discrepancies among them. Subsequently, the optimization model-based minimum consensus judgment penalty is formulated to handle the non-cooperative behaviors of DMs. Furthermore, we show how to determine the unique consensus adjustment result for the non-cooperative DMs using the cross-allocation scheme. Therefore, our study contributes by developing a new GDM method that conducts consensus adjustment allocation by considering interactions among DMs. Finally, a case study is employed to demonstrate the specific application of the new method and discuss its efficiency. Meanwhile, comparison analysis and simulation experiments are provided.},
  archive      = {J_EJOR},
  author       = {Fan-Yong Meng and Deng-Yu Zhao and Zai-Wu Gong and Jun-Fei Chu and Witold Pedrycz and Zhe Yuan},
  doi          = {10.1016/j.ejor.2024.05.003},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {200-216},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Consensus adjustment for multi-attribute group decision making based on cross-allocation},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multistage stochastic optimization for mid-term integrated
generation and maintenance scheduling of cascaded hydroelectric system
with renewable energy uncertainty. <em>EJOR</em>, <em>318</em>(1),
179–199. (<a href="https://doi.org/10.1016/j.ejor.2024.05.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uncertainties resulting from the escalating penetration of renewable energy resources pose severe challenges to the efficient operation of modern power systems. Hydroelectricity is characterized by its flexibility, controllability, and reliability, and thus becomes one of the most ideal energy resources to hedge against such uncertainties. This paper studies the mid-term integrated generation and maintenance scheduling of a cascaded hydroelectric system (CHS) consisting of multiple cascaded reservoirs and hydroelectric units. To precisely describe the mid-term water regulation policies, the hydraulic coupling relationship and water-energy nexus of CHS are incorporated into the proposed optimization model. The uncertainties of natural water inflow and the power outputs of wind/solar energy generation are taken into consideration and captured via a stochastic process modeled by a scenario tree. A multistage stochastic optimization (MSO) approach is developed to coordinate the complementary operations of multiple energy resources, by optimizing the mid-term water resource management, generation scheduling, and maintenance scheduling of CHS. The proposed MSO model is formulated as a large-scale mixed-integer linear program that presents significant computational intractability. To address this issue, a tailored Benders decomposition algorithm is developed. Two real-world case studies are conducted to demonstrate the capability and characteristics of the proposed model and algorithm. The computational results show that the proposed MSO model can exploit the flexibility of hydroelectricity to efficiently respond to variable wind and solar power, and reserve water resources for the generation in peak months to reduce the consumption of fossil fuel. The proposed solution approach also exhibits promising computational efficiency when handling large-scale models.},
  archive      = {J_EJOR},
  author       = {Zhiming Zhong and Neng Fan and Lei Wu},
  doi          = {10.1016/j.ejor.2024.05.011},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {179-199},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multistage stochastic optimization for mid-term integrated generation and maintenance scheduling of cascaded hydroelectric system with renewable energy uncertainty},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rank-1 transition uncertainties in constrained markov
decision processes. <em>EJOR</em>, <em>318</em>(1), 167–178. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an infinite-horizon discounted constrained Markov decision process (CMDP) with uncertain transition probabilities. We assume that the uncertainty in transition probabilities has a rank-1 matrix structure and the underlying uncertain parameters belong to a polytope. We formulate the uncertain CMDP problem using a robust optimization framework. To derive reformulation of the robust CMDP problem, we restrict to the class of stationary policies and show that it is equivalent to a bilinear programming problem. We provide a simple example where a Markov policy performs better than the optimal policy in the class of stationary policies, implying that, unlike in classical CMDP problem, an optimal policy of the robust CMDP problem need not be present in the class of stationary policies. For the case of a single uncertain parameter, we propose sufficient conditions under which an optimal policy of the restricted robust CMDP problem is unaffected by uncertainty. The numerical experiments are performed on randomly generated instances of a machine replacement problem and a well-known class of problems called Garnets.},
  archive      = {J_EJOR},
  author       = {V Varagapriya and Vikas Vikram Singh and Abdel Lisser},
  doi          = {10.1016/j.ejor.2024.04.023},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {167-178},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Rank-1 transition uncertainties in constrained markov decision processes},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Problem-based scenario generation by decomposing output
distributions. <em>EJOR</em>, <em>318</em>(1), 154–166. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scenario generation is required for most applications of stochastic programming to evaluate the expected effect of decisions made under uncertainty. We propose a novel and effective problem-based scenario generation method for two-stage stochastic programming that is agnostic to the specific stochastic program and kind of distribution. Our contribution lies in studying how an output distribution may change across decisions and exploit this for scenario generation. From a collection of output distributions, we find a few components that largely compose these, and such components are used directly for scenario generation. Computationally, the procedure relies on evaluating the recourse function over a large discrete distribution across a set of candidate decisions, while the scenario set itself is found using standard and efficient linear algebra algorithms that scale well. The method’s effectiveness is demonstrated on four case study problems from typical applications of stochastic programming to show it is more effective than its distribution-based alternatives. Due to its generality, the method is especially well suited to address scenario generation for distributions that are particularly challenging.},
  archive      = {J_EJOR},
  author       = {Benjamin S. Narum and Jamie Fairbrother and Stein W. Wallace},
  doi          = {10.1016/j.ejor.2024.04.006},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {154-166},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Problem-based scenario generation by decomposing output distributions},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discrete forecast reconciliation. <em>EJOR</em>,
<em>318</em>(1), 143–153. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a formal framework and proposes algorithms to extend forecast reconciliation to discrete-valued data, including low counts. A novel method is introduced based on recasting the optimisation of scoring rules as an assignment problem, which is solved using quadratic programming. The proposed framework produces coherent joint probabilistic forecasts for count hierarchical time series. Two discrete reconciliation algorithms are also proposed and compared against generalisations of the top-down and bottom-up approaches for count data. Two simulation experiments and two empirical examples are conducted to validate that the proposed reconciliation algorithms improve forecast accuracy. The empirical applications are forecasting criminal offences in Washington D.C. and product unit sales in the M5 dataset. Compared to benchmarks, the proposed framework shows superior performance in both simulations and empirical studies.},
  archive      = {J_EJOR},
  author       = {Bohan Zhang and Anastasios Panagiotelis and Yanfei Kang},
  doi          = {10.1016/j.ejor.2024.05.024},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {143-153},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Discrete forecast reconciliation},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Manufacturer’s choice of online selling format in a
dual-channel supply chain with green products. <em>EJOR</em>,
<em>318</em>(1), 131–142. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When selling green products on online platforms, manufacturers often have to choose their selling format between agency selling and reselling. This paper focuses on a green manufacturer selling substitutable products through an e-commerce platform (also known as an e-tailer) and an independent offline retailer. Our research makes a major contribution by examining how the manufacturer makes joint decisions on green product development, pricing, and the online selling format. Our analytical results show that, first, in the case of a low agency fee, agency selling leads to a greener product on the online channel, which benefits the manufacturer. Otherwise, reselling improves the product greenness on both channels, which benefits the manufacturer. More notably, higher consumer green awareness incentivizes the manufacturer to prefer agency selling. Second, counterintuitively, it is found that agency selling can be more profitable for the e-tailer when the agency fee is low and moderate, and vice versa. This is because a high agency fee will depress the manufacturer&#39;s online sales of green products, hurting the e-tailer. Finally, we extend our model to the cases with different marginal demand expansion parameters, different greenness-enhancing cost factors, a leading e-tailer, the simultaneous use of both formats, and different channel competition coefficients on the price and product greenness. We demonstrate the robustness of our main analytical results and obtain more managerial insights.},
  archive      = {J_EJOR},
  author       = {Jin Li and Haoyu Wang and Victor Shi and Qi Sun},
  doi          = {10.1016/j.ejor.2024.04.038},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {131-142},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Manufacturer&#39;s choice of online selling format in a dual-channel supply chain with green products},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Green technological licensing strategies with fixed-fee
among rival firms under emissions trading scheme. <em>EJOR</em>,
<em>318</em>(1), 110–130. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers no-licensing, unilateral licensing, and cross-licensing strategies among rival firms with different green technologies under emissions trading scheme. We mainly focus on the impact of green technological licensing strategies on firms’ operational management from a business perspective by considering different carbon quota allocations. It is shown that the green technological licensing strategy is always a preferred strategy in globally optimal sense when the technological gap and emission improvement are lower than some thresholds; if firms’ bargaining powers are within a certain range, the green technological licensing strategies can realize a Pareto improvement; the equilibrium decisions have a certain degree of robustness under random perturbation. To improve the performance of green technological licensing models, we introduce revenue-sharing contracts into the green technological licensing negotiation processes and show that, if the better-off firms agree to transfer a certain portion of their revenues, revenue-sharing contracts can increase the total profits of firms and are profitable for all parties. From an economic and environmental perspective, green technological licensing strategies can promote sustainable social development, while revenue-sharing contracts can significantly increase the incentive for rival firms to license green technologies.},
  archive      = {J_EJOR},
  author       = {Qi Zhang and Xide Zhu and Gui-Hua Lin},
  doi          = {10.1016/j.ejor.2024.04.036},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {110-130},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Green technological licensing strategies with fixed-fee among rival firms under emissions trading scheme},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Complexity analysis of integrated dynamic lot sizing and
maintenance planning problems. <em>EJOR</em>, <em>318</em>(1), 100–109.
(<a href="https://doi.org/10.1016/j.ejor.2024.04.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a problem where the planning decisions of producing on and maintaining a single machine are integrated. The age of the machine, and thus when maintenance should be performed, is influenced by the production decisions. Decisions are taken on a planning horizon discretized in periods. The computational complexity of several variants of the single-item problem are studied depending on whether (i) Maintenance can be performed on the machine at any point in time in a period or must be performed at the end of a period, (ii) There is a fixed aging component when starting production, and (iii) There is a minimum age before maintenance can be performed on the machine. The multi-item case is proved to be NP-hard.},
  archive      = {J_EJOR},
  author       = {Nabil Absi and Wilco van den Heuvel and Stéphane Dauzère-Pérès},
  doi          = {10.1016/j.ejor.2024.04.025},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {100-109},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Complexity analysis of integrated dynamic lot sizing and maintenance planning problems},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Product portfolio adjustments and the bullwhip effect: The
impact of product introduction and retirement. <em>EJOR</em>,
<em>318</em>(1), 87–99. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many manufacturers frequently tweak their product portfolios by introducing new products and retiring low performers. In this paper, we study how the demand shock caused by portfolio adjustments impacts the bullwhip effect (BWE) of existing products. With the help of two approximations, we provide a closed-form expression for the BWE as a function of the time (number of periods) remaining until the shock, which enables us to obtain novel insights. When products are retired, the market share of the remaining product varieties often increases. We prove that the product experiencing the most significant market share increase also encounters the highest BWE surge in the periods leading up to the portfolio change. On the other hand, the introduction of new products does not consistently lead to a higher BWE for existing products. The impact on the BWE depends on several parameters, particularly the uncertainty surrounding the market share of existing products after the portfolio change. When this uncertainty is low for an existing product, its BWE reduces when new varieties are introduced.},
  archive      = {J_EJOR},
  author       = {Hamed Jalali and Mozart B.C. Menezes},
  doi          = {10.1016/j.ejor.2024.04.035},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {87-99},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Product portfolio adjustments and the bullwhip effect: The impact of product introduction and retirement},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spare parts recommendation for corrective maintenance of
capital goods considering demand dependency. <em>EJOR</em>,
<em>318</em>(1), 71–86. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a maintenance service provider that services geographically dispersed customers with its local service engineers. Traditionally, when a system failure is reported, a service engineer makes a diagnostic visit to the customer’s location to perform corrective maintenance. If spare parts are required, they are ordered and a second visit is scheduled at a later date to complete the corrective maintenance. In this paper, the service provider can proactively send spare parts to the customer to avoid the costly second visit. Motivated by a real-world problem in the high-tech industry, our model considers the cost of a second visit, fixed shipment costs, retrieval costs for the parts that are sent to the customer, and send-back costs for the parts that are sent but not used for corrective maintenance. The uncertainty in the set of parts required for corrective maintenance is modeled with a general distribution that can capture the dependencies between demands for different spare parts. We formulate an integer linear program to find the optimal set of spare parts that minimizes the expected total cost. We derive analytical results for the structure of the optimal policy and compare the optimal policy with two benchmark policies from practice. We observe that the policies from practice often find the optimal policy, and a new heuristic policy that exploits the structure of the optimal policy, on average, performs better than the benchmark policies.},
  archive      = {J_EJOR},
  author       = {İpek Dursun and Anastasiia Grishina and Alp Akcay and Geert-Jan van Houtum},
  doi          = {10.1016/j.ejor.2024.04.024},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {71-86},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Spare parts recommendation for corrective maintenance of capital goods considering demand dependency},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Railway crew planning with fairness over time.
<em>EJOR</em>, <em>318</em>(1), 55–70. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Passenger railway operators typically employ large numbers of drivers and guards, and are interested in providing them with fair and attractive working conditions. At Netherlands Railways (NS), the largest passenger railway operator in The Netherlands, this challenge is addressed through the use of Sharing-Sweet-and-Sour rules, which specify a fair allocation of sweet (attractive) and sour (unattractive) work over the different crew bases. While these rules are currently implemented at the crew base level and in the tactical planning phase, NS is considering formulating these rules at the individual level, in the operational planning phase, and with respect to a given planning period. This gives rise to a new problem, which we call the railway crew planning problem with fairness over time. We propose a rolling horizon approach with a penalty-based feedback mechanism and a column generation heuristic to solve this problem. On several real-life instances from NS, including up to 572 unique guards, this method is able to satisfy the individual rules for on average 95.2% of the employees.},
  archive      = {J_EJOR},
  author       = {B.T.C. van Rossum and T. Dollevoet and D. Huisman},
  doi          = {10.1016/j.ejor.2024.04.029},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {55-70},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Railway crew planning with fairness over time},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A generalized benders decomposition approach for the optimal
design of a local multi-energy system. <em>EJOR</em>, <em>318</em>(1),
43–54. (<a href="https://doi.org/10.1016/j.ejor.2024.05.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A local multi-energy system (LMES) is a decentralized energy system producing energy under multiple forms to satisfy the energy demand of a set of buildings located in its neighborhood. We study the problem of optimally designing an LMES over a multi-phase horizon. This problem is formulated as a large-size mixed-integer linear program with a block-decomposable structure involving mixed-integer sub-problems. We propose a new way to adapt a recently published framework for generalized Benders decomposition to our problem. This is done by exploiting the fact that the constraint matrix appearing in front of the first-stage variables in the coupling constraints is non-negative. The obtained generalized Benders decomposition algorithm relies on the use of a new type of non-convex Benders cuts involving indicator functions. We first prove that, under the assumption that all first-stage decision variables are integer and bounded, the finite and optimal convergence of our algorithm is guaranteed in theory. We then investigate how to obtain a good numerical performance in practice. Finally, we report the results of a computational study carried out on a real-life case study. These results show that the proposed algorithm clearly outperforms both a mathematical programming solver directly solving the problem as a whole and a state-of-the art hierarchical decomposition algorithm.},
  archive      = {J_EJOR},
  author       = {Bingqian Liu and Côme Bissuel and François Courtot and Céline Gicquel and Dominique Quadri},
  doi          = {10.1016/j.ejor.2024.05.013},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {43-54},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A generalized benders decomposition approach for the optimal design of a local multi-energy system},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient hybrid genetic algorithm for the traveling
salesman problem with release dates. <em>EJOR</em>, <em>318</em>(1),
31–42. (<a href="https://doi.org/10.1016/j.ejor.2024.05.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with a generalization of the classic traveling salesman problem where each customer is associated with a release date, defined as the time at which the desired product becomes available at the depot. In this problem, a single uncapacitated vehicle is allowed to perform multiple trips in order to satisfy all demands. However, the vehicle cannot start a route unless all the products associated with the demands in the route are released. As a consequence, there might be a waiting time before starting the next route. The objective of the problem is to minimize the completion time of the service, defined as the time at which the vehicle returns to the depot after satisfying all demands. We propose a hybrid genetic algorithm that incorporates more advanced mechanisms to evaluate individuals and to ensure population diversity. We also introduce a novel dynamic programming splitting algorithm that converts a sequence of visits to customers, the so-called giant-tour , into the best set of routes that respects the sequence. Computational experiments performed on 522 benchmark instances show that our approach is able to find all 154 known optimal solutions from the literature. In addition, we were able to improve the best-known upper bounds for 364 instances in significantly shorter computational times when compared to the state-of-the-art.},
  archive      = {J_EJOR},
  author       = {Gabriel Soares and Teobaldo Bulhões and Bruno Bruck},
  doi          = {10.1016/j.ejor.2024.05.010},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {31-42},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An efficient hybrid genetic algorithm for the traveling salesman problem with release dates},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Labeling methods for partially ordered paths.
<em>EJOR</em>, <em>318</em>(1), 19–30. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The landscape of applications and subroutines relying on shortest path computations continues to grow steadily. This growth is driven by the undeniable success of shortest path algorithms in theory and practice. It also introduces new challenges as the models and assessing the optimality of paths become more complicated. Hence, multiple recent publications in the field adapt existing labeling methods in an ad hoc fashion to their specific problem variant without considering the underlying general structure: they always deal with multi-criteria scenarios, and those criteria define different partial orders on the paths. In this paper, we introduce the partial order shortest path problem ( POSP POSP ), a generalization of the multi-objective shortest path problem (MOSP) and in turn also of the classical shortest path problem. POSP POSP captures the particular structure of many shortest path applications as special cases. In this generality, we study optimality conditions or the lack of them, depending on the objective functions’ properties. Our final contribution is a big lookup table summarizing our findings and providing the reader with an easy way to choose among the most recent multi-criteria shortest path algorithms depending on their problems’ weight structure. Examples range from time-dependent shortest path bottleneck path problems to the electric vehicle shortest path problem with recharging and complex financial weight functions studied in the public transportation community. Our results hold for general digraphs and, therefore, surpass previous generalizations that were limited to acyclic graphs.},
  archive      = {J_EJOR},
  author       = {Ricardo Euler and Pedro Maristany de las Casas},
  doi          = {10.1016/j.ejor.2024.05.002},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {19-30},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Labeling methods for partially ordered paths},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fifty years of portfolio optimization. <em>EJOR</em>,
<em>318</em>(1), 1–18. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The allocation of resources to alternative investment opportunities is one of the most important decisions organizations and individuals face. These decisions can be guided by building and solving portfolio optimization models that capture the salient aspects of the investment problem, including decision-makers’ preferences, multiple objectives, and decision opportunities over the planning horizon. In this paper, we give a historically grounded overview of portfolio optimization which, as a field within operational research with roots in finance, is vast thanks to many decades of research and the huge diversity of problems that have been tackled. In particular, we provide a unified and therefore unique treatment that covers the full breadth of portfolio optimization problems, including, for instance, the allocation of resources to financial assets and the selection of indivisible assets such as R&amp;D projects. We also identify opportunities for future methodological and applied research, hoping to inspire researchers to contribute to the growing field of portfolio optimization.},
  archive      = {J_EJOR},
  author       = {Ahti Salo and Michalis Doumpos and Juuso Liesiö and Constantin Zopounidis},
  doi          = {10.1016/j.ejor.2023.12.031},
  journal      = {European Journal of Operational Research},
  month        = {10},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fifty years of portfolio optimization},
  volume       = {318},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new class of composite indicators: The penalized power
mean. <em>EJOR</em>, <em>317</em>(3), 1015–1035. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a new aggregation method for constructing composite indicators based on a penalization of the power mean. The idea underlying this approach consists in multiplying the power mean by a factor that accounts for the horizontal heterogeneity among indicators while penalizing units with a larger heterogeneity. In line with the minimum loss of information principle, the penalization factor proposed is proven to be linked to the loss of information generated when the indicators are substituted with their power means. As a consequence, the aggregation approach gives rise to the class of penalized power means and the penalized Benefit of the Doubt aggregative approach. Including heterogeneity makes the aggregation approach more suitable for refined rankings. Interestingly, the penalized power mean of order one coincides with the Mazziotta Pareto Index. Some theoretical properties of the penalized power means are proven, thus supporting the Mazziotta Pareto index. An empirical analysis of the Human Development Index in 2019 is presented. Comparisons of the rankings induced by the penalized and non-penalized Benefit of the Doubt and power mean aggregation approaches are shown. There are three main findings: the penalized power means satisfy the properties characterizing weakly monotone aggregation functions; the penalization reduces ranking variations while differentiating units with close means; and the geometric mean provides composite indicators whose ranking is closest to those obtained with power means of different order.},
  archive      = {J_EJOR},
  author       = {Francesca Mariani and Mariateresa Ciommi and Maria Cristina Recchioni},
  doi          = {10.1016/j.ejor.2024.04.032},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {1015-1035},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new class of composite indicators: The penalized power mean},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reward function design method to achieve system-level
objectives in ambulance diversion problem. <em>EJOR</em>,
<em>317</em>(3), 1003–1014. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses a reward function design problem in multi-agent systems, using ambulance diversion (AD) problem in emergency medical services (EMS) as an application. While Emergency Departments (EDs) may declare AD to alleviate overcrowding, excessive use of this strategy by individual EDs can have negative consequences, such as limited access and delayed care for emergency patients. To eliminate negative consequences caused by individual decisions, we propose a reward function design method to align individual agents’ decisions with socially optimal strategies. This method ensures that an equilibrium status is achieved under socially optimal operation by removing incentives for deviations from socially optimal behavior while maximizing system welfare without extra investment. The proposed method offers an exact solution for designing reward function of a stochastic game model with finite state and action spaces. We conduct numerical experiments for a 2-ED system and demonstrate that the designed reward function properly guides the EDs toward a socially optimal AD strategy.},
  archive      = {J_EJOR},
  author       = {Hyun-Rok Lee and Taesik Lee},
  doi          = {10.1016/j.ejor.2024.04.033},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {1003-1014},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Reward function design method to achieve system-level objectives in ambulance diversion problem},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust two-stage optimization consensus models with
uncertain costs. <em>EJOR</em>, <em>317</em>(3), 977–1002. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the consensus-reaching process (CRP), decision-makers (DMs) frequently encounter the dilemma of too much uncertain information, which can lead the actual decision to deviate from the optimal solution obtained by the currently used consensus models. To do this, we construct two robust two-stage optimization consensus models with uncertain costs and obtain their robust two-stage counterparts. We then apply a Benders decomposition algorithm to solve the resulting models. Finally, the experimental results show that the new models are better suited for uncertain contexts and could help DMs produce more reliable choices.},
  archive      = {J_EJOR},
  author       = {Huanhuan Li and Ying Ji and Jieyu Ding and Shaojian Qu and Huijie Zhang and Yuanming Li and Yubing Liu},
  doi          = {10.1016/j.ejor.2024.04.020},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {977-1002},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust two-stage optimization consensus models with uncertain costs},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ranking voting systems and surrogate weights: Explicit
formulas for centroid weights. <em>EJOR</em>, <em>317</em>(3), 967–976.
(<a href="https://doi.org/10.1016/j.ejor.2024.04.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most important issues in the field of ranking voting systems is the choice of the weighting vector. This issue has been addressed in the literature from different approaches, and one of them has been to obtain the weighting vector as a solution to a linear programming problem. In this paper we analyze some models proposed in the literature and show that one of their main shortcomings is that they cannot guarantee the uniqueness of the solution, so the winner or the final ranking of the candidates may depend on the chosen weighting vector. An alternative to these models is the use of surrogate weights, among which rank order centroid (ROC) weights stand out as the centroid of a specific simplex. Following this idea, in this paper we show the explicit expression for the weights that form the centroid of diverse simplices utilized in ranking voting systems, and we also see that certain surrogate weights frequently employed in literature can be derived as extreme cases where the simplices collapse into a single vector. Moreover, we argue that averaging two weighting vectors can be a valid approach in some cases and, in this way, we can get weighting vectors that closely resemble those used in some sports competitions.},
  archive      = {J_EJOR},
  author       = {Bonifacio Llamazares},
  doi          = {10.1016/j.ejor.2024.04.021},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {967-976},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Ranking voting systems and surrogate weights: Explicit formulas for centroid weights},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Electric vehicle supply equipment location and capacity
allocation for fixed-route networks. <em>EJOR</em>, <em>317</em>(3),
953–966. (<a href="https://doi.org/10.1016/j.ejor.2024.04.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric vehicle (EV) supply equipment location and allocation (EVSELCA) problems for freight vehicles are becoming more important because of the trending electrification shift. Some previous works address EV charger location and vehicle routing problems simultaneously by generating vehicle routes from scratch. Although such routes can be efficient, introducing new routes may violate practical constraints, such as drive schedules, and satisfying electrification requirements can require dramatically altering existing routes. To address the challenges in the prevailing adoption scheme, we approach the problem from a fixed-route perspective. We develop a mixed-integer linear program, a clustering approach, and a metaheuristic solution method using a genetic algorithm (GA) to solve the EVSELCA problem. The clustering approach simplifies the problem by grouping customers into clusters, while the GA generates solutions that are shown to be nearly optimal for small problem cases. A case study examines how charger costs, energy costs, the value of time (VOT), and battery capacity impact the cost of the EVSELCA. Charger equipment costs were found to be the most significant component in the objective function, leading to a substantial reduction in cost when decreased. VOT costs exhibited a significant decrease with rising energy costs. An increase in VOT resulted in a notable rise in the number of fast chargers. Longer EV ranges decrease total costs up to a certain point, beyond which the decrease in total costs is negligible.},
  archive      = {J_EJOR},
  author       = {Amir Davatgari and Taner Cokyasar and Anirudh Subramanyam and Jeffrey Larson and Abolfazl (Kouros) Mohammadian},
  doi          = {10.1016/j.ejor.2024.04.022},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {953-966},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Electric vehicle supply equipment location and capacity allocation for fixed-route networks},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Forecasting and planning for a critical infrastructure
sector during a pandemic: Empirical evidence from a food supply chain.
<em>EJOR</em>, <em>317</em>(3), 936–952. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The meat supply chain (MSC) – a key constituent of the ‘Food &amp; Agriculture’ CISA critical infrastructure sector, was among the most impacted by the COVID-19 pandemic. The witnessed successive demand and supply shocks uncovered the fragility of the MSC and revealed that more attention should be given by researchers and practitioners to ensure effective planning of such a critical infrastructure sector during periods of turbulence. To that end, in this paper we propose a two-stage approach for the planning of an MSC. In the first stage, we identify the most suitable model for predicting the demand and the supply. In the second stage, a multi-period multi-product mixed integer programming (MIP) model accounting for key MSC features is devised to deal with the planning of the MSC. Furthermore, in order to validate our theoretical proposition, a case study pertaining to a real-life MSC was used during the second and first wave of COVID-19 under different conditions. In particular, the results show that accurate demand and supply forecasting, and the recourse to rolling horizon planning approach, allow for satisfying the demand and maintaining the MSC profit in periods of turbulence, and so can be considered as levers for supply chain resilience.},
  archive      = {J_EJOR},
  author       = {Tariq Aljuneidi and Sushil Punia and Aida Jebali and Konstantinos Nikolopoulos},
  doi          = {10.1016/j.ejor.2024.04.009},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {936-952},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Forecasting and planning for a critical infrastructure sector during a pandemic: Empirical evidence from a food supply chain},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid genetic search and dynamic programming-based split
algorithm for the multi-trip time-dependent vehicle routing problem.
<em>EJOR</em>, <em>317</em>(3), 921–935. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We design a hybrid algorithm for the multi-trip time-dependent vehicle routing problem (MT-TD-VRP). One of its components is the Time-Dependent SPlit Algorithm (TD-SPA), which is a dynamic programming-based algorithm specifically designed to handle both the multi-trip per vehicle and the time-dependent aspects of the problem. The hybrid algorithm combines the proposed TD-SPA, designed to efficiently split a giant tour into complete vehicle routes, with a genetic algorithm for generating these tours. We introduce a monotone queue optimization (MQO) technique to accelerate the TD-SPA. The effectiveness of MQO is evaluated by comparing computation times between the original split algorithm for the capacitated vehicle routing problem (CVRP) and its MQO-enhanced counterpart. Extensive numerical experiments with a real-world dataset from a Singapore food and beverage company are conducted to assess our algorithm’s performance on various MT-TD-VRP instances. The results indicate that our algorithm surpasses the performance of the commercial solver Gurobi, with an average improvement of 25.13% on the best solutions found within a prescribed duration. Our numerical simulations further reveal the algorithm’s ability to efficiently solve both the capacitated vehicle routing problem (CVRP) and the multi-trip vehicle routing problem (MTVRP), consistently producing competitive solutions. Moreover, to highlight the importance of incorporating the time-dependent (TD) factor into our model and algorithm, we demonstrate a notable enhancement in performance–averaging at 7.47% for the best solutions under TD conditions for an MTVRP dataset.},
  archive      = {J_EJOR},
  author       = {Jingyi Zhao and Mark Poon and Vincent Y.F. Tan and Zhenzhen Zhang},
  doi          = {10.1016/j.ejor.2024.04.011},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {921-935},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A hybrid genetic search and dynamic programming-based split algorithm for the multi-trip time-dependent vehicle routing problem},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing service networks to support freight rail
decarbonization: Flow selection, facility location, and energy sourcing.
<em>EJOR</em>, <em>317</em>(3), 906–920. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a framework to support decarbonization of energy intensive transportation systems offering periodic service on expansive networks (e.g., freight rail, trucking, and intercity bus services). The framework consists of two optimization problems that respectivelyaddress (i) flow selection and facility location, and (ii) energy sourcing/procurement at the service facilities to enable the selected flows. The framework generalizes mixed integer linear programming formulations for flow refueling facility location and flow-based set cover models appearing in the literature to situations where it is of interest to account for repositioning of assets along cyclical trajectories to allow for periodic service, and to account for intermediate flow capture (i.e., trip chaining). The framework also consists of a minimum cost network flow model to determine optimal energy sourcing and distribution strategies, which dictate capacity requirements at the service facilities. The energy demands are obtained from the solution to the flow selection and facility location model. To illustrate the framework, we analyze the deployment of charging stations to support battery-electric locomotive service on a subset of the US freight rail network (i.e., an aggregate network of 3 Class I Railroads). The results show that the deployment of 30 charging stations can support battery-electric locomotives (with 1600-km ranges) to serve 86% of distance-weighted flows (ton-km) and reduce emissions by approximately 50%.},
  archive      = {J_EJOR},
  author       = {Adrian Hernandez and Max Ng and Pablo L. Durango-Cohen and Hani S. Mahmassani},
  doi          = {10.1016/j.ejor.2024.04.010},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {906-920},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing service networks to support freight rail decarbonization: Flow selection, facility location, and energy sourcing},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combinatorial benders decomposition for single machine
scheduling in additive manufacturing with two-dimensional packing
constraints. <em>EJOR</em>, <em>317</em>(3), 890–905. (<a
href="https://doi.org/10.1016/j.ejor.2024.05.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a single-machine scheduling problem in additive manufacturing (AM). We focus on the direct metal laser sintering (DMLS) technology of an AM process, where parts can be produced simultaneously in a batch. In this problem, we consider simultaneously the assignment of parts to batches and the packing of parts onto two-dimensional surfaces of the build chamber to minimize the makespan objective. To solve this problem, a mixed integer linear programming model is formulated, and an approximation algorithm is proposed, followed by an exact algorithm based on combinatorial Benders decomposition method with various Benders cuts and acceleration strategies (Algorithm CBD). Finally, we conduct a comprehensive computational study to verify the efficiency of our proposed Algorithm CBD. The computational results show that our proposed Algorithm CBD can effectively solve the test instances with different sizes.},
  archive      = {J_EJOR},
  author       = {Zhaofang Mao and Enyuan Fu and Dian Huang and Kan Fang and Lin Chen},
  doi          = {10.1016/j.ejor.2024.05.001},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {890-905},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Combinatorial benders decomposition for single machine scheduling in additive manufacturing with two-dimensional packing constraints},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic rebalancing optimization for bike-sharing systems: A
modeling framework and empirical comparison. <em>EJOR</em>,
<em>317</em>(3), 875–889. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Station-based Bike-sharing systems have been implemented in multiple major cities, offering a low-cost and environmentally friendly transportation alternative. As a remedy to unbalanced stations, operators typically rebalance bikes by trucks. The resulting dynamic planning has received significant attention from the Operations Research community. Due to its modeling flexibility, mixed-integer programming remains a popular choice. However, the complex planning problem requires significant simplifications to obtain a computationally tractable model. As a result, existing models have used a large variety of modeling assumptions and techniques regarding decision variables and constraints. Unfortunately, the impact of such assumptions on the solutions’ performance in practice remains generally unexplored. In this paper, we first systematically survey the literature on rebalancing problems and their modeling assumptions. We then propose a general mixed-integer programming model for multi-period rebalancing problems that can be easily adapted to different assumptions, including trip modeling, time discretization, trip distribution, and event sequences. We develop an instance generator to synthesize realistic station networks and customer trips, as well as a realistic fine-grained simulator to evaluate the operational performance of rebalancing strategies. Finally, extensive numerical experiments are carried out, both on the synthetic and real-world data, to analyze the effectiveness of various modeling assumptions and techniques. Based on our results, we identify the assumptions that empirically provide the most effective rebalancing strategies in practice. Specifically, a set of specific trip distribution constraints and event sequences ignored in the previous literature seem to provide particularly good results.},
  archive      = {J_EJOR},
  author       = {Jiaqi Liang and Sanjay Dominik Jena and Andrea Lodi},
  doi          = {10.1016/j.ejor.2024.04.037},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {875-889},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic rebalancing optimization for bike-sharing systems: A modeling framework and empirical comparison},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Benders decomposition for the discrete ordered median
problem. <em>EJOR</em>, <em>317</em>(3), 858–874. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordered median optimization has been proven to be a powerful tool to generalize many well-known problems from the literature. In Location Theory, the Discrete Ordered Median Problem ( DOMP ) is a facility location problem where clients are first ranked according to their allocation cost to the nearest open facility, and then these costs are multiplied by a suitable weight vector λ λ . That way, DOMP generalizes many well-known discrete location problems including p p -median, p p -center or centdian. In this article, we also allow negative entries of λ λ , allowing us to derive models for better addressing equity and fairness in facility location, for modeling obnoxious facility location problems or for including other client preference models. We present new mixed integer programming models for DOMP along with algorithmic enhancements for solving the DOMP to optimality using mixed integer programming techniques. Specifically, starting from state-of-the-art formulations from the literature, we present several Benders decomposition reformulations applied to them. Using these approaches, new state-of-the-art results have been obtained for different ordered weighting vectors.},
  archive      = {J_EJOR},
  author       = {Ivana Ljubić and Miguel A. Pozo and Justo Puerto and Alberto Torrejón},
  doi          = {10.1016/j.ejor.2024.04.030},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {858-874},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Benders decomposition for the discrete ordered median problem},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Literature survey on the container stowage planning problem.
<em>EJOR</em>, <em>317</em>(3), 841–857. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Container shipping drives the global economy and is an eco-friendly mode of transportation. A key objective is to maximize the utilization of vessels, which is challenging due to the NP-hardness of stowage planning. This article surveys the literature on the Container Stowage Planning Problem (CSPP). We introduce a classification scheme to analyze single-port and multi-port CSPPs, as well as the hierarchical decomposition of CSPPs into the master and slot planning problem. Our survey shows that the area has a relatively small number of publications and that it is hard to evaluate the industrial applicability of many of the proposed solution methods due to the oversimplification of problem formulations. To address this issue, we propose a research agenda with directions for future work, including establishing a representative problem definition and providing new benchmark instances where needed.},
  archive      = {J_EJOR},
  author       = {Jaike van Twiller and Agnieszka Sivertsen and Dario Pacino and Rune Møller Jensen},
  doi          = {10.1016/j.ejor.2023.12.018},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {841-857},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Literature survey on the container stowage planning problem},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using public transport in a 2-echelon last-mile delivery
network. <em>EJOR</em>, <em>317</em>(3), 827–840. (<a
href="https://doi.org/10.1016/j.ejor.2022.10.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the integration of public transport services into last-mile delivery networks. The free capacity of an already established public transport system that operates according to a given timetable on predetermined lines is used to carry goods from outside of the city into the city center. Dedicated bus or tram stations of the public transport network serve as satellites. From these satellites, city freighters pick up the goods and deliver them to the final customers. The main contribution is an extensive computational study, in which we consider various scenarios of the shared part of the public transport network and investigate different hierarchical objectives minimizing two of the three key indicators (number of city freighters, routing costs, and number of trips). We quantify the tradeoff between the key indicators for different objectives and the impact of limiting the capacity of public transport vehicles on two instance sets with different demand distributions. The key instrument to conduct all these experiments are effective exact and heuristic branch-price-and-cut algorithms that we develop and evaluate in detail.},
  archive      = {J_EJOR},
  author       = {Jeanette Schmidt and Christian Tilk and Stefan Irnich},
  doi          = {10.1016/j.ejor.2022.10.041},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {827-840},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Using public transport in a 2-echelon last-mile delivery network},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Electric van-based robot deliveries with en-route charging.
<em>EJOR</em>, <em>317</em>(3), 806–826. (<a
href="https://doi.org/10.1016/j.ejor.2022.06.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a two-echelon electric van-based robot delivery system with en-route charging for last-mile delivery in logistics operations. Each of the vans is equipped with a single robot, and the robots can visit areas with van access restrictions, such as pedestrianized areas or university campuses. The time during which electric vans are carrying robots can be used to recharge the robots, thereby increasing the efficiency of the distribution system. To model the proposed system, we present a mixed integer program. We note that the energy transfer from a van to its robot needs time and will cause the available travel distance of a van to decrease and that of a robot to increase. Focusing on the new time-distance-energy trade-off problem, which increases the difficulty checking the feasibility of any given route, we further propose a greedy route evaluation approach and a linear programming-based route evaluation method. An adaptive large neighborhood search algorithm is presented for solving larger instances. A sensitivity analysis for vehicle charging modes, charging rates, and maximum battery capacities shows that using en-route charging, while appropriately increasing battery level and charging rate can have useful effects on cost.},
  archive      = {J_EJOR},
  author       = {Shaohua Yu and Jakob Puchinger and Shudong Sun},
  doi          = {10.1016/j.ejor.2022.06.056},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {806-826},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Electric van-based robot deliveries with en-route charging},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Public acceptance of crowdsourced delivery from a customer
perspective. <em>EJOR</em>, <em>317</em>(3), 793–805. (<a
href="https://doi.org/10.1016/j.ejor.2023.03.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goals of crowdsourced delivery are to enable customers to be served efficiently and flexibly by occasional deliverymen. It could also be considered pro-social behavior by utilizing available human resources as deliverymen. The successful implementation of crowdsourced delivery highly depends on customers&#39; willingness to adopt the crowdsourced delivery service considering its characteristics. This study develops a novel theoretical acceptance model of crowdsourced delivery service, integrating the technology acceptance model and norm activation model with the considerations of trust, social influence, and loss of privacy. The proposed model is tested based on the empirical data captured by a cross-sectional survey administered to 2333 participants in China through partial least squares structural equation modeling. Multiple group analyses are conducted to test whether the results were different or identical among various factors. The results indicate the proposed acceptance model interprets 84.5% of the variance in the behavioral intention of using the crowdsourced delivery service. The influences of predictors from the technology acceptance model are greater than those of predictors from the norm activation model, while social influence and trust are revealed to contribute most to explaining whether customers would accept crowdsourced delivery services. In contrast, loss of privacy negatively affects behavioral intention. Age, usage experience, and experience of being occasional deliverymen also moderate the path coefficients between antecedent factors and behavioral intention to use crowdsourced delivery services. We also provide theoretical findings and practical suggestions for developing crowdsourced delivery services based on the results and our analysis.},
  archive      = {J_EJOR},
  author       = {Yi-Jia Wang and Yue Wang and George Q. Huang and Ciyun Lin},
  doi          = {10.1016/j.ejor.2023.03.028},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {793-805},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Public acceptance of crowdsourced delivery from a customer perspective},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The effect of increasing vehicle utilization on the
automotive industry. <em>EJOR</em>, <em>317</em>(3), 776–792. (<a
href="https://doi.org/10.1016/j.ejor.2022.10.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shared mobility is widely expected to play an important role in the future of transportation. Sharing vehicles (using services such as ride-hailing, peer-to-peer car-sharing, and autonomous taxis) will allow people to enjoy the benefits of automobile use without ownership, access various types of mobility services on-demand, and create value by increasing the utilization of these expensive and durable assets. Most analysts agree that widespread adoption of shared mobility would cause the size of the on-road automobile fleet to shrink, potentially dramatically, because the same amount of personal mobility can be provided by fewer vehicles. There is less agreement, however, on the effect higher utilization will have on the rate of new vehicle sales: some believe that vehicle sales will fall similarly, while others believe there will be no change in sales, or even an increase in sales as fleets of shared vehicles turn over more frequently. In this paper, we seek to clarify the effect that emerging mobility technologies will have on the future rate of new vehicle sales in the United States, modeling how the sales rate varies with factors such as population growth, vehicle utilization, and vehicle durability. We show across a range of plausible scenarios that vehicle sales are likely to remain steady or increase in coming decades. However, the potential exists for a temporary surge or dip in sales as the composition of new vehicle sales transitions, requiring effective mental models if managers are to make efficient production and capacity planning decisions during this time.},
  archive      = {J_EJOR},
  author       = {David R. Keith and Sergey Naumov and Hannah E. Rakoff and Lars Meyer Sanches and Anuraag Singh},
  doi          = {10.1016/j.ejor.2022.10.030},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {776-792},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The effect of increasing vehicle utilization on the automotive industry},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A column generation heuristic for the dynamic bicycle
rebalancing problem. <em>EJOR</em>, <em>317</em>(3), 762–775. (<a
href="https://doi.org/10.1016/j.ejor.2022.07.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public bicycle sharing systems are becoming an essential part of the future urban mobility system. Real-time monitoring of the system state through sensors on bicycles and/or stations gives possibilities for advanced coordination of the system. In this paper, we consider the dynamic bicycle rebalancing problem, where bicycles are re-positioned by service vehicles to prevent stations from becoming completely full or empty, and so satisfying the demand for bicycles or locks. We solve the problem in a rolling horizon fashion with dynamic deterministic bicycle rebalancing subproblems (DDBRS) at the decision epochs. To solve the DDBRS within a few seconds in real-time, we propose a novel column generation heuristic (CGH). The CGH is tested within a simulation framework based on real data from the bicycle sharing system in Oslo. We show that the CGH is able to solve large real-life instances with computational times that are suitable for actual operation and that it provides significantly improved solutions compared with current planning practice. We also perform a number of tests to analyze the effect of changing the number of bicycles and locks in the system, as well as adding extra service vehicles. The case company is now making preparations to implement an optimization-based decision support system based on the CGH proposed in this paper.},
  archive      = {J_EJOR},
  author       = {Marte D. Gleditsch and Kristine Hagen and Henrik Andersson and Steffen J. Bakker and Kjetil Fagerholt},
  doi          = {10.1016/j.ejor.2022.07.004},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {762-775},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A column generation heuristic for the dynamic bicycle rebalancing problem},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Let the fast passengers wait: Boarding an airplane takes
shorter time when passengers with the most bin luggage enter first.
<em>EJOR</em>, <em>317</em>(3), 748–761. (<a
href="https://doi.org/10.1016/j.ejor.2022.12.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Airlines usually organize the passenger queue by letting certain groups of passengers enter the airplane in a specific order. The total boarding time of such airplane boarding policies can be estimated and compared by a Lorentzian metric based on the one used in Einstein’s theory of relativity. The metric accounts for aisle-clearing times that depend on the passengers’ queue positions, in particular when passengers in the back of the queue with increasing probability will have to wait for already seated aisle or middle seat passengers to rise up and let the others pass to a seat closer to the window. We provide closed-form expressions for the asymptotic total boarding time when the number of passengers is large, and prove that the best queue ordering with low congestion is according to decreasing luggage-handling time. The effect of seat interference amplifies the previously shown superiority of slow first vs. random boarding and fast first. That this ranking of policies also holds for realistic congestion is illustrated by both analytical methods and simulations, and parameters are taken from empirical data. However, the result is non-trivial, as the ranking shifts for unrealistically high congestion. Based on the analytical results, we demonstrate that the slow-first policy can be improved by dividing the passengers into more than two groups based on their number of bin luggage items, and let the slowest groups with the most luggage items enter the queue first.},
  archive      = {J_EJOR},
  author       = {Sveinung Erland and Eitan Bachmat and Albert Steiner},
  doi          = {10.1016/j.ejor.2022.12.027},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {748-761},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Let the fast passengers wait: Boarding an airplane takes shorter time when passengers with the most bin luggage enter first},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Truthful online double auctions for on-demand integrated
ride-sourcing platforms. <em>EJOR</em>, <em>317</em>(3), 737–747. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrated platforms are an emerging model of business that integrates ride-sourcing services provided by multiple companies on a single platform. It reduces market fragmentation and brings benefits to both travelers and participating independent transport service providers. To ensure the sustainability of such platforms, the main challenge lies in efficient matching between travelers and ride-sourcing companies, so that both sides obtain non-negative utility. In this study, we propose a double auction based framework to solve the matching and pricing problems for on-demand integrated ride-sourcing platforms. To solve the real-time matching problem, we develop two online mechanisms with a critical price dynamic updating algorithm and a greedy algorithm. The proposed mechanisms are guaranteed to achieve the desired economic properties, and their efficiency is evaluated through numerical studies.},
  archive      = {J_EJOR},
  author       = {Xiaoshu Ding and Qi Qi and Sisi Jian},
  doi          = {10.1016/j.ejor.2023.12.004},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {737-747},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Truthful online double auctions for on-demand integrated ride-sourcing platforms},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Single-leader multi-follower games for the regulation of
two-sided mobility-as-a-service markets. <em>EJOR</em>, <em>317</em>(3),
718–736. (<a href="https://doi.org/10.1016/j.ejor.2022.06.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobility-as-a-Service (MaaS) is an emerging business model in transportation enabled through mobile internet technologies. A MaaS platform can be viewed as a two-sided market, where travelers and transportation service providers (TSPs) are two groups of interacting agents. We propose an optimization framework for the regulation of two-sided MaaS markets. We cast this problem as a single-leader multi-follower game (SLMFG) where the leader is the MaaS regulator and two groups of follower problems represent the travelers and the TSPs. The MaaS regulator aims to maximize its profits by optimizing service prices and resource allocation. In response, travelers (resp. TSPs) adjust their participation level in the MaaS platform to minimize their travel costs (resp. maximize their profits). We analyze network effects in the MaaS market and formulate SLMFGs without/with network effects leading to mixed-integer linear/quadratic bilevel programming problems. We propose single-level reformulations based on mathematical programming with equilibrium constraints (MPECs) and prove the equivalence between the solutions obtained using the MPECs and the original bilevel problems. Customized branch-and-bound algorithms based on strong duality reformulations are developed to solve these MPECs. Extensive numerical experiments conducted on large-scale instances generated from realistic mobility data highlight the performance of the proposed algorithms relative to a benchmarking approach, and provide meaningful managerial insights for the regulation of two-sided MaaS markets.},
  archive      = {J_EJOR},
  author       = {Haoning Xi and Didier Aussel and Wei Liu and S.Travis. Waller and David Rey},
  doi          = {10.1016/j.ejor.2022.06.041},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {718-736},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Single-leader multi-follower games for the regulation of two-sided mobility-as-a-service markets},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Instance generation tool for on-demand transportation
problems. <em>EJOR</em>, <em>317</em>(3), 696–717. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present REQreate, a tool to generate instances for on-demand transportation problems. Such problems consist of optimizing vehicle routes according to passengers’ demand for transportation under space and time restrictions (called requests). REQreate is flexible and can be configured to generate instances for a variety of problems types in this problem class. In this paper, we exemplify this with the Dial-a-Ride Problem (DARP) and On-demand Bus Routing Problem (ODBRP). In most of the literature, researchers either test their solution algorithms with instances based on artificial networks or they perform real-life case studies on instances derived from a specific city or region. Furthermore, locations of requests for on-demand transportation problems are mostly randomly chosen according to a uniform distribution, rather than being derived from actual data. The aim of REQreate is to overcome any shortcomings from synthetic or specific instances. Rather than relying on artificial or limited data, we retrieve real-world street networks from OpenStreetMaps (OSM). To the best of our knowledge, this is the first tool to make use of real-life networks to generate instances for an extensive catalog of existing and upcoming on-demand transportation problems. Additionally, we present a simple method that can be embedded in the instance generation process to produce distinct urban mobility patterns. We perform an analysis with real-life data sets reported by rideshare companies and compare them with properties of synthetic instances generated with REQreate. Another contribution of this work is the introduction of the concept of instance similarity that serves as support to create a set of diverse instances, in addition to properties (size, dynamism, urgency, and geographic dispersion) that can be used to comprehend which characteristics of the problem instances have an impact on the performance quality (or efficiency) of a solution algorithm.},
  archive      = {J_EJOR},
  author       = {Michell Queiroz and Flavien Lucas and Kenneth Sörensen},
  doi          = {10.1016/j.ejor.2024.03.006},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {696-717},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Instance generation tool for on-demand transportation problems},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis of cost-efficient urban air mobility systems:
Optimization of operational and configurational fleet decisions.
<em>EJOR</em>, <em>317</em>(3), 678–695. (<a
href="https://doi.org/10.1016/j.ejor.2023.04.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the introduction of low-noise and low-emission electric vertical take-off and landing vehicles, passenger air transportation in urban areas is becoming increasingly important. Previous studies have designed vehicle concepts based on reference mission profiles, however, without considering strategic decisions about fleet operations, such as charging infrastructure, range and battery capacity. Comprehensive cost analyses for urban air mobility fleets have been largely neglected. In this paper, we develop an optimization model to analyze the cost-efficient operation of urban air mobility systems. Strategic decisions on vehicle concepts, battery capacity, and charging infrastructure are incorporated and evaluated using a total cost of ownership approach. We consider state-of-the-art modeling approaches, including vehicle-specific parameters, for accurate calculation of energy consumption. The optimization model is applied to the multi-agent transport simulation MATSim in a case study of the Ruhr (Germany) scenario to evaluate key parameter variations. The study results indicate the feasibility of an urban air mobility system in the study region with trip costs ranging from 27 US-$ to 46 US-$ per requested trip, depending on the scenario settings. Based on parameter variations, we find that a high cruising speed has a detrimental effect on the total cost. A medium charging power level is sufficient and energy costs account for only a moderate share. The latter is in contrast to previous research results, but can be attributed to the more detailed modeling approach of vehicle-specific parameters. We propose a cost incentive system as the ground handling time of the vehicles outweighs the recharging and flight time. The overall results provide a promising basis for model extensions.},
  archive      = {J_EJOR},
  author       = {Michael Husemann and Ansgar Kirste and Eike Stumpf},
  doi          = {10.1016/j.ejor.2023.04.040},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {678-695},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Analysis of cost-efficient urban air mobility systems: Optimization of operational and configurational fleet decisions},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Regulating the rebound effect in the traveling purchaser
problem. <em>EJOR</em>, <em>317</em>(3), 660–677. (<a
href="https://doi.org/10.1016/j.ejor.2022.06.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite engineers’ best intentions, technological innovations intended to reduce resource consumption are not assured to achieve their desired effects. As self-interested agents utilize the technological innovation, theretofore unprofitable activities may be rendered profitable, leading to a disparity between the expected reduction in resource consumption and what is actually achieved. This rebound effect is particularly salient given the current global climate crisis. In practice, many national governments are promoting fuel efficiency gains via new, cutting-edge technologies. However, to maximize the effectiveness of such technological innovations, additional regulation is likely required to avoid unfavorable rebound effects. To further study the dynamics of this setting, we set forth a logistics-based Stackelberg game underpinned by the Traveling Purchaser Problem. More specifically, we develop a bilevel programming formulation wherein the upper-level player is a regulator and the lower-level player is the purchaser. The regulator encounters a multi-objective problem and desires to reduce resource consumption while minimally disrupting commerce on the network. Mathematical conditions are derived and proved to determine when the null regulator action is optimal. These results are leveraged to develop a preprocessing algorithm and customized heuristic solution methodology. Extensive empirical testing is conducted on these methods and their results are analyzed using statistical techniques to quantitatively characterize their behavior. Analysis confirms the supposition that regulation and technological innovations are often required in tandem to achieve a regulator’s aims; however, it also reveals that, under select conditions, the regulator is better served by not intervening.},
  archive      = {J_EJOR},
  author       = {William N. Caballero and Brian J. Lunday and Finn Meissner},
  doi          = {10.1016/j.ejor.2022.06.045},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {660-677},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Regulating the rebound effect in the traveling purchaser problem},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A method for evaluating accessibility in transportation
problems considering social vulnerability. <em>EJOR</em>,
<em>317</em>(3), 646–659. (<a
href="https://doi.org/10.1016/j.ejor.2023.04.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a methodological approach for evaluating transportation-based access via the public roadway network referred to as edge accessibility , which is derived from the graph theory measure of closeness. EA evaluates each edge in the roadway network based on its system-wide contribution in facilitating access between all origin-destination (OD) pairs in the roadway network and includes an edge disruption component in the calculation. The measure also includes an importance weighting approach that can be applied to both origins and destinations to addresses concerns related to equity and criticality and can be readily incorporated into existing transportation planning models. The measure is demonstrated via a case study that examines food accessibility by socially vulnerable populations in a rural setting to support the expansion of a fixed-route public transit service. As part of the case study, we use a statewide network of all public roadways in a GIS-based transportation planning platform called TransCAD™, a customizable off-the-shelf software for transportation network applications.},
  archive      = {J_EJOR},
  author       = {James L. Sullivan and David C. Novak},
  doi          = {10.1016/j.ejor.2023.04.015},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {646-659},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A method for evaluating accessibility in transportation problems considering social vulnerability},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The future of transport: Coordination in a new field between
public and private transport. <em>EJOR</em>, <em>317</em>(3), 643–645.
(<a href="https://doi.org/10.1016/j.ejor.2024.05.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Hillel Bar-Gera and Marco Bijvank and Florian Jaehn and Simone Neumann and Sandra Transchel},
  doi          = {10.1016/j.ejor.2024.05.008},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {3},
  pages        = {643-645},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The future of transport: Coordination in a new field between public and private transport},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal energy collection with rotational movement
constraints in concentrated solar power plants. <em>EJOR</em>,
<em>317</em>(2), 631–642. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In concentrated solar power (CSP) plants based on parabolic trough collectors (PTC), the sun is tracked at discrete time intervals, with each interval representing a movement of the collector system. The act of moving heavy mechanical structures can lead to the development of cracks, bending, and/or displacement of components from their optimal optical positions. This, in turn, diminishes the overall energy capture performance of the entire system. In this context, we introduce two combinatorial optimization problems of great interest to PTC plants. The minimum tracking motion (MTM) problem is aimed at detecting the minimum number of movements needed while maintaining production within a given range. The maximal energy collection (MEC) problem seeks to achieve optimal energy production within a predetermined number of movements. Both problems are solved assuming scenarios where the energy collection function contains any number of local maximums/minimums due to optical errors of the elements in the PTC system. The MTM and MEC problems are solved in O ( n ) O(n) time and O ( n 2 m ω ∗ ) O(n2mω∗) time respectively, where n n is the number of steps in the energy collection function, m m the maximum number of movements of the solar structure, and ω ∗ ω∗ the maximal amplitude angle that the structure can cover. The advantages of the solutions are shown in realistic experiments. While these problems can be solved in polynomial time, we establish the NP-hardness of a slightly modified version of the MEC problem. The proposed algorithms are generic and can be adapted to schedule solar tracking in other CSP systems.},
  archive      = {J_EJOR},
  author       = {José-Miguel Díaz-Báñez and José-Manuel Higes-López and Miguel-Angel Pérez-Cutiño and Juan Valverde},
  doi          = {10.1016/j.ejor.2024.04.027},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {631-642},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal energy collection with rotational movement constraints in concentrated solar power plants},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient solver for large-scale onshore wind farm siting
including cable routing. <em>EJOR</em>, <em>317</em>(2), 616–630. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing planning approaches for onshore wind farm siting and grid integration often do not meet minimum cost solutions or social and environmental considerations. In this paper, we develop an exact approach for the integrated layout and cable routing problem of onshore wind farm planning using the Quota Steiner tree problem. Applying a novel transformation on a known directed cut formulation, reduction techniques, and heuristics, we design an exact solver that makes large problem instances solvable and outperforms generic MIP solvers. In selected regions of Germany, the trade-offs between minimizing costs and landscape impact of onshore wind farm siting are investigated. Although our case studies show large trade-offs between the objective criteria of cost and landscape impact, small burdens on one criterion can significantly improve the other criteria. In addition, we demonstrate that contrary to many approaches for exclusive turbine siting, grid integration must be simultaneously optimized to avoid excessive costs or landscape impacts in the course of a wind farm project. Our novel problem formulation and the developed solver can assist planners in decision-making and help optimize wind farms in large regions in the future.},
  archive      = {J_EJOR},
  author       = {Jaap Pedersen and Jann Michael Weinand and Chloi Syranidou and Daniel Rehfeldt},
  doi          = {10.1016/j.ejor.2024.04.026},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {616-630},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An efficient solver for large-scale onshore wind farm siting including cable routing},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inventory reallocation in a fashion retail network: A
matheuristic approach. <em>EJOR</em>, <em>317</em>(2), 603–615. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a fashion retail network consisting of a central warehouse, owned by a fashion firm, and a fairly large number of retail stores. Some stores are owned by the firm itself, whereas others are owned by franchisees. An initial inventory allocation decision is made at the beginning of the selling season and is periodically revised. Inventory reallocation comprises both direct shipments from the warehouse to stores and lateral shipments among the stores. Besides stock availability and shipping costs, a suitable reallocation policy must take into account the probability of selling each item, some operational constraints, as well as other preference factors that define the utility of shipping an item from a node of the network to another one. Since the problem does not lend itself to the application of typical tools from inventory theory, we propose an optimization model that complements such tools. The model, given the number of nodes and SKUs, may involve about one million binary variables, and just solving the LP relaxation may take hours using state-of-the-art software. Since typical metaheuristics for combinatorial optimization do not seem a viable alternative, we propose a matheuristic approach, in which a sequence of maximum-weight matching problems is solved in order to reduce the problem and restrict the set of potential shipping pairs, with a corresponding drop in the number of decision variables. Computational results obtained on a set of real-life problem instances are discussed, showing the viability of the proposed algorithm.},
  archive      = {J_EJOR},
  author       = {Paolo Brandimarte and Giuseppe Craparotta and Elena Marocco},
  doi          = {10.1016/j.ejor.2024.04.016},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {603-615},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Inventory reallocation in a fashion retail network: A matheuristic approach},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On cone-based decompositions of proper pareto-optimality in
multi-objective optimization. <em>EJOR</em>, <em>317</em>(2), 592–602.
(<a href="https://doi.org/10.1016/j.ejor.2024.04.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, research focus in multi-objective optimization has shifted from approximating the Pareto optimal front in its entirety to identifying solutions that are well-balanced among their objectives. Proper Pareto optimality is an established concept for eliminating Pareto optimal solutions that exhibit unbounded tradeoffs. Imposing a strict tradeoff bound in a classical definition of proper Pareto optimality allows specifying how many units of one objective one is willing to trade in for obtaining one unit of another objective. Recent studies have shown that this notion shows favorable convergence properties. One of the aims of this paper is to translate the proper Pareto optimality notion to an ordering relation, which we denote by M-domination . The mathematical properties of M-domination are thoroughly analyzed in this paper yielding key insights into its applicability as decision making aid and in designing population-based algorithms for solving multi-objective optimization problems. We complement our work by providing four different geometrical descriptions of the M-dominated space given by a union of polyhedral cones. A geometrical description does not only yield a greater understanding of the underlying tradeoff concept, but also allows a quantification of the hypervolume dominated by a particular solution or an entire set of solutions. These descriptions shall enable researchers to formulate hypervolume-based approaches for finding approximations of the Pareto front that emphasize regions that are well-balanced among their tradeoffs in subsequent works.},
  archive      = {J_EJOR},
  author       = {Marlon Braun and Pradyumn Shukla},
  doi          = {10.1016/j.ejor.2024.04.019},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {592-602},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On cone-based decompositions of proper pareto-optimality in multi-objective optimization},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Repositioning to sink: The pricing and quality decisions for
product line considering the sinking market. <em>EJOR</em>,
<em>317</em>(2), 578–591. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Opening up new markets (e.g., the sinking market) is one way to boost growth momentum, especially with the decrease in the rate of technological development and the impact of the black swan event (e.g., the COVID-19 pandemic). Considering the difficulty and cost of developing new products, repositioning existing products by a price markdown is an easier way to expand the market. Companies can implement different pricing strategies for different products to target different markets and make extra profits, but products entering the sinking market may deeply erode the original market. Therefore, balancing the advantages and disadvantages of entering the sinking market is a significant challenge for firms selling products as a product line. By building a theoretical model, we investigate the optimal product line repositioning strategy when companies decide to expand the market. First, we examine the optimal conditions for companies to enter a sinking market. We then analyze the optimal product line strategy in the sinking market. Furthermore, we investigate the interaction between repositioning strategy and quality decisions. The main results indicate that with the increase of the consumers’ willingness to pay at the sinking market and the decrease of the production cost, the seller&#39;s motivation to enter the sinking market would be greater. More importantly, entering the sinking market with higher quality can also be the optimal decision. What&#39;s more, we also find that the seller implementing low-quality repositioning strategy may prefer fiercer product erosion. Interestingly, the consideration of the quality decision would motivate the seller to enter the sinking market more aggressively even when the production cost is relatively high. Yet, this motivation would be weakened when the production cost is relatively low.},
  archive      = {J_EJOR},
  author       = {Yusheng Wang and Yongjian Li and Shuangshuang Xu},
  doi          = {10.1016/j.ejor.2024.04.012},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {578-591},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Repositioning to sink: The pricing and quality decisions for product line considering the sinking market},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Individualized second stage corrections in data envelopment
analysis. <em>EJOR</em>, <em>317</em>(2), 563–577. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of two-stage data envelopment analysis (DEA) for efficiency correction, we shift the focus from the common central tendency orientation in its second stage to an individually oriented procedure. We propose to evaluate the influence of contextual variables on each unit&#39;s performance relative to the other operating units. This results in an alternative approach in which the second stage inherits the principal property of DEA in the first stage of putting each individual unit in its best possible light. We demonstrate the applicability of our approach using data from the energy sector in the domain of incentive regulation, where operators are natural monopolies. In such systems of incentives, ensuring fair performance evaluations is crucial, given the influence of contextual variables beyond management control. Our approach contributes to efficiency correction procedures under these circumstances. The results not only encourage operators to economize costs and improve service quality but also motivate them to, for example, minimize environmental impact of operations, adopt eco-friendly technologies, and invest in renewable energy sources.},
  archive      = {J_EJOR},
  author       = {Mohsen Afsharian and Sara Kamali and Heinz Ahn and Peter Bogetoft},
  doi          = {10.1016/j.ejor.2024.04.008},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {563-577},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Individualized second stage corrections in data envelopment analysis},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An exact method for a last-mile delivery routing problem
with multiple deliverymen. <em>EJOR</em>, <em>317</em>(2), 550–562. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for efficient last-mile delivery systems in large cities creates an opportunity to develop innovative logistics schemes. In this paper, we study a problem in which each vehicle may travel with more than one deliveryman to serve multiple customers with a single stop of the vehicle, increasing the delivery efficiency. We extend the vehicle routing problem with time windows and multiple deliverymen by explicitly considering the deliveryman routes. We introduce the problem, formally define it with a formulation, propose valid inequalities, and develop a tailored branch-and-Benders-cut (BBC) algorithm to solve it. The BBC is capable of solving 89% of the instances to proven optimality in reasonable times, many of them of realistic sizes. Additionally, we show the benefits of evaluating the deliveryman routes considering a cost minimization perspective, and discuss relevant solutions for urban logistics problems that can help decrease congestion and emissions.},
  archive      = {J_EJOR},
  author       = {Fernando Senna and Leandro C. Coelho and Reinaldo Morabito and Pedro Munari},
  doi          = {10.1016/j.ejor.2024.04.007},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {550-562},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An exact method for a last-mile delivery routing problem with multiple deliverymen},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Supply chain coordination in a dual sourcing system under
the tailored base-surge policy. <em>EJOR</em>, <em>317</em>(2), 533–549.
(<a href="https://doi.org/10.1016/j.ejor.2024.03.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the coordination of a dual sourcing supply chain comprising a buyer and two suppliers: a regular and an expedited one. The suppliers differ in lead time and cost, with the expedited supplier offering a shorter lead time at a higher cost than the regular supplier. The buyer uses the Tailored Base-Surge inventory policy, ordering every period a fixed quantity from the regular supplier and using the expedited supplier to meet any excess demand. We employ a novel perspective by assuming that each of the three firms is an independent party optimizing its profit function. We consider two scenarios: in the first scenario, the expedited supplier acts as a spot market, resulting in a two-players game between the buyer and regular supplier. The second scenario considers a three-players game. We derive the conditions for coordination for both scenarios, which we refer to as single and double coordination, and explore the impact of various parameters on the games and coordination. Our findings reveal that in the two-players scenario, regular orders increase with the spot market price, with a greater increase under coordination. Meanwhile, in the three-players scenario, equilibrium can only be sustained by increasing the order quantity from the expedited supplier in case its sourcing cost increases. Moreover, the regular supplier has an incentive to raise its price, whereas the expedited supplier charges a fixed price to the buyer. However, coordination results in the buyer placing fewer expedited orders. We demonstrate that the regular supplier sets its price just below the expedited supplier’s price. In contrast, the expedited supplier acts more aggressively in setting its price to either eliminate the regular supplier or charge the maximum possible price.},
  archive      = {J_EJOR},
  author       = {Kilani Ghoudi and Younes Hamdouch and Youssef Boulaksil and Sadeque Hamdan},
  doi          = {10.1016/j.ejor.2024.03.038},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {533-549},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Supply chain coordination in a dual sourcing system under the tailored base-surge policy},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Platform financing versus bank financing: “When to choose
which” for green production systems. <em>EJOR</em>, <em>317</em>(2),
515–532. (<a href="https://doi.org/10.1016/j.ejor.2024.03.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread implementation of the carbon trading system, carbon permits are used as pledged assets for manufacturers to obtain extra financing due to the asset attributes of carbon permits. We consider a supply chain where a manufacturer with limited capital sells goods via a platform employing the agency mode. The manufacturer obtains finance either from a bank or the platform. Facing a carbon trading system, remanufacturing or green technology is used by the manufacturer to cut down carbon emissions. We analytically derive the following research conclusions via conducting a Stackelberg game analysis: First, the optimal interest rates with remanufacturing and green technology in two financing modes decrease with the correlation coefficient between the potential market size and the price of carbon permits (CMC), and the initial emissions intensity. Second, with remanufacturing, the manufacturer adopts bank financing if CMC is polarized (i.e., low or high); otherwise, it adopts platform financing. However, with green technology, the manufacturer should adopt platform (bank) financing if CMC is low (high). Third, in the platform financing mode, the manufacturer should switch to remanufacturing (green technology) if the green consciousness is low (high). In the bank financing mode, the manufacturer should turn to remanufacturing (green technology) if CMC is high (low). In addition, we explore the scenario where the collection rate is endogenous. This paper reveals the role played by many critical factors such as CMC in affecting the optimal financing model in green manufacturing.},
  archive      = {J_EJOR},
  author       = {Xiaoping Xu and Xinyang Chen and Tsan-Ming Choi and T.C.E. Cheng},
  doi          = {10.1016/j.ejor.2024.03.014},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {515-532},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Platform financing versus bank financing: “When to choose which” for green production systems},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An accelerated benders decomposition algorithm for the
solution of the multi-trip time-dependent vehicle routing problem with
time windows. <em>EJOR</em>, <em>317</em>(2), 500–514. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The logistics companies executing the last mile delivery of goods in urban areas deal every day with the problem of routing their vehicles, while taking into account multiple trips per vehicle, time-dependent travel time, customers’ time windows and loading time at the depot simultaneously. This paper addresses this problem, known as Multi-Trip Time-Dependent Vehicle Routing Problem with Time Windows, aiming at its exact solution, minimizing the total travelled distance of a company&#39;s fleet. Based on a literature model, a new reformulation with reduced size is suggested. This reformulation is decomposed by applying the Benders method in an effective way, resulting in a subproblem with no duality gap. By exploiting the special features of the problem and the particular structure of the decomposition made, several novel valid inequalities are introduced, in order to both tighten the non-decomposed formulations and warm start the relaxed master problem to achieve less infeasible solutions and higher lower bounds. For the solution of the problem, an innovative algorithm is proposed, including suboptimal master solutions and a multi-cut generation procedure, which is based on the careful observation of the values of the Benders dual subproblem variables. The impact of the valid inequalities as well as two variants of the suggested algorithm are tested on benchmark data and they are compared with the non-decomposed models and a heuristic introduced in the literature. The computational results indicate improved efficiency and stronger bounds for the proposed algorithm.},
  archive      = {J_EJOR},
  author       = {Antonios Fragkogios and Yuzhuo Qiu and Georgios K.D. Saharidis and Panos M. Pardalos},
  doi          = {10.1016/j.ejor.2024.04.013},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {500-514},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An accelerated benders decomposition algorithm for the solution of the multi-trip time-dependent vehicle routing problem with time windows},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A generic approach to conference scheduling with integer
programming. <em>EJOR</em>, <em>317</em>(2), 487–499. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conferences are a key aspect of communicating knowledge, and their schedule plays a vital role in meeting the expectations of participants. Given that many conferences have different constraints and objectives, different mathematical models and heuristic methods have been designed to address rather specific requirements of the conferences being studied per se. We present a penalty system that allows organisers to set up scheduling preferences for tracks and submissions regarding sessions and rooms, and regarding the utilisation of rooms within sessions. In addition, we also consider hybrid and online conferences where submissions need to be scheduled in appropriate sessions based on timezone information. A generic scheduling tool is presented that schedules tracks into sessions and rooms, and submissions into sessions by minimising the penalties subject to certain hard constraints. Two integer programming models are presented: an exact model and an extended model. Both models were tested on five real instances and on two artificial instances which required the scheduling of several hundreds of time slots. The results showed that the exact model achieved optimal solutions for all instances except for one instance which resulted in 0.001% optimality gap, and the extended model handles more complex and additional constraints for some instances. Overall, this work demonstrates the suitability of the proposed generic approach to optimise schedules for in-person, hybrid, and online conferences.},
  archive      = {J_EJOR},
  author       = {Yaroslav Pylyavskyy and Peter Jacko and Ahmed Kheiri},
  doi          = {10.1016/j.ejor.2024.04.001},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {487-499},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A generic approach to conference scheduling with integer programming},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Home chemotherapy delivery: An integrated production
scheduling and multi-trip vehicle routing problem. <em>EJOR</em>,
<em>317</em>(2), 468–486. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Home chemotherapy systems allow the administration of cancer treatments at a patient’s residence, avoiding an admission to inpatient care facilities. This innovative health care model is interesting both economically and on a human level. It also raises several logistical challenges. This paper focuses on one of the optimization problems arising in the context of home chemotherapy services, where a complex scheduling problem underlies the operational planning process. Indeed, some injectable chemotherapy drugs may remain stable only during a few hours after being produced. Consequently, their production has to be carefully scheduled jointly with their administration, which takes place at the patients homes during a predefined time window. This gives rise to an integrated production scheduling and vehicle routing problem, that we address using a large neighborhood search approach. Production and administration sequences are iteratively modified, while a linear program is used to determine optimal production and administration start times for the candidate sequences. We analyze the impact of the linear program and establish that it is a crucial component of the proposed method. We assess the performance of the proposed method by comparing its solutions with those obtained through a compact mathematical formulation. We then provide insights about the cost of taking into consideration time-related aspects of the problem, i.e. , integrated planning horizons, drug stability times, and administration time windows.},
  archive      = {J_EJOR},
  author       = {Yasemin Arda and Diego Cattaruzza and Véronique François and Maxime Ogier},
  doi          = {10.1016/j.ejor.2024.03.039},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {468-486},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Home chemotherapy delivery: An integrated production scheduling and multi-trip vehicle routing problem},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An explainable federated learning and blockchain-based
secure credit modeling method. <em>EJOR</em>, <em>317</em>(2), 449–467.
(<a href="https://doi.org/10.1016/j.ejor.2023.08.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning has drawn a lot of interest as a powerful technological solution to the “credit data silo” problem. The interpretability of federated learning is a crucial issue due to the lack of user interaction and the complexity of credit data monitoring. We advocate the importance of a credit data processing-as-a-service model, which completes conventional credit models in local environments, in order to overcome these restrictions. In particular, we describe an explainable federated learning and blockchain-based credit scoring system (EFCS) in this work. First, we propose an explainable federated learning method with controllable machine learning efficiency and controllable credit model decision making, thus having controllable credit model complexity and transparent and traceable credit decision-making mechanism. Then, we suggest an explainable federated learning training mechanism for credit data that prevents leakage of the model gradients trained by individual nodes during the training of the overall model. Neither the credit data provider nor the data user has access to the raw data in the credit model training ecosystem. Therefore, privacy protection, model performance, and algorithm efficiency, the core triangular cornerstones of federated learning, when added with model interpretability, together constitute a more secure and trustworthy federated learning-based methodology, thus providing a more reliable service for credit model training and construction. The EFCS scheme is presented via simulations of different types of federated learning and their resistance to system attack, applying the proposed model to six different credit scoring datasets. Extensive experimental analyses support the efficiency, security, and explainability of the EFCS.},
  archive      = {J_EJOR},
  author       = {Fan Yang and Mohammad Zoynul Abedin and Petr Hajek},
  doi          = {10.1016/j.ejor.2023.08.040},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {449-467},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An explainable federated learning and blockchain-based secure credit modeling method},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable real-time predictive analytics on employee
workload in digital railway control rooms. <em>EJOR</em>,
<em>317</em>(2), 437–448. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both workload peaks and lows contribute to lower employee well-being. Predictive employee workload analytics can empower management to undertake proactive prevention. For this purpose, we develop a real-time machine learning framework to predict and explain future workload in a challenging environment with variable and imbalanced workload: the digital control rooms for railway traffic management of Infrabel, Belgium’s railway infrastructure company. The proposed two-stage methodology leverages granular data of workload categories that are very different in nature and separates the effects of workload presence and magnitude. In this way, the set-up addresses the changing workload mix over 15-minute intervals. We extensively benchmark machine learning and deep learning models within this context, leading to LightGBM (Light Gradient Boosting Machine) as the best-performing model. SHAP (SHapley Additive exPlanations) values highlight the benefits of disentangling presence and magnitude and reveal associations with human-machine interaction and team exposure. As a proof of concept, our implemented predictive model offers tailored decision support to the traffic supervisor in an explainable way. In particular, the tool depicts overloaded and/or underloaded workstations and provides in-depth insights through local SHAP values.},
  archive      = {J_EJOR},
  author       = {Léon Sobrie and Marijn Verschelde and Bart Roets},
  doi          = {10.1016/j.ejor.2023.09.016},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {437-448},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Explainable real-time predictive analytics on employee workload in digital railway control rooms},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). What makes accidents severe! Explainable analytics framework
with parameter optimization. <em>EJOR</em>, <em>317</em>(2), 425–436.
(<a href="https://doi.org/10.1016/j.ejor.2023.11.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most analytics models are built on complex internal learning processes and calculations, which might be unintuitive, opaque, and incomprehensible to humans. Analytics-based decisions must be transparent and intuitive to foster greater human acceptability and confidence in analytics. Explainable analytics models are transparent models in which the primary factors and weights that lead to a prediction can be explained. Typical AI models are non-transparent or opaque models, in which even the designers cannot explain how their models arrive at a specific decision. These transparent models help decision-makers understand their judgments and build trust in analytics. This study introduces an innovative, comprehensive model that fuses descriptive, predictive, and prescriptive analytics, offering a fresh perspective on car accident severity. Our methodological contribution lies in the application of advanced techniques to address data-related challenges, optimize feature selection, develop predictive models, and fine-tune parameters. Importantly, we also incorporate model-agnostic interpretation techniques, further enhancing the transparency and interpretability of our model, and separate explanations from models (i.e., model-agnostic interpretation techniques). Our findings should provide novel insights for a domain expert to understand accident severity. The explainable analytics approach suggested in this study supplements non-transparent machine learning prediction models, particularly optimized ensemble models. Our model&#39;s end product is a comprehensible representation of crash severity factors. To obtain a more trustworthy assessment of accident severity, this model may be supplemented with insurance data, medical data such as blood work and pulse rate, and previous medical history.},
  archive      = {J_EJOR},
  author       = {Abdulaziz Ahmed and Kazim Topuz and Murad Moqbel and Ismail Abdulrashid},
  doi          = {10.1016/j.ejor.2023.11.013},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {425-436},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {What makes accidents severe! explainable analytics framework with parameter optimization},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explaining and predicting customer churn by monotonic rules
induced from ordinal data. <em>EJOR</em>, <em>317</em>(2), 414–424. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the course of a computational experiment on bank customer churn data, we demonstrate the explanatory and predictive capacity of monotonic decision rules. The data exhibit a partially ordinal character, as certain attribute value sets describing the clients are ordered and demonstrate a monotonic relationship with churn or non-churn outcomes. The data are structured by the Variable Consistency Dominance-based Rough Set Approach (VC-DRSA) prior to the induction of monotonic decision rules. The supervised learning is conducted using an extended version of VC-DRSA, implemented in RuLeStudio and RuleVisualization programs. The first one is designed to experiment with parameterized rule models, and the second one is used for visualization and a thorough examination of the rule model. The monotonic decision rules give insight into the bank data, characterizing loyal customers and the ones who left the bank. Such an approach is in line with explainable AI, aiming to obtain a transparent decision model, that can be easily understood by decision-makers. We also compare the predictive performance of monotonic rules with some well-known machine learning models.},
  archive      = {J_EJOR},
  author       = {Marcin Szeląg and Roman Słowiński},
  doi          = {10.1016/j.ejor.2023.09.028},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {414-424},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Explaining and predicting customer churn by monotonic rules induced from ordinal data},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature importance in the age of explainable AI: Case study
of detecting fake news &amp; misinformation via a multi-modal framework.
<em>EJOR</em>, <em>317</em>(2), 401–413. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, fake news has become a global phenomenon due to its explosive growth and ability to leverage multimedia content to manipulate user opinions. Fake news is created by manipulating images, text, audio, and videos, particularly on social media, and the proliferation of such disinformation can trigger detrimental societal effects. False forwarded messages can have a devastating impact on society, spreading propaganda, inciting violence, manipulating public opinion, and even influencing elections. A major shortcoming of existing fake news detection methods is their inability to simultaneously learn and extract features from two modalities and train models with shared representations of multimodal (textual and visual) information. Feature engineering is a critical task in the fake news detection model&#39;s machine learning (ML) development process. For ML models to be explainable and trusted, feature engineering should describe how many features used in the ML models contribute to making more accurate predictions. Feature engineering, which plays an important role in the development of an explainable AI system by shaping the features used in the ML models, is an interconnected concept with explainable AI as it affects the model&#39;s interpretability. In the research, we develop a fake news detector model in which we (1) identify several textual and visual features that are associated with fake or credible news; specifically, we extract features from article titles, contents, and, top images; (2) investigate the role of all multimodal features (content, emotions and manipulation-based) and combine the cumulative effects using the feature engineering that represent the behavior of fake news propagators; and (3) develop a model to detect disinformation on benchmark multimodal datasets consisting of text and images. We conduct experiments on several real-world multimodal fake news datasets, and our results show that on average, our model outperforms existing single-modality methods by large margins that do not use any feature optimization techniques.},
  archive      = {J_EJOR},
  author       = {Ajay Kumar and James W. Taylor},
  doi          = {10.1016/j.ejor.2023.10.003},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {401-413},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Feature importance in the age of explainable AI: Case study of detecting fake news &amp; misinformation via a multi-modal framework},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards the development of an explainable e-commerce fake
review index: An attribute analytics approach. <em>EJOR</em>,
<em>317</em>(2), 382–400. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instruments of corporate risk and reputation assessment tools are quintessentially developed on structured quantitative data linked to financial ratios and macroeconomics. An emerging stream of studies has challenged this norm by demonstrating improved risk assessment and model prediction capabilities through unstructured textual corporate data. Fake online consumer reviews pose serious threats to a business’ competitiveness and sales performance, directly impacting revenue, market share, brand reputation and even survivability. Research has shown that as little as three negative reviews can lead to a potential loss of 59.2 % of customers. Amazon, as the largest e-commerce retail platform, hosts over 85,000 small-to-medium-size (SME) retailers (UK), selling over fifty percent of Amazon products worldwide. Despite Amazon&#39;s best efforts, fake reviews are a growing problem causing financial and reputational damage at a scale never seen before. While large corporations are better equipped to handle these problems more efficiently, SMEs become the biggest victims of these scam tactics. Following the principles of attribute (AA) and responsible (RA) analytics, we present a novel hybrid method for indexing enterprise risk that we call the Fake Review Index ( R FRI RFRI ). The proposed modular approach benefits from a combination of structured review metadata and semantic topic index derived from unstructured product reviews. We further apply LIME to develop a Confidence Score, demonstrating the importance of explainability and openness in contemporary analytics within the OR domain. Transparency, explainability and simplicity of our roadmap to a hybrid modular approach offers an attractive entry platform for practitioners and managers from the industry.},
  archive      = {J_EJOR},
  author       = {Ronnie Das and Wasim Ahmed and Kshitij Sharma and Mariann Hardey and Yogesh K. Dwivedi and Ziqi Zhang and Chrysostomos Apostolidis and Raffaele Filieri},
  doi          = {10.1016/j.ejor.2024.03.008},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {382-400},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Towards the development of an explainable e-commerce fake review index: An attribute analytics approach},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 360 degrees rumor detection: When explanations got some
explaining to do. <em>EJOR</em>, <em>317</em>(2), 366–381. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unverified rumor detection recently received considerable academic attention due to the societal impact resulting from this potential misinformation. Previous work in this area mainly focused on textual features using a limited number of data sets and candidate algorithms, and completely disregarded model explainability. This study aims to come up with a more comprehensive social media rumor detection methodology. First, we investigate which machine or deep learning algorithm is best suited to classify tweets into rumors and non-rumors using both textual and structured features. Next, we interpret these rumor detection models with the LIME method and assess the quality of the explanations via fidelity and stability. To ensure the robustness of our methodology, it is benchmarked across the well-known PHEME data sets and two novel data sets, which are made publicly available. The results indicate that machine learners perform best on small data sets, while transformer architectures show the highest predictive accuracy for larger data sets. Unfortunately, these high accuracy transformer models are incompatible with LIME, which results in low fidelity. Moreover, our study shows that all LIME explanations are unstable across folds. Based on these results, we argue to evaluate explanation quality using fidelity and stability before explanation deployment. Our results further demonstrate that apparent model-agnostic explanations such as LIME do not seem to be completely model-agnostic and should be used with caution.},
  archive      = {J_EJOR},
  author       = {Bram Janssens and Lisa Schetgen and Matthias Bogaert and Matthijs Meire and Dirk Van den Poel},
  doi          = {10.1016/j.ejor.2023.06.024},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {366-381},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {360 degrees rumor detection: When explanations got some explaining to do},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An algorithmic approach to identification of gray areas:
Analysis of sleep scoring expert ensemble non agreement areas using a
multinomial mixture model. <em>EJOR</em>, <em>317</em>(2), 352–365. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) models have become a key component in modern world services. In decision-making domains where human expertise is crucial, for example, for manually scoring biological signal data, human uncertainties undermine experts’ trust in the outcomes of these models. The field of sleep staging in particular, which requires experts to score complex biological signal is notably impacted by scoring uncertainties. Data consisting of an ensemble of independent scorers are collected to estimate inter scorer agreement and the uncertainty associated with manual scoring. However, scorers’ uncertainty lacks statistical modeling, which poses difficulties in validating ML algorithms and leads to issues of reliability and explainability. From the ensemble of scorers, uncertainty zones, called gray areas , are highlighted by samples where scorers disagree. The objective of our work is to provide a framework introducing and inferring gray areas . We present a flexible and easy-to-use multi-objective method based on multinomial mixture models clustering the different levels of scorer agreement and summarize the results into two sets of high-agreement and gray area clusters, which are called supra-clusters. The threshold is selected according to the maximization of the distance between two distributions of scorers agreement measure. Effective results were obtained by the method after it was fitted on simulated data. Additionally, the method was applied to a real case of uncertainty analysis in the sleep staging domain. A series of actual sleep stages scored by an ensemble of 10 independent scorers for a dataset of 50 participants was used.},
  archive      = {J_EJOR},
  author       = {Gabriel Jouan and Erna Sif Arnardottir and Anna Sigridur Islind and María Óskarsdóttir},
  doi          = {10.1016/j.ejor.2023.09.039},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {352-365},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An algorithmic approach to identification of gray areas: Analysis of sleep scoring expert ensemble non agreement areas using a multinomial mixture model},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A markovian score model for evaluating provider performance
for continuity of care—an explainable analytics approach. <em>EJOR</em>,
<em>317</em>(2), 341–351. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuity of care refers to the practice of capturing, sharing, and effectively using knowledge about the diagnosis and prognosis of a patient over time. Prior studies have established a positive association between continuity and quality of care. However, because previous measures have focused on the patient rather than the provider, there is no widely-accepted metric for evaluating provider performance in this context. Furthermore, existing measures frequently rely on statistical formulations that may be difficult to interpret in a clinical setting. Analytics-driven decisions must be both explainable and transparent in order to be trusted. To address this issue, we propose an explainable analytics framework based on Markovian theory for assessing provider performance. Two explainable, transparent, and pragmatic measures from Markovian theory are presented: sojourn time (number of visits with a provider before changing to another) and recurrent time (number of transitions that take place before returning to a provider). Higher-order Markov concepts are incorporated into the scoring, such as when a patient sees another provider due to scheduling conflicts, urgent care, etc., but promptly returns to the primary provider. We also generalize this higher-order model to accommodate unique weights for each provider. The proposed model elucidates the inner mechanics of Markovian theory in order to achieve explainability, and provides interpretable scores for evaluating provider performance which increases trust and transparency in analytics-driven decisions.},
  archive      = {J_EJOR},
  author       = {Kazim Topuz and Timothy L. Urban and Mehmet B. Yildirim},
  doi          = {10.1016/j.ejor.2023.08.039},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {341-351},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A markovian score model for evaluating provider performance for continuity of care—An explainable analytics approach},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainability through uncertainty: Trustworthy
decision-making with neural networks. <em>EJOR</em>, <em>317</em>(2),
330–340. (<a href="https://doi.org/10.1016/j.ejor.2023.09.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty is a key feature of any machine learning model and is particularly important in neural networks, which tend to be overconfident. This overconfidence is worrying under distribution shifts, where the model performance silently degrades as the data distribution diverges from the training data distribution. Uncertainty estimation offers a solution to overconfident models, communicating when the output should (not) be trusted. Although methods for uncertainty estimation have been developed, they have not been explicitly linked to the field of explainable artificial intelligence (XAI). Furthermore, literature in operations research ignores the actionability component of uncertainty estimation and does not consider distribution shifts. This work proposes a general uncertainty framework, with contributions being threefold: (i) uncertainty estimation in ML models is positioned as an XAI technique, giving local and model-specific explanations; (ii) classification with rejection is used to reduce misclassifications by bringing a human expert in the loop for uncertain observations; (iii) the framework is applied to a case study on neural networks in educational data mining subject to distribution shifts. Uncertainty as XAI improves the model’s trustworthiness in downstream decision-making tasks, giving rise to more actionable and robust machine learning systems in operations research.},
  archive      = {J_EJOR},
  author       = {Arthur Thuy and Dries F. Benoit},
  doi          = {10.1016/j.ejor.2023.09.009},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {330-340},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Explainability through uncertainty: Trustworthy decision-making with neural networks},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainability in process outcome prediction: Guidelines to
obtain interpretable and faithful models. <em>EJOR</em>,
<em>317</em>(2), 317–329. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process outcome prediction pertains to the classification of ongoing cases of (business) processes into a given set of categorical outcomes. This field of research has seen a strong uptake in recent years due to advances in machine and deep learning. Although a recent shift has been made in the field of process outcome prediction to use models from the explainable artificial intelligence field, the evaluation still occurs mainly through predictive performance-based metrics, thus not accounting for the explainability, actionability, and the implications of the results of the models. This paper addresses explainability through the properties interpretability and faithfulness in the field of process outcome prediction. We introduce metrics to analyse these properties along the main dimensions of process data: the event, case, and control flow attributes. This allows for comparing explanations produced by transparent models with explanations generated by (post-hoc) explainability techniques on top of opaque black box models. We utilise thirteen real-life event logs and seven classifiers, encompassing a variety of transparent and non-transparent machine learning and deep learning models, complemented with (post-hoc) explainability techniques. Next, this paper contributes a set of guidelines named X-MOP for obtaining explainable models for outcome prediction, which helps to select the most suitable model by providing insight into how the varying preprocessing, model complexity, and explainability techniques typical in process outcome prediction influence the explainability of the model.},
  archive      = {J_EJOR},
  author       = {Alexander Stevens and Johannes De Smedt},
  doi          = {10.1016/j.ejor.2023.09.010},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {317-329},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Explainability in process outcome prediction: Guidelines to obtain interpretable and faithful models},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interpretable generalized additive neural networks.
<em>EJOR</em>, <em>317</em>(2), 303–316. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose Interpretable Generalized Additive Neural Networks (IGANN), a novel machine learning model that uses gradient boosting and tailored neural networks to obtain high predictive performance while being interpretable to humans. We derive an efficient training algorithm based on the theory of extreme learning machines, that allows reducing the training process to solving a sequence of regularized linear regressions. We analyze the algorithm theoretically, provide insights into the rate of change of so-called shape functions, and show that the computational complexity of the training process scales linearly with the number of samples in the training dataset. We implement IGANN in PyTorch, which allows the model to be trained on graphics processing units (GPUs) to speed up training. We demonstrate favorable results in a variety of numerical experiments and showcase IGANN’s value in three real-world case studies for productivity prediction, credit scoring, and criminal recidivism prediction.},
  archive      = {J_EJOR},
  author       = {Mathias Kraus and Daniel Tschernutter and Sven Weinzierl and Patrick Zschech},
  doi          = {10.1016/j.ejor.2023.06.032},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {303-316},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Interpretable generalized additive neural networks},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A model-agnostic and data-independent tabu search algorithm
to generate counterfactuals for tabular, image, and text data.
<em>EJOR</em>, <em>317</em>(2), 286–302. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing prevalence of artificial decision systems has prompted a keen interest in their efficiency, yet this progress is accompanied by their inherent complexity. This poses a significant challenge for various domains, including operational research, where decisions hold crucial influence over outcomes and thus must not remain undisclosed. Counterfactual explanations are greatly remarked as a simple (to understand) yet efficient way to explain the decisions made by a machine learning model by finding a minimal set of changes required to change the prediction outcome for a specific instance. We, then, present a novel algorithmic approach, called CFNOW, which implements a modular, fast, two-step process using tabu search, a well-known metaheuristic framework, to find counterfactuals for multiple data types (tabular, image, and text) with high efficiency. We run an extensive benchmark study with more than 5000 factual points from 25 datasets to demonstrate that CFNOW can generate high-quality counterfactual results in terms of metrics such as speed, coverage, distance, and sparsity, surpassing the state-of-the-art. These characteristics, associated with the simple code implementation, may aid embedding explainability to complex models which are often necessary for compliance requirements.},
  archive      = {J_EJOR},
  author       = {Raphael Mazzine Barbosa de Oliveira and Kenneth Sörensen and David Martens},
  doi          = {10.1016/j.ejor.2023.08.031},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {286-302},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A model-agnostic and data-independent tabu search algorithm to generate counterfactuals for tabular, image, and text data},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Supervised feature compression based on counterfactual
analysis. <em>EJOR</em>, <em>317</em>(2), 273–285. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfactual Explanations are becoming a de-facto standard in post-hoc interpretable machine learning. For a given classifier and an instance classified in an undesired class, its counterfactual explanation corresponds to small perturbations of that instance that allows changing the classification outcome. This work aims to leverage Counterfactual Explanations to detect the important decision boundaries of a pre-trained black-box model. This information is used to build a supervised discretization of the features in the dataset with a tunable granularity. Using the discretized dataset, an optimal Decision Tree can be trained that resembles the black-box model, but that is more interpretable and compact. Numerical results on real-world datasets show the effectiveness of the approach in terms of accuracy and sparsity.},
  archive      = {J_EJOR},
  author       = {Veronica Piccialli and Dolores Romero Morales and Cecilia Salvatore},
  doi          = {10.1016/j.ejor.2023.11.019},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {273-285},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Supervised feature compression based on counterfactual analysis},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable AI for operational research: A defining
framework, methods, applications, and a research agenda. <em>EJOR</em>,
<em>317</em>(2), 249–272. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to understand and explain the outcomes of data analysis methods, with regard to aiding decision-making, has become a critical requirement for many applications. For example, in operational research domains, data analytics have long been promoted as a way to enhance decision-making. This study proposes a comprehensive, normative framework to define explainable artificial intelligence (XAI) for operational research (XAIOR) as a reconciliation of three subdimensions that constitute its requirements: performance, attributable, and responsible analytics. In turn, this article offers in-depth overviews of how XAIOR can be deployed through various methods with respect to distinct domains and applications. Finally, an agenda for future XAIOR research is defined.},
  archive      = {J_EJOR},
  author       = {Koen W. De Bock and Kristof Coussement and Arno De Caigny and Roman Słowiński and Bart Baesens and Robert N. Boute and Tsan-Ming Choi and Dursun Delen and Mathias Kraus and Stefan Lessmann and Sebastián Maldonado and David Martens and María Óskarsdóttir and Carla Vairetti and Wouter Verbeke and Richard Weber},
  doi          = {10.1016/j.ejor.2023.09.026},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {249-272},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Explainable AI for operational research: A defining framework, methods, applications, and a research agenda},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable analytics for operational research.
<em>EJOR</em>, <em>317</em>(2), 243–248. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Koen W. De Bock and Kristof Coussement and Arno De Caigny},
  doi          = {10.1016/j.ejor.2024.04.015},
  journal      = {European Journal of Operational Research},
  month        = {9},
  number       = {2},
  pages        = {243-248},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Explainable analytics for operational research},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy-saving time allocation strategy with uncertain dwell
times in urban rail transit: Two-stage stochastic model and nested
dynamic programming framework. <em>EJOR</em>, <em>317</em>(1), 219–242.
(<a href="https://doi.org/10.1016/j.ejor.2024.03.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During practical operations, the urban rail transit system suffers from various uncertainties, particularly uncertain dwell times, which significantly impact the execution of the timetable and affect its performance, regarding train energy consumption and timetable stability. Using multi-scenario dwell times to capture its uncertainty, in this study, a two-stage chance-constrained stochastic model involving a section-time allocation stage and an optimal driving strategy stage is developed to minimize the expected energy consumption and improve stability. An exact nested dynamic programming (NDP) framework was designed to solve the model. The effectiveness and performance of the proposed methodology were investigated using a series of numerical experiments based on a small-scale instance from the Beijing Yizhuang Line. The optimized section-time allocation strategy reduced the expected energy consumption by 6.6% and improved the the minimum stability ratio by 8.5% by selecting the appropriate weight ratio. Four other sensitivity analyses were conducted to provide realistic managerial insights. Finally, a large-scale study of the Beijing 4-Daxing Subway Line was conducted to validate the scalability and efficiency of the NDP framework.},
  archive      = {J_EJOR},
  author       = {Deheng Lian and Pengli Mo and Andrea D’Ariano and Ziyou Gao and Lixing Yang},
  doi          = {10.1016/j.ejor.2024.03.015},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {1},
  pages        = {219-242},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Energy-saving time allocation strategy with uncertain dwell times in urban rail transit: Two-stage stochastic model and nested dynamic programming framework},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Configuring systems to be viable in a crisis: The role of
intuitive decision-making. <em>EJOR</em>, <em>317</em>(1), 205–218. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making in complex systems becomes even more challenging when the environment creates volatile, uncertain, complex, and ambiguous conditions that disrupt operations. In these settings, the viable system model (VSM) advocates that delegated autonomy, appropriately calibrated, can help decision-makers deal with disruptions quickly to preserve system viability and performance. However, the delegated authority to act also requires the confidence and knowledge to make effective decisions and, in this vein, we explore the role of intuition as an enabler of autonomy in emergency response systems. Intuition allows decision-makers who confront a novel situation to translate their experience, knowledge, and protocols in creative ways – innovations permitted by their delegated authority. This study contributes to VSM literature by a) demonstrating how VSM&#39;s structure and complexity management principles can support the analysis of viability in multi-agency emergency systems and b) using VSM to design a systems model to explain the role of autonomy and intuition in supporting decision-making and complexity management in viable systems. Methodologically, the study uses a multi-stage discovery-oriented approach (DOA) to develop theory, with each stage combining literature, data analysis, and model/theory development and identifying further questions to inform the subsequent stage. Through the DOA, we synthesise literature (e.g. on VSM, complexity management) with seven months of field-based insights (from interviews, workshops, and observation of a live disaster exercise) to develop VSM models. This research makes two contributions to soft operational research (OR) literature: taking a black-box approach to theory development in soft OR to uncover the role of autonomy and intuition in managing complexity and demonstrating DOA as a methodology that can provide fresh insights for behavioural soft OR studies.},
  archive      = {J_EJOR},
  author       = {Ayham Fattoum and Simos Chari and Duncan Shaw},
  doi          = {10.1016/j.ejor.2024.03.034},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {1},
  pages        = {205-218},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Configuring systems to be viable in a crisis: The role of intuitive decision-making},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Competition under demand uncertainty: The roles of
technology and capacity strategy. <em>EJOR</em>, <em>317</em>(1),
185–204. (<a href="https://doi.org/10.1016/j.ejor.2024.03.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To uncover the secrets of creating competitive advantage for firms under demand uncertainty, we study the roles of technology level and capacity investment strategies. Specifically, we analyze the Nash equilibrium of two competing firms at different technology levels under two capacity investment strategies, namely flexible or inflexible. We examine both symmetrical competition where the two firms adopt a same capacity type (flexible or inflexible), and asymmetrical competition where the two firms invest different capacity types. We find that an advanced technology level incentivises capacity expansion regardless of the capacity strategy adopted. In addition, the technology-capacity relationship significantly depends on demand distribution when both firms adopt inflexible capacity investment, but is independent of demand distribution when both firms invest in flexible capacity. No overwhelming superiority is observed from either side when both firms adopt the same capacity investment, and firms always co-exist in a profitable market, despite significant differences in technology. However, overwhelming superiority emerges from one side when both firms have different capacity investments. A firm can squeeze out its competitor and capture the entire market by upgrading its technology. When the two firms adopt the same capacity strategy, each firm may increase or decrease its technology level and capacity volume proportionally in equilibrium, regardless of the competition scenarios. We further explore the endogenous capacity investment type and technology flexibility in competition. We show that the competition effect plays an important role when the flexible capacity cost is moderate.},
  archive      = {J_EJOR},
  author       = {Liu Yang and Chi To Ng and T.C.E. Cheng and Mingyao Sun and Xuefeng Shao and Ruiqing Li},
  doi          = {10.1016/j.ejor.2024.03.017},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {1},
  pages        = {185-204},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Competition under demand uncertainty: The roles of technology and capacity strategy},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust decisions for heterogeneous agents via certainty
equivalents. <em>EJOR</em>, <em>317</em>(1), 171–184. (<a
href="https://doi.org/10.1016/j.ejor.2024.04.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of a planner who resolves risk–return trade-offs – like financial investment decisions – on behalf of a collective of agents with heterogeneous risk preferences. The planner’s objective is a two-stage utility functional where an outer utility function is applied to the distribution of the agents’ certainty equivalents from a given decision. Assuming lognormal risks and heterogeneous power utility preferences for the agents, we characterize optimal behavior in a setting where the planner can let each agent choose between different options from a fixed menu of possible decisions, leading to a grouping of the agents by risk preferences. These optimal decision menus are derived first for the case where the planner knows the distribution of preferences exactly and then for a case where he faces uncertainty about this distribution, only having access to upper and lower bounds on agents’ relative risk aversion. Finally, we provide tight bounds on the welfare loss from offering a finite menu of choices rather than fully personalized decisions.},
  archive      = {J_EJOR},
  author       = {Anne G. Balter and Nikolaus Schweizer},
  doi          = {10.1016/j.ejor.2024.04.003},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {1},
  pages        = {171-184},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust decisions for heterogeneous agents via certainty equivalents},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trust exploration- and leadership incubation- based opinion
dynamics model for social network group decision-making: A quantum
theory perspective. <em>EJOR</em>, <em>317</em>(1), 156–170. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social network (SN) holds significant sway over the consciousness and behavior of involved individuals, serving as an evolutionary medium for opinion dynamics models. Consensus is a fundamental concept in group decision-making (GDM). How to effectively explore the opinion evolution during the consensus-reaching process through SN is of paramount significance for decision-making science. Therefore, a dual-mechanism containing trust exploration and leadership incubation is developed for modeling opinion dynamics, creating a favorable condition for achieving consensus. First, a novel mechanism for analyzing the completeness of SN is proposed, encompassing a trust propagation process that considers trust discount and stability, as well as a trust aggregation method grounded by quantum theory. Second, a trust screening rule is discussed to retain the valid indirect trust relationships (TRs), and then a leadership incubation mechanism is developed to promote the effective achievement of consensus opinions in group decision-making. Finally, a numerical study is presented to elucidate the superiority and rationality of the proposed methods, and some simulation experiments and comparative analyses demonstrating the effectiveness and advantages of which are covered.},
  archive      = {J_EJOR},
  author       = {Peng Wang and Peide Liu and Yueyuan Li and Fei Teng and Witold Pedrycz},
  doi          = {10.1016/j.ejor.2024.03.025},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {1},
  pages        = {156-170},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Trust exploration- and leadership incubation- based opinion dynamics model for social network group decision-making: A quantum theory perspective},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The impact of platform’s information sharing on manufacturer
encroachment and selling format decision. <em>EJOR</em>,
<em>317</em>(1), 141–155. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by recent practice observations, we consider an incumbent manufacturer who has an existing wholesale contract with an e-commerce platform, which the latter sells as a private label product in its online marketplace. In this context, the manufacturer launches its follower product, which will coexist alongside the private label product on the platform. We study the interplay between the manufacturer’s choice of selling format (i.e., reselling or agency) and how this choice influences the platform’s decision to share (or not to share) demand information with the manufacturer (i.e., information sharing policy). In particular, we examine how the platform’s information-sharing policy, depending on its perceived information accuracy, impacts the manufacturer’s selling format decision. Using game-theoretic analyses, we find that under low perceived information accuracy, the manufacturer adopts the agency format when the commission rate is low but the reselling format when the commission rate is high. However, the platform withholds the demand information. More interestingly, when the commission rate and perceived information accuracy are both high, the manufacturer switches from the reselling to the agency format and this induces the platform to share demand information. This benefits both the manufacturer and the platform with the Pareto-improving zone expanding when perceived information accuracy is at least moderate but shrinking when the market size potential of the follower product increases. Ultimately, both parties can benefit from information sharing once in business and when the commission rate is high. The platform should also invest in greater information accuracy in such conditions.},
  archive      = {J_EJOR},
  author       = {Canran Gong and Joshua Ignatius and Huaming Song and Junwu Chai and Steven James Day},
  doi          = {10.1016/j.ejor.2024.03.036},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {1},
  pages        = {141-155},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The impact of platform’s information sharing on manufacturer encroachment and selling format decision},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Working along both lines? The relationship between
government green publicity and emissions tax. <em>EJOR</em>,
<em>317</em>(1), 128–140. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emissions reduction has long been the most concerning environmental issue. To promote emissions reduction among firms, governments have adopted mandatory tools such as emissions tax and voluntary guidance such as government green publicity. This paper investigates the interaction between emissions tax and government green publicity and analyzes the optimal decisions when the government combines these two policies. The results show that these two policies are mutually reinforcing, that is, the enhancement of one leads to the enhancement of the other. Moreover, although these two policies are complements in reducing emissions, it may be not wise to combine them to improve social welfare. Specifically, when the emissions damage is small, these two policies are substitutes in improving social welfare. More surprisingly, this substitutive relationship will increase with the baseline emissions level. This suggests that governments combining these two policies may not suitable for addressing high-pollution industries. When governments combine these two policies, intuitively, the emissions tax level and publicity degree will increase with tax implement efficiency. However, the results show that when the emissions damage is relatively large, the emissions tax level and publicity degree will decrease with tax efficiency. We also find that under asymmetric firms, heightened competition will improve the social welfare and the strategic complementarity of the two policies, albeit at the cost of firms’ profits. Moreover, we analyze the influence of budget constraints, revealing that as the budget limit level decreases, the strategic complementarity can initially decline but subsequently exhibit an upward trend.},
  archive      = {J_EJOR},
  author       = {Liqun Wei and Libin Zhang and Wanying Wei and Xiaohong Chen and Kai Wang},
  doi          = {10.1016/j.ejor.2024.03.032},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {1},
  pages        = {128-140},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Working along both lines? the relationship between government green publicity and emissions tax},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vehicle routing with stochastic demand, service and waiting
times — the case of food bank collection problems. <em>EJOR</em>,
<em>317</em>(1), 111–127. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food banks play an important role both in combating food waste, and in alleviating hunger. However, due to the many uncertainties that food banks face, they often struggle to effectively collect all food items that donors such as supermarkets are willing to provide. To tackle this problem, we introduce the capacitated vehicle routing problem with travel time restrictions and stochastic demand, service and waiting times, in which the uncertainties are dependent of each other. This problem can be generalized to a large variety of routing applications. The goal of the problem is to determine a minimum number of vehicles, and to plan cost-effective routes for these vehicles so that each route violates the vehicle capacity and the travel time limit with only a very small probability. The resulting problem is highly complex and thus solved by means of a matheuristic, which decomposes the problem into its natural decision components. Thus, it first determines the number of districts into which the service area should be partitioned, before allocating each customer to exactly one district and then plans a route for each district. A set of feedback mechanisms is activated whenever no feasible solution has been found through these steps. Extensive numerical experiments, involving both randomly generated and real-life instances, demonstrate the matheuristic’s effectiveness in solving instances with up to 100 customers. When applying our matheuristic to real-life instances from Dutch and Canadian food banks, we furthermore gain managerial insights to assist in optimizing fleet size and route cost.},
  archive      = {J_EJOR},
  author       = {Meike Reusken and Gilbert Laporte and Sonja U.K. Rohmer and Frans Cruijssen},
  doi          = {10.1016/j.ejor.2024.03.031},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {1},
  pages        = {111-127},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Vehicle routing with stochastic demand, service and waiting times — The case of food bank collection problems},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal decomposition approach for solving large nesting and
scheduling problems of additive manufacturing systems. <em>EJOR</em>,
<em>317</em>(1), 92–110. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenges associated with nesting and production scheduling in additive manufacturing (AM). The problem studied consists of grouping a set of parts into batches, which are then assigned to and sequenced across the available machines, guaranteeing the production of all parts. This work stands out by proposing exact methods for the AM nesting and scheduling problem considering irregular-shaped parts with specific release dates, processing times, and due dates, with the aim of minimizing the cumulative tardiness. The proposed approaches include two logic-based Benders decompositions: one combining Mixed Integer Programming (MIP) and Constraint Programming (CP), and the other relying solely on CP. To deal with the sub-problems, a strategic procedure was developed to reduce the solution space while maintaining low resolution times per iteration. Problem-specific cuts are also generated to improve the efficiency of these approaches. Computational experiments show that both decompositions significantly outperform a prior monolithic CP model, with the decomposition based solely on CP yielding the best results. Moreover, the results show that this approach has the potential to achieve similar computational performance of non-exact approaches that are currently considered state-of-the-art. A set of instances is provided to serve as a benchmark for future studies.},
  archive      = {J_EJOR},
  author       = {Paulo Jorge Nascimento and Cristóvão Silva and Carlos Henggeler Antunes and Samuel Moniz},
  doi          = {10.1016/j.ejor.2024.03.004},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {1},
  pages        = {92-110},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal decomposition approach for solving large nesting and scheduling problems of additive manufacturing systems},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel model for transfer synchronization in transit
networks and a lagrangian-based heuristic solution method.
<em>EJOR</em>, <em>317</em>(1), 76–91. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To realize the benefits of network connectivity in transfer-based transit networks, it is critical to minimize transfer disutility for passengers by synchronizing timetables of intersecting routes. We propose a mixed-integer linear programming timetable synchronization model that incorporates new features, such as dwell time determination and vehicle capacity consideration, which have been largely overlooked in the literature at the scheduling stage. We introduce a new concept of pre-planned holding time, called transfer buffer time, to reduce the transfer waiting time, particularly for transfers to low-frequency routes, while taking into account the penalty of extra in-vehicle time for onboard passengers and the possible consequences on headway regularity of a route. We develop a Lagrangian relaxation-based heuristic to obtain high-quality solutions efficiently for large instances. Our experiments on instances with up to 12 transfer nodes in the City of Toronto, with a mixture of low- and high-frequency routes, illustrate the potential benefits of the proposed model over the state of the art. The results indicate that incorporating transfer buffer time, dwell time determination, and vehicle capacity consideration improves model outcomes considerably, also demonstrating the computational efficiency of our Lagrangian-based solution method.},
  archive      = {J_EJOR},
  author       = {Zahra Ansarilari and Merve Bodur and Amer Shalaby},
  doi          = {10.1016/j.ejor.2024.03.010},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {1},
  pages        = {76-91},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A novel model for transfer synchronization in transit networks and a lagrangian-based heuristic solution method},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Logistics sourcing of e-commerce firms considering promised
delivery time and environmental sustainability. <em>EJOR</em>,
<em>317</em>(1), 60–75. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online consumers prioritise swift and dependable deliveries but are also concerned about the environmental repercussions of e-commerce, such as carbon emissions and packaging waste. E-commerce firms, therefore, grapple with balancing short promised delivery times (PDT) and environmental sustainability in a competitive landscape. Through a game-theoretic lens, this study delves into the logistics choices of two rival e-commerce firms. These firms can either manage their own logistics or outsource to third-party logistics providers (TPLs) that have a green edge due to advanced eco-friendly technologies. Our findings reveal that if the e-commerce firms compete on demand, their logistics strategies depend on the TPLs’ levels of green technology readiness. Conversely, intense PDT competition can diminish the TPLs’ benefits, prompting e-commerce firms to handle logistics in-house. Regarding environmental sustainability, the outcomes depend on whether demand or PDT competition drives the firms’ choices. Notably, if both firms compete on PDT, the most sustainable outcome remains elusive. Our conclusions remain consistent even when tested further by model extensions.},
  archive      = {J_EJOR},
  author       = {Canran Gong and Huaming Song and Daqiang Chen and Steven James Day and Joshua Ignatius},
  doi          = {10.1016/j.ejor.2024.02.026},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {1},
  pages        = {60-75},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Logistics sourcing of e-commerce firms considering promised delivery time and environmental sustainability},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integer optimization models and algorithms for the
multi-period non-shareable resource allocation problem. <em>EJOR</em>,
<em>317</em>(1), 43–59. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The resource allocation problem (RAP) determines a solution to optimally allocate limited resources to several activities or tasks. In this study, we propose a novel resource allocation problem referred to as multi-period non-shareable resource allocation problem (MNRAP), which is motivated by the characteristics of resources considered in the stem cell culture process for producing stem cell therapeutics. A resource considered in the MNRAP has the following three characteristics: (i) resource consumption required to perform an activity and available resource capacity may change over time; (ii) multiple activities cannot share one resource; and (iii) resource requirements can be satisfied through the combination of different types of resources. The MNRAP selects some of the given activities to maximize the overall profit under limited resources with these characteristics. To address this problem, pattern-based integer programming formulations based on the concept of resource patterns are proposed. These formulations attempt to overcome the limitations of a compact integer programming formulation, the utilization of which is challenging for large-scale problems owing to their complexity. Further, based on a branch-and-price approach to solving pattern-based formulations, effective heuristic algorithms are proposed to provide high-quality solutions for large instances. Moreover, through computational experiments on a wide range of instances, including real-world instances, the superiority of the proposed formulations and heuristic algorithms is demonstrated.},
  archive      = {J_EJOR},
  author       = {Jongyoon Park and Jinil Han and Kyungsik Lee},
  doi          = {10.1016/j.ejor.2024.03.027},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {1},
  pages        = {43-59},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integer optimization models and algorithms for the multi-period non-shareable resource allocation problem},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A computationally efficient approach to optimizing offers in
centrally committed electricity markets. <em>EJOR</em>, <em>317</em>(1),
25–42. (<a href="https://doi.org/10.1016/j.ejor.2024.01.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the incentive properties of the two primary approaches to incorporating unit-commitment decisions in wholesale electricity markets. One approach is centralized unit commitment, wherein generating firms provide complex multi-part offers that specify their non-convex fixed and variable operating costs. The market operator uses these offers to co-optimize unit-commitment and economic-dispatch decisions. The second approach is self-commitment, whereby firms determine unit-commitment decisions for their generating units individually and submit simple offers for the provision of energy. Operators of self-committed markets determine generator dispatch based on the merit order of the simple offers. Comparing the incentive properties of the two market designs is challenging because the offer-optimization problem for a firm that participates in a centrally committed market is a bi-level model with binary variables in the lower-level problem. To address this challenge, we develop a computationally efficient approach to solve such a problem and illustrate the method with examples. We use the examples to compare the incentive properties of the two market designs. Our examples show that the profit of the profit-maximizing firm does not differ significantly between the two market designs but that system costs can be higher under a self-committed design. These cost differences are because the complex offers and discriminatory payment schemes that are used under centrally committed designs can mitigate incentives for the profit-maximizing firm to exercise market power.},
  archive      = {J_EJOR},
  author       = {Yuzhou Jiang and Ramteen Sioshansi},
  doi          = {10.1016/j.ejor.2024.01.040},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {1},
  pages        = {25-42},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A computationally efficient approach to optimizing offers in centrally committed electricity markets},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maximizing the net present value of a project under
uncertainty: Activity delays and dynamic policies. <em>EJOR</em>,
<em>317</em>(1), 16–24. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a project with stochastic activity durations and cash flows; we model the uncertainty using discrete scenarios. The project entails precedence-related activities, each of which incurs a cash flow that may be positive (inflow) or negative (outflow). The problem is to find a scheduling policy that maximizes the expected net present value of the project. A scheduling policy decides the starting time of each activity under every possible realization of the unknown parameters. Ideally, one wants to expedite the inflows (e.g., incoming payments), while delaying the outflows (e.g., costs) as much as possible, without violating the project deadline. In this article, we devise an exact and a heuristic method to define policies within two new classes of scheduling policies. The first policy class generalizes all existing static policies in the literature and further illustrates the importance of intentional activity delays from both a theoretical as well as an empirical point of view. Whereas the literature on project scheduling has mainly focused on static policies, we also propose a second class of dynamic policies. We show that dynamic policies outperform static policies by means of extensive computational experiments.},
  archive      = {J_EJOR},
  author       = {Salim Rostami and Stefan Creemers and Roel Leus},
  doi          = {10.1016/j.ejor.2024.03.029},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {1},
  pages        = {16-24},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Maximizing the net present value of a project under uncertainty: Activity delays and dynamic policies},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vehicle routing problems with multiple commodities: A
survey. <em>EJOR</em>, <em>317</em>(1), 1–15. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a survey on vehicle routing problems with multiple commodities. In most routing problems, only one commodity is explicitly considered. This may be due to the fact that, indeed, a single commodity is involved, or multiple commodities are transported, but they are aggregated and modeled as a single commodity, as no specific requirement imposes their explicit consideration. However, there exist cases in which this aggregation is not possible due to the characteristics of the commodities or to the fact that it would lead to sub-optimal routing plans. This survey focuses on the analysis of the settings of the problems and the features of the commodities that require explicit consideration of disaggregated commodities in routing problems. We show that problem settings are inherently different with respect to the single commodity problems, and this has a consequence on both models and solution approaches, which cannot be straightforwardly adapted from the single commodity cases. We propose a classification of the routing problems with multiple commodities and discuss the motivations that force considering the presence of multiple commodities explicitly. Specifically, we focus on the modeling perspective by proposing a general formulation for routing problems with multiple commodities and showing how this formulation can be adapted to the different features that characterize the problem classes discussed in the survey. Also, for each major class of problems, promising future research directions are discussed by analyzing what has been studied in the current literature and focusing on challenging topics not covered yet.},
  archive      = {J_EJOR},
  author       = {Wenjuan Gu and Claudia Archetti and Diego Cattaruzza and Maxime Ogier and Frédéric Semet and M. Grazia Speranza},
  doi          = {10.1016/j.ejor.2023.11.032},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Vehicle routing problems with multiple commodities: A survey},
  volume       = {317},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comparison of chance-constrained data envelopment
analysis, stochastic nonparametric envelopment of data and bootstrap
method: A case study of cultural regeneration performance of cities.
<em>EJOR</em>, <em>316</em>(3), 1179–1191. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study comprehensively compares three efficiency measurement methods—chance-constrained data envelopment analysis (CCDEA), stochastic nonparametric envelopment of data (StoNED), and the bootstrap method—in the context of the cultural regeneration performance of cities. The research examines these methods’ methodological differences, advantages, and disadvantages with a focus on uncertainty handling, production function assumptions, and computational requirements. The analysis reveals that CCDEA and the bootstrap method yield similar efficiency scores, while StoNED tends to produce lower efficiency scores. Furthermore, regions exhibit higher value-creation efficiency of cultural and creative industry than operational management efficiency, thus highlighting the untapped potential for improving value creation in cultural regeneration projects. This comprehensive comparison enables researchers and practitioners to further understand the nuances among these methods and select the most suitable method for their specific needs and objectives when evaluating the performance of cultural regeneration projects or other applications.},
  archive      = {J_EJOR},
  author       = {Sheng-Wei Lin and Wen-Min Lu},
  doi          = {10.1016/j.ejor.2024.03.018},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {1179-1191},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A comparison of chance-constrained data envelopment analysis, stochastic nonparametric envelopment of data and bootstrap method: A case study of cultural regeneration performance of cities},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Game of banks - biform game theoretical framework for ATM
network cost sharing. <em>EJOR</em>, <em>316</em>(3), 1158–1178. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated teller machines (ATM) play a major role in the world economy as they enable financial transactions and hence good exchanges and consumption. ATM transaction fees are incurred to cover the cost of running the network and these are often settled among the members including banks and cash machine operators. In this paper, we develop a novel biform game theoretic model for members to optimally invest in the ATM network and to share the cost. This biform game includes both a cooperative game theory mechanism for interchange fee sharing and a non-cooperative counterpart to model the fact that members also wish to maximize their utilities. While the proposed coopetition framework is applicable to general ATM networks, we focus the case study on the UK ATM network thanks to the accessibility of the data in addition to the notable stability issues that the network is currently experiencing as has been widely featured by the mainstream media. On the technical side, we prove the existence of a pure Nash equilibrium, which can be computed efficiently. We also show that, under some settings, the Shapley allocation belongs to the core and hence it is not only fair to all members but also leads to a stable ATM network. In addition, we show that the Shapley value allocation dominates the current mechanism in terms of social welfare. Finally, we provide numerical analysis and managerial insights using real data on the complete UK ATM network.},
  archive      = {J_EJOR},
  author       = {Tri-Dung Nguyen},
  doi          = {10.1016/j.ejor.2024.02.036},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {1158-1178},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Game of banks - Biform game theoretical framework for ATM network cost sharing},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A digital economy development index based on an improved
hierarchical data envelopment analysis approach. <em>EJOR</em>,
<em>316</em>(3), 1146–1157. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digital economy is playing an increasingly important role in the global economy. National and international organizations commonly utilize a composite index composed of multi-dimensional indicators to monitor performance, analyse policies, and communicate in the digital economy. This study introduces a hierarchical framework for constructing a Digital Economy Development Index (DEDI). One of the key challenges is determining the attribute weights to be assigned by aggregating the sub-indicators with hierarchical dimensions for DEDI. The current study shows that an H-DEA model can be transformed into a parametric linear programming problem and develops an improved golden section algorithm to search for approximate optimal solutions. The newly developed method is highly robust and provides an alternative procedure to determine the optimal weights for building a DEDI. We established a hierarchical evaluation framework and utilized a new approach to measure the DEDI of 30 provinces in China from 2015 to 2020. The results show that inter-provincial digital economy development in China shows a sequential weakening from the east, centre, and northeast to the west. The East leads the country&#39;s digital economy overall, while there is a clear gradient gap between provinces. The central region needs to create a cluster for the development of digital industries. The Northeast should enhance the competitiveness of the industry across the board. The West must strengthen the construction of innovative talent and new infrastructure for the digital economy. These findings can serve as guidelines for designing China&#39;s ongoing digital economy development.},
  archive      = {J_EJOR},
  author       = {Chuanyin Guo and Qiwei Song and Ming-Miin Yu and Jian Zhang},
  doi          = {10.1016/j.ejor.2024.02.023},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {1146-1157},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A digital economy development index based on an improved hierarchical data envelopment analysis approach},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Locating charging stations and routing drones for efficient
automated stocktaking. <em>EJOR</em>, <em>316</em>(3), 1129–1145. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drones have received growing attention in logistics recently. One possible application is deploying drones for auditing inventory in warehouses. With the use of drones, warehouses are able to increase inventory record accuracy and decrease labor costs. In this research, we introduce the stocktaking drone routing problem (STDRP), which consists of routing a fleet of drones through a warehouse for stocktaking purposes as well as deciding on the location of charging stations on the warehouse floor, which is necessary due to the limited battery capacity of the drones. Subsequently, we develop an adaptive large neighborhood search-based heuristic (ALNS) with novel solution encoding and decoding approaches to solve the STDRP. In a numerical study, we show that ALNS can solve realistic instances in reasonable time. We also derive recommendations regarding the ideal size of the drone fleet, the charging infrastructure, and battery capacity. Finally, we investigate the interplay between the storage assignment policy (such as the popular ABC rule) and stocktaking efficiency using drones.},
  archive      = {J_EJOR},
  author       = {Panupong Vichitkunakorn and Simon Emde and Makusee Masae and Christoph H. Glock and Eric H. Grosse},
  doi          = {10.1016/j.ejor.2024.03.002},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {1129-1145},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Locating charging stations and routing drones for efficient automated stocktaking},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic modeling of integrated order fulfillment
processes with delivery time promise: Order picking, batching, and
last-mile delivery. <em>EJOR</em>, <em>316</em>(3), 1114–1128. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To guarantee high customer service and short and accurate lead times, many e-commerce retailers have started to home deliver their customer orders within a few hours or even minutes, also known as quick-commerce order fulfillment. Quick-commerce order fulfillment consists of three main processes: order picking in the warehouse, order batching for delivery, and last-mile delivery. The ultimate delivery performance depends on managing all three processes, which are highly stochastic, and interdependent. We capture this stochasticity and interdependency in an integrated analytical framework and derive approximate analytical expressions for the mean and variance of the total order fulfillment time. We validate the analytical expressions with both in-house detailed process simulations and external-party output measures. We then analyze the delivery cost-service quality trade-offs using an optimization model that minimizes the expected order fulfillment cost with a delivery probability ( D P DP ) constraint, focusing on meeting delivery time deadlines. The optimization model determines the number of pickers, the optimal delivery batch size, and the number of vehicles required to deliver the customer orders. Achieving a high delivery reliability comes at a cost. In comparison to the model with DP constraints, we observe that the expected order fulfillment cost averaged over all data parameter settings obtained from the model without DP constraints is 8.9% lower; however, the mean and standard deviation of order fulfillment time increase by 44.1% and 18.6%, respectively, which results in low delivery reliability. We further demonstrate that an integrated analysis of the order fulfillment process is essential to set reliable fulfillment due times.},
  archive      = {J_EJOR},
  author       = {G. Raj and D. Roy and R. de Koster and V. Bansal},
  doi          = {10.1016/j.ejor.2024.03.003},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {1114-1128},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stochastic modeling of integrated order fulfillment processes with delivery time promise: Order picking, batching, and last-mile delivery},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A sample robust optimal bidding model for a virtual power
plant. <em>EJOR</em>, <em>316</em>(3), 1101–1113. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many energy markets, the trade amount of electricity must be committed to before the actual supply. This study explores one consecutive operational challenge for a virtual power plant—the optimal bidding for highly uncertain distributed energy resources in a day-ahead electricity market. The optimal bidding problem is formulated as a scenario-based multi-stage stochastic optimization model. However, the scenario-tree approach raises two consequent issues—scenario overfitting and massive computation cost. This study addresses the issues by deploying a sample robust optimization approach with linear decision rules. A tractable robust counterpart is derived from the model where the uncertainty appears in a nonlinear objective and constraints. By applying the decision rules to the balancing policy, the original model can be reduced to a two-stage stochastic mixed-integer programming model and then efficiently solved by adopting a dual decomposition method combined with heuristics. Based on real-world business data, a numerical experiment is conducted with several benchmark models. The results verify the superior performance of our proposed approach based on increased out-of-sample profits and decreased overestimation of in-sample profits.},
  archive      = {J_EJOR},
  author       = {Seokwoo Kim and Dong Gu Choi},
  doi          = {10.1016/j.ejor.2024.03.001},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {1101-1113},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A sample robust optimal bidding model for a virtual power plant},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrated inventory replenishment and online demand
allocation decisions for an omnichannel retailer with ship-from-store
strategy. <em>EJOR</em>, <em>316</em>(3), 1085–1100. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retailing has changed dramatically from single-channel brick-and-mortar stores to multi-channel and omnichannel retailers over the last few decades. Omnichannel retailers employ different strategies to integrate online and offline sales channels as well as order fulfillment processes. Among these strategies, the ship-from-store is the most popular and widely accepted among retailers. It enables retailers to use inventory from store locations to fulfill online demand. An omnichannel retailer with a distribution center and a retail store has to make important, interlinked decisions — (1) how much inventory to keep at the retail store, and (2) where to fulfill the online demand from and how much. In this work, we model the integrated inventory replenishment and online demand allocation decisions for an omnichannel retailer employing the ship-from-store strategy. We analyze this problem for both single-period and multi-period settings. We extend the analytical framework of the single-period problem by providing a finite-horizon Markov decision process (MDP) formulation for the multi-period problem. Our findings suggest that for a single-period setting, decentralized inventory replenishment and demand allocation system maximizes the profit of the omnichannel retailer for low values of the incentive for fulfilling the online demand through store inventory, while for sufficiently high values of the incentive, a pooled system provides the optimal profit. An increment in the discount factor has the same effect on the optimal decisions in a multi-period setting as that of salvage value in a single-period setting for a given value of the incentive for the ship-from-store strategy. We also provide several extensions (such as cross selling, endogenous and correlated demand streams) of our analytical framework for the multi-period problem.},
  archive      = {J_EJOR},
  author       = {Vishal Bansal and Arnab Bisi and Debjit Roy and Prahalad Venkateshan},
  doi          = {10.1016/j.ejor.2024.02.027},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {1085-1100},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrated inventory replenishment and online demand allocation decisions for an omnichannel retailer with ship-from-store strategy},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mathematical programming for simultaneous feature selection
and outlier detection under l1 norm. <em>EJOR</em>, <em>316</em>(3),
1070–1084. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of simultaneous feature selection and outlier detection is to determine a sparse linear regression vector by fitting a dataset possibly affected by the presence of outliers. The problem is well-known in the literature. In its basic version it covers a wide range of tasks in data analysis. Simultaneously performing feature selection and outlier detection strongly improves the application potential of regression models in more general settings, where data governance is a concern. To trigger this potential, flexible training models are needed, with more parameters under control of decision makers. The use of mathematical programming, although pertinent, is scarce in this context and mostly focusing on the least-squares setting. Instead we consider the least absolute deviation criterion, proposing two mixed-integer linear programs, one adapted from existing studies, and the other obtained from a disjunctive programming argument. We show theoretically and computationally that the disjunctive-based formulation is better in terms of both continuous relaxation quality and integer optimality convergence. We experimentally benchmark against existing methodologies from the literature. We identify the characteristics of contamination patterns, in which mathematical programming is better than state-of-the-art algorithms in combining prediction quality, sparsity and robustness against outliers. Additionally, the mathematical programming approaches allow the decision maker to directly control parameters like the number of features or outliers to tolerate, those based on least absolute deviations performing best. On real world datasets, where privacy is a concern, our approach compares well to state-of-the-art methods in terms of accuracy, being at the same time more flexible.},
  archive      = {J_EJOR},
  author       = {Michele Barbato and Alberto Ceselli},
  doi          = {10.1016/j.ejor.2024.03.035},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {1070-1084},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mathematical programming for simultaneous feature selection and outlier detection under l1 norm},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Propensity score oversampling and matching for uplift
modeling. <em>EJOR</em>, <em>316</em>(3), 1058–1069. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel matching strategy to correct for confounding in uplift modeling. Our method, called propensity score oversampling and matching (ProSOM), extends the well-known propensity score matching (PSM) technique by addressing one of its main limitations: dealing with small datasets that face an imbalance in the distribution of the causal variable. Apart from this, we also face the additional complexity of dealing with class labels. The proposed method establishes a parallel between uplift modeling and class-imbalance classification as it extends existing oversampling techniques to create synthetic elements from the treatment group. We design an algorithm that performs classaware data oversampling in the treatment group, and then it matches samples from this group with the control group. This can be seen as a novel hybrid undersampling-oversampling solution for causal learning. Experiments on five datasets show the virtues of ProSOM in terms of predictive performance, achieving the best Qini coefficient for all five datasets in relation to PSM and other resampling solutions.},
  archive      = {J_EJOR},
  author       = {Carla Vairetti and Franco Gennaro and Sebastián Maldonado},
  doi          = {10.1016/j.ejor.2024.03.024},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {1058-1069},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Propensity score oversampling and matching for uplift modeling},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Review-based recommendation under preference uncertainty: An
asymmetric deep learning framework. <em>EJOR</em>, <em>316</em>(3),
1044–1057. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online reviews are one of the most trusted resources for inferring customer needs and understanding consumer decision-making behavior. This study attempts to integrate textual reviews and user-item ratings to improve recommendation performance. To achieve this goal, we propose a deep neural network model. Specifically, the proposed model applies a review-level aggregation strategy to learn user preferences while using an aspect-based document-level aggregation strategy to learn item representation. In this process, we introduce two attention modules at the review and aspect levels, respectively. The review-level attention is used to learn the user preferences that are most related to the target item. The aspect-level attention attempts to learn the item&#39;s aspect features that users are most concerned about. In addition, we design a latent stochastic attention mechanism based on the probabilistic generative mechanism, to model the user preference uncertainty. For evaluation, we conduct extensive experiments on several real-world datasets. Using several state-of-the-art methods as comparisons, we find that the proposed model can significantly improve rating predictive power in the context of the recommendation system. Based on ablation experiments, we find that the enhanced predictive power benefits from the preference uncertainty and the attention mechanism. From the qualitative analysis, we suggest that the proposed model can yield many interpretable results.},
  archive      = {J_EJOR},
  author       = {Yingqiu Xiong and Yezheng Liu and Yang Qian and Yuanchun Jiang and Yidong Chai and Haifeng Ling},
  doi          = {10.1016/j.ejor.2024.01.042},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {1044-1057},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Review-based recommendation under preference uncertainty: An asymmetric deep learning framework},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Plant capacity utilization with piecewise cobb-douglas
technology: Definition and interpretation. <em>EJOR</em>,
<em>316</em>(3), 1034–1043. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convex and nonconvex nonparametric technologies have been applied to estimate plant capacity utilization. However, they face challenges in capturing the production characteristic that involves the simultaneous consideration of increasing, constant, and decreasing marginal production rates along the production surfaces, which may be inconsistent with the standard microeconomic production theory. This inconsistency raises concerns regarding the potential bias of plant capacity utilization estimates. Thus, this paper introduces a new plant capacity utilization measure based on the piecewise Cobb–Douglas technology, aligned with the standard microeconomic production theory. This measure is defined using two multiplicative directional distance functions with optimal endogenous directions. It can be interpreted by the Euclidean distance between two points associated with optimal capacities and the Euclidean norm of one optimal endogenous direction vector. The new measure captures potential production slacks to measure plant capacity in the sense of Pareto–Koopmans efficiency. It also suggests a remedy of non-existence of a maximal plant capacity in the Cobb–Douglas function by utilizing the piecewise Cobb–Douglas technology. The proposed plant capacity utilization measure is validated using a secondary dataset of 19 Chilean hydroelectric power plants.},
  archive      = {J_EJOR},
  author       = {Xiangyang Tao and Qingxian An and Mark Goh},
  doi          = {10.1016/j.ejor.2024.02.028},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {1034-1043},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Plant capacity utilization with piecewise cobb-douglas technology: Definition and interpretation},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fueling the future: Overcoming the barriers to market
development of renewable fuels in germany using a novel analytical
approach. <em>EJOR</em>, <em>316</em>(3), 1012–1033. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Germany has set ambitious targets for reducing greenhouse gas (GHG) emissions, namely by 65% until 2030 (compared to the 1990 level) and achieving climate neutrality by 2045. Although GHG emissions have decreased in most sectors, the transport sector has experienced failed reduction attempts. Renewable fuels are promising sustainable fuel alternatives that can replace current market-dominant fossil fuels to reduce GHG emissions. However, the market development of renewable fuels is hindered by various economic, environmental, technical, regulatory, and social barriers. Using a novel holistic approach, this study aims to analyze the market development barriers for renewable fuels in the German transport sector. First, a novel extension to the decision making trial and evaluation laboratory (DEMATEL) method is proposed using the Type-2 Neutrosophic Numbers (T2NN), which is improved by the K-means algorithm. Second, the maximum mean de-entropy algorithm is applied to convert the results of T2NN-DEMATEL into input for interpretive structural modeling (ISM). Next, a case study is conducted to analyze the impacts of barriers on different transport modes using the T2NN-based additive ratio assessment. Extensive sensitivity analyses are conducted to measure the impacts of different factors under different circumstances. The obtained results indicate that insufficient renewable energy policies and regulations, the lack of coordination in the supply chain, and high technology conversion challenges are the most significant barriers. Moreover, road and maritime transport are affected more than the aviation and rail sectors by the market development barriers.},
  archive      = {J_EJOR},
  author       = {Ali Ebadi Torkayesh and Sepehr Hendiani and Grit Walther and Sandra Venghaus},
  doi          = {10.1016/j.ejor.2024.02.039},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {1012-1033},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fueling the future: Overcoming the barriers to market development of renewable fuels in germany using a novel analytical approach},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Structural rearrangement of the network system from an
efficiency perspective: A silver lining of profit improvement.
<em>EJOR</em>, <em>316</em>(3), 1001–1011. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous studies on profit improvement mainly consider improving traditional profit efficiency including the technical, allocative, and price profit efficiencies. Few studies discuss profit improvement by optimizing the structural arrangement of the network system, which is about adjusting the combinations of upstream and downstream entities in the system. When achieving traditional efficiency, the system&#39;s profit can no longer be increased only by reducing inputs, increasing outputs, and adjusting prices. In this situation, structural rearrangement may provide a silver lining to profit improvement. In this study, we take the two-level supply chains as an example and address the research question of how to improve profit via structural rearrangement of the system containing several two-stage subsystems from the efficiency perspective . To answer this question, we view two-stage subsystems in each system as players and propose a data envelopment analysis permutation game method. Through this method, we find the optimal structural rearrangement plan, which is a new way to further improve the profit in addition to improving traditional profit efficiency. We propose a new efficiency measurement, the structural profit efficiency, and find overall profit efficiency is the product of structural profit efficiency and traditional profit efficiency. Finally, we conduct an experiment using the data of 27 supply chains to validate our proposed method and provide the optimal structural rearrangement plans for them.},
  archive      = {J_EJOR},
  author       = {Yao Wen and Qingxian An and Yeming Gong and Pengkun Wu},
  doi          = {10.1016/j.ejor.2024.02.018},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {1001-1011},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Structural rearrangement of the network system from an efficiency perspective: A silver lining of profit improvement},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling project interactions in multiattribute portfolio
decision analysis: Axiomatic foundations and practical implications.
<em>EJOR</em>, <em>316</em>(3), 988–1000. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common approach to modeling project interactions in multiattribute project portfolio selection is to augment the additive portfolio utility function, in which portfolio utility is the sum of the included projects’ utilities, with additional terms representing the synergy/cannibalization effects triggered by selecting specific subsets of projects. In this paper we develop a set of sufficient and necessary assumptions for representing preferences among multiattribute project portfolios with a quasi-symmetric multilinear utility function and show how this function gives rise to interpreting interaction effects as additional terms in the additive portfolio utility function. To foster practical applicability of these theoretical contributions, we also develop techniques to elicit such portfolio utility functions as well as optimization models to identify the feasible portfolio that satisfies relevant resource and other constraints with the maximal expected utility. In recognition that incorporating project interactions necessitates increased involvement of decision makers in assessing the interaction effects and results in computationally more challenging portfolio optimization problems, we analyze the importance of modeling interactions through series of simulation studies based on randomly generated and real-world data sets. Specifically, we examine the impact that omitting project interactions has on the project-level decision recommendations and on the expected utility of the recommended portfolio.},
  archive      = {J_EJOR},
  author       = {Juuso Liesiö and Taeyoung Kee and Pekka Malo},
  doi          = {10.1016/j.ejor.2024.02.015},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {988-1000},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modeling project interactions in multiattribute portfolio decision analysis: Axiomatic foundations and practical implications},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploiting symmetry for the job sequencing and tool
switching problem. <em>EJOR</em>, <em>316</em>(3), 976–987. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Job Sequencing and Tool Switching Problem (SSP), a well-known combinatorial optimization problem in the domain of Flexible Manufacturing Systems (FMS), is studied in this article. The aim of this research is to improve the currently known exact solution methodology for this NP NP -hard problem. We propose a new integer linear programming approach with symmetry-breaking and tightening cuts that provably outperformed the existing methodology described in the literature. The computational study conducted on a data set with 1,050 instances showed that the developed method can solve hard instances that were not solvable with the state-of-the-art methods presented in the literature.},
  archive      = {J_EJOR},
  author       = {Najmaddin Akhundov and James Ostrowski},
  doi          = {10.1016/j.ejor.2024.02.030},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {976-987},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exploiting symmetry for the job sequencing and tool switching problem},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing location-routing and demand allocation in the
household waste collection system using a branch-and-price algorithm.
<em>EJOR</em>, <em>316</em>(3), 958–975. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In catering to the rapid development of urbanization and the growing urban population, it is essential to design an efficient and effective household waste collection system for guaranteeing a favorable ecological environment in cities. This paper focuses on a location-routing and demand allocation problem (LRDAP) in the household waste collection system where the household waste is initially allocated and transported to a set of intermediate transfer stations using a category of small garbage vehicles, and subsequently a fleet of large garbage vehicles visits each transfer station and transports the collected household waste to the waste disposal center for harmless treatment. The purpose is to simultaneously determine the location of transfer stations, the demand allocation of household waste collection and the routing plan of garbage vehicles while maximizing the efficiency of household waste collection within the whole system. Then, we formulate the proposed LRDAP into a mixed integer program. To solve our LRDAP, an exact branch-and-price (B&amp;P) algorithm is developed along with several acceleration strategies involving column generation (CG) stabilization and heuristic dynamic programming (DP). Finally, we illustrate the proposed model and solution methodology by dealing with real-world problem instances with respect to household waste collection in China. Computational results are presented that explore the performance of our proposed B&amp;P algorithm, analyze the optimized location-routing and demand allocation plan, discuss the impact of selected parameters, and gain some managerial insights in designing an efficient and effective household waste collection system under different decision-making conditions.},
  archive      = {J_EJOR},
  author       = {Jialin Han and Jiaxiang Zhang and Haoyue Guo and Ning Zhang},
  doi          = {10.1016/j.ejor.2024.02.029},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {958-975},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing location-routing and demand allocation in the household waste collection system using a branch-and-price algorithm},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recourse strategy for the routing problem of mobile parcel
lockers with time windows under uncertain demands. <em>EJOR</em>,
<em>316</em>(3), 942–957. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is expected that mobile parcel lockers (MPLs) will provide more responsive and flexible service to the increasing variation of demand than fixed parcel lockers. However, the service provided by MPLs following planned routes can be degraded and even fail due to the demand uncertainty, such as demand volume and pickup time. In this study, we propose an optimization approach integrated with the recourse strategies to overcome this barrier. Three types of uncertain demands and two types of service failures are addressed in this study, with consideration of uncertain demands and time window constraint. To optimally determine the a priori routes for a set of MPLs, we propose a tailored tabu search algorithm by taking into account the recourse cost. A series of numerical experiments were conducted to examine the effectiveness of the proposed approach in enhancing route reliability with a comparison to ordinary express vehicles. The results reveal that the service reliability can be significantly improved with only a marginal increase in the operational cost by the proposed approach.},
  archive      = {J_EJOR},
  author       = {Yang Wang and Mengyu Bi and Jianhui Lai and Chenxi Wang and Yanyan Chen and José Holguín-Veras},
  doi          = {10.1016/j.ejor.2024.02.034},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {942-957},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Recourse strategy for the routing problem of mobile parcel lockers with time windows under uncertain demands},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How to optimize container withholding decisions for reuse in
the hinterland? <em>EJOR</em>, <em>316</em>(3), 930–941. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates how a hinterland consignee (importer) makes decisions regarding the storage of empty containers for reuse by a shipper (exporter). The system is modeled as a double-ended queue with non-zero matching times, limited truck resources, and both consignee and shipper having fixed withholding capacities. The consignee’s withholding threshold is strategically set to minimize overall transport and detention costs. We derive closed-form expressions for performance measures in the case of a single storage facility at the shipper, utilizing a matrix-based approach. We extend this methodology numerically to the general case. Additionally, we present an accurate fixed-point approximation facilitating the determination of performance measures and optimal threshold. Our findings show the importance of withholding decisions in import and balanced areas for cost reduction. In export areas, a policy of full reuse proves nearly optimal. Analyzing dynamic state-dependent consignee decisions via a Markov decision process, we establish that the optimal policy involves withholding thresholds increasing with stored quantity at the shipper. While optimal, state-dependent thresholds yield limited cost savings compared to a fixed threshold, suggesting minimal impact from consignee-shipper information sharing. Additionally, we examine the influence of variability in matching and production times, observing decreased costs with reduced variability, particularly in export areas, but with minor impacts on withholding decisions.},
  archive      = {J_EJOR},
  author       = {Benjamin Legros and Jan Fransoo and Oualid Jouini},
  doi          = {10.1016/j.ejor.2024.02.035},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {930-941},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {How to optimize container withholding decisions for reuse in the hinterland?},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New exact algorithm for the integrated train timetabling and
rolling stock circulation planning problem with stochastic demand.
<em>EJOR</em>, <em>316</em>(3), 906–929. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies an integrated train timetabling and rolling stock circulation planning problem with stochastic demand and flexible train composition (TRSF). A novel stochastic integer programming model, which is formulated on a space-time underlying network to simultaneously optimize the train timetable and rolling stock circulation plan with flexible train composition, is proposed by explicitly considering the random feature of passenger distribution on an urban rail transit line. To solve this problem efficiently, the proposed model is decomposed into a master problem and a series of sub-problems regarding different stochastic scenarios. We further prove that each sub-problem model is equivalent to its linear programming relaxation problem, by proving that the coefficient matrix of each linear programming relaxation model is totally unimodular. Then, the classical Benders decomposition algorithm is applied to the studied problem. Based on the model characteristics, both single-cut and multi-cut methods with some speed-up techniques are developed to solve the proposed model in a novel and effective way. Numerical experiments are conducted on small-scale cases and large-scale cases derived from Shanghai Metro Line 17, and the results show that solving the stochastic problem can extract gains in efficiency and the value of stochastic solution tends to be high.},
  archive      = {J_EJOR},
  author       = {Hanchuan Pan and Lixing Yang and Zhe Liang and Hai Yang},
  doi          = {10.1016/j.ejor.2024.02.017},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {906-929},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {New exact algorithm for the integrated train timetabling and rolling stock circulation planning problem with stochastic demand},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A simple heuristic for computing non-stationary inventory
policies based on function approximation. <em>EJOR</em>,
<em>316</em>(3), 899–905. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a finite-horizon periodic-review inventory system with fixed replenishment costs that faces non-stationary demands. The structure of the optimal control policy for this system has long been known. However, finding optimal policy parameters requires solving a large-scale stochastic dynamic program. To circumvent this, we devise a recursion-free approximation for the cost function of the problem. This translates into an efficient and effective heuristic to compute policy parameters that significantly outperforms earlier heuristics. Our approach is easy-to-understand and easy-to-use as it follows by elementary methods of shortest paths and convex minimization.},
  archive      = {J_EJOR},
  author       = {Onur A. Kilic and S. Armagan Tarim},
  doi          = {10.1016/j.ejor.2024.02.016},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {899-905},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A simple heuristic for computing non-stationary inventory policies based on function approximation},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Coordinating scheduling and rejection decisions in a
two-machine flow shop scheduling problem. <em>EJOR</em>,
<em>316</em>(3), 887–898. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a two-machine flow shop scheduling problem where any operation can be rejected at a certain cost. A solution for such a problem requires two sets of decisions. The first involves the partition of the set of operations into two subsets: the set of operations that are accepted for scheduling in the shop, and the set of rejected operations. The second decision involves scheduling the set of accepted operations in the shop. The objective is to find a solution that minimizes the sum of the makespan and the total rejection cost. We prove that the problem is NP NP -hard even if all processing operations have identical processing times and identical rejection costs on either one of the two machines. We show, however, that the problem is fixed parameterized tractable with respect to a parameter that combine the number of different processing times on both machines with the number of different rejection costs on one out of the two machines. We also provide a pseudo-polynomial time algorithm for the problem, which we then convert into a fully polynomial time approximation scheme. This is achieved by dividing the problem into a set of subproblems and deriving a fully polynomial time approximation scheme for each one of them, separately. Finally, we present an integer linear programming formulation of the problem and two simple 2-approximation algorithms.},
  archive      = {J_EJOR},
  author       = {Dvir Shabtay and Enrique Gerstl},
  doi          = {10.1016/j.ejor.2024.03.021},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {887-898},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Coordinating scheduling and rejection decisions in a two-machine flow shop scheduling problem},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Iterated local search with ejection chains for the
space-free multi-row facility layout problem. <em>EJOR</em>,
<em>316</em>(3), 873–886. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an iterated local search algorithm based on ejection chains to solve the space-free multi-row facility layout problem. The aim of this problem is to find a non-overlapping layout of facilities on a given number of rows such that there is no space between two adjacent facilities. In addition, the left-most facility of the arrangement must have zero abscissa. Our algorithm looks for a local optimal solution by continuously alternating ejection moves and trial moves to form an ejection chain. Since the ejection chain can compound simple moves to create more complex and powerful moves, it has a greater chance to discover better solutions. Additionally, we propose a directional perturbation strategy to produce a solution of both high quality and good diversity. The idea is to calculate the score of each facility based on the location concentration of facilities in the elite solution set and the historical perturbation times of facilities in the search process, and to select the facility with the highest score for perturbation. Experimental results on four benchmark sets containing a total of 290 instances reveal that the proposed algorithm performs better for 131 (45.2%) instances in terms of best solution values and for 196 (80.0%) instances in terms of average solution values than a recently reported state-of-the-art algorithm.},
  archive      = {J_EJOR},
  author       = {Song Wu and Wei Yang and Saïd Hanafi and Christophe Wilbaut and Yang Wang},
  doi          = {10.1016/j.ejor.2024.03.012},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {873-886},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Iterated local search with ejection chains for the space-free multi-row facility layout problem},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A branch-and-price algorithm for unrelated parallel machine
scheduling with machine usage costs. <em>EJOR</em>, <em>316</em>(3),
856–872. (<a href="https://doi.org/10.1016/j.ejor.2024.03.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers unrelated parallel machine scheduling involving machine usage costs, in addition to classic job completion time-related costs. The usage cost of each machine is made up of a fixed usage cost and a variable usage cost proportional to the total processing time of the jobs assigned to it. These features model many practical situations where machine usage costs include, for example, rental fees when the machines are not owned but rented. To tackle this problem, four mathematical models based on the Shortest Weighted Processing Time (SWPT) rule are introduced. Additionally, the problem is formulated into a set-partitioning model, for which a branch-and-price algorithm is proposed with an appropriate branching strategy. This facilitates the development of an efficient pseudo-polynomial dynamic programming algorithm and a polynomial-time heuristic to solve the pricing problem. Extensive numerical experiments demonstrate the superior performance of the proposed branch-and-price algorithm over the four SWPT-based mathematical formulations and an existing branch-and-price algorithm designed for a special case. Notably, it can optimally solve instances involving up to 225 jobs and 15 machines within one hour. Moreover, statistical analyses reveal that the proposed polynomial-time heuristic significantly reduces the computation time, and the mathematical model based on the contribution of every job to the total weighted completion time exhibits the best overall performance.},
  archive      = {J_EJOR},
  author       = {Jianfu Chen and Chengbin Chu and Abderrahim Sahli and Kai Li},
  doi          = {10.1016/j.ejor.2024.03.011},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {856-872},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A branch-and-price algorithm for unrelated parallel machine scheduling with machine usage costs},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bike rebalancing: How to find a balanced matching in the k
center problem? <em>EJOR</em>, <em>316</em>(3), 845–855. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the bike-sharing system, inspired by the problem proposed by O’Mahony and Shmoys (AAAI 2015), we present a new model called the balanced k k center problem with matching constraints. Given a network containing the same number of two types of points, supply points and demand points, we aim to allocate k k (supply) centers for supply points, and k k (demand) centers for demand points. The k k supply centers should be perfectly matched with the k k demand centers, within an allowed distance. The goal is to minimize the maximum distance from each supply (or demand) point to its closest supply (or demand) centers. The model is motivated by the real-world application in rebalancing bikes, where the bikes are collected in supply centers, and delivered to the matched demand centers, and then distributed from there to serve their demand vertices. Therefore, to successfully complete this rebalancing procedure, two matched groups must have the same number of points. Otherwise, the bikes collected at the supply center may not be enough to serve the demand stations assigned to the demand center. To fully capture the problem, we bring an identical restriction L L , which restricts the exact number of vertices assigned to a single center. As a result, all matched centers must serve the same number of bikes. Hence, they are balanced. Our main result is a 9 approximation algorithm. The algorithm is built on the technique called transfer preserving network that successfully combines the approach for the capacitated k k center problem with the maximum flow network.},
  archive      = {J_EJOR},
  author       = {Jinxiang Gan and Guochuan Zhang and Yuhao Zhang},
  doi          = {10.1016/j.ejor.2024.03.009},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {845-855},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bike rebalancing: How to find a balanced matching in the k center problem?},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hub location with congestion and time-sensitive demand.
<em>EJOR</em>, <em>316</em>(3), 828–844. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work studies the effect of hub congestion and time-sensitive demand on a hub-and-spoke location/allocation system. The Hub Location with Congestion and Time-sensitive Demand Problem is introduced, which combines these two main characteristics. On the one hand, hubs can be activated at several service levels, each of them characterized by a maximum capacity, expressed as the amount of flow that may circulate through the hub, which is associated with a hub transit time. On the other hand, alternative levels are available for served commodities, where each demand level is characterized by its amount of demand, unit revenue, and maximum service time. In this problem the efficiency of a hub-and-spoke system is given by the maximum net profit it may produce. To the best of our knowledge this is the first work where hub congestion and time-sensitive demand are jointly considered. Two alternative mixed-integer linear programming formulations are proposed. They include a new set of constraints, which are necessary to guarantee the consistency of the obtained solutions under the presence of the capacity-type constraints derived from hub service levels and served demand levels. The efficiency of the formulations is analyzed through a set of computational experiments. The results of the computational experiments allow to study the structure of the obtained solutions and to analyze how the different parameters affect them.},
  archive      = {J_EJOR},
  author       = {Carmen-Ana Domínguez-Bravo and Elena Fernández and Armin Lüer-Villagra},
  doi          = {10.1016/j.ejor.2024.03.007},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {828-844},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Hub location with congestion and time-sensitive demand},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A genetic algorithm for the resource-constrained project
scheduling problem with alternative subgraphs using a boolean
satisfiability solver. <em>EJOR</em>, <em>316</em>(3), 815–827. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study evaluates a new solution approach for the Resource-Constrained Project Scheduling with Alternative Subgraphs (RCPSP-AS) in case that complex relations (i.e. nested and linked alternatives) are considered. In the RCPSP-AS, the project activity structure is extended with alternative activity sequences. This implies that only a subset of all activities should be scheduled, which corresponds with a set of activities in the project network that model an alternative execution mode for a work package. Since only the selected activities should be scheduled, the RCPSP-AS comes down to a traditional RCPSP problem when the selection subproblem is solved. It is known that the RCPSP and, hence, its extension to the RCPSP-AS is NP-hard. Since similar scheduling and selection subproblems have already been successfully solved by satisfiability (SAT) solvers in the existing literature, we aim to test the performance of a GA-SAT approach that is derived from the literature and adjusted to be able to deal with the problem-specific constraints of the RCPSP-AS. Computational results on small- and large-scale instances (both artificial and empirical) show that the algorithm can compete with existing metaheuristic algorithms from the literature. Also, the performance is compared with an exact mathematical solver and learning behaviour is observed and analysed. This research again validates the broad applicability of SAT solvers as well as the need to search for better and more suited algorithms for the RCPSP-AS and its extensions.},
  archive      = {J_EJOR},
  author       = {Tom Servranckx and José Coelho and Mario Vanhoucke},
  doi          = {10.1016/j.ejor.2024.02.041},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {815-827},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A genetic algorithm for the resource-constrained project scheduling problem with alternative subgraphs using a boolean satisfiability solver},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Operational research for, with, and by citizens: An
overview. <em>EJOR</em>, <em>316</em>(3), 800–814. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interest in citizen participation is increasing generally. Almost all operational research (OR) is engaged with clients, but it is mainly in the areas of Soft and Community OR that wider stakeholder and citizen participation has been a significant focus. It is the involvement of citizens that is the subject of this paper. We surveyed OR literature and compiled a corpus of 62 studies, the earliest from 1970, to systematically characterize the involvement of citizens in OR processes. Our review produced three findings: First, some fields of OR have embraced citizen participation, but this is not yet a major concern outside the field of Community OR. Second, citizen participation in OR processes is often driven by a moral rationale. Third, progress in information and communication technology (ICT) enables broad participation, but traditional processes requiring physical presence can also be participatory. From these insights, we formulate research opportunities for OR. (1) OR may join Community OR&#39;s endeavor to engage with and empower citizens who have so far rarely been involved in OR processes. (2) OR may identify benefits and drawbacks of digital OR processes in empirical studies. (3) OR may determine whether involving large numbers of citizens is suitable for the societal scale. (4) OR may research building and maintaining trust. (5) OR may join efforts for data protection of participants. (6) OR may systematically report and reflect on participatory OR processes. (7) OR should continue researching the fair aggregation of individual inputs. Citizen participation in OR is topical and challenging. Pursuing these research opportunities will contribute to OR fulfilling its mandate of better decision-making in close cooperation with all affected stakeholders.},
  archive      = {J_EJOR},
  author       = {Alice H. Aubert and Judit Lienert},
  doi          = {10.1016/j.ejor.2023.10.037},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {800-814},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Operational research for, with, and by citizens: An overview},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 2024 editors’ awards for excellence in reviewing.
<em>EJOR</em>, <em>316</em>(3), 799. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Roman Słowiński Co-ordinating Editor},
  doi          = {10.1016/j.ejor.2024.03.037},
  journal      = {European Journal of Operational Research},
  month        = {8},
  number       = {3},
  pages        = {799},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {2024 editors’ awards for excellence in reviewing},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Corrigendum to “a new formulation and a branch-and-cut
algorithm for the set orienteering problem” [european journal of
operational research, volume 314, issue 2, 16 april 2024, pages
446-465]. <em>EJOR</em>, <em>316</em>(2), 798. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {C. Archetti and F. Carrabs and R. Cerulli and F. Laureana},
  doi          = {10.1016/j.ejor.2024.03.019},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {798},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Corrigendum to “A new formulation and a branch-and-cut algorithm for the set orienteering problem” [European journal of operational research, volume 314, issue 2, 16 april 2024, pages 446-465]},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A note on steuer and utz’s (2023) multi-objective
optimization approach for generating sustainability-efficient fronts.
<em>EJOR</em>, <em>316</em>(2), 792–797. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the increasing importance of sustainability in investing, Steuer and Utz (2023) propose a new approach for integrating environmental, social and governance (ESG) scores into the portfolio selection process. These authors claim that their multi-objective portfolio optimization problem always provides mean-variance-ESG-efficient solutions because it belongs to the class of ϵ ϵ -constraint problems. Contending that this classification is problematic, we show that the developed approach cannot guarantee efficient portfolios.},
  archive      = {J_EJOR},
  author       = {Marcel Marohn and Benjamin R. Auer},
  doi          = {10.1016/j.ejor.2024.03.023},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {792-797},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A note on steuer and utz’s (2023) multi-objective optimization approach for generating sustainability-efficient fronts},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Clinical site selection problems with probabilistic
constraints. <em>EJOR</em>, <em>316</em>(2), 779–791. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recruiting candidates globally and across multiple sites in different geographic regions is necessary to speed up the enrollment of clinical trials. While patient enrollment can benefit from this globalization, initiating clinical trials has become much more complicated. In the start-up stage, the sites must be selected out of a set of potential candidates around the globe based on the specifics of those clinical trials, such as protocols, operational costs, and recruitment deadlines. Sites in one region can be very distinct from sites in another area. Yet, a common mistake in selecting sites is to rely on too little knowledge or subjective data. Poor selection decisions can lead to study delays and prolong the time to market for life-saving treatments. Thus, this paper proposes a novel framework to aid the decision-making in the global site selection problem (GSSP). To ensure that our framework accurately captures the uncertainty in recruitment time, we adopt a risk-based constraint that accounts for random patient enrollment. The extensive computational studies help quantify significant time-cost trade-offs as a potential solution to control the costs of conducting a trial.},
  archive      = {J_EJOR},
  author       = {Anh Ninh and Yunhong Bao and Daniel McGibney and Tuan Nguyen},
  doi          = {10.1016/j.ejor.2024.03.013},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {779-791},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Clinical site selection problems with probabilistic constraints},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Schedule situations and their cooperative game theoretic
representations. <em>EJOR</em>, <em>316</em>(2), 767–778. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we optimize and allocate the costs of a non-rival common-pool resource among several users. In such a so-called schedule situation the players have different demands given by distinct subsets of periods satisfying their needs. The total costs resulting from shared use of the resource are allocated by natural allocations called Equal Pooling allocations, in which the cost of each needed period is shared equally among the users of this period. The associated schedule game gives, for each coalition of players, the minimal cost of a period configuration satisfying the needs of all its members. We have three main contributions. First, we provide several sufficient conditions for the non-emptiness of the core of a schedule game. Second, we prove that under some of these conditions the Shapley value is in the core and coincides with some Equal pooling allocation. Third, we establish connections with other classes of operational research games. Furthermore, we present an application to the allocation of the common costs of the mail carrier route of La Poste, the french postal operator.},
  archive      = {J_EJOR},
  author       = {Léa Munich},
  doi          = {10.1016/j.ejor.2024.02.012},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {767-778},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Schedule situations and their cooperative game theoretic representations},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Monotonicity of equilibria in nonatomic congestion games.
<em>EJOR</em>, <em>316</em>(2), 754–766. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the monotonicity of equilibrium costs and equilibrium loads in nonatomic congestion games, in response to variations of the demands. The main goal is to identify conditions under which a paradoxical non-monotone behavior can be excluded. In contrast with routing games with a single commodity, where the network topology is the sole determinant factor for monotonicity, for general congestion games with multiple commodities the structure of the strategy sets plays a crucial role. We frame our study in the general setting of congestion games, with a special focus on singleton congestion games, for which we establish the monotonicity of equilibrium loads with respect to every demand. We then provide conditions for comonotonicity of the equilibrium loads, i.e., we investigate when they jointly increase or decrease after variations of the demands. We finally extend our study from singleton congestion games to the larger class of constrained series–parallel congestion games, whose structure is reminiscent of the concept of a series–parallel network.},
  archive      = {J_EJOR},
  author       = {Roberto Cominetti and Valerio Dose and Marco Scarsini},
  doi          = {10.1016/j.ejor.2024.01.050},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {754-766},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Monotonicity of equilibria in nonatomic congestion games},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An image convolution-based method for the irregular stone
packing problem in masonry wall construction. <em>EJOR</em>,
<em>316</em>(2), 733–753. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of natural stones as building material can help reducing the carbon footprint of the construction industry. However, their non-uniform shapes makes the construction of stone masonry structures challenging. Therefore, the development of efficient algorithms for the stacking of irregular stones obeying structural and architectonic requirements is essential. In this paper, we propose an image-based method for automating the stacking of non-uniform stones in the construction of 2D load-resistant stone masonry walls. Stone wedging, a traditional technique employed by skilled masons, is implemented to reinforce the stability of stone placements. We use image processing for accelerating the stone selection and placement, and determine the wall’s resistance using a variational rigid-block modeling approach. It is demonstrated that the developed method is efficient and robust in challenging conditions. The analysis of the computational performance of the presented method shows that it is suitable for automated construction.},
  archive      = {J_EJOR},
  author       = {Qianqing Wang and Bryan German Pantoja-Rosero and Ketson R.M. dos Santos and Katrin Beyer},
  doi          = {10.1016/j.ejor.2024.01.037},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {733-753},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An image convolution-based method for the irregular stone packing problem in masonry wall construction},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving order picking efficiency through storage
assignment optimization in robotic mobile fulfillment systems.
<em>EJOR</em>, <em>316</em>(2), 718–732. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The order picking efficiency in robotic mobile fulfillment systems is not only determined by the order and rack processing sequences, but also by the product distribution on the racks. In this paper, we focus on long-term planning based on historical order data to identify the optimal distribution of SKUs on racks for order picking operation improvement. This product distribution problem is formulated as an integer linear program, with the goal of minimizing rack movements required to fulfill orders. We develop a solution procedure that takes into account both the affinity and frequency of products in the orders, as well as the corresponding performance of the order and rack sequencing. We evaluate the performance of the proposed method through comparisons with the theoretical optimal solution on manually generated small instances and with existing heuristic solutions on a large real-world order dataset provided by a major e-commerce company, demonstrating a significant improvement from using our algorithm.},
  archive      = {J_EJOR},
  author       = {Yanling Zhuang and Yun Zhou and Elkafi Hassini and Yufei Yuan and Xiangpei Hu},
  doi          = {10.1016/j.ejor.2024.02.025},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {718-732},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Improving order picking efficiency through storage assignment optimization in robotic mobile fulfillment systems},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The maximum length car sequencing problem. <em>EJOR</em>,
<em>316</em>(2), 707–717. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the maximum length car sequencing problem to support the assembly operations of a multinational automotive company. We propose an integer linear programming (ILP) formulation to schedule the maximum number of cars without violating the so-called option constraints. In addition, we present valid combinatorial lower and upper bounds, which can be calculated in less than 0.01 s, as well as binary and iterative search algorithms to solve the problem when good primal bounds are not readily available. To quickly obtain high-quality solutions, we devise an effective iterated local search algorithm, and we use the heuristic solutions as warm start to further enhance the performance of the exact methods. Computational results demonstrate that relatively low gaps were achieved for benchmark instances within a time limit of ten minutes. We also conducted an instance space analysis to identify the features that make the problem more difficult to solve. Moreover, the instances reflecting the company’s needs could be solved to optimality in less than a second. Finally, simulations with real-world demands, divided into shifts, were conducted over a period of four months. In this case, we use the proposed ILP model in all shifts except the last one of each month, for which we employ an alternative ILP model to sequence the unscheduled cars, adjusting the pace of the assembly line in an optimal fashion. The results pointed out that the latter was necessary in only one of the months.},
  archive      = {J_EJOR},
  author       = {Lara Pontes and Carlos Neves and Anand Subramanian and Maria Battarra},
  doi          = {10.1016/j.ejor.2024.02.024},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {707-717},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The maximum length car sequencing problem},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust insurance design with distortion risk measures.
<em>EJOR</em>, <em>316</em>(2), 694–706. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the optimal insurance problem within the risk minimization framework and from a policyholder’s perspective. We assume that the decision maker (DM) is uncertain about the underlying distribution of her loss and considers all the distributions that are close to a given (benchmark) distribution, where the “closeness” is measured by the L 2 L2 or L 1 L1 distance. Under the expected-value premium principle, the DM picks the indemnity function that minimizes her risk exposure under the worst-case loss distribution. By assuming that the DM’s preferences are given by a convex distortion risk measure, we disentangle the structures of the optimal indemnity function and worst-case loss distribution in an analytical way, and provide the explicit forms for both of them under specific distortion risk measures. We also compare the results under the L 2 L2 distance and the first-order Wasserstein ( L 1 L1 ) distance. Some numerical examples are presented at the end to illustrate the implications of our main results.},
  archive      = {J_EJOR},
  author       = {Tim J. Boonen and Wenjun Jiang},
  doi          = {10.1016/j.ejor.2024.02.002},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {694-706},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust insurance design with distortion risk measures},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reconfiguration of inpatient services to reduce bed pressure
in hospitals. <em>EJOR</em>, <em>316</em>(2), 680–693. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare systems around the world are facing an inpatient bed crisis. This was highlighted more than ever during the recent COVID-19 pandemic. The consequences of bed shortage are substantial for both patients and staff. Finding innovative ways to improve the utilization of the existing bed base is therefore of significant importance. We focus on reconfiguration of inpatient services as a cost-effective solution to bed pressure in hospitals, and propose a comprehensive methodology for finding a low-cost configuration given a total number of beds, a set of specialties, and a finite or infinite waiting time threshold for patients. This involves developing novel approximations for performance evaluation of overflow delay and abandonment systems, and embedding them within heuristic search algorithms. We apply our reconfiguration methodology on inpatient data from a large UK hospital. Simulation experiments show that the configurations proposed by our methodology can result in significant savings compared to the existing configuration, and that a clustered overflow configuration is likely to produce the best results in many scenarios.},
  archive      = {J_EJOR},
  author       = {Navid Izady and Bahar Arabzadeh and Nicholas Sands and James Adams},
  doi          = {10.1016/j.ejor.2024.02.008},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {680-693},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Reconfiguration of inpatient services to reduce bed pressure in hospitals},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cost allocation problems on highways with grouped users.
<em>EJOR</em>, <em>316</em>(2), 667–679. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the practical applications of cooperative transferable utility games involves determining the fee structure for users of a given facility, whose construction or maintenance costs need to be recouped. In this context, certain efficiency and equity criteria guide the considered solutions. This paper analyzes how to allocate the fixed costs of a highway among its users through tolls, considering that different classes of vehicles or travelers utilize the service. For this purpose, we make use of generalized highway games with a priori unions that represent distinct user groups, such as frequent travelers or truckers, who, due to enhanced bargaining power, often secure reductions in their fares in real-world scenarios. In particular, the Owen value, the coalitional Tijs value, and a new value termed the Shapley–Tijs value are axiomatically characterized. Additionally, straightforward formulations for calculating these values are provided. Finally, the proposed methodology is applied to actual traffic data from the AP-9 highway in Spain.},
  archive      = {J_EJOR},
  author       = {Marcos Gómez-Rodríguez and Laura Davila-Pena and Balbina Casas-Méndez},
  doi          = {10.1016/j.ejor.2024.02.011},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {667-679},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cost allocation problems on highways with grouped users},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fishing policies in a supply chain with an organic
waste-based side stream. <em>EJOR</em>, <em>316</em>(2), 651–666. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organic waste resulting from fishing—consisting primarily of inedible fish parts and bycatch (non-target species) discarded during on-shore processing—is a source of substantial ecological concern. Researchers and practitioners are increasingly exploring how fishing supply chains can convert such waste into profitable products, towards benefiting the environment and the economy. The current study puts forward an optimal control model that addresses interactions between fishing practices, fish populations, and waste streams from fishing operations, with the aim of understanding how to achieve profitable and environmentally sustainable fishing practices. Although numerous models have been proposed for optimizing fish population management, ours is among the first to incorporate waste-processing dynamics, providing insight into how dynamic interactions between main-stream and side-stream supply chain operations can affect fishing policies and the overall ecosystem. We derive a necessary condition for sustainability of a “green” supply chain (i.e., one that incorporates side-stream processing) and determine the maximum fishing effort to ensure that a steady-state fish stock exists. We prove that when the cost of fish harvesting is negligible, a green supply chain (vs. a supply chain without side-stream processing) significantly reduces the rate of waste disposal but does not improve the stock of fish biomass. In a numerical analysis, we show that this result holds even when harvesting costs are high. The numerical analysis also shows that a sufficient increase in the marginal cost of fishing eliminates potential multiplicity of the steady states, thereby improving fish stock stability and ecosystem health.},
  archive      = {J_EJOR},
  author       = {Konstantin Kogan and Yael Perlman and Smadar Shatz},
  doi          = {10.1016/j.ejor.2024.02.014},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {651-666},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fishing policies in a supply chain with an organic waste-based side stream},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A general computational framework and a hybrid algorithm for
large-scale data envelopment analysis. <em>EJOR</em>, <em>316</em>(2),
639–650. (<a href="https://doi.org/10.1016/j.ejor.2024.01.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a new algorithm to accelerate DEA computation for large-scale datasets. We first provide a general DEA computation framework that employs a simple small-size linear program (LP). This LP can obtain all the critical outcomes simultaneously for accelerating DEA computation in the literature. Based on the general computational framework, we propose a new algorithm (called hybrid algorithm) that uses a hybrid strategy of density-increasing mechanism and reference set selection. The hybrid algorithm continuously solves the simple small-size LP to either identify an extreme efficient DMU or directly obtain the efficiency of the DMU under evaluation. To ensure the LPs solved are always in a small size, the hybrid algorithm selects the data of only a small subsample of the identified extreme efficient DMUs into the LPs’ coefficient matrix each time when a DMU is evaluated. A new subsample selection technique is also suggested. The numerical experiment shows that the new technique can select subsample of extreme efficient DMUs more effectively compared with the previous subsample selection technique. Consequently, the hybrid algorithm solves only one or a minuscule number of small-size LPs to obtain each DMU’s efficiency. Therefore, the hybrid algorithm ensures that the size and number of LPs solved for each DMU are small. The computational experiment on large datasets shows that the hybrid algorithm performs more than an order of magnitude faster than the existing representative algorithms.},
  archive      = {J_EJOR},
  author       = {Junfei Chu and Yuting Rui and Dariush Khezrimotlagh and Joe Zhu},
  doi          = {10.1016/j.ejor.2024.01.030},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {639-650},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A general computational framework and a hybrid algorithm for large-scale data envelopment analysis},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Competitive pricing and advertising strategies for online
retailers with “showrooming” and “webrooming.” <em>EJOR</em>,
<em>316</em>(2), 617–638. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, customers’ showrooming and webrooming behaviors, namely, gathering information offline/online and purchasing online/offline, have become common practices. Focusing on the effect of showrooming and webrooming, we develop a generic model that captures channel switching behavior by customers and analyzes the decisions by the online retailer and offline store. We consider regular/non-regular customers in the unified model and find that different groups of customers exhibit different channel switching behaviors. In particular, regular customers are more likely to switch since they won&#39;t incur a learning cost. We demonstrate that showrooming and webrooming affect the online retailer&#39;s profit negatively since the online retailer needs to decrease its price to attract new customers. Also, the online retailer&#39;s advertising efforts should be adjusted conversely in showrooming and webrooming cases. Next, we extend our basic model by considering a return policy and a flexible target capability for online retailers and show that these strategies may improve online retailer&#39;s profit under showrooming and webrooming. Last, but not the least, we consider another extension that allows showrooming and webrooming to arise simultaneously, namely dual-rooming. We find that the dual-rooming behavior still hurts the online retailer. Our main results are found to be robust in several model extensions. The paper has provided several insights into online retailer&#39;s price and advertising strategies.},
  archive      = {J_EJOR},
  author       = {Xiang He and Michael Z.F. Li and Li Li and Jing Li and Jiao Hu},
  doi          = {10.1016/j.ejor.2024.02.001},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {617-638},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Competitive pricing and advertising strategies for online retailers with “showrooming” and “webrooming”},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A variable neighborhood search for the green vehicle routing
problem with two-dimensional loading constraints and split delivery.
<em>EJOR</em>, <em>316</em>(2), 597–616. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the Green Vehicle Routing Problem with Two-Dimensional Loading Constraints and Split Delivery (G2L-SDVRP), which extends the split delivery vehicle routing problem to include customer demands represented by two-dimensional, rectangular items. We aim to minimize carbon dioxide (CO 2 2 ) emissions instead of travel distance, a critical issue in contemporary logistics activities. The CO 2 2 emission rate is proportional to fuel consumption and measured in terms of the vehicle’s total weight and traveled distance. We propose the first metaheuristic for the G2L-SDVRP, based on a variable neighborhood search approach that designs effective routes and guarantees the feasibility of loading constraints using various strategies, such as lower bound procedures, the open space heuristic, and a constraint programming model. We evaluate the performance of our approach through computational experiments using benchmark and newly created instances. The results indicate that the proposed approach is effective. It achieves improved solutions for 21 out of 60 instances in relatively short computing times when compared to existing methods for the G2L-SDVRP. Furthermore, our approach is competitive on benchmark instances of a related variant, namely the Capacitated Vehicle Routing Problem with Two-Dimensional Loading Constraints, improving the best-known solutions for 50 out of 180 instances.},
  archive      = {J_EJOR},
  author       = {Kamyla Maria Ferreira and Thiago Alves de Queiroz and Pedro Munari and Franklina Maria Bragion Toledo},
  doi          = {10.1016/j.ejor.2024.01.049},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {597-616},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A variable neighborhood search for the green vehicle routing problem with two-dimensional loading constraints and split delivery},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 3D dynamic heterogeneous robotic palletization problem.
<em>EJOR</em>, <em>316</em>(2), 584–596. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a practical robotic packing system to automate packing heterogeneous carton boxes into pallets, which is still handled manually in many distribution centers. The main challenge is to solve a 3D dynamic heterogeneous robotic palletization (DHRP) problem. Aside from the NP-completeness, there are two additional complexities in DHRP. First, the packing plan must be executable by a robotic arm without collision. Second, the packing decision must be made in real time with partial information. Tractable models are proposed to avoid collision for a common type of robotic arm and ensure the stability of the packing layout. An efficient algorithm is proposed to compute collision-free trajectories of the robotic arm during packing operations, which is embedded into a tree search algorithm to solve the semi-online counterpart of DHRP. Our semi-online algorithm is extended to solve the online version by adopting a Monte Carlo simulation strategy. A comprehensive set of test cases is generated based on realistic data to measure the performance of our algorithm. Numerical experiments show that our algorithm can produce feasible packing decisions in a few seconds for each incoming box on a modest personal computer, which is adequate for many practical setups. To help practitioners select the best setup for their application, numerical experiments are also conducted to analyze the impact of a few key design parameters in a robotic packing system on packing performance.},
  archive      = {J_EJOR},
  author       = {Wenbin Zhu and Ying Fu and You Zhou},
  doi          = {10.1016/j.ejor.2024.02.007},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {584-596},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {3D dynamic heterogeneous robotic palletization problem},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing stability and robustness in online machine shop
scheduling: A multi-agent system and negotiation-based approach for
handling machine downtime in industry 4.0. <em>EJOR</em>,
<em>316</em>(2), 569–583. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous factories require high levels of adaptability, flexibility, and resilience to react to uncertainties on the shop floor, such as machine downtime. This paper proposes a negotiation-based, partial rescheduling method, combined with an existing multi-agent system, to swap jobs between machines. The negotiations are restricted to machines within the same work center, giving rise to a partial reschedule. A learning algorithm is also utilized, allowing machines to individually learn how to evaluate proposed bids from other machines and adapt the bids to their current environment. The main objective is to minimize the mean weighted tardiness of all jobs. Computational results indicate an improvement of 10–30 tardiness, compared to continuous rescheduling and complete rescheduling methods. In addition, a decrease of 70–80 sensitivity analysis and analysis of the partial reschedule.},
  archive      = {J_EJOR},
  author       = {Jeroen B.H.C. Didden and Quang-Vinh Dang and Ivo J.B.F. Adan},
  doi          = {10.1016/j.ejor.2024.02.006},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {569-583},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Enhancing stability and robustness in online machine shop scheduling: A multi-agent system and negotiation-based approach for handling machine downtime in industry 4.0},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rethinking cyclic structures in liner shipping networks.
<em>EJOR</em>, <em>316</em>(2), 556–568. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liner shipping networks are a central feature of modern supply chains that consist of cyclical, periodic services operated by container vessels. This specialized, cyclical structure eases planning for both shipper and carrier, but the combination of cyclical planning with the available time windows at ports can lead to inefficient operations. We propose to relax the cyclical assumption and allow vessels to move between services to avoid inefficient connections without interruption to container flows. From the view of a shipper, the cyclical and periodic properties of the services still hold, and the liner carrier can offer a more efficient overall network. The ensuing optimization problem consists of a combined vessel routing problem and cargo allocation problem, resulting in large and challenging instances. We model the problem using mixed-integer linear programming and use an expanding horizon heuristic to find starting solutions for our model. We use real-world data to show that giving flexibility to a liner network can result in a significant cost reduction over standard cyclical schedules.},
  archive      = {J_EJOR},
  author       = {Daniel Wetzel and Kevin Tierney},
  doi          = {10.1016/j.ejor.2024.01.035},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {556-568},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Rethinking cyclic structures in liner shipping networks},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Managing industry 4.0 supply chains with innovative and
traditional products: Contract cessation points and value of
information. <em>EJOR</em>, <em>316</em>(2), 539–555. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In supply chain management, how contract designs relate to the production system with traditional and Industry 4.0 innovative products (I4I products) is under-explored. In this paper, we fill this literature gap by studying a two-period model in which a manufacturer strategically chooses to incorporate an I4I product line into a traditional product line. In this context, we show that there exists a critical market potential threshold above which the sale of the I4I product is higher than that of the traditional product even when the former is sold at a higher price. For both wholesale price and linear two-part tariff contracts, we show that the contract cessation points and critical market potential threshold behave oppositely. We also find that the innovation level for the I4I product would be higher when the manufacturer’s expected valuation towards the retailer’s cost is higher than the actual one. We extend our base model to demonstrate that the innovation level of the I4I product is higher when the manufacturer uses a linear two-part tariff contract instead of a wholesale price contract. Finally, we uncover that the quantity-dependent innovation investment results in increased profitability and innovation level for the manufacturer provided that the innovation investment coefficient is sufficiently high.},
  archive      = {J_EJOR},
  author       = {Indranil Biswas and Gurmeet Singh and Sunil Tiwari and Tsan-Ming Choi and Shivanee Pethe},
  doi          = {10.1016/j.ejor.2024.01.047},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {539-555},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Managing industry 4.0 supply chains with innovative and traditional products: Contract cessation points and value of information},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mixed-integer linear programming formulations and column
generation algorithms for the minimum normalized cuts problem on
networks. <em>EJOR</em>, <em>316</em>(2), 519–538. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the k k -way normalized cut problem in complex networks. It presents a methodology that uses mathematical optimization to provide mixed-integer linear programming formulations for the problem. The paper also develops a branch-and-price algorithm for the above-mentioned problem which scales better than the compact formulations. Additionally, a heuristic algorithm which is able to approximate large-scale image problems in those cases where the exact methods are not applicable is presented. Extensive computational experiments assess the usefulness of these methods to solve the k k -way normalized cut problem. Finally, we have applied the minimum normalized cut objective function to the segmentation of actual images, showing the applicability of the introduced methodology.},
  archive      = {J_EJOR},
  author       = {Diego Ponce and Justo Puerto and Francisco Temprano},
  doi          = {10.1016/j.ejor.2024.02.033},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {519-538},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mixed-integer linear programming formulations and column generation algorithms for the minimum normalized cuts problem on networks},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis of the impact of corrective actions for stochastic
project networks. <em>EJOR</em>, <em>316</em>(2), 503–518. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In project management, a project plan is constructed that assigns a planned start time to each project activity. Based on this plan, the total planned project duration and cost can be determined. However, during project execution, deviations from the plan are inevitable due to uncertainty and variability. When these deviations endanger the timely completion of projects, the project manager should take corrective actions to get the project back on track. In this study, corrective actions are modelled as modifications of the original activity duration distributions (i.e., reduced mean and/or standard deviation) to account for the uncertain nature of their impact. Further, an analytical procedure is developed to rank activities according to their expected impact on the project duration distribution when they are controlled by a corrective action. This activity ranking is used to determine the number of actions that should be taken and to select the set of activities that will be controlled. A computational experiment on a large set of project networks with varying network complexity and network structures has been conducted. These experiments have shown that taking actions on a relatively small subset of activities, rather than on the entire set of project activities, proves more efficient, when the subset of activities is carefully selected. More precisely, the efficiency of the corrective actions process depends on both the number of actions and the activity selection criterion (activity ranking).},
  archive      = {J_EJOR},
  author       = {Forough Vaseghi and Annelies Martens and Mario Vanhoucke},
  doi          = {10.1016/j.ejor.2024.02.040},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {503-518},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Analysis of the impact of corrective actions for stochastic project networks},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The wildfire suppression problem with multiple types of
resources. <em>EJOR</em>, <em>316</em>(2), 488–502. (<a
href="https://doi.org/10.1016/j.ejor.2024.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The frequency and impact of wildfires have considerably increased in the past decade, due to the extreme weather conditions as well as the increased population density. The aim of this study is to introduce, model, and solve a wildfire suppression problem that involves multiple types of fire suppression resources and their operational characteristics. Two integer programming (IP) formulations, a basic IP and its reformulation with combinatorial Benders’ cuts, are presented. The performances of the proposed formulations are evaluated on a set of randomly generated instances. The results indicate that the proposed formulations are able to obtain high quality upper and lower bounds. Extensive numerical experiments are performed to analyse the effects of several operational constraints on the computational performance of the models. A case study arising in Yatağan district of Muğla province of Türkiye is presented.},
  archive      = {J_EJOR},
  author       = {Mualla Gonca Avci and Mustafa Avci and Maria Battarra and Güneş Erdoğan},
  doi          = {10.1016/j.ejor.2024.03.005},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {488-502},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The wildfire suppression problem with multiple types of resources},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The hamiltonian p-median problem: Polyhedral results and
branch-and-cut algorithms. <em>EJOR</em>, <em>316</em>(2), 473–487. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study the Hamiltonian p p -median problem, in which we are given an edge-weighted graph and we are asked to determine p p vertex-disjoint cycles spanning all vertices of the graph and having minimum total weight. We introduce two new families of valid inequalities for a formulation of the problem in the space of edge variables. Each one of the families forbids solutions to the 2-factor relaxation of the problem that have less than p p cycles. The inequalities in one of the families are associated with large cycles of the underlying graph and generalize known inequalities associated with Hamiltonian cycles. The other family involves inequalities for the case with p = n / 3 p=n/3 , associated with edge cuts and multi-cuts whose shores have specific cardinalities. We identify inequalities from both families that define facets of the polytope associated with the problem. We design branch-and-cut algorithms based on these families of inequalities and on inequalities associated with 2-opt moves removing sub-optimal solutions. Computational experiments on benchmark instances show that the proposed algorithms exhibit a comparable performance with respect to existing exact methods from the literature. Moreover the algorithms solve to optimality new instances with up to 400 vertices.},
  archive      = {J_EJOR},
  author       = {Michele Barbato and Luís Gouveia},
  doi          = {10.1016/j.ejor.2024.02.032},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {473-487},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The hamiltonian p-median problem: Polyhedral results and branch-and-cut algorithms},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Order consolidation in warehouses: The loop sorter
scheduling problem. <em>EJOR</em>, <em>316</em>(2), 459–472. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To meet today’s ambitious order throughput targets, many distribution centers, especially those operated by online retailers, apply batching and zoning in their picker-to-parts warehouses. These order retrieval policies improve the pick density per tour by unifying multiple customer orders to larger pick lists and allow a parallelization of the picking process among multiple zones, respectively. The price for this is an additional consolidation stage, where picked products must be sorted according to customer orders, typically with the help of a sortation conveyor. In this context, we treat the loop sorter scheduling problem, which is defined as follows. Once a wave of orders, picked concurrently in multiple zones, has been inducted onto a closed-loop sorter, we have to assign the products that refer to the same stock keeping units (SKUs) to orders and orders to packing lanes, where they are prepared for shipping. Furthermore, we have to decide on the sequence in which the orders are channeled into their packing lanes. Our aim is to minimize the makespan until all orders of the current wave are readily sorted. We formulate the loop sorter scheduling problem, investigate computational complexity, and derive suitable solution algorithms. One important finding of our computational study is that simple priority rules, which are frequently applied in real-world warehouses and previous research, waste significant optimization potential.},
  archive      = {J_EJOR},
  author       = {Nils Boysen and Konrad Stephan and Stefan Schwerdfeger},
  doi          = {10.1016/j.ejor.2024.02.042},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {459-472},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Order consolidation in warehouses: The loop sorter scheduling problem},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scheduling with cardinality dependent unavailability
periods. <em>EJOR</em>, <em>316</em>(2), 443–458. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider non-preemptive scheduling problems on parallel identical machines where machines change their status from being available to being unavailable and vice versa along the time horizon. The particular form of unavailability we consider is when the starting time of each downtime depends upon the cardinality of the job subset processed on that machine since the previous downtime. We consider the problem of minimizing the makespan in such scenarios as well as its dual problem where we have a fixed common deadline of 1 and the goal is to minimize the number of machines for which there is a feasible schedule. We develop an EPTAS for the first variant and an AFPTAS for the second variant.},
  archive      = {J_EJOR},
  author       = {G. Jaykrishnan and Asaf Levin},
  doi          = {10.1016/j.ejor.2024.02.038},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {443-458},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Scheduling with cardinality dependent unavailability periods},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New exact and heuristic algorithms for general production
and delivery integration. <em>EJOR</em>, <em>316</em>(2), 419–442. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study considers a general production and delivery integration problem, commonly faced by a manufacturer that adopts make-to-order and commit-to-delivery business strategies. In the problem, the manufacturer determines acceptance or rejection of customers, produces products for accepted customers, and cooperates with third-party logistics providers who offer multiple shipping modes chosen by the manufacturer to deliver the finished products to customers. To better reflect the practical needs, this problem takes into account nonlinear production cost functions, nonlinear earliness and tardiness penalty functions, and nonlinear shipping cost functions of both shipping time and shipping quantity. The problem is to determine an integrated customer acceptance, production, and delivery plan by minimizing the total cost of production, shipping and inventory holding, and the total penalty of rejection, earliness, and tardiness. We investigate two variants of the problem where splittable delivery for the orders from customers is allowed and where splittable delivery is not allowed. For both the variants, we develop exact algorithms which achieve pseudo-polynomial running time in some practical situations, and design column generation-based heuristic algorithms to find near-optimal solutions efficiently. The computational results demonstrate that the heuristic algorithms are capable of generating near-optimal solutions for the instances generated randomly, with average optimality gap less than 4% in a reasonable running time.},
  archive      = {J_EJOR},
  author       = {Xianyan Yang and Feng Li and Zhixue Liu and Zhou Xu},
  doi          = {10.1016/j.ejor.2024.02.005},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {419-442},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {New exact and heuristic algorithms for general production and delivery integration},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Facility location decisions for drone delivery: A literature
review. <em>EJOR</em>, <em>316</em>(2), 397–418. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a comprehensive literature survey on facility location problems for drone (uncrewed vehicle) delivery, where either (i) drones are the only vehicles, or (ii) drones and other vehicles (e.g., trucks) work together for delivery, but drones do not ride in or on the other vehicles. The main goals of this review are to identify and categorize fundamental facility location problems associated with drone delivery, to document the large volume of research in this area, to provide a connection between the studies from different research fields that consider similar location problems, and to highlight promising areas for future research. We first discuss and classify the functions of drones and the various types of facilities used for drone and hybrid vehicle-drone (e.g., truck and drone, or transit and drone) delivery systems, including drone bases (fixed or temporary), other vehicle bases, recharging stations, (re)supply points, and platooning points. The literature is reviewed and categorized based on the types of vehicles involved and their interactions, the types of facilities located, the types of drones and the location space (discrete or continuous). Each category is analyzed in terms of the modeling approach, decision(s), the objective function(s), constraint(s) and additional feature(s). The paper concludes with some promising future research directions.},
  archive      = {J_EJOR},
  author       = {Okan Dukkanci and James F. Campbell and Bahar Y. Kara},
  doi          = {10.1016/j.ejor.2023.10.036},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {2},
  pages        = {397-418},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Facility location decisions for drone delivery: A literature review},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Selection of multi-criteria energy efficiency and emission
abatement portfolios in container terminals. <em>EJOR</em>,
<em>316</em>(1), 386–395. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Environmental protection, sustainability, and energy efficiency are important issues in seaport management. As the interface between sea and hinterland transport, container terminals play an important role in global trade, logistics, and supply chains. To increase sustainability and improve the environmental footprint of the terminal, a wide range of emission abatement measures are available. Often, however, there is not only a lack of a precise analysis of the impact, costs and consequences of the measures on the terminal, but also a lack of a methodology for the selection of a set of measures, i.e. for portfolio selection in environmental decisions. This paper presents an approach for multi-criteria portfolio selection to environmental decision problems. It is illustrated via an extensive case study for environmental sustainability measures in container terminals. Particularly, energy and emission abatement measures are assessed and used to construct a portfolio that improves the overall energy efficiency of the terminal. A modified PROMETHEE V approach is used to construct appropriate portfolios of measures based on the decision maker’s (DM’s) preferences and further interdependencies. PROMETHEE II is again used to decide on a portfolio.},
  archive      = {J_EJOR},
  author       = {Erik Pohl and Jutta Geldermann},
  doi          = {10.1016/j.ejor.2024.02.004},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {386-395},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Selection of multi-criteria energy efficiency and emission abatement portfolios in container terminals},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite maturity caps and floors on continuous flows under
the constant elasticity of variance process. <em>EJOR</em>,
<em>316</em>(1), 361–385. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper offers novel analytical solutions for evaluating perpetual caps and floors on continuous flows under the constant elasticity of variance (CEV) model. We demonstrate that the inclusion of a perpetual bubble value is required to avoid arbitrage opportunities in the case of the CEV process with upward-sloping volatility skews. We then extend the previous literature on caps and floors arrangements by providing new analytical formulae for valuing finite maturity caps and floors that are contingent on continuous flows. We discuss the impact of the finite-lived solutions on the optimal behavior of a firm, relative to the perpetual case. We also show the implications of the correct specification of the underlying state variable process for the valuation of caps and floors by comparing the CEV results with the ones obtained when assuming a lognormal diffusion. Practical applications of these contractual agreements arising within the context of executive management decisions are also discussed.},
  archive      = {J_EJOR},
  author       = {José Carlos Dias and João Pedro Vidal Nunes and Fernando Correia da Silva},
  doi          = {10.1016/j.ejor.2024.01.039},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {361-385},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Finite maturity caps and floors on continuous flows under the constant elasticity of variance process},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A data-driven approach for optimal operational and financial
commodity hedging. <em>EJOR</em>, <em>316</em>(1), 341–360. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Commodity price risk management has been subject to various modeling and optimization approaches. Recently, data-driven policies focusing on the decision rather than prediction quality have been developed to overcome price model misspecification. Yet, in the context of data-driven commodity purchasing, the existing literature either considers anticipatory inventory management or forward contracting where the decision frequency corresponds to the maturity of the traded contracts. We prove the optimality of a novel procurement policy combining operational and financial instruments with decision granularities independent of the derivative’s maturity. A mixed-integer programming model is developed to train policy parameters efficiently. We study the implications of policy complexity for learning-stability and out-of-sample generalization. Finally, we backtest the data-driven policy on real market data of four major commodities (i. e., copper, nickel, corn, and soybean) over ten years and show that the average savings potential of a combined financial and operational procurement policy compared to single-instrument strategies is up to 6.38 % for corn where warehousing can efficiently mitigate price seasonality. The approach hedges corn and soybean commodities more efficiently through inventories while copper and nickel can be hedged efficiently by leveraging available financial instruments. Best model results are identified for a decision granularity with fewer parameters as high-frequent decisions deteriorate learning stability and model generalization.},
  archive      = {J_EJOR},
  author       = {Moritz Rettinger and Christian Mandl and Stefan Minner},
  doi          = {10.1016/j.ejor.2024.01.026},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {341-360},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A data-driven approach for optimal operational and financial commodity hedging},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new integrated cooperative game and optimization model for
the allocation of forest resources. <em>EJOR</em>, <em>316</em>(1),
329–340. (<a href="https://doi.org/10.1016/j.ejor.2024.01.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an integrated approach combining a cooperative game model and a multi-objective optimization model to determine the quantities of forest resources to allocate to several mills. The new mechanism developed in this study is applied to a regional case study in the province of Quebec (Canada), where public-owned forest resources should be allocated by the government to multiple competing mills. Collaboration between mills is considered in the upstream supply chain (i.e., harvesting, road construction/upgrading, and transportation operations) as well as their individual sustainability performances (economic, environmental and social aspects) in the allocation process. Moreover, this approach highlights the conditions under which the allocation ensures the stability of the configuration of the coalitions through a coalitional stability analysis. The proposed approach attempts to capture collaboration benefits and mills’ individual performances in the allocation process, while promoting equity among them. The coalitions of the case study overlap and thus, the concept of coalition configuration value is used to measure the marginal contribution of each mill to the cost savings. In particular, a methodology is proposed for the estimation of this value based on real data. The results of this study demonstrate that the allocation honors the efforts made by mills, both individually and collectively. In addition, it stimulates them towards a sustainable resource management relationship.},
  archive      = {J_EJOR},
  author       = {Mahdi Rahmoune and Mohammed Said Radjef and Tasseda Boukherroub and Margarida Carvalho},
  doi          = {10.1016/j.ejor.2024.01.018},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {329-340},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new integrated cooperative game and optimization model for the allocation of forest resources},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rethinking urban quality of life: Unveiling causality links
using cognitive mapping, neutrosophic logic and DEMATEL. <em>EJOR</em>,
<em>316</em>(1), 310–328. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality of life (QoL) is an important issue that reflects changes around the world caused not only by human population density, growth, and related initiatives but also by crises and pandemics. Concurrently, people’s increasing tendency to live in urban areas has generated growing concerns about correctly assessing city QoL to facilitate the implementation of practical measures that favor both current and future generations’ well-being. Conducting accurate analyses in this context is a challenging endeavor due to the subjectivity and complexity intrinsic to QoL evaluations. Thus, this study develops a multicriteria model based on a constructivist and complementarity logic that helps decision makers evaluate urban QoL. The proposed analysis system combines cognitive mapping, neutrosophic logic, and the decision-making trial and evaluation laboratory (DEMATEL) method in order to address the limitations of previous studies. This model also enhances experts’ ability to decide which determining factors should be included in assessments of urban QoL. In addition, the system developed can help decision makers cope with uncertainty during evaluations because this holistic, realistic, and complete model fosters conscious decision making in urban contexts. The practical implications, advantages, and limitations of the proposed analysis system are also discussed.},
  archive      = {J_EJOR},
  author       = {Constança M.R.P. Vaz-Patto and Fernando A.F. Ferreira and Kannan Govindan and Neuza C.M.Q.F. Ferreira},
  doi          = {10.1016/j.ejor.2023.12.034},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {310-328},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Rethinking urban quality of life: Unveiling causality links using cognitive mapping, neutrosophic logic and DEMATEL},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-period time window assignment for attended home
delivery. <em>EJOR</em>, <em>316</em>(1), 295–309. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a multi-period stochastic variant of the Time Window Assignment Vehicle Routing Problem, where customers’ demands, locations, and service times are uncertain. Customers are partitioned into geographical zones, each of which has to be visited a predetermined number of times over a planning period of several days. Whenever a zone is visited, a time window is assigned. Time windows are decided before knowing customers and their demands. A fleet of homogeneous vehicles is available to serve customers each day. At a tactical level, the problem looks for a static time window assignment that minimizes the expected traveling costs plus the expected penalty costs for unserved customers. We propose a two-stage formulation and a solution approach, which relies on the Sample Average Approximation Method, while encompassing a perturbation method to assign time windows in the first stage and an Adaptive Large Neighborhood Search to optimize routes in the second stage. We experimentally evaluate three instance sets, including real ones from a Canadian company, comparing our results to lower bounds from the exact solution of a deterministic equivalent formulation over a finite number of scenarios. Our method outperforms the manual approach used by the company.},
  archive      = {J_EJOR},
  author       = {Jean-François Côté and Renata Mansini and Alice Raffaele},
  doi          = {10.1016/j.ejor.2024.01.021},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {295-309},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-period time window assignment for attended home delivery},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scheduling of parallel continuous annealing lines with
alternative processing modes to optimize efficiency under tardiness
constraints. <em>EJOR</em>, <em>316</em>(1), 282–294. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous annealing is a core process in steel cold-rolling facilities. It is used to set desired material properties by passing coils of flat steel through a high-temperature furnace in a precisely controlled manner. High efficiency is achieved by feeding the steel through the furnace in the form of a continuous strand. For this purpose, the coils are welded together before being fed into the furnace. Whenever two consecutive coils are incompatible, a special dummy coil called stringer is used to connect them, which reduces efficiency and adds costs and emissions. We consider the scheduling of coils with specific due dates and alternative order-specific processing modes on parallel heterogeneous lines. The problem is to simultaneously assign coils to lines and sequence them on these lines with a defined processing mode with adherence to tardiness constraints while minimizing the number of stringers needed. To address this problem, we formulate a mixed-integer linear program based on a model from the literature and propose a two-phase heuristic solution procedure. The procedure combines an opening phase using shortest path algorithms and local search with an improvement phase based on problem-specific decompositions according to the principles of an Fix-and-Optimize procedure. The results show that our heuristic outperforms a state-of-the-art commercial solver in finding good solutions in short computation time. Based on a sensitivity analysis for several industry-inspired data sets, we observe a trade-off between efficiency and tardiness which strongly depends on the operating conditions.},
  archive      = {J_EJOR},
  author       = {Sebastian Wegel and Anton Ivanov and Ralf Lenz and Thomas Volling},
  doi          = {10.1016/j.ejor.2023.12.032},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {282-294},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Scheduling of parallel continuous annealing lines with alternative processing modes to optimize efficiency under tardiness constraints},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Three-way decisions based multi-attribute decision-making
with utility and loss functions. <em>EJOR</em>, <em>316</em>(1),
268–281. (<a href="https://doi.org/10.1016/j.ejor.2024.01.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional multi-attribute decision-making (MADM) methods are based on two-way decisions (2WD), i.e., acceptance and rejection. In contrast, three-way decisions (3WD) add a deferred decision to effectively handle MADM problems by reducing decision risks. In the past 3WD models have been broadly explored considering losses and utilities associated with the decisions, but none of the studies considered loss and utility together. Also, the existing studies lack the influence of decision-makers on outcomes. Accordingly, this paper presents a novel 3WD model based on a similarity measure, integrating the hybrid information of MADM matrix, utility and loss values along with the influence of decision-makers. First, the two states are formed by the fuzzy c-mean clustering algorithm. Second, the similarity class for each alternative is constructed based on the Jaccard index. With reference to the equivalence classes formed, conditional probabilities are further calculated and 3WD decision rules are studied. Finally, considering both expected utility and losses associated with the alternatives we propose a novel 3WD model for solving MADM problems. The effectiveness of the proposed approach is demonstrated with the help of an illustrative example. The proposed 3WD-MADM model is further verified from different perceptions through comparative and experimental analysis.},
  archive      = {J_EJOR},
  author       = {Garima Bisht and A.K. Pal},
  doi          = {10.1016/j.ejor.2024.01.043},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {268-281},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Three-way decisions based multi-attribute decision-making with utility and loss functions},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A homothetic data generated technology. <em>EJOR</em>,
<em>316</em>(1), 255–267. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I propose a method for constructing an enlargement of a variable returns to scale production technology that will satisfy homotheticity. The method can be used both with DEA and FDH single output (or single input) technologies and it is computationally fast. The method is constructed by adding a restriction to the axiomatically delineated homothetic reference technologies which requires these reference technologies to be subsets of the minimal reference technology that satisfies constant returns to scale. Within this set it is possible to identify a homothetic technology that satisfies the property of minimum extrapolation.},
  archive      = {J_EJOR},
  author       = {Antonio Peyrache},
  doi          = {10.1016/j.ejor.2024.01.031},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {255-267},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A homothetic data generated technology},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inference for aggregate efficiency: Theory and guidelines
for practitioners. <em>EJOR</em>, <em>316</em>(1), 240–254. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We expand and develop further the recently developed framework for the inference about the aggregate efficiency, extending the existing theory and providing guidelines for practitioners. In Monte Carlo simulations, we thoroughly examine the performance of the various improvement methods (compared with the original CLT results) for the aggregate input-oriented and output-oriented efficiency for different ranges of small samples and different dimensions of the production model. From the simulations, we conclude that: (i) when the sample sizes are relatively small (around 200 and less), the full variance correction method (adapted from Simar et al., 2023) with the data sharpening method (adapted from Nguyen et al., 2022) generally provides a better performance; (ii) when the sample sizes are relatively large, the full variance correction method without the data sharpening method is expected to perform better than the other suitable methods known to date. Finally, we use two well-known empirical data sets to illustrate the practical implementations and the differences across the existing methods to facilitate their use by practitioners.},
  archive      = {J_EJOR},
  author       = {Léopold Simar and Valentin Zelenyuk and Shirong Zhao},
  doi          = {10.1016/j.ejor.2024.01.028},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {240-254},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Inference for aggregate efficiency: Theory and guidelines for practitioners},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A sequential benefit-of-the-doubt composite indicator.
<em>EJOR</em>, <em>316</em>(1), 228–239. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many contexts, performances are measured by aggregating indicators. To do so, practitioners have to choose how to normalize and weight the selected indicators. A popular method is the benefit-of-the-doubt (BoD) which constructs composite indicators based on relative weights and avoids normalization. When dealing with panel data, the BoD computes composite indicators using contemporaneous data only. A consequence is that composite indicators are over-estimated because the accumulation of best practices is ignored. Inspired by the production economics literature, we suggest new sequential composite indicators keeping the BoD spirit. These indicators are not based on contemporaneous data but include current and past information. By comparing the two approaches, we define the new concept of knowledge accumulation ratio. We use the sequential composite indicators to evaluate the vulnerability, readiness, and resilience to climate change of more than 180 countries over the 1995–2020 period. Our results highlight two main groups of countries: those with great need of new investments and an urgency for adaptation, and those well positioned but with some adaptation challenges.},
  archive      = {J_EJOR},
  author       = {Barnabé Walheer},
  doi          = {10.1016/j.ejor.2024.01.029},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {228-239},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A sequential benefit-of-the-doubt composite indicator},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Higher-order assortativity for directed weighted networks
and markov chains. <em>EJOR</em>, <em>316</em>(1), 215–227. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new class of assortativity measures for weighted and directed networks. We extend Newman’s classical degree–degree assortativity by considering node attributes other than degree, and we propose connections among nodes via directed walks of length greater than one, thus obtaining higher-order assortativity. We test the new measure in the paradigmatic case of the world trade network and for other networks from a socioeconomic context, and we also provide some simulation results. Importantly, we show how this global network indicator is strongly related to the autocorrelations of the states of a Markov chain.},
  archive      = {J_EJOR},
  author       = {Alberto Arcagni and Roy Cerqueti and Rosanna Grassi},
  doi          = {10.1016/j.ejor.2024.02.031},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {215-227},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Higher-order assortativity for directed weighted networks and markov chains},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the separation of estimation and control in
risk-sensitive investment problems under incomplete observation.
<em>EJOR</em>, <em>316</em>(1), 200–214. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A typical approach to tackle stochastic control problems with partial observation is to separate the control and estimation tasks. However, it is well known that this separation generally fails to deliver an actual optimal solution for risk-sensitive control problems. This paper investigates the separability of a general class of risk-sensitive investment management problems when a finite-dimensional filter exists. We show that the corresponding separated problem, where instead of the unobserved quantities, one considers their conditional filter distribution given the observations, is strictly equivalent to the original control problem. We widen the applicability of the so-called Modified Zakai Equation (MZE) for the study of the separated problem and prove that the MZE simplifies to a PDE in our approach. Furthermore, we derive criteria for separability. We do not solve the separated control problem but note that the existence of a finite-dimensional filter leads to a finite state space for the separated problem. Hence, the difficulty is equivalent to solving a complete observation risk-sensitive problem. Our results have implications for existing risk-sensitive investment management models with partial observations in that they establish their separability. Their implications for future research on new applications is mainly to provide conditions to ensure separability.},
  archive      = {J_EJOR},
  author       = {Sébastien Lleo and Wolfgang J. Runggaldier},
  doi          = {10.1016/j.ejor.2024.01.044},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {200-214},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the separation of estimation and control in risk-sensitive investment problems under incomplete observation},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stabilized benders decomposition for energy planning under
climate uncertainty. <em>EJOR</em>, <em>316</em>(1), 183–199. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper applies Benders decomposition to two-stage stochastic problems for energy planning under climate uncertainty, a key problem for the design of renewable energy systems. To improve performance, we adapt various refinements for Benders decomposition to the problem’s characteristics—a simple continuous master-problem, and few but large sub-problems. The primary focus is stabilization, specifically comparing established bundle methods to a quadratic trust-region approach for continuous problems. An extensive computational comparison shows that all stabilization methods can significantly reduce computation time. However, the quadratic trust-region and the linear box-step method are the most robust and straightforward to implement. When parallelized, the introduced algorithm outperforms the vanilla version of Benders decomposition by a factor of 100. In contrast to off-the-shelf solvers, computation time remains constant when the number of scenarios increases. In conclusion, the algorithm enables robust planning of renewable energy systems with a large number of climatic years. Beyond climate uncertainty, it can make an extensive range of other analyses in energy planning computationally tractable, for instance, endogenous learning and modeling to generate alternatives.},
  archive      = {J_EJOR},
  author       = {Leonard Göke and Felix Schmidt and Mario Kendziorski},
  doi          = {10.1016/j.ejor.2024.01.016},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {183-199},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stabilized benders decomposition for energy planning under climate uncertainty},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fleet resupply by drones for last-mile delivery.
<em>EJOR</em>, <em>316</em>(1), 168–182. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Vehicle Routing Problem with Release Dates and Drone Resupply consists of routing a fleet of trucks to deliver orders that arrive at a depot over time. During the delivery horizon, the trucks can return to the depot to collect newly arrived orders, or these orders can be resupplied to the trucks along their routes via drones dispatched from the depot. A Mixed-Integer Linear Programming (MILP) formulation is developed for the version of the problem where order arrival times at the depot (generally termed order release dates) are known beforehand. To address large-size instances, we devise a unified matheuristic approach that provides high-quality solutions for both the truck-and-drone and the truck-only versions of the problem. In this approach, truck routes are iteratively modified using a tabu search scheme, where a subordinate fast MILP model defines optimal loading operations (truck depot returns and drone resupplies) for promising truck routes. We perform extensive numerical experiments with instances of up to 100 customers. Results show the effectiveness of the matheuristic approach for solving both the truck-and-drone and the truck-only versions of the problem. We also show the benefits of drone resupply to reduce completion times and the number of times the trucks need to return to the depot to collect newly released orders. Furthermore, we provide several managerial insights regarding fleet utilization and consolidation.},
  archive      = {J_EJOR},
  author       = {Juan C. Pina-Pardo and Daniel F. Silva and Alice E. Smith and Ricardo A. Gatica},
  doi          = {10.1016/j.ejor.2024.01.045},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {168-182},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fleet resupply by drones for last-mile delivery},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive large neighborhood search heuristic for the
multi-port continuous berth allocation problem. <em>EJOR</em>,
<em>316</em>(1), 152–167. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a problem that integrates the vessel scheduling problem with the berth allocation into a collaborative problem denoted as the multi-port continuous berth allocation problem (MCBAP). This problem optimizes the berth allocation of a set of ships simultaneously in multiple ports while also considering the sailing speed of ships between ports. Due to the highly combinatorial character of the problem, exact methods struggle to scale to large-size instances, which points to exploring heuristic methods. We present a mixed-integer problem formulation for the MCBAP and introduce an adaptive large neighborhood search (ALNS) algorithm enhanced with a local search procedure to solve it. The computational results highlight the method’s suitability for larger instances by providing high-quality solutions in short computational times. Practical insights indicate that the carriers’ and terminal operators’ operational costs are impacted in different ways by fuel prices, external ships at port, and the modeling of a continuous quay.},
  archive      = {J_EJOR},
  author       = {Bernardo Martin-Iradi and Dario Pacino and Stefan Ropke},
  doi          = {10.1016/j.ejor.2024.02.003},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {152-167},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An adaptive large neighborhood search heuristic for the multi-port continuous berth allocation problem},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effective goal framing for managers using inventory
management systems. <em>EJOR</em>, <em>316</em>(1), 138–151. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While automated inventory management systems are prevalent, managers are known to use judgmental adjustment when they have access to system recommendations. However, these adjustments might be subject to human decision biases in the form of framing effects contingent on managers’ profit maximizing or cost minimizing goals. We conduct the first investigation of goal framing effects that influence the judgmental adjustment of system recommended order quantities. Our laboratory experiment uses a 4 (Goal framing: Positive, Negative, Neutral, Control) × 1 design that manipulates the goal frame. Except for the control group, decision makers in other treatments had access to a system recommendation. The participants in all treatments were asked to determine the optimum order quantity in a high margin newsvendor task. We find that the decision makers’ trust in the system recommendation determines the extent to which they make adjustments to the system recommendation. Most importantly our results reveal a significant goal framing effect: participants in the positive/negative frame condition ordered less/more than the system recommendation. This implies when organizations communicate goals and set targets for their decision makers, those goals should align with a cost minimization strategy to improve performance.},
  archive      = {J_EJOR},
  author       = {Dilina Kosgoda and H. Niles Perera and John Aloysius},
  doi          = {10.1016/j.ejor.2024.01.034},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {138-151},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Effective goal framing for managers using inventory management systems},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Price signal or blockchain technology? Quality information
disclosure in dual-channel supply chains. <em>EJOR</em>,
<em>316</em>(1), 126–137. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality information asymmetry regardless of online or offline channels have damaged the profits of high-quality manufacturers. Price signal and blockchain technology (BCT) are two strategies to eliminate this asymmetry, with BCT potentially incurring higher costs but also boosting demand potential. Therefore, in a dual-channel supply chain consisting of a manufacturer with private quality information and a retailer, we use a game-theoretic model to investigate which information strategy should be adopted by the high-quality manufacturer. Main results unveil a counterintuitive finding: the high-quality manufacturer may not reap greater benefits from BCT despite its ability to simultaneously boost prices and demands in both channels; conversely, the retailer can still derive benefits from BCT even if it fails to augment the expected demand in the retail channel. We attribute this phenomenon to two key effects of BCT: the information effect and the basic demand expansion effect. Additionally, we highlight the pivotal impact of channel market share on the value of these two strategies, as it not only affects the efficiency of information transmission through the price signal strategy but also the distinct demand enhancement that BCT offers to both channels. Specifically, for the products with a lower production cost difference and a higher market share in the retail channel, our research demonstrates that BCT has the potential to benefit the entire supply chain. This paper provides practical guidance for the strategic implementation of BCT in dual channels.},
  archive      = {J_EJOR},
  author       = {Qian Zhang and Yongjian Li and Pengwen Hou and Jun Wang},
  doi          = {10.1016/j.ejor.2024.01.019},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {126-137},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Price signal or blockchain technology? quality information disclosure in dual-channel supply chains},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid truck-drone delivery system with multi-visits and
multi-launch and retrieval locations: Mathematical model and adaptive
variable neighborhood search with neighborhood categorization.
<em>EJOR</em>, <em>316</em>(1), 100–125. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drones have recently been suggested as a means of performing last-mile deliveries, as they have several advantages compared to traditional delivery vehicles. A recent research avenue is to adopt a hybrid truck-drone delivery system that integrates drones with traditional delivery methods such as trucks. This paper deals with the problem of optimizing the delivery operation of a truck working in tandem with a drone capable of visiting multiple customers per dispatch. We also introduce practical attributes such as allowing the truck to launch and retrieve the drone from both customer and non-customer nodes as well as permitting cyclic and acyclic drone operations. An integer linear programming model is first formulated followed by the development of an effective variable neighborhood search (VNS)-based approach. The novelty of the latter is that it incorporates an effective categorisation of neighborhoods due to their large number that is needed while retaining their individual impact through an adaptive selection scheme. The performance of this powerful VNS-based heuristic is empirically assessed against three variants of the VNS. The VNS heuristic was also shown to be flexible and effective at handling the issue of synchronization. A sensitivity analysis, based on some of the critical parameters of the drone, is conducted alongside highlights of some interesting insights.},
  archive      = {J_EJOR},
  author       = {Batool Madani and Malick Ndiaye and Said Salhi},
  doi          = {10.1016/j.ejor.2024.02.010},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {100-125},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Hybrid truck-drone delivery system with multi-visits and multi-launch and retrieval locations: Mathematical model and adaptive variable neighborhood search with neighborhood categorization},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving the patient admission scheduling problem using
constraint aggregation. <em>EJOR</em>, <em>316</em>(1), 85–99. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patient admission scheduling (PAS) consists of assigning patients to beds over a planning horizon to maximize treatment efficiency, patient satisfaction, and hospital utilization while meeting all necessary medical constraints and considering patient preferences as much as possible. There are several different variants of the PAS problem in the literature, which differ mainly in the constraints that must be satisfied (hard) or can be violated (soft). Due to the intrinsic difficulty of the PAS problem, solving large integer programming (IP) models to optimality is challenging. In this paper, we consider the widely studied variant of the PAS problem that has the maximum number of soft constraints, and focus on how to reduce the size of IP formulations of the PAS problem to improve the solving efficiency. We employ a two-stage optimization method where the first stage builds reduced models by constraint aggregation to improve the typical formulation of the PAS problem. Experimental results on the 13 benchmark instances in the literature indicate that our method can obtain new improved solutions (new upper bounds) for 6 instances, including one proven optimal solution. For the 5 other instances whose optimal solutions are known, our approach can reach these known optimal solutions in a shorter computation time compared to the existing methods. In addition, we apply our method to the original PAS problem, which has the maximum number of hard constraints, and perform computational experiments on the same 13 benchmark instances. Our method yields 5 new best solutions and proves optimality for 6 instances.},
  archive      = {J_EJOR},
  author       = {Haichao Liu and Yang Wang and Jin-Kao Hao},
  doi          = {10.1016/j.ejor.2024.02.009},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {85-99},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solving the patient admission scheduling problem using constraint aggregation},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tighter bounds for the harmonic bin packing algorithm.
<em>EJOR</em>, <em>316</em>(1), 72–84. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The harmonic algorithm, defined for online bin packing, partitions items into a fixed number M of classes of similar items, and packs each class independently and greedily in constant time for every packed item. The positive integer M is a parameter of the algorithm. This algorithm had a major role in the development of the online bin packing problem. Tight bounds on its asymptotic approximation ratio were known for M ≤ 7 M≤7 , and for values of M with specific properties. The parametric variant of this algorithm, where item sizes are bounded from above by a certain value, was studied as well. We find tight bounds for many additional cases that were known as open, including the case M = 8 M=8 for the classic problem.},
  archive      = {J_EJOR},
  author       = {Leah Epstein},
  doi          = {10.1016/j.ejor.2024.01.051},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {72-84},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Tighter bounds for the harmonic bin packing algorithm},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Different formulations of the gray pattern problem and their
optimal solutions. <em>EJOR</em>, <em>316</em>(1), 61–71. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Gray Pattern Problem (GPP) requires selecting a given number ( p p ) of pixels (or dots) within a central rectangle to be colored black (the remaining pixels remain white) to form a repeating pattern covering the plane that is as uniformly gray as possible. Taillard proposed the original model in 1995, which is based on the principle of minimization of entropy taken from physics. The aim of this paper is to present alternate formulations of the GPP inspired by dispersion models studied in location theory. We show that these variants have much greater tractability than the original model, while producing patterns of equivalent or better quality.},
  archive      = {J_EJOR},
  author       = {Jack Brimberg and Pawel Kalczynski and Zvi Drezner},
  doi          = {10.1016/j.ejor.2024.01.048},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {61-71},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Different formulations of the gray pattern problem and their optimal solutions},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A distributionally robust chance-constrained kernel-free
quadratic surface support vector machine. <em>EJOR</em>,
<em>316</em>(1), 46–60. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of constructing a robust nonlinear classifier when the data set involves uncertainty and only the first- and second-order moments are known a priori. A distributionally robust chance-constrained kernel-free quadratic surface support vector machine (SVM) model is proposed using the moment information of the uncertain data. The proposed model is reformulated as a semidefinite programming problem and a second-order cone programming problem for efficient computations. A geometric interpretation of the proposed model is also provided. For commonly used data without prescribed uncertainty, a cluster-based data-driven approach is introduced to retrieve the hidden moment information that enables the proposed model for robust classification. Extensive computational experiments using synthetic and public benchmark data sets with or without uncertainty involved support the superior performance of the proposed model over other state-of-the-art SVM models, particularly when the data sets are massive and/or imbalanced.},
  archive      = {J_EJOR},
  author       = {Fengming Lin and Shu-Cherng Fang and Xiaolei Fang and Zheming Gao and Jian Luo},
  doi          = {10.1016/j.ejor.2024.02.022},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {46-60},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A distributionally robust chance-constrained kernel-free quadratic surface support vector machine},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A branch-and-bound algorithm with growing datasets for
large-scale parameter estimation. <em>EJOR</em>, <em>316</em>(1), 36–45.
(<a href="https://doi.org/10.1016/j.ejor.2024.02.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The solution of nonconvex parameter estimation problems with deterministic global optimization methods is desirable but challenging, especially if large measurement datasets are considered. We propose to exploit the structure of this class of optimization problems to enable their solution with the spatial branch-and-bound algorithm. In detail, we start with a reduced dataset in the root node and progressively augment it, converging to the full dataset. We show for nonlinear programs (NLPs) that our algorithm converges to the global solution of the original problem considering the full dataset. The implementation of the algorithm extends our open-source solver MAiNGO. A numerical case study with a mixed-integer nonlinear program (MINLP) from chemical engineering and a dynamic optimization problem from biochemistry both using noise-free measurement data emphasizes the potential for savings of computational effort with our proposed approach.},
  archive      = {J_EJOR},
  author       = {Susanne Sass and Alexander Mitsos and Dominik Bongartz and Ian H. Bell and Nikolay I. Nikolov and Angelos Tsoukalas},
  doi          = {10.1016/j.ejor.2024.02.020},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {36-45},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A branch-and-bound algorithm with growing datasets for large-scale parameter estimation},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient and provable sequential quadratic programming
method for american and swing option pricing. <em>EJOR</em>,
<em>316</em>(1), 19–35. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A sequential quadratic programming numerical method is proposed for American option pricing based on the variational inequality formulation. The variational inequality is discretized using the θ θ -method in time and the finite element method in space. The resulting system of algebraic inequalities at each time step is solved through a sequence of box-constrained quadratic programming problems, with the latter being solved by a globally and quadratically convergent, large-scale suitable reflective Newton method. It is proved that the sequence of quadratic programming problems converges with a constant rate under a mild condition on the time step size. The method is general in solving the variational inequalities for the option pricing with many styles of optimal stopping and complex underlying asset models. In particular, swing options and stochastic volatility and jump diffusion models are studied. Numerical examples are presented to confirm the effectiveness of the method.},
  archive      = {J_EJOR},
  author       = {Jinye Shen and Weizhang Huang and Jingtang Ma},
  doi          = {10.1016/j.ejor.2023.11.012},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {19-35},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An efficient and provable sequential quadratic programming method for american and swing option pricing},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Competitive location models: A review. <em>EJOR</em>,
<em>316</em>(1), 5–18. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of facility location models is to maximize the profit or minimize the cost of a company that wishes to expand or enter the market. The market share captured by facilities is a function of the distances to the facilities and their attractiveness. The analysis involves how to estimate the market share captured by facilities, where to locate new facilities, how to determine their attractiveness, and reactions of competitors to the actions of locating a facility. This invited review is dedicated to honor Tammy Drezner and her significant contributions to the field of competitive location. Her main innovative contributions include ways to find best locations for competing facilities, methods to assess their attractiveness levels, and significant modifications to the classic gravity model. The research on competitive facility location is still evolving and there are many aspects yet to be analyzed. A list of ideas for future research is proposed.},
  archive      = {J_EJOR},
  author       = {Zvi Drezner and H.A. Eiselt},
  doi          = {10.1016/j.ejor.2023.10.030},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {5-18},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Competitive location models: A review},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Obituary of mike tsionas (1965-2024). <em>EJOR</em>,
<em>316</em>(1), 2–4. (<a
href="https://doi.org/10.1016/j.ejor.2024.02.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  doi          = {10.1016/j.ejor.2024.02.019},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {2-4},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Obituary of mike tsionas (1965-2024)},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial. <em>EJOR</em>, <em>316</em>(1), 1. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {The Editors of EJOR, on January 5th, 2024},
  doi          = {10.1016/j.ejor.2024.01.010},
  journal      = {European Journal of Operational Research},
  month        = {7},
  number       = {1},
  pages        = {1},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Editorial},
  volume       = {316},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The influence of key components and digital technologies on
manufacturer’s choice of innovation strategy. <em>EJOR</em>,
<em>315</em>(3), 1210–1220. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of digital technologies and intense market competition have compelled manufacturers to innovate traditional products (TPs) using digital technologies, aiming to create more innovative digital products (IDPs). In practice, the selection of digital technologies collaboration and innovation (DTCI) strategies by manufacturers is influenced by the quality of key components in TPs, the maturity of digital technologies, and the level of matching between them. However, current operations literature has provided limited insights into the underlying mechanisms of how these factors affect manufacturers&#39; decision-making. In light of this, this study employs a game-theory approach to investigate how manufacturers can make optimal choices among three DTCI strategies: self-innovation, collaboration with incumbent suppliers or new suppliers. Different from previous studies, we propose a cooperative innovation strategy selection method based on key components and, digital technologies, as well as their matching degree. For the first time, we explore both the unidirectional and bidirectional matching scenarios. Our findings indicate that as the degree of unidirectional (bidirectional) matching increases, manufacturers are more inclined to choose self-innovation. An interesting finding is that, in the process of DTCI, manufacturers, as the leaders of digital technology cooperative innovation, do not possess a first-mover advantage.},
  archive      = {J_EJOR},
  author       = {Shuang Wei and Weihua Liu and Tsan-Ming Choi and Jing-xin Dong and Shangsong Long},
  doi          = {10.1016/j.ejor.2024.01.008},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1210-1220},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The influence of key components and digital technologies on manufacturer&#39;s choice of innovation strategy},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The economic viability of the sharing economy business model
and its environmental impact. <em>EJOR</em>, <em>315</em>(3), 1197–1209.
(<a href="https://doi.org/10.1016/j.ejor.2023.12.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sharing economy refers to a business model where access to products or services is shared among consumers through an online platform. This model has recently received much attention to determine whether it is economically viable and environmentally friendly. The main trade-off is this: a decrease in production volume possibly favoring the environment while reducing the manufacturer’s profits versus an increase in product usage potentially harmful to the environment while enhancing the manufacturer’s profits from increased margins. Furthermore, the sharing economy may prod the manufacturer to either elevate product efficiency so as to justify a higher selling price or to reduce it with the intent of cutting production costs. Given these arguments, we investigate both economic and environmental impacts of the sharing economy business model for comparison with the traditional models of pure sales and servicizing. We find that the manufacturer may prefer peer-to-peer product-sharing over pure sales or hybrid servicizing under two sets of conditions: (1) either consumers are sufficiently heterogeneous in their product usage needs, while concurrently the size of high-usage consumers being relatively small, or consumers are sufficiently homogeneous in their product usage needs, while concurrently consumer segments with different usage needs being similar in size, and (2) the marginal cost of production (per unit of efficiency) and the manufacturer’s ability to pool consumers’ needs are both sufficiently low. The sharing economy can also environmentally outperform traditional business models, especially for products where environmental impact accrues mostly at production/disposal than at usage. As a result, the sharing economy can yield a win–win outcome as to manufacturer’s profits and environmental impact.},
  archive      = {J_EJOR},
  author       = {Fahimeh Chomachaei and Esther Gal-Or and Paolo Letizia and Paolo Roma},
  doi          = {10.1016/j.ejor.2023.12.022},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1197-1209},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The economic viability of the sharing economy business model and its environmental impact},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimization models for the installation planning of
offshore wind farms. <em>EJOR</em>, <em>315</em>(3), 1182–1196. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Challenges posed by global warming motivate the increasing interest in green energy sources, such as wind energy. To make wind energy attractive from an economic viewpoint, the decision-making problems faced in designing, installing, and maintaining wind farms have to be optimized. In this paper, we focus on the problem of optimally planning the installation process of offshore wind farms, as faced by Vattenfall, a leading European energy company. We first formulate the deterministic version of this Installation Planning of Offshore Wind Farms (IPOWF) problem as a Mixed Integer Linear Programming (MILP) model. From this model, we then derive other MILPs that can provide lower and upper bounds to the optimal installation cost. To cope with weather uncertainty, we also provide a light-robust MILP. These models are tested on real-life instances corresponding to two wind farms that Vattenfall has recently built in Denmark and Germany. Computational results show that tight primal and dual solutions can be computed for the deterministic case with the proposed models and that the light-robust model yields solutions that are robust to weather uncertainty.},
  archive      = {J_EJOR},
  author       = {Lavinia Amorosi and Martina Fischetti and Rosario Paradiso and Roberto Roberti},
  doi          = {10.1016/j.ejor.2024.01.011},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1182-1196},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimization models for the installation planning of offshore wind farms},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How to load your auto carrier. A hybrid packing approach for
the auto-carrier loading problem. <em>EJOR</em>, <em>315</em>(3),
1167–1181. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distribution of new vehicles is a critical cost factor for automotive original equipment manufacturers (OEMs). While trains are the ideal mode for overland transport, OEMs often opt for road transport via auto carriers due to flexibility reasons or unavailability of rail networks. Auto carriers are specialized trucks equipped with flexible loading platforms. Finding the optimal configuration of platforms can be a difficult task due to passenger vehicles varying in size, shape, and weight. This problem is known as the auto-carrier loading problem (ACLP). The current literature deals with the ACLP on a strategic level with the goal to maximize transport capacities. However, it neglects the resulting increase in operational complexity. In this paper, we present a hybrid packing approach to solve the ACLP on an operational level. Our approach considers the shapes of the vehicles as polygons and incorporates an approximation of continuous rotation by combining a geometric algorithm with a mixed integer model formulation. We aim not only to maximize loading capacities but also to provide instructions for truck drivers on how to arrange the vehicles on the truck. We conduct a proof of concept (POC) with actual auto carriers to verify the feasibility of our approach and to quantify potential benefits for our industry partner. The POC confirms that our approach reliably generates feasible and comprehensive loading instructions. Not only could the implementation of our approach reduce lead times and transportation damages, but in addition, could completely automate the manual load creation process in distribution centers.},
  archive      = {J_EJOR},
  author       = {Christian Jäck and Jochen Gönsch},
  doi          = {10.1016/j.ejor.2024.01.001},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1167-1181},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {How to load your auto carrier. a hybrid packing approach for the auto-carrier loading problem},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A framework for conceptualising hybrid system dynamics and
agent-based simulation models. <em>EJOR</em>, <em>315</em>(3),
1153–1166. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing complexity of systems and problems that stakeholders from the private and public sectors have sought advice on has led systems modellers to increasingly use multimethodology and to combine multiple OR/MS methods. This includes hybrid simulation that combines two or more of the following methods: system dynamics (SD), discrete-event simulation, and agent-based models (ABM). Although a significant number of studies describe the application of hybrid simulation across different domains, research on the theoretical and practical aspects of combining simulation modelling methods, particularly the combining of SD and ABM, is still limited. Existing frameworks for combining simulation methods are high-level and lack methodological clarity and practical guidance on modelling decisions and elements specific to hybrid simulation that modellers need to consider. This paper proposes a practical framework for developing a conceptual hybrid simulation model that is built on reviews and reflections of theoretical and application literature on combining methods. The framework is then used to inform and guide the process of conceptual model building for a case study in controlling the spread of COVID-19 in care homes. In addition, reflection on the use of the framework for the case study led to refining the framework itself. This case study is also used to demonstrate how the framework informs the structural design of a hybrid simulation model and relevant modelling decisions during the conceptualisation phase.},
  archive      = {J_EJOR},
  author       = {Le Khanh Ngan Nguyen and Susan Howick and Itamar Megiddo},
  doi          = {10.1016/j.ejor.2024.01.027},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1153-1166},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A framework for conceptualising hybrid system dynamics and agent-based simulation models},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The fulfillment service in online marketplaces.
<em>EJOR</em>, <em>315</em>(3), 1139–1152. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, fulfillment services in online marketplaces have witnessed a surge in popularity. Dominant e-commerce platforms, such as Amazon.com, now allow small retailers to join their online marketplaces, while concurrently providing comprehensive fulfillment services. In return, small retailers pay a fulfillment fee per unit of sales. We examine the advantages of these fulfillment programs in the context of a dominant retailer that possesses an online marketplace, alongside a small retailer who operates within this marketplace and possesses private fulfillment cost information. We analyze two scenarios, contingent upon the presence or absence of competition between the two retailers, and we derive the optimal fulfillment fees for the dominant retailer. Our findings indicate that the structure of market competition plays a pivotal role in shaping fulfillment fees and associated advantages. In the absence of market competition, the provision of fulfillment services consistently proves advantageous. This is attributed to enhancements in (1) consumer valuation of the small retailer&#39;s products and (2) overall system efficiency in fulfillment. Conversely, when there is competition, offering a fulfillment program may not be as lucrative if the improvements in product valuation and the degree of cost heterogeneity are minimal. Furthermore, our findings highlight that enhancements in product valuation can positively impact both retailers and consumer welfare, irrespective of market competition. However, in cases where cost heterogeneity arises due to asymmetric information, it may adversely affect consumer welfare in the absence of competition.},
  archive      = {J_EJOR},
  author       = {Jun Li and Wenjing Shen and Yi Liao and Gangshu Cai and Xiangfeng Chen},
  doi          = {10.1016/j.ejor.2024.01.003},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1139-1152},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The fulfillment service in online marketplaces},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A semi-supervised concept-cognitive computing system for
dynamic classification decision making with limited feedback
information. <em>EJOR</em>, <em>315</em>(3), 1123–1138. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dynamic environments, making classification decisions based on classical intelligent decision support systems is a challenge, as the classification performance of decision-making and the time-cost of learning need to be considered simultaneously. Moreover, many tasks of classification decisions lack label information because annotating data is time-consuming, labor-intensive and expensive process. This means that some standard intelligent decision support systems will perform inferior performance if they cannot dynamically make full use of the information behind abundant unlabeled data. Therefore, by incorporating knowledge representation and dynamic updating mechanisms into concept learning processes, we introduce a novel dynamic concept learning approach, namely semi-supervised concept-cognitive computing system (s2C3S), for making classification decisions by jointly utilizing some labeled data and abundant unlabeled data under dynamic environments. A theoretical analysis has shown that the proposed s2C3S can achieve significantly lower computational costs and higher classification accuracies than the existing incremental K Nearest Neighbor method (IKNN) and concept-cognitive computing system (C3S). The experimental results on various datasets further demonstrated that our system is effective for dynamic classification decision-making with limited labeled data under dynamic learning processes. Additionally, s2C3S can also be applied to computer-assisted intelligent diagnosis from the given medical images (such as chest X-ray images) dynamically and accurately.},
  archive      = {J_EJOR},
  author       = {Yunlong Mi and Zongrun Wang and Pei Quan and Yong Shi},
  doi          = {10.1016/j.ejor.2023.12.033},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1123-1138},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A semi-supervised concept-cognitive computing system for dynamic classification decision making with limited feedback information},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimating relative importance of criteria by
post-processing dominance-based rough set approach’s outputs.
<em>EJOR</em>, <em>315</em>(3), 1096–1122. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dominance-based rough set approach (DRSA) is one of the rare multicriteria sorting methods that does not require a priori values for the relative importance of criteria. This method therefore is cognitively less demanding. However, the decision-maker may lack some valuable information that is needed to explain and justify final decisions to stakeholders. The relative importance of criteria can instead be estimated based on the characteristics of the outputs of the DRSA, which are mainly decision rules and attribute reducts. The estimated values can then be used to understand the role played by each criterion and justify the final decisions to stakeholders. This paper first reviews and improves the decision rule attractiveness measure and the relative importance measures that are based on decision rules and attribute reducts, which were all proposed in the authors’ previous work. It also introduces new measures that rely on the marginal contributions and entropy of the criteria. This paper also extends these measures to estimate the relative importance of criteria with respect to specific unions of classes. The proposed measures have been applied to Brexit referendum and bankruptcy risk assessment datasets. Both applications showed that the proposed measures generally lead to different results. This can be explained by the diversity of the knowledge on which these measures rely and also by the multiplicity of the analytical perspectives associated with them. The results also showed that the marginal contribution-based measure is a good estimator of both Shapley and Banzhaf values.},
  archive      = {J_EJOR},
  author       = {T.E.M. Atteya and Salem Chakhar and Ashraf Labib and Adam Cox and Alessio Ishizaka},
  doi          = {10.1016/j.ejor.2023.12.027},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1096-1122},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Estimating relative importance of criteria by post-processing dominance-based rough set approach’s outputs},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Counterfactual analysis and target setting in benchmarking.
<em>EJOR</em>, <em>315</em>(3), 1083–1095. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data Envelopment Analysis (DEA) allows us to capture the complex relationship between multiple inputs and outputs in firms and organizations. Unfortunately, managers may find it hard to understand a DEA model and this may lead to mistrust in the analyses and to difficulties in deriving actionable information from the model. In this paper, we propose to use the ideas of target setting in DEA and of counterfactual analysis in Machine Learning to overcome these problems. We define DEA counterfactuals or targets as alternative combinations of inputs and outputs that are close to the original inputs and outputs of the firm and lead to desired improvements in its performance. We formulate the problem of finding counterfactuals as a bilevel optimization model. For a rich class of cost functions, reflecting the effort an inefficient firm will need to spend to change to its counterfactual, finding counterfactual explanations boils down to solving Mixed Integer Convex Quadratic Problems with linear constraints. We illustrate our approach using both a small numerical example and a real-world dataset on banking branches.},
  archive      = {J_EJOR},
  author       = {Peter Bogetoft and Jasone Ramírez-Ayerbe and Dolores Romero Morales},
  doi          = {10.1016/j.ejor.2024.01.005},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1083-1095},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Counterfactual analysis and target setting in benchmarking},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Benders decomposition for robust distribution network design
and operations in online retailing. <em>EJOR</em>, <em>315</em>(3),
1069–1082. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasingly flourishing e-commerce has prompted e-retailers to implement a two-layer distribution network consisting of regional and forward distribution centers (FDCs) to reduce the fulfillment cost. This is done at the expense of incurring construction cost and complicating the inventory management, thus may not achieve a cost-effective goal. In this paper, we study a joint network design and operations problem that first chooses the locations and assortments for FDCs before the horizon starts, then decides the replenishment, allocation, and fulfillment quantities adaptively as random demands reveal over periods. We formulate a multi-period stochastic model and propose a robustness based Benders decomposition algorithm, which first applies a linear decision rule to get a mixed-integer robust counterpart model, then solves it using a Benders decomposition. Numerical experiments suggest that our algorithm produces good-quality solutions efficiently and robustly under distributional ambiguity. A case study using real data from JD.com demonstrates the applicability of our algorithm, which yields substantial cost savings over a decentralized policy and a status quo policy. Some managerial and practical insights are derived from the results.},
  archive      = {J_EJOR},
  author       = {Song Jiu and Dan Wang and Zujun Ma},
  doi          = {10.1016/j.ejor.2024.01.046},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1069-1082},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Benders decomposition for robust distribution network design and operations in online retailing},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human-and-cost-centric storage assignment optimization in
picker-to-parts warehouses. <em>EJOR</em>, <em>315</em>(3), 1049–1068.
(<a href="https://doi.org/10.1016/j.ejor.2024.01.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Warehouses are key for supply chain efficiency and company success. Over the past decade, warehouse operations have become more complex due to small-quantity orders with volatile demand patterns and the need for fast and error-free deliveries. In line with these developments, order picking is among the most critical tasks in warehouses, as it directly impacts the speed, availability and accuracy of the order. Although we see an increasing use of assistive and automation technology in order picking, manual tasks are still prevalent, and warehouse employment increases constantly. The high amount of manual work in order picking poses a risk environment for workers to develop injuries, which is why a research stream that focuses on the joint optimization of operational performance indicators and human well-being has emerged. This work contributes to this research area by developing an integrated storage assignment model that considers the vertical and horizontal dimension as well as the simultaneous minimization of the total order processing time and the minimization of the order picker’s total physical strain. Based on the results of numerical experiments, which are inspired by practical cases, we propose improved storage assignment policies for the case that order pickers follow the return or traversal routing strategy. This work contributes to further developing the research stream of human-centered warehousing and highlights implications for warehouse managers to improve working conditions with simultaneous consideration of performance optimization.},
  archive      = {J_EJOR},
  author       = {Heiko Diefenbach and Eric H. Grosse and Christoph H. Glock},
  doi          = {10.1016/j.ejor.2024.01.033},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1049-1068},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Human-and-cost-centric storage assignment optimization in picker-to-parts warehouses},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combining probabilistic forecasts of intermittent demand.
<em>EJOR</em>, <em>315</em>(3), 1038–1048. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, new methods and approaches have been developed for forecasting intermittent demand series. However, the majority of research has focused on point forecasting, with little exploration into probabilistic intermittent demand forecasting. This is despite the fact that probabilistic forecasting is crucial for effective decision-making under uncertainty and inventory management. Additionally, most literature on this topic has focused solely on forecasting performance and has overlooked the inventory implications, which are directly relevant to intermittent demand. To address these gaps, this study aims to construct probabilistic forecasting combinations for intermittent demand while considering both forecasting accuracy and inventory control utility in obtaining combinations and evaluating forecasts. Our empirical findings demonstrate that combinations perform better than individual approaches for forecasting intermittent demand, but there is a trade-off between forecasting and inventory performance.},
  archive      = {J_EJOR},
  author       = {Shengjie Wang and Yanfei Kang and Fotios Petropoulos},
  doi          = {10.1016/j.ejor.2024.01.032},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1038-1048},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Combining probabilistic forecasts of intermittent demand},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constructing decision rules for multiproduct newsvendors: An
integrated estimation-and-optimization framework. <em>EJOR</em>,
<em>315</em>(3), 1021–1037. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop an integrated estimation-and-optimization framework for constructing decisions rules for the order quantities of multiple perishable products. The framework accounts for substitution in case of scarcity by providing models incorporating substitution rates, received as input. Specifically, it builds decision rules minimizing the empirical risk and accommodates multiple classes of functions, including those leveraging exogenous features. We provide a continuous reformulation of the empirical risk minimization problem that is quadratic in the decision rules. In addition, we show how to incorporate information from in-sample optimal decisions to derive a linear approximation to it. The dual of this approximation allows us to estimate decision rules that exploit nonlinearities and interactions of features. The numerical results on real and simulated datasets suggest that decision rules computed within the proposed integrated framework have the potential to outperform separated estimation and optimization methods. In particular, larger improvements are obtained under low service levels requirements or high volatility of the demands. Furthermore, we empirically observe that information provided by exogenous features may be particularly significant in the presence of large fluctuations of the demand.},
  archive      = {J_EJOR},
  author       = {Alba V. Olivares-Nadal},
  doi          = {10.1016/j.ejor.2024.01.014},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1021-1037},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Constructing decision rules for multiproduct newsvendors: An integrated estimation-and-optimization framework},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new policy for scattered storage assignment to minimize
picking travel distances. <em>EJOR</em>, <em>315</em>(3), 1006–1020. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various retail and e-commerce companies face the challenge of picking a large number of time-critical customer orders that include both a small number of items and multiple order lines. To reduce the unproductive work time of order pickers, several storage assignment policies have been proposed in the literature and in practice. In case of the scattered storage assignment (SSA) policy individual items are intentionally distributed to multiple positions in the picking area to increase the probability that items belonging to the same order can be picked at nearby positions. In this paper, we examine our recently proposed SSA policy that seeks to minimize the sum of pairwise distances (SPD) between all item positions that belong to the same order, including a drop-off point. We develop an efficient variable neighborhood search (VNS) metaheuristic to solve large instances in a reasonable computation time. We tested our SSA-SPD strategy by implementing a picking algorithm that considers multiple drop-off points and tracks inventory in the meantime. Our results show that our SSA-SPD policy helps reduce picking distances by up to 36% compared to a random scatter policy and 56% compared to a volume-based policy, depending on the number of order lines and drop-off points in the problem instance.},
  archive      = {J_EJOR},
  author       = {Harol Mauricio Gámez Albán and Trijntje Cornelissens and Kenneth Sörensen},
  doi          = {10.1016/j.ejor.2024.01.013},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1006-1020},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new policy for scattered storage assignment to minimize picking travel distances},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving efficiency in supply chains with a
capital-constrained app developer under the agency contract.
<em>EJOR</em>, <em>315</em>(3), 991–1005. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a supply-chain model with a capital-constrained app developer. The developer interacts with a distribution platform via an agency contract, and the demand is uncertain and dependent on the app’s quality level and selling price. Given the amount of capital that the developer commits to investing in the creation of quality, the platform offers the developer a loan at a certain interest rate, based on which the developer determines the app’s quality level and subsequently also the selling price. We analytically prove that: (i) the interest rate offered by the platform decreases in the developer’s capital and, interestingly, the platform subsidizes the developer’s efforts either when the platform’s share of the revenue or the developer’s capital are sufficiently large; (ii) there is an amount of capital assigned to the creation of quality that is optimal in terms of maximizing the developer’s expected profit; and (iii) the total channel’s expected profit increases in the developer’s capital, which enables us to propose an improved contract leading to Pareto improvement and full coordination by using a side payment that compensates the developer for his loss of profit. In addition, we compare the supply-chain measures of the platform-financing model with those of four common benchmark models: a self-financing developer, a centralized system, no financing, and bank financing. Finally, we extend the analysis in three directions: setting price under demand uncertainty; analyzing a multiplicative demand form with regard to price and quality; and exploring the case of bank financing in addition to platform financing.},
  archive      = {J_EJOR},
  author       = {Tal Avinadav and Priel Levy},
  doi          = {10.1016/j.ejor.2024.01.015},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {991-1005},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Improving efficiency in supply chains with a capital-constrained app developer under the agency contract},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An algorithm for stochastic convex-concave fractional
programs with applications to production efficiency and equitable
resource allocation. <em>EJOR</em>, <em>315</em>(3), 980–990. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an algorithm to solve convex and concave fractional programs and their stochastic counterparts in a common framework. Our approach is based on a novel reformulation that involves differences of square terms in the constraints, and subsequent employment of piecewise-linear approximations of the concave terms. Using the branch-and-bound (B&amp;B) framework, our algorithm adaptively refines the piecewise-linear approximations and iteratively solves convex approximation problems. The convergence analysis provides a bound on the optimality gap as a function of approximation errors. Based on this bound, we prove that the proposed B&amp;B algorithm terminates in a finite number of iterations and the worst-case bound to obtain an ϵ ϵ -optimal solution reciprocally depends on the square root of ϵ ϵ . Numerical experiments on Cobb–Douglas production efficiency and equitable resource allocation problems support that the algorithm efficiently finds a highly accurate solution while significantly outperforming the benchmark algorithms for all the small size problem instances solved. A modified branching strategy that takes the advantage of non-linearity in convex functions further improves the performance. Results are also discussed when solving a dual reformulation and using a cutting surface algorithm to solve distributionally robust counterpart of the Cobb–Douglas example models.},
  archive      = {J_EJOR},
  author       = {Shibshankar Dey and Cheolmin Kim and Sanjay Mehrotra},
  doi          = {10.1016/j.ejor.2023.12.020},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {980-990},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An algorithm for stochastic convex-concave fractional programs with applications to production efficiency and equitable resource allocation},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). In-house or outsourcing? The impact of remanufacturing
strategies on the dynamics of component remanufacturing systems under
lifecycle demand and returns. <em>EJOR</em>, <em>315</em>(3), 965–979.
(<a href="https://doi.org/10.1016/j.ejor.2024.01.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a component manufacturing and remanufacturing system where, due to the end-of-life warranty, new and after-sales demand must be satisfied. Two kinds of demand exhibit different lifecycle patterns with different scales and a time lag, while a third correlated component return lifecycle with again a different lag and scale, driven by adoption of remanufacturing, is also presented. To achieve supply and demand balance during demand lifecycles, companies need a strategic decision on their remanufacturing: remanufacturing outsourcing strategy (ROS) or remanufacturing in-house strategy (RIS), yet inadequately studied from system dynamics perspective. We developed base-stock system dynamics models and analytically explored the dynamic implications of RIS and ROS remanufacturing strategies under correlated lifecycle demand and returns. Applying z z -transform and discrete time simulation, we found that RIS outperforms ROS system including less peak capacity cost, less inventory holding cost and less backlog cost. Also, the bullwhip of the RIS is always less than the ROS system. However, the adoption of the RIS may result longer-lasting manufacturing production and thus lead to a higher cost: an important cost needs to be strategically considered. Thereby, from system dynamics perspective, the component manufacturer needs carefully consider trade-offs between production and inventory costs, as well as their demand lifecycle characteristics to choose the right remanufacturing strategy.},
  archive      = {J_EJOR},
  author       = {Junyi Lin and Mohamed M. Naim and Ou Tang},
  doi          = {10.1016/j.ejor.2024.01.006},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {965-979},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {In-house or outsourcing? the impact of remanufacturing strategies on the dynamics of component remanufacturing systems under lifecycle demand and returns},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Platform financing or bank financing in agricultural supply
chains: The impact of platform digital empowerment. <em>EJOR</em>,
<em>315</em>(3), 952–964. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agricultural supply chains face multiple challenges, including fund shortages and the need for planting technology improvement. With the development of the platform economy, powerful platforms can address these challenges by providing farmers with digital technology empowerment and loan services. This study considers a two-echelon supply chain consisting of a platform and a farmer with yield uncertainty. We establish game-theoretic models with and without platform digital empowerment under bank financing and platform financing. Our main findings are as follow. First, the farmer benefits from empowerment when it reduces or slightly increases the farmer’s cost coefficient of planting technology application. Interestingly, there is a possibility that when the cost coefficient of empowerment is too low, the farmer is less likely to benefit from empowerment The platform will always benefit after the farmer accepts the empowerment. Second, if the bankruptcy risk and platform loan interest rate are low (high), both will choose platform (bank) financing. The platform is more willing to provide loan services to the farmer when the platform loan interest rate is low. Furthermore, platform financing can improve the platform digital empowerment level. The empowerment level increases with the bank loan interest rate, whereas it first decreases then increases with the platform loan interest rate. Third, under bank financing, cost-sharing contracts where one firm shares the other’s costs can achieve Pareto improvement. However, under platform financing, only when the platform shares the farmer’s cost can the supply chain achieve Pareto improvement.},
  archive      = {J_EJOR},
  author       = {Qihui Lu and Changhua Liao and Meilan Chen and Victor Shi and Xiangling Hu and Weiwei Hu},
  doi          = {10.1016/j.ejor.2023.12.024},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {952-964},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Platform financing or bank financing in agricultural supply chains: The impact of platform digital empowerment},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An exact algorithm for maximum electric vehicle flow
coverage problem with heterogeneous chargers, nonlinear charging time
and route deviations. <em>EJOR</em>, <em>315</em>(3), 926–951. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Typical electric vehicles (EVs) should be recharged multiple times to reach a long distance due to the limited travel ranges. The EV flow covering problem determines the locations of charging stations to maximize the “covered” OD flows, respecting a given budget for the new charging stations. This paper proposes an exact algorithm for solving the problem by considering the heterogeneous EV chargers, nonlinear charging time, and route deviations from the shortest distance paths. We develop an exact Benders decomposition-based algorithm, in which the Benders subproblem utilizes a nested cut-generation via a customized labeling algorithm. Two methods for solving the Benders subproblem are developed, which are combined to accelerate the Benders cut generation. In addition, we present a heuristic algorithm based on the proposed exact algorithm for the larger-sized problems. The computational results show that the proposed algorithm could solve real-life problems. Especially, the heuristic algorithm could solve problems up to 339 nodes and 500 km of the EV’s travel range. The extensive computational study shows that addressing the multiple charger types, the charging time, and the deviation routes can be crucial to provide realistic charging infrastructure for EVs.},
  archive      = {J_EJOR},
  author       = {Hyunwoo Park and Chungmok Lee},
  doi          = {10.1016/j.ejor.2023.12.019},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {926-951},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An exact algorithm for maximum electric vehicle flow coverage problem with heterogeneous chargers, nonlinear charging time and route deviations},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An algorithm for flexible transshipments with perfect
synchronization. <em>EJOR</em>, <em>315</em>(3), 913–925. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Direct and instant deliveries have gained popularity among customers, but have also increased the burden on cities due to rising transport incidents, especially as delivery vehicles often drive empty when returning to their origin. Flexible transshipments with perfect synchronization would allow loads to be transshiped between these vehicles without the need for storage facilities. This may increase their average proximity to their origin and reduce the proportion of empty rides. We present a problem-specific algorithm with three sub-steps to solve this concept. The first evaluates the relational position between two deliveries and, based on 36 structured cases, decides which pairs to exclude from the solution space. The second formulates the optimization problem to find the best transshipment location while considering time-limit constraints and transfer times. Finally, we apply the request-pair combination problem to graph theory to determine the lowest overall travel time. In our paper, we consider a continuous problem definition which allows flexible transshipments, and assume unit-sized capacity per vehicle and a maximum of one transshipment per request. We show that our algorithm reduces the initial total travel time of direct deliveries by 9.6% in a numerical simulation, and by 11% in a case study using food delivery data from the city of Bordeaux. We also demonstrate that the total time is best reduced by increasing time constraints rather than adding requests to increase the chance of transshipments. Our algorithm not only helps to reduce travel time, but also improves sustainability, mitigates driver shortages and is easy to implement.},
  archive      = {J_EJOR},
  author       = {Sven F. Falkenberg and Stefan Spinler and Arne K. Strauss},
  doi          = {10.1016/j.ejor.2023.12.003},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {913-925},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An algorithm for flexible transshipments with perfect synchronization},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving the list coloring problem through a branch-and-price
algorithm. <em>EJOR</em>, <em>315</em>(3), 899–912. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a branch-and-price algorithm to solve the weighted version of the List Coloring Problem, based on a vertex cover formulation by stable sets. This problem is interesting for its applications and also for the many other problems that it generalizes, including the well-known Graph Coloring Problem. With the introduction of the concept of indistinguishable colors, some theoretical results are presented which are later incorporated into the algorithm. We propose two branching strategies based on others for the Graph Coloring Problem, the first is an adaptation of the one used by Mehrotra and Trick in their pioneering branch-and-price algorithm and the other is inspired by the one used by Méndez-Díaz and Zabala in their branch-and-cut algorithm. The rich structure of this problem makes both branching strategies robust. Extensive computation experimentation on a wide variety of instances shows the effectiveness of this approach and evidences the different behaviors that the algorithm can have according to the structure of each type of instance.},
  archive      = {J_EJOR},
  author       = {Mauro Lucci and Graciela Nasini and Daniel Severín},
  doi          = {10.1016/j.ejor.2024.01.038},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {899-912},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solving the list coloring problem through a branch-and-price algorithm},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A bi-level framework for heterogeneous fleet sizing of
ride-hailing services considering an approximated mixed equilibrium
between automated and non-automated traffic. <em>EJOR</em>,
<em>315</em>(3), 879–898. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ride-hailing companies will face the emergence and gradual expansion of AVs-only zones in urban areas where only automated vehicles (AVs) are allowed to circulate. When owning a mixed fleet (automated and conventional taxis), a ride-hailing company has to determine the optimal fleet size as a function of the gradually expanding coverage of AVs-only zones while taking into account interactions with privately-owned human-driven vehicles. To model this problem, we propose a bi-level framework in which the lower level captures the mixed routing behaviour of the vehicles and the endogenous traffic congestion, and the upper level determines fleet sizes to maximise profit. A parallel genetic algorithm is introduced to solve this bi-level framework, which is embedded with a tailored algorithm for solving the lower-level model. Numerical experiments are conducted on instances based on a small network and the network of the city of Delft, The Netherlands, to demonstrate the performance of the proposed solution method and investigate the impacts of AVs-only zones on traffic and ride-hailing operations. Results indicate that the fleet size of automated taxis increases nonlinearly with the expansion of the AVs-only zone while that of conventional taxis decreases as demand shifts from human-driven vehicles to automated taxis. The fleet size decision depends heavily on the fleet’s cost structure, the location and the distribution of parking depots. Furthermore, the existence of an AVs-only zone leads to detours for human-driven vehicles in the early stages, but it will bring major benefits by reducing congestion as its size increases.},
  archive      = {J_EJOR},
  author       = {Qiaochu Fan and J. Theresia van Essen and Gonçalo H.A. Correia},
  doi          = {10.1016/j.ejor.2024.01.017},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {879-898},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A bi-level framework for heterogeneous fleet sizing of ride-hailing services considering an approximated mixed equilibrium between automated and non-automated traffic},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Managing appointment-based services with electronic visits.
<em>EJOR</em>, <em>315</em>(3), 863–878. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic visits, or “E-visits” for short, have emerged as a promising channel for accessing healthcare and can significantly impact daily operations in healthcare facilities. However, there is a lack of research on how to efficiently manage appointments for outpatient care providers when faced with E-visits that exhibit different waiting cost patterns. Our study investigates how providers can use appointment scheduling as a “passive” control when patients have full access to the E-visit channel, to better utilise resources and reduce patient waiting. Specifically, we demonstrate that multimodularity still applies to the model with E-visits, despite their waiting costs being typically nonlinear. Furthermore, we analyse how providers can “actively” control the arrival of E-visits by scheduling their time windows. By examining the structures of the optimal joint schedule of appointments and E-visit time windows, and reformulating the problem into a two-stage program, we have designed an Accelerated Cut Generation Algorithm, which is shown to be efficient in our numerical study. To the best of our knowledge, this is the first study to explore the optimal scheduling of both appointments and E-visit time windows. By implementing proper scheduling, the negative impact of E-visits can be mitigated, their benefits to the provider can be enhanced, and overall operational efficiency can be improved.},
  archive      = {J_EJOR},
  author       = {Yun Cai and Haiqing Song and Shan Wang},
  doi          = {10.1016/j.ejor.2024.01.012},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {863-878},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Managing appointment-based services with electronic visits},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online early work scheduling on parallel machines.
<em>EJOR</em>, <em>315</em>(3), 855–862. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider non-preemptive online parallel-machine scheduling with a common due date to maximize the total early work of all the jobs, i.e., the total processing time of the jobs (or parts) completed before the common due date. For the general case of m m machines, we provide a parameter lower bound with respect to m m . For the online algorithm, we first show that the tight competitive ratio of the classical list scheduling (LS) algorithm is 4 3 43 . We then improve the upper bound on the competitive ratio for the previous algorithm, EFF m m , to 1.2956. Additionally, we present a formula to compute the upper bound on the competitive ratio for any given m m . For the case of three machines, we improve the lower bound to 1.1878 and propose an improved online algorithm with a tight competitive ratio of 1.2483.},
  archive      = {J_EJOR},
  author       = {Yiwei Jiang and Mengjing Wu and Xin Chen and Jianming Dong and T.C.E. Cheng and Jacek Blazewicz and Min Ji},
  doi          = {10.1016/j.ejor.2024.01.009},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {855-862},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Online early work scheduling on parallel machines},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimizing total completion time with machine-dependent
priority lists. <em>EJOR</em>, <em>315</em>(3), 844–854. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a natural, yet challenging variant of the parallel machine scheduling problem in which each machine imposes a preferential order over the jobs and schedules the jobs accordingly once assigned to it. We study the problem of minimizing the total completion time, distinguishing between identical and unrelated machines, machine-dependent and identical priority lists, or a constant number of different priority classes. Additionally, we consider the setting in which the priority list on a machine must satisfy longest processing time first. We resolve the computational complexity of the problem and provide a clear distinction between problems that are polynomial time solvable and APX-hard.},
  archive      = {J_EJOR},
  author       = {Vipin Ravindran Vijayalakshmi and Marc Schröder and Tami Tamir},
  doi          = {10.1016/j.ejor.2023.12.030},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {844-854},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Minimizing total completion time with machine-dependent priority lists},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scheduling in manufacturing with transportation:
Classification and solution techniques. <em>EJOR</em>, <em>315</em>(3),
821–843. (<a href="https://doi.org/10.1016/j.ejor.2023.10.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many modern manufacturing settings feature especially close relationship of the transportation of workpieces between production steps with the scheduling of manufacturing operations. Consider flexible manufacturing systems, reconfigurable manufacturing systems or flexible assembly lines, to name a few. In this paper, we review over 140 papers on sched uling p roblems in manufacturing with t ransportation (SchedPT). We classify the reviewed papers according to an extension of the three-field notation of Graham et al. (1979) and outline relevant problem settings, such as characteristics of transporters, material flow or of the buffer system. Afterwards, we discuss selected main solution approaches to solve SchedPT. We also collected more than 60 results on polynomially solvable problem variants and performance guarantees. Based on our analysis, we formulate promising directions for future research.},
  archive      = {J_EJOR},
  author       = {Amir Hosseini and Alena Otto and Erwin Pesch},
  doi          = {10.1016/j.ejor.2023.10.013},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {821-843},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Scheduling in manufacturing with transportation: Classification and solution techniques},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pekka korhonen in memoriam. <em>EJOR</em>, <em>315</em>(3),
819–820. (<a href="https://doi.org/10.1016/j.ejor.2024.02.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Wallenius Jyrki ( Prof. )},
  doi          = {10.1016/j.ejor.2024.02.013},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {819-820},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pekka korhonen in memoriam},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing credit limit adjustments under adversarial goals
using reinforcement learning. <em>EJOR</em>, <em>315</em>(2), 802–817.
(<a href="https://doi.org/10.1016/j.ejor.2023.12.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning has been explored for many problems, from video games with deterministic environments to portfolio and operations management in which scenarios are stochastic; however, there have been few attempts to test these methods in banking problems. In this study, we sought to find and automatize an optimal credit card limit adjustment policy by employing reinforcement learning techniques. In particular, because of the historical data available, we considered two possible actions per customer, namely increasing or maintaining an individual’s current credit limit. To find this policy, we first formulated this decision-making question as an optimization problem in which the expected profit was maximized; therefore, we balanced two adversarial goals: maximizing the portfolio’s revenue and minimizing the portfolio’s provisions. Second, given the particularities of our problem, we used an offline learning strategy to simulate the impact of the action based on historical data from a super-app (i.e., a mobile application that offers various services from goods deliveries to financial products) in Latin America to train our reinforcement learning agent. Our results, based on the proposed methodology involving synthetic experimentation, show that a Double Q-learning agent with optimized hyperparameters can outperform other strategies and generate a non-trivial optimal policy not only reflecting the complex nature of this decision but offering an incentive to explore reinforcement learning in real-world banking scenarios. Our research establishes a conceptual structure for applying reinforcement learning framework to credit limit adjustment, presenting an objective technique to make these decisions primarily based on data-driven methods rather than relying only on expert-driven systems. We also study the use of alternative data for the problem of balance prediction, as the latter is a requirement of our proposed model. We find the use of such data does not always bring prediction gains.},
  archive      = {J_EJOR},
  author       = {Sherly Alfonso-Sánchez and Jesús Solano and Alejandro Correa-Bahnsen and Kristina P. Sendova and Cristián Bravo},
  doi          = {10.1016/j.ejor.2023.12.025},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {802-817},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing credit limit adjustments under adversarial goals using reinforcement learning},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved credit risk prediction based on an integrated graph
representation learning approach with graph transformation.
<em>EJOR</em>, <em>315</em>(2), 786–801. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate credit risk prediction effectively supports decision makings and risk prevention in quantitative management. The general paradigm of previous works usually conducts supervised classification with internal information (credit attributes) of instances, while recent studies have introduced external information like texts, images, relations, to improve predictive accuracy. However, how to improve forecasting without explicit external relations still needs to be explored. Motivated by this and also by the increasing popularity of Graph Neural Network (GNN) with its fast infiltration into other disciplines, we propose an integrated graph representation learning approach to realize improved credit risk prediction. It includes two stages: (i) treat instances as nodes and use kNN to extract and construct edges; (ii) implement GNN models to discriminate risk/default cases by node classification. In this way, both “unsupervised” graph transformation and “supervised” node classification have been integrated to formulate the hybrid kNN–GNN model, and experiments on widely-used credit datasets demonstrate its outperformance over direct classification by conventional machine learning techniques. Sensitivity of hyperparameter k k indicating different graph sparsity is also analyzed to reveal its optimal selection. Furthermore, ensemble multi-graphs and introduce edge weights are examined to investigate possible advancements with some enhancements observed for both, providing feasible ways to extend the upper bound of this hybrid model’s performances. Our findings exhibit valid improvements in credit risk prediction under the circumstance of only internal information available, and in depth present the future prospects of innovative integrations and applications of GNN methods in dealing with many other operational research tasks.},
  archive      = {J_EJOR},
  author       = {Yong Shi and Yi Qu and Zhensong Chen and Yunlong Mi and Yunong Wang},
  doi          = {10.1016/j.ejor.2023.12.028},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {786-801},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Improved credit risk prediction based on an integrated graph representation learning approach with graph transformation},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Repositioning with unreliable carriers: The case of marine
chassis equipment at container ports. <em>EJOR</em>, <em>315</em>(2),
777–785. (<a href="https://doi.org/10.1016/j.ejor.2023.12.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chassis shortage and, especially, dislocation have become major recurring challenges for the maritime industry in the U.S. To prevent chassis dislocation, chassis pool managers at container ports can work with third-party repositioning partners to pro-actively reposition chassis between the different chassis storage yards within the port complex. One challenge that arises in practice is that not all repositioning requests made by the chassis pool manager are fulfilled, i.e. repositioning partners can be unreliable. This paper contributes to our understanding of the impact of unreliable repositioning partners on chassis shortages by presenting a stochastic model to describe the day-to-day evolution of chassis at container ports. Expressions for the chassis shortage probability and the expected time until a shortage are rigorously derived. Using a detailed case study employing real-world data, (counterintuitive) managerial insights are revealed and discussed that can be used to help formulate policies when managing chassis.},
  archive      = {J_EJOR},
  author       = {ManWo Ng},
  doi          = {10.1016/j.ejor.2023.12.015},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {777-785},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Repositioning with unreliable carriers: The case of marine chassis equipment at container ports},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An incentive compatible ZD strategy-based data sharing model
for federated learning: A perspective of iterated prisoner’s dilemma.
<em>EJOR</em>, <em>315</em>(2), 764–776. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning has been increasingly adopted as an effective means to cope with the significant increase in the volume of training data needed for machine learning and address the privacy concerns in using these data. However, moral hazard may occur when individual data providers (IDPs) use smaller amounts or low-quality data to train their local models and submit these low-quality results (gradients) to free-ride on the benefits of the federated learning. Therefore, federated learning operators often face the dilemma of encouraging more IDPs to participate in data sharing and ensuring truthful contributions from IDPs to obtain high-quality global training results. This article proposes a spontaneous cooperative data-sharing model to address this dilemma. Through an iterated prisoner&#39;s dilemma model solved by the zero-determinant (ZD) strategy, we show that the optimal ZD strategies of all IDPs are to maximize their training efforts when participating in federated learning. According to the comparisons with other approaches through simulations, we demonstrate that either the two-IDP with binary strategies case or the multi-IDP with continuous strategies case could result in the optimal individual utility and social welfare. Therefore, the proposed spontaneous cooperative model effectively avoids the existing moral hazard problem in federated learning and provides a viable instrument for the federated learning operator to maximize the performance of the global model without the need to evaluate the quality of local gradients.},
  archive      = {J_EJOR},
  author       = {Yingmo Jie and Charles Zhechao Liu and Kim-Kwang Raymond Choo and Cheng Guo},
  doi          = {10.1016/j.ejor.2023.12.013},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {764-776},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An incentive compatible ZD strategy-based data sharing model for federated learning: A perspective of iterated prisoner&#39;s dilemma},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). COVID-19 infections and short-run worker performance:
Evidence from european football. <em>EJOR</em>, <em>315</em>(2),
750–763. (<a href="https://doi.org/10.1016/j.ejor.2023.12.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 infections represent a recurrent source of workplace absenteeism impacting labour productivity. Using a unique matched employee-employer dataset, we consider the effects of the virus on the performance of highly valuable employees when returning to work: professional footballers in the top five European leagues. This offers a window to study job scheduling and managerial decision-making. We employ a difference-in-differences (DiD) model that compares the performance of infected players to a matched control group for game tasks that require physical exertion. Results suggest that per-minute performance is unaffected upon returning to play. This is likely due to effective management of minutes on the pitch. We carry out a battery of checks on the primary results to consider causal mechanisms outside of infection that could impact the results such as lockdown breaks, clusters within squads, and scheduling effects. The findings carry an optimistic message and specifically speak to managers supervising physical labour. If appropriately managed, infected workers can return to past performance levels.},
  archive      = {J_EJOR},
  author       = {David Butler and Robert Butler and Alex Farnell and Robert Simmons},
  doi          = {10.1016/j.ejor.2023.12.017},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {750-763},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {COVID-19 infections and short-run worker performance: Evidence from european football},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A tree search algorithm for uncertainty-considered
consecutive discharging and loading operations between ship and offshore
platform. <em>EJOR</em>, <em>315</em>(2), 729–749. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a combinatorial optimization problem for consecutive discharging and loading operations on a floating cargo-handling platform which is a new maritime technology for liquified natural gas redistribution. Because the discharging and loading process involves complex operations with stochastic and sequential nature, a Markov decision process model is formulated for the problem description with the objective of minimizing the ship turnaround time. Then, a tabu-based tree search algorithm allowing a look-ahead at future states is developed. Two sets of practical rules are proposed to control the local tree structure in terms of depth and breadth. The ship stability is also considered. A comprehensive analysis is conducted to determine the most suitable operation strategy for a specific platform design, followed by the analyses of the impacts of strategy parameters, ship size, operation uncertainties. The results show that a customized strategy that considers the dual-cycling operation outperforms other strategies.},
  archive      = {J_EJOR},
  author       = {Chenhao Zhou and Mengxue Yuan and Jingwen Zhang and Wei Zhang},
  doi          = {10.1016/j.ejor.2023.12.010},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {729-749},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A tree search algorithm for uncertainty-considered consecutive discharging and loading operations between ship and offshore platform},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Designing risk-free service for renewable wind and solar
resources. <em>EJOR</em>, <em>315</em>(2), 715–728. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In all world geographies, renewable energy investment is viewed as a major component of the solution to meet the global energy demand. However, key renewable energy resources, such as wind and solar, are inherently stochastic, and thus, pose significant risk and reliability challenges. We apply financial engineering asset securitization principles in this paper to carve out risk-free generation capability from wind and solar energy generation. A market driven, dynamically evolving design and pricing of a risk-free tranche is developed that would allow renewable generators to competitively bid and participate in day-ahead power markets. We apply the framework to wind and solar resources located in different US geographies and assess the risk-free performance of the tranche against a risk-free benchmark established in this paper.},
  archive      = {J_EJOR},
  author       = {Aparna Gupta and Sai Palepu},
  doi          = {10.1016/j.ejor.2023.11.041},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {715-728},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Designing risk-free service for renewable wind and solar resources},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bilevel optimization for feature selection in the
data-driven newsvendor problem. <em>EJOR</em>, <em>315</em>(2), 703–714.
(<a href="https://doi.org/10.1016/j.ejor.2024.01.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the feature-based newsvendor problem, in which a decision-maker has access to historical data consisting of demand observations and exogenous features. In this setting, we investigate feature selection, aiming to derive sparse, explainable models with improved out-of-sample performance. Up to now, state-of-the-art methods utilize regularization, which penalizes the number of selected features or the norm of the solution vector. As an alternative, we introduce a novel bilevel programming formulation. The upper-level problem selects a subset of features that minimizes an estimate of the out-of-sample cost of ordering decisions based on a held-out validation set. The lower-level problem learns the optimal coefficients of the decision function on a training set, using only the features selected by the upper-level. We present a mixed integer linear program reformulation for the bilevel program, which can be solved to optimality with standard optimization solvers. Our computational experiments show that the method accurately recovers ground-truth features already for instances with a sample size of a few hundred observations. In contrast, regularization-based techniques often fail at feature recovery or require thousands of observations to obtain similar accuracy. Regarding out-of-sample generalization, we achieve improved or comparable cost performance.},
  archive      = {J_EJOR},
  author       = {Breno Serrano and Stefan Minner and Maximilian Schiffer and Thibaut Vidal},
  doi          = {10.1016/j.ejor.2024.01.025},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {703-714},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bilevel optimization for feature selection in the data-driven newsvendor problem},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Industry-sensitive language modeling for business.
<em>EJOR</em>, <em>315</em>(2), 691–702. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce BusinessBERT, a new industry-sensitive language model for business applications. The key novelty of our model lies in incorporating industry information to enhance decision-making in business-related natural language processing (NLP) tasks. BusinessBERT extends the Bidirectional Encoder Representations from Transformers (BERT) architecture by embedding industry information during pretraining through two innovative approaches that enable BusinessBert to capture industry-specific terminology: (1) BusinessBERT is trained on business communication corpora totaling 2.23 billion tokens consisting of company website content, MD&amp;A statements and scientific papers in the business domain; (2) we employ industry classification as an additional pretraining objective. Our results suggest that BusinessBERT improves data-driven decision-making by providing superior performance on business-related NLP tasks. Our experiments cover 7 benchmark datasets that include text classification, named entity recognition, sentiment analysis, and question-answering tasks. Additionally, this paper reduces the complexity of using BusinessBERT for other NLP applications by making it freely available as a pretrained language model to the business community. The model, its pretraining corpora and corresponding code snippets are accessible via https://github.com/pnborchert/BusinessBERT .},
  archive      = {J_EJOR},
  author       = {Philipp Borchert and Kristof Coussement and Jochen De Weerdt and Arno De Caigny},
  doi          = {10.1016/j.ejor.2024.01.023},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {691-702},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Industry-sensitive language modeling for business},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic order allocation in a duopoly hybrid workforce of
competition: A machine learning approach. <em>EJOR</em>,
<em>315</em>(2), 668–690. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a continuous-time stochastic differential game model that aims to capture market demand and stochastic cross-network effects, and we seek to find equilibrium order allocation strategies between the firm and the platform. By solving the Hamilton–Jacobi–Bellman (HJB) partial differential equation system, we obtain the feedback equilibrium. For a simple scenario, we derive the analytical solution which indicates that the equilibrium expenditures depend only on the marginal market thickness, and that market thickness is consistently advantageous for the value function. For the complex scenario, we propose a machine learning approach based on the Deep Galerkin Method to solve high-dimensional nonlinear HJB systems, and we demonstrate its good convergence properties. Based on reliable parameter values, our simulation results show that: (1) For higher market thickness, value functions exhibit greater sensitivity to changes in cross-network effects. (2) For a given cross-network effect, the equilibrium acquisition and retention expenditures display significant sensitivity to market thickness and time, respectively. To show the interaction between the two platforms, we present the following two results. One is that for the platform adopting a high pricing strategy, its acquisition expenditures exceed those of its competitor, while retention expenditures are the opposite. The other is that as the cross-network effect of the platform increases, its maximum profit initially rises and then declines, and the time of occurrence of the maximum profit monotonically decreases. In contrast, the competitor’s maximum profit initially declines and then rises, and the time of occurrence of the maximum profit monotonically increases.},
  archive      = {J_EJOR},
  author       = {Xinyu Wang and Yuxing Zhang and Shuhua Zhang},
  doi          = {10.1016/j.ejor.2023.12.026},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {668-690},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic order allocation in a duopoly hybrid workforce of competition: A machine learning approach},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A sustainable dynamic optimization model of pricing and
advertising in the presence of green innovation investment.
<em>EJOR</em>, <em>315</em>(2), 654–667. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing greenhouse effect and global warming, ecological and environmental protection issues are growing tremendously. The Paris Agreement and other international agreements have been enacted to slow down the increase in carbon emissions to prevent it from degrading the ecosystem. With the increasing consumer awareness of environmental protection and environmental regulatory pressures, firms must integrate carbon emissions concerns into decision-making. This paper analyzes a joint dynamic pricing, green innovation investment, and advertising model under the cap-and-price mechanism. The demand rate is multiplicatively related to the selling price and goodwill. The profit-maximizing problem is considered over an infinite horizon. Specifically, we assume that the stock of goodwill grows with green innovation and advertising efforts but depreciates by a constant proportion each period. Numerous theoretical results have been established to expand our comprehension of the problem. Moreover, we present several explications corresponding to these structural properties, characterizing the effects of critical parameters on optimal decisions. Finally, some numerical illustrations and explanations of the concepts of sensitivity analysis are presented to obtain managerial insights, followed by concluding remarks and future research.},
  archive      = {J_EJOR},
  author       = {Chung-Yuan Dye and Tsu-Pang Hsieh},
  doi          = {10.1016/j.ejor.2024.01.007},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {654-667},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A sustainable dynamic optimization model of pricing and advertising in the presence of green innovation investment},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consensus measures based on a fuzzy concept. <em>EJOR</em>,
<em>315</em>(2), 642–653. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When evaluations concerning a decision alternative are available from multiple sources (e.g. criteria or experts), the individual evaluation inputs are typically combined into one value that may be viewed as an aggregate evaluation of the alternative. In such situations, besides the aggregate value, the extent to which the inputs agree is also an important piece of information. Consensus measures are utilized for measuring this degree of agreement. In our study, we will introduce the so-called decumulative distribution function of the individual inputs measured on the unit interval. Using a fuzziness measure of this function, we will construct a consensus measure that satisfies seven reasonable properties. In the proposed construction, a consensus measure depends on a fuzzy entropy that may be viewed as the generator of the proposed consensus measure. This generator function-based nature of the proposed consensus measure makes it flexible. Also, we will prove that in a special case, the new consensus measure coincides with the measure of Bonferroni consensus with implication pairs. Furthermore, we will describe how our proposal can be extended to a weighted version.},
  archive      = {J_EJOR},
  author       = {József Dombi and Tamás Jónás},
  doi          = {10.1016/j.ejor.2024.01.004},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {642-653},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Consensus measures based on a fuzzy concept},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust data envelopment analysis with variable budgeted
uncertainty. <em>EJOR</em>, <em>315</em>(2), 626–641. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Including uncertainty in data envelopment analysis (DEA) is vital to achieving stable and reliable performance evaluations for the field of operational research as business environments are becoming increasingly volatile and unpredictable. Robust DEA models with budgeted uncertainty have been drawing particular attention in the DEA literature for modelling uncertainties, aiming to obtain robust efficiency scores in a way that guarantees the feasibility of solutions. A concern with such robust DEA models – which has been largely ignored in the literature – is that incorporating high uncertainty levels might result in too conservative efficiency measures, possibly reducing the decision support value of such information. To address this concern, this paper tackles uncertainties by employing variable budgeted uncertainty, which is a generalisation of the budgeted uncertainty. We introduce a novel robust DEA model with variable budgeted uncertainty that is less conservative than extant robust DEA models. Furthermore, we suggest a solution for specifying the probabilistic bounds for constraint violations of the uncertain parameters in robust DEA models. A comparison of the introduced robust DEA model with existing robust DEA models based on a numerical example shows an average reduction in the price of robustness by approximately 20%. Finally, the usefulness and applicability of the suggested model are demonstrated by using a large-scale data set in the context of grocery retailing.},
  archive      = {J_EJOR},
  author       = {Aliasghar Arabmaldar and Adel Hatami-Marbini and Dominic Loske and Maik Hammerschmidt and Matthias Klumpp},
  doi          = {10.1016/j.ejor.2023.11.043},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {626-641},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust data envelopment analysis with variable budgeted uncertainty},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How to induce multinational firms’ local sourcing to break
carbon lock-in? <em>EJOR</em>, <em>315</em>(2), 613–625. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon lock-in poses a significant challenge in developing countries such as India and China. To mitigate this issue, these countries can leverage mandatory carbon emission reduction mandates imposed by multinational firms (MNFs) on their domestic manufacturers, thereby spurring the latter&#39;s investment in carbon emission reduction. However, facing eco-conscious customers, MNFs might opt to source from carbon-neutral overseas manufacturers even at high import tariff costs. We therefore explore how a local government can adjust the tariff rate and/or the domestic manufacturer&#39;s carbon emission reduction efficiency to induce an MNF local sourcing. Our findings indicate that even if the MNF has sourced locally, the overall emissions can be effectively reduced only when the domestic manufacturer&#39;s efficiency in reducing carbon emissions surpasses a unique threshold. Regarding social welfare, our results demonstrate a hump-shaped relationship with import tariff rates when an overseas sourcing strategy is adopted. We identify a triple-win situation where the MNF&#39;s local sourcing harmonizes the MNF&#39;s profit-maximization goal, the local government&#39;s environment protection goal, and the social welfare maximization goal. This paper sheds light on the value of MNFs’ sustainability requirements and local sourcing strategy in curbing emissions and tackling the pervasive issue of carbon lock-in that plagues many developing countries.},
  archive      = {J_EJOR},
  author       = {Baozhuang Niu and Nan Zhang and Jianhua Zhang},
  doi          = {10.1016/j.ejor.2023.12.009},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {613-625},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {How to induce multinational firms’ local sourcing to break carbon lock-in?},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accuracy of deterministic nonparametric frontier models with
undesirable outputs. <em>EJOR</em>, <em>315</em>(2), 596–612. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy of deterministic nonparametric frontier models with desirable outputs has been extensively investigated. However, research on the models’ accuracy in the presence of undesirable outputs is almost nonexistent, though applications in this regard are abundant. This paper evaluates the accuracy of seven representative deterministic nonparametric frontier models in dealing with undesirable outputs. The experimental design employs Monte Carlo simulation and translog production functions across a wide range of settings. We find that the integration of undesirable outputs lowers model accuracy. All seven models display robust performance under different returns-to-scale assumptions. Outputs correlation has a positive effect on model performance. Using a large sample can improve the models’ accuracy except for the range-adjusted measure model. The models’ accuracy is most sensitive to noise at low noise levels. Endogeneity has a negative effect on the models’ accuracy, but depreciation of accuracy is minor at low to medium endogeneity levels. Heteroskedasticity leads to improved performance. Overall, the experimental results support the usage of the by-production approach and strongly disfavor the range-adjusted measure approach and the hyperbolic approach. The directional distance function method has an edge for large samples, if the objective is to identify top and bottom units. Another approach, treating undesirable outputs as inputs, is dominated by other methods. The ranking of the methods is generally robust to the variations of returns-to-scale, sample size, noise, outputs correlation, endogeneity, and heteroskedasticity. We also show that the slacks-based measure under the by-production framework has better performance than the Färe–Grosskopf–Lovell index proposed in literature.},
  archive      = {J_EJOR},
  author       = {Derek D. Wang and Yaoyao Ren},
  doi          = {10.1016/j.ejor.2023.12.016},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {596-612},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Accuracy of deterministic nonparametric frontier models with undesirable outputs},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fighting pickpocketing using a choice-based resource
allocation model. <em>EJOR</em>, <em>315</em>(2), 580–595. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by European actions to fight organized crimes, we develop a choice-based resource allocation model that can help policy makers to reduce the number of pickpocket attempts. In this model, the policy maker needs to allocate a limited budget over local and central protective resources as well as over potential pickpocket locations, while keeping in mind the thieves’ random preferences towards potential pickpocket locations. We prove that the optimal budget allocation is proportional in ( i i ) the thieves’ sensitivity towards protective resources and ( i i ii ) the initial attractiveness of the potential pickpocket locations. On top of this, we also study two alternatives of our choice-based resource allocation model: one where pickpocket probabilities are enforced to be equal over the pickpocket locations, and one where the decision-making process of the thief becomes deterministic, with known preferences, as observed by the policy maker. For both alternatives, we also derive the optimal budget allocation and compare it with the initial budget allocation using numerical experiments. Finally, we illustrate how these optimal budget allocations perform against various others budget allocations, proposed by policy makers from the field.},
  archive      = {J_EJOR},
  author       = {Loe Schlicher and Virginie Lurkin},
  doi          = {10.1016/j.ejor.2023.12.007},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {580-595},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fighting pickpocketing using a choice-based resource allocation model},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A scalable multi-objective maintenance optimization model
for systems with multiple heterogeneous components and a finite
lifespan. <em>EJOR</em>, <em>315</em>(2), 567–579. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Delivering after-sales maintenance services is a challenging task for original equipment manufacturers who must tailor their offers to customers’ needs. To accommodate this challenge, we propose a multi-objective optimization model to derive optimal maintenance policies for systems with a large number of heterogeneous components over a finite lifespan. Based on the practical assumption of a fixed time interval between two consecutive scheduled downs, we develop a decomposition approach that enables the fast computation of the optimal policy per component and the optimal time interval between two consecutive scheduled visits. We also analyze the structural properties of the optimal policies for both age-based and condition-based maintenance and prove that they have a non-static control-limit structure. Using a set of computational experiments, we first investigate the computational tractability of our model for systems with an increasing number of components. Then, we apply our model to a real case study to demonstrate how it can be used to derive optimal maintenance policies tailored to different customer needs.},
  archive      = {J_EJOR},
  author       = {İpek Kivanç and Claudia Fecarotti and Néomie Raassens and Geert-Jan van Houtum},
  doi          = {10.1016/j.ejor.2023.12.005},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {567-579},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A scalable multi-objective maintenance optimization model for systems with multiple heterogeneous components and a finite lifespan},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint relocation and pricing in electric car-sharing
systems. <em>EJOR</em>, <em>315</em>(2), 553–566. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study the integrated planning problem of determining car-sharing prices between zones of the operating area and routing employees (operators) to relocate cars in preparation for future uncertain demand. We present a novel two-stage integer stochastic programming model for this problem together with a heuristic algorithm, based on Adaptive Large Neighborhood Search (ALNS), to obtain solutions to realistically sized instances. We test the ALNS heuristic on a set of instances generated based on data from a real car-sharing organization and show that it outperforms a commercial solver.},
  archive      = {J_EJOR},
  author       = {Ulrik Eilertsen and Olav M. Falck-Pedersen and Jone V. Henriksen and Kjetil Fagerholt and Giovanni Pantuso},
  doi          = {10.1016/j.ejor.2023.12.001},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {553-566},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Joint relocation and pricing in electric car-sharing systems},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Piecewise linear trees as surrogate models for system design
and planning under high-frequency temporal variability. <em>EJOR</em>,
<em>315</em>(2), 541–552. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design and planning of systems subject to high-frequency time-varying conditions (e.g., prices, resource supplies, and customer demand) requires the solution of multi-period optimization problems, which have to account for operational aspects that are often described by complex nonlinear models. Accordingly, to overcome the computational challenges associated with the solution of the above problems, we present a framework to build computationally efficient and yet accurate optimization models. We also propose a general method to use trained piecewise linear (PWL) trees as surrogate models to approximate nonlinearities in relatively high dimensions and embed these trees onto mathematical optimization models. We show that, for some datasets, embedding PWL trees leads to models that result in a better balance between accuracy and computational performance when compared with approaches based on other machine-learning surrogate models. We showcase the applicability of the proposed framework via a case study on maintenance optimization of building cooling systems.},
  archive      = {J_EJOR},
  author       = {Yaqing Wu and Christos T. Maravelias},
  doi          = {10.1016/j.ejor.2023.10.028},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {541-552},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Piecewise linear trees as surrogate models for system design and planning under high-frequency temporal variability},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Voluntary green technology adoption: The effects of
regulatory uncertainty and competition. <em>EJOR</em>, <em>315</em>(2),
528–540. (<a href="https://doi.org/10.1016/j.ejor.2023.11.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stricter environmental regulations force firms to adopt green technology. However, firms have realized that the more they voluntarily adopt green technology, the higher the probability that stricter new regulations will be enforced. Thus, firms may delay adopting green technology to resist stricter regulations. Conversely, some firms choose voluntary adoption to gain a market advantage over their rivals. Considering the impact of firms’ adoption decisions on the enforcement of new regulations and product competition, this study develops a two-period game model to investigate how competing firms adopt green technology when facing a potentially stricter regulation. The Nash equilibrium shows that if the basic probability of the new regulation is moderate, firms will differentiate their products through green technology to alleviate price competition; if the probability is high, firms will voluntarily adopt green technology; otherwise, they will wait until the government enforces a stricter regulation and mandates them to adopt green technology. Interestingly, our results show that potentially stricter regulations will induce firms to behave strategically. When firms’ green cost difference is small, competing firms will collude to delay stricter regulations by not adopting green technology. However, when firms’ green cost difference is significant, the low-cost firm tends to adopt green technology to lobby for new regulations and gain a cost advantage. Our work not only provides an economic explanation for the different adoption behaviors of firms but also provides managerial insights for competing firms as well as policy insights for the government.},
  archive      = {J_EJOR},
  author       = {Shaofu Du and Chong Huang and Xia Yan and Wenzhi Tang},
  doi          = {10.1016/j.ejor.2023.11.042},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {528-540},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Voluntary green technology adoption: The effects of regulatory uncertainty and competition},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid forecasting model to predict the duration and cost
performance of projects with bayesian networks. <em>EJOR</em>,
<em>315</em>(2), 511–527. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new hybrid forecasting model to predict the final time and cost of a project using input parameters from the project scheduling and risk analysis literature. The hybrid method integrates two well-known risk models. A Structural Equation Modeling constructs and validates a theoretical risk model to represent known relations between project indicators and the project performance. A Bayesian Networks is used to train the theoretical model using artificial project data from the literature. These two integrated models are then used to predict the final duration and cost of a new unseen project. The accuracy of this integrated model is compared with other well-known forecasting methods from the literature. The computational experiments on a set of 33 empirical projects show that risk models demonstrate a noteworthy advantage for time and cost forecasting. To show the usefulness of this method, it is compared with a set of known machine learning forecasting algorithms. These static predictions of risk models are also compared with some well-known dynamic forecasting methods that continuously update the time/cost predictions along the project progress. These dynamic models make use of predictors from the earned value management and earned duration management literature. The results show that the static risk models offer more precise forecasts than the dynamic methods in the first half of the project progress for time forecasting, but then loose their power in favor of the dynamic forecasts.},
  archive      = {J_EJOR},
  author       = {Izel Ünsal-Altuncan and Mario Vanhoucke},
  doi          = {10.1016/j.ejor.2023.12.029},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {511-527},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A hybrid forecasting model to predict the duration and cost performance of projects with bayesian networks},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Valid inequalities for the k-color shortest path problem.
<em>EJOR</em>, <em>315</em>(2), 499–510. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a digraph D = ( V , A ) D=(V,A) where each arc ( i , j ) ∈ A (i,j)∈A has a cost d i j ∈ R + dij∈R+ and a color c ( i , j ) c(i,j) , a positive integer k k , and vertices s , t ∈ V s,t∈V , the k k -Color Shortest Path Problem consists in finding a path from s s to t t of minimum cost while using at most k k distinct arc colors. We propose valid inequalities for the problem that proved to strengthen the linear relaxation of an existing Integer Linear Programming formulation for the problem. One exponential set of valid inequalities defines a new formulation for the problem that is solved by using a branch-and-cut algorithm. We introduce more challenging instances for the problem and present numerical experiments for both the benchmark and the new instances. Finally, we evaluate the individual and the collective use of the valid inequalities. Computational results for the proposed ideas and for existing solution approaches for the problem showed the effectiveness of the new inequalities in handling the new instances, both in terms of execution times and improvement of the linear relaxed solutions.},
  archive      = {J_EJOR},
  author       = {Rafael Castro de Andrade and Emanuel Elias Silva Castelo and Rommel Dias Saraiva},
  doi          = {10.1016/j.ejor.2023.12.014},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {499-510},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Valid inequalities for the k-color shortest path problem},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Instance space analysis for 2D bin packing mathematical
models. <em>EJOR</em>, <em>315</em>(2), 484–498. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we apply Instance Space Analysis (ISA) to study the two-dimensional bin-packing problem. We consider classical and newly-generated instances to test the performance of four mixed-integer programming (MIP) models from the literature. This is the first time ISA is used to compare MIP models. We set as a performance metric the time taken by the black-box MIP solver CPLEX to obtain a proven optimal solution when running each model. Our results provide a new perspective on the different models’ performance according to each instance’s features.},
  archive      = {J_EJOR},
  author       = {Chang Liu and Kate Smith-Miles and Tony Wauters and Alysson M. Costa},
  doi          = {10.1016/j.ejor.2023.12.008},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {484-498},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Instance space analysis for 2D bin packing mathematical models},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multiphase dynamic programming algorithm for the shortest
path problem with resource constraints. <em>EJOR</em>, <em>315</em>(2),
470–483. (<a href="https://doi.org/10.1016/j.ejor.2023.11.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shortest path problem with resource constraints (SPPRC) finds a least cost path between two nodes in a network while respecting constraints on resource consumption. The problem is mainly used as a subproblem inside column generation for crew scheduling and vehicle routing problems. The standard approach for the subproblems is based on dynamic programming (DP). This class of methods is generally effective in practice when there are only a few resources, but it seems to be time-consuming for huge instances with many resources. To handle this issue, we propose a new exact primal algorithm called the multiphase dynamic programming algorithm (MPDPA) to solve the SPPRC in acyclic networks. The proposed approach splits the state-space into small disjoint subspaces. These subspaces are sequentially explored in several iterations, where each iteration builds on the previous ones, to reduce the dimension of the subspaces to explore and to quickly generate better paths. Computational experiments on vehicle and crew scheduling instances show the excellent performance of our approach compared to the standard DP method. On the one hand, MPDPA returns optimal solutions while achieving time reduction factors between 1.44 and 3.59 on average compared to DP. On the other hand, MPDPA is able to generate feasible paths with up to 90% of the optimal cost in less than 10% of the time required by standard DP. This feature is useful in column generation and may greatly reduce the computational effort, because we can stop the MPDPA solution process once columns with sufficiently negative reduced costs are obtained.},
  archive      = {J_EJOR},
  author       = {Ilyas Himmich and Issmail El Hallaoui and François Soumis},
  doi          = {10.1016/j.ejor.2023.11.047},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {470-483},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A multiphase dynamic programming algorithm for the shortest path problem with resource constraints},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A simulation-based approximate dynamic programming approach
to dynamic and stochastic resource-constrained multi-project scheduling
problem. <em>EJOR</em>, <em>315</em>(2), 454–469. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the dynamic and stochastic resource-constrained multi-project scheduling problem which allows for the random arrival of projects and stochastic task durations. Completing projects generates rewards, which are reduced by a tardiness cost in the case of late completion. Multiple types of resource are available, and projects consume different amounts of these resources when under processing. The problem is modelled as an infinite-horizon discrete-time Markov decision process and seeks to maximise the expected discounted long-run profit. We use an approximate dynamic programming algorithm (ADP) with a linear approximation model which can be used for online decision making. Our approximation model uses project elements that are easily accessible by a decision-maker, with the model coefficients obtained offline via a combination of Monte Carlo simulation and least squares estimation. Our numerical study shows that ADP often statistically significantly outperforms the optimal reactive baseline algorithm (ORBA). In experiments on smaller problems however, both typically perform suboptimally compared to the optimal scheduler obtained by stochastic dynamic programming. ADP has an advantage over ORBA and dynamic programming in that ADP can be applied to larger problems. We also show that ADP generally produces statistically significantly higher profits than common algorithms used in practice, such as a rule-based algorithm and a reactive genetic algorithm.},
  archive      = {J_EJOR},
  author       = {U. Satic and P. Jacko and C. Kirkbride},
  doi          = {10.1016/j.ejor.2023.10.046},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {454-469},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A simulation-based approximate dynamic programming approach to dynamic and stochastic resource-constrained multi-project scheduling problem},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exact and heuristic algorithms for minimizing the makespan
on a single machine scheduling problem with sequence-dependent setup
times and release dates. <em>EJOR</em>, <em>315</em>(2), 442–453. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes efficient exact and heuristic approaches for minimizing the makespan on a single machine scheduling problem with sequence-dependent setup times and release dates. The exact procedure consists of a branch-and-price (B&amp;P) algorithm implemented over an arc-time-indexed formulation with a pseudo-polynomial number of variables and constraints. Our B&amp;P algorithm includes several modern features, such as a dynamic ng-path relaxation and a bidirectional labeling method for efficiently solving the pricing subproblem. The proposed heuristic algorithm is based on the iterated local search framework that employs a beam search approach adapted from the literature for generating initial solutions and an efficient scheme to perform move evaluations in amortized constant time. Computational experiments were carried out on benchmark instances containing 1800 instances ranging from 25 to 150 jobs. The results obtained attest the high performance of both the exact and heuristic algorithms in obtaining high-quality bounds when compared to existing methods. We report improved lower and upper bounds for the vast majority of the instances, as well as optimal solutions for 42.7% of the instances.},
  archive      = {J_EJOR},
  author       = {Rafael Morais and Teobaldo Bulhões and Anand Subramanian},
  doi          = {10.1016/j.ejor.2023.11.024},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {442-453},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exact and heuristic algorithms for minimizing the makespan on a single machine scheduling problem with sequence-dependent setup times and release dates},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Flexibility in manufacturing system design: A review of
recent approaches from operations research. <em>EJOR</em>,
<em>315</em>(2), 413–441. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to increasing demand uncertainty and product variety, manufacturing systems must continually adapt to maintain productivity. Generally, decision-makers can maintain flexibility to account for these adaptations efficiently already in the design phase of manufacturing systems. Consequently, over the past few decades, a significant body of literature has addressed manufacturing system design associated with various manufacturing paradigms, claiming to provide the ‘right’ level of flexibility. Advanced analytical methods from Operations Research are frequently used in this domain to support decision-making. However, articles on the manufacturing paradigms remain in disjunct literature streams. In this article, we review literature from the last two decades that focuses on the application of Operations Research methods in manufacturing system design. The analyzed articles were selected from peer-reviewed scientific literature in a systematic search and screening process. To unite literature on different manufacturing paradigms, the concept of manufacturing flexibility is adapted, focusing on flexibility types required and considered in manufacturing systems’ design phases. The reviewed articles frequently employ mixed-integer linear programming or propose heuristic procedures. Most contributions evaluate static and deterministic settings, overlooking short- or long-term uncertainties in the design of manufacturing systems. Predominantly, flexibility is maintained to enhance economic or performance-oriented objectives. The consideration of social or ecological indicators, however, is barely found. Therefore, research perspectives from this analysis include integrating social and ecological indicators into multi-objective decision-making methods, anticipating neighboring planning problems during design, and applying systematic procedures to address uncertainty.},
  archive      = {J_EJOR},
  author       = {Christian Weckenborg and Patrick Schumacher and Christian Thies and Thomas S. Spengler},
  doi          = {10.1016/j.ejor.2023.08.050},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {413-441},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Flexibility in manufacturing system design: A review of recent approaches from operations research},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Corrigendum to “vehicle routing for connected service areas
- a versatile approach covering single, hierarchical, and bi-criteria
objectives” [european journal of operational research 313(3) (2024)
905–925]. <em>EJOR</em>, <em>315</em>(1), 411. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Stefan Bock},
  doi          = {10.1016/j.ejor.2024.01.020},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {411},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Corrigendum to “Vehicle routing for connected service areas - A versatile approach covering single, hierarchical, and bi-criteria objectives” [European journal of operational research 313(3) (2024) 905–925]},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal investment in ambiguous financial markets with
learning. <em>EJOR</em>, <em>315</em>(1), 393–410. (<a
href="https://doi.org/10.1016/j.ejor.2024.01.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the classical multi-asset Merton investment problem under drift uncertainty, i.e. the asset price dynamics are given by geometric Brownian motions with constant but unknown drift coefficients. The investor assumes a prior drift distribution and is able to learn by observing the asset prize realizations during the investment horizon. While the solution of an expected utility maximizing investor with constant relative risk aversion (CRRA) is well known, we consider the optimization problem under risk and ambiguity preferences by means of the KMM (Klibanoff et al., 2005) approach. Here, the investor maximizes a double certainty equivalent. The inner certainty equivalent is for given drift coefficient, the outer is based on a drift distribution. Assuming also a CRRA type ambiguity function, it turns out that the optimal strategy can be stated in terms of the solution without ambiguity preferences but an adjusted drift distribution. To the best of our knowledge an explicit solution method in this setting is new. We rely on some duality theorems to prove our statements. Based on our theoretical results, we are able to shed light on the impact of the prior drift distribution as well as the consequences of ambiguity preferences via the transfer to an adjusted drift distribution, i.e. we are able to explain the interaction of risk and ambiguity preferences. We compare our results with the ones in a pre-commitment setup where the investor is restricted to deterministic strategies. It turns out that (under risk and ambiguity aversion) an infinite investment horizon implies in both cases a maximin decision rule, i.e. the investor follows the worst (best) Merton fraction (over all realizations of it) if she is more (less) risk averse than a log-investor. We illustrate our findings with an extensive numerical study.},
  archive      = {J_EJOR},
  author       = {Nicole Bäuerle and Antje Mahayni},
  doi          = {10.1016/j.ejor.2024.01.022},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {393-410},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal investment in ambiguous financial markets with learning},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robo-advising: Optimal investment with mismeasured and
unstable risk preferences. <em>EJOR</em>, <em>315</em>(1), 378–392. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a robo-advising framework that incorporates interactions with a client who has time-varying risk preferences that can be mismeasured. In the presence of measurement error, a client’s welfare decreases compared to perfect measurements. The worse the quality of the measurements (higher measurement volatility), the worse this is for the client. When measurements are more volatile, interacting frequently can lead to further losses in a client’s welfare. We include a client’s willingness to interact using a budget constraint. A trade-off arises between interacting frequently to obtain up-to-date information with more volatile measurements versus less up-to-date information with more accuracy. We find that integrating client-initiated interactions and using an average of measured risk aversions both lead to more personalised investment advice. Using an alternative investment strategy rather than a time-consistent strategy can lead to improved welfare for the client.},
  archive      = {J_EJOR},
  author       = {Henk Keffert},
  doi          = {10.1016/j.ejor.2023.12.002},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {378-392},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robo-advising: Optimal investment with mismeasured and unstable risk preferences},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solidarity to achieve stability. <em>EJOR</em>,
<em>315</em>(1), 368–377. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agents may form coalitions. Each coalition shares its endowment among its agents by applying a sharing rule. The sharing rule induces a coalition formation problem by assuming that agents rank coalitions according to the allocation they obtain in the corresponding sharing problem. We characterize the sharing rules that induce a class of stable coalition formation problems as those that satisfy a natural axiom that formalizes the principle of solidarity. Thus, solidarity becomes a sufficient condition to achieve stability.},
  archive      = {J_EJOR},
  author       = {Jorge Alcalde-Unzu and Oihane Gallo and Elena Inarra and Juan D. Moreno-Ternero},
  doi          = {10.1016/j.ejor.2023.11.034},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {368-377},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solidarity to achieve stability},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An integrated bi-objective optimization model accounting for
the social acceptance of renewable fuel production networks.
<em>EJOR</em>, <em>315</em>(1), 354–367. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Renewable liquid fuels produced from biomass, hydrogen, and carbon dioxide play an important role in reaching climate neutrality in the transportation sector. For large-scale deployment, production facilities and corresponding logistics have to be established. However, the implementation of such a large-scale renewable fuel production network requires acceptance by citizens. To gain insights into the structure of efficient and socially accepted renewable fuel production networks, we propose a bi-objective mixed-integer programming model. In addition to an economic objective function, we consider social acceptance as a second objective function. We use results from a conjoint analysis study on the acceptance and preference of renewable fuel production networks, considering the regional topography, facility size, production pathway, and raw material transportation to model social acceptance. We find significant trade-offs between the economic and social acceptance objective. The most favorable solution from a social acceptance perspective is almost twice as expensive as the most efficient economical solution. However, it is possible to strongly increase acceptance at a moderate expense by carefully selecting sites with preferred regional topography.},
  archive      = {J_EJOR},
  author       = {Tristan Becker and Michael Wolff and Anika Linzenich and Linda Engelmann and Katrin Arning and Martina Ziefle and Grit Walther},
  doi          = {10.1016/j.ejor.2023.11.044},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {354-367},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An integrated bi-objective optimization model accounting for the social acceptance of renewable fuel production networks},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A capacitated multi-vehicle covering tour problem on a road
network and its application to waste collection. <em>EJOR</em>,
<em>315</em>(1), 338–353. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In most Swiss municipalities, a curbside system consisting of heavy trucks stopping at almost each household is used for non-recoverable waste collection. Due to the many stops of the trucks, this strategy causes high fuel consumption, emissions and noise. These effects can be alleviated by reducing the number of stops performed by the collection vehicles. One possibility consists of selecting a subset of candidate locations that are scattered throughout the municipality to place collection points which are used by residents to bring their waste. Provided that the underlying road network is available and that the collection vehicle has a known capacity, we refer to this problem as the capacitated multi-vehicle covering tour problem on a road network (C m m -CTP-R). We propose a road-network-based mixed-integer linear programming (MILP) formulation that exploits the sparsity of the network. We compare it against the MILP formulation that results from assuming a customer-based graph, which is typically used in vehicle routing problems (VRP). To solve large instances, we develop a two-phased heuristic approach that addresses the two subproblems the C m m -CTP-R is built on: a set covering problem to select the locations and a split-delivery VRP to determine the tours. Computational experiments on instances derived from real-life data show that the road-network-based formulation is better suited. Furthermore, the proposed heuristic provides good solutions with optimality gaps below 1.7% and finds better solutions for most of the instances that the exact method is not able to solve within a given time limit.},
  archive      = {J_EJOR},
  author       = {Vera Fischer and Meritxell Pacheco Paneque and Antoine Legrain and Reinhard Bürgy},
  doi          = {10.1016/j.ejor.2023.11.040},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {338-353},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A capacitated multi-vehicle covering tour problem on a road network and its application to waste collection},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sharing in construction projects — on determining optimal
container assignments for the on-site accommodation of trades.
<em>EJOR</em>, <em>315</em>(1), 324–337. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sharing economy is among the top trending topics in operations research. In this paper, we introduce a novel sharing application encountered in the construction industry. The problem under research, which has been developed in close cooperation with an industrial partner, is concerned with the on-site accommodation of trades in large-scale construction projects. In such projects, a construction logistics company provides containers gathered in an area of the site and assigns trades to them based on their requests issued online. Usually, a single trade will only remain on-site for a certain period of time, i. e. for as long as it is carrying out its activities in the project. Similarly, containers will only be provided for a certain time interval. This dynamic nature may require re-assigning trades as the project progresses. As such re-assignments impose costs for the logistics company, it is the goal to keep them to a minimum. We formally define the resulting optimization problem, present two mixed-integer programming formulations and develop a fix-and-optimize heuristic. In an extensive computational study, we show the latter to not only clearly outperform standard solver CPLEX operating on the holistic mixed-integer program, but to also provide substantial savings over the assignment policy currently applied in practice.},
  archive      = {J_EJOR},
  author       = {Michael Dienstknecht and Dirk Briskorn},
  doi          = {10.1016/j.ejor.2023.11.045},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {324-337},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Sharing in construction projects — On determining optimal container assignments for the on-site accommodation of trades},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A cascading model of stakeholder engagement for large-scale
regional development using structured dialogical design. <em>EJOR</em>,
<em>315</em>(1), 307–323. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a large-scale systemic intervention conducted in the wine village communities of Cyprus. The scientific aim of this paper is to contribute to expanding community operational research&#39;s purpose, scope, and tools by reflecting on a cascading engagement model of stakeholders toward regional development in Cyprus. An ad-hoc committee comprising three representatives of the Department of Town Planning and Housing, three members of the Cyprus Academy of Public Administration, and a few external consultants came up initially with about a dozen stakeholders’ categories they considered “relevant.” Using a stepwise (cascading) expansion, they eventually engaged over 200 actors representing 26 stakeholder categories. The first 29 stakeholders identified 71 obstacles to developing the wine villages using Structured Democratic Dialogue (SDD). They clustered the obstacles into themes and formed working groups to address them. Each group identified and invited experts and additional stakeholders they considered relevant to form extended theme-specific groups. Each group conducted a SWOT analysis to deepen understanding and produced a thematic vision map using SDD. A holistic vision map was constructed through a final SDD process in which participants were the authors of the most influential factors from each thematic vision map. The approach adheres to the bottom-up, community-led method and falls within community operational research and citizen science. The cascading model offers a formula for multi-methodological intervention. The stepwise bottom-up identification and engagement of stakeholders empowers and engages authentically, especially those marginalised. The expansion in numbers and the effective engagement of stakeholders creates the required momentum for societal change. We discuss the model&#39;s broader applicability, frame it within third-phase science, and suggest future directions.},
  archive      = {J_EJOR},
  author       = {Marios Michaelides and Yiannis Laouris},
  doi          = {10.1016/j.ejor.2023.11.050},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {307-323},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A cascading model of stakeholder engagement for large-scale regional development using structured dialogical design},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modelling de novo programming within simon’s satisficing
theory: Methods and application in designing an optimal offshore wind
farm location system. <em>EJOR</em>, <em>315</em>(1), 289–306. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {De novo programming (DNP) is an efficient technique for optimal system design. This paper explores the ability to link the DNP technique with Simon’s satisficing theory to deal with a system design that is satisfactory rather than optimal. To achieve this aim, the ideal vector is replaced by an aspiration-level vector, and the solutions are determined by minimising the L p Lp -distance metric between the aspiration level and the feasible objective region. To generate a satisficing solution, we develop two models (weighted DNP (W-DNP) and Chebyshev DNP (C-DNP)) based on goal programming techniques. To achieve equilibrium between the solutions obtained from W-DNP and C-DNP, an extended DNP (E-DNP) model is proposed. Moreover, to deal with uncertainty and give decision makers more flexibility to incorporate their preferences, we consider the concept of penalty function (PF) with DNP and propose DNP type models with penalty functions (DNP-PFs). An illustrative example is adopted to show the usefulness of the proposed approach over the standard DNP. We also conduct a hypothetical application to Italian offshore wind farm locations to assess and validate the proposed formulations for solving real-world problems. To check the stability of the obtained results, the impact of the weights on the obtained solution is detected with a weight–space analysis. The results confirm the proposed methodologies and show that they can assist decision makers in determining the optimal location under uncertain aspiration levels.},
  archive      = {J_EJOR},
  author       = {Amin Hocine and Noureddine Kouaissah and Sergio Ortobelli Lozza and Tarik Aouam},
  doi          = {10.1016/j.ejor.2023.11.046},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {289-306},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modelling de novo programming within simon’s satisficing theory: Methods and application in designing an optimal offshore wind farm location system},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Designing electricity distribution networks: The impact of
demand coincidence. <em>EJOR</em>, <em>315</em>(1), 271–288. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the global effort to reduce carbon emissions, clean technologies such as electric vehicles and heat pumps are increasingly introduced into electricity distribution networks. These technologies considerably increase electricity flows and can lead to more coincident electricity demand. In this paper, we analyze how such increases in demand coincidence impact future distribution network investments. For this purpose, we develop a novel model for designing electricity distribution networks, called the distribution network reconfiguration problem with line-specific demand coincidence (DNRP-LSDC). Our analysis is two-fold: (1) We apply our model to a large sample of real-world networks from a Swiss distribution network operator. We find that a high demand coincidence due to, for example, a large-scale uptake of electric vehicles, requires a substantial amount of new network line construction and increases average network cost by 84% in comparison to the status quo. (2) We use a set of synthetic networks to isolate the effect of specific network characteristics. Here, we show that high coincidence has a more detrimental effect on large networks and on networks with low geographic consumer densities, as present in, e. g., rural areas. We also show that expansion measures are robust to variations in the cost parameters. Our results demonstrate the necessity of designing policies and operational protocols that reduce demand coincidence. Moreover, our findings show that operators of distribution networks must consider the demand coincidence of new electricity uses and adapt investment budgets accordingly. Here, our solution algorithms for the DNRP-LSDC problem can support operators of distribution networks in strategic and operational network design tasks.},
  archive      = {J_EJOR},
  author       = {Gunther Gust and Alexander Schlüter and Stefan Feuerriegel and Ignacio Úbeda and Jonathan T. Lee and Dirk Neumann},
  doi          = {10.1016/j.ejor.2023.11.029},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {271-288},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Designing electricity distribution networks: The impact of demand coincidence},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Less is more? Channel separation to mitigate triple
competition and combat copycats in agency e-commerce. <em>EJOR</em>,
<em>315</em>(1), 242–270. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practice, agency e-commerce, also known as e-marketplace, faces the challenges of copycat products with nearly identical “consumption quality” to genuine products. The e-marketplace may lack incentives to combat copycat sellers, leading many brands to adopt a novel “Channel Separation” strategy to protect their brand image. Under this strategy, although the brand seems to lose profit from stopping product sales in the e-marketplace, copycat products will be successfully revealed and the channel competition will be softened. We then investigate the brand&#39;s strategy choice by examining the tradeoffs among three factors: triple competition under a co-existing strategy (the brand decides co-selling with the copycat sellers in the e-marketplace), dual-channel competition under a channel separation strategy (the brand sells genuine products exclusively through the self-operated channel), and the value of revealing copycat products to eliminate their free-riding of brand image. Our findings indicate that a high agency commission rate and/or intensified channel competition may lead to a surge in copycat product sales under the co-existing strategy. Only the brand with a significant image advantage could benefit from channel separation. Interestingly, our results suggest that copycat sellers and the e-marketplace could also benefit from the brand&#39;s channel separation when channel competition is adequately alleviated and the brand&#39;s image advantage is not very pronounced.},
  archive      = {J_EJOR},
  author       = {Baozhuang Niu and Yiyuan Ruan and Haotao Xu},
  doi          = {10.1016/j.ejor.2023.10.033},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {242-270},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Less is more? channel separation to mitigate triple competition and combat copycats in agency e-commerce},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging decision diagrams to solve two-stage stochastic
programs with binary recourse and logical linking constraints.
<em>EJOR</em>, <em>315</em>(1), 228–241. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We generalize an existing binary decision diagram-based (BDD-based) approach of Lozano and Smith (MP, 2022) to solve a special class of two-stage stochastic programs (2SPs) with binary recourse, where the first-stage decisions impact the second-stage constraints. First, we extend the second-stage problem to a more general setting where logical expressions of the first-stage solutions enforce constraints in the second stage. Then, as our primary contribution, we introduce a complementary problem, that appears more naturally for many of the same applications of the former approach, and a distinct BDD-based solution method, that is more efficient than the existing BDD-based approach on commonly applicable problem classes. In the novel problem, second-stage costs, rather than constraints, are impacted by expressions of the first-stage decisions. In both settings, we convexify the second-stage problems using BDDs and parameterize either the BDD arc costs or capacities with first-stage solutions. We extend this work by incorporating conditional value-at-risk and propose the first decomposition method for 2SP with binary recourse and a risk measure. We apply these methods to a novel stochastic problem, namely stochastic minimum dominating set problem, and present numerical results to support their effectiveness.},
  archive      = {J_EJOR},
  author       = {Moira MacNeil and Merve Bodur},
  doi          = {10.1016/j.ejor.2023.12.021},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {228-241},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Leveraging decision diagrams to solve two-stage stochastic programs with binary recourse and logical linking constraints},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic differential investment and reinsurance game
between an insurer and a reinsurer under thinning dependence structure.
<em>EJOR</em>, <em>315</em>(1), 213–227. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a non-zero-sum stochastic differential investment and reinsurance game between an insurer and a reinsurer. It is assumed that the insurer can purchase proportional reinsurance and the claim businesses between the insurer and the reinsurer are correlated through thinning dependence structure. Besides, both the insurer and the reinsurer are allowed to invest in a risk-free asset and a risky asset, in which the two risky assets are supposed to be correlated. The objective of each is to maximize the mean–variance utility of the difference between its terminal wealth and that of its cooperator. By solving the extended Hamilton–Jacobi–Bellman systems within the game theoretic framework, explicit expressions of the optimal time-consistent strategies and value functions of the insurer and the reinsurer are derived, and some comparison results with and without game are obtained as well. Finally, several sensitivity analyses and numerical examples are presented to illustrate the effects of market parameters on the optimal strategies as well as the economic interpretation behind.},
  archive      = {J_EJOR},
  author       = {Caibin Zhang and Zhibin Liang and Yu Yuan},
  doi          = {10.1016/j.ejor.2023.12.035},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {213-227},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stochastic differential investment and reinsurance game between an insurer and a reinsurer under thinning dependence structure},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Variance swaps with mean reversion and multi-factor
variance. <em>EJOR</em>, <em>315</em>(1), 191–212. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel model for the valuation of variance swaps that incorporates a multi-factor stochastic spot variance and a multi-factor stochastic long-term variance, while allowing mean reversion in the asset price and a co-jump structure in the model. We propose a general analytical approach for pricing discretely monitored variance swaps via a moment-based method and confirm its accuracy and efficiency using Monte Carlo simulations. Our empirical results indicate that the model with a three-factor spot variance and a one-factor long-term variance significantly outperforms other nested models. The incorporation of multiple factors in our model is essential not only for fitting market data, but also for reconciling the term structure of variance swaps.},
  archive      = {J_EJOR},
  author       = {Bin Wu and Pengzhan Chen and Wuyi Ye},
  doi          = {10.1016/j.ejor.2023.12.012},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {191-212},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Variance swaps with mean reversion and multi-factor variance},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online reinforcement learning for condition-based group
maintenance using factored markov decision processes. <em>EJOR</em>,
<em>315</em>(1), 176–190. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a condition-based group maintenance problem for multi-component systems, where the degradation process of a specific component is affected only by its neighbouring ones, leading to a special type of stochastic dependence among components. We formulate the maintenance problem into a factored Markov decision process taking advantage of this dependence property, and develop a factored value iteration algorithm to efficiently approximate the optimal policy. Through both theoretical analyses and numerical experiments, we show that the algorithm can significantly reduce computational burden and improve efficiency in solving the optimization problem. Moreover, since model parameters are unknown a priori in most practical scenarios, we further develop an online reinforcement learning algorithm to simultaneously learn the model parameters and determine an optimal maintenance action upon each inspection. A novel feature of this online learning algorithm is that it is capable of learning both transition probabilities and system structure indicating the stochastic dependence among components. We discuss the error bound and sample complexity of the developed learning algorithm theoretically, and test its performance through numerical experiments. The results reveal that our algorithm can effectively learn the model parameters and approximate the optimal maintenance policy.},
  archive      = {J_EJOR},
  author       = {Jianyu Xu and Bin Liu and Xiujie Zhao and Xiao-Lin Wang},
  doi          = {10.1016/j.ejor.2023.11.039},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {176-190},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Online reinforcement learning for condition-based group maintenance using factored markov decision processes},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Container port truck dispatching optimization using Real2Sim
based deep reinforcement learning. <em>EJOR</em>, <em>315</em>(1),
161–175. (<a href="https://doi.org/10.1016/j.ejor.2023.11.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In marine container terminals, truck dispatching optimization is often considered as the primary focus as it provides crucial synergy between the sea-side operations and yard-side activities and hence can greatly affect the terminal throughput and quay crane utilization. However, many existing studies rely on strong assumptions that often overlook the uncertainties and dynamics innate to real-life applications. In this work, we propose a dynamic truck dispatching system for container ports equipped with the latest IoT technologies. The system is comprised of Real2Sim simulation and a truck dispatch agent, trained through a spatial-attention based deep reinforcement learning module, supported by an expert network. The proposed Real2Sim framework has the ability to model the non-linear complexities and non-deterministic events while our attention-aware deep reinforcement learning module is capable of making full use of both historical and real-time port data to learn a high-quality truck dispatching policy under uncertainties. Extensive experiments show our proposed method has good generalization and achieves the state-of-the-art results on the problems derived from real-life data of a large international port.},
  archive      = {J_EJOR},
  author       = {Jiahuan Jin and Tianxiang Cui and Ruibin Bai and Rong Qu},
  doi          = {10.1016/j.ejor.2023.11.038},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {161-175},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Container port truck dispatching optimization using Real2Sim based deep reinforcement learning},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blockchain adoption in retail operations: Stablecoins and
traceability. <em>EJOR</em>, <em>315</em>(1), 147–160. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retailers are embracing cryptocurrency payments to gain a competitive edge. However, the high volatility of traditional cryptocurrencies, such as Bitcoin, deters risk-averse consumers from using them regularly. This issue is particularly salient in retail markets with high product return rates, as consumers may bear the volatility risk by directly holding cryptocurrencies after claiming a refund. In real-world operations, collateralized stablecoins are proposed as a solution for transaction settlements, yet they still exhibit short-term volatility, as shown by empirical evidence. In this context, retailers can reduce the likelihood of returns by leveraging blockchain traceability to disclose information. This study analytically investigates how the retailer effectively utilizes the two blockchain functions to enhance firm profitability and increase consumer surplus. Our analysis shows that the retailer may offer a stingy or generous refund policy with blockchain adoption, depending on the degrees of information disclosure and price volatility. Next, we find that blockchain adoption always benefits consumers, though it may decrease social welfare. Interestingly, the benefit brought by blockchain to consumers declines if information is oversupplied. Further, we discover that blockchain adoption is likely to increase retailer profit when the information disclosure level is polarized (i.e., very high or low). Finally, the analysis reveals that greater stability of stablecoins benefits the retailer but hurts consumers. The reason for this seemingly counterintuitive result is that having stablecoins with better stability allows the retailer to charge a high price.},
  archive      = {J_EJOR},
  author       = {Kun Zhang and Tsan-Ming Choi and Sai-Ho Chung and Yue Dai and Xin Wen},
  doi          = {10.1016/j.ejor.2023.11.026},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {147-160},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Blockchain adoption in retail operations: Stablecoins and traceability},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Platform financing vs. Bank financing: Strategic choice of
financing mode under seller competition. <em>EJOR</em>, <em>315</em>(1),
130–146. (<a href="https://doi.org/10.1016/j.ejor.2023.11.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Third-party sellers on online platforms primarily rely on banks to meet their financing requirements and are often constrained by the lack of sufficient working capital. Online platforms such as Amazon and Alibaba have ushered new dynamics in the e-commerce financing landscape by offering working capital loans to these sellers, thereby directly competing with banks and influencing market competition. This paper analytically studies how the competition between third-party sellers on platforms affects the strategic financing choices of sellers, namely, platform financing (P) vs. bank financing (B). We examine how the financing choice influences sellers’ pricing decisions in the competitive product market. Based on the sellers’ financing choices, four lending modes are possible: BB, PP, BP, and PB. Our analyses provide critical insights on the optimal financing choices and uncover the interplay of pricing, product substitution, referral fees, and production costs. We show that any seller deviating from PP to a hybrid mode (BP/PB) leads to a higher platform interest rate and a lower seller profit. We find that the competing sellers choose a hybrid lending mode when the unit production cost is low. However, the platform always prefers PP, leading to an all-win outcome in the supply chain when the production cost is high. Furthermore, for products with low referral fees and high substitution effect, BP/PB emerges as the equilibrium mode, while for products with low referral fees and low substitution effect, PP is the equilibrium outcome. Interestingly, we find that both sellers may choose bank financing when their working capital levels are high.},
  archive      = {J_EJOR},
  author       = {Prasenjit Mandal and Preetam Basu and Tsan-Ming Choi and Sambit Brata Rath},
  doi          = {10.1016/j.ejor.2023.11.025},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {130-146},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Platform financing vs. bank financing: Strategic choice of financing mode under seller competition},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Risk pooling under demand and price uncertainty.
<em>EJOR</em>, <em>315</em>(1), 120–129. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies purchasing a commodity or a perishable item under stochastically evolving and correlated prices for a distribution system environment. We consider the central purchasing of the commodity under the demand process correlated with the random price and decide on the timing and quantity of allocation to demand locations. As an implementation of the physical pooling concept, we investigate the benefits of pooling price and demand risk when the forward purchase is realized for all demand locations. We also study the benefits of informational pooling concepts by deciding on the allocation timing. Even when the demand locations are independent entities, organizing joint purchasing of a commodity may take advantage of economies of scale with a more reliable and less expensive delivery option. We develop a model to guide the purchasing and allocation of quantities and employ multi-echelon inventory theory methods and stochastic processes commonly used in financial engineering and operations management literature.},
  archive      = {J_EJOR},
  author       = {Refik Güllü and Nesim Erkip},
  doi          = {10.1016/j.ejor.2023.11.028},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {120-129},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Risk pooling under demand and price uncertainty},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Network design with route planning for battery electric
high-speed passenger vessel services. <em>EJOR</em>, <em>315</em>(1),
102–119. (<a href="https://doi.org/10.1016/j.ejor.2023.11.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the Zero Emission passenger Vessel Service Network Design Problem (ZEVSNDP) in order to investigate how technical and economic challenges related to diffusion of battery electric vessels can be alleviated by appropriate planning of services. The ZEVSNDP considers decisions that are strategic (i.e., vessel fleet and charging locations), tactical (i.e., routes, whether to omit servicing ports, fleet deployment, and operating frequencies), as well as operational (i.e., passenger flow, sailing speeds, and scheduling decisions). A novel Mixed Integer Programming (MIP) model considering operator and passenger costs is proposed for the ZEVSNDP. Since the MIP model cannot be solved to optimality by a commercial solver except for tiny instances, we implement a heuristic Decomposition Based (DB) solution method. The DB solution method is applied to a real complex passenger vessel service in Florø, Norway, as well as two other test instances focusing on short-range transport and dense markets, respectively. Except for the short-range test instance, abatement costs (i.e., the costs of removing CO 2 CO2 emissions by introducing battery electric vessels) are found to be significant. This is attributed to limited reach and time used for charging of battery electric vessels. Routes should consequently accommodate range limitations: omitting ports from the current route can be a cost-effective strategy when the cost of alternative transport for the passengers is moderate.},
  archive      = {J_EJOR},
  author       = {Håkon Furnes Havre and Ulrik Lien and Mattias Myklebust Ness and Kjetil Fagerholt and Kenneth Løvold Rødseth},
  doi          = {10.1016/j.ejor.2023.11.015},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {102-119},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Network design with route planning for battery electric high-speed passenger vessel services},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Setting the deadline and the penalty policy for a new
environmental standard. <em>EJOR</em>, <em>315</em>(1), 88–101. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common approach that governments use to combat the potential environmental harm caused by industry is to set an environmental standard for firms to either comply with by a specified deadline or face a penalty. Two penalty policies that governments often rely on to pressure firms to comply with a new standard are a per-period penalty policy and a per-unit penalty policy. We examine how a government should set the deadline and the penalty for a new standard in a market with two competing firms, both of whom make development investment decisions. We analyze and compare the government’s decisions under both penalty policies. Our results show that only when one of the firms has a significantly higher development capability and/or production capability should the government set the deadline in a way such that only one firm complies on time. Comparing the two penalty policies, we find that when the firms’ production decisions are not impacted by the penalty, the government either prefers the per-unit policy or is indifferent between the two policies. Our work adds to the environmental literature on regulatory policy design by examining a government’s deadline choice and penalty decisions (both type and size) for a competitive market with heterogeneous firms.},
  archive      = {J_EJOR},
  author       = {Amirmohsen Golmohammadi and Tim Kraft and Seyedamin Monemian},
  doi          = {10.1016/j.ejor.2023.11.014},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {88-101},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Setting the deadline and the penalty policy for a new environmental standard},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Matheuristics for scheduling of maintenance service with
linear operation cost and step function maintenance cost. <em>EJOR</em>,
<em>315</em>(1), 73–87. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a problem of scheduling machine maintenance activities in discretized periods, under the constraint that a maximum of one activity can be scheduled for each period. The scheduled maintenance activities will be repeated in a cyclic policy with a given cycle length. The problem is to find a scheduling policy specifying which activity is executed in each period in order to minimize the total cost. Two kinds of costs are assumed: operation and maintenance costs. Both of them depend on the number of periods since the last machine maintenance service. The operation cost occurs during the periods in which a machine is not maintained and increases linearly. The maintenance cost takes place in the periods in which a machine is maintained and is defined as a step function. The steps in the maintenance cost function could be justified by the fact of considering the machine element&#39;s substitution when this machine is run for too long without being maintained. This cost structure reduces the gap between the academic problem and the industrial reality. In this paper, the scheduling problem with linear operation cost and step function maintenance cost is defined and formalized. In addition, different matheuristic algorithms are proposed for its resolution. Lower bounds for the objective function are proposed and the computational results show an average deviation from the optimal solution lower than or equal to 3.19%.},
  archive      = {J_EJOR},
  author       = {Javier Maquirriain and Alberto García-Villoria and Rafael Pastor},
  doi          = {10.1016/j.ejor.2023.10.001},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {73-87},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Matheuristics for scheduling of maintenance service with linear operation cost and step function maintenance cost},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Single machine adversarial bilevel scheduling problems.
<em>EJOR</em>, <em>315</em>(1), 63–72. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider single machine scheduling problems in the context of adversarial bilevel optimization where two agents, the leader and the follower, take decisions on the same jobset and the leader acts first with the aim of inducing the worst possible solution for the follower. Thus, the follower schedules the jobs in order to optimize a given criterion. The considered criteria are the total completion time, the total weighted completion time, the maximum lateness and the number of tardy jobs. We focus on adversarial bilevel scheduling with job selection and data modification. In the case with job selection, the leader selects a fixed cardinality subset of the jobs that the follower schedules next. In the case with data modification, the leader can modify some of the data (processing times, due dates, weights), given a limited budget Q Q . Thus, the follower schedules the set of jobs with modified data. For all the considered criteria either we provide polynomial-time algorithms or show that they can be solved in the worst-case in pseudo-polynomial time.},
  archive      = {J_EJOR},
  author       = {Vincent T’kindt and Federico Della Croce and Alessandro Agnetis},
  doi          = {10.1016/j.ejor.2023.11.018},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {63-72},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Single machine adversarial bilevel scheduling problems},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Piecewise linear approximation with minimum number of linear
segments and minimum error: A fast approach to tighten and warm start
the hierarchical mixed integer formulation. <em>EJOR</em>,
<em>315</em>(1), 50–62. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In several areas of economics and engineering, it is often necessary to fit discrete data points or approximate non-linear functions with continuous functions. Piecewise linear (PWL) functions are a convenient way to achieve this. PWL functions can be modeled in mathematical problems using only linear and integer variables. Moreover, there is a computational benefit in using PWL functions that have the least possible number of segments. This work proposes a novel hierarchical mixed integer linear programming (MILP) formulation that identifies a continuous PWL approximation with minimum number of linear segments for a given target maximum error. The proposed MILP formulation also identifies the solution with the least maximum error among the solutions with minimum number of segments. Then, this work proposes a fast iterative algorithm that identifies non necessarily continuous PWL approximations by solving O(S log N) linear programming (LP) problems, where N is the number of data points and S is the minimum number of segments in the non necessarily continuous case. This work demonstrates that tight bounds for the MILP problem can be derived from these approximations. Next, a fast algorithm is introduced to transform a non necessarily continuous PWL approximation into a continuous one. Finally, the tight bounds and the continuous PWL approximations are used to tighten and warm start the MILP problem. The tightened formulation is shown in experimental results to be more efficient, especially for large data sets, with a solution time that is up to two orders of magnitude less than the existing literature.},
  archive      = {J_EJOR},
  author       = {Quentin Ploussard},
  doi          = {10.1016/j.ejor.2023.11.017},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {50-62},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Piecewise linear approximation with minimum number of linear segments and minimum error: A fast approach to tighten and warm start the hierarchical mixed integer formulation},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). When is the next order? Nowcasting channel inventories with
point-of-sales data to predict the timing of retail orders.
<em>EJOR</em>, <em>315</em>(1), 35–49. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slow-moving goods are common in many retail settings and occupy a vast part of retail shelves. Since stores sell these products irregularly and in small quantities, the replenishing distribution center may only place batched orders with manufacturers every few weeks. While order quantities are often fixed, the challenge for manufacturers facing such intermittent demand is to forecast the order timing. In this paper, we explore the value of Point-of-Sales (PoS) data to improve a food manufacturer’s order timing forecast for slow-moving goods. We propose an inventory modeling approach that uses the last order, PoS data from retail stores, and the expected lead time demand to estimate the retailer’s channel inventory. With this dynamic estimate, we can ‘nowcast’ the retailer’s inventory and predict his next order. To illustrate our methodology, we first conduct an experimental simulation and compare our results to a Croston variant and a moving average model. Next, we validate our approach with empirical data from a small German food manufacturer that serves a grocery retailer with a central distribution center and 53 hypermarkets. We find that, on average, our approach improves the accuracy of order-timing predictions by 10–20 percent points. We overcome a shrinkage-induced bias by incorporating an inventory correction factor. Our approach describes a new way of utilizing PoS data in multi-layered distribution networks and can complement established forecasting methods such as Croston. Particular applications arise when the order history is short (e.g., product launch) or represents a bad predictor for future demand (e.g., during COVID-19).},
  archive      = {J_EJOR},
  author       = {Tim Schlaich and Kai Hoberg},
  doi          = {10.1016/j.ejor.2023.10.038},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {35-49},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {When is the next order? nowcasting channel inventories with point-of-sales data to predict the timing of retail orders},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A genetic algorithm with resource buffers for the
resource-constrained multi-project scheduling problem. <em>EJOR</em>,
<em>315</em>(1), 19–34. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we compose a new metaheuristic algorithm for solving the resource-constrained multi-project scheduling problem. Our approach is based on a general metaheuristic strategy which incorporates two resource-buffered scheduling tactics. We build on the most effective evolutionary operators and other well-known scheduling methods to create a novel genetic algorithm with resource buffers. We test our algorithm on a large benchmark dataset and compare its performance to ten existing metaheuristic algorithms. Our results show that our algorithm can generate new best-known solutions for about 20% of the test instances, depending on the optimisation criterion and due date. In some cases, our algorithm outperforms all other available methods combined. Finally, we introduce a new schedule metric that can quantitatively measure the dominant structure of a solution, and use it to analyse the differences between the best solutions for different objectives, due dates, and instance parameters.},
  archive      = {J_EJOR},
  author       = {Dries Bredael and Mario Vanhoucke},
  doi          = {10.1016/j.ejor.2023.11.009},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {19-34},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A genetic algorithm with resource buffers for the resource-constrained multi-project scheduling problem},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A literature review of economic efficiency assessments using
data envelopment analysis. <em>EJOR</em>, <em>315</em>(1), 1–18. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a literature review on Data Envelopment Analysis assessments of economic efficiency, covering methodological developments and empirical applications. We review the seminal models for economic efficiency measurement, involving the optimization of cost, revenue, and profit. The applications of the different modelling approaches are also discussed. Based on a content analysis of papers published between 1978 and 2020 in various sectors, the main areas of study are identified, and the pathways of research developments are discussed. Most studies are based on disaggregated quantity and price data. In addition, the use of panel data is prevalent compared to cross-sectional studies. There is a preponderance of input-oriented studies focused on cost efficiency rather than revenue or profit efficiency. Informed by the historical evolution of economic efficiency assessments portrayed in this review, we suggest directions for future developments.},
  archive      = {J_EJOR},
  author       = {Ana Santos Camanho and Maria Conceicao Silva and Fabio Sartori Piran and Daniel Pacheco Lacerda},
  doi          = {10.1016/j.ejor.2023.07.027},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A literature review of economic efficiency assessments using data envelopment analysis},
  volume       = {315},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A note on “a unified solution framework for multi-attribute
vehicle routing problems.” <em>EJOR</em>, <em>314</em>(3), 1215–1219.
(<a href="https://doi.org/10.1016/j.ejor.2023.11.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this note, the authors propose correcting one erroneous formula from [Vidal, T., Crainic, T. G., Gendreau, M., &amp; Prins, C. (2014). A unified solution framework for multi-attribute vehicle routing problems. European Journal of Operational Research, 234(3), 658–673] in charge of lunch breaks. In the original paper, the authors propose to compute several attribute values from the solution of a vehicle routing problem; like the earliest and latest starting time for sequences of customers to visit. The computed values allow us to quickly evaluate the feasibility and the marginal cost of some neighbor solutions. Several variants of the class of vehicle routing problems can be addressed using this approach. In the case of drivers’ lunch break scheduling, the proposed formula combines optimistic values for the earliest and the latest completion times of the sequence of customers to visit. Using these values to evaluate neighbor solutions, may conclude that unfeasible solutions are feasible, or underestimate the completion time of a driver’s route. In this note, we describe a counter-example to identify the error in the formula. We also adapt the formula to the correct result.},
  archive      = {J_EJOR},
  author       = {Thierry Garaix and Mohammed Skiredj},
  doi          = {10.1016/j.ejor.2023.11.037},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1215-1219},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A note on “A unified solution framework for multi-attribute vehicle routing problems”},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constructing copulas using corrected hermite polynomial
expansion for estimating cross foreign exchange volatility.
<em>EJOR</em>, <em>314</em>(3), 1195–1214. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A finite order multivariate Hermite polynomial expansion, as an approximation of a joint density function, can handle complex correlation structures. However, it does not construct copulas, because the density function can take negative values. In this study, we propose a formulation of multivariate Hermite polynomial expansion suitable for the application of correction that recovers non-negativity and construct a copula. Several useful expressions for integrals with the copula are derived from this formulation. We also apply this copula to estimate the volatility smile of cross-currency pairs in the foreign exchange option market. In the numerical experiments, we compare the estimation results of the volatility smile of EUR–JPY, GBP–JPY, and AUD–JPY for the proposed and other copulas to confirm the validity of the proposed copula.},
  archive      = {J_EJOR},
  author       = {Kenichiro Shiraya and Tomohisa Yamakami},
  doi          = {10.1016/j.ejor.2023.11.033},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1195-1214},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Constructing copulas using corrected hermite polynomial expansion for estimating cross foreign exchange volatility},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new bivariate approach for modeling the interaction
between stock volatility and interest rate: An application to s&amp;P500
returns and options. <em>EJOR</em>, <em>314</em>(3), 1185–1194. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The GARCH models developed so far do not take into account the interaction between the volatility of asset returns and the dynamics of the interest rate. In this paper, we propose a bivariate GARCH model in which interest rate movements and asset price volatility are fully coupled. This approach yields explicit and simple to implement recursion formulas for the moment generating function, which can be exploited to compute option prices by applying the fast Fourier transform or other convolution techniques. We perform a thorough and comprehensive empirical analysis based on real S&amp;P500 return and option data showing the usefulness and robustness of the suggested methodology. Both in-sample and out-of-sample results reveal the superiority of our approach over the GARCH model with constant interest rates.},
  archive      = {J_EJOR},
  author       = {Luca Vincenzo Ballestra and Enzo D’Innocenzo and Andrea Guizzardi},
  doi          = {10.1016/j.ejor.2023.11.049},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1185-1194},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new bivariate approach for modeling the interaction between stock volatility and interest rate: An application to S&amp;P500 returns and options},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust linear algebra. <em>EJOR</em>, <em>314</em>(3),
1174–1184. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a robust optimization (RO) framework that immunizes some of the central linear algebra problems in the presence of data uncertainty. Namely, we formulate linear systems, matrix inversion, eigenvalues–eigenvectors and matrix factorization under uncertainty, as robust optimization problems using appropriate descriptions of uncertainty. The resulting optimization problems are computationally tractable and scalable. We show in theory that RO improves the relative error of the linear system by reducing the condition number of the underlying matrix. Moreover, we provide empirical evidence showing that the proposed approach outperforms state of the art methods for linear systems and matrix inversion, when applied on ill-conditioned matrices. We show that computing eigenvalues–eigenvectors under RO, corresponds to solving linear systems that are better conditioned than the nominal and illustrate with numerical experiments that the proposed approach is more accurate than the nominal, when perturbing ill-conditioned matrices. Finally, we demonstrate empirically the benefit of the robust Cholesky factorization over the nominal.},
  archive      = {J_EJOR},
  author       = {Dimitris Bertsimas and Thodoris Koukouvinos},
  doi          = {10.1016/j.ejor.2023.11.036},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1174-1184},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust linear algebra},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sentiment classification of time-sync comments: A
semi-supervised hierarchical deep learning method. <em>EJOR</em>,
<em>314</em>(3), 1159–1173. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-sync comment (TSC) has emerged as a new type of textual comment for real-time user interactions on online video platforms. The sentiment classification of TSCs provides considerable potential for platforms to optimize operation strategies but inevitably faces great challenges due to the TSCs’ often uninformative and informal text. Considering the contextual dependency among TSCs posted within the same video clip, this study posits that contextual TSCs may benefit the sentiment classification of a target TSC. To address the challenges of leveraging contextual TSCs, such as their semantic representation and fusion, we propose a semi-supervised hierarchical deep learning method for the sentiment classification of TSCs. We design a hierarchical architecture to capture the semantics of TSCs at the word, comment, and context levels. Considering the varying importance of words and comments, we also design attention mechanisms to focus on important sentiment information and fuse semantic representations. Empirical evaluation shows that the proposed method outperforms benchmarked sentiment classification methods. This study advances our knowledge of contextual information indicative of TSC sentiment, and contributes to improving the service operation of online video platforms.},
  archive      = {J_EJOR},
  author       = {Renzhi Gao and Xiaoyu Yao and Zhao Wang and Mohammad Zoynul Abedin},
  doi          = {10.1016/j.ejor.2023.11.035},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1159-1173},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Sentiment classification of time-sync comments: A semi-supervised hierarchical deep learning method},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed mean reversion online portfolio strategy with
stock network. <em>EJOR</em>, <em>314</em>(3), 1143–1158. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online portfolio selection is a practical problem in financial engineering and quantitative trading. Many empirical studies show that stock performance in the market is likely to follow mean reversion, and strategies based on mean reversion show better return performance than the market average. However, the existing mean reversion strategies are not universal and short selling is not allowed, which is unsuitable for real-time investment. In this paper, we propose a distributed mean reversion online portfolio strategy through a stock correlation sub-network to solve these problems. Theoretical analysis shows that our strategy is universal and the convergence rate is calculated. The empirical results show that our strategy is better than the existing universal strategies in terms of return performance, nor is it sensitive to transaction cost.},
  archive      = {J_EJOR},
  author       = {Yannan Zhong and Weijun Xu and Hongyi Li and Weiwei Zhong},
  doi          = {10.1016/j.ejor.2023.11.021},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1143-1158},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Distributed mean reversion online portfolio strategy with stock network},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multicommodity international agricultural trade network
equilibrium: Competition for limited production and transportation
capacity under disaster scenarios with implications for food security.
<em>EJOR</em>, <em>314</em>(3), 1127–1142. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of people affected by disasters, including man-made ones, is on the rise globally, with rising food insecurity being one of the most critical impacts. Disasters, both sudden-onset and slow-onset ones, can cause disruptions to the production and transportation of agricultural commodities. Having the tools that can quantitatively assess the changes in agricultural commodity shipment volumes and their prices under disruptions caused by disaster scenarios is of major importance. In this paper, we utilize the theory of variational inequalities as the methodology to construct a multicommodity international agricultural trade network equilibrium model, which contains novel features of capacities on the production and transportation of multiple agricultural commodities to capture competition. The model includes exchange rates and accounts for multiple routes and possibly distinct transportation modes and combinations. Theoretical results are given and an algorithm is proposed. A series of numerical examples, both illustrative and algorithmically solved ones, inspired by Russia’s war on Ukraine, highlight the effects of reduced production and transportation capacities on food security in the Middle Eastern and North African (MENA) countries of Lebanon and Egypt. We also include sensitivity analysis results for exchange rates. The solutions reveal insights into the importance of the production and transportation capacities regarding food security, along with having multiple transportation routes that are cost-efficient as well as the importance of the magnitude of exchange rates.},
  archive      = {J_EJOR},
  author       = {Anna Nagurney and Dana Hassani and Oleg Nivievskyi and Pavlo Martyshev},
  doi          = {10.1016/j.ejor.2023.11.010},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1127-1142},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multicommodity international agricultural trade network equilibrium: Competition for limited production and transportation capacity under disaster scenarios with implications for food security},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new ordinal mixed-data sampling model with an application
to corporate credit rating levels. <em>EJOR</em>, <em>314</em>(3),
1111–1126. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a new ordinal logistic regression model (OLMIDAS) that allows the inclusion of independent variables at higher frequencies than that of the dependent variable. A simulation study shows that our proposed model can find the true patterns in the data. In an empirical study we apply OLMIDAS to the prediction of corporate credit rating levels and compare its performance to classical logistic regression models with an annual aggregation of the higher-frequency variable, such as ordinal logistic regression and multinomial logistic regression. We find that OLMIDAS outperforms the classical logistic regression models while providing additional knowledge of the structure of the higher-frequency explanatory variable.},
  archive      = {J_EJOR},
  author       = {Leonie Goldmann and Jonathan Crook and Raffaella Calabrese},
  doi          = {10.1016/j.ejor.2023.10.017},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1111-1126},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new ordinal mixed-data sampling model with an application to corporate credit rating levels},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A preference elicitation approach for the ordered weighted
averaging criterion using solution choice observations. <em>EJOR</em>,
<em>314</em>(3), 1098–1110. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decisions under uncertainty or with multiple objectives usually require the decision maker to formulate a preference regarding risks or trade-offs. If this preference is known, the ordered weighted averaging (OWA) criterion can be applied to aggregate scenarios or objectives into a single function. Formulating this preference, however, can be challenging, as we need to make explicit what is usually only implicit knowledge. We explore an optimization-based method of preference elicitation to identify appropriate OWA weights. We follow a data-driven approach, assuming the existence of observations, where the decision maker has chosen the preferred solution, but otherwise remains passive during the elicitation process. We then use these observations to determine the underlying preference by finding the preference vector that is at minimum distance to the polyhedra of feasible vectors for each of the observations. Using our optimization-based model, weights are determined by solving an alternating sequence of linear programs and standard OWA problems. Numerical experiments on risk-averse preference vectors for selection, assignment and knapsack problems show that our passive elicitation method compares well against having to conduct pairwise comparisons and performs particularly well when there are inconsistencies in the decision maker’s choices.},
  archive      = {J_EJOR},
  author       = {Werner Baak and Marc Goerigk and Michael Hartisch},
  doi          = {10.1016/j.ejor.2023.11.020},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1098-1110},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A preference elicitation approach for the ordered weighted averaging criterion using solution choice observations},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimax regret stability in the graph model for conflict
resolution. <em>EJOR</em>, <em>314</em>(3), 1087–1097. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In strategic conflicts, decision-makers (DMs) do not constantly make their best decisions, which makes room for DMs to feel regretful. In this context, this work proposes the Minimax Regret Stability within the graph model for conflict resolution (GMCR) for modelling and analysing conflicts, considering that DMs would feel regret for an unsatisfactory decision. This concept does not require knowledge about the opponent’s preference in bilateral conflicts. The aim of the new solution concept is to recommend a state as stable if there exists a policy recommending to stay at that state which minimizes the maximum regret of the DM for a given conflict horizon, where a policy specifies what action a DM must choose in every conflict state. In addition, we investigate the relations among the Minimax regret stability and other classical GMCR solution concepts. Following, the influence of the horizon on the stability of states is also studied. Finally, a truckers’ strike conflict was used to illustrate how the new solution concept can provide valuable strategic insights in real-life conflict situations.},
  archive      = {J_EJOR},
  author       = {Emerson Rodrigues Sabino and Leandro Chaves Rêgo},
  doi          = {10.1016/j.ejor.2023.10.047},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1087-1097},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Minimax regret stability in the graph model for conflict resolution},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A lexicographically optimal completion for pairwise
comparison matrices with missing entries. <em>EJOR</em>,
<em>314</em>(3), 1078–1086. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating missing judgements is a key component in many multi-criteria decision making techniques, especially in the Analytic Hierarchy Process. Inspired by the Koczkodaj inconsistency index and a widely used solution concept of cooperative game theory called the nucleolus, the current study proposes a new algorithm for this purpose. In particular, the missing values are substituted by variables, and the inconsistency of the most inconsistent triad is reduced first, followed by the inconsistency of the second most inconsistent triad, and so on. The necessary and sufficient condition for the uniqueness of the suggested lexicographically optimal completion is proved to be a simple graph-theoretic notion: the undirected graph associated with the pairwise comparisons, where the edges represent the known elements, should be connected. Crucially, our method does not depend on an arbitrarily chosen measure of inconsistency as there exists essentially one reasonable triad inconsistency index.},
  archive      = {J_EJOR},
  author       = {Kolos Csaba Ágoston and László Csató},
  doi          = {10.1016/j.ejor.2023.10.035},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1078-1086},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A lexicographically optimal completion for pairwise comparison matrices with missing entries},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cluster ensemble selection and consensus clustering: A
multi-objective optimization approach. <em>EJOR</em>, <em>314</em>(3),
1065–1077. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cluster ensembles have emerged as a powerful tool to obtain clusters of data points by combining a library of clustering solutions into a consensus solution. In this paper, we address the cluster ensemble selection problem and design a multi-objective optimization-based solution framework to produce consensus solutions. Given a library of clustering solutions, we first design a preprocessing procedure that measures the agreement of each clustering solution with the other solutions and eliminates the ones that may mislead the process. We then develop a multi-objective optimization algorithm that selects representative clustering solutions from the preprocessed library with respect to size, coverage, and diversity criteria and combines them into a single consensus solution, for which the true number of clusters is assumed to be unknown. We conduct experiments on different benchmark data sets. The results show that our approach yields more accurate consensus solutions compared to full-ensemble and the existing approaches for most data sets. We also present an application on the customer segmentation problem, where our approach is used to segment customers and to find a consensus solution for each segment, simultaneously.},
  archive      = {J_EJOR},
  author       = {Dilay Aktaş and Banu Lokman and Tülin İnkaya and Gilles Dejaegere},
  doi          = {10.1016/j.ejor.2023.10.029},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1065-1077},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cluster ensemble selection and consensus clustering: A multi-objective optimization approach},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Profit-based unit commitment models with price-responsive
decision-dependent uncertainty. <em>EJOR</em>, <em>314</em>(3),
1052–1064. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Highlighting the increasing importance of demand elasticity in electricity markets and its impact on the revenues of power generating companies, this paper proposes new profit-based unit commitment models that effectively capture the uncertainty in the willingness-to-pay the price set for the elastic demand. To develop a new revenue scheme for power generating companies, we use a coupling function to model the willingness-to-pay response of the elastic demand as a decision-dependent source of uncertainty. The coupling function reflects how power generating companies’ pricing decisions may influence the market appeal (i.e., the buyer’s willingness-to-pay) and how it affects their revenues. The optimization models are stochastic mixed-integer nonlinear problems with nonconvex continuous relaxations and are not amenable to a numerical solution in their original forms. We devise a convexification reformulation method and derive valid inequalities to strengthen the formulation. We propose a learning framework to parameterize the willingness-to-pay functions and the concept of the value of the decision-dependent solution to quantify the value of the uncertainty modeling approach. Numerical tests on power systems of various sizes, demand portfolios, and price elasticity levels show (i) how the valid inequalities speed up the solution process, (ii) the benefits of properly modeling decision-dependent uncertainty and demand elasticity, and (iii) how the incorporation of decision-dependent uncertainty in demand elasticity can change the power generating companies’ decisions and revenue estimation.},
  archive      = {J_EJOR},
  author       = {Miguel A. Lejeune and Payman Dehghanian and Wenbo Ma},
  doi          = {10.1016/j.ejor.2023.12.006},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1052-1064},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Profit-based unit commitment models with price-responsive decision-dependent uncertainty},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distribution-free control charts for monitoring scale in
finite horizon productions. <em>EJOR</em>, <em>314</em>(3), 1040–1051.
(<a href="https://doi.org/10.1016/j.ejor.2023.11.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distribution-free (also known as nonparametric) control charts have been shown to be useful for on-line monitoring of lot production within a finite horizon production (FHP) process. Despite the partial process knowledge at the beginning of production in a FHP process, a distribution-free control chart can be started without any restrictive assumption about the underlying distribution of the quality characteristic. In this work, three nonparametric Shewhart-type control charts are investigated to monitor the unknown scale parameter in FHP processes based on some well-known nonparametric tests for scale. To this end, the violation of the assumption of equal medians of the reference and the test population distributions is investigated and a fourth control chart based on the Moses test, which does not require this assumption, is considered. An extensive numerical analysis is performed to examine chart performance based on some metrics suitable in the FHP setting. A real industrial example is presented to show a practical implementation of the investigated charts. Conclusions and future research ideas are provided.},
  archive      = {J_EJOR},
  author       = {Theodoros Perdikis and Giovanni Celano and Subhabrata Chakraborti},
  doi          = {10.1016/j.ejor.2023.11.048},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1040-1051},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Distribution-free control charts for monitoring scale in finite horizon productions},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The impact of ambiguity on dynamic portfolio selection in
the epsilon-contaminated binomial market model. <em>EJOR</em>,
<em>314</em>(3), 1029–1039. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider dynamic portfolio selection under ambiguity in the classical multi-period binomial market model. Ambiguity is incorporated in the real-world probability measure through an epsilon-contamination, that gives rise to a completely monotone capacity conveying a pessimistic investor’s ambiguous beliefs. The dynamic portfolio selection problem is formulated as a Choquet expected utility maximization problem on the final wealth. Then, the optimal final wealth is proved to be a function of the final stock price: this allows a dimension reduction of the problem, switching from an exponential to a linear size with respect to the number of periods. Finally, an explicit characterization of the optimal final wealth is given in the case of a constant relative risk aversion utility function and the interaction between the ambiguity and the relative risk aversion parameters is investigated.},
  archive      = {J_EJOR},
  author       = {Davide Petturiti and Barbara Vantaggi},
  doi          = {10.1016/j.ejor.2023.11.011},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1029-1039},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The impact of ambiguity on dynamic portfolio selection in the epsilon-contaminated binomial market model},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Should original equipment manufacturers authorize
third-party remanufacturers? <em>EJOR</em>, <em>314</em>(3), 1013–1028.
(<a href="https://doi.org/10.1016/j.ejor.2023.11.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remanufacturing is well-established as a means for original equipment manufacturers (OEMs) to reduce waste, save on raw materials costs, and tap into new markets. At the same time, OEMs are often skeptical of remanufacturing due to the potential for remanufactured items to steal market share from new items. Third-party remanufacturers (TPRs) experience no such skepticism, since these market players do not sell new items. TPRs often find profit potential in acquiring used items in the marketplace, refurbishing, and reselling them. In response, some OEMs choose to “authorize” these TPRs, as a way to control quality and reputation, while other OEMs do not provide such authorization. By authorizing TPR, an OEM can realize additional revenues from the authorization fees. However, there are two potential downsides: authorization might enhance the perceived value of TPR’s remanufactured products and therefore their competitiveness against new items, and it might trigger quality concerns for the OEM’s new products. The net impact of authorization on OEM and TPR prices and profits, and the optimal structure of an authorization fee, will depend critically on how authorization impacts consumer willingness to pay for new and remanufactured products. We develop an analytical model that enables us to suggest optimal authorization fees and to provide insights into the conditions under which both parties can increase profits when authorization is present. We show that, under certain conditions, TPR authorization can enable the entry of an otherwise-unprofitable TPR into the market, while at the same time increasing OEM profits.},
  archive      = {J_EJOR},
  author       = {Wei Li and Mingzhou Jin and Michael R. Galbreth},
  doi          = {10.1016/j.ejor.2023.11.007},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {1013-1028},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Should original equipment manufacturers authorize third-party remanufacturers?},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The supply of convenience stores: Challenges of
short-distance routing within the constraints of working time
regulations. <em>EJOR</em>, <em>314</em>(3), 997–1012. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convenience stores are small shops typically located in dense urban areas. They are an important element in modern retailing considering growing urbanization. The layout of convenience stores usually differs significantly for individual stores depending on the local conditions and the types of store (e.g., grocery stores, kiosks, gas stations). Convenience stores have specific delivery requirements that differ significantly due to their variety. In this context, retailers have to cope with small order sizes and frequent deliveries that need to occur within opening hours or predetermined time windows. In addition to these requirements, working hour regulations for the drivers, i.e., the consideration of break times and tour duration restrictions, have to be respected. These regulations have so far been neglected within short-distance routing but significantly impact the planning in practice. The supply of convenience stores is thus a major challenge for retailers. This article addresses the supply of convenience stores as it takes place at a major European retailer. We develop a mathematical model that integrates existing working time regulations and actual requirements in retail practice. The resulting routing problem is solved using an adaptive large neighborhood search. We demonstrate the impact of the requirements imposed on the routing problem and corresponding delivery solutions in numerical studies. Our experiments show that ignoring break times within route planning when strict time windows are given leads to non-feasible solutions and a potential delay in deliveries of more than 18 h for a single planning week.},
  archive      = {J_EJOR},
  author       = {Manuel Ostermeier},
  doi          = {10.1016/j.ejor.2023.11.004},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {997-1012},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The supply of convenience stores: Challenges of short-distance routing within the constraints of working time regulations},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The impact of blockchain on restricting the misuse of green
loans in a capital-constrained supply chain. <em>EJOR</em>,
<em>314</em>(3), 980–996. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, green loans have been widely promoted to support the capital-constrained supply chain under carbon regulation. However, the borrowers in the supply chain may use the preferential green loans for other purposes which are not related to green development. That phenomenon is mainly attributed to the lack of valid information investigation under traditional information technology. Blockchain, as an innovative technology, can provide valid financial information and identify liability in the use of green loans, which could be an effective tool to restrict the misuse behavior. But will the high operating cost weaken the advantage of blockchain? To address this question, we consider a supply chain system composed of a supplier and a capital-constrained manufacturer. The manufacturer may misuse part of the green loans to purchase primary components from the supplier. Two operational modes corresponding to no-blockchain adoption (N case) and blockchain adoption (B case) are designed, in which the supplier determines the wholesale price, and the manufacturer determines the order quantity under green loans. By comparing the optimal decisions of supply chain members, we put forward and differentiate three types of effects: the carbon regulation effect, the information verification effect, and the blockchain cost effect, which influence the adoption of blockchain technology in the supply chain. In addition, we show that blockchain can restrict the misused amount of green loans and improve the environmental performance, but decrease the consumer surplus.},
  archive      = {J_EJOR},
  author       = {Minxue Wang and Bo Li and Dongping Song},
  doi          = {10.1016/j.ejor.2023.11.003},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {980-996},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The impact of blockchain on restricting the misuse of green loans in a capital-constrained supply chain},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solution strategies for integrated distribution, production,
and relocation problems arising in modular manufacturing. <em>EJOR</em>,
<em>314</em>(3), 963–979. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been a paradigm shift by certain energy companies towards modular manufacturing, whereby transportable modular production units can be relocated between production facilities to meet the spatial and temporal changes in the availabilities, demands, and prices of the underlying commodities. We refer to the optimal distribution, production, and storage of commodities, including intermediary commodities, and the relocation and operation of the modular production units as the dynamic multiple commodity supply chain problem with modular production units . To this end, we present a “flow-based” and a “path-based” mixed-integer linear programming formulation to model the problem. In an effort to solve large-scale instances of the problem, we propose an iterative three-stage matheuristic for the “path-based” formulation. In the first stage of the matheuristic, a feasible solution to the problem is generated by an integrated column generation and Lagrangian relaxation based heuristic. In the second stage of the matheuristic, a path-relinking procedure is utilized as a local search heuristic to further improve the solution. And in the final stage of the matheuristic, the Lagrangian multipliers are updated via a subgradient method. The effectiveness of the matheuristic is illustrated through numerical experiments with a set of randomly generated test instances. For the large-scale test instances, the results show that the matheuristic produces quality solutions orders of magnitude faster than a “state-of-the-art” mixed-integer linear programming solver.},
  archive      = {J_EJOR},
  author       = {R. Cory Allen and Styliani Avraamidou and Sergiy Butenko and Efstratios N. Pistikopoulos},
  doi          = {10.1016/j.ejor.2023.09.014},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {963-979},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solution strategies for integrated distribution, production, and relocation problems arising in modular manufacturing},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Freight railcar-to-train assignment and departure scheduling
in a railyard. <em>EJOR</em>, <em>314</em>(3), 950–962. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rail freight distribution operations require assembling trains consisting of multiple freight cars with a common destination, and assigning departure times to the assembled trains. Limits on railyard train assembly capacity restrict the number of trains that may be assembled and, therefore, depart the railyard, per unit time. Each individual car, or unit, in a railyard typically has an associated subsequent destination and preferred due date, as well as an acceptable time window within which the destination location will accept delivery. Railyard planners thus face the recurring problem of determining the assignment of cars to assembled trains, as well as the schedule of train departures within a planning horizon. We propose a 0–1 integer linear program for solving this assignment and scheduling problem under the two objectives of minimizing of the number of required train departures within the week, and maximizing on-time performance. We show that this problem is NP NP -hard and propose constructive, Lagrangian-based, and neighborhood interchange heuristics for obtaining near-optimal solutions. We also provide computational results that characterize the tradeoff between on-time performance and weekly workload, as measured by the number of weekly train departures.},
  archive      = {J_EJOR},
  author       = {Mina Aliakbari and Joseph Geunes and Amir Ghahari and Mike Prince},
  doi          = {10.1016/j.ejor.2023.11.006},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {950-962},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Freight railcar-to-train assignment and departure scheduling in a railyard},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal control policies for dynamic inventory systems with
service level dependent demand. <em>EJOR</em>, <em>314</em>(3), 935–949.
(<a href="https://doi.org/10.1016/j.ejor.2023.11.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Empirical studies have shown that stockouts may adversely affect future demand. However, much of the literature on inventory optimization has ignored this effect. In this paper, we investigate the effect of stockouts on a firm’s operational policy and total discounted profit. We show that compared with classic periodic review inventory models with no stockout effect, the optimal inventory control policies for inventory systems with stockout-dependent demand have different but interesting structures. Specifically, the optimal perceived stock-out service levels exhibit a mean-reverting pattern. These results shed lights on operational decisions and customer services to effectively manage inventory systems. Numerical studies show that neglecting stockout-dependent demand can lead to significant drop in the firm’s performance when compared with the optimum. This paper deepens our understanding on inventory systems when customer demand is discouraged by stockouts, and it helps inventory managers develop effective inventory control mechanisms that incorporate stockout effect.},
  archive      = {J_EJOR},
  author       = {Xiaoming Yan and Xiuli Chao and Ye Lu},
  doi          = {10.1016/j.ejor.2023.11.005},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {935-949},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal control policies for dynamic inventory systems with service level dependent demand},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Power structure preferences in a dual-channel supply chain:
Demand information symmetry vs. asymmetry. <em>EJOR</em>,
<em>314</em>(3), 920–934. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study establishes a dual-channel supply chain (DCSC) wherein the e-retailer is endowed with superior demand information, and investigates power structure preferences of the supplier and e-retailer. Game models are investigated based on two information structures (information symmetry and asymmetry) and three power structures, i.e., vertical Nash, e-retailer-led Stackelberg, and supplier-led Stackelberg. We derive the optimal solutions under each model and then conduct a deep comparison analysis. The results reveal that the impacts of information asymmetry on the DCSC vary with the power structure, and the DCSC members’ power structure preferences vary with the information structure. Under information symmetry, it is best for DCSC members to move late and is worst for them to move simultaneously. Under information asymmetry, the supplier has the first-move advantage given specific conditions, in which he has the initiative to screen the e-retailer’s private information. Furthermore, by introducing proper contracts, information asymmetry would not always be harmful for the DCSC; in contrast, DCSC members may obtain more ex-ante profits compared with information symmetry.},
  archive      = {J_EJOR},
  author       = {Xiaoqing Hu and Jianhu Cai and Xiaohang Yue},
  doi          = {10.1016/j.ejor.2023.10.041},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {920-934},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Power structure preferences in a dual-channel supply chain: Demand information symmetry vs. asymmetry},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Machine scheduling with restricted rejection: An
application to task offloading in cloud–edge collaborative computing.
<em>EJOR</em>, <em>314</em>(3), 912–919. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the burgeoning of the Internet of everything, the amount of data generated by edge devices increases dramatically. In order to relieve the huge pressure of the could computing center, a popular computing scheme, called edge computing , is to select and process part of the computation tasks on edge servers of the network. In this paper we model the task offloading problem motivated by the popular Cloud–Edge Collaborative Computing Frame as a parallel-machine scheduling problem with restricted job rejection. We present an easy-to-implement heuristic with worst-case bound analysis and polynomial time approximation schemes for the general problem and some of the important special cases.},
  archive      = {J_EJOR},
  author       = {Weidong Li and Jinwen Ou},
  doi          = {10.1016/j.ejor.2023.11.002},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {912-919},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Machine scheduling with restricted rejection: An application to task offloading in cloud–edge collaborative computing},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integer programming models and polyhedral study for the
geodesic classification problem on graphs. <em>EJOR</em>,
<em>314</em>(3), 894–911. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a discrete version of the classical classification problem in Euclidean space, to be called the geodesic classification problem. It is defined on a graph, where some vertices are initially assigned a class and the remaining ones must be classified. This vertex partition into classes is grounded on the concept of geodesic convexity on graphs, as a replacement for Euclidean convexity in the multidimensional space. We propose two new integer programming models along with branch-and-bound algorithms to solve them. We also carry out a polyhedral study of the associated polyhedra, which produced families of facet-defining inequalities and separation algorithms. Finally, we run computational experiments to evaluate the computational efficiency and the classification accuracy of the proposed approaches by comparing them with classic solution methods for the Euclidean convexity classification problem.},
  archive      = {J_EJOR},
  author       = {Paulo H. M. Araújo and Manoel Campêlo and Ricardo C. Corrêa and Martine Labbé},
  doi          = {10.1016/j.ejor.2023.08.029},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {894-911},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integer programming models and polyhedral study for the geodesic classification problem on graphs},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Approximation algorithms for scheduling parallel machines
with an energy constraint in green manufacturing. <em>EJOR</em>,
<em>314</em>(3), 882–893. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by current green manufacturing standards, in this paper we study a parallel-machine scheduling model in which the energy cost incurred on each machine is machine-dependent and proportional to the load of the machine. The objective is to determine a production schedule with the minimum makespan subject to the energy constraint that the total energy cost does not exceed a given bound. We provide a technical lemma that enables us to design a very efficient approximation algorithm with a worst-case bound that can arbitrarily approach 4 3 43 , improving on the existing performance ratio of 33 + 1 4 ≈ 1 . 686 33+14≈1.686 in the literature. By introducing the concept of a monotonic schedule, we are able to develop the first polynomial time approximation scheme for this scheduling problem. The scheduling problem studied in this paper is an important special case of the generalized assignment problem (GAP). Our techniques and results bring new insights into research on the GAP.},
  archive      = {J_EJOR},
  author       = {Weidong Li and Jinwen Ou},
  doi          = {10.1016/j.ejor.2023.11.008},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {882-893},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Approximation algorithms for scheduling parallel machines with an energy constraint in green manufacturing},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Demand management using responsive pricing and product
variety to counter supply chain disruptions. <em>EJOR</em>,
<em>314</em>(3), 867–881. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a retailer that offers multiple variants of two brands, all of which are substitutable, within a single product category. Due to supply disruptions, the retailer may not be able to always offer either or both brands. To mitigate potential loss in demand due to unavailability of one brand, the retailer may choose the product variety strategically and/or adjust the price of the available brand. The goal of this paper is to compare the relative impact of these two levers of demand management in the face of supply disruptions. To that end, we develop and analyze a model of a retailer buying from two brands (suppliers) subject to random supply disruptions. The retailer’s customer demand depends on price and product variety, and their impact on customer choice is captured through the nested logit model. The model also takes into account fixed design and operational costs associated with product variety. Our analysis reveals that strategic choice of product variety yields most of the benefit; price is a largely ineffective lever. We also show that when the supply of one brand is disrupted, the optimal price for the other brand is lower than when both brands are available, provided the outside option is equally or less affected by the disruption. However, even if the outside option is affected more, this result may not necessarily reverse. Finally, even though responsive pricing does not improve the profit substantially, it may reduce safety stock requirements.},
  archive      = {J_EJOR},
  author       = {Aydın Alptekinoğlu and Ashish S. Bhandari and Amar Sapra},
  doi          = {10.1016/j.ejor.2023.10.002},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {867-881},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Demand management using responsive pricing and product variety to counter supply chain disruptions},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A copula-based approach to modelling the failure process of
items under two-dimensional warranty and applications. <em>EJOR</em>,
<em>314</em>(3), 854–866. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hundreds of scholarly papers on optimisation of preventive maintenance policies for items under warranty have been published in the reliability related literature. They typically have two limitations: they make a simplified assumption on the relationship between age and usage for items under two-dimensional warranty and they assume that it is cost-effective to conduct preventive maintenance (PM) on each sold product item. These assumptions may not reflect the reality. This paper therefore proposes a copula-based approach to modelling the relationship between age and usage of items under two-dimensional (2D) warranty. It investigates the probabilistic properties of the bivariate failure rate functions of age and usage and derives optimal PM policies for users who bought multiple product items. It also proposes approaches to incorporating maintenance effectiveness in bivariate copulas for depicting the dependence between age and usage. A case study and numerical examples are provided to illustrate the findings.},
  archive      = {J_EJOR},
  author       = {Shaomin Wu},
  doi          = {10.1016/j.ejor.2023.10.043},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {854-866},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A copula-based approach to modelling the failure process of items under two-dimensional warranty and applications},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The family capacitated vehicle routing problem.
<em>EJOR</em>, <em>314</em>(3), 836–853. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we address the family capacitated vehicle routing problem (F-CVRP), an NP-hard problem that generalizes both the FTSP and the capacitated vehicle routing problem. The F-CVRP has practical application in warehouse management in warehouses with scattered storage. We present several mixed integer linear programming formulations for this problem and establish a theoretical and empirical comparison. We also propose valid inequalities adapted from known routing problems from the literature. Some formulations are solved using a branch-and-cut algorithm, which is tested with a newly generated data set. The computational experiment allows us to identify the instances’ most challenging characteristics and the exact methods’ limitations. Finally, we develop an iterated local search (ILS) algorithm to efficiently obtain feasible solutions for the instances that could not be solved to proven optimality. The ILS algorithm is very efficient and can improve the upper bounds obtained by the exact methods within the set time limit.},
  archive      = {J_EJOR},
  author       = {Raquel Bernardino and Ana Paias},
  doi          = {10.1016/j.ejor.2023.10.042},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {836-853},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The family capacitated vehicle routing problem},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey on the generalized traveling salesman
problem. <em>EJOR</em>, <em>314</em>(3), 819–835. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generalized traveling salesman problem (GTSP) is an extension of the classical traveling salesman problem (TSP) and it is among the most researched combinatorial optimization problems due to its theoretical properties, complexity aspects and real-life applications in various areas: location-routing problems, material flow design problem, distribution of medical supplies, urban waste collection management, airport selection and routing the courier airplanes, image retrieval and ranking, digital garment manufacturing, etc. Even though the importance of this combinatorial optimization problem was highlighted in several publications and there were developed several methods for solving it, there is no survey dedicated to the GTSP. The scope of this paper is to close this gap by providing a comprehensive survey on mathematical formulations, solution approaches and latest advances regarding the GTSP. The paper is organized around the following issues: problem definition, variations and related problems, real-life applications of the GTSP, mathematical formulations, solution approaches designed for solving the investigated problem, datasets, computational results and comparative analysis of the performance of the existing state-of-the-art algorithms. Additionally, we discuss certain open problems and potential research directions.},
  archive      = {J_EJOR},
  author       = {Petrică C. Pop and Ovidiu Cosma and Cosmin Sabo and Corina Pop Sitar},
  doi          = {10.1016/j.ejor.2023.07.022},
  journal      = {European Journal of Operational Research},
  month        = {5},
  number       = {3},
  pages        = {819-835},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A comprehensive survey on the generalized traveling salesman problem},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Corrigendum to “self-adjusting the tolerance level in a
fully sequential feasibility check procedure” [european journal of
operational research, volume 272, issue 2, december 2018, pages
733–745]. <em>EJOR</em>, <em>314</em>(2), 817. (<a
href="https://doi.org/10.1016/j.ejor.2023.12.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Mi Lim Lee and Chuljin Park and Dong Uk Park},
  doi          = {10.1016/j.ejor.2023.12.011},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {817},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Corrigendum to ‘Self-adjusting the tolerance level in a fully sequential feasibility check procedure’ [European journal of operational research, volume 272, issue 2, december 2018, pages 733–745]},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchy selection: New team ranking indicators for cyclist
multi-stage races. <em>EJOR</em>, <em>314</em>(2), 807–816. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, I report some investigation discussing team selection, whence hierarchy, through ranking indicators, for example when “measuring” professional cyclist team’s “sportive value”, in particular in multistage races. A logical, it seems, constraint is introduced on the riders: they must finish the race. Several new indicators are defined, justified, and compared. These indicators are mainly based on the arriving place of (“the best 3”) riders instead of their time needed for finishing the stage or the race, — as presently classically used. A case study, serving as an illustration containing the necessary ingredients for a wider discussion, is the 2023 Vuelta de San Juan, but without loss of generality. It is shown that the new indicators offer some new viewpoint for distinguishing the ranking through the cumulative sums of the places of riders rather than their finishing times. On the other hand, the indicators indicate a different team hierarchy if only the finishing riders are considered. Some consideration on the “distance” between ranking indicators is presented. Moreover, it is argued that these new ranking indicators should hopefully promote more competitive races, not only till the end of the race, but also until the end of each stage. Generalizations and other applications within operational research topics, like in academia, are suggested.},
  archive      = {J_EJOR},
  author       = {Marcel Ausloos},
  doi          = {10.1016/j.ejor.2023.10.044},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {807-816},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Hierarchy selection: New team ranking indicators for cyclist multi-stage races},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A target-time-windows technique for project scheduling under
uncertainty. <em>EJOR</em>, <em>314</em>(2), 792–806. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of determining the start times of activities in order to maximize the expected net present value of a project given precedence constraints. We assume that each activity has a random duration and profit with a known probability distribution. Most approaches generate either: a baseline schedule that is robust to uncertainty (using proactive approaches), or a policy that reacts to the revelation of uncertainty (using reactive approaches). We propose an integrated proactive-reactive technique that generates both a baseline time window for each activity’s start time, and a policy that indicates how the schedule should be adapted for each realization of uncertainty. The time window explicitly constrains the extent to which the realized start times vary. An important feature of our approach is that, once computed, it can easily be communicated and implemented in practice. Numerical experiments show that the objective value of the solutions generated by our technique can be within 4%, on average, of the optimal value obtained with perfect information, and up to 50% better when compared to an earliest-start policy. Moreover, the variability of activities’ start times can be 10 times smaller when compared to those generated by other policies. We solve an instance with 300 scenarios and 357 activities in 30 min, illustrating the scalability of our technique on a real-world problem that produces out-of-sample feasible solutions with a desired probability.},
  archive      = {J_EJOR},
  author       = {Patricio Lamas and Marcos Goycoolea and Bernardo Pagnoncelli and Alexandra Newman},
  doi          = {10.1016/j.ejor.2023.10.027},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {792-806},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A target-time-windows technique for project scheduling under uncertainty},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A quadrant shrinking heuristic for solving the dynamic
multi-objective disaster response personnel routing and scheduling
problem. <em>EJOR</em>, <em>314</em>(2), 776–791. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the aftermath of natural disasters there is a need to provide disaster relief services. These services are offered by diverse disaster relief personnel teams that are specialized in the provision of the required services, e.g., teams that set up temporary shelters, teams that are providing medical services. These services are provided during a rolling horizon and the demand and supply characteristics of the disaster relief system evolve dynamically over time. In this paper we are presenting a dynamic variant of the multi-objective disaster relief personnel routing and scheduling (DDRPRS) problem, which considers efficiency, fairness and transportation risk objectives. We introduce a Quadrant Shrinking Method (QSM) based heuristic algorithm to approximate the Pareto Optimal Solutions of the DDRPRS problem under consideration. The proposed algorithm considers the performance of the solutions over the entire planning horizon and their robustness over time in terms of their efficiency, fairness and transportation risk. We apply the proposed heuristic for routing and scheduling personnel involved in evacuation and medical operations using data from the 2018 Lombok Earthquake in Indonesia. Our heuristic implementation covers both the dynamic and static variants of the disaster relief personnel routing and scheduling problem. Computational results show that the proposed heuristic can generate in a short time sufficiently large number of Pareto Optimal Solutions which cover the entire Pareto frontier as indicated by the diverging behaviours of the Pareto Optimal Solutions and the associated hypervolume metrics.},
  archive      = {J_EJOR},
  author       = {İstenç Tarhan and Konstantinos G. Zografos and Juliana Sutanto and Ahmed Kheiri},
  doi          = {10.1016/j.ejor.2023.09.002},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {776-791},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A quadrant shrinking heuristic for solving the dynamic multi-objective disaster response personnel routing and scheduling problem},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Can online interfaces enhance learning for public
decision-making? Eliciting citizens’ preferences for multicriteria
decision analysis. <em>EJOR</em>, <em>314</em>(2), 760–775. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Innovative online interfaces informing and consulting citizens about their preferences for multicriteria decision analysis (MCDA) could make public decision-making more participatory. We propose a three-faceted learning for decision-making framework and used it to test newly-designed online weight elicitation interfaces. We investigated two features meant to enhance learning: fully-fledged gamification with a narrative, interaction with nonplayer characters, and ambient music, and learning loops (LL) using consistency checks of elicited weights and the challenge to resolve inconsistencies. We operationalized our framework with a novel systematic set of measure instruments providing complementary data types. We designed a 2 × 2 between-subject experiment with pre- and postquestionnaires. Answers from 769 respondents, representative of the Swiss population in age and gender, indicated that the interfaces successfully raised awareness about wastewater management. Gamification was helpful: respondents performed better in the factual learning test, and unexpected social learning occurred. However, gamification lowered the perception of process understanding. The LL were beneficial: objectively, respondents performed better in the factual learning test. However, respondents perceived the LL as cognitively demanding and their factual learning as lower. Our structured assessment highlighted the need for further research to investigate, for instance, high interpersonal variability and the disparities between tested and perceived learning. Measuring preference construction remains challenging; and social learning should be added to the assessment framework. Applying such structured assessment of learning outcomes to more traditional operational research interventions would provide a baseline for future comparison.},
  archive      = {J_EJOR},
  author       = {Alice H. Aubert and Sara Schmid and Judit Lienert},
  doi          = {10.1016/j.ejor.2023.10.031},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {760-775},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Can online interfaces enhance learning for public decision-making? eliciting citizens’ preferences for multicriteria decision analysis},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Government subsidy policies for guarantee financing: Risk
compensation vs. Fee reduction. <em>EJOR</em>, <em>314</em>(2), 747–759.
(<a href="https://doi.org/10.1016/j.ejor.2023.10.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small and medium-sized enterprises (SMEs) often rely on credit guarantee companies (guarantors) to obtain financing from banks. To encourage guarantors’ engagement and reduce SMEs’ guarantee costs, governments commonly implement two subsidy policies: risk compensation, which shares a fraction of guarantors’ losses, and fee reduction, which reimburses SMEs for a fraction of their guarantee fees. This paper formulates a game theoretical model to analyze the impact of these two policies on the decisions and profits of a capital-constrained SME firm and a profit-maximizing guarantor, and how a government should choose between the two policies. We find that under each policy, the total expected profit improvement of the firm and the guarantor is greater than the government expected expenditure incurred if and only if the firm&#39;s default probability is below a threshold. Comparing the two policies with a budget constraint, we find that if the government&#39;s objective is to maximize the firm&#39;s expected profit, risk compensation outperforms fee reduction. But if the objective is to maximize the total expected profit of the firm and the guarantor, which policy performs better depends on the firm&#39;s default probability. Moreover, if the government aims to maximize social welfare, risk compensation performs as well as or better than fee reduction. We also consider the case where the guarantor is publicly owned and not-for-profit; in this case, under each policy, the expected profit improvement of the firm is always lower than the government expected expenditure.},
  archive      = {J_EJOR},
  author       = {Luping Luo and Wen He and Hao Hu},
  doi          = {10.1016/j.ejor.2023.10.032},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {747-759},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Government subsidy policies for guarantee financing: Risk compensation vs. fee reduction},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new cross-efficiency meta-frontier analysis method with
good ability to identify technology gaps. <em>EJOR</em>,
<em>314</em>(2), 735–746. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-efficiency evaluation and meta-frontier analysis (MFA) have been widely used to measure performance in many areas. However, cross-efficiency MFA (CMFA) has rarely been studied due to its potential violation of the basic MFA property, that is, the efficiency relative to the group frontier is not less than that relative to the meta-frontier. In this paper, we deduce the conditions under which the cross-efficiency score generated by the current CMFA method relative to the group frontier is smaller than that relative to the meta-frontier, and the conditions under which the current CMFA method is unable to identify the technical gaps between the group frontiers and the meta-frontier. To guarantee the basic property and identify technical gaps, we introduce a new CMFA method, where the efficiencies relative to the group frontiers are first cross-evaluated by the traditional cross-evaluation approach and then those relative to the meta-frontier are cross-evaluated by using modified data envelopment analysis models. Compared with the existing CMFA method, our approach has the following advantages: it can successfully ensure that the cross-efficiencies and cross-efficiency scores relative to the group frontiers are not less than those relative to the meta-frontier; it has a good identification of technology gaps and provides more detailed information about the inefficiency; all the mathematical programming models involved in our CMFA method are feasible. Theoretical analyses and numerical examples support the practicality and superiority of our method.},
  archive      = {J_EJOR},
  author       = {Ruiyue Lin and Yudan Peng},
  doi          = {10.1016/j.ejor.2023.10.034},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {735-746},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new cross-efficiency meta-frontier analysis method with good ability to identify technology gaps},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal instant discounts of multiple ride options at a
ride-hailing aggregator. <em>EJOR</em>, <em>314</em>(2), 718–734. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, ride-hailing aggregators have emerged to help passengers find the best ride options. It aggregates the results from different service providers, allowing sorting and filtering all in a single app. It is not unusual for an aggregator to offer instant discounts on the prices returned from the service providers to increase its Gross Transaction Value (GTV) or Total Transaction Volume (TTV). In this research, we study this optimal instant discount problem, which can be viewed as a new variant of the classical multi-product price optimization problem. We first use the Nested Logit model to predict the probability a passenger would complete the trip with each ride option. We then formulate the instant discount problem as a nonlinear optimization model with a budget constraint and a group of discount bound constraints. To solve this model, we construct a surrogate relaxation formulation with strong duality. We develop a Lagrangian-dual-based approach to decompose this problem into a series of subproblems, and then design heuristic methods to give feasible solutions. For both cases when the GTV or the TTV is maximized, we quantify the optimality gap, give its asymptotic properties, and establish conditions under which it becomes zero and tight. Finally, we use real data from Meituan, a leading ride-hailing aggregator in China, to validate the proposed approach. Results show that compared to the baseline methods, we can improve the GTV by 1.293%, improve the TTV by 0.475%, and decrease the magnitude of the optimality gap.},
  archive      = {J_EJOR},
  author       = {Junlin Chen and Jinghong Xiong and Guobao Chen and Xin Liu and Peng Yan and Hai Jiang},
  doi          = {10.1016/j.ejor.2023.10.019},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {718-734},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal instant discounts of multiple ride options at a ride-hailing aggregator},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Column generation for solving large scale multi-commodity
flow problems for passenger transportation. <em>EJOR</em>,
<em>314</em>(2), 703–717. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In light of the need for design and analysis of intermodal transportation systems, we propose an algorithmic framework to optimize respective passenger flows from a system perspective. To this end, we model an intermodal transportation system by combining two core principles of network optimization – layered-graph structures and (partially) time-expanded networks – to formulate our problem on a graph that allows us to implicitly encode problem specific constraints related to intermodality. This enables us to solve a standard integer minimum-cost multi-commodity flow problem to obtain the passenger flow system optimum for an intermodal transportation system. To solve this problem efficiently, we present a column generation approach to find continuous minimum-cost multi-commodity flow solutions, which we combine with a price-and-branch procedure to obtain integer solutions. To speed up our column generation, we further develop a pricing filter and an admissible distance approximation to utilize the A * A* algorithm for solving the pricing problems. We show the efficiency of our framework by applying it to a real-world case study for the city of Munich, where we solve instances with up to 56,295 passengers to optimality, and show that the computation time of our algorithm can be reduced by up to 60% through the use of our pricing filter and by up to additional 90% through the use of our A * A* -based pricing algorithm.},
  archive      = {J_EJOR},
  author       = {Benedikt Lienkamp and Maximilian Schiffer},
  doi          = {10.1016/j.ejor.2023.09.019},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {703-717},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Column generation for solving large scale multi-commodity flow problems for passenger transportation},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The multi-visit drone-assisted pickup and delivery problem
with time windows. <em>EJOR</em>, <em>314</em>(2), 685–702. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a new combined truck–drone routing problem with time windows in the context of last-mile logistics. A fleet of trucks, each equipped with an identical drone, is scheduled to provide both pickup and delivery services to a set of customers with minimum cost. Some customers are paired, in that the goods picked up from one must be delivered to the other on the same route. Drones are launched from and retrieved by trucks at a pool of designated stations, which can be used multiple times. Each drone can serve multiple customers in one flight. We formulate this problem as a large-scale mixed-integer bilinear program, with the bilinear terms used to calculate the load-time-dependent energy consumption of drones. To accelerate the solution process, multiple valid inequalities are proposed. For large-size problems, we develop a customised adaptive large neighbourhood search (ALNS) algorithm, which includes several preprocessing procedures to quickly identify infeasible solutions and accelerate the search process. Moreover, two feasibility test methods are developed for trucks and drones, along with an efficient algorithm to determine vehicles’ optimal waiting time at launch stations, which is important to consider due to the time windows. Extensive numerical experiments demonstrate the effectiveness of the valid inequalities and the strong performance of the proposed ALNS algorithm over two benchmarks in the literature, and highlight the cost-savings of the combined mode over the truck-only mode and the benefits of allowing multiple drone visits.},
  archive      = {J_EJOR},
  author       = {Shanshan Meng and Yanru Chen and Dong Li},
  doi          = {10.1016/j.ejor.2023.10.021},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {685-702},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The multi-visit drone-assisted pickup and delivery problem with time windows},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint rolling stock rotation planning and depot deadhead
scheduling in complicated urban rail transit lines. <em>EJOR</em>,
<em>314</em>(2), 665–684. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the joint rolling stock rotation planning and depot deadhead scheduling in complicated urban rail transit lines with multiple depots, multiple line services, and multiple compositions. The rotation planning aims at connecting the given train trips into train sequences (each of which is served by an individual rolling stock) and determining the routing plan of rolling stocks to pass through visited turnback stations while connecting train trips. The task of the depot deadhead scheduling is to determine conflict-free deadhead routes and deadhead timetables of rolling stocks between the origin/destination of each train sequence and corresponding depot. We formulate the studied problem as a generalized set partitioning-type model containing an exponential number of variables, by using a new time-space network representation and by proposing a novel modelling method for the departure–arrival headway requirement to control the number of constraints. Owing to the complexity of this model, a column generation-based algorithm is adopted to solve efficiently practical-size problems. We enhance a standard column generation (to compute tight lower bound) by further incorporating procedures of variable rounding and halted column generation, to strengthen the capability of searching for better quality solutions. Customized acceleration mechanisms are also explored to speed up the convergence of column generation and the computation of best-known integer solution. We compare our approach with three benchmark approaches and the trial-and-error-based empirical method used by rail dispatchers in practice. Computational results reveal that our approach outperforms these benchmark approaches by computing (near-)optimal solutions. Our optimized solution for a large real-world instance (computed within a practically reasonable computation time) is better than the empirical solution, in terms of all the considered objective function parts.},
  archive      = {J_EJOR},
  author       = {Dian Wang and Andrea D’Ariano and Jun Zhao and Shuguang Zhan and Qiyuan Peng},
  doi          = {10.1016/j.ejor.2023.10.012},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {665-684},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Joint rolling stock rotation planning and depot deadhead scheduling in complicated urban rail transit lines},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Performance evaluation of a two-echelon inventory system
with network lost sales. <em>EJOR</em>, <em>314</em>(2), 647–664. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inventory systems are largely analyzed in the literature under the common assumption of backorders due to the complexity of lost sales. In this paper, we consider a two-echelon inventory system composed of a central warehouse and multiple local warehouses subject to lost sales. The demand faced by each local warehouse is a Poisson process and the stock in the warehouses is controlled according to a continuous review base-stock policy. This system has been analyzed in the literature under deterministic or exponential lead-times at the central warehouse, deterministic lead times at the local warehouses and approximate performance evaluations have been proposed for two cases: (1) the demand is lost if no items are available in the local warehouse, the central warehouse, or in the pipeline in between (i.e., a waiting time threshold for incoming demand equal to the local warehouse lead time), and (2) when there is a waiting time threshold less than the local warehouse lead time. Based on a queuing network representation of the system, we extend the performance analysis of the system in the first case by considering generally distributed lead times both at the central and local warehouses and by providing the exact closed-form expressions for the inventory performance measures. In the second case, we provide new approximate solutions under generally distributed lead times at the central warehouse. We numerically show that our exact and approximate solutions perform equally or better than those presented in the literature under deterministic lead times.},
  archive      = {J_EJOR},
  author       = {Chaaben Kouki and Joachim Arts and M. Zied Babai},
  doi          = {10.1016/j.ejor.2023.10.009},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {647-664},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Performance evaluation of a two-echelon inventory system with network lost sales},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated storage and retrieval system design with variant
lane depths. <em>EJOR</em>, <em>314</em>(2), 630–646. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper models a warehouse design problem with 2D automated storage and retrieval system (AS/RS) and 3D AS/RS as options, where 3D racks may have different depths. The design problem is first modeled as a mixed-integer nonlinear program to minimize investment and maximize throughput under various business needs, such as cost structure, responsiveness requirement, demand rates, and inventory levels. The model is then converted to a mixed-integer program based on optimality conditions. A basic Branch-and-Bound algorithm and a modified one are developed to overcome computational challenges. A high throughput expectation leads to a design with shallow storage racks, while high land/equipment costs have opposite impacts. When demand rates are similar across SKUs, heterogeneously distributed inventory levels lead to racks with different depths and assigning SKUs with higher inventory levels to deeper racks. More heterogeneous demand rates also make rack depths more variant and have SKUs with higher demand rates assigned to shallower racks. In other words, the heterogeneities of inventory levels and demand rates have a contradictory effect on the SKU-to-rack assignment and result in racks with more uniform depths when SKUs with high demand also have high inventory levels, which is often the case in practice.},
  archive      = {J_EJOR},
  author       = {Wenquan Dong and Mingzhou Jin},
  doi          = {10.1016/j.ejor.2023.10.006},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {630-646},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Automated storage and retrieval system design with variant lane depths},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Request acceptance with overbooking in dynamic and
collaborative vehicle routing. <em>EJOR</em>, <em>314</em>(2), 612–629.
(<a href="https://doi.org/10.1016/j.ejor.2023.10.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem setting of a less-than-truckload carrier serving stochastic customer requests. Each request must be answered dynamically by accepting or rejecting it immediately. On the next day, accepted requests are served in routes using a set of vehicles with limited load capacity and route duration. After the request acceptance phase and before the fulfillment, multiple carriers participate in a combinatorial auction to exchange requests. An auctioneer allocates the bundles of requests to carriers according to their bids in a cost-minimizing way and distributes the auction profits. This type of horizontal collaboration provides cost savings and contributes to reducing negative impacts of transportation. We describe the carrier’s optimization problem of maximizing profit as a Markov decision process that comprises the sequential decisions in all phases, i.e., request acceptance, request selection for the auction, bidding, and routing. For solving a version of the vehicle routing problem with pickups and deliveries, heuristic approaches are proposed that achieve efficient and balanced routes. We design overbooking policies for strategically accepting more requests bearing in mind the options provided by the auction. Computational results show that – by trading requests in an auction – carriers can accept more requests than they could serve on their own. The carriers’ request acceptance decisions impact their individual profits and the overall collaboration savings. The largest benefits can be achieved with an overbooking policy that prescribes which requests should be accepted by all carriers, based on the locations of both the request and the carriers’ depots.},
  archive      = {J_EJOR},
  author       = {Yannick Oskar Scherr and Margaretha Gansterer and Richard F. Hartl},
  doi          = {10.1016/j.ejor.2023.10.014},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {612-629},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Request acceptance with overbooking in dynamic and collaborative vehicle routing},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Balancing mixed-model assembly lines for random sequences.
<em>EJOR</em>, <em>314</em>(2), 597–611. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assembly lines are the standard choice for the manufacturing of large products and must combine efficiency with flexibility. Since multiple product variants are assembled on the same line, the variation in the processing time and the production sequence must be accounted for. This is especially hard in the planning phase of assembly lines when the demand is only forecast and the production sequence is not yet known. In this paper, an exact method and heuristic extensions are proposed to tackle the paced assembly-line balancing problem considering a random production sequence. Along with the assignment of tasks, the length of the stations is optimized in a Branch-and-Bound algorithm using Markov chains to evaluate the expected costs, which require the solution of a convex subproblem on each node. Product variants are modelled with a given probability, which can be either independent or correlated. Results of the model can be then further improved by optimizing the sequencing once the orders are known. The exact method can solve instances of small and medium-size containing up to 1 0 12 1012 product variants and the heuristic extensions can give good solutions with up to 1 0 20 1020 products. Results show that the optimization of station lengths is more important for the total cost than the difference between optimal and good task assignment solutions.},
  archive      = {J_EJOR},
  author       = {Celso Gustavo Stall Sikora},
  doi          = {10.1016/j.ejor.2023.10.008},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {597-611},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Balancing mixed-model assembly lines for random sequences},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incorporating risk aversion and time preference into
omnichannel retail operations considering assortment and inventory
optimization. <em>EJOR</em>, <em>314</em>(2), 579–596. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An omnichannel retail network includes an omnichannel retailer (o-retailer) determining which products among the candidate set are offered via an online or offline channel, and then procuring these products from the supplier and distributing them from a distribution center (DC) to physical stores for serving customers. The o-retailer adopts either the distribution center or physical stores to fulfill online orders. This study considers an integrated approach to manage assortment planning, inventory control and e-fulfillment problems and develops a distributionally robust optimization model, in which the distribution of uncertain demand is only partially available in advance. In the proposed model, the worst-case mean-Conditional Value-at-Risk (WMCVaR) is formulated as the objective function that makes a trade-off between the expected profit and the risk, and a quasi-hyperbolic discounting function is adopted to denote the customers’ time preference. Furthermore, to overcome model solvability obstacle caused by imprecise probability distributions, the box ambiguity set is applied to derive computationally tractable counterparts. Numerical studies are conducted to investigate the validity and efficiency of our proposed model. Some useful managerial insights and implications for o-retailers are generated through the analyses of computational results.},
  archive      = {J_EJOR},
  author       = {Zhimin Guan and Yuxia Mou and Jun Zhang},
  doi          = {10.1016/j.ejor.2023.09.034},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {579-596},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Incorporating risk aversion and time preference into omnichannel retail operations considering assortment and inventory optimization},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Entry decisions for vertically differentiated markets with
brand spillovers. <em>EJOR</em>, <em>314</em>(2), 565–578. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a branded firm offers a new product at a quality level different from that of its existing product(s), some bias is often present as consumers are affected by the quality of the existing product(s) when evaluating the quality of the new one(s). Consequently, this product offering creates a forward spillover effect and, in turn, might even impact consumers’ utility from the existing product, referred to as the reciprocal spillover effect. Given the potential for such brand spillovers, how should a branded firm enter a new market with a vertically differentiated product? We analytically investigate a branded firm’s choice of quality and the profitability of entering a new market. The results indicate that bilateral spillovers cause the entrant to fail to adjust the quality of its new product, meaning that a new firm providing a high-end existing product entering the market will not be profitable, even in the absence of any fixed entry costs and potential competitors. Nevertheless, we also show that when the new market has a rival firm, the potential presence of severe spillovers works as a commitment device for the entrant’s quality positioning, which can reverse the entrant’s incentive to enter; in contrast, the entrant’s resulting profits can be greater in this case than in the absence of spillovers.},
  archive      = {J_EJOR},
  author       = {Keita Nire and Nobuo Matsubayashi},
  doi          = {10.1016/j.ejor.2023.09.024},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {565-578},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Entry decisions for vertically differentiated markets with brand spillovers},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aiding airlines for the benefit of whom? An applied
game-theoretic approach. <em>EJOR</em>, <em>314</em>(2), 552–564. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the face of a significant exogenous shock, government intervention may be required at the level of an industry in order to preserve the market. By employing a game engineering approach, we develop a model to test the potential impact of varying types of bailout schemes on network oriented industries facing such a shock. Investigating the European aviation market, served by both legacy and low-cost carriers, we assess whether the forms of aid offered during the Covid-19 pandemic may lead to changes in market equilibrium outcomes over the coming years. Airlines choose the size of their fleet, schedule and airfares across the network and compete for market share. The social welfare analysis suggests that the European Commission has likely distorted competition in the aviation markets by allowing Member States to provide different types of rescue packages. In addition, we show that the most efficient solution would have been to coordinate state aid, preferably in the form of time-limited loans. Furthermore, the approach could be applied as a screening tool by governments when considering bailout requests. Its application ex-ante allows policymakers to assess the likelihood of taxpayers receiving a return on their investment.},
  archive      = {J_EJOR},
  author       = {Nicole Adler and Gianmarco Andreana},
  doi          = {10.1016/j.ejor.2023.09.015},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {552-564},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Aiding airlines for the benefit of whom? an applied game-theoretic approach},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The bright side of the planning fallacy in distribution
channels. <em>EJOR</em>, <em>314</em>(2), 540–551. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The planning fallacy describes the tendency of people to underestimate the costs and to overestimate the benefits of investments. It is typically associated with cost overruns and decreased performance. In this paper, we demonstrate that in a simple distribution channel with an upstream manufacturer and a downstream retailer that both make demand-enhancing investments, there is a bright side of the planning fallacy: managerial optimism bias that results in underestimated investment costs can in fact lead to a win-win outcome which makes the manufacturer, the retailer, and consumers better off than without bias. Moreover, the total profit of the decentralized distribution channel can be even higher than the centralized channel’s profit. We find that our results are robust to changes in the sequencing of decisions and continue to hold under generalized Nash bargaining over the wholesale price as well as under upstream or downstream competition or consumer demand uncertainty.},
  archive      = {J_EJOR},
  author       = {Michael Kopel and Vinay Ramani},
  doi          = {10.1016/j.ejor.2023.10.040},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {540-551},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The bright side of the planning fallacy in distribution channels},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simplifying tree-based methods for retail sales forecasting
with explanatory variables. <em>EJOR</em>, <em>314</em>(2), 523–539. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite being consistently outperformed by machine learning (ML) in forecasting competitions, simple statistical forecasting techniques remain standard in retail. This is partly because, for all their advantages, these top-performing ML methods are often too complex to implement. We have experimented with various tree-based ML methods and find that a ‘simple’ implementation of these can (substantially) outperform traditional forecasting methods while being computationally efficient. Our approach is validated with a dataset of 4,523 products of a leading Belgian retailer containing various explanatory variables (e.g., promotions and national events). Using Shapley values and slightly adjusted tree-based methods, we show that superior performance depends on the availability of explanatory variables and additional feature engineering. For robustness, we show that our findings also hold when using the M5 competition dataset. Extensive numerical experimentation finally shows how the forecast superiority of our proposed framework translates to higher service levels, lower inventory costs, and improvements in the bullwhip of orders and inventory. Our framework, with its excellent performance and scalability to practical forecasting settings, we contribute to the growing body of research aimed at facilitating the higher adoption rate of ML among ‘traditional’ retailers.},
  archive      = {J_EJOR},
  author       = {Arnoud P. Wellens and Robert N. Boute and Maximiliano Udenio},
  doi          = {10.1016/j.ejor.2023.10.039},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {523-539},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Simplifying tree-based methods for retail sales forecasting with explanatory variables},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wasserstein distributionally robust surgery scheduling with
elective and emergency patients. <em>EJOR</em>, <em>314</em>(2),
509–522. (<a href="https://doi.org/10.1016/j.ejor.2023.10.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a surgery scheduling problem with regard to both elective and emergency patients, where surgery durations are uncertain and emergency patients arrive dynamically. The problem determines, at the beginning of a day, how many operating rooms to open and how to allocate elective and (possibly dummy) emergency patients into them to minimize the operating room opening and expected overtime costs. Incorporating (possibly dummy) emergency patients provides a novel approach for reserving emergency capacity. We propose a robust data-driven model that allows for distributional ambiguity via the Wasserstein metric. We derive its mixed-integer conic reformulation and develop an exact branch-and-cut algorithm. We also uncover our model’s connections to its sample average approximation counterpart. Since emergency patients necessitate adequate and timely treatments, we formalize a rolling horizon scheme to dynamically reschedule and prioritize the emergency patients upon their arrivals. Our scheme handles practical features such as dynamic emergency arrivals and uncertain service duration. We perform simulation studies based on real data and numerical experiments show that our method outperforms the benchmark ones in a variety of performance indicators.},
  archive      = {J_EJOR},
  author       = {Yu Wang and Yu Zhang and Jiafu Tang},
  doi          = {10.1016/j.ejor.2023.10.026},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {509-522},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Wasserstein distributionally robust surgery scheduling with elective and emergency patients},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing steel coil production schedules under continuous
casting and hot rolling. <em>EJOR</em>, <em>314</em>(2), 496–508. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In continuous steel casting operations, heats of molten steel are alloyed and refined in ladles, continuously cast and cut into slabs, and hot-rolled into coils. We present a mixed-integer program that produces a daily casting schedule and that is solved using state-of-the-art software for a 100% direct-charge steel mill; two casters concurrently produce slabs, which are rolled into coils at a single hot rolling mill. This model minimizes penalties incurred by violating plant best practices while strictly adhering to safety and logical constraints to manage risk associated with manufacturing incidents. An efficient formulation, combined with variable reduction and cutting planes, expedites solutions for small instances containing hundreds of variables and thousands of constraints by factors of at least two or three (and sometimes even 100); instances an order of magnitude larger along both problem dimensions suggest solutions that reduce costs incurred using plant best practices by as much as 40%.},
  archive      = {J_EJOR},
  author       = {Nelson Torres and Gus Greivel and Joshua Betz and Eduardo Moreno and Alexandra Newman and Brian Thomas},
  doi          = {10.1016/j.ejor.2023.10.005},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {496-508},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing steel coil production schedules under continuous casting and hot rolling},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Drone routing problem with swarm synchronization.
<em>EJOR</em>, <em>314</em>(2), 477–495. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advantages of rotary-wing drone (RWD) delivery modes have already been delineated. However, single-unit RWDs do not completely solve real problems in last-mile parcel deliveries because of limited payload capacity and flight endurance. Currently, drone swarm technology is being rapidly developed. An RWD swarm can deliver heavy or multiple packages to customers; therefore, the RWD swarm strategy can address the payload capacity limitation of RWDs. Herein, an RWD delivery mode that involves dynamic swarms of RWDs in addition to single-unit RWDs is explored. The “dynamic” characteristic permits the RWD members in swarms to vary by coupling/decoupling operations at nodes. From the routing plan perspective, using RWD swarms for last-mile parcel deliveries is challenging; accordingly, we introduce a swarm synchronization mode that involves interactions among RWD routes. We formally define the drone routing problem with swarm synchronization (DRP-SS) and develop a mixed-integer linear programming model, which considers the decision on RWD swarms and multi trips. An adaptive large neighborhood search heuristic with specific operators is proposed. In the computational experiments, both small- and large-scale instances are used to validate the effectiveness of the mathematical formulation and the heuristic. Several managerial insights are obtained regarding the influence of detours, the utilization of RWD swarms, and the benefits of multi trips. The DRP-SS model and solution method can be used to estimate the performance of the selection of RWD swarms in practical situations.},
  archive      = {J_EJOR},
  author       = {Hongqi Li and Feilong Wang and Zhuopeng Zhan},
  doi          = {10.1016/j.ejor.2023.10.015},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {477-495},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Drone routing problem with swarm synchronization},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Responsible audit and consumer awareness under collusion
risk. <em>EJOR</em>, <em>314</em>(2), 466–476. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While sourcing from emerging economies can significantly reduce a buying firm’s operating costs, it may cause great financial or reputational damages due to supplier violations (e.g., child labor and environmental damage). In practice, multinational firms often employ third-party audits as an important approach to ensure their suppliers’ compliance prior to procurement. Unfortunately, in countries with lax law enforcement, collusion between suppliers and auditors often occurs, which helps suppliers pass audits with a lower compliance level, thus lowering consumers’ expectations of supply chain compliance. In this paper, we develop a game theoretic model to study a firm’s contracting strategy under supplier–auditor collusion risk when consumers have rational expectations. First, we show that the firm’s equilibrium contracting strategy takes three different forms depending on the collusion penalty. Interestingly, in contrast to the well-established results in the literature, we show that the firm may reduce the equilibrium compliance requirement. Second, we show that decreasing the supplier’s compliance effort cost, increasing their ethical level, or increasing consumers’ awareness of responsibility may lead to more rampant collusion, although all of them increase the supplier’s compliance level and the firm’s profit. In contrast, increasing the penalty always leads to a higher profit for the firm, a higher supplier’s compliance level, and lower collusion risk. Finally, we extend our model to examine the impacts of uncertainty about the auditor’s ethical level, bargaining power, and mandatory external standards.},
  archive      = {J_EJOR},
  author       = {Ruoxin Gao and Shiqing Yao and Ruina Yang},
  doi          = {10.1016/j.ejor.2023.10.011},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {466-476},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Responsible audit and consumer awareness under collusion risk},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A new formulation and a branch-and-cut algorithm for the
set orienteering problem. <em>EJOR</em>, <em>314</em>(2), 446–465. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study we address the Set Orienteering Problem, which is a generalization of the Orienteering Problem where customers are clustered in groups. Each group is associated with a profit which is gained in case at least one customer in the group is served. A single vehicle is available to serve the customers. The aim is to find the vehicle route that maximizes the profit collected without exceeding a maximum route cost, which can be interpreted also as route duration. The problem was introduced in Archetti (2018) together with a mathematical programming formulation. In this paper, we propose a new formulation which uses less variables. We also derive different classes of valid inequalities to strengthen the formulation. In addition, separation algorithms are developed, some of which are new with respect to those presented in the literature. A branch-and-cut algorithm is implemented to solve the problem and tests are made on benchmark instances. The results show that the branch-and-cut algorithm is effective in solving instances with up to 100 customers. Moreover, the difficulty of solving the problem largely depends on the maximum route duration. We also show that valid inequalities are effective in speeding up the solution process. Finally, a comparison with two exact benchmark approaches proposed in the literature shows that the branch-and-cut algorithm proposed in this paper is the new state-of-the-art exact approach for solving the Set Orienteering Problem.},
  archive      = {J_EJOR},
  author       = {C. Archetti and F. Carrabs and R. Cerulli and F. Laureana},
  doi          = {10.1016/j.ejor.2023.09.038},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {446-465},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new formulation and a branch-and-cut algorithm for the set orienteering problem},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep reinforcement learning for inventory optimization with
non-stationary uncertain demand. <em>EJOR</em>, <em>314</em>(2),
433–445. (<a href="https://doi.org/10.1016/j.ejor.2023.10.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider here a single-item lot sizing problem with fixed costs, lead time, and both backorders and lost sales, and we show that, after an appropriate training in randomly generated environments, Deep Reinforcement Learning (DRL) agents can interpolate in real-time near-optimal dynamic policies on instances with a rolling-horizon, provided a previously unseen demand forecast and without the need to periodically resolve the problem. Extensive computational experiments show that the policies provided by these agents compete, and in some circumstances even outperform by several percentage points of gap, those provided by heuristics based on dynamic programming. These results confirm the importance of DRL in the context of inventory control problems and support its use in solving practical instances featuring realistic assumptions.},
  archive      = {J_EJOR},
  author       = {Henri Dehaybe and Daniele Catanzaro and Philippe Chevalier},
  doi          = {10.1016/j.ejor.2023.10.007},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {433-445},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Deep reinforcement learning for inventory optimization with non-stationary uncertain demand},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The flexible job shop scheduling problem: A review.
<em>EJOR</em>, <em>314</em>(2), 409–432. (<a
href="https://doi.org/10.1016/j.ejor.2023.05.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flexible job shop scheduling problem (FJSP) is an NP-hard combinatorial optimization problem, which has wide applications in the real world. The complexity and relevance of the FJSP have led to numerous research works on its modeling and resolution. This paper reviews some of the research of the past 30 years on the problem, by presenting and classifying the different criteria, constraints, configurations and solution approaches that have been considered. Recent emerging topics on complex shop scheduling, multi-criteria optimization and uncertain and dynamic environments are discussed. Finally, future research opportunities are proposed.},
  archive      = {J_EJOR},
  author       = {Stéphane Dauzère-Pérès and Junwen Ding and Liji Shen and Karim Tamssaouet},
  doi          = {10.1016/j.ejor.2023.05.017},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {2},
  pages        = {409-432},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The flexible job shop scheduling problem: A review},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Persistence in financial connectedness and systemic risk.
<em>EJOR</em>, <em>314</em>(1), 393–407. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper characterizes dynamic linkages arising from shocks with heterogeneous degrees of persistence. Using frequency domain techniques, we introduce measures that identify smoothly varying links of a transitory and persistent nature. Our approach allows us to test for statistical differences in such dynamic links. We document substantial differences in transitory and persistent linkages among US financial industry volatilities, argue that they track heterogeneously persistent sources of systemic risk, and thus may serve as a useful tool for market participants.},
  archive      = {J_EJOR},
  author       = {Jozef Baruník and Michael Ellington},
  doi          = {10.1016/j.ejor.2023.11.023},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {393-407},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Persistence in financial connectedness and systemic risk},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Impacts of extreme weather events on mortgage risks and
their evolution under climate change: A case study on florida.
<em>EJOR</em>, <em>314</em>(1), 377–392. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop an additive Cox proportional hazard model with time-varying covariates, including spatio-temporal characteristics of weather events, to study the impact of weather extremes (heavy rains and tropical cyclones) on the probability of mortgage default and prepayment. We compare the survival model with a flexible logistic model and an extreme gradient boosting algorithm. We estimate the models on a portfolio of mortgages in Florida, consisting of 69,046 loans and 3,707,831 loan-month observations with localization data at the five-digit ZIP code level. We find a statistically significant and non-linear impact of tropical cyclone intensity on default as well as a significant impact of heavy rains in areas with large exposure to flood risks. These findings confirm existing results in the literature and also provide estimates of the impact of the extreme event characteristics on mortgage risk, e.g. the impact of tropical cyclones on default more than doubles in magnitude when moving from a hurricane of category two to a hurricane of category three or more. We build on the identified effect of exposure to flood risk (in interaction with heavy rainfall) on mortgage default to perform a scenario analysis of the future impacts of climate change using the First Street flood model, which provides projections of exposure to floods in 2050 under RCP 4.5. We find a systematic increase in risk under climate change that can vary based on the scenario of extreme events considered. Climate-adjusted credit risk allows risk managers to better evaluate the impact of climate-related risks on mortgage portfolios.},
  archive      = {J_EJOR},
  author       = {Raffaella Calabrese and Timothy Dombrowski and Antoine Mandel and R. Kelley Pace and Luca Zanin},
  doi          = {10.1016/j.ejor.2023.11.022},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {377-392},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Impacts of extreme weather events on mortgage risks and their evolution under climate change: A case study on florida},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simulation schemes for the heston model with poisson
conditioning. <em>EJOR</em>, <em>314</em>(1), 363–376. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exact simulation schemes under the Heston stochastic volatility model (e.g., Broadie–Kaya and Glasserman–Kim) suffer from computationally expensive modified Bessel function evaluations. We propose a new exact simulation scheme without the modified Bessel function, based on the observation that the conditional integrated variance can be simplified when conditioned by the Poisson variate used for simulating the terminal variance. Our approach also enhances the low-bias and time discretization schemes, which are suitable for pricing derivatives with frequent monitoring. Extensive numerical tests reveal the good performance of the new simulation schemes in terms of accuracy, efficiency, and reliability when compared with existing methods.},
  archive      = {J_EJOR},
  author       = {Jaehyuk Choi and Yue Kuen Kwok},
  doi          = {10.1016/j.ejor.2023.10.048},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {363-376},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Simulation schemes for the heston model with poisson conditioning},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A bi-level model for district-fairness participatory
budgeting: Decomposition methods and application. <em>EJOR</em>,
<em>314</em>(1), 340–362. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Participatory budgeting is one of the most well-known and widespread participatory programs implemented in many municipalities worldwide. Targeting poorer regions to receive a greater per capita amount of spending than wealthier regions is the most important transformational aspect of participatory budgeting. However, current approaches do not provide a precise method for achieving social justice through participatory budgeting. This paper proposes a bi-level mixed-integer non-linear optimization framework under the partial cooperation assumption to promote social justice in participatory budgeting programs. In addition, single-level reformulation and linearization techniques are presented, along with valid inequalities that speed up their resolution procedure. The single-level linear problem is solved using the Benders decomposition algorithm to find global optimality. To improve the computational performance of the proposed model on large-scale instances, a hierarchical iterative, evolutionary algorithm is proposed based on the hybrid binary particle swarm optimization and gravitational search algorithm. To illustrate the capability of the proposed model, computational experiments were conducted on both adapted examples from the literature and real-world, large-scale cases implemented in recent years in Warsaw, the capital of Poland. The results show that the proposed model is significantly more efficient, affordable, and faster than other methods presented in the literature, such as the Greedy rule and ε-district-fair lottery. In addition, the proposed model is fully operational for real-world societal problems.},
  archive      = {J_EJOR},
  author       = {Majid Beikverdi and Nasim Ghanbar Tehrani and Kamran Shahanaghi},
  doi          = {10.1016/j.ejor.2023.09.037},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {340-362},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A bi-level model for district-fairness participatory budgeting: Decomposition methods and application},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How responsive should a firm be to customers’ expectations?
<em>EJOR</em>, <em>314</em>(1), 323–339. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores ways to optimally align quality with customer expectations in light of changes in expectations related to experience with the actual quality of the product. A firm&#39;s strategic decision is its responsivity. Responsivity is defined here as the extent to which the quality delivered is aligned with customer expectations. The issue is to find the level of responsivity that maximizes the firm&#39;s benefits by increasing the number of loyal customers. The key tradeoff is that although responsivity can help the firm increase its volume of loyal consumers, it is also costly. The main findings are a theoretical characterization of optimal responsivity and an extension to a strategy that offers good/service both with and without responsivity. The outcome is a win-win strategy, that significantly increases both profits and the number of loyal customers, whose expectations converge to the quality delivered. The potential impact of these findings on practice is significant: by understanding what determines the optimal level of responsivity and implementing this win-win strategy, firms can enhance customer satisfaction, loyalty, and profitability.},
  archive      = {J_EJOR},
  author       = {Gila E. Fruchter and Agnieszka Wiszniewska-Matyszkiel},
  doi          = {10.1016/j.ejor.2023.09.011},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {323-339},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {How responsive should a firm be to customers’ expectations?},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new multiple criteria data envelopment analysis with
variable return to scale: Applying bi-dimensional representation and
super-efficiency analysis. <em>EJOR</em>, <em>314</em>(1), 308–322. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that, in general, in practical real-world problems, when the number of Decision- Making Units (DMUs) is not large enough compared to the total number of input and output parameters, the traditional DEA models with Constant Return to Scale – CRS and with Variable Return to Scale – VRS have a weak power of discrimination, producing solutions that identify many DMUs as being efficient, in addition to obtaining unrealistic weight distributions. In this context, it is recommended to work with Multiple Criteria Data Envelopment Analysis - MCDEA models. So far, all MCDEA models available in the literature adopt CRS approach. This paper proposes a New Multiple Criteria Data Envelopment Analysis (NMCDEA) – VRS model, as well as performs a super-efficiency analysis for this model. Furthermore, through bi- dimensional graphic representations, a geometric demonstration is provided, showing that, in fact, the proposed model is a good representation of situations in which it is interesting to consider a VRS behavior. The results obtained through the optimization of instances available in the literature, for real instances, as well as the sensitivity analysis carried out, indicated that the NMCDEA-VRS has a much greater power of discrimination compared to the classic DEA–VRS model.},
  archive      = {J_EJOR},
  author       = {Aneirson Francisco da Silva and Rafael de Carvalho Miranda and Fernando Augusto Silva Marins and Erica Ximenes Dias},
  doi          = {10.1016/j.ejor.2023.09.008},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {308-322},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new multiple criteria data envelopment analysis with variable return to scale: Applying bi-dimensional representation and super-efficiency analysis},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Column generation-based prototype learning for optimizing
area under the receiver operating characteristic curve. <em>EJOR</em>,
<em>314</em>(1), 297–307. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional classification algorithms focus on the maximization of classification accuracy which might lead to poor performance in practice by forcing classifiers to overfit to the majority class. In order to overcome this issue, various approaches focus on the optimization of alternative loss functions such as the Area Under the Curve (AUC). AUC is a Receiver Operating Characteristics (ROC) metric that has been widely used to measure classification performance, especially when there are class imbalances. In this work, we propose a column generation (CG)-based algorithm called Ranking-CG, which learns a model, similar to the popular Ranking SVM, through approximate maximization of the AUC. Unlike the Ranking SVM, our algorithm utilizes a column generation method that iteratively adds features to control the model complexity effectively working as an internal feature selection procedure. Our experiments show that column generation can be an important tool to prevent overfitting. We extend the Ranking-CG by proposing a prototype generation method, denoted by Ranking-CG Prototype, that constructs reference points by solving a non-linear optimization problem. Based on the extensive experiments conducted on 74 binary classification problems, the Ranking-CG Prototype yields the best average test AUC among all competing methods by using significantly few features than other benchmarks.},
  archive      = {J_EJOR},
  author       = {Erhan C. Ozcan and Berk Görgülü and Mustafa G. Baydogan},
  doi          = {10.1016/j.ejor.2023.11.016},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {297-307},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Column generation-based prototype learning for optimizing area under the receiver operating characteristic curve},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An expandable machine learning-optimization framework to
sequential decision-making. <em>EJOR</em>, <em>314</em>(1), 280–296. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an integrated prediction-optimization (PredOpt) framework to efficiently solve sequential decision-making problems by predicting the values of binary decision variables in an optimal solution. We address the key issues of sequential dependence, infeasibility, and generalization in machine learning (ML) to make predictions for optimal solutions to combinatorial problems. The sequential nature of the combinatorial optimization problems considered is captured with recurrent neural networks and a sliding-attention window. We integrate an attention-based encoder–decoder neural network architecture with an infeasibility-elimination and generalization framework to learn high-quality feasible solutions to time-dependent optimization problems. In this framework, the required level of predictions is optimized to eliminate the infeasibility of the ML predictions. These predictions are then fixed in mixed-integer programming (MIP) problems to solve them quickly with the aid of a commercial solver. We demonstrate our approach to tackling the two well-known dynamic NP-Hard optimization problems: multi-item capacitated lot-sizing (MCLSP) and multi-dimensional knapsack (MSMK). Our results show that models trained on shorter and smaller-dimensional instances can be successfully used to predict longer and larger-dimensional problems. The solution time can be reduced by three orders of magnitude with an average optimality gap below 0.1%. We compare PredOpt with various specially designed heuristics and show that our framework outperforms them. PredOpt can be advantageous for solving dynamic MIP problems that need to be solved instantly and repetitively.},
  archive      = {J_EJOR},
  author       = {Dogacan Yilmaz and İ. Esra Büyüktahtakın},
  doi          = {10.1016/j.ejor.2023.10.045},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {280-296},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An expandable machine learning-optimization framework to sequential decision-making},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cost-sensitive probabilistic predictions for support vector
machines. <em>EJOR</em>, <em>314</em>(1), 268–279. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machines (SVMs) are widely used and constitute one of the best examined and used machine learning models for two-class classification. Classification in SVM is based on a score procedure, yielding a deterministic classification rule, which can be transformed into a probabilistic rule (as implemented in off-the-shelf SVM libraries), but is not probabilistic in nature. On the other hand, the tuning of the regularization parameters in SVM is known to imply a high computational effort and generates pieces of information that are not fully exploited, not being used to build a probabilistic classification rule. In this paper we propose a novel approach to generate probabilistic outputs for the SVM. The new method has the following three properties. First, it is designed to be cost-sensitive, and thus the different importance of sensitivity (or true positive rate, TPR) and specificity (true negative rate, TNR) is readily accommodated in the model. As a result, the model can deal with imbalanced datasets which are common in operational business problems as churn prediction or credit scoring. Second, the SVM is embedded in an ensemble method to improve its performance, making use of the valuable information generated in the parameters tuning process. Finally, the probabilities estimation is done via bootstrap estimates, avoiding the use of parametric models as competing approaches. Numerical tests on a wide range of datasets show the advantages of our approach over benchmark procedures.},
  archive      = {J_EJOR},
  author       = {Sandra Benítez-Peña and Rafael Blanquero and Emilio Carrizosa and Pepa Ramírez-Cobo},
  doi          = {10.1016/j.ejor.2023.09.027},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {268-279},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cost-sensitive probabilistic predictions for support vector machines},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). What is a decision problem? <em>EJOR</em>, <em>314</em>(1),
255–267. (<a href="https://doi.org/10.1016/j.ejor.2023.10.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a general framework about what is a decision problem. Our motivation is related to the fact that decision analysis and operational research are structured (as disciplines) around classes of methods, while instead we should first characterise the decision problems our clients present us. For this purpose, we define a decision problem as a set partitioning problem and we introduce a new framework, independent from any existing method, based upon primitives provided by (or elicited from) the client and four fundamental problem statements. We show that constructing the set to partition is a decision problem itself and that the types of primitives are finite. The result is that the number of archetypal decision problems are finite and so the archetypal decision support methods.},
  archive      = {J_EJOR},
  author       = {Alberto Colorni and Alexis Tsoukiàs},
  doi          = {10.1016/j.ejor.2023.10.025},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {255-267},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {What is a decision problem?},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Managing conflicting revenue streams from advertisers and
subscribers for online platforms. <em>EJOR</em>, <em>314</em>(1),
241–254. (<a href="https://doi.org/10.1016/j.ejor.2023.10.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a typical ad-supported online video platform with two interacting revenue streams: ad display and ad-free subscription. In practice, ad display and ad-free subscription serve different customers and are typically operated by separate divisions. Within this context, there is clearly a need for the platform to align the decentralized pricing for two interacting services. Motivated by this practical problem, this paper proposes an easy and operable coordination mechanism for the platform to coordinate the division-level pricing to maximize its total revenue. We first model the pricing under both centralized and decentralized settings. The derived equilibrium reveals that, contrary to typical negative relationships between price and demand in one-sided and most two-sided markets, a positive relationship (higher ad-free subscription fees lead to more advertising on the other side) is observed on this platform. If this indirect relationship is ignored, decentralized pricing will always underprice ad-free subscription. We then propose an easy-to-implement coordination mechanism consisting of customer-oriented subsidies and fees for the platform to maximize the total revenue. Our analysis shows the proposed coordination can be self-financed as long as the ad-watching cost is relatively low or the advertiser base is relatively large. These findings not only apply to online video platforms, but to any digital platform generating interacting revenue streams from both sides, such as online gaming platforms.},
  archive      = {J_EJOR},
  author       = {Xin Li and Hari Balasubramanian and Yan Chen and Chuan Pang},
  doi          = {10.1016/j.ejor.2023.10.024},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {241-254},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Managing conflicting revenue streams from advertisers and subscribers for online platforms},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Product innovation in a supply chain with information
asymmetry: Is more private information always worse? <em>EJOR</em>,
<em>314</em>(1), 229–240. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates supply chain innovation under different degrees of information asymmetry. The supplier could be uncertain about either the manufacturer&#39;s production cost or innovation capability, or both, leading to the existence of relatively less or more private information that can distort innovation investment. We find that the effects of different degrees of information asymmetry on supply chain innovation can be complicated. While information asymmetry can often cause underinvestment in innovation, such an underinvestment problem could be substantially mitigated with more private information, and even more so when customer demand is sensitive to price. This counter-intuitive finding can be understood as a consequence of the relatively stronger innovation-motivation motive but weaker profit-extraction motive of the supplier facing more private information. We further examine the effects of CSR undertaking in supply chain, and show that the underinvestment in innovation would still deteriorate with less private information. Thus, one should be cautious towards information sharing schemes that partially reduce information asymmetry of supply chain.},
  archive      = {J_EJOR},
  author       = {Jian Ni and Yue Xu and Jia Shi and Jiali Li},
  doi          = {10.1016/j.ejor.2023.10.023},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {229-240},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Product innovation in a supply chain with information asymmetry: Is more private information always worse?},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Impact of loss aversion on financing mechanism preference
under consignment: Direct vs. guarantee. <em>EJOR</em>, <em>314</em>(1),
206–228. (<a href="https://doi.org/10.1016/j.ejor.2023.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines the impact of loss aversion on the retailer’s financing mechanism preference under the consignment contract in a supply chain consisting of a retailer and a capital-constrained supplier. Both the retailer and the supplier could be loss averse. To help the supplier overcome financial distress, two financing mechanisms are available for the retailer as follows. (1) direct financing (DF): the retailer directly provides loans to the supplier; (2) guarantee financing (GF): the retailer guarantees to repay a certain percentage of the supplier’s outstanding loan to the bank, and thereby the supplier can obtain a loan from the bank. By comparing different financing mechanisms, we show that the retailer always prefers GF over DF once his loss aversion level exceeds a threshold. We find that the differences in cash flows (i.e., losses and gains per period) between mechanisms are the driving force behind the impact of loss aversion in determining the relative preference of the financing mechanisms. More specifically, even when the sum of the losses and gains under DF is greater than that under GF, the absolute magnitude of losses under DF can be significantly greater than that under GF. In equilibrium, we have Furthermore, numerical studies show that the attractiveness of GF for the loss-averse retailer increases with the consignment rate and the production cost, and decreases with the supplier’s working capital. The results provide an explanation for the adoption of GF in practice business and can help managers map financing options to environments where they perform best.},
  archive      = {J_EJOR},
  author       = {Wei Xie and Huilin Yu and Yuanguang Zhong and Yong-Wu Zhou},
  doi          = {10.1016/j.ejor.2023.09.013},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {206-228},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Impact of loss aversion on financing mechanism preference under consignment: Direct vs. guarantee},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Smart home insurance: Collaboration and pricing.
<em>EJOR</em>, <em>314</em>(1), 176–205. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A product marketed as smart home insurance combines home insurance and “smart” home products, at an attractive price, so that customers are better protected from hazards and hence the insurance company suffers fewer losses. Our study analyzes two policies offered by insurers to promote the adoption of smart products: a discount on insurance either with or without offering a free smart product to customers. We examine the insurer’s preferences with regard to these two policies for two types of interactions with the smart product manufacturer (SPM): the no-contract setting and the wholesale-price contract setting. A Nash model allows us to compare the players’ pricing decisions regarding both types of policies and different interactions. For the wholesale-price contract, we find that the insurer always prefers the free smart product policy (the insurer incurs the cost of the smart product). In the no-contract setting, the insurer prefers the free smart product unless the product development cost coefficient is high. We observe that the change in an insurer’s decisions—namely, those that are affected by hazard and customer characteristics—varies with the type of interaction. Finally, when an SPM is the market leader, we find that insurers are indifferent between the two promotional policies because the same profit results in both cases.},
  archive      = {J_EJOR},
  author       = {Debajyoti Biswas and Sara Rezaee Vessal},
  doi          = {10.1016/j.ejor.2023.09.004},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {176-205},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Smart home insurance: Collaboration and pricing},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Capacity planning with uncertainty on contract fulfillment.
<em>EJOR</em>, <em>314</em>(1), 152–175. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the tactical planning problem faced by a shipper which seeks to secure transportation and warehousing capacity, such as containers, vehicles or space in a warehouse, of different sizes, costs, and characteristics, from a carrier or logistics provider, while facing different sources of uncertainty. The uncertainty can be related to the loads to be transported or stored, the cost and availability of ad-hoc capacity on the spot market in the future, and the availability of the contracted capacity in the future when the shipper needs it. This last source of uncertainty on the capacity loss on the contracted capacity is particularly important in both long-haul transportation and urban distribution applications, but no optimization methodology has been proposed so far. We introduce the Stochastic Variable Cost and Size Bin Packing with Capacity Loss problem and model that directly address this issue, together with a metaheuristic to efficiently address it. We perform a set of extensive numerical experiments on instances related to long-haul transportation and urban distribution contexts and derive managerial insights on how such capacity planning should be performed.},
  archive      = {J_EJOR},
  author       = {Teodor Gabriel Crainic and Guido Perboli and Walter Rei and Mariangela Rosano and Veronica Lerma},
  doi          = {10.1016/j.ejor.2023.09.003},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {152-175},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Capacity planning with uncertainty on contract fulfillment},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Logistics mode selection and information sharing in a
cross-border e-commerce supply chain with competition. <em>EJOR</em>,
<em>314</em>(1), 136–151. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting an appropriate logistics mode is crucial for overseas suppliers (OSs) who enter new markets through the cross-border e-commerce platform (CEP), but it is challenging because OSs are unfamiliar with the local markets. Thus motivated, we aim at a supply chain where an OS sells its product through a CEP that holds demand information advantages, and the OS faces competition from the domestic supplier (DS). By constructing a multi-stage game model, we study the OS&#39;s logistics mode selection between direct-mail and bonded-warehouse, which has different logistics costs and inventory risks. Moreover, the influence of the CEP&#39;s information sharing decision on the logistics mode selection is investigated. Our results show that with information sharing, the OS always selects the bonded-warehouse logistics mode; while without information sharing, the OS makes a choice between direct-mail and bonded-warehouse mode according to the tax rate and market fluctuation. Particularly, under a high tax rate, with the increase in market fluctuation, the uninformed OS not only needs to adjust the logistics mode choice but also change the inventory strategy. We also reveal that information sharing could lead to the OS changing the logistics mode from direct-mail to bonded-warehouse, and then cause fierce competition between the OS and DS. Therefore, sharing information does not always benefit the CEP. Under certain conditions, it is more beneficial for the OS to choose the direct-mail mode when the information is shared, as doing so can help chain members escape the prisoner&#39;s dilemma and thus lead to a “win-win-win” outcome.},
  archive      = {J_EJOR},
  author       = {Xumei Zhang and Xiaoyu Zha and Bin Dan and Yi Liu and Ronghua Sui},
  doi          = {10.1016/j.ejor.2023.08.058},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {136-151},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Logistics mode selection and information sharing in a cross-border e-commerce supply chain with competition},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How can suppliers strategically involve downstream
manufacturers in research and development collaboration? A knowledge
spillover perspective. <em>EJOR</em>, <em>314</em>(1), 122–135. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Innovation collaboration has become increasingly important for supply chain partners. In this study, we examine the impact of innovation collaboration on supply chain partners, specifically focusing on how suppliers can design strategies to motivate downstream buyers to engage in cost-reduction research and development (R&amp;D) activities. We present a scenario in which two downstream manufacturers purchase identical parts from a shared supplier and compete on the end market while individually investing in R&amp;D. Our findings indicate that the manufacturers may be less inclined to invest in R&amp;D due to knowledge spillover effects, which can reduce their order quantities from the supplier. To address this issue, we propose that the supplier become involved in the R&amp;D through a cost-sharing agreement, aligning the incentives of all supply chain partners and internalizing both supply chain and knowledge externalities. Our results suggest that this approach allows the supplier to share R&amp;D costs with the manufacturers while ensuring that the manufacturers are not worse off in a supply chain collaboration scenario compared to other scenarios. We also recommend that the supplier involve downstream manufacturers with perfect spillovers.},
  archive      = {J_EJOR},
  author       = {Jinyu Yang and Wenqing Zhang and Xiande Zhao},
  doi          = {10.1016/j.ejor.2023.08.057},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {122-135},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {How can suppliers strategically involve downstream manufacturers in research and development collaboration? a knowledge spillover perspective},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the update frequency of univariate forecasting models.
<em>EJOR</em>, <em>314</em>(1), 111–121. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In univariate time series forecasting, models are typically updated at every single review period. This practice, which includes specifying the optimal form of the model and estimating its parameters, theoretically allows the models to exploit new information and to respond quickly to possible structural breaks. We argue that such updates may be irrelevant in practice, also unnecessarily increasing computational cost and forecast instability. Using two large data sets of monthly and daily series as well as an indicative family of conventional time series models, we investigate several model updating scenarios, ranging from complete model form specification and parameter estimation at every review period to no updating at all. We find that intermediate updating scenarios, including the re-estimation of specific parameters but not necessarily the specification of the model form, can result in similar or even better accuracy with significantly lower computational cost. We also show that similar conclusions hold true for popular machine learning methods, as well as for setups where different approaches are utilized for training the models or accelerating their specification and estimation. We discuss the implications of our findings for manufacturers, suppliers, and retailers and propose avenues for future advances in the area of model frequency updating.},
  archive      = {J_EJOR},
  author       = {Evangelos Spiliotis and Fotios Petropoulos},
  doi          = {10.1016/j.ejor.2023.08.056},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {111-121},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the update frequency of univariate forecasting models},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual sourcing under non-stationary demand and partial
observability. <em>EJOR</em>, <em>314</em>(1), 94–110. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study dual sourcing under stochastic and non-stationary demand. The non-stationarity is modeled through Markov-modulated changes in the underlying demand distribution. The actual demand distribution is not observed directly, yet demand observations reveal partial information about it. We propose a policy where a pre-committed base order from the slow source is complemented with flexible short-term orders from both the fast and slow source. The pre-committed order is cheaper, while flexible orders can be adjusted to the actual inventory needs and the non-stationary demand. By formulating the problem as a partially observable Markov decision process, we show that the optimal flexible orders follow an adaptive dual base-stock policy when the lead time difference between both sources is one period. A numerical validation study reveals how flexible slow source orders reduce the share of expensive orders from the fast source compared to a conventional tailored base-surge policy. In addition, our policy’s ability to adapt decisions to partial information allows for a more effective use of flexible orders. Our findings show the value of incorporating partial information to deal with the non-stationary demand and adding the flexible slow-sourcing option to create a more resilient replenishment policy.},
  archive      = {J_EJOR},
  author       = {Hannah Yee and Heletjé E. van Staden and Robert N. Boute},
  doi          = {10.1016/j.ejor.2023.09.033},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {94-110},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dual sourcing under non-stationary demand and partial observability},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient solution approaches for the bi-criteria p-hub
median and dispersion problem. <em>EJOR</em>, <em>314</em>(1), 79–93.
(<a href="https://doi.org/10.1016/j.ejor.2023.09.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the bi-criteria p p -hub median and dispersion problem, that arises in the design of hub networks where the dispersion of hubs is desired to mitigate the risk of disruptions. The problem is formulated as a bi-objective mixed integer program, where the first objective is to minimize the total cost of routing the flows through p p hubs and the second objective is to maximize the minimum distance (or dispersion) among the selected p p hub locations themselves. We present two exact solution approaches that guaranteed to obtain the entire non-dominated Pareto frontier. The first is a cutting plane method in which a p p -hub median problem with a particular dispersion distance is solved at each iteration. Three formulations of the problem, based on the different type of cuts and preprocessing, are presented. We study the dominance relationship among the three formulations. Through computational experiments, we show that the proposed cutting plane method is efficient in solving medium size instances of the problem and our strongest formulation is at least 40% computationally faster than the others. For solving large instances of the problem, we present a decomposition method where the p p -hub median problem with dispersion distance is solved using an accelerated Benders decomposition approach. We present several problem specific enhancements to the algorithm such as starting with a better solution, efficient ways of solving decomposed subproblem and adding Pareto optimal Benders cuts to the master problem. The computational results on the Turkish network (TR81), US423, and Australian Post (AP) dataset show that the cutting plane algorithm with the proposed decomposition procedure is three to four times faster than the commercial solver.},
  archive      = {J_EJOR},
  author       = {Prasanna Ramamoorthy and Navneet Vidyarthi and Manish Verma},
  doi          = {10.1016/j.ejor.2023.09.032},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {79-93},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Efficient solution approaches for the bi-criteria p-hub median and dispersion problem},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-attribute two-echelon location routing: Formulation
and dynamic discretization discovery approach. <em>EJOR</em>,
<em>314</em>(1), 66–78. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the two-echelon location-routing system under tight synchronization constraints, in addition to several other interacting attributes. Prompted, in particular, by city-logistics applications, the system we address concerns a two-echelon distribution layout composed of a set of platform facilities and a set of intermediate satellite facilities to deliver freight from supply zones outside the city to customers within. The problem setting includes time-dependent multicommodity demand, time windows, lack of storage capacity at intermediate facilities, and synchronization at these facilities of the fleets operating on different echelons. The problem requires the selection of facilities at both levels, the allocation of suppliers to platforms and of customers to satellites, and the routing and scheduling of vehicles at each echelon, in order to deliver the freight from platforms to customers, through the satellites. The lack of storage capacity of the shared facilities, the satellites, requires tight scheduling of the vehicle routes and demand itineraries, i.e., departure times from the platforms and satellites, and the synchronization of vehicle routes at satellites for efficient transshipment operations. We introduce the problem setting, present a mixed-integer programming formulation, and a dynamic discretization discovery-based exact solution method for the problem. We perform thorough analyses to assess the impact of the problem attributes and requirements on the system behaviour and algorithm performance.},
  archive      = {J_EJOR},
  author       = {David Escobar-Vargas and Teodor Gabriel Crainic},
  doi          = {10.1016/j.ejor.2023.09.031},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {66-78},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-attribute two-echelon location routing: Formulation and dynamic discretization discovery approach},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New formulations for two location problems with
interconnected facilities. <em>EJOR</em>, <em>314</em>(1), 51–65. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies two location problems with interconnected facilities. In the first problem, all customers need to be served by open facilities, and in the second (covering) variant a penalty is imposed for customers that cannot receive the service. Compared to the standard facility location setting, an additional constraint is imposed asking that all open facilities are interconnected, i.e., all open facilities need to be within a given radius of each other. These problems combine classical facility location aspects with network design, and we exploit this link to derive new mixed integer programming models. The strength of these models is investigated both theoretically and empirically. An extensive computational study is conducted on a set of benchmark instances from the literature, in which branch-and-cut, Benders decomposition and compact models are assessed in terms of the runtime and the resulting gaps.},
  archive      = {J_EJOR},
  author       = {Yerlan Kuzbakov and Ivana Ljubić},
  doi          = {10.1016/j.ejor.2023.09.030},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {51-65},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {New formulations for two location problems with interconnected facilities},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Competitive integrated airline schedule design and fleet
assignment. <em>EJOR</em>, <em>314</em>(1), 32–50. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Airline profits are significantly influenced by competitive timetables that match passenger demand to fleet resources. In this research, we develop an integrated, mixed-integer optimization model to derive a comprehensive flight schedule, fleet assignment, and average airfares jointly. Passenger choice behavior is incorporated through a prospect theory-adjusted, nested, multinomial logit model which estimates market share. The competitive fleet assignment and schedule design (CFSD) formulation is embedded in a differentiated Bertrand game, such that each transport operator optimizes their best response function connected through the market share model. To solve the integrated optimization problem efficiently, a hybrid algorithm is developed that combines stabilized column generation with a large neighborhood search algorithm. The game-theoretic framework is applied to a case study in China involving legacy airlines, a low-cost carrier, and a high-speed rail (HSR) operator. The equilibrium outcomes suggest that the low-cost carrier is likely to stimulate demand and improve the level of service through secondary airports. The further development of high-speed rail service is expected to intensify competition among airlines and reduce the overall fare level. The low-cost carriers and HSR are able to significantly increase overall consumer surplus, providing insights into the potential for low-cost service in the Chinese aviation markets and the entrance of the public service obligation program at minimum cost.},
  archive      = {J_EJOR},
  author       = {Yifan Xu and Nicole Adler and Sebastian Wandelt and Xiaoqian Sun},
  doi          = {10.1016/j.ejor.2023.09.029},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {32-50},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Competitive integrated airline schedule design and fleet assignment},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Technician routing and scheduling for the sharing economy.
<em>EJOR</em>, <em>314</em>(1), 15–31. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient routing and scheduling plans for a modern workforce are challenging to develop for many firms offering services to customers at their home. In this paper, we focus on those firms that provide technical or maintenance related assistance using heterogeneously skilled technicians working in the sharing economy. We present a model that minimizes the costs of routing and scheduling these technicians, operating out of their own homes, serving a set of customers with demand for a variety of tasks revealed on a daily basis over a multi-period planning horizon. We construct this dynamic, stochastic problem as a Markov decision process and introduce a heuristic that takes advantage of problem characteristics to provide solutions efficiently. This heuristic simplifies the model by reducing the goal function and incorporating an approximation for routing cost, effectively and efficiently solving real world sized problems. We use the heuristic to provide insight into managerial decisions associated with managing a team of technicians, showing that the benefit of cross-training technicians has limitations and that in most circumstances it is more efficient to use technicians with focused areas of expertise.},
  archive      = {J_EJOR},
  author       = {Maciek Nowak and Przemysław Szufel},
  doi          = {10.1016/j.ejor.2023.09.023},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {15-31},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Technician routing and scheduling for the sharing economy},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimization with constraint learning: A framework and
survey. <em>EJOR</em>, <em>314</em>(1), 1–14. (<a
href="https://doi.org/10.1016/j.ejor.2023.04.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-life optimization problems frequently contain one or more constraints or objectives for which there are no explicit formulae. If however data on feasible and/or infeasible states are available, these data can be used to learn the constraints. The benefits of this approach are clearly seen, however, there is a need for this process to be carried out in a structured manner. This paper, therefore, provides a framework for Optimization with Constraint Learning (OCL) which we believe will help to formalize and direct the process of learning constraints from data. This framework includes the following steps: (i) setup of the conceptual optimization model, (ii) data gathering and preprocessing, (iii) selection and training of predictive models, (iv) resolution of the optimization model, and (v) verification and improvement of the optimization model. We then review the recent OCL literature in light of this framework and highlight current trends, as well as areas for future research.},
  archive      = {J_EJOR},
  author       = {Adejuyigbe O. Fajemisin and Donato Maragno and Dick den Hertog},
  doi          = {10.1016/j.ejor.2023.04.041},
  journal      = {European Journal of Operational Research},
  month        = {4},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimization with constraint learning: A framework and survey},
  volume       = {314},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the paper “augmented lagrangian algorithms for solving
the continuous nonlinear resource allocation problem.” <em>EJOR</em>,
<em>313</em>(3), 1217–1222. (<a
href="https://doi.org/10.1016/j.ejor.2023.11.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the paper Torrealba et al. (2021) an augmented Lagrangian algorithm was proposed for resource allocation problems with the intriguing characteristic that instead of solving the box-constrained augmented Lagrangian subproblem, they propose projecting the solution of the unconstrained subproblem onto such box. A global convergence result for the quadratic case was provided, however, this is somewhat counterintuitive, as in usual augmented Lagrangian theory, this strategy can fail in solving the augmented Lagrangian subproblems. In this note we investigate further this algorithm and we show that the proposed method may indeed fail when the Hessian of the quadratic is not a multiple of the identity. In the paper, it is not clear enough that two different projections are being used: one for obtaining their convergence results and other in their implementation. However, despite the lack of theoretical convergence, their strategy works remarkably well in some classes of problems; thus, we propose a hybrid method which uses their idea as a starting point heuristics, switching to a standard augmented Lagrangian method under certain conditions. Our contribution consists in presenting an efficient way of determining when the heuristics is failing to improve the KKT residual of the problem, suggesting that the heuristic procedure should be abandoned. Numerical results are provided showing that this strategy is successful in accelerating the standard method.},
  archive      = {J_EJOR},
  author       = {L.F. Bueno and G. Haeser and O. Kolossoski},
  doi          = {10.1016/j.ejor.2023.11.001},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {1217-1222},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the paper “Augmented lagrangian algorithms for solving the continuous nonlinear resource allocation problem”},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Payment schemes for sustaining cooperation in dynamic games
played over event trees. <em>EJOR</em>, <em>313</em>(3), 1200–1216. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose two payment schemes to sustain cooperation in the class of dynamic games played over event trees, where the transition between nodes is determined by Nature. The planning horizon is given and finite, but the game can terminate at any intermediate stage. The two payment schemes share some desirable properties, e.g., dynamic individual rationality, stability against deviation along the cooperative state trajectory, and efficiency, but differ in some other features. We illustrate the construction of two payment schemes with an example in environmental economics.},
  archive      = {J_EJOR},
  author       = {Elena M. Parilina and Georges Zaccour},
  doi          = {10.1016/j.ejor.2023.10.016},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {1200-1216},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Payment schemes for sustaining cooperation in dynamic games played over event trees},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The collective security dilemma of preemptive strikes.
<em>EJOR</em>, <em>313</em>(3), 1191–1199. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Players who are targets of potential raids can sometimes preempt some of these raids and neutralize the raiders. These threatened players have different values to the attackers as raid targets, and they act independently of each other and sometimes sequentially. The order in which the threatened players make their neutralization decisions turns out to be critical to the number of raids and the resulting probability of being attacked. The lowest number of raids results when the threatened players act in ascending order of attractiveness as targets for preemptive strikes. The analysis characterizes game-theoretic equilibrium as a function of action sequencing. It also discusses variations in the game situation, such as if the same threatened player can make multiple preemptive strikes, or if threatened players all act simultaneously rather than in a sequential order. The results are relevant in many contexts, including cybercrime, military threats from revisionist states, international terrorism, sabotage among employees in firms and other organizations, and defense of corporations against hostile takeover attempts.},
  archive      = {J_EJOR},
  author       = {Kai A. Konrad},
  doi          = {10.1016/j.ejor.2023.10.010},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {1191-1199},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The collective security dilemma of preemptive strikes},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Do you want to know a secret? Strategic alliances and
competition in product markets. <em>EJOR</em>, <em>313</em>(3),
1180–1190. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strategic alliances make firms’ boundaries permeable to information leakages that may benefit the competitive position of partnering firms. In this paper, we examine the implications of information leakage on the incentives to join a strategic alliance and the nature of competition in the product market. We show that information leakage can trigger opportunistic behaviours in which firms engage in unprofitable alliances simply because the possibility of learning sensitive information about their competitors increases the expected private rents that firms earn when competing in the product market. Thus, our findings uncover a purely informational mechanism through which information leakage affects the incentives to join a strategic alliance that does not rely on the firm’s ability to absorb spillovers from other firms. We also show that the incentives to devise alliances to gain access to the partner’s sensitive private information may remain even if the negatively affected firm can pursue compensation for the damage that this deceptive business practice may cause.},
  archive      = {J_EJOR},
  author       = {Cristián Troncoso-Valverde and Felipe Chávez-Bustamante},
  doi          = {10.1016/j.ejor.2023.10.004},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {1180-1190},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Do you want to know a secret? strategic alliances and competition in product markets},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparing eco-efficiency with productive efficiency:
Addressing the dimensionality issue. <em>EJOR</em>, <em>313</em>(3),
1170–1179. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One important strategic question in sustainable operations is how explicitly internalizing the societal impact of undesirable outputs (UO) would affect a company&#39;s relative competitiveness: the discrepancy between eco-efficiency and productive efficiency. This paper presents a DEA approach to evaluating the impact of considering UO on productive efficiency. The main challenge to be overcome is that the two models have different dimensionalities: the eco-efficiency model additionally considers UO and thus is endowed with higher dimensionality. Prior research suggested that the added dimensionality alone can inflate the overall efficiency score. Thus, comparing the eco-efficiency directly with productive efficiency scores would create biased results. Moreover, the model should allow a firm&#39;s eco-efficiency to be higher or lower than its productive efficiency, depending on its relative UO performance. This paper proposes an approach to addressing these issues. More generally, our approach applies to studies that compare efficiency scores from models with different dimensions. We included several numerical examples for illustration.},
  archive      = {J_EJOR},
  author       = {Chien-Ming Chen and Hui Wang},
  doi          = {10.1016/j.ejor.2023.09.001},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {1170-1179},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Comparing eco-efficiency with productive efficiency: Addressing the dimensionality issue},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Formulation and solution technique for agricultural waste
collection and transport network design. <em>EJOR</em>, <em>313</em>(3),
1152–1169. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agricultural waste management in developing countries has become a challenging issue for rural planners due to the lack of an efficient planning tool. In the countries, farmers burnt agricultural waste at fields after each harvesting season to solve the issue. As a result, it has caused air and water pollution in the rural areas of the countries. In this paper, we present a mixed-integer nonlinear programming model for agricultural waste collection and transport network design that aims to stop burning waste and use the waste to produce bio-organic fertilizer. The model supports rural planners to optimally locate waste storages, and to determine the optimal set of routes for a fleet of vehicles to collect and transport the waste from the storages to the bio-organic fertilizer production facility. In the novel location-assignment-routing problem, the overall objective is to minimize total cost of locating storages, collecting waste from fields and planning vehicle routes. A solution technique is developed to linearise the mixed-integer nonlinear programming model into a model in linear form. In addition, a parallel water flow algorithm is developed to solve efficiently the large-sized instances. The efficiency of the proposed model and algorithm is validated and evaluated on the real case study in Trieu Phong district, Quang Tri province, Vietnam, as well as a set of randomly generated large-sized instances. The results show that our solution approach outperforms the general optimisation solver and tabu search algorithm. Our algorithm can find the optimal or near-optimal solutions for the large-sized instances within a reasonable time.},
  archive      = {J_EJOR},
  author       = {Trung Hieu Tran and Thu Ba T. Nguyen and Hoa Sen T. Le and Duc Chinh Phung},
  doi          = {10.1016/j.ejor.2023.08.052},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {1152-1169},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Formulation and solution technique for agricultural waste collection and transport network design},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pump scheduling optimization in water distribution system
based on mixed integer linear programming. <em>EJOR</em>,
<em>313</em>(3), 1140–1151. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The energy consumption in water distribution systems (WDSs) is significant. Improving the efficiency of pump operation can significantly reduce energy costs. However, optimal pump operation is a nonconvex mixed-integer nonlinear programming (MINLP) problem, which can be challenging to solve. A feasible approach is to linearize the problem and convert it into a mixed-integer linear programming (MILP) problem. However, this approach introduces many auxiliary variables, which can lead to inefficiency in finding the optimal solution due to the expanded search space. To address this issue, we propose a novel method for linearization of the original MINLP problem and a strategy that can adaptively adjust the number of piecewise linearization breakpoints. By reducing the number of auxiliary variables, our approach achieved competitive computing efficiency and the ability to save energy costs, as demonstrated in two benchmark instances. Furthermore, in a realistic large-scale WDS, our approach saved 9.83% more energy costs than the genetic algorithm and achieved a gap of only 7.36% from the lower bound.},
  archive      = {J_EJOR},
  author       = {Yu Shao and Xinhong Zhou and Tingchao Yu and Tuqiao Zhang and Shipeng Chu},
  doi          = {10.1016/j.ejor.2023.08.055},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {1140-1151},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pump scheduling optimization in water distribution system based on mixed integer linear programming},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On solving robust log-optimal portfolio: A supporting
hyperplane approximation approach. <em>EJOR</em>, <em>313</em>(3),
1129–1139. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A log-optimal portfolio is any portfolio that maximizes the expected logarithmic growth (ELG) of an investor’s wealth, which typically assumes prior knowledge of the true return distribution. However, in practice, return distributions are often ambiguous ; i.e., the true distribution is unknown, making this problem challenging to solve. This paper proposes a supporting hyperplane approximation approach, reformulating a class of distributional robust log-optimal portfolio problems with polyhedron ambiguity sets into tractable robust linear programs. An efficient algorithm is presented to determine the optimal number of hyperplanes. Additionally, to adapt to the constantly changing market, we propose an online trading algorithm using a sliding window approach to solve a sequence of robust linear programs, offering significant computational advantages. The effectiveness of the proposed approach is supported by empirical studies using historical stock price data.},
  archive      = {J_EJOR},
  author       = {Chung-Han Hsieh},
  doi          = {10.1016/j.ejor.2023.09.040},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {1129-1139},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On solving robust log-optimal portfolio: A supporting hyperplane approximation approach},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A single-stage optimization procedure for data envelopment
analysis. <em>EJOR</em>, <em>313</em>(3), 1119–1128. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data envelopment analysis, a conventional procedure for testing efficiency of decision making units (DMUs) consists of two stages, each requiring solution of a linear program. The first stage identifies the input or output radial efficiency of a DMU, and the second stage maximizes the sum of component input and output slacks. A traditional alternative is the single-stage approximation of the two-stage procedure in which the objective functions of the first and second stages are combined, with the latter multiplied by a small positive constant epsilon. A known drawback of such approach is that very small values of epsilon may cause computational inaccuracies and large values do not allow a good approximation. In this paper, we develop a new single-stage linear programming approach that does not require the specification of a small constant epsilon and is completely equivalent to the conventional two-stage solution procedure. It produces exactly the same sets of primal and dual optimal solutions as the two separate stages of the two-stage approach. The new single-stage procedure is applicable to any convex polyhedral technology.},
  archive      = {J_EJOR},
  author       = {Grammatoula Papaioannou and Victor V. Podinovski},
  doi          = {10.1016/j.ejor.2023.09.036},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {1119-1128},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A single-stage optimization procedure for data envelopment analysis},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data sharing between platform and seller: An analysis of
contracts, privacy, and regulation. <em>EJOR</em>, <em>313</em>(3),
1105–1118. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online platforms share their customers’ data with their upstream sellers, which is utilized by the sellers to gain better insights about the customers. This may help sellers to develop a product that would provide higher value to the customers. However, such data sharing among the firms causes privacy concerns among customers. In this paper, we study a game-theoretic model with an online platform (or buyer), seller, and customers facing privacy concerns. We study scenarios where the platform, the seller, and the customers may decide the extent of data to be shared by the platform with the seller under different models, such as marketplace and reselling models. Later, we also analyze the regulation of data sharing by the social planner. Our analysis characterizes the equilibrium data sharing and quality decisions, leading to intriguing findings. Specifically, under the marketplace model, the regulation of data sharing can result in either an increase or a decrease in the extent of data shared by the platform. Furthermore, compared to the scenario where a platform decides the extent of data sharing, the regulation of data sharing proves advantageous for seller and customers while being less beneficial for the platform itself. Interestingly, in the context of reselling model, we find that the regulation of data sharing does not influence the extent of data shared or the players’ payoffs compared to unregulated scenarios.},
  archive      = {J_EJOR},
  author       = {Ayesha Arora and Tarun Jain},
  doi          = {10.1016/j.ejor.2023.09.035},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {1105-1118},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Data sharing between platform and seller: An analysis of contracts, privacy, and regulation},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stop clicking around and book direct: Impact of best rate
guarantee on hotel pricing. <em>EJOR</em>, <em>313</em>(3), 1088–1104.
(<a href="https://doi.org/10.1016/j.ejor.2023.09.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hotel chains sell their rooms through both their own distribution channels and third-party online travel agencies (OTAs). However, with the growing popularity of OTAs over the last decade, major hotel chains have started to fight against OTAs for control and market share by offering Best Rate Guarantee (BRG) in an attempt to incentivize customers to bypass OTAs and book directly with the hotels. BRG ensures that guests who book direct will get the best price. We study a stylized model where a hotelier that works closely with an OTA offers BRG to its customers to maximize its revenue over a selling horizon. Motivated by common practices in the hotel industry, we model the hotelier-OTA decision making process as a sequential game. We focus on the case where there is a sufficient inventory, derive closed-form optimal solutions for the problem, prove some structural properties, and identify necessary and sufficient conditions under which offering BRG always benefits the hotel (resp. the OTA). While in general BRG makes the hotelier better off and the OTA worse off, we show that when the commission rate is high, BRG can make both channels better off. On the other hand, when the commission rate and the fraction of swing customers who claim BRG are both low, BRG can make both channels worse off. We also consider the case with a limited inventory in the appendix and derive various managerial insights regarding the impact of BRG through computational tests. Our findings will shed some lights for hotel managers when deciding whether to practice BRG and what relevant actions to take when BRG is practiced.},
  archive      = {J_EJOR},
  author       = {Ming Chen and Zhi-Long Chen},
  doi          = {10.1016/j.ejor.2023.09.025},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {1088-1104},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stop clicking around and book direct: Impact of best rate guarantee on hotel pricing},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The role of completely joint liability in financing multiple
capital-constrained firms: Risk sharing, inventory and financial
strategies. <em>EJOR</em>, <em>313</em>(3), 1072–1087. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper makes an attempt to explore the relative value of a completely joint liability (CJL) financing scheme over traditional individual financing scheme for two financially-constrained firms. We develop a risk-sharing non-cooperative Nash-game model for the two firms in which they make unilateral ordering and financial decisions based on the CJL financing agreement as to the additional benefit (i.e., unit financing cost reduction) because of joint liability. We prove the existence of the firms’ equilibrium inventory decisions in a Nash game that is in general not quasi-concave or even supermodular. We show that in equilibrium, the completely joint liability of CJL financing induces the two firms to order more (compared to individual financing case), and meanwhile, the firms become more aggressive in ordering as the shared risk goes up. However, such over-investment in ordering under CJL financing does not always result in higher bankruptcy risks for the firms. Importantly, we show that the choice of the proposed financing schemes for both the firms is completely determined by a simple two-threshold policy in terms of the firms’ initial capitals and loan terms, and provide insights on how a financing-need firm to select proper partners to use CJL financing together, and how a profit-seeking bank to strategically set the proper financing terms to make the CJL financing scheme generate more benefits to itself and the two firms simultaneously (i.e., “win-win-win” situation).},
  archive      = {J_EJOR},
  author       = {Bin Cao and Yuanguang Zhong and Yong-Wu Zhou},
  doi          = {10.1016/j.ejor.2023.08.047},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {1072-1087},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The role of completely joint liability in financing multiple capital-constrained firms: Risk sharing, inventory and financial strategies},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving the unit-load pre-marshalling problem in block
stacking storage systems with multiple access directions. <em>EJOR</em>,
<em>313</em>(3), 1054–1071. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Block stacking storage systems are highly adaptable warehouse systems with low investment costs. With multiple, deep lanes they can achieve high storage densities, but accessing some unit loads can be time-consuming. The unit-load pre-marshalling problem sorts the unit loads in a block stacking storage system in off-peak time periods to prepare for upcoming orders. The goal is to find a minimum number of unit-load moves needed to sequence a storage bay in ascending order based on the retrieval priority group of each unit load. In this paper, we present two solution approaches for determining the minimum number of unit-load moves. We show that for storage bays with one access direction, it is possible to adapt existing, exact tree search procedures and lower bound heuristics from the container pre-marshalling problem. For multiple access directions, we develop a novel, two-step solution approach based on a network flow model and an A* algorithm with an adapted lower bound that is applicable for all possible access direction combinations. We further analyze the performance of the presented solutions in computational experiments for randomly generated problem instances and show that multiple access directions greatly reduce both the total access time of unit loads and the required sorting effort.},
  archive      = {J_EJOR},
  author       = {Jakob Pfrommer and Anne Meyer and Kevin Tierney},
  doi          = {10.1016/j.ejor.2023.08.044},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {1054-1071},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solving the unit-load pre-marshalling problem in block stacking storage systems with multiple access directions},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Value of screening in procurement mechanism: An experimental
study. <em>EJOR</em>, <em>313</em>(3), 1031–1053. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Procurement mechanisms are widely employed and recommended for use in supply chain management practices. This study examines a retailer’s decision to design a separating mechanism (as opposed to pooling mechanism) which is applied when buying from a supplier whose production cost information is private. The retailer’s decision is based on the value of screening of the separating mechanism, as it allows the retailer to screen the supplier’s private cost information, whereas the pooling mechanism does not. We conducted a laboratory experiment to investigate the retailer’s decision-making behaviors, the supplier’s decision behaviors, and the value of screening. We found that the observed value of screening is negligible and significantly lower than predicted given a large market size; however, it is substantially higher than predicted given a medium market size. According to the behavioral model analysis, this effect is mainly caused by the supplier’s fairness concerns; the screening increases the supplier’s fairness concern when operating in a large market, but decreases it when operating in a medium sized market. The results imply that a retailer should use a separating mechanism if the screening reduces the supplier’s fairness concern; otherwise, a pooling mechanism suffices.},
  archive      = {J_EJOR},
  author       = {Zewu Jiang and Wanshan Zhu and Yang Zhang and Xiaobo Zhao and Jinxing Xie},
  doi          = {10.1016/j.ejor.2023.08.049},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {1031-1053},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Value of screening in procurement mechanism: An experimental study},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new upper bound based on dantzig-wolfe decomposition to
maximize the stability radius of a simple assembly line under
uncertainty. <em>EJOR</em>, <em>313</em>(3), 1015–1030. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a new upper bounding approach, based on Dantzig-Wolfe decomposition and column generation, for a relatively novel problem of designing simple assembly lines to maximize their stability radius under uncertainty in task processing times. The problem considers task precedence constraints, a fixed cycle time, and a fixed number of workstations. This NP-hard optimization problem aims to assign a given set of assembly tasks to workstations in order to find the most robust feasible line configuration. The robustness of the configuration is measured by the stability radius with respect to its feasibility, i.e. , the maximum increase in task processing times, for which the cycle time constraint remains satisfied. The reformulation resulting from the Dantzig-Wolfe decomposition is enhanced with valid inequalities and tight assignment intervals are used to reduce the solution space of pricing sub-problems. In addition, a bisection method is proposed as a pre-processing technique to improve the initial upper bound on the stability radius, which is an input for the pricing sub-problem. Computational experiments show that the proposed approach can significantly improve the upper bound on the stability radius for the most challenging instances.},
  archive      = {J_EJOR},
  author       = {Rui S. Shibasaki and André Rossi and Evgeny Gurevsky},
  doi          = {10.1016/j.ejor.2023.08.046},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {1015-1030},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new upper bound based on dantzig-wolfe decomposition to maximize the stability radius of a simple assembly line under uncertainty},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New benchmark instances for the inventory routing problem.
<em>EJOR</em>, <em>313</em>(3), 992–1014. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing sets of benchmark instances for the inventory routing problem (IRP) have been beneficial for investigating and illustrating the properties of the problem. However, they possess certain features and design choices that are not necessarily representative of all real-world IRPs. Therefore, we propose a new collection of 270 real-world-like instances ranging from 10 to 200 customers. These instances vary in terms of the number of vehicles and their capacity, the length of the planning horizon, the demand structure, and the geographical distribution of customers. Transportation and inventory holding costs resemble costs found in practice. We present an instance space analysis showing that the new instances nicely complement the original instances. To derive lower and upper bounds for each instance, we present computational experiments with two high-quality solution methods: a matheuristic and an exact branch-and-cut method. The results confirm that the new set of instances is hard to solve with the proposed methods, and they demonstrate the need for developing new solution methods.},
  archive      = {J_EJOR},
  author       = {Jørgen Skålnes and Mohamed Ben Ahmed and Lars Magnus Hvattum and Magnus Stålhane},
  doi          = {10.1016/j.ejor.2023.08.010},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {992-1014},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {New benchmark instances for the inventory routing problem},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning and forgetting interactions within a collaborative
human-centric manufacturing network. <em>EJOR</em>, <em>313</em>(3),
977–991. (<a href="https://doi.org/10.1016/j.ejor.2023.09.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning and forgetting (LaF) phenomena are characteristic of labor-intensive production and service industries. To mitigate the effects of LaF in a human-centric manufacturing system integrated with outsourcing, managers need to coordinate their decisions with partners for assigning operations and scheduling processes following a hierarchy. A model that addresses this should consider the expected latency of various tasks across assignments and production sequences and similarities among jobs as that affects learning. This paper develops a novel bi-level LaF model to help determine the leader-follower decisions in a decentralized network. It models the learning concept as a factor of task execution order and task variety. The mixed-integer non-linear optimization model determines the best order coordination and scheduling scheme by minimizing the processing, operating, and holding costs and penalties for missing deadlines. This study also develops an efficient column-and-constraint generation algorithm based on the duplication method, which enables solving bi-level models in which the lower-level model includes integer variables. This study also provides an illustrative real-sized example to validate the model and prove the efficiency of our resolution method. The results indicate that adopting compromise solutions enables preoccupied workers to be released earlier than expected, reducing the costs associated with learning and forgetting (due to latency). Despite the effects of LaF and the decentralized structure of the supply chain, which includes rising network costs, the schedules become more precise, and the cost balance among actors effectively increases.},
  archive      = {J_EJOR},
  author       = {M. Asghari and H. Afshari and M.Y. Jaber and C. Searcy},
  doi          = {10.1016/j.ejor.2023.09.020},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {977-991},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Learning and forgetting interactions within a collaborative human-centric manufacturing network},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Just-in-time scheduling problem with affine idleness cost.
<em>EJOR</em>, <em>313</em>(3), 954–976. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a single-machine scheduling problem which minimizes total earliness, tardiness and idleness costs. In this problem, n jobs with job-specific due dates and processing times need to be processed in a non-preemptive fashion. We assume that when the idle time between two jobs is strictly positive, an idleness cost will be generated which is affine in the idle time. A hybrid solution approach is designed by integrating a tailored dynamic programming (TDP) algorithm for the exact timing solution and a customized Genetic Algorithm with restarts and early discarding (GARED) as the sequencing heuristic. By bounding the number of segments of the optimal cost function, we show that the proposed TDP algorithm has a low time complexity of O ( n 2 ) O(n2) despite the non-convexity of the idleness cost function. In GARED, we utilize the monotonicity in the optimal cost in TDP to design a fast-screening scheme called Early Discarding which identifies and abandons an unpromising sequencing solution by evaluating only a short starting sub-sequence. Restarts are allowed to make the algorithm more robust in the case of premature local convergence of one evolutionary trial. Experimental results show that GARED significantly outperforms the basic elitist GA with or without restarts under most problems tested. Our hybrid method also scales well to large problem instances with n = 300 n=300 and achieves similar or better performance compared to an exact algorithm in the literature, but the latter only applies to problems with integer-valued time parameters and no idleness cost in between the jobs.},
  archive      = {J_EJOR},
  author       = {Zhen Tan and Guanqi Fu},
  doi          = {10.1016/j.ejor.2023.08.038},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {954-976},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Just-in-time scheduling problem with affine idleness cost},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A huff-like location model with quality adjustment and/or
closing of existing facilities. <em>EJOR</em>, <em>313</em>(3), 937–953.
(<a href="https://doi.org/10.1016/j.ejor.2023.08.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of an expanding chain in a given area is considered. It may locate a new facility, vary the quality of its existing facilities, close some of them, or a combination of all these possibilities, whatever is the best to maximize its profit, given a budget for the expansion. A new competitive location and design model is proposed that allows all these possibilities. The resulting model is a difficult to solve MINLP problem. A branch-and-bound method based on interval analysis is proposed to cope with it. The method can solve medium-size problems in a reasonable amount of CPU time. An ad-hoc heuristic and a hybrid method that usually find a near-optimal solution in a fraction of time of the exact method are also proposed. Some computational studies are presented to show the performance of the algorithms.},
  archive      = {J_EJOR},
  author       = {Boglárka G．-Tóth and Laura Anton-Sanchez and José Fernández},
  doi          = {10.1016/j.ejor.2023.08.054},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {937-953},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A huff-like location model with quality adjustment and/or closing of existing facilities},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exact and heuristic algorithms for the domination problem.
<em>EJOR</em>, <em>313</em>(3), 926–936. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a simple connected graph G = ( V , E ) G=(V,E) , a subset of vertices S ⊆ V S⊆V is a dominating set if any vertex v ∈ V ∖ S v∈V∖S is adjacent to some vertex x x from this subset. A number of real-life problems can be modeled using this problem which is known to be among the difficult NP-hard problems in its class. We formulate the problem as an integer liner program (ILP) and compare the performance with the two earlier existing exact state-of-the-art algorithms and exact implicit enumeration and heuristic algorithms that we propose here. Our exact algorithm was able to find optimal solutions much faster than ILP and the above two exact algorithms for middle-dense instances. For graphs with a considerable size, our heuristic algorithm was much faster than both, ILP and our exact algorithm. It found an optimal solution for more than half of the tested instances, whereas it improved the earlier known state-of-the-art solutions for almost all the tested benchmark instances. Among the instances where the optimum was not found, it gave an average approximation error of 1.18.},
  archive      = {J_EJOR},
  author       = {Ernesto Parra Inza and Nodari Vakhania and José María Sigarreta Almira and Frank Angel Hernández Mira},
  doi          = {10.1016/j.ejor.2023.08.033},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {926-936},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exact and heuristic algorithms for the domination problem},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Vehicle routing for connected service areas - a versatile
approach covering single, hierarchical, and bi-criteria objectives.
<em>EJOR</em>, <em>313</em>(3), 905–925. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle routing in urban areas or in-house tour planning is characterized by the fact that tours have to service orders in areas with limited road or aisle access. During last mile delivery, courier service providers often face the situation that subsets of customers in urban areas are located along a single street that can be accessed from only one or two directions. This also applies to warehouses, where, due to the given grid layout, pickers locate products on shelves only in specific areas positioned along an aisle between two neighboring cross aisles. By being confronted with a substantial time and/or cost pressure, those tour planning applications have to deal with the trade-off between service orientation and cost minimization. In order to cover many of those applications, this study proposes a general model that integrates the definition of customizable service areas with limited access and soft due dates of urgent orders, whereas the objective function can be defined in a versatile way covering to choose between a single objective, a hierarchical, and a bi-criteria objective system. The model is dubbed the Vehicle Routing Problem of Service Areas (VRPSA). A comprehensive complexity analysis of the VRPSA for different objective systems shows that a pure travel cost minimization variant can be solved to optimality in polynomial time, whereas the bi-criteria variant simultaneously pursuing travel cost and tardiness cost minimization is proven to be intractable. In order to generate tour plans, a customizable best-first branch-and-bound algorithm is developed and assessed through a computational study.},
  archive      = {J_EJOR},
  author       = {Stefan Bock},
  doi          = {10.1016/j.ejor.2023.08.051},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {905-925},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Vehicle routing for connected service areas - A versatile approach covering single, hierarchical, and bi-criteria objectives},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrated production and transportation scheduling problem
under nonlinear cost structures. <em>EJOR</em>, <em>313</em>(3),
883–904. (<a href="https://doi.org/10.1016/j.ejor.2023.08.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an integrated production and transportation scheduling problem arising in several make-to-order settings, where customer orders have release times and pre-specified delivery time windows. These orders are first processed in a plant and, thereafter, delivered to their customer sites by transporters (e.g., freight trains, ships, or air flights) with fixed departure times and nonlinear transportation cost functions. If the processing of an order is completed but not immediately delivered, it will be stored temporarily, incurring inventory holding costs. The objective is finding an integrated schedule for production and transportation such that the total cost of inventory holding and transportation is minimized. In this study, we consider the following two cases: one where partial delivery is not allowed, and the other where partial delivery is allowed. For each case, we propose an exact algorithm to find optimal solutions for small-scale instances, and a heuristic algorithm to find near-optimal solutions for large-scale instances. For the randomly generated test instances, the computational results reveal that the exact algorithms significantly outperform a commercial optimization solver in terms of the computational times and the number of instances solved within a specified time limit, and the heuristic algorithms are capable of generating near-optimal solutions within a reasonable computational time. Finally, we incorporate considerations of sequence-dependent setup time into the problem and apply the approaches for designing the algorithms to address the more general problem.},
  archive      = {J_EJOR},
  author       = {Julong Wang and Zhixue Liu and Feng Li},
  doi          = {10.1016/j.ejor.2023.08.030},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {883-904},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrated production and transportation scheduling problem under nonlinear cost structures},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Set-based robust optimization of uncertain multiobjective
problems via epigraphical reformulations. <em>EJOR</em>,
<em>313</em>(3), 871–882. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a method for finding robust solutions to multiobjective optimization problems under uncertainty. We follow the set-based minmax approach for handling the uncertainties which leads to a certain set optimization problem with the strict upper type set relation. We introduce, under some assumptions, a reformulation using instead the strict lower type set relation without sacrificing the compactness property of the image sets. This allows to apply vectorization results to characterize the optimal solutions of these set optimization problems as optimal solutions of a multiobjective optimization problem. We end up with multiobjective semi-infinite problems which can then be studied with classical techniques from the literature.},
  archive      = {J_EJOR},
  author       = {Gabriele Eichfelder and Ernest Quintana},
  doi          = {10.1016/j.ejor.2023.09.017},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {871-882},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Set-based robust optimization of uncertain multiobjective problems via epigraphical reformulations},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convex support vector regression. <em>EJOR</em>,
<em>313</em>(3), 858–870. (<a
href="https://doi.org/10.1016/j.ejor.2023.05.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonparametric regression subject to convexity or concavity constraints is increasingly popular in economics, finance, operations research, machine learning, and statistics. However, the conventional convex regression based on the least squares loss function often suffers from overfitting and outliers. This paper proposes to address these two issues by introducing the convex support vector regression (CSVR) method, which effectively combines the key elements of convex regression and support vector regression. Numerical experiments demonstrate the performance of CSVR in prediction accuracy and robustness that compares favorably with other state-of-the-art methods.},
  archive      = {J_EJOR},
  author       = {Zhiqiang Liao and Sheng Dai and Timo Kuosmanen},
  doi          = {10.1016/j.ejor.2023.05.009},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {858-870},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Convex support vector regression},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quadratic regularization of bilevel pricing problems and
application to electricity retail markets. <em>EJOR</em>,
<em>313</em>(3), 841–857. (<a
href="https://doi.org/10.1016/j.ejor.2023.05.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the profit-maximization problem solved by an electricity retailer who aims at designing a menu of contracts. This is an extension of the unit-demand envy-free pricing problem: customers aim to choose a contract maximizing their utility based on a reservation bill and multiple price coefficients (attributes). A basic approach supposes that the customers have deterministic utilities; then, the response of each customer is highly sensitive to price since it concentrates on the best offer. A second classical approach is to consider logit model to add a probabilistic behavior in the customers’ choices. To circumvent the intrinsic instability of the former and the resolution difficulties of the latter, we introduce a quadratically regularized model of customer’s response, which leads to a quadratic program under complementarity constraints (QPCC). This allows to robustify the deterministic model, while keeping a strong geometrical structure. In particular, we show that the customer’s response is governed by a polyhedral complex, in which every polyhedral cell determines a set of contracts which is effectively chosen. Moreover, the deterministic model is recovered as a limit case of the regularized one. We exploit these geometrical properties to develop a pivoting heuristic, which we compare with implicit or non-linear methods from bilevel programming, showing the effectiveness of the approach. Throughout the paper, the electricity retailer problem is our guideline, and we present a numerical study on this application case.},
  archive      = {J_EJOR},
  author       = {Quentin Jacquet and Wim van Ackooij and Clémence Alasseur and Stéphane Gaubert},
  doi          = {10.1016/j.ejor.2023.05.006},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {841-857},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Quadratic regularization of bilevel pricing problems and application to electricity retail markets},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synchronisation in vehicle routing: Classification schema,
modelling framework and literature review. <em>EJOR</em>,
<em>313</em>(3), 817–840. (<a
href="https://doi.org/10.1016/j.ejor.2023.04.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The practical relevance and challenging nature of the Vehicle Routing Problem (VRP) have motivated the Operations Research community to consider different practical requirements and problem variants throughout the years. However, businesses still face increasingly specific and complex transportation requirements that need to be tackled, one of them being synchronisation. No literature contextualises synchronisation among other types of problem aspects of the VRP, increasing ambiguity in the nomenclature used by the community. The contributions of this paper originate from a literature review and are threefold. First, new conceptual and classification schemas are proposed to analyse literature and re-organise different interdependencies that arise in routing decisions. Secondly, a modelling framework is presented based on the proposed schemas. Finally, an extensive literature review identifies future research gaps and opportunities in the field of VRPs with synchronisation.},
  archive      = {J_EJOR},
  author       = {Ricardo Soares and Alexandra Marques and Pedro Amorim and Sophie N. Parragh},
  doi          = {10.1016/j.ejor.2023.04.007},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {3},
  pages        = {817-840},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Synchronisation in vehicle routing: Classification schema, modelling framework and literature review},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Corrigendum to “how bad can the centroid be?”[eur. J. Oper.
Res. 252 (2016) 98–102]. <em>EJOR</em>, <em>313</em>(2), 814–815. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This note corrects a blatant error in my paper ‘How bad can the centroid be?’[European Journal of Operational Research (2016) 98–102]. More precisely, Theorems 6 and 7 only hold for distances derived from a norm (and not, as claimed, from a gauge).},
  archive      = {J_EJOR},
  author       = {Frank Plastria},
  doi          = {10.1016/j.ejor.2023.10.022},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {814-815},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Corrigendum to ‘How bad can the centroid be?’[Eur. j. oper. res. 252 (2016) 98–102]},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pricing for services with cross-segment externalities,
capacity constraints, and competition. <em>EJOR</em>, <em>313</em>(2),
801–813. (<a href="https://doi.org/10.1016/j.ejor.2023.09.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many service systems such as movie theaters, sports clubs, or hotels, different customer segments share physical space, and the presence of customers from different segments may affect the utility a customer receives from the service. We consider a setting where two competing facilities offer service to two distinct types of customers and study whether and when the firms can benefit from using differential pricing. The two firms do not explicitly decide whether to use uniform or differential pricing. Rather, we derive our findings by characterizing and comparing all equilibria that might arise when differential pricing is feasible. Our results suggest that if the network externalities are symmetric, that is, if the two customer segments feel equally about the presence of customers of the other segment, then the firms never benefit from price differentiation, unless the network externalities are negative and strong when compared to the travel/inconvenience cost that the customers incur when receiving service from their less preferred facility. Interestingly, we find that using differential pricing can even hurt firm profits, when it leads to fierce price competition between the two service providers.},
  archive      = {J_EJOR},
  author       = {Wei Gu and H. Sebastian Heese and Eda Kemahlıoğlu-Ziya and Serhan Ziya},
  doi          = {10.1016/j.ejor.2023.09.021},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {801-813},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pricing for services with cross-segment externalities, capacity constraints, and competition},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Across-time risk-aware strategies for outperforming a
benchmark. <em>EJOR</em>, <em>313</em>(2), 776–800. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel objective function for constructing dynamic investment strategies with the goal of outperforming an investment benchmark at multiple points of evaluation during the investment time horizon. The proposed objective is intuitive, easy to parameterize, and directly targets a favorable tracking difference of the actively managed portfolio relative to the benchmark. Under stylized assumptions, we derive closed-form optimal investment strategies to guide the intuition in more realistic settings. In the case of discrete rebalancing with investment constraints, optimal strategies are obtained using a neural network-based numerical approach that does not rely on dynamic programming techniques. Compared to the targeting of a favorable tracking difference relative to the benchmark only at some fixed time horizon, our results show that the proposed objective offers a number of advantages: (i) The associated optimal strategies exhibit potentially more attractive asset allocation profiles, in that less extreme positions in individual assets are taken early in the investment time horizon, while achieving a similar terminal terminal wealth distribution. (ii) Across-time risk awareness leads to more robust performance and a higher probability of benchmark outperformance during the investment horizon in out-of-sample testing. The resulting strategies therefore exhibit desirable characteristics for active portfolio managers with periodic reporting requirements.},
  archive      = {J_EJOR},
  author       = {Pieter M. van Staden and Peter A. Forsyth and Yuying Li},
  doi          = {10.1016/j.ejor.2023.08.028},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {776-800},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Across-time risk-aware strategies for outperforming a benchmark},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal pure strategies for a discrete search game.
<em>EJOR</em>, <em>313</em>(2), 767–775. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a two-person zero-sum search game between a Hider and a Searcher. The Hider chooses to hide in one of n n discrete locations (or “boxes”) and the Searcher chooses a search sequence specifying which order to look in these boxes until finding the Hider. A search at box i i takes t i ti time units and finds the Hider—if hidden there—independently with probability q i qi , for i = 1 , … , n i=1,…,n . The Searcher wants to minimize the expected total time needed to find the Hider, while the Hider wants to maximize it. It is shown in the literature that the Searcher has an optimal search strategy that mixes up to n n distinct search sequences with appropriate probabilities. This paper investigates the existence of optimal pure strategies for the Searcher—a single deterministic search sequence that achieves the optimal expected total search time regardless of where the Hider hides. We identify several cases in which the Searcher has an optimal pure strategy, and several cases in which such optimal pure strategy does not exist. An optimal pure search strategy has significant practical value because the Searcher does not need to randomize their actions and will avoid second guessing themselves if the chosen search sequence from an optimal mixed strategy does not turn out well.},
  archive      = {J_EJOR},
  author       = {Thuy Bui and Thomas Lidbetter and Kyle Y. Lin},
  doi          = {10.1016/j.ejor.2023.08.041},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {767-775},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal pure strategies for a discrete search game},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reliable dynamic wireless charging infrastructure deployment
problem for public transport services. <em>EJOR</em>, <em>313</em>(2),
747–766. (<a href="https://doi.org/10.1016/j.ejor.2023.08.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic wireless power transfer (DWPT) technology offers the promise of eliminating the limited driving range of electric buses (EBs), providing greater convenience and safety benefits through the ability to charge EBs in motion. It may be possible to effectively circumvent the drawbacks of EBs such that it becomes mainstream in the future EB market. In this paper, we study the robust DWPT deployment problem for an EB system, aiming to determine the DWPT facility deployment, battery size, and en-route charging schedule simultaneously. We first formulate the deterministic problem as a novel mixed-integer linear programming (MILP) model. Next, we consider the energy consumption uncertainty and travel time uncertainty to develop a two-stage robust model. We further analyze the structural properties of our proposed model, and implement the column-and-constraint generation (C&amp;CG) method to solve it optimally. Finally, a series of experiments based on a test bus network and the National University of Singapore internal bus network are carried out to verify the efficiency and effectiveness of our models and algorithms. Some managerial insights are also provided that public transit (PT) operators could use to enhance the efficiency of the EB system in the future.},
  archive      = {J_EJOR},
  author       = {Yun Wang and Yu Zhou and Xuedong Yan},
  doi          = {10.1016/j.ejor.2023.08.053},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {747-766},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Reliable dynamic wireless charging infrastructure deployment problem for public transport services},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A simulation evacuation framework for effective disaster
preparedness strategies and response decision making. <em>EJOR</em>,
<em>313</em>(2), 733–746. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The damage and destruction of homes, buildings, and other infrastructure after a major earthquake makes it necessary for a segment of the population to be evacuated to emergency shelters. However, since areas prone to earthquakes face a major strike at highly unpredictable and infrequent times, disaster and evacuation management can and should be enhanced through the development and effective utilization of useful simulation models. We utilize the Stochastic Pedestrian Cell Transmission Model (SPCTM), a real data-based pedestrian evacuation simulation framework built in collaboration with the National Science and Technology Center for Disaster Reduction (NCDR) in Taiwan to carry out various statistical analyses to gain useful insights for disaster management decision makers. In particular, SPCTM is used to (1) examine how evacuee compliance rate with the current government evacuation protocol (as opposed to SPCTM) affects the total evacuation time (2) compare the results of the evacuation process for different neighborhoods and compliance rates in Da’an district, and (3) determine how allocating different subsets of shelters to be opened affects the evacuation response time. The analysis results are insightful for government officials to formulate effective evacuation guidelines and strategies in the preparedness or response phases.},
  archive      = {J_EJOR},
  author       = {Kuo-Hao Chang and Ying-Zheng Wu and Wen-Ray Su and Lee-Yaw Lin},
  doi          = {10.1016/j.ejor.2023.08.048},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {733-746},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A simulation evacuation framework for effective disaster preparedness strategies and response decision making},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Compete or cooperate? Effects of channel relationships on
government policies for sustainability. <em>EJOR</em>, <em>313</em>(2),
718–732. (<a href="https://doi.org/10.1016/j.ejor.2023.08.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The importance of sustainability has led governments worldwide to impose emission regulations on manufacturers. However, it is largely unknown how channel relationships between manufacturers (i.e., competitive or cooperative) affect government policies, such as the emission tax price. In this paper, we address this pertinent yet underexplored issue by building formal analytical models. In the context of different channel relationships and with the goal of increasing social welfare, we also explore whether providing positive incentives is more effective than imposing taxes. We show that although cooperation leads to better economic performance, competition may be the channel relationship that better improves sustainability and social welfare. We find that government incentives to promote green technology need not be effective in enhancing sustainability. If investment is needed to fund green technology, increasing taxes on greenhouse gas emissions (hereafter “emissions”) can protect the environment only if the product&#39;s initial emission intensity is sufficiently high. We also reveal that the total emissions are not necessarily decreased when (i) the consumers are more environmentally aware and (ii) there is a reduction in emission-abatement costs. Finally, we generalize our model to the extended modeling cases with (i) N-manufacturer and (ii) market segments with a proportion of environmentally aware consumers. Our main conclusions remain valid in the extended cases. The practical relevance and real-world implications of these results are discussed.},
  archive      = {J_EJOR},
  author       = {Guowei Dou and Tsan-Ming Choi},
  doi          = {10.1016/j.ejor.2023.08.012},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {718-732},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Compete or cooperate? effects of channel relationships on government policies for sustainability},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Right-left asymmetry of the eigenvector method: A simulation
study. <em>EJOR</em>, <em>313</em>(2), 708–717. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The eigenvalue method, suggested by the developer of the extensively used Analytic Hierarchy Process methodology, exhibits right-left asymmetry: the priorities derived from the right eigenvector do not necessarily coincide with the priorities derived from the reciprocal left eigenvector. This paper offers a comprehensive numerical experiment to compare the two eigenvector-based weighting procedures and their reasonable alternative of the row geometric mean with respect to four measures. The underlying pairwise comparison matrices are constructed randomly with different dimensions and levels of inconsistency. The disagreement between the two eigenvectors turns out to be not always a monotonic function of these important characteristics of the matrix. The ranking contradictions can affect alternatives with relatively distant priorities. The row geometric mean is found to be almost at the midpoint between the right and inverse left eigenvectors, making it a straightforward compromise between them.},
  archive      = {J_EJOR},
  author       = {László Csató},
  doi          = {10.1016/j.ejor.2023.09.022},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {708-717},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Right-left asymmetry of the eigenvector method: A simulation study},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving uplift model evaluation on randomized controlled
trial data. <em>EJOR</em>, <em>313</em>(2), 691–707. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating treatment effects is one of the most challenging and important tasks of data analysts. Personalized medicine, digital marketing, and many other applications demand an efficient allocation of scarce treatments to those individuals who benefit the most. Uplift models support this allocation by estimating how individuals react to a treatment. A major challenge in uplift modeling concerns evaluation. Previous literature suggests methods like the Qini curve and the transformed outcome mean squared error. However, these metrics suffer from variance: their evaluations are strongly affected by random noise in the data, which renders their signals, to a certain degree, arbitrary. We theoretically analyze the variance of uplift evaluation metrics and derive possible methods of variance reduction, which are based on statistical adjustment of the outcome. We derive simple conditions under which the variance reduction methods improve the uplift evaluation metrics and empirically demonstrate their benefits on simulated and real-world data. Our paper provides strong evidence in favor of applying the suggested variance reduction procedures by default when evaluating uplift models on RCT data.},
  archive      = {J_EJOR},
  author       = {Björn Bokelmann and Stefan Lessmann},
  doi          = {10.1016/j.ejor.2023.09.018},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {691-707},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Improving uplift model evaluation on randomized controlled trial data},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Productive efficiency analysis with unobserved inputs: An
application to endogenous automation in railway traffic management.
<em>EJOR</em>, <em>313</em>(2), 678–690. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Productive efficiency analytics are commonly used in managerial decision making, but are vulnerable to an omitted variable bias issue when there is incomplete information on the used production factors. In this paper, we relax the standard assumption in productive efficiency analysis that all input quantities are observed, and we propose a nonparametric methodology for cost inefficiency measurement that accounts for the presence of unobserved inputs. Our main contribution is that we bridge the nonparametric OR/MS and the economic Industrial Organization literature by addressing the general critique of Stigler (1976) on the concept of inefficiency (Leibenstein, 1966), which states that found inefficiencies reflect unobserved inputs rather than waste. Our methodology explicitly differentiates between cost inefficiency (i.e., waste; deviations from optimizing behavior) and unobserved input usage (i.e., optimally chosen input factors that are unobserved to the empirical analyst). We apply our novel method to a purpose-built dataset on Belgian railway traffic management control rooms. Our findings show the existence of meaningful inefficiencies that cannot be attributed to use of unobserved inputs or environmental factors. In addition, we document how the omitted variable bias impacts cost efficiencies of individual observations in a dissimilar way in case the use of unobserved inputs is not controlled for.},
  archive      = {J_EJOR},
  author       = {Laurens Cherchye and Bram De Rock and Dieter Saelens and Marijn Verschelde and Bart Roets},
  doi          = {10.1016/j.ejor.2023.09.012},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {678-690},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Productive efficiency analysis with unobserved inputs: An application to endogenous automation in railway traffic management},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Signaling quality through price guarantee window for
technology-related products. <em>EJOR</em>, <em>313</em>(2), 669–677.
(<a href="https://doi.org/10.1016/j.ejor.2023.09.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a firm producing and selling a technology-related product with asymmetric quality information to a destination market in two periods. A characteristic of the technology-related product is that its prevailing price may reduce throughout the product’s life cycle and therefore trigger the firm’s price guarantee window. We develop a two-period dynamic signaling game model in which the firm with knowledge of the product quality first decides on the price guarantee window, and then determines the price discount coefficient. We show that quality information disclosure may reduce a high-quality firm’s price guarantee window in which a high-quality firm actively disclosing product quality information can set a shorter price guarantee window to reduce the operating costs. In equilibrium, a high-quality firm would benefit from quality information disclosure but a low-quality firm would be worse off. Quality information disclosure may increase (decrease) a high-quality firm’s first-period sales volume and induce (discourage) more consumers to purchase as early as possible when the quality difference is low (high).},
  archive      = {J_EJOR},
  author       = {Zhiguo Li and Faqi Xie and Han Zhang and Hongwu Zhang},
  doi          = {10.1016/j.ejor.2023.09.007},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {669-677},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Signaling quality through price guarantee window for technology-related products},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven incentive mechanism design for chronic disease
prevention from the perspective of government. <em>EJOR</em>,
<em>313</em>(2), 652–668. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current government subsidies on prevention fail to effectively incentive primary care providers and patients with chronic diseases, resulting in ineffective prevention. It hinders the shift from “the treatment-based” to “the combination of prevention and treatment” philosophy for chronic diseases. To encourage primary care provider and patients with chronic diseases to make better prevention efforts, a sequential game model for government-primary care provider-patients is developed. Using mechanism design theory, an incentive mechanism for chronic disease prevention is proposed. This mechanism aims to increase patients’ motivation for prevention and ensure truthful reporting of their prevention efforts. Moreover, by integrating data from a primary care provider in Jiangsu Province, a closed loop with problem analysis-model construction-results testing is established. Specifically, with the data, the severity of prevention inefficiencies is quantified, the key functions required for modelling are identified with a new and identifiable regression method. Furthermore, the proposed mechanism is compared to the original mechanism in terms of its impact on the government, primary care provider, and patients.The comparison demonstrates the superiority of the proposed mechanism. This study reveals that the mechanism aligns the interests of all subjects by redistributing government subsidies between the primary care provider and the patients. The mechanism adjusts the primary care provider&#39;s authority to use the left subsidies. Besides, it enables the primary care provider to actively monitor and motivate patients to take further prevention action. Meanwhile,it successfully makes patients increase their prevention efforts and report them truthfully. Finally,the robustness of the model has also been demonstrated and verified.},
  archive      = {J_EJOR},
  author       = {Huan Sun and Haiyan Wang},
  doi          = {10.1016/j.ejor.2023.09.005},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {652-668},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Data-driven incentive mechanism design for chronic disease prevention from the perspective of government},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal promotional mix and pricing when faced with
uncertain product value. <em>EJOR</em>, <em>313</em>(2), 637–651. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of digital technology has facilitated firms to adopt a variety of innovative strategies for promoting their new products. However, as different promotion strategies have different implications on market reach, consumers’ information structure, and incurred cost, figuring out how to minimize wastage on marketing expenditure with a combination of multiple promotion strategies remains a challenging task. To provide insights into the efficient adoption of a promotional mix, we develop a stylized model that considers a firm selling an innovative product to a market wherein the product value is ex ante unknown to each consumer and the firm. The firm has two promotion strategies, hype advertising campaign (HAC) and referral reward program (RRP). Specifically, HAC refers to a basic publicity that aims only on raising product awareness through an extensive market reach. In contrast, in line with the pay-for-performance nature, RRP is an incentive-based program that offers rewards to the existing customers for bringing new buyers through consumer-to-consumer (C2C) referrals. Whereas both strategies allow previously ignorant consumers to learn of a product’s existence, due to the variation on the communication intensity, only those who become aware of the product through C2C referrals will be able to make an informed purchase decision. We find that both HAC and RRP should not always be adopted simultaneously since consumer referrals may intensify the wastage on HAC expenditure. The condition under which the promotional mix yields the optimal outcome and the circumstances when the firm should abandon either HAC or RRP are investigated.},
  archive      = {J_EJOR},
  author       = {Ruibing Wang and Qiao Wang and Wei-yu Kevin Chiang},
  doi          = {10.1016/j.ejor.2023.08.042},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {637-651},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal promotional mix and pricing when faced with uncertain product value},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computing cardinality constrained portfolio selection
efficient frontiers via closest correlation matrices. <em>EJOR</em>,
<em>313</em>(2), 628–636. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we demonstrate a completely new approach for computing cardinality constrained mean-variance efficient frontiers. By cardinality constrained, it is meant that if there is to be investment in a security, it is to be of at least some minimum amount (a buyin threshold), and that there is also a specification on the number of securities to be held in a portfolio (called a cardinality constraint). Whereas the usual strategy, as such problems are NP -hard, is to take the original exact problem and apply heuristics to solve, in this paper the strategy is to perturb the original problem and then apply exact procedures to solve. The advantages of the approach are that the perturbations are tiny, they are only applied to the problem’s correlation matrix, and they allow for the accurate computation of cardinality constrained efficient frontiers in problems with up to at least 1000 securities in remarkably little time. Moreover, the simplicity of the approach is such that it can be inserted into existing portfolio management systems without requiring any re-training beyond what a typical portfolio analyst would already know. 1},
  archive      = {J_EJOR},
  author       = {Ralph E. Steuer and Yue Qi and Maximilian Wimmer},
  doi          = {10.1016/j.ejor.2023.08.026},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {628-636},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Computing cardinality constrained portfolio selection efficient frontiers via closest correlation matrices},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mathematical programs with distributionally robust chance
constraints: Statistical robustness, discretization and reformulation.
<em>EJOR</em>, <em>313</em>(2), 616–627. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider mathematical programs with distributionally robust chance constraints (MPDRCC), where the ambiguity set is given by the general moment information. From the contaminated data-driven viewpoint, we first study the qualitative statistical robustness of MPDRCC. Then, motivated by the computational tractability, we investigate the discrete approximation of MPDRCC. The corresponding convergence results of the optimal value and the optimal solution set of the discrete approximation problem are established. After that, a reformulation of the discrete approximation problem is presented under standard assumptions, which is applied to solve MPDRCC approximately according to the above convergence results. Finally, two applications are reported, and some numerical results show that the statistical robustness assertion and the discrete approximation scheme are practical and effective.},
  archive      = {J_EJOR},
  author       = {Jie Jiang and Shen Peng},
  doi          = {10.1016/j.ejor.2023.10.020},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {616-627},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mathematical programs with distributionally robust chance constraints: Statistical robustness, discretization and reformulation},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A study of distributionally robust mixed-integer programming
with wasserstein metric: On the value of incomplete data. <em>EJOR</em>,
<em>313</em>(2), 602–615. (<a
href="https://doi.org/10.1016/j.ejor.2023.10.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses a class of linear mixed-integer programming (MILP) problems that involve uncertainty in the objective function parameters. The parameters are assumed to form a random vector, whose probability distribution can only be observed through a finite training data set. Unlike most of the related studies in the literature, we also consider uncertainty in the underlying data set. The data uncertainty is described by a set of linear constraints for each random sample, and the uncertainty in the distribution (for a fixed realization of data) is defined using a type-1 Wasserstein ball centered at the empirical distribution of the data. The overall problem is formulated as a three-level distributionally robust optimization (DRO) problem. First, we prove that the three-level problem admits a single-level MILP reformulation, if the class of loss functions is restricted to biaffine functions. Secondly, it turns out that for several particular forms of data uncertainty, the outlined problem can be solved reasonably fast by leveraging the nominal MILP problem. Finally, we conduct a computational study, where the out-of-sample performance of our model and computational complexity of the proposed MILP reformulation are explored numerically for several application domains.},
  archive      = {J_EJOR},
  author       = {Sergey S. Ketkov},
  doi          = {10.1016/j.ejor.2023.10.018},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {602-615},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A study of distributionally robust mixed-integer programming with wasserstein metric: On the value of incomplete data},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling strategic walk-in patients in appointment systems:
Equilibrium behavior and capacity allocation. <em>EJOR</em>,
<em>313</em>(2), 587–601. (<a
href="https://doi.org/10.1016/j.ejor.2023.09.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an outpatient clinic with strategic patients who choose between making an appointment with an indirect wait cost (advance patients) and walking in with an inconvenience cost that includes the risk of being rejected and waiting in the clinic (walk-ins). Patients have different indirect waiting costs and show up with some probability. The clinic allocates slots to advance and walk-in patients to minimize the expected blockage of walk-in patients. We characterize the equilibrium behavior of patients and investigate the optimal capacity allocation, for unobservable (patients know the expected waiting time) and observable (patients know their exact waiting time) cases. For the unobservable case, one of the three options is optimal: allocating all slots to advance patients, allocating all slots to walk-ins, or allocating a certain number of slots to advance patients so that only urgent patients would choose the walk-in option. In contrast, for the observable case, no such structure exists. We investigate the value of information numerically. Finally, we develop a simulation platform to examine the effects of model assumptions. We find the optimal capacity allocation for the simulation model to benchmark the performance of the theoretical models and two simple policies. These analyses verify that our models work well in realistic simulations, offering a useful tool in practice. In contrast to the common practice of allocating some slots to walk-ins, our results suggest that the clinics should prefer a system that allocates all slots to advance patients in certain environments due to the strategic behavior of patients.},
  archive      = {J_EJOR},
  author       = {Feray Tunçalp and Evrim D. Güneş and E. Lerzan Örmeci},
  doi          = {10.1016/j.ejor.2023.09.006},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {587-601},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modeling strategic walk-in patients in appointment systems: Equilibrium behavior and capacity allocation},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Digital advertising spillover, online-exclusive product
launches, and manufacturer-remanufacturer competition. <em>EJOR</em>,
<em>313</em>(2), 565–586. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manufacturers launch and advertise new generations of products through e-retailers. However, this advertising effort also benefits independent remanufacturers selling the previous generation of the same product online because of product recommendation algorithms and consumer category search. Through a stylized game-theoretic model, we investigate how independent, arm’s-length, and cooperative digital advertising strategies by a manufacturer and e-retailer unintentionally displace the sales of a new product to the benefit of an independently remanufactured alternative due to digital advertising spillover. We consider the manufacturer’s and remanufacturer’s relative production costs, the degree of substitutability between the two products, and the degree to which advertising spillover from the new product to the remanufactured product occurs. Further investigating the latter issue, we also consider that the remanufacturer’s advertising may spill over to the new product’s benefit, although at a comparatively weak level. Our results explore the optimal digital advertising strategy and effort in different conditions. We give recommendations to the manufacturer to maximize profits, which sometimes, unintuitively, involves sacrificing sales quantity and wholesale price under a cooperative advertising strategy to reduce advertising expenditures that would otherwise significantly benefit the remanufacturer’s product. A numerical analysis shows our findings to be robust and in an extension we explore the scenario that the manufacturer possesses its own direct channel.},
  archive      = {J_EJOR},
  author       = {Zhifeng Qian and Steven James Day and Joshua Ignatius and Lalitha Dhamotharan and Junwu Chai},
  doi          = {10.1016/j.ejor.2023.08.045},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {565-586},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Digital advertising spillover, online-exclusive product launches, and manufacturer-remanufacturer competition},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Newsvendor conditional value-at-risk minimisation: A
feature-based approach under adaptive data selection. <em>EJOR</em>,
<em>313</em>(2), 548–564. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical risk-neutral newsvendor problem is to decide the order quantity that maximises the expected profit. Some recent works have proposed an alternative model, in which the goal is to minimise the conditional value-at-risk (CVaR), a different but very much important risk measure in financial risk management. In this paper, we propose a feature-based non-parametric approach to Newsvendor CVaR minimisation under adaptive data selection (NPC). The NPC method is simple and general. It can handle minimisation with both linear and nonlinear profits, and requires no prior knowledge of the demand distribution. Our main contribution is two-fold. Firstly, NPC uses a feature-based approach. The estimated parameters of NPC can be easily applied to prescriptive analytic to provide additional operational insights. Secondly, unlike common non-parametric methods, our NPC method uses an adaptive data selection criterion and requires only a small proportion of data (only data from two tails), significantly reducing the computational effort. Results from both numerical and real-life experiments confirm that NPC is robust with regard to difficult and large data structures. Using fewer data points, the computed order quantities from NPC lead to equal or less downside loss in extreme cases than competing methods.},
  archive      = {J_EJOR},
  author       = {Congzheng Liu and Wenqi Zhu},
  doi          = {10.1016/j.ejor.2023.08.043},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {548-564},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Newsvendor conditional value-at-risk minimisation: A feature-based approach under adaptive data selection},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New integrated routing and surveillance model with drones
and charging station considerations. <em>EJOR</em>, <em>313</em>(2),
527–547. (<a href="https://doi.org/10.1016/j.ejor.2023.08.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cash/valuables routing is vulnerable to attacks and robberies, so it is essential to prioritize transport security. This research employs a surveillance drone approach to enhance the transport security of cash/valuables routing. Using drones to identify suspicious and high-risk situations is a secure way to transport cash/valuables. Compared to ground-based operators, drones provide superior advantages such as improved security, efficiency, and accuracy. To this end, an integrated routing and surveillance problem is proposed to secure cash/valuables transport. In this problem, ground vehicles (GVs) and surveillance drones are routed in coordination. GVs are responsible for transporting and delivering cash/valuables, while drones are tasked with monitoring the GVs’ routes. The drone surveillance is as follows: before GVs leave the customers’ points, drones must surveil the GV through the link ahead and ensure their security. Links are surveilled in specific time windows. In this problem, charging stations are considered to swap drones’ batteries. In addition, an improved iterated local search (ILS) algorithm is designed in this study to optimize the proposed problem. The performance of the proposed algorithm is then evaluated in small and large sizes. Furthermore, a sensitivity analysis is performed on some key parameters to assess the proposed model. Finally, the proposed approach is implemented in a real-world case study in Iran, with the results analyzed.},
  archive      = {J_EJOR},
  author       = {Fatemeh Zandieh and Seyed Farid Ghannadpour and Mohammad Mahdavi Mazdeh},
  doi          = {10.1016/j.ejor.2023.08.035},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {527-547},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {New integrated routing and surveillance model with drones and charging station considerations},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive robust optimization for lot-sizing under yield
uncertainty. <em>EJOR</em>, <em>313</em>(2), 513–526. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In manufacturing environments, uncertain production yield directly impacts the quality and feasibility of the production planning decisions. This paper investigates the use of adaptive robust optimization to hedge against uncertain yield when determining a production plan, and to react properly when updated information unfolds. We first derive a myopic adaptive robust policy for the inventory management problem, a special case of the lot-sizing problem where the setup and the production costs are omitted. We show that the policy is optimal under mild assumptions. Second, we address a multi-period single-item lot-sizing problem with a backorder and uncertain yield via adaptive robust optimization. We formulate an adaptive robust model based on the budgeted uncertainty set, where we exploit a linear approximation to transform the quadratic constraints into a mixed-integer linear program. We also propose a column and constraint generation algorithm to solve the adaptive model exactly. Finally, we demonstrate the performances of the proposed approaches and the value of the adaptive robust solutions through extensive numerical experiments.},
  archive      = {J_EJOR},
  author       = {Paula Metzker Soares and Simon Thevenin and Yossiri Adulyasak and Alexandre Dolgui},
  doi          = {10.1016/j.ejor.2023.08.036},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {513-526},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Adaptive robust optimization for lot-sizing under yield uncertainty},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Timetable synchronization of the last several trains at
night in an urban rail transit network. <em>EJOR</em>, <em>313</em>(2),
494–512. (<a href="https://doi.org/10.1016/j.ejor.2023.08.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve passenger accessibility and reduce the travel time cost at night, this paper aims to optimize the synchronization of the last several trains’ timetables on each line of an urban rail transit (URT) network. A space-time network is constructed to describe the train flow and passenger flow in the URT network, based on which an integer programming model is formulated. To effectively solve the proposed model, we decompose the problem into two levels and propose an iterative algorithm. In the upper level, an adaptive large neighbourhood search (ALNS) method is developed to generate new train timetables in the URT network, which are then evaluated by the passenger flow problem in the lower level, and the optimization-evaluation iteration continues until the termination conditions are met. The method and algorithm are applied to a large-scale instance using data for the Wuhan URT network at night, which involve 9 urban rail transit lines and over 119,000 passengers, and the results show that the number of inaccessible passengers is reduced by 27.53 % 27.53% , and the average travel time cost is reduced by 2.70 % 2.70% , compared with the original timetable. Then, the experimental results on a small-scale instance show that the proposed algorithm can find a near-optimal solution in a short time, which illustrates the effectiveness and efficiency of the ALNS method.},
  archive      = {J_EJOR},
  author       = {Di Zhang and Yuan Gao and Lixing Yang and Lixin Cui},
  doi          = {10.1016/j.ejor.2023.08.034},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {494-512},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Timetable synchronization of the last several trains at night in an urban rail transit network},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collection-disassembly-delivery problem of disassembly
centers in a reverse logistics network. <em>EJOR</em>, <em>313</em>(2),
478–493. (<a href="https://doi.org/10.1016/j.ejor.2023.07.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disassembly centers are essential in a reverse logistics network for breaking end-of-life products and recycling valuable materials. This paper studies a collection-disassembly-delivery problem for a disassembly center, which collects products from collection centers, disassembles products into materials and delivers materials to remanufacturing plants. A set of homogenous vehicles are available for collecting products and delivering materials. The disassembly center makes the best decision on disassembly, inventory, and vehicle routing for collecting products and delivering materials. We propose a mixed-integer linear programming model to formulate the problem, and then improve the two-phase iterative heuristic approach and adaptive large neighborhood search heuristic to solve the problem. This method introduces a tabu search procedure, a learning mechanism, and four new removal operators. A real case and three generated datasets are used to evaluate its computational performance. The results demonstrate that the method can quickly obtain high-quality solutions.},
  archive      = {J_EJOR},
  author       = {Jieyu Lei and Ada Che and Tom Van Woensel},
  doi          = {10.1016/j.ejor.2023.07.008},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {478-493},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Collection-disassembly-delivery problem of disassembly centers in a reverse logistics network},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mathematical formulations for consistent travelling salesman
problems. <em>EJOR</em>, <em>313</em>(2), 465–477. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The consistent travelling salesman problem looks for a minimum-cost set of Hamiltonian routes, one for every day of a given time period. When a customer requires service in several days, the service times on different days must differ by no more than a given threshold (for example, one hour). We analyze two variants of the problem, depending on whether the vehicle is allowed to wait or not at a customer location before its service starts. There are three mathematical models in the literature for the problem without waiting times, and this paper describes a new model appropriated to be solved with a branch-and-cut algorithm. The new model is a multi-commodity flow formulation on which Benders’ Decomposition helps manage a large number of flow variables. There were no mathematical models in the literature for the variant with waiting times, and this paper adapts the four mathematical models to it. We analyze the computational results of the formulations on instances from the literature with up to 100 customers and three days.},
  archive      = {J_EJOR},
  author       = {Daniel Díaz-Ríos and Juan-José Salazar-González},
  doi          = {10.1016/j.ejor.2023.08.021},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {465-477},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mathematical formulations for consistent travelling salesman problems},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Coordinated seru scheduling and distribution operation
problems with DeJong’s learning effects. <em>EJOR</em>, <em>313</em>(2),
452–464. (<a href="https://doi.org/10.1016/j.ejor.2023.08.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the advantage of just-in-time philosophy, zero-inventory is common in many industries, especially those need fast response with a short lifespan. Accordingly, this paper focuses on coordinated production scheduling and distribution operation problems considering workers’ DeJong’s learning effects in seru production system (SPS), in which seru is a relatively new-type manufacturing mode originating from Japan and can achieve fast response in practice. Two variants of coordinated seru scheduling and distribution operation problems are studied, and the corresponding 0–1 integer programming model is formulated. By analyzing the mathematical property, the polynomial computation time of the former is able to be determined, and an intractability and NP-hardness proof is provided for the latter. The dynamic programming-based exact algorithm and the heuristic ant colony optimization algorithm are developed respectively. Computational experiments are conducted finally, and a series of experimental results indicate that the Dejong’s learning effect has a significant influence on coordinated seru scheduling and distribution operation problems, meanwhile a remarkable benefit (the average improvement is 16.97%) can be achieved by the coordinated production scheduling and distribution operation in SPS.},
  archive      = {J_EJOR},
  author       = {Zhe Zhang and Xiaoling Song and Xue Gong and Yong Yin and Benjamin Lev and Xiaoyang Zhou},
  doi          = {10.1016/j.ejor.2023.08.022},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {452-464},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Coordinated seru scheduling and distribution operation problems with DeJong’s learning effects},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An optimization-based approach for an integrated forest fire
monitoring system with multiple technologies and surveillance drones.
<em>EJOR</em>, <em>313</em>(2), 435–451. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wildfires pose a significant threat to forests and the delicate natural balance. In this work, we present a novel optimization approach for designing forest fire monitoring systems that incorporate surveillance towers, monitoring balloons, and drone technology, which have gained popularity in recent years for monitoring, logistics, and civil applications. We develop a compact mixed-integer linear programming model that includes location decisions for multiple monitoring technologies and routing of drones among monitoring facilities to achieve the most extensive possible terrain coverage. Additionally, we propose a matheuristic algorithm that comprises six components: a solution procedure, perturbation procedures, local search procedures, a call to the general-purpose solver to solve a mixed-integer linear programming model, a global reset strategy, a local reset strategy, and an acceptance criterion. We test the proposed model and algorithm on a set of random instances and a real-life case study in Chile. While the proposed model can only solve small instances, the matheuristic can find good-quality solutions for all instances. This study can aid the government and private sector in designing an integrated fire monitoring system that leverages watchtowers, monitoring balloons, and drones.},
  archive      = {J_EJOR},
  author       = {Rodrigo De la Fuente and Maichel M. Aguayo and Carlos Contreras-Bolton},
  doi          = {10.1016/j.ejor.2023.08.008},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {435-451},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An optimization-based approach for an integrated forest fire monitoring system with multiple technologies and surveillance drones},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An effective hybrid evolutionary algorithm for the clustered
orienteering problem. <em>EJOR</em>, <em>313</em>(2), 418–434. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a variant of the orienteering problem called the clustered orienteering problem. In this problem, customers are grouped into clusters. A profit is associated with each cluster and is collected if and only if all customers in the cluster are served. A single vehicle is available to visit the customers. The goal is to maximize the total profits collected within a maximum travel time limit. To address this NP-hard problem, we propose the first evolutionary algorithm that integrates a backbone-based crossover operator and a destroy-and-repair mutation operator for search diversification and a solution-based tabu search procedure reinforced by a reinforcement learning mechanism for search intensification. The experiment results indicate that our algorithm outperforms the state-of-the-art algorithms from the literature on a wide range of 924 well-known benchmark instances. In particular, the proposed algorithm obtains new records (new lower bounds) for 14 instances and finds the best-known solutions for the remaining instances. Furthermore, a new set of 72 large instances with 50 to 100 clusters and at least 400 vertices is generated to evaluate the scalability of the proposed algorithm. Results show that the proposed algorithm manages to outperform three state-of-the-art COP algorithms. We also adopt our algorithm to solve a dynamic version of the COP considering stochastic travel time.},
  archive      = {J_EJOR},
  author       = {Qinghua Wu and Mu He and Jin-Kao Hao and Yongliang Lu},
  doi          = {10.1016/j.ejor.2023.08.006},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {418-434},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An effective hybrid evolutionary algorithm for the clustered orienteering problem},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of attacker-defender games: Current state and paths
forward. <em>EJOR</em>, <em>313</em>(2), 401–417. (<a
href="https://doi.org/10.1016/j.ejor.2023.04.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we review the literature which proposes attacker-defender games to protect against strategic adversarial threats. More specifically, we follow the systematic literature review methodology to collect and review 127 journal articles that have been published over the past 15 years. We start by briefly discussing the common application areas that are addressed in the literature, although our focus in this review lies heavily in the approaches that have been adopted to model and solve attacker-defender games. In studying these approaches, we begin by analyzing the following features of the proposed game formulations: the sequence of moves, number of players, nature of decision variables and objective functions, and time horizons. We then analyze the common assumptions of perfect rationality, risk neutrality, and complete information that are enforced within the majority of the articles, and report on state-of-the-art research which has begun relaxing these assumptions. We find that relaxing these assumptions presents further challenges, such as enforcing new assumptions regarding how uncertainties are modeled, and issues with intractability when models are reformulated to account for considerations such as risk preferences. Finally, we examine the methods that have been adopted to solve attacker-defender games. We find that the majority of the articles obtain closed-form solutions to their models, while there are also many articles that developed novel solution algorithms and heuristics. Upon synthesizing and analyzing the literature, we expose open questions in the field, and present promising future research directions that can advance current knowledge.},
  archive      = {J_EJOR},
  author       = {Kyle Hunt and Jun Zhuang},
  doi          = {10.1016/j.ejor.2023.04.009},
  journal      = {European Journal of Operational Research},
  month        = {3},
  number       = {2},
  pages        = {401-417},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A review of attacker-defender games: Current state and paths forward},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Daily scheduling of generating units with natural-gas market
constraints. <em>EJOR</em>, <em>313</em>(1), 387–399. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the daily scheduling of generating units (unit commitment) in a system whose production mix includes a large number of natural-gas-fired units. We assume that the natural-gas system, operating under market conditions, does its best to supply the natural-gas for electricity production required by the power system. We formulate this problem as a bi-level model whose upper-level problem represents the scheduling of generating units under a second-order conic relaxation of the AC network constraints, and whose lower-level one represents the clearing of the natural-gas market. The upper-level problem is mixed-integer second-order conic, while the lower-level one is second-order conic as well, but continuous. We replace the lower-level problem by its optimality conditions in the form of primal constraints, dual constraints, and strong duality equality, which results in a single-level nonconvex mixed-integer nonlinear optimization problem. To improve the computational tractability of such formulation, we derive a mixed-integer second-order conic relaxation of the single-level nonconvex mixed-integer nonlinear optimization problem. Such problem is solved using a Benders-type outer-approximation decomposition framework with a master mixed-integer linear problem and two subproblems that are nonlinear but convex. The communication between the master problem and the subproblems is enhanced by incorporating into the master problem linearized information pertaining to the subproblems and valid linear inequalities. The benefits of the proposed model and the effectiveness of the solution procedure are illustrated using the IEEE 24-bus test system coupled with a 20-node natural-gas system and the Central Illinois 200-bus power system coupled with a 48-node natural-gas system.},
  archive      = {J_EJOR},
  author       = {Gonzalo E. Constante-Flores and Antonio J. Conejo and Feng Qiu},
  doi          = {10.1016/j.ejor.2023.08.024},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {387-399},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Daily scheduling of generating units with natural-gas market constraints},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cluster-based lateral transshipments for the zambian health
supply chain. <em>EJOR</em>, <em>313</em>(1), 373–386. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many low- and middle-income countries, including Zambia, suffer from unreliable distribution of health commodities leading to high variation in service levels across health facilities. Our work investigates how transshipment can improve system-wide service levels, equity across facilities, and average inventory levels. We focus on the distribution of malaria medicines in Zambia’s public pharmaceutical supply chain, which is heavily impacted by the rainy season leading to seasonality and uncertainty in demand and lead times. We use the more advanced deep reinforcement learning method Proximal Policy Optimization to develop transshipment policies and compare their performance with currently available, easy-to-use heuristics. To ensure that the model applies to settings of a realistic scale, we adopt a policy architecture that effectively decouples the policy’s complexity from the problem dimensions. We find that deep reinforcement learning is mainly useful in resource-constrained environments where system-wide inventory is scarce. When sufficient inventory is available, transshipment heuristics are more appealing from an overall cost-effectiveness perspective. Based on our numerical experiments, we formulate policy insights that can support policymakers in a humanitarian health context.},
  archive      = {J_EJOR},
  author       = {Nathalie Vanvuchelen and Kim De Boeck and Robert N. Boute},
  doi          = {10.1016/j.ejor.2023.08.005},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {373-386},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cluster-based lateral transshipments for the zambian health supply chain},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Production trade-offs in models of data envelopment analysis
with ratio inputs and outputs: An application to schools in england.
<em>EJOR</em>, <em>313</em>(1), 359–372. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In applications of data envelopment analysis (DEA), the inputs and outputs representing environmental and quality characteristics of the production process are often stated in the form of percentages, ratios and averages, collectively referred to as ratio measures. It is known that the conventional variable and constant returns-to-scale (VRS and CRS) DEA models cannot correctly incorporate such ratio inputs and outputs. This problem has been addressed by the development of Ratio-VRS and Ratio-CRS (R-VRS and R-CRS) models suitable for the incorporation of both volume and ratio inputs and outputs. Such models may, however, depending on the application, lack sufficient discriminatory power. In this paper we address this issue by developing a further extension of the R-VRS and R-CRS models (the latter with the most common fixed type of ratio inputs and outputs) by allowing the specification of production trade-offs between volume inputs and outputs, and, similarly, between ratio measures. As in the case of conventional VRS and CRS models in which the role of production trade-offs is well understood, the specification of such trade-offs in the R-VRS and R-CRS production technologies leads to their controlled expansion and results in improved efficiency discrimination of the resulting DEA models. We illustrate the application of the proposed methodology by the assessment of efficiency of a large sample of secondary schools in England.},
  archive      = {J_EJOR},
  author       = {Victor V. Podinovski and Junlin Wu and Nikolaos Argyris},
  doi          = {10.1016/j.ejor.2023.08.019},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {359-372},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Production trade-offs in models of data envelopment analysis with ratio inputs and outputs: An application to schools in england},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An age-cohort simulation model for generating COVID-19
scenarios: A study from ireland’s pandemic response. <em>EJOR</em>,
<em>313</em>(1), 343–358. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic presented an immediate need for the Irish Government to establish modelling capacity in order to inform public health decision making. A broad-based interdisciplinary team was created at short notice, drawing together related expertise from the academic and health sectors. This paper documents one of a number of modelling solutions developed by the Irish Epidemiological Modelling Advisory Group (IEMAG), which advised the Irish Government on COVID-19 responses during the pandemic. The model inputs included surveillance data, epidemiological data, demographic data, vaccination schedules, vaccine efficacy estimates, estimates of social contacts, and new variant data. Outputs from the model supported policy discussions, including: decisions on the timing of public health restrictions, simulating the effects of school reopening on overall disease transmission, exploring the impact of vaccination across different age cohorts, and generating scenarios on the plausible impact on cases caused by the Omicron variant. An innovative aspect of the solution was the use of a modular design, with three benefits: (1) it enabled a simplification of the disease transmission structure; (2) it provided a practical workflow to coordinate activities; and (3) it speeded up the process of scenario generation and the requirement to provide timely and informative scenario analysis to support Ireland&#39;s pandemic response. Given the paper&#39;s applied and practical focus, it presents a record of modelling and scenario outputs as they were developed, presented and deployed during the actual outbreak - therefore all simulation results and scenarios are documented “as they happened”, and without the benefit of hindsight.},
  archive      = {J_EJOR},
  author       = {Jim Duggan and Jair Andrade and Thomas Brendan Murphy and James P. Gleeson and Cathal Walsh and Philip Nolan},
  doi          = {10.1016/j.ejor.2023.08.011},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {343-358},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An age-cohort simulation model for generating COVID-19 scenarios: A study from ireland&#39;s pandemic response},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Impacts of consumer virtual showrooming behavior on
manufacturer and retailer strategic decisions in a dual-channel supply
chain. <em>EJOR</em>, <em>313</em>(1), 325–342. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A dual-channel supply chain is considered with a manufacturer selling its product through an offline retailer and an online store. The manufacturer can set up a virtual showroom to help consumers judge the product suitability. Consumers may switch to the offline retailer to buy the product after experiencing virtual demonstration, called virtual showrooming behavior (VSB). Consumers are divided into H-consumers with, and L-consumers without, positive experience cost. The problem is modeled as a Stackelberg game with the manufacturer as the leader and the retailer as the follower. Based on consumer heterogeneity and VSB, the manufacturer makes the strategic decision of whether to set up a virtual showroom and the retailer makes the strategic decision of whether to support consumer VSB. The conditions influencing the manufacturer and retailer decisions are explored. The results show H-consumers may engage in VSB if their experience cost is low, and L-consumers may engage in VSB if their store visit cost is relatively low. Consumer VSB significantly depends on the product suitability and the virtual showroom informatization degree. When the experience cost is neither too high nor too low, the manufacturer will set up a virtual showroom if the consumers are relatively sensitive to the store visit cost. The retailer may not benefit by supporting consumer VSB regardless of the experience cost, when consumers are relatively insensitive to the store visit cost. The retailer will choose the same strategy and the manufacturer may choose the opposite strategy when the wholesale price is endogenous instead of exogenous.},
  archive      = {J_EJOR},
  author       = {Ruozhen Qiu and Chunxia Li and Minghe Sun},
  doi          = {10.1016/j.ejor.2023.08.025},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {325-342},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Impacts of consumer virtual showrooming behavior on manufacturer and retailer strategic decisions in a dual-channel supply chain},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A simulation-based method for estimating systemic risk
measures. <em>EJOR</em>, <em>313</em>(1), 312–324. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on simulation-based approaches for estimating systemic risk measures. In particular, we provide the asymptotic forms of the relative errors for widely used systemic risk measures including conditional value-at-risk (CoVaR), coexpected shortfall (CoES) and marginal expected shortfall (MES). Based on asymptotic expansions, a general framework is provided for the simulation of systemic risk measures. The numerical results show that the proposed simulation framework works well, and it is more user-friendly, easier to expand and less time-consuming than simulation approaches using the resampling method and importance sampling.},
  archive      = {J_EJOR},
  author       = {Wuyi Ye and Yi Zhou and Pengzhan Chen and Bin Wu},
  doi          = {10.1016/j.ejor.2023.08.032},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {312-324},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A simulation-based method for estimating systemic risk measures},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A decision variable classification strategy based on the
degree of environmental change for dynamic multiobjective optimization.
<em>EJOR</em>, <em>313</em>(1), 296–311. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective optimization problems (DMOPs) are constantly changing over time, which requires algorithms to keep track of the location of the Pareto optimal front (POF) at different moments in time. In this work, a decision variable classification strategy based on the degree of environmental change (DVCEC) is proposed. To accurately capture the occurrence of environmental changes, DVCEC designs an adaptive change detection method based on multiple regions. Since environmental changes affect each decision variable to different degrees, DVCEC classifies decision variables into several types and applies an appropriate prediction method to each type. In addition, an adjustment strategy is developed to minimize the impact of inaccurate predictions. The proposed DVCEC is evaluated on 22 benchmark problems and compared with four algorithms. Statistical results show that DVCEC can quickly approach POF and uniformly distribute it in most problems.},
  archive      = {J_EJOR},
  author       = {Hao Sun and Cong Wang and Xiaxia Li and Ziyu Hu},
  doi          = {10.1016/j.ejor.2023.08.023},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {296-311},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A decision variable classification strategy based on the degree of environmental change for dynamic multiobjective optimization},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fixed cost allocation based on data envelopment analysis
from inequality aversion perspectives. <em>EJOR</em>, <em>313</em>(1),
281–295. (<a href="https://doi.org/10.1016/j.ejor.2023.08.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world cases, fixed cost allocation frequently occurs in constructing the common platform of an organization: all divisions related to the platform must share the platform&#39;s fixed cost. Addressing the fixed cost allocation issue has become a vital topic, and numerous approaches have been used, including data envelopment analysis (DEA). However, inequality aversion, one vital concept of fairness concern, is frequently ignored in the previous publications. This paper is devoted to guaranteeing fairness for all decision-making units (DMUs) in allocation solutions from DEA. Firstly, we discuss how inequality impacts DMUs by proposing the concept of “fairness concern disutility” and using various parameters to reflect the negative impact of an unfair allocation plan on DMUs. Secondly, we discuss fixed cost allocation from three perspectives: optimistic, pessimistic, and mixed. Moreover, we give algorithms to obtain a unique, optimal solution and propose theorems to better understand our model. Lastly, we use a numerical example to illustrate the proposed models and theorems before applying our approach to address a fixed allocation issue in a commercial bank. Our analysis results show that the proposed approaches can guarantee fairness in fixed cost allocation.},
  archive      = {J_EJOR},
  author       = {Guangcheng Xu and Jie Wu and Qingyuan Zhu and Yinghao Pan},
  doi          = {10.1016/j.ejor.2023.08.020},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {281-295},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fixed cost allocation based on data envelopment analysis from inequality aversion perspectives},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Entry mode selection for a new entrant of the electric
vehicle automaker. <em>EJOR</em>, <em>313</em>(1), 270–280. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Firms are increasingly joining the electric vehicle industry and facing the prospect of how to recycle spent power batteries. This study considers two competing automakers, the incumbent and the new entrant. The incumbent has a stable forward (reverse) channel structure. The new entrant has a forward channel structure different from the incumbent’s and, consequently, needs to decide which reverse channel structure to adopt; the two primary choices are a traditional 3P-recycler or an emerging co-recycler. We find that both the fixed cost of spent power battery treatment and the government’s one-time fixed cost subsidy will affect which reverse channel structure the new entrant will select. Interestingly, our results disclose that a high fixed cost of spent power battery treatment does not necessarily worsen a firm’s profit, but social welfare decreases in the fixed cost. Moreover, we find that the government’s one-time fixed cost subsidy has no direct effect on consumer surplus or social welfare, but it can affect consumer surplus or social welfare by influencing the new entrant’s reverse channel selection. Therefore, the government would like to consider a one-time fixed cost subsidy policy to encourage new entrants to select a co-recycler as the reverse channel in the presence of a high fixed cost. However, in the presence of a low fixed cost, the government does not need to subsidize the new entrant for the fixed cost. The analysis yields insights into how drivers influence the new entrant’s selection of strategies in a competitive environment.},
  archive      = {J_EJOR},
  author       = {Lei Fang and Yanlin Li and Kannan Govindan},
  doi          = {10.1016/j.ejor.2023.08.014},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {270-280},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Entry mode selection for a new entrant of the electric vehicle automaker},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On strategic customers with correlated utility attributes:
Effects and information benefits. <em>EJOR</em>, <em>313</em>(1),
258–269. (<a href="https://doi.org/10.1016/j.ejor.2023.08.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate a service system where heterogeneous customers arrive with varying assessments of service reward and unit waiting cost. Additionally, we allow for correlation between a customer’s valuations for service reward and unit waiting cost. We first model the service facility as an unobservable M/M/1 queue and demonstrate that the correlation between the previously mentioned utility attributes affects various critical performance metrics. If the expected net utility of the customers, when exactly half of the customers join the facility, is positive (negative), then the equilibrium arrival rate increases (decreases) with the correlation. We also show that the expected utility of arriving customers decreases with correlation. Finally, we examine the observability of queue length within our model and calculate regions of model parameters where disclosing queue length information benefits the customers and the service provider the least or the most.},
  archive      = {J_EJOR},
  author       = {Zeynep Gökçe İşlier and Refik Güllü},
  doi          = {10.1016/j.ejor.2023.08.015},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {258-269},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On strategic customers with correlated utility attributes: Effects and information benefits},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generating and validating cluster sampling matrices for
model-free factor screening. <em>EJOR</em>, <em>313</em>(1), 241–257.
(<a href="https://doi.org/10.1016/j.ejor.2023.08.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Morris’ elementary effect-based screening (MM) has been widely used in a variety of domains to identify a few important factors among many possible ones. In MM, cluster sampling offers substantial computational savings over non-cluster sampling, but it remains a challenge to construct a cluster sampling matrix that generates any particular number of elementary effects for each factor. In this paper, we thoroughly address this issue. We uncover the mathematical association between distinct block sampling matrices within the complete cluster sampling matrix, by introducing a “dummy” sub-block matrix. By leveraging this property, we propose an easy-to-implement adaptive cluster sampling (ACS) method that is capable of identifying the appropriate sub-block sampling matrix to use. Its advantage over existing brute-force methods is that it can provide easy-to-obtain cluster sampling matrices, and it can be applied to computational model with any number of factors given a prior. We demonstrate the attractive properties of ACS using analytical proofs and simulation experiments. We show the robustness of ACS via a real-world case study. Our code for the algorithm is available online.},
  archive      = {J_EJOR},
  author       = {Wen Shi and Ao Chen and Xiang Xie},
  doi          = {10.1016/j.ejor.2023.08.007},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {241-257},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Generating and validating cluster sampling matrices for model-free factor screening},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Arc routing based compact formulations for picker routing in
single and two block parallel aisle warehouses. <em>EJOR</em>,
<em>313</em>(1), 225–240. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Order picking is the most expensive and labor-intensive warehouse activity. The objective of the order picking problem (OPP) is to collect the items on the pick list in a sequence that minimizes the total travel time. While the literature has generally modeled the OPP as a special case of the traveling salesman problem, this paper presents arc routing-based binary integer programming formulations for the OPP in single- and two-block parallel-aisle warehouses, by taking into account the special properties of the graph corresponding to both warehouse layouts. These formulations depend on replacing the subtour elimination constraints with a much smaller number of disconnectivity elimination constraints, which significantly reduces the integrality gap. Our computational experiments show that the proposed formulation solves large instances within significantly short computing times when compared with its counterparts in the literature for single- and two-block parallel-aisle warehouses. The efficiency of these formulations implies that not only can they be used to solve the OPP in a timely manner, but they can also be incorporated into integrated models that consider multiple warehouse decision problems at the operational level. More importantly, when compared to other state-of-the-art formulations, the extensibility of our proposed model makes it an ideal candidate for further research in this field.},
  archive      = {J_EJOR},
  author       = {Serhat Saylam and Melih Çelik and Haldun Süral},
  doi          = {10.1016/j.ejor.2023.08.018},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {225-240},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Arc routing based compact formulations for picker routing in single and two block parallel aisle warehouses},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Train stop scheduling problem: An exact approach using valid
inequalities and polar duality. <em>EJOR</em>, <em>313</em>(1), 207–224.
(<a href="https://doi.org/10.1016/j.ejor.2023.07.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the problem of minimizing the number of train stops on a particular rail line. The objective is to assign passengers of each origin-destination pair to different trains in such a way that train capacity and passenger demand constraints are satisfied with minimal stoppages. The literature refers to this problem as the train stop scheduling problem. The problem has been extensively studied for decades, yet an exact solution approach has not been proposed. This paper proposes several valid inequalities to strengthen the mixed-integer programming formulation and solve the problem exactly in a reasonable amount of CPU time. The concept of polar duality has been utilized to find more complex valid inequalities which may be hard to find otherwise. Despite the problem’s high practical relevance, valid inequalities for the problem have not yet been studied in the literature. An aggregation procedure has been proposed to solve large size problem instances exactly. Computational study demonstrate the efficacy of the proposed valid inequalities.},
  archive      = {J_EJOR},
  author       = {Faiz Hamid and Yogesh K. Agarwal},
  doi          = {10.1016/j.ejor.2023.07.023},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {207-224},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Train stop scheduling problem: An exact approach using valid inequalities and polar duality},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extensions to the guaranteed service model for industrial
applications of multi-echelon inventory optimization. <em>EJOR</em>,
<em>313</em>(1), 192–206. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-echelon inventory optimization (MEIO) plays a key role in a supply chain seeking to achieve specified customer service levels with a minimum capital in inventory. In this work, we propose a generalized MEIO model based on the Guaranteed Service approach to allocate safety stock levels across the network at the lowest holding cost. This model integrates several existing and some novel features that are usually present in pharmaceutical multi-echelon supply chains into a single model: review periods, manufacturing facilities, hybrid nodes (nodes with both internal and external demand), minimum order quantities (MOQ), and different service level performance indicators (fill rate and cycle service levels). We include a polynomial regression to approximate fill rates as a possible target measure to set safety stocks. To improve efficiency, we propose a nonlinear programming model to support decision making, which can be reformulated as a Quadratically Constrained Program (QCP), which leads to order of magnitude reductions in computational time. The performance of the model is evaluated by solving illustrative and real-world cases, and is validated with simulation.},
  archive      = {J_EJOR},
  author       = {Victoria G. Achkar and Braulio B. Brunaud and Héctor D. Pérez and Rami Musa and Carlos A. Méndez and Ignacio E. Grossmann},
  doi          = {10.1016/j.ejor.2023.08.013},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {192-206},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Extensions to the guaranteed service model for industrial applications of multi-echelon inventory optimization},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A joint demand and supply management approach to large scale
urban evacuation planning: Evacuate or shelter-in-place, staging and
dynamic resource allocation. <em>EJOR</em>, <em>313</em>(1), 171–191.
(<a href="https://doi.org/10.1016/j.ejor.2023.07.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban evacuation management is challenging to implement as it requires planning and coordination over a large geographical area. To address these challenges and to bolster evacuation planning and management, joint supply and demand management strategies should be considered. In this study, we explore and jointly optimize evacuate or shelter-in-place (SIP), dynamic resource allocation (DRA), and staging decisions for an efficient evacuation plan that minimizes total risk exposure of the population threatened by a sudden onset disaster. We introduce a Cell Transmission Model-based mathematical formulation and propose an exact solution methodology based on Benders decomposition. We further enhance the effectiveness of the algorithm by solving the Benders subproblem using a network flow based formulation on a time-expanded-network, and generating valid inequalities based on DRA decisions and for time-feasible solutions and develop an effective branch-and-cut algorithm to solve the master problem. We conduct extensive numerical experiments using realistic instances to test the effectiveness of the algorithm and to derive managerial insights. We find that considering evacuate or SIP, staging, and DRA decisions jointly contributes significantly to the effectiveness of the evacuation operations. A zone-based approach where some zones are ordered to evacuate while others shelter-in-place is superior to other approaches where an evacuate or SIP decision is given for all population at risk.},
  archive      = {J_EJOR},
  author       = {Vedat Bayram and Hande Yaman},
  doi          = {10.1016/j.ejor.2023.07.033},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {171-191},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A joint demand and supply management approach to large scale urban evacuation planning: Evacuate or shelter-in-place, staging and dynamic resource allocation},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating train service route design with passenger flow
allocation for an urban rail transit line. <em>EJOR</em>,
<em>313</em>(1), 146–170. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Train service design problem considers many operating strategies, i.e., multiple service routes, multiple train compositions, and express/local modes. Incorporating multiple operating strategies, this study first formulates an integer linear programming model for integrating train service route design with the passenger flow allocation problem. Consistency between the two components is enforced by a set of linking constraints that consider the relationship between the number of transit trips assigned to a route and the capacity of a single train. To solve the proposed model on real-life instances, we develop an approach that utilizes the Alternating Direction Method of Multipliers (ADMM). This dualizes the linking constraints and decomposes the problem into two subproblems: a train service route design subproblem and a passenger flow allocation subproblem. The latter can be subdivided into a set of passenger group-specific subproblems and is solved by a label correcting algorithm. Through Lagrangian multipliers, the interplay between the train service route design and passenger flow allocation subproblems is explored. To address the nonlinearities that arise in ADMM, we describe a new linearization technique for the quadratic penalty terms in the two subproblems by exploiting the rolling update mechanism of ADMM. The proposed approach is tested on synthetic and real-life instances from an urban rail company in China. The numerical results show that the proposed ADMM approach provides objective values that are on average 7.63% better than the conventional sequential approach. We also demonstrate that ADMM provides smaller optimality gaps in general when compared to a Lagrangian relaxation approach.},
  archive      = {J_EJOR},
  author       = {Tao Feng and Richard M. Lusby and Yongxiang Zhang and Qiyuan Peng},
  doi          = {10.1016/j.ejor.2023.07.031},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {146-170},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrating train service route design with passenger flow allocation for an urban rail transit line},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A vehicle routing problem with multiple service agreements.
<em>EJOR</em>, <em>313</em>(1), 129–145. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a logistics service provider which arranges transportation services to customers with different service agreements. The most prominent feature of this service agreement is the time period in which these customers send their orders and want to retrieve delivery information. After customers place their orders, they require information about the driver and an early indication of the arrival times. At the moment, this information needs to be provided. The order information of other customers with a different service agreement that needs to be serviced in the same period might still be unknown. Ultimately all customers have to be planned, constrained by the information provided to the customers in the earlier stage. In this paper, we investigate how the logistic service provider plans its routes and communicates the driver and arrival time information in the phase where not all customers are known (stage 1). Once all customer orders are known (stage 2), the final routes can be determined, which adhere to the already communicated driver and arrival time information from stage 1, minimizing total routing cost. For this problem, an exact algorithm is presented. This problem is solved using a novel tractable branch-and-bound method and re-optimization in stage 2. Detailed results are presented, showing the improvements of using re-optimization. We show that integrating the planning of the customers with the different service agreements leads to significant cost savings compared to treating the customers separately (as is currently done by most logistics service providers).},
  archive      = {J_EJOR},
  author       = {Vincent C.G. Karels and Walter Rei and Lucas P. Veelenturf and Tom Van Woensel},
  doi          = {10.1016/j.ejor.2023.07.029},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {129-145},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A vehicle routing problem with multiple service agreements},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Capacity and surgery partitioning: An approach for improving
surgery scheduling in the inpatient surgical department. <em>EJOR</em>,
<em>313</em>(1), 112–128. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In hospitals, efficiently scheduling operating rooms (ORs) is challenging, especially for an inpatient surgical department where complex and long surgeries with different surgery types are often performed in combination with surgeries on emergency patients. Although pooling ORs for surgeries could counter various uncertainties, all ORs might be disrupted. To improve the scheduling of the inpatient department, this paper develops a promising scheduling approach (namely OR capacity and surgery partitioning) which separates in surgery scheduling the more predictable elective surgeries (MPS) from the less predictable elective and emergency surgeries. To study the effect of partitioning, we apply Markov decision process, linear programming and simulation models, while incorporating surgeons’ preferences for using one OR for a whole day. Based on extensive numerical experiments, we report important findings. First, the partitioning can considerably reduce the cancellation rate without damaging the OR utilization. Meanwhile, an overflow must be allowed to schedule elective patients across OR subgroups rather than sticking to complete partitioning. Second, to better partition surgeries into subgroups, it is important to consider both surgery duration length and variability, while those surgeries with a better bin-packing nature should be given more consideration than those with a smaller surgery duration variability in the MPS ORs. Third, the benefit of partitioning increases with a larger surgery duration uncertainty and a growing non-elective demand. This framework is an easy-to-implement way to manage various variabilities and complexities in the inpatient surgical department. Our findings can help OR managers to better perform partitioning and guide surgery scheduling.},
  archive      = {J_EJOR},
  author       = {Lien Wang and Erik Demeulemeester and Nancy Vansteenkiste and Frank E. Rademakers},
  doi          = {10.1016/j.ejor.2023.08.017},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {112-128},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Capacity and surgery partitioning: An approach for improving surgery scheduling in the inpatient surgical department},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid differential evolution algorithm for the resource
constrained project scheduling problem with a flexible project structure
and consumption and production of resources. <em>EJOR</em>,
<em>313</em>(1), 92–111. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The resource constrained project scheduling problem with a flexible project structure and consumption and production of resources, involves making a selection of activities and scheduling these activities in order to minimize the makespan, subject to precedence and resource constraints. Since finding a feasible selection of activities is NP-hard, we introduce the concept of group graphs and restrict ourselves to instances with an acyclic group graph. For these instances, which represent many practical cases, we show how to make a feasible selection of activities in polynomial time and use this concept to schedule the selected activities using a hybrid differential evolution algorithm. We compare this algorithm with an algorithm from the literature on special cases of instances without consumption and production of resources, and show that our algorithm creates solutions of higher quality. Furthermore, to compare general instances, we develop an ant colony optimization algorithm that performs slightly better on special cases than the algorithm from literature and show that the hybrid differential evolution algorithm outperforms the ant colony optimization algorithm on general instances.},
  archive      = {J_EJOR},
  author       = {T. van der Beek and D. Souravlias and J.T. van Essen and J. Pruyn and K. Aardal},
  doi          = {10.1016/j.ejor.2023.07.043},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {92-111},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Hybrid differential evolution algorithm for the resource constrained project scheduling problem with a flexible project structure and consumption and production of resources},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mixed-integer programming models for irregular strip packing
based on vertical slices and feasibility cuts. <em>EJOR</em>,
<em>313</em>(1), 69–91. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The irregular strip-packing problem, also known as nesting or marker making, is defined as the automatic computation of a non-overlapping placement of a set of non-convex polygons onto a rectangular strip of fixed width and unbounded length, such that the strip length is minimized. Nesting methods based on heuristics are a mature technology, and currently, the only practical solution to this problem. However, recent performance gains of the Mixed-Integer Programming (MIP) solvers, together with the known limitations of the heuristics methods, have encouraged the exploration of exact optimization models for nesting during the last decade. Despite the research effort, there is room to improve the efficiency of the current family of exact MIP models for nesting. In order to bridge this gap, this work introduces a new family of continuous MIP models based on a novel formulation of the NoFit-Polygon Covering Model (NFP-CM), called NFP-CM based on Vertical Slices (NFP-CM-VS). Our new family of MIP models is based on a new convex decomposition of the feasible space of relative placements between pieces into vertical slices, together with a new family of valid inequalities, symmetry breakings, and variable eliminations derived from the former convex decomposition. Our experiments show that our new NFP-CM-VS models outperform the current state-of-the-art MIP models. Ten instances are solved up to optimality within one hour for the first time, including one with 27 pieces. Finally, we provide a detailed reproducibility protocol and dataset as supplementary material to allow the exact replication of our models, experiments, and results.},
  archive      = {J_EJOR},
  author       = {Juan J. Lastra-Díaz and M. Teresa Ortuño},
  doi          = {10.1016/j.ejor.2023.08.009},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {69-91},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mixed-integer programming models for irregular strip packing based on vertical slices and feasibility cuts},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A revisited branch-and-cut algorithm for large-scale
orienteering problems. <em>EJOR</em>, <em>313</em>(1), 44–68. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The orienteering problem is a route optimization problem which consists of finding a simple cycle that maximizes the total collected profit subject to a maximum distance limitation. In the last few decades, the occurrence of this problem in real-life applications has boosted the development of many heuristic algorithms to solve it. However, during the same period, not much research has been devoted to the field of exact algorithms for the orienteering problem. The aim of this work is to develop an exact method which is able to obtain the optimum in a wider set of instances than with previous methods, or to improve the lower and upper bounds in its disability. We propose a revisited version of the branch-and-cut algorithm for the orienteering problem which includes new contributions in the separation algorithms of inequalities stemming from the cycle problem, in the separation loop, in the variables pricing, and in the calculation of the lower and upper bounds of the problem. Our proposal is compared to three state-of-the-art algorithms on 258 benchmark instances with up to 7397 nodes. The computational experiments show the relevance of the designed components where 18 new optima, 76 new best-known solutions and 85 new upper-bound values were obtained.},
  archive      = {J_EJOR},
  author       = {Gorka Kobeaga and Jairo Rojas-Delgado and María Merino and Jose A. Lozano},
  doi          = {10.1016/j.ejor.2023.07.034},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {44-68},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A revisited branch-and-cut algorithm for large-scale orienteering problems},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using an exact bi-objective decoder in a memetic algorithm
for arc-routing (and other decoder-expressible) problems. <em>EJOR</em>,
<em>313</em>(1), 25–43. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the bi-objective Capacitated Arc Routing Problem (CARP) by considering two levels of solution interpretation: implicit and explicit solutions. An algorithm that translates implicit solutions into explicit solutions is called a decoder. In this work, the decoder takes as input a permutation of the required edges and generates a Pareto frontier of CARP solutions. While bi-objective CARP was our main focus and starting point, we could also use the proposed framework to solve a bi-objective version of the traveling salesman problem by plugging-in a different decoder. Recall that bi-objective CARP asks to service (the demands of) a set of required edges using a fleet of vehicles of limited capacity so as to minimize: (i) the total travelled distance and (ii) the length of the longest route. Any permutation s s of the required edges constitutes an implicit CARP solution. The decoder constructs all non-dominated explicit solutions that service the edges in the order indicated by s s , i.e. , the decoder is an exact algorithm that returns the optimal Pareto frontier subject to the service order s s . To achieve competitive CARP results it is also important to reinforce the decoder using a local search operator that acts on explicit routes (and that may change the service order s s ). For nine instances, the resulting algorithm was even able to find a new total-cost upper bound, improving upon the best solutions reported in the (considerably larger) mono-objective CARP literature. This shows that (some of) the proposed ideas can also be useful in single objective optimization: the second objective can be seen as a guide for the mono-objective search process.},
  archive      = {J_EJOR},
  author       = {Daniel Porumbel and Igor M. Coelho and El-Ghazali Talbi},
  doi          = {10.1016/j.ejor.2023.07.021},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {25-43},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Using an exact bi-objective decoder in a memetic algorithm for arc-routing (and other decoder-expressible) problems},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Order batching problems: Taxonomy and literature review.
<em>EJOR</em>, <em>313</em>(1), 1–24. (<a
href="https://doi.org/10.1016/j.ejor.2023.02.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Order Batching is a family of optimization problems related to the process of picking items in a warehouse as part of supply chain management. Problems classified into this category are those whose picking policy consists of grouping the orders received in a warehouse into batches, prior to starting the picking process. Once the batches have been formed, all items within the same batch are picked together on a single picking route. In this survey we review the optimization problems known in this family, focusing on manual picking systems and rectangular-shaped warehouses with only parallel and cross aisles, which is the most common warehouse configuration in the literature. First, we identify the decisions within the strategic, tactical, and operational levels that influence the picking task. Then, we characterize the optimization problems belonging to this family, whose objective function might differ. The identified problems are classified into a taxonomy proposed in this paper, which is designed to host future problems within this family. We also review the most outstanding papers by category and the strategies and algorithms proposed for the most relevant activities: batching, routing, sequencing, waiting, and assigning. To conclude, we outline the open issues and future paths of the topic under study.},
  archive      = {J_EJOR},
  author       = {Eduardo G. Pardo and Sergio Gil-Borrás and Antonio Alonso-Ayuso and Abraham Duarte},
  doi          = {10.1016/j.ejor.2023.02.019},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Order batching problems: Taxonomy and literature review},
  volume       = {313},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The impacts of innovation and trade openness on bank market
power: The proposal of a minimum distance cost function approach and a
causal structure analysis. <em>EJOR</em>, <em>312</em>(3), 1178–1194.
(<a href="https://doi.org/10.1016/j.ejor.2023.08.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study estimates output market power in the Chinese banking industry using the multi-output Lerner index. We propose a minimum distance cost function approach, which allows us to determine not only the level of market power but also the non-profit maximizers and efficiency level of Chinese banks. Following the first-stage analysis, we employ the generalized method of moment system estimator to evaluate the impacts of bank innovation and trade openness on market power in a multi-output banking context. In particular, we innovatively propose a causal structure analysis based on Wang and Blei (2019) to validate and verify the robustness of our results. We also assess this relationship for different types of bank ownership in China. The findings suggest that Chinese banks exhibit high market power in loans. Furthermore, the results show that bank innovation and trade openness have a significant negative impact on market power in loans, but a significant positive impact on market power in securities. The results also indicate a significantly negative impact of trade openness on overall market power. We find that higher levels of innovation among state-owned and joint-stock commercial banks improve the overall level of market power. The results suggest that, for all bank ownership types, trade openness has a significant negative impact on market power in loans but a significant positive impact on market power in securities. The impact on the overall level of market power is consistently significant and negative.},
  archive      = {J_EJOR},
  author       = {Hirofumi Fukuyama and Mike Tsionas and Yong Tan},
  doi          = {10.1016/j.ejor.2023.08.016},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1178-1194},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The impacts of innovation and trade openness on bank market power: The proposal of a minimum distance cost function approach and a causal structure analysis},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Kernel quantile estimators for nested simulation with
application to portfolio value-at-risk measurement. <em>EJOR</em>,
<em>312</em>(3), 1168–1177. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nested simulation has been widely used in portfolio risk measurement in recent years. We focus on one risk measure, value at risk (VaR), and study a kernel quantile estimator (KQE) for nested simulation to estimate this risk. We analyze the bias, variance, and mean squared error (MSE), based on which we show that the variance is reduced in the lower-order terms, while in some cases bias could be reduced in the dominant term. For practical implementation, we propose an efficient bootstrap-based algorithm to guide kernel bandwidth selection and budget allocation in nested simulation. We also conduct numerical experiments to show that KQE works quite well at different significance levels compared with the widely used sample quantile.},
  archive      = {J_EJOR},
  author       = {Xiaoyu Liu and Xing Yan and Kun Zhang},
  doi          = {10.1016/j.ejor.2023.07.040},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1168-1177},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Kernel quantile estimators for nested simulation with application to portfolio value-at-risk measurement},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimization models for cloud seeding network design and
operations. <em>EJOR</em>, <em>312</em>(3), 1146–1167. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water shortage has become a significant challenge in many regions, affecting sectors such as agriculture, energy, industry, and the economy. Based on this subject matter and considering cloud seeding as an emerged water achieving promising technique, this paper provides an effective and innovative optimization approach for cloud seeding. This approach involves location analysis and operational planning, which offers significant potential for addressing water shortage challenges. The proposed approach considers atmospheric conditions, functional properties of facilities, seeding method variants, and cloud seeding system vulnerabilities as strategic programming for integrated facility network design. Additionally, operational planning, including flight routing and ground-based facility scheduling during rainfall storms, is considered to manipulate storms according to atmospheric conditions and systemic/facility operational constraints. To this end, the paper proposes a multi-objective mixed-integer linear programming model for facility location, which uses an innovative and application depended point-to-polygon covering algorithm, with the principal objective of maximization of spatial coverage. Moreover, a bi-objective mixed-integer linear programming model for seeding operations is developed based on the optimally located facilities in the strategic model, which uses an innovative line-to-polygon covering algorithm. The first objective of this model is to maximize precipitation augmentation, while the second objective of the both models is to minimize total system-wide costs. Finally, the applications of the proposed models and the managerial insights are also illustrated in a real case study domain.},
  archive      = {J_EJOR},
  author       = {Mohammad Sadeghi and Saeed Yaghoubi},
  doi          = {10.1016/j.ejor.2023.07.041},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1146-1167},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimization models for cloud seeding network design and operations},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluating different groups of mutual funds using a
metafrontier approach: Ethical vs. Non-ethical funds. <em>EJOR</em>,
<em>312</em>(3), 1134–1145. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ethical mutual funds (MFs) have grown in popularity over the past few years. However, the investors generally have concerns about their profitability compared to the investment group of non-ethical MFs. Performance comparison could be a potential way to address this concern, but the differences in their essential investment objectives raise the issue of heterogeneity between the ethical and non-ethical investment groups. Motivated by addressing this heterogeneity, this article proposes a general nonconvex metafrontier framework for comparing different investment groups of MFs. Investment groups can exhibit heterogeneity from different perspectives, such as from regulations, resource constraints, to name a few. To provide a rather complete framework for estimating the frontiers, the diversified, convex and nonconvex evaluation approaches are adapted and presented in a multi-moment setting. The proposed metafrontier framework is then applied to an empirical example where the investment groups are heterogeneous from the ethical perspective. The empirical results suggest that the ethical constraint does not necessarily lead to a worse financial performance; quite the contrary, the results provide some evidence on the outperformance of ethical MFs over the non-ethical MFs.},
  archive      = {J_EJOR},
  author       = {Qianying Jin and Antonella Basso and Stefania Funari and Kristiaan Kerstens and Ignace Van de Woestyne},
  doi          = {10.1016/j.ejor.2023.07.019},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1134-1145},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Evaluating different groups of mutual funds using a metafrontier approach: Ethical vs. non-ethical funds},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable subgradient tree boosting for prescriptive
analytics in operations management. <em>EJOR</em>, <em>312</em>(3),
1119–1133. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the success of gradient boosting approaches in machine learning and driven by the need for explainable prescriptive analytics approaches in operations management (OM), we propose subgradient tree boosting (STB) as an explainable prescriptive analytics approach to solving convex stochastic optimization problems that frequently arise in OM. The STB approach combines the well-known method of subgradient descent in function space with sample average approximation, and prescribes decisions from a problem-specific loss function, historical demand observations, and prescriptive features. The approach provides a decision-maker with detailed explanations for the prescribed decisions, such as a breakdown of individual features’ impact. These explanations are particularly valuable in practice when the decision-maker has the discretion to adjust the recommendations made by a decision support system. We show how subgradients can be derived for common single-stage and two-stage stochastic optimization problems; demonstrate the STB approach’s applicability to two real-world, complex capacity-planning problems in the service industry; benchmark the STB approach’s performance against those of two prescriptive approaches—weighted sample average approximation (wSAA) and kernelized empirical risk minimization (kERM); and show how the STB approach’s prescriptions can be explained by estimating the impact of individual features. The results suggest that the quality of the STB approach’s prescriptions is comparable to that of wSAA’s and kERM’s prescriptions while also providing explanations.},
  archive      = {J_EJOR},
  author       = {Pascal M. Notz and Richard Pibernik},
  doi          = {10.1016/j.ejor.2023.08.037},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1119-1133},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Explainable subgradient tree boosting for prescriptive analytics in operations management},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analytics-driven complaint prioritisation via deep learning
and multicriteria decision-making. <em>EJOR</em>, <em>312</em>(3),
1108–1118. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complaint analysis is an essential business analytics application because complaints have a strong influence on customer satisfaction (CSAT). However, the process of categorising and prioritising complaints manually can be extremely time consuming for large companies. In this paper, we propose a framework for automatic complaint labelling and prioritisation using text analytics and operational research techniques. The labelling step of the training set is performed using a simple weighting approach from the multiple-criteria decision-making (MCDM) literature, while transformer-based deep learning (DL) techniques are used for text classification. We define two priority classes, namely, urgent complaints and other claims, and develop a system for automatic complaint categorisation. Our experimental results show that excellent predictive performance can be achieved with state-of-the-art text classification models. In particular, BETO, a bidirectional encoder representations from transformers (BERT) model trained on a large Spanish corpus, reaches an accuracy (ACCU) and area under the curve (AUC) of 92.1% and 0.9785, respectively. This positive result translates into a successful complaint prioritisation scheme, which improves CSAT and reduces the churn rate.},
  archive      = {J_EJOR},
  author       = {Carla Vairetti and Ignacio Aránguiz and Sebastián Maldonado and Juan Pablo Karmy and Alonso Leal},
  doi          = {10.1016/j.ejor.2023.08.027},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1108-1118},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Analytics-driven complaint prioritisation via deep learning and multicriteria decision-making},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reconciling business analytics with graphically initialized
subspace clustering for optimal nonlinear pricing. <em>EJOR</em>,
<em>312</em>(3), 1086–1107. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The relationship between price and quantity in nonlinear pricing transcends simple proportionality, as conditional rebates and discounts may be contingent upon the quantity of goods or services purchased by consumers. This dynamic introduces significant challenges for both consumers and business operators because incomplete information arises from the inherent uncertainty of consumer behavior. In light of this, the present research elucidates the pursuit of optimal nonlinear pricing strategies by business operators through an innovative data-driven approach. Our contributions encompass two distinctive facets: a novel unsupervised spectral clustering method, termed graphically initialized subspace clustering, and a decision optimization framework. The proposed data-driven method introduces an optimization problem aimed at minimizing subspace partitioning costs, leveraging the efficient utilization of a mixture multivariate skewed t t distribution to effectively capture heavy users and to characterize their parametric behavioral patterns. In addition, the decision optimization component builds upon the aforementioned method, employing a convex optimization algorithm to enable seamless modification of attributes in nonlinear pricing, while ensuring revenue consistency during pre- and post-modification. Notably, we substantiate the interpretability and practical applicability of our proposed methodology in the realm of business analytics, through empirical analysis utilizing real-world data obtained from a cellular carrier. The findings of this study confirm the efficacy and viability of our approach in enabling business operators to navigate the complexities of nonlinear pricing optimization with confidence and informed decision-making.},
  archive      = {J_EJOR},
  author       = {Claire Y.T. Chen and Edward W. Sun and Wanyu Miao and Yi-Bing Lin},
  doi          = {10.1016/j.ejor.2023.07.011},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1086-1107},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Reconciling business analytics with graphically initialized subspace clustering for optimal nonlinear pricing},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). First passage times in portfolio optimization: A novel
nonparametric approach. <em>EJOR</em>, <em>312</em>(3), 1074–1085. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a portfolio optimization procedure that aims to minimize the intra-horizon (IH) risk subject to a minimum expected time to achieve a target cumulative return. To estimate the first passage probabilities and the expected time a novel nonparametric method and a new Markov chain order determination approach are developed. The optimization framework proposed allows us to include novel path-dependent measures of risk and return in the asset allocation problem. An empirical application to S&amp;P 100 companies, a risk-free asset and stock indices is provided. Our empirical results suggest that the proposed framework exhibits more consistency between in-sample and out-of-sample performance than the mean-variance model and an alternative optimization problem that minimizes the MaxVaR measure of Boudoukh et al. (2004). Overall, the portfolio optimization approach we introduce results in higher out-of-sample annualized returns for relatively low levels of IH risk.},
  archive      = {J_EJOR},
  author       = {Gabriel Zsurkis and João Nicolau and Paulo M.M. Rodrigues},
  doi          = {10.1016/j.ejor.2023.07.044},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1074-1085},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {First passage times in portfolio optimization: A novel nonparametric approach},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Strategic incentives for comparative advertising investments
in non-zero-sum competition and economic consequences. <em>EJOR</em>,
<em>312</em>(3), 1059–1073. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Persuasive advertising is viewed as an effective tool to affect willingness-to-pay of customers for a firm’s product. In their use of persuasive advertising, firms typically face the choice of whether to tout the benefits of their own products without mentioning rival products ( self-promotional advertising) or make references to rival products while promoting their own products ( comparative advertising). A concomitant (and intrinsic) issue in the use of comparative advertising is whether to portray rival products negatively or positively and the level of comparative intensity (the valence of comparative advertising). Although it is often criticized and disapproved of by business decision makers and its effectiveness has been a subject of contentious debate, comparative advertising is used prevalently by firms in consumer goods markets. In this paper, we examine the strategic incentives of competing firms to abandon their self-promotional advertising in favor of comparative advertising, the ways in which they choose a positive or negative valence in their comparative advertising, and the economic consequences of these decisions. We consider a simultaneous (and a leader-follower Stackelberg) game between two asymmetric firms vying for customers in a market that is not characterized by zero-sum competition. We also study the possibility that comparative advertising elicits positive or negative market externalities on the advertised product. We seek market- and channel-based explanations for why firms may opt to undertake comparative advertising (in lieu of self-promotional advertising) and use its constructive or combative form. We show that the use of comparative advertising can be an effective tactic in attaining certain objectives and when carefully executed in certain ways, and detrimental to not only the advertising firm but also the product category in other ways.},
  archive      = {J_EJOR},
  author       = {Arda Yenipazarli},
  doi          = {10.1016/j.ejor.2023.07.030},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1059-1073},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Strategic incentives for comparative advertising investments in non-zero-sum competition and economic consequences},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Price volatility of revenue managed goods: Implications for
demand and price elasticity. <em>EJOR</em>, <em>312</em>(3), 1039–1058.
(<a href="https://doi.org/10.1016/j.ejor.2023.07.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Revenue management practices are widely employed in various sectors. These mechanisms dynamically adjust prices observed by consumers typically through the control of price classes and their availability. As such, these pricing environments tend to exhibit some predictable behaviors as the product approaches the expiration or consumption date but may also result in varying degrees of price volatility. Such price paths may ultimately alter consumer behavior, e.g., via delayed purchase timing (i.e., strategic behavior) or different willingness to pay. Accordingly, we assess consumers’ responses to the realized price changes induced by revenue management mechanisms, using fare and sales data from aviation markets. Our empirical analyses reveal that price elasticity decreases (in absolute terms) in the degree of price volatility, whereas the realized demand is lower when price volatility is higher. This suggests that as prices become more volatile, consumers become more oblivious to these price fluctuations and may end up paying more for the products—thereby confirming and generalizing a behavior previously documented for consumer packaged goods (CPGs), which follow dramatically different pricing regimes. While this may suggest support for higher and more volatile prices, we find that given the higher prices, the overall demand decreases, highlighting a delicate trade-off firms face. To distill the insights from the empirical analyses, we formulate two hypotheses, which we test in a laboratory setting by means of an ad hoc experiment.},
  archive      = {J_EJOR},
  author       = {Chiara Morlotti and Benny Mantin and Paolo Malighetti and Renato Redondi},
  doi          = {10.1016/j.ejor.2023.07.018},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1039-1058},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Price volatility of revenue managed goods: Implications for demand and price elasticity},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the zero-inventory-ordering policy in the inventory
routing problem. <em>EJOR</em>, <em>312</em>(3), 1024–1038. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Inventory Routing Problem (IRP) aims at determining the best distribution plan of a certain commodity from a supplier to a set of customers over a given planning horizon. Customers face a per period consumption and the plan has to be such that they can always satisfy it. The aim is to minimize the total cost of the distribution plan, which is given by the sum of routing and inventory holding cost. A replenishment strategy that has become common in the recent literature is the Maximum Level (ML) strategy, where no restriction is imposed on when the customers are visited and what the quantity delivered is, provided that a maximum inventory level at each customer (corresponding to the customer′s warehouse capacity) is not exceeded. This strategy is highly flexible and this clearly provides cost advantages. However, it might also create inconveniences to customers, who might receive visits when their inventory level is still relatively high. Towards addressing this issue, we study in this paper the Zero-Inventory-Ordering (ZIO) replenishment strategy for the IRP, where customers can be served only when their inventory level is zero. The aim is to analyze the impact of a policy which is more customer-oriented than the ML. The analysis is made in terms of advantages from the customers′ perspective and disadvantages from the system perspective, i.e., increase of the total cost. We propose a formulation based on two-commodity flow variables, and strengthen it through new valid inequalities tailored for our problem as well as with valid inequalities inherited from the literature on the IRP. We develop branch-and-cut algorithms and experimentally compare the ZIO and ML policies on benchmark IRP instances. The results show that the application of the ZIO policy allows to reduce the inventory costs at the customers without substantially increasing, or even decreasing, the number of visits to them. This comes at the expense of an increase of the total costs. Results also show that the increase in total cost is inversely proportional to the relative weight of the inventory costs at the customers. More precisely, inventory costs at customers are decreased by more than 20% on average while total cost increases, on average, by 17.6% when the inventory costs are high and of 9.2% when inventory costs are low. In addition, we generated new sets of instances in which inventory costs are more aligned with practical applications with respect to what happens in the benchmark IRP instances. Results show how the ZIO policy consistently provides solutions where the inventory cost to customers is lower than the one associated with the ML policy. Also, the gap in total cost reduces when the inventory cost at customers increases.},
  archive      = {J_EJOR},
  author       = {Ali Diabat and Nicola Bianchessi and Claudia Archetti},
  doi          = {10.1016/j.ejor.2023.07.013},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1024-1038},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the zero-inventory-ordering policy in the inventory routing problem},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Roles of reciprocity and fairness concerns in
airline-airport systems with environmental considerations.
<em>EJOR</em>, <em>312</em>(3), 1011–1023. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operations of airports and airlines are highly inter-dependent. Over the past decades, we have witnessed all kinds of alliances and coordination between airports and airlines. The observed industrial practices uncover that airports reward their airline partners with aligned objectives such as those in environmental sustainability, thereby displaying the positive reciprocity behaviors. However, the airport&#39;s preferential treatment towards a particular airline may induce the feeling of unfairness to the other airlines, leading to non-trivial peer-induced fairness concerns. In this paper, by building game-theoretic mathematical models, we analytically explore the impacts of reciprocity and fairness concerns on environmental sustainability in a single-airport two-airlines system. Our analysis highlights the importance of the cardinal relationship between an airport and airline(s) and shows that (i) a higher level of reciprocity of airport towards an airline helps improve the greening level, (ii) the presence of peer-induced fairness concern yields a lower revenue-sharing fraction of the fairness concerned airline, and (iii) improving the passengers’ environmental awareness is favorable for enhancing the environmental sustainability. To enhance research rigor, we examine various extended models. We show that the theoretical findings derived in the main model remain robust in the extensions.},
  archive      = {J_EJOR},
  author       = {Aasheesh Dixit and Tsan-Ming Choi and Patanjal Kumar and Suresh K. Jakhar},
  doi          = {10.1016/j.ejor.2023.07.016},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {1011-1023},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Roles of reciprocity and fairness concerns in airline-airport systems with environmental considerations},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Split-demand multi-trip vehicle routing problem with
simultaneous pickup and delivery in airport baggage transit.
<em>EJOR</em>, <em>312</em>(3), 996–1010. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we focus on the routing and scheduling of multi-carriage transit trains for airport baggage transit. It is modeled as a vehicle routing problem with cross-route dependencies caused by side constraints, including split demand, multiple trips per vehicle, and simultaneous pickup and delivery. Besides, some other practical constraints such as time windows, baggage release time, baggage waiting time, and priority of unloading are taken into account in the implementation. The joint consideration of these characteristics brings a unique challenge to determine the start time of each service for aircraft due to the interdependencies across vehicle routes. Thus, we adopt topological sort to construct the directed acyclic graph and then derive the flight service time. Based on that, we develop an Adaptive Large Neighborhood Search (ALNS) algorithm. Moreover, in order to examine the moves quickly, a two-stage solution evaluation method is proposed, where the single tour is checked based on the segment-based evaluation method in the first stage, and the complete solution is checked using the topological sort in the second stage. The results demonstrate the superiority of our algorithm in computational time and solution quality. In addition, some insightful conclusions are drawn through detailed analyses.},
  archive      = {J_EJOR},
  author       = {Zhenzhen Zhang and Yuxin Che and Zhe Liang},
  doi          = {10.1016/j.ejor.2023.07.028},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {996-1010},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Split-demand multi-trip vehicle routing problem with simultaneous pickup and delivery in airport baggage transit},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A branch-cut-and-price algorithm for the time-dependent
electric vehicle routing problem with time windows. <em>EJOR</em>,
<em>312</em>(3), 978–995. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adoption of electric vehicles (EVs) within last-mile deliveries is considered one of the key transformations towards more sustainable logistics. The inclusion of EVs introduces new operational constraints to the models such as a restricted driving range and the possibility to perform recharges en route. The discharge of the typical batteries is complex and depends on several variables, including the vehicle travel speed, but most of the approaches assume that the energy consumption depends only on the distance traveled. This becomes relevant in different logistics contexts, such as last-mile distrubtion in large cities and mid-haul logistics in retail, where traffic congestion affects severely the travel speeds. In this paper, we introduce a general version of the Time-Dependent Electric Vehicle Routing Problem with Time Windows (TDEVRPTW), which incorporates the time-dependent nature of the transportation network both in terms of travel times and the energy consumption. We propose a unifying framework to integrate other critical variable times arising during the operations previously studied in the literature, such as the time-dependent waiting times and non-linear charging times. We propose a state of the art branch-cut-and-price (BCP) algorithm. Based on extensive computational experiments, we show that the approach is very effective solving instances with up to 100 customers with different time dependent configurations. From a managerial standpoint, our experiments indicate that neglecting the travel speeds can affect the quality of the solutions obtained, where up to 40 percent of the infeasibilities induced by neglecting the time dependency can be caused by exceeding the battery capacity.},
  archive      = {J_EJOR},
  author       = {Gonzalo Lera-Romero and Juan José Miranda Bront and Francisco J. Soulignac},
  doi          = {10.1016/j.ejor.2023.06.037},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {978-995},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A branch-cut-and-price algorithm for the time-dependent electric vehicle routing problem with time windows},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal location of remote dental units. <em>EJOR</em>,
<em>312</em>(3), 969–977. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dental care, though critical, may not be accessible for many rural populations. Remote dental units (RDUs) can address the gap in access by providing basic services to rural areas, since recent digital health advancements enable close data integration between field RDUs and regional medical center clinical experts. Yet, the economic viability of this remote/hybrid care delivery effort has not been clearly established. We explore the economics of a major dental hospital operating RDUs in a distant rural area. Specifically, we characterize the optimal location of an RDU and examine the impact of operating this RDU on the hospital’s profit. We prove that the ideal scenario, from a patient-coverage perspective, is to put the RDU far enough away from the hospital such that patients accessing the RDU are distinct from patients accessing the hospital. This positioning avoids coverage overlap (market cannibalization). However, we show that such a placement may not always be optimal for the hospital’s profit, and we derive conditions under which the optimal patient coverage for the hospital and the RDU overlaps. Our results remain consistent for a hospital operating an RDU at different locations. The RDU will not be deployed in another location if the previous two locations have some coverage overlap. Our characterization of the profit-maximizing location provides hospitals with a practical guideline by quantifying the key trade-off between service expansion and the costs incurred by sending the provider team to remote, underserved locations. Our findings lead to important operational implications for regional dental care service by RDUs.},
  archive      = {J_EJOR},
  author       = {Jong Youl Lee and Balaraman Rajan and Abraham (Avi) Seidmann},
  doi          = {10.1016/j.ejor.2023.07.025},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {969-977},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal location of remote dental units},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A heuristic approach to the stochastic capacitated single
allocation hub location problem with bernoulli demands. <em>EJOR</em>,
<em>312</em>(3), 954–968. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hubs are critical components of transportation and distribution systems, and hub networks play a special role in freight and passenger transportation services worldwide. This paper studies a capacitated single allocation hub location problem with Bernoulli demands. Since the origin-destination (OD) demands are stochastic in nature, and the nodes are allocated to hubs before knowing their realized values, the actual total demand allocated to each hub is uncertain. Therefore, demand can exceed the capacity of hubs, rendering a need for outsourcing. The problem is studied under two distinct outsourcing policies, namely the facility and customer outsourcing. Mathematical models are developed for each case as two-stage stochastic programs. Deterministic equivalent formulations are obtained for problems, assuming a homogeneous demand distribution for all OD pairs. A Tabu Search-based algorithm is presented as a solution approach to deal with large problem instances. Extensive computational tests demonstrate the outstanding performance of the developed models and the metaheuristic procedure in terms of solution quality and computational time. The relevance of using stochastic programming approach for the problems is demonstrated via computational results. This study also reports solutions for problems with 200 nodes for the first time.},
  archive      = {J_EJOR},
  author       = {Abdullah Zareh Andaryan and Kasra Mousighichi and Nader Ghaffarinasab},
  doi          = {10.1016/j.ejor.2023.07.015},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {954-968},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A heuristic approach to the stochastic capacitated single allocation hub location problem with bernoulli demands},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inverse optimization of integer programming games for
parameter estimation arising from competitive retail location selection.
<em>EJOR</em>, <em>312</em>(3), 938–953. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When determining store locations, competing retailers must take customers’ store choice into consideration. Customers predominantly select which store to visit based on price, accessibility, and convenience. Incumbent retailers can estimate the weight of these factors (customer attraction parameters) using granular historical data. Their location decision under full information and simultaneous competition translates into an integer programming game. Unlike incumbents, new entrants lack this detailed information; however, they can observe the resulting location structure of incumbents. Assuming the observed location structure is (near-)optimal for all incumbent retailers, a new entrant can use these observations to estimate customer attraction parameters. To facilitate this estimation, we propose an “inverse optimization approach” for integer programming games (IPGs), enabling a new entrant to identify parameters that lead to the observed equilibrium solutions. We solve this “inverse IPG” via decomposition by solving a master problem and a subproblem. The master problem identifies parameter combinations for which the observations represent (approximate) Nash equilibria compared with optimal solutions enumerated in the subproblem. This row-generation approach extends prior methods for inverse integer optimization to competitive settings with (approximate) equilibria. We compare the decision-making of new entrants selecting locations based on scenarios, or information about the underlying distribution of customer attraction parameters (expected values), with new entrants using inversely estimated parameters for their location decisions. New entrants who rely on inversely optimized parameters can improve their profits. On average over a large set of synthetic numerical experiments, we observe improvements of 4–11%. This benefit can be realized with as little as one or two observations, yet additional observations help to increase prediction reliability significantly.},
  archive      = {J_EJOR},
  author       = {Tobias Crönert and Layla Martin and Stefan Minner and Christopher S. Tang},
  doi          = {10.1016/j.ejor.2023.06.041},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {938-953},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Inverse optimization of integer programming games for parameter estimation arising from competitive retail location selection},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating efforts for product development and market
penetration. <em>EJOR</em>, <em>312</em>(3), 927–937. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we build a decision model to explore an innovative firm’s budget allocation problem, which needs to be solved for each successive generation of a product. The firm introduces the product to the market through a distributor while aiming to maximize the market potential. This goal can be achieved by investing in R&amp;D and increasing availability using subsidies registered to the distributor. We analyze the problem using a game theoretical model and provide a guideline for the funding strategy. We show that the optimal budget allocation decision is characterized by two budget thresholds and a threshold on the cost efficiency of R&amp;D. We identify and analyze the effects of two significant parameters, total available budget and efficiency level of R&amp;D, on the optimal solution. In addition, we assess the model’s applicability by examining the expected excess budget requirement and the distributor’s expected profit. We provide valuable managerial insights on when and how to prioritize the two components of the budget.},
  archive      = {J_EJOR},
  author       = {Ece Zeliha Demirci and Nesim Erkip},
  doi          = {10.1016/j.ejor.2023.07.017},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {927-937},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrating efforts for product development and market penetration},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An actor-critic algorithm with policy gradients to solve the
job shop scheduling problem using deep double recurrent agents.
<em>EJOR</em>, <em>312</em>(3), 910–926. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a method that applies Deep Reinforcement Learning, an approximate dynamic programming procedure using deep neural networks, to the job shop scheduling problem (JSSP). The aim is to show that a greedy-like heuristic trained on a subset of problems, can effectively generalize to some extent to unseen instances, and be competitive compared to other methods. We model the JSSP as a Markov Decision Process and we exploit the efficacy of reinforcement learning to solve the problem. We adopt an actor-critic scheme based on policy gradients, specifically the Proximal Policy Gradient method, where the action taken by the agent is influenced by policy considerations on the state-value function. The procedures take into account the challenging nature of JSSP, where the state and the action space change for every instance and after each decision. To tackle this variability, we introduced a novel model based on two incident Long-Short Term Memory networks, followed by an encoding model, different in structure for both the actor and the critic. Experiments show the algorithm reaches good solutions in a short time, proving that is possible to generate new greedy heuristics just from learning-based methodologies. We compared our algorithms against several established heuristics, an adaptive method, a commercial solver based on branch and cut, and another approach based on Deep Reinforcement Learning, proving the validity of the proposed method in terms of time and makespan. The model can generalize, to some extent, to larger problems originating from a different distribution.},
  archive      = {J_EJOR},
  author       = {Marta Monaci and Valerio Agasucci and Giorgio Grani},
  doi          = {10.1016/j.ejor.2023.07.037},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {910-926},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An actor-critic algorithm with policy gradients to solve the job shop scheduling problem using deep double recurrent agents},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Flexible job-shop scheduling with transportation resources.
<em>EJOR</em>, <em>312</em>(3), 890–909. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses an extension of the flexible job-shop scheduling problem where transportation resources are explicitly considered when moving jobs from one machine to another. Operations should be assigned to and scheduled on machines and vehicles and the routes of vehicles should be determined. We extend the classical disjunctive graph model to include transportation operations and exploit the graph in an integrated approach to solve the problem. We propose a metaheuristic using a neighborhood function that allows a large set of moves to be explored. As the exact computation of the makespan of every move is time-consuming, we present a move evaluation procedure that runs in constant time (which does not depend on the size of the instance) to choose a promising move in the neighborhood of a solution. This move evaluation procedure is used in a tabu search framework. Computational results show the efficiency of the proposed approach, the quality of the move evaluation procedure and the relevance of explicitly modeling transportation resources. New benchmark instances are also proposed.},
  archive      = {J_EJOR},
  author       = {Lucas Berterottière and Stéphane Dauzère-Pérès and Claude Yugma},
  doi          = {10.1016/j.ejor.2023.07.036},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {890-909},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Flexible job-shop scheduling with transportation resources},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Markov decision processes with burstiness constraints.
<em>EJOR</em>, <em>312</em>(3), 877–889. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a Markov Decision Process (MDP), over a finite or infinite horizon, augmented by so-called ( σ , ρ ) (σ,ρ) -burstiness constraints. Such constraints, which had been introduced within the framework of network calculus, are meant to limit some additive quantity to a given rate over any time interval, plus a term which allows for occasional and limited bursts. We introduce this class of constraints for MDP models, and formulate the corresponding constrained optimization problems. Due to the burstiness constraints, constrained optimal policies are generally history-dependent. We use a recursive form of the constraints to define an augmented-state model, for which sufficiency of Markov or stationary policies is recovered and the standard theory may be applied, albeit over a larger state space. The analysis is mainly devoted to a characterization of feasible policies, followed by application to the constrained MDP optimization problem. A simple queuing example serves to illustrate some of the concepts and calculations involved.},
  archive      = {J_EJOR},
  author       = {Michal Golan and Nahum Shimkin},
  doi          = {10.1016/j.ejor.2023.07.045},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {877-889},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Markov decision processes with burstiness constraints},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-agent single-machine scheduling with a rate-modifying
activity. <em>EJOR</em>, <em>312</em>(3), 866–876. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study single-machine scheduling problems involving a rate-modifying activity and two competing agents with due-date-related functions. Classical scheduling models assume that job processing times remain constant over time; however, in real-world settings, processing times may change due to factors such as technological upgrades or machine maintenance. We complement this with the notion of multiple independent agents competing over the use of a shared resource, each with their own motives. These considerations allow us to model the upcoming trend of the sharing economy, where resources are shared amongst independent competitors in the market. We aim to model these scenarios by considering a variety of scheduling criteria for each agent, including the makespan, the number of late jobs, and the total late work. To account for the change in processing times, we consider an optional rate-modifying activity that once completed, results in a reduction in subsequent job processing times. We show that problems involving the total late work are binary NP NP -hard and propose efficient pseudo-polynomial dynamic programming algorithms for solving these problems. We also show that the remaining problems are solvable in polynomial time.},
  archive      = {J_EJOR},
  author       = {Johnson Phosavanh and Daniel Oron},
  doi          = {10.1016/j.ejor.2023.08.002},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {866-876},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Two-agent single-machine scheduling with a rate-modifying activity},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The robust cyclic job shop problem. <em>EJOR</em>,
<em>312</em>(3), 855–865. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the cyclic job shop problem where the task durations are uncertain and belong to a polyhedral uncertainty set. We formulate the cyclic job shop problem as a two-stage robust optimization model. The cycle time and the execution order of tasks executed on the same machines correspond to the here-and-now decisions and have to be decided before the realization of the uncertainty. The starting times of tasks corresponding to the wait-and-see decisions are delayed and can be adjusted after the uncertain parameters are known. In the last decades, different solution approaches have been developed for two-stage robust optimization problems. Among them, the use of affine policies, row and row-and-column generation algorithms are the most common. In this paper, we propose a branch-and-bound algorithm to tackle the robust cyclic job shop problem with cycle time minimization. The algorithm uses, at each node of the search tree, a robust version of the Howard’s algorithm to derive a lower bound on the optimal cycle time. Moreover, we design a row generation algorithm and a column-and-row generation algorithm and compare it to the branch-and-bound method. Finally, encouraging preliminary results on numerical experiments performed on randomly generated instances are presented.},
  archive      = {J_EJOR},
  author       = {Idir Hamaz and Laurent Houssin and Sonia Cafieri},
  doi          = {10.1016/j.ejor.2023.07.042},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {855-865},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The robust cyclic job shop problem},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combining optimisation and simulation using logic-based
benders decomposition. <em>EJOR</em>, <em>312</em>(3), 840–854. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operations Research practitioners often want to model complicated functions that are difficult to encode in their underlying optimisation framework. A common approach is to solve an approximate model, and then use a simulation to evaluate the true objective value of one or more solutions. We propose a new approach to integrating simulation into the optimisation model itself. The idea is to run the simulation at each incumbent solution to a master problem. The simulation results are then used to guide the trajectory of the optimisation model itself using logic-based Benders cuts. We test the approach on a class of stochastic resource allocation problems with monotonic performance measures. We derive strong novel Benders cuts that are provably valid for all problems of the given form. We consider two concrete examples: a nursing home shift scheduling problem, and an airport check in counter allocation problem. While previous papers on these applications could only approximately solve realistic instances, we are able to solve them exactly within a reasonable amount of time. Moreover, while those papers account for the inherent variance of the problem by including estimates of the underlying random variables as model parameters, we are able to compute sample-average approximations to optimality with up to 100 scenarios.},
  archive      = {J_EJOR},
  author       = {M.A. Forbes and M.G. Harris and H.M. Jansen and F.A. van der Schoot and T. Taimre},
  doi          = {10.1016/j.ejor.2023.07.032},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {840-854},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Combining optimisation and simulation using logic-based benders decomposition},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Supply chain network design with financial considerations: A
comprehensive review. <em>EJOR</em>, <em>312</em>(3), 799–839. (<a
href="https://doi.org/10.1016/j.ejor.2023.02.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supply chain network design (SCND) is a large and growing area of research. Although SCND has a remarkable effect on companies’ main financial accounts, our examination reveals that most of the models only investigate roughly the costs and revenues related to the design project and neglect other significant financial factors linked to its future performance. This study carries out a comprehensive survey of SCND articles published from 2008 to 2021 by systematically selecting 689 journal papers and exploring their types, paradigms, modelling methods, and uncertainty factors, with special attention to financial considerations. We develop a framework to classify and analyse all these aspects. We also analyse the most recent survey studies related to SCND models, notably facility location problems (FLPs), hub location problems (HLPs), reverse logistics (RL), and closed-loop supply chains (CLSC). Compared to these studies, a broad range of topics is added to the search process. We recommend a framework for detecting and reporting financial perspectives by employing useful concepts, e.g., the duality principle, charts of accounts, and financial statements analysis. We identify several research gaps and offer future research directions such as using specific complementary equations, e.g., depreciation, amortisation, and inventory valuation, to improve the applicability of the SCND models.},
  archive      = {J_EJOR},
  author       = {Hamed Jahani and Babak Abbasi and Jiuh-Biing Sheu and Walid Klibi},
  doi          = {10.1016/j.ejor.2023.02.033},
  journal      = {European Journal of Operational Research},
  month        = {2},
  number       = {3},
  pages        = {799-839},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Supply chain network design with financial considerations: A comprehensive review},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning in bank merger prediction: A text-based
approach. <em>EJOR</em>, <em>312</em>(2), 783–797. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the role of textual information in a U.S. bank merger prediction task. Our intuition behind this approach is that text could reduce bank opacity and allow us to understand better the strategic options of banking firms. We retrieve textual information from bank annual reports using a sample of 9,207 U.S. bank-year observations during the period 1994-2016. To predict bidders and targets, we use textual information along with financial variables as inputs to several machine learning models. We find that when we jointly use textual information and financial variables as inputs, the performance of our models is substantially improved compared to models using a single type of input. Furthermore, we find that the performance improvement due to the inclusion of text is more noticeable in predicting future bidders, a task which is less explored in the relevant literature. Therefore, our findings highlight the importance of textual information in a bank merger prediction task.},
  archive      = {J_EJOR},
  author       = {Apostolos G. Katsafados and George N. Leledakis and Emmanouil G. Pyrgiotakis and Ion Androutsopoulos and Manos Fergadiotis},
  doi          = {10.1016/j.ejor.2023.07.039},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {783-797},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Machine learning in bank merger prediction: A text-based approach},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Long-term dynamic asset allocation under asymmetric risk
preferences. <em>EJOR</em>, <em>312</em>(2), 765–782. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine the impact of return predictability and parameter uncertainty on long-term portfolio allocations when investors’ utility function quantifies their asymmetric behaviour against expected gains and losses on risky assets. Allowing for different return generating systems and two investable assets, we examine the way portfolio allocation to the risky asset evolves over the course of the investment horizon in the presence of risk asymmetries. We find persisting horizon effects, with stocks appearing progressively more attractive at longer horizons as opposed to shorter ones. The role of parameter uncertainty also appears to be prominent in the portfolio choice problem. Accounting for this results in both significantly lowering the exposure to the risky asset and lessening the horizon effects driven by return predictability. An equally important aspect of this study relates to detecting a level of disappointment aversion below which it is optimal for investors to hold zero units of a risky asset. In this regard, our analysis has implications for the nonparticipation puzzle in stock markets.},
  archive      = {J_EJOR},
  author       = {Vasileios E. Kontosakos and Soosung Hwang and Vasileios Kallinterakis and Athanasios A. Pantelous},
  doi          = {10.1016/j.ejor.2023.07.038},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {765-782},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Long-term dynamic asset allocation under asymmetric risk preferences},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Designing interagency responses to wicked problems: A viable
system model board game. <em>EJOR</em>, <em>312</em>(2), 746–764. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Government agencies struggle to address wicked problems because they are open-ended, highly interdependent issues that cross agency, stakeholder, jurisdictional, and geopolitical boundaries. While both quantitative modelling and qualitative problem structuring methodologies have been used to support interagency decision making in the past, co-designing an effective interagency organization to collaboratively tackle wicked problems is more challenging. Few approaches have been developed to enable such efforts. This paper explains how the viable system model (VSM) was implemented through a board game, which was employed to co-design an interagency meta-organization that would be capable of more effectively collaborating to jointly address a wicked problem: international organized drug crime and its interface with local gangs in Chicago, USA. The board game was developed to make the VSM easier for the participants to learn, given that the cybernetic language and engineering-influenced diagrams in the original literature can be off-putting to leaders and managers. The board game was used as the final stage of a multi-method, systemic approach, which involved boundary critique and problem structuring as well as deployment of the VSM. The research findings indicate that the VSM board game, used as part of a larger mixed-methods systemic intervention, contributes to building trust in the value of systems thinking amongst the participants, and sets up a rich context for collaboration on multi-agency co-design. The game therefore offers significant promise as part of the co-design of interagency responses to wicked problems because it creates an embodied process for stakeholders to learn about the VSM. It also reduces the work involved in this learning. Thus, the game enables an effective appropriation of the VSM language and criteria.},
  archive      = {J_EJOR},
  author       = {Pamela Sydelko and Angela Espinosa and Gerald Midgley},
  doi          = {10.1016/j.ejor.2023.06.040},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {746-764},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Designing interagency responses to wicked problems: A viable system model board game},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting individual preferences and erroneous verdicts in
mixed martial arts judging using bayesian hierarchical models.
<em>EJOR</em>, <em>312</em>(2), 733–745. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we use Bayesian hierarchical models to investigate the decision-making of judges of mixed martial arts (MMA) contests. Whilst there has been research into the judging of various sports in the past, none have explicitly modelled the judges’ behaviours at an individual level. We progress the literature by demonstrating that judges have personal preferences towards the different actions that they must assess during a fight. The preferences themselves may be the deciding factor in a bout, as demonstrated using a historical case study. We apply the concept of variable significance to the predictions of scores, to assess whether a judge’s verdict was within reason. Finally, we develop a model that predicts a bout’s fair outcome, which could be used in various ways in MMA.},
  archive      = {J_EJOR},
  author       = {Benjamin Holmes and Ian G. McHale and Kamila Żychaluk},
  doi          = {10.1016/j.ejor.2023.07.004},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {733-745},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Detecting individual preferences and erroneous verdicts in mixed martial arts judging using bayesian hierarchical models},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fishing route optimization decision support system: The
case of the tuna purse seiner. <em>EJOR</em>, <em>312</em>(2), 718–732.
(<a href="https://doi.org/10.1016/j.ejor.2023.07.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fisheries face challenges in improving efficiency and reducing their emission footprint and operating costs. Decision support systems offer an opportunity to tackle such challenges. This study focuses on the dynamic fishing routing problem (DFRP) of a tuna purse seiner from a tactical and operational routing point of view. The tactical routing problem is formalized as the dynamic k k -travelling salesperson problem with moving targets and time windows, whereas the operational problem is formulated as the time-dependent shortest path problem. The algorithm proposed to solve this problem, called GA-TDA*, couples a genetic algorithm (GA), which uses problem-dependent operators, with a time-dependent A* algorithm. Using real data from a fishing company, the designed GA crossovers were evaluated along with the trade-off between the combination of the proposed objectives: fuel consumption and probability of high catches. The DFRP was also solved as a real dynamic problem with route updates every time a dFAD was fished. The results obtained by this approach were compared with historical fishing trips, where a potential saving in fuel consumption and time at sea of around 57% and 33%, respectively were shown. The dynamic GA-TDA* shows that a better selection of fishing grounds together with considerations about weather conditions can help industry to mitigate and adapt to climate change while decreasing one of their main operational costs.},
  archive      = {J_EJOR},
  author       = {Igor Granado and Leticia Hernando and Zigor Uriondo and Jose A. Fernandes-Salvador},
  doi          = {10.1016/j.ejor.2023.07.009},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {718-732},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A fishing route optimization decision support system: The case of the tuna purse seiner},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Portfolio optimization through a network approach: Network
assortative mixing and portfolio diversification. <em>EJOR</em>,
<em>312</em>(2), 700–717. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper deals with the classical problem of selecting a portfolio in the financial market and follows a risk-return optimization approach. The main issue in portfolio selection is capturing the dependency structure of the returns of the different assets. In the well-known Markowitz models this is measured by the variance/covariance matrix of the assets’ returns. Recent works have focused on a new way of modeling the dependency between returns of different assets by means of the so called “market graph” or “correlation graph”. Basing on this graph, the paper introduces new mixed integer linear formulations for the portfolio selection problem in which the portfolio expected return is maximized, while controlling the worst case loss. There are two innovative aspects related to the market graph. One is the introduction of a set of constraints over the neighborhood of each node. These constraints force the model to include in the portfolio a subset of assets which correspond to nodes poorly connected in the correlation graph. The second is the use of a measure from the area of complex network analysis called ‘assortativity’. A local assortativity coefficient is computed for each node, and it is used to formulate linear objective functions in the optimization models. We propose two Mixed Integer Linear Programs for finding the most ‘disassortative’ portfolios by using either the ‘local degree’ or the ‘local strength’ assortativity coefficients. A set of computational experiments is performed over real-world data sets to test the performance of the proposed models. The experimental results show that combining the assortativity criterion and the neighborhood constraints leads to an effective strategy to obtain portfolios with a good out-of-sample performance under the risk-return viewpoint.},
  archive      = {J_EJOR},
  author       = {Federica Ricca and Andrea Scozzari},
  doi          = {10.1016/j.ejor.2023.07.010},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {700-717},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Portfolio optimization through a network approach: Network assortative mixing and portfolio diversification},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimating production functions through additive models
based on regression splines. <em>EJOR</em>, <em>312</em>(2), 684–699.
(<a href="https://doi.org/10.1016/j.ejor.2023.06.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new methodology for the estimation of production functions satisfying some classical production theory axioms, such as monotonicity and concavity, which is based upon the adaptation of an additive version of the machine learning technique known as Multivariate Adaptive Regression Splines (MARS). The new approach shares the piece-wise linear shape of the estimator associated with Data Envelopment Analysis (DEA). However, the new technique is able to surmount the overfitting problems associated with DEA by resorting to generalized cross-validation. In this paper, a computational experience was employed to measure how well the new approach performs, showing that it can reduce the mean squared error and bias of the estimator of the true production function in comparison with DEA and the more recent Corrected Concave Non-Parametric Least Squares (C 2 NLS) methodology. We also show that the success of the new approach depends on whether or not interactions among variables prevail and the degree of non-additivity of the true production function to be estimated.},
  archive      = {J_EJOR},
  author       = {Victor J. España and Juan Aparicio and Xavier Barber and Miriam Esteve},
  doi          = {10.1016/j.ejor.2023.06.035},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {684-699},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Estimating production functions through additive models based on regression splines},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pricing and structuring product trials: Separate versus
mixed wine tastings. <em>EJOR</em>, <em>312</em>(2), 668–683. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many sellers offer product trials to allow consumers the option to try products before purchasing. With a product trial, a consumer may find they like a product more than expected, thus stimulating a purchase, but the opposite may be equally likely. Understanding when product trials are profitable, and optimizing the trial structure and associated pricing decisions is a complex challenge. Product trials are common in practice, yet their impact on segmentation and pricing is not well understood, particularly for a multi-product setting. For example, using the example of wine, should a vineyard offer mixed tastings spanning both red and white varietals, or have separate tastings for each, and what are the pricing implications? Product trials can be product specific or offered jointly across multiple products. We model and analyze these separate versus mixed trial structures, considering optimal fee-setting and product pricing decisions and the resulting consumer segmentation, in markets with heterogeneous consumers. By analyzing the relative profitability of separate and mixed trials, we develop a deeper understanding of their distinct strengths. We prove that mixed trials are preferable to separate when customers’ trials are more likely to lead to favorable product impressions, and when consumers have a low-to-moderate preference gap between the products. Our results stipulate when sellers should offer mixed tastings across product varieties, versus the alternative separate tastings, or potentially no tastings at all. We also analyze how product-trial fees should be set, as well as the impact of these trial alternatives on product pricing decisions.},
  archive      = {J_EJOR},
  author       = {Monire Jalili and Eren B. Çil and Michael S. Pangburn},
  doi          = {10.1016/j.ejor.2023.07.024},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {668-683},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pricing and structuring product trials: Separate versus mixed wine tastings},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mental models of dynamic systems are different: Adjusting
for heterogeneous granularity. <em>EJOR</em>, <em>312</em>(2), 653–667.
(<a href="https://doi.org/10.1016/j.ejor.2023.07.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This is a methodological contribution to mental model research. It is based on the fact that people emphasize different features of complex situations. Their mental models of the situation are complex because of the situation and of interpersonal diversity. Framed by prior knowledge, they contain elements of distinct detail or granularity levels. Established comparison methods assume that granularity is standardized before elicitation. But unelicited details cannot be analyzed later. However, if elicitation includes details, some of them will be at distinct granularity levels; this leads to unequal distances between some variables. Link-based comparison methods therefore produce exaggerated distance indicators. The method presented here avoids the apparent trade-off between not capturing relevant details and bias from heterogenous granularity. It first selects a subset of variables that are on a comparable level of detail in several mental models, accounting for the frequency of these variables in subgroups. Second, it replaces the sequences of links between each pair of selected variables with a compressed link that maintains the polarity and delay information provided in each mental model. All relevant structural information of the original models is preserved. Such compressed models are constructed for each set of original models to be compared using standard methods without risking to exaggerate distance indicators. Data from a recent study with nine participants illustrates the use.},
  archive      = {J_EJOR},
  author       = {Martin FG. Schaffernicht and Stefan N. Groesser},
  doi          = {10.1016/j.ejor.2023.07.003},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {653-667},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mental models of dynamic systems are different: Adjusting for heterogeneous granularity},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic search for a parametric cost function
approximation: Energy storage with rolling forecasts. <em>EJOR</em>,
<em>312</em>(2), 641–652. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling forecasts have been almost overlooked in the renewable energy storage literature. In this paper, we provide a new approach for handling uncertainty not just in the accuracy of a forecast, but in the evolution of forecasts over time. Our approach shifts the focus from modeling the uncertainty in a lookahead model to accurate simulations in a stochastic base model. We develop a robust policy for making energy storage decisions by creating a parametrically modified lookahead model, where the parameters are tuned in the stochastic base model. Since computing unbiased stochastic gradients with respect to the parameters require restrictive assumptions, we propose a simulation-based stochastic approximation algorithm based on numerical derivatives to optimize these parameters. While numerical derivatives, calculated based on the noisy function evaluations, provide biased gradient estimates, an online variance reduction technique built in the framework of our proposed algorithm, will enable us to control the accumulated bias errors and establish the finite-time rate of convergence of the algorithm. Our numerical experiments show the performance of this algorithm in finding policies outperforming the deterministic benchmark policy.},
  archive      = {J_EJOR},
  author       = {Saeed Ghadimi and Warren B. Powell},
  doi          = {10.1016/j.ejor.2023.08.003},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {641-652},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stochastic search for a parametric cost function approximation: Energy storage with rolling forecasts},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Index policy for multiarmed bandit problem with dynamic risk
measures. <em>EJOR</em>, <em>312</em>(2), 627–640. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multiarmed bandit problem (MAB) is a classic problem in which a finite amount of resources must be allocated among competing choices with the aim of identifying a policy that maximizes the expected total reward. MAB has a wide range of applications including clinical trials, portfolio design, tuning parameters, internet advertisement, auction mechanisms, adaptive routing in networks, and project management. The classical MAB makes the strong assumption that the decision maker is risk-neutral and indifferent to the variability of the outcome. However, in many real life applications, these assumptions are not met and decision makers are risk-averse. Motivated to resolve this, we study risk-averse control of the multiarmed bandit problem in regard to the concept of dynamic coherent risk measures to determine a policy with the best risk-adjusted total discounted return. In respect of this specific setting, we present a theoretical analysis based on Whittle’s retirement problem and propose a priority-index policy that reduces to the Gittins index when the level of risk-aversion converges to zero. We generalize the restart formulation of the Gittins index to effectively compute these risk-averse allocation indices. Numerical results exhibit the excellent performance of this heuristic approach for two well-known coherent risk measures of first-order mean-semideviation and mean-AVaR. Our experimental studies suggest that there is no guarantee that an index-based optimal policy exists for the risk-averse problem. Nonetheless, our risk-averse allocation indices can achieve optimal or near-optimal policies which in some instances are easier to interpret compared to the exact optimal policy.},
  archive      = {J_EJOR},
  author       = {Milad Malekipirbazari and Özlem Çavuş},
  doi          = {10.1016/j.ejor.2023.08.004},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {627-640},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Index policy for multiarmed bandit problem with dynamic risk measures},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive scheduling in service systems: A dynamic
programming approach. <em>EJOR</em>, <em>312</em>(2), 605–626. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers appointment scheduling in a setting in which at every client arrival the schedule of all future clients can be adapted. Starting our analysis with an explicit treatment of the case of exponentially distributed service times, we then develop a phase-type-based approach to also cover cases in which the service times’ squared coefficient of variation differs from 1. The approach relies on dynamic programming, with the state information being the number of clients waiting, the elapsed service time of the client in service, and the number of clients still to be scheduled. The use of dynamic schedules is illustrated through a set of numerical experiments, showing (i) the effect of wrongly assuming exponentially distributed service times, and (ii) the gains (over static schedules, that is) achieved by rescheduling.},
  archive      = {J_EJOR},
  author       = {Roshan Mahes and Michel Mandjes and Marko Boon and Peter Taylor},
  doi          = {10.1016/j.ejor.2023.06.026},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {605-626},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Adaptive scheduling in service systems: A dynamic programming approach},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Should competing suppliers with dual-channel supply chains
adopt agency selling in an e-commerce platform? <em>EJOR</em>,
<em>312</em>(2), 587–604. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we examine which of an agency selling or a wholesale contract offered by an e-commerce platform competing suppliers with typical dual-channel supply chains should adopt, where the products are not differentiated between a direct channel and an indirect platform channel, as in the case of digital goods. Specifically, we consider the situation in which each of two competing suppliers chooses its distribution strategy regarding whether it sells via a direct channel and/or an indirect channel via the platform. In addition, a supplier also chooses an agency selling contract or a wholesale contract if selling via the platform. Constructing and solving a game-theoretic model, we derive the primary result that, in equilibrium, one supplier sells products only via the direct channel, while the other supplier sells via both the direct channel and the platform channel through adopting a wholesale contract, even given the assumption of symmetric suppliers. This finding yields the managerial implication that a supplier selling products of the same quality between direct and platform channels in a competitive environment should not adopt agency selling but instead a regular wholesale contract when selling via a platform. Moreover, this finding reverses the conventional insight from existing models in previous studies that at least one competing supplier always adopts an agency contract when the suppliers are without their own direct sales channels.},
  archive      = {J_EJOR},
  author       = {Kenji Matsui},
  doi          = {10.1016/j.ejor.2023.06.030},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {587-604},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Should competing suppliers with dual-channel supply chains adopt agency selling in an e-commerce platform?},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Competitive pricing and product strategies in the presence
of consumers’ social comparisons. <em>EJOR</em>, <em>312</em>(2),
573–586. (<a href="https://doi.org/10.1016/j.ejor.2023.06.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When buying products that are used in public (e.g., smart phones and cars), consumers may compare their products with those of others they meet in their community. This behavior is referred to as “social comparisons”. In these comparisons, the consumers make (incur) a psychological gain (loss) when they find that their product is superior (inferior). Analytically examining this psychological gain (loss) from “the consumer&#39;s social-comparison benefit (cost)”, we show how it would affect the pricing, quality, and product-line strategies of two competing firms. We find that a greater consumer&#39;s social-comparison benefit may increase both firms’ profits by reducing their price competition, while a higher consumer&#39;s social-comparison cost may decrease both firms’ profits by intensifying their price competition. When the firms can strategically choose their product quality, a greater consumer&#39;s social-comparison benefit will lead the firms to increase their quality difference, and a higher consumer&#39;s social-comparison cost will lead the firms to reduce their quality difference. When the firms can extend their product lines to sell more than one product, their product lines tend to shrink (expand) as the consumer&#39;s social-comparison benefit (cost) increases. If the consumer&#39;s social-comparison benefit is low relative to the consumer&#39;s social-comparison cost, both firms earn higher profits when they can extend their product lines (versus when they cannot extend their product lines). This result highlights that relative to reducing the quality difference between the two firms, the product-line extension strategy can be a more effective way for the firms to manage consumers’ social comparisons. Our results show that understanding consumers’ social comparisons is important for firms to formulate an effective product offering strategy.},
  archive      = {J_EJOR},
  author       = {Ting Zhang and Tsan-Ming Choi and Tai-Chiu (Edwin) Cheng},
  doi          = {10.1016/j.ejor.2023.06.023},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {573-586},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Competitive pricing and product strategies in the presence of consumers’ social comparisons},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-period distribution networks with purchase commitment
contracts. <em>EJOR</em>, <em>312</em>(2), 556–572. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retailers which deliver products directly to their customer locations often rely on Logistics Service Intermediaries (LSI) for order management, warehousing, transportation and distribution services. Usually, the LSI acts as a shipper and subcontracts the transportation to carriers for long-haul and last-mile delivery services. All agents interact and are connected through cross-docking facilities. As the demand from customers may vary significantly over time, the shipper’s requirements for transportation evolve accordingly at the tactical level. This creates opportunities for the shipper to take advantage of medium-term contracts with the carriers at prices lower than those offered by the spot market. The study focuses on the tactical design, through dynamic contracts, of a suitable network of cross-docking facilities and related transportation capacities (belonging to different carriers) to reduce the shipper’s operational costs. In this article, we propose an MILP formulation for the multi-period planning problem with minimum purchase commitment contracts faced by the shipper. We propose exact and heuristic decomposition methods for the the model, respectively, based on combinatorial Benders cuts and on relax-and-repair approaches. The performance of these algorithms is experimentally compared to that of commercial solvers (branch-and-cut and classical Benders). The numerical results show that our methods perform comparatively well for the solution of large size instances and brings economic benefits to the shipper.},
  archive      = {J_EJOR},
  author       = {Christian Clavijo López and Yves Crama and Thierry Pironet and Frédéric Semet},
  doi          = {10.1016/j.ejor.2023.07.007},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {556-572},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-period distribution networks with purchase commitment contracts},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the stochastic inventory problem under order capacity
constraints. <em>EJOR</em>, <em>312</em>(2), 541–555. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the single-item single-stocking location stochastic inventory system under a fixed ordering cost component. A long-standing problem is that of determining the structure of the optimal control policy when this system is subject to order quantity capacity constraints; to date, only partial characterisations of the optimal policy have been discussed. An open question is whether a policy with a single continuous interval over which ordering is prescribed is optimal for this problem. Under the so-called “continuous order property” conjecture, we show that the optimal policy takes the modified multi- ( s , S ) (s,S) form. Moreover, we provide a numerical counterexample in which the continuous order property is violated, and hence show that a modified multi- ( s , S ) (s,S) policy is not optimal in general. However, in an extensive computational study, we show that instances violating the continuous order property do not surface, and that the plans generated by a modified multi- ( s , S ) (s,S) policy can therefore be considered, from a practical standpoint, near-optimal. Finally, we show that a modified ( s , S ) (s,S) policy also performs well in this empirical setting.},
  archive      = {J_EJOR},
  author       = {Roberto Rossi and Zhen Chen and S. Armagan Tarim},
  doi          = {10.1016/j.ejor.2023.06.045},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {541-555},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the stochastic inventory problem under order capacity constraints},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust decision trees for the multi-mode project scheduling
problem with a resource investment objective and uncertain activity
duration. <em>EJOR</em>, <em>312</em>(2), 525–540. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we advocate the use of robust decision trees for a multi-mode resource constrained project scheduling problem with uncertain activity duration and a resource investment objective, coming from an industrial assembly line scheduling application. This work takes place in the context of multi-stage optimization where uncertainty is revealed progressively across a succession of decision time points. In a robust decision tree, a node represents a robust partial schedule from the time origin to a specific decision time point. At this point, the decision maker has access to some information, which partitions the uncertainty scenario set, yielding for each scenario subset a child node and an associated extended partial robust schedule up to the next decision point. Considering that the level of uncertainty is lowered, the new partial schedule is less conservative and improves the robustness guarantee. However, since all accessible information may not be relevant, we turned the information selection part into an optimization problem. An algorithm is proposed to solve the robust decision tree problem. Experimentation is provided to study the influence of decision tree parameters as well as highlighted recommendations. The interest of the decision tree is shown through an experimental comparison with classical approaches of the literature on benchmark instances and industrial instances.},
  archive      = {J_EJOR},
  author       = {Tom Portoleau and Christian Artigues and Romain Guillaume},
  doi          = {10.1016/j.ejor.2023.07.035},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {525-540},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust decision trees for the multi-mode project scheduling problem with a resource investment objective and uncertain activity duration},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Single machine parallel-batch scheduling under time-of-use
electricity prices: New formulations and optimisation approaches.
<em>EJOR</em>, <em>312</em>(2), 512–524. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electricity costs account for a relatively large proportion of total production costs in many energy-intensive manufacturing industries. And energy-efficient scheduling is getting increasing attention from researchers owing to its wide real-world applications and computational challenges. In this study, the single-machine parallel-batch scheduling problem with non-identical job sizes under time-of-use electricity prices is investigated. The objective is to minimise the total energy consumption cost such that the makespan does not exceed a given deadline. First, an improved time-slot-indexed formulation is proposed to eliminate symmetric solutions. Subsequently, a new set partition-based formulation is developed. To the best of our knowledge, there is no exact algorithm for this problem, except for some formulations solved by off-the-shelf solvers. To address this problem, a branch-and-price algorithm is developed with a novel and efficient branching rule. In addition, a column-generation-based heuristic is proposed to solve larger-scale instances. Extensive numerical experiments show that the efficiency of the branch-and-price algorithm is significantly better than that of off-the-shelf solvers, and many instances with up to 100 jobs could be solved to optimality within a 20-minute computational time limit for the first time. The column-generation-based heuristic can efficiently provide better solutions than existing heuristics (2.75% average gap in three minutes on instances with 100 jobs and 3.12% average gap in ten minutes on instances with 200 jobs).},
  archive      = {J_EJOR},
  author       = {Zheng Tian and Li Zheng},
  doi          = {10.1016/j.ejor.2023.07.012},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {512-524},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Single machine parallel-batch scheduling under time-of-use electricity prices: New formulations and optimisation approaches},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A linear programming approach to difference-of-convex
piecewise linear approximation. <em>EJOR</em>, <em>312</em>(2), 493–511.
(<a href="https://doi.org/10.1016/j.ejor.2023.07.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of finding continuous piecewise linear (CPWL) approximations of deterministic functions of any dimension that satisfy any predefined error-tolerance, while keeping the number of polytopes that partition the approximation domain low. Specifically, we focus on overcoming the major computational bottleneck of the CPWL Approximation Algorithm (CPWL-AA) that has been proposed in the recent literature. CPWL-AA uses the difference-of-convex CPWL representation to search CPWL approximations which can partition the approximation domain to have polytopes of any shape. A computational bottleneck of the method is to solve a mixed-integer linear program (MILP) in which the number of binary variables is large for many problems of practical interest. In this paper, we overcome this by introducing a method that obtains a high quality solution of the MILP by iteratively solving a linear program (LP). We further reduce the computational expense by developing a method that treats some constraints in the LP problem as lazy constraints. Through a computational study we demonstrate that the proposed methods substantially reduce the computation time of CPWL-AA, while maintaining high quality CPWL approximations. With this, we demonstrate that we can generate CPWL approximations that satisfy predefined error-tolerances on functions of up to five dimensions within reasonable solution times.},
  archive      = {J_EJOR},
  author       = {Kody Kazda and Xiang Li},
  doi          = {10.1016/j.ejor.2023.07.026},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {493-511},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A linear programming approach to difference-of-convex piecewise linear approximation},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A flow based formulation and a reinforcement learning based
strategic oscillation for cross-dock door assignment. <em>EJOR</em>,
<em>312</em>(2), 473–492. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-dock door assignment is a critical warehouse optimization problem in supply chain management. It involves assigning incoming trucks to inbound doors and outgoing trucks to outbound doors to minimize the total pallet-handling cost inside the warehouse. This study investigates a flow based formulation and a reinforcement learning based heuristic approach to solve this problem. The flow based formulation relies on the flow of goods. It is significantly smaller than the existing mixed integer programming formulations in the literature. The proposed heuristic algorithm relies on a Q Q -learning reinforced procedure to guide the search toward promising areas, and a strategic oscillation method to adaptively explore feasible and infeasible search spaces. It also relies on an improved tabu strategy using attributive and explicit memories. The formulation and proposed heuristic algorithm were tested on two sets of benchmark instances widely used in the literature and compared with several state-of-the-art algorithms. The computational results demonstrated the high competitiveness of the proposed methods in solution quality and computation time. In particular, the flow based formulation can optimally solve more and larger instances and produce better lower and upper bounds than the existing mixed integer programming formulations in the literature. The heuristic approach improved the best solutions (new upper bounds) for 43 of the 99 tested instances while matching the other best-known solutions, except in two cases. The key components of the algorithm were analyzed to justify the algorithm design. The code of the proposed algorithm will be publicly available.},
  archive      = {J_EJOR},
  author       = {Mingjie Li and Jin-Kao Hao and Qinghua Wu},
  doi          = {10.1016/j.ejor.2023.07.014},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {473-492},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A flow based formulation and a reinforcement learning based strategic oscillation for cross-dock door assignment},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using fixed paths to improve branch-and-cut algorithms for
precedence-constrained routing problems. <em>EJOR</em>, <em>312</em>(2),
456–472. (<a href="https://doi.org/10.1016/j.ejor.2023.07.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper introduces a fixed-path procedure to solve precedence-constrained routing problems. The procedure can be applied within a branch-and-cut framework to improve the search with respect to arrival time variables. Every time when a new variable is fixed in a branch-and-cut node, the fixed-path procedure tries to improve lower bounds on variables picturing the arrival time at customer locations. With the help of these lower bounds, we can identify infeasible solutions ahead of time, fix additional arc variables, and add additional valid inequalities. The fixed-path procedure is evaluated for several objective functions for the dial-a-ride problem. Moreover, we apply it to a dial-a-ride problem focusing on the residents of large cities. These individuals have access to a wide range of means of transportation. Therefore, ridepooling providers have to solve the trade-off between the costs for deployed vehicles and small detours for customers to be competitive. We evaluate our fixed-path procedure in an extensive computational study with 4500 instances with up to 120 customers and 10 vehicles for this problem. With the fixed-path procedure, we were able to solve 838 (29.9%) additional problem instances to optimality and to find better lower and upper bounds than a standard mixed-integer programming formulation.},
  archive      = {J_EJOR},
  author       = {Arne Schulz and Christian Pfeiffer},
  doi          = {10.1016/j.ejor.2023.07.002},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {456-472},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Using fixed paths to improve branch-and-cut algorithms for precedence-constrained routing problems},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discrete scheduling and critical utilization. <em>EJOR</em>,
<em>312</em>(2), 445–455. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient scheduling is essential for optimizing resource allocation and robust system performance in a wide range of real-life applications. In most of these cases, the success of scheduling largely depends on one&#39;s ability to ensure that system resources can be utilized to their maximum capacity, yet without overloading the system. In this work, we study the problem of critical utilization and efficient scheduling by considering systems with discrete schedules, widely used in real-life workflows. Using an implementation-based approach, we introduce discrete scheduling by developing its analytic equations, which enables us to express the behavior of the scheduling metrics with respect to system utilization. Using this result, we define critical resource utilization and solve for its exact value as a function of schedule length. Finally, we compare our results with the equations from the classical queueing theory, and discuss their applicability. Our findings have immediate practical implications in developing robust schedules and controlling for optimal system performance.},
  archive      = {J_EJOR},
  author       = {Oleg S. Pianykh and Sebastian Perez and Chengzhao “Richard” Zhang},
  doi          = {10.1016/j.ejor.2023.06.010},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {445-455},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Discrete scheduling and critical utilization},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time-flexible min completion time variance in a single
machine by quadratic programming. <em>EJOR</em>, <em>312</em>(2),
427–444. (<a href="https://doi.org/10.1016/j.ejor.2023.06.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of job scheduling, the time required to complete a task is related not only to the intrinsic difficulty of the task, but also to the operator’s willingness to speed up (or slow down) its execution. In fact, service operators are sometimes authorized to flexibly calibrate job processing times when this is beneficial for the efficient design of services and production plans. In this paper, we show that some forms of time flexibility have major consequences on the operator’s ability to efficiently solve the problem of scheduling non-preemptive jobs to minimize the variance of their completion times. In fact, although this remains a challenging combinatorial problem, authorizing forms of processing time flexibility allows for solving it up to optimality by convex quadratic programming approaches, with a view to tackling large-scale instances, where no exact algorithm can be applied. Our contribution allows establishing a form of least flexibilization of job processing times while guaranteeing the solvability of the resulting problem by convex quadratic programming approaches. To this end, we provide novel bounding conditions for the characterization of an optimal sequence that strengthen and integrate state-of-the-art dominance properties. Our numerical tests indicate that this new methodology is capable of approaching the solution of the original min completion time variance problem with a max relative difference of about 0.05 % 0.05% (on average), with respect to the time-flexible solution.},
  archive      = {J_EJOR},
  author       = {Stefano Nasini and Rabia Nessah},
  doi          = {10.1016/j.ejor.2023.06.034},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {427-444},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Time-flexible min completion time variance in a single machine by quadratic programming},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Channel strategies for competing retailers: Whether and when
to introduce live stream? <em>EJOR</em>, <em>312</em>(2), 413–426. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Live stream channel expands consumer awareness and resolves consumer valuation uncertainty. However, its public accessibility may trigger consumer freeriding (watching the live stream introduced by one retailer but buying from the other). This study examines the impacts and strategies of live stream channel introduction for competing retailers. The live stream may not increase the introducer&#39;s demand or benefit the retailer with freeriding consumers. The equilibrium strategy regarding who introduces the live stream channel, i.e., NN (no retailer introduces), LN/NL (one retailer introduces), and LL (both retailers introduce), depends on the commission rate and mismatch cost. Specifically, in the symmetric products case, a moderately high mismatch cost leads to LL equilibrium. A high (moderately low) mismatch cost and a high (low) commission rate lead to NN equilibrium; otherwise, LN/NL equilibrium occurs. In the asymmetric products case, the retailer of the high-fit product is more likely to introduce a live stream channel. Interestingly, the retailers may be trapped in a prisoner&#39;s dilemma under a low mismatch cost. Nonetheless, the likelihood of a prisoner&#39;s dilemma decreases if the live stream improves consumer valuation. Furthermore, an endogenous commission that guarantees the live stream channel introduction can prevent the prisoner&#39;s dilemma in the symmetric products case.},
  archive      = {J_EJOR},
  author       = {Lingchen Huang and Bin Liu and Rong Zhang},
  doi          = {10.1016/j.ejor.2023.06.017},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {413-426},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Channel strategies for competing retailers: Whether and when to introduce live stream?},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Survey of optimization models for power system operation and
expansion planning with demand response. <em>EJOR</em>, <em>312</em>(2),
401–412. (<a href="https://doi.org/10.1016/j.ejor.2023.01.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the implementation of demand response programs and its increasing penetration in the power grid, various new challenges to the grid’s operation have emerged. As a consequence, optimizing the operation of the power grid and the allocation of demand response resources, in the short-term, medium-term and long-term, has become a fundamental problem. This survey presents a review of the optimization approaches in the literature for the integration of DR in three central problems in power systems planning, namely optimal power flow, unit commitment, and generation and transmission expansion planning. We also highlight important future research directions.},
  archive      = {J_EJOR},
  author       = {Vinicius N. Motta and Miguel F. Anjos and Michel Gendreau},
  doi          = {10.1016/j.ejor.2023.01.019},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {401-412},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Survey of optimization models for power system operation and expansion planning with demand response},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). In memory of professor john edward boylan, 1959 – 2023.
<em>EJOR</em>, <em>312</em>(2), 399–400. (<a
href="https://doi.org/10.1016/j.ejor.2023.08.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  doi          = {10.1016/j.ejor.2023.08.001},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {2},
  pages        = {399-400},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {In memory of professor john edward boylan, 1959 – 2023},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The min-knapsack problem with compactness constraints and
applications in statistics. <em>EJOR</em>, <em>312</em>(1), 385–397. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the min-Knapsack problem, one is given a set of items, each having a certain cost and weight. The objective is to select a subset with minimum cost, such that the sum of the weights is not smaller than a given constant. In this paper, we introduce an extension of the min-Knapsack problem with additional “compactness constraints” (mKPC), stating that selected items cannot lie too far apart. This extension has applications in statistics, including in algorithms for change-point detection in time series. We propose three solution methods for the mKPC. The first two methods use the same Mixed-Integer Programming (MIP) formulation but with two different approaches: passing the complete model with a quadratic number of constraints to a black-box MIP solver or dynamically separating the constraints using a branch-and-cut algorithm. Numerical experiments highlight the advantages of this dynamic separation. The third approach is a dynamic programming labelling algorithm. Finally, we focus on the particular case of the unit-cost mKPC (1c-mKPC), which has a specific interpretation in the context of the statistical applications mentioned above. We prove that the 1c-mKPC is solvable in polynomial time with a different ad-hoc dynamic programming algorithm. Experimental results show that this algorithm vastly outperforms both generic approaches for the mKPC and a simple greedy heuristic from the literature.},
  archive      = {J_EJOR},
  author       = {Alberto Santini and Enrico Malaguti},
  doi          = {10.1016/j.ejor.2023.07.020},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {385-397},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The min-knapsack problem with compactness constraints and applications in statistics},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adjustable robust optimization with objective uncertainty.
<em>EJOR</em>, <em>312</em>(1), 373–384. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study optimization problems where some cost parameters are not known at decision time and the decision flow is modeled as a two-stage process within a robust optimization setting. We address general problems in which all constraints (including those linking the first and the second stages) are defined by convex functions and involve mixed-integer variables, thus extending the existing literature to a much wider class of problems. We show how these problems can be reformulated using Fenchel duality, allowing to derive an enumerative exact algorithm, for which we prove asymptotic convergence in the general case, and finite convergence for cases where the first-stage variables are all integer. An implementation of the resulting algorithm, embedding a column generation scheme, is then computationally evaluated on a variant of the Capacitated Facility Location Problem with uncertain transportation costs, using instances that are derived from the existing literature. To the best of our knowledge, this is the first approach providing results on the practical solution of this class of problems.},
  archive      = {J_EJOR},
  author       = {Boris Detienne and Henri Lefebvre and Enrico Malaguti and Michele Monaci},
  doi          = {10.1016/j.ejor.2023.06.042},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {373-384},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Adjustable robust optimization with objective uncertainty},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interpretable machine learning for imbalanced credit scoring
datasets. <em>EJOR</em>, <em>312</em>(1), 357–372. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class imbalance problem is common in the credit scoring domain, as the number of defaulters is usually much less than the number of non-defaulters. To date, research on investigating the class imbalance problem has mainly focused on indicating and reducing the adverse effect of the class imbalance on the predictive accuracy of machine learning techniques, while the impact of that on machine learning interpretability has never been studied in the literature. This paper fills this gap by analysing how the stability of Local Interpretable Model-agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP), two popular interpretation methods, are affected by class imbalance. Our experiments use 2016–2020 UK residential mortgage data collected from European Datawarehouse. We evaluate the stability of LIME and SHAP on datasets of progressively increased class imbalance. The results show that interpretations generated from LIME and SHAP are less stable as the class imbalance increases, which indicates that the class imbalance does have an adverse effect on machine learning interpretability. To check the robustness of our outcomes, we also analyse two open-source credit scoring datasets and we obtain similar results.},
  archive      = {J_EJOR},
  author       = {Yujia Chen and Raffaella Calabrese and Belen Martin-Barragan},
  doi          = {10.1016/j.ejor.2023.06.036},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {357-372},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Interpretable machine learning for imbalanced credit scoring datasets},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prepositioning can improve the performance of a dynamic
stochastic on-demand public bus system. <em>EJOR</em>, <em>312</em>(1),
338–356. (<a href="https://doi.org/10.1016/j.ejor.2023.07.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the first application of prepositioning in the context of the dynamic stochastic on-demand bus routing problem (DODBRP). The DODBRP is a large-scale dial-a-ride problem that involves bus station assignment and aims to minimize the total user ride time (URT) by simultaneously assigning passengers to alternative stations and determining optimal bus routes. In the DODBRP, transportation requests are introduced dynamically, and buses are dispatched to stations with known requests. This paper investigates the concept of prepositioning, which involves sending buses not only to currently known requests but also to requests that are likely to appear in the future, based on a given probability. To solve this dynamic and stochastic ODBRP, the paper proposes a heuristic algorithm based on variable neighborhood search (VNS). The algorithm considers multiple scenarios to represent different realizations of the stochastic requests. Experimental results demonstrate the superiority of the prepositioning approach over the DODBRP across various levels of forecast accuracy, lengths of time bucket, and probabilities of realization. Furthermore, the paper shows that removing empty stations as a recourse action can further enhance solution quality. Additionally, in situations with low prediction accuracy, increasing the number of scenarios can lead to improved solutions. Finally, a combination of prepositioning, empty station removal, and the insertion of dynamic requests proves to be effective. Overall, the findings of this paper provide valuable insights into the application of prepositioning in the dynamic stochastic on-demand bus routing problem, highlighting its potential for addressing real-world transportation challenges.},
  archive      = {J_EJOR},
  author       = {Ying Lian and Flavien Lucas and Kenneth Sörensen},
  doi          = {10.1016/j.ejor.2023.07.006},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {338-356},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Prepositioning can improve the performance of a dynamic stochastic on-demand public bus system},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hit or miss: A decision support system framework for signing
new musical talent. <em>EJOR</em>, <em>312</em>(1), 324–337. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the music industry, the process of signing new musical talent is one of the most complex decision-making problems. The decision, which is generally made by an artist and repertoire (A&amp;R) team, involves consideration of various quantitative and qualitative criteria, and usually results in a low success rate. We conducted a series of mental model interviews with the aim of developing a decision support framework for A&amp;R teams. This framework was validated by creating a decision support system that utilises multi-criteria decision analysis to support decision-making. Our framework and subsequent implementation of the decision support system involving decision rule and weighted sum methods show an improvement in the ability to analyse and decide on greater amounts of talent. This paper serves as a building block for developing systems to aid in this complex decision-making problem.},
  archive      = {J_EJOR},
  author       = {Aritad Choicharoon and Richard Hodgett and Barbara Summers and Sajid Siraj},
  doi          = {10.1016/j.ejor.2023.06.014},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {324-337},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Hit or miss: A decision support system framework for signing new musical talent},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A generalized inefficiency model with input and output
dependence. <em>EJOR</em>, <em>312</em>(1), 315–323. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a general inefficiency model, in the sense that technical inefficiency is, simultaneously, a function of all inputs, outputs, and contextual variables. We recognize that change in inefficiency is endogenous or rational, and we propose an adjustment costs model with firm-specific but unknown adjustment cost parameters. When inefficiency depends on inputs and outputs, the firm&#39;s optimization problem changes as the first order conditions must take into account the dependence of inefficiency on the endogenous variables of the problem. The new formulation introduces statistical challenges which are successfully resolved. The model is estimated using Maximum Simulated Likelihood and an empirical application to U.S. banking is provided.},
  archive      = {J_EJOR},
  author       = {Mike G. Tsionas},
  doi          = {10.1016/j.ejor.2023.06.029},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {315-323},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A generalized inefficiency model with input and output dependence},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unified approach to radial, hyperbolic, and directional
efficiency measurement in data envelopment analysis. <em>EJOR</em>,
<em>312</em>(1), 298–314. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper analyses properties of a large class of “path-based” Data Envelopment Analysis models through a unifying general scheme. The scheme includes the well-known oriented radial models, the hyperbolic distance function model, the directional distance function models, and even permits their generalisations. The modelling is not constrained to non-negative data and is flexible enough to accommodate variants of standard models over arbitrary data . Mathematical tools developed in the paper allow systematic analysis of the models from the point of view of ten desirable properties. It is shown that some of the properties are satisfied (resp., fail) for all models in the general scheme, while others have a more nuanced behaviour and must be assessed individually in each model. Our results can help researchers and practitioners navigate among the different models and apply the models to mixed data.},
  archive      = {J_EJOR},
  author       = {Margaréta Halická and Mária Trnovská and Aleš Černý},
  doi          = {10.1016/j.ejor.2023.06.039},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {298-314},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A unified approach to radial, hyperbolic, and directional efficiency measurement in data envelopment analysis},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combining bootstrap data envelopment analysis with social
networks for rank discrimination and suitable potential benchmarks.
<em>EJOR</em>, <em>312</em>(1), 283–297. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many studies have attempted to overcome the inherent relativity of data envelopment analysis (DEA), which gives rise to the existence of undiscriminated decision-making units (DMUs) or the changes in the reference relationships depending on how the DMUs are grouped. This study presents a new and intuitive algorithm based on the bootstrapping method for generating a network that reflects both the DMUs’ original reference relationships and their potential benchmarks in a way that does not violate DEA&#39;s theoretical and practical premises while enabling a fuller ranking of the DMUs. An in-depth discussion regarding the definition of two types of potential benchmarks that can be used to rank DMUs flexibly is provided to highlight the superiority of the proposed algorithm. The application of our proposed algorithm delivers significant advantages over existing network approach models and opens new possibilities for utilizing the bootstrap DEA method.},
  archive      = {J_EJOR},
  author       = {Hee Jay Kang and Changhee Kim and Kanghwa Choi},
  doi          = {10.1016/j.ejor.2023.06.038},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {283-297},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Combining bootstrap data envelopment analysis with social networks for rank discrimination and suitable potential benchmarks},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inconsistency indices for pairwise comparisons and the
pareto dominance principle. <em>EJOR</em>, <em>312</em>(1), 273–282. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of quantifying inconsistency in pairwise comparisons and valued-preferences. A wide range of indices have been proposed in the literature to perform this task, and two sets of conditions have been introduced to validate such indices. We summarize some criticisms from the literature and we add more evidence to show that neither of the two systems is adequate in its current formulation. Thanks to the widely accepted concept of weak Pareto dominance, we formulate a new property. We argue that a simple regularity condition and this new property can overcome the shortcomings of the two axiomatic systems, and represents a significantly simpler framework. Finally, we claim that, if we had resorted to strict Pareto dominance, we would have needed just one axiom.},
  archive      = {J_EJOR},
  author       = {Matteo Brunelli and Michele Fedrizzi},
  doi          = {10.1016/j.ejor.2023.06.033},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {273-282},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Inconsistency indices for pairwise comparisons and the pareto dominance principle},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic pricing and strategic retailers in the energy
sector: A multi-leader-follower approach. <em>EJOR</em>,
<em>312</em>(1), 255–272. (<a
href="https://doi.org/10.1016/j.ejor.2023.05.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider strategic retail pricing in markets, where retail companies buy commodities at fluctuating wholesale prices and resell them to final consumers by applying dynamic retail tariffs. This is of especially large relevance in the context of energy markets where substantial wholesale price fluctuations are observed. Policy makers currently foster the introduction of such dynamic tariff schemes. From a modelling point of view, we propose a multi-leader-follower problem to investigate the implications of strategic retail pricing and we compare the impacts of implementing dynamic tariffs on retailers and final consumers. Our analysis tackles different aspects: first, we formulate the model and provide theoretical results. Second, we develop algorithms, which solve the multi-leader-follower problem and allow us to characterize the resulting market equilibria. Third, we calibrate and solve our framework based on data of the German retail electricity market for the years 2020 and 2021. This allows us to quantitatively assess the impact of introducing real time prices on retailers’ profits and customers’ benefits. As our results show, dynamic real-time pricing on the one hand typically increases market efficiency, which confirms previous results obtained without the explicit consideration of strategic behavior. On the other hand, however, as a novel aspect, dynamic real-time pricing turns out to significantly reduce equilibrium profits in case of strategic firms. This effect is especially large in environments with strongly fluctuating wholesale prices.},
  archive      = {J_EJOR},
  author       = {Giorgia Oggioni and Alexandra Schwartz and Ann-Kathrin Wiertz and Gregor Zöttl},
  doi          = {10.1016/j.ejor.2023.05.036},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {255-272},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic pricing and strategic retailers in the energy sector: A multi-leader-follower approach},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Network revenue management game in the railway industry:
Stackelberg equilibrium, global optimality, and mechanism design.
<em>EJOR</em>, <em>312</em>(1), 240–254. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many countries have adopted the vertical separation governance structure in the railway freight industry over the past decades. Under this governance structure, an Infrastructure Manager (IM), which might be an independent company or a government agency, sells train itineraries to Freight Operating Companies (FOCs). After purchasing the itineraries, a FOC will have the rights to run trains on the designated paths at the designated times and thus can provide transport service to shippers. In the process, an IM needs to determine a list of prices for their train itineraries; and a FOC needs to determine which train itineraries to purchase to serve uncertain customer demands based on the IM&#39;s price list. This study considers the interaction between an IM and a FOC as a network-based Stackelberg game. Our study first formulates a bi-level optimisation model to determine the equilibrium prices that the IM would charge to maximise its own profits unilaterally without collaboration. A method involving gradient and local search has been developed to solve the bi-level model. Secondly, an inverse optimisation model is proposed to determine the prices leading to global optimality. A Fenchel cutting plane-based algorithm is developed to solve the inverse optimisation model. Thirdly, a subsidy contract is designed for the game to coordinate the players’ decisions. A two-layer gradient search method is developed to determine the optimal subsidy rate. Numerical cases based on the UK rail freight industry data are provided to validate the models and algorithms.},
  archive      = {J_EJOR},
  author       = {Dongjun Li and Dewan Md Zahurul Islam and Mark Robinson and Dong-Ping Song and Jing-Xin Dong and Marc Reimann},
  doi          = {10.1016/j.ejor.2023.06.044},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {240-254},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Network revenue management game in the railway industry: Stackelberg equilibrium, global optimality, and mechanism design},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). The information value of logistics platforms in a freight
matching market. <em>EJOR</em>, <em>312</em>(1), 227–239. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The information asymmetry in the freight matching of the long-haul trucking industry usually pushes shippers to join a logistics platform that has better knowledge of truckers’ cost information. A logistics platform that is plugged into a freight transportation system helps shippers overcome their information disadvantage but produces the double marginalization effect. We investigate the equilibrium characteristics of a shipper and logistics platform in the freight matching market and find that the shipper prefers to cooperate with the logistics platform in a small-scale sales market but searches for truckers by himself in a large-scale sales market. We show that the information value of a logistics platform for the freight system consists of two aspects: (i) employ low-cost truckers for the shipper and avoid the shipper’s inefficient expansion of the selling quantity in a moderate-scale sales market with greatly heterogeneous truckers, and (ii) improve both the total profit and social welfare of the freight system in a small-scale sales market. We further find that the shipper’s private information may hurt the logistics platform and the logistics platform can mitigate her double marginalization disadvantage by improving value-added services or lowering the logistics price in a large-scale market. Our findings provide guidelines for the shipper and logistics platform on how to choose the appropriate transportation strategy and employment strategy in different logistics markets.},
  archive      = {J_EJOR},
  author       = {Yaobin Wu and Jiazhou Huang and Xiangfeng Chen},
  doi          = {10.1016/j.ejor.2023.06.043},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {227-239},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The information value of logistics platforms in a freight matching market},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Store-wide space planning balancing impulse and convenience.
<em>EJOR</em>, <em>312</em>(1), 211–226. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a store-wide shelf space planning framework that assigns product categories to shelves with the objective of balancing impulse buying and shopping convenience. Our resulting model is a bi-objective nonlinear integer program, similar in structure to a quadratic assignment. The model parameters are estimated based on data collected from a large supermarket in the Normandy region, France. We propose a linearization scheme and utilize it to exploit the efficient frontier of Pareto-optimal solutions via the ϵ ϵ -constraint method. Our results indicate that the supermarket management can significantly increase their revenue from impulse buying, while not burdening the customer with the inconvenience of extensive walking and search. In fact, we observe that many of our Pareto-optimal layout are anticipated to perform better than the actual layout the retailer is currently using on both impulse and convenience. For example, one well-balanced layout is anticipated to increase impulse profit by 82% and decrease walking by 11% with respect to the current layout. A side contribution of our work is developing a framework for data collection and parameter estimation based on panel (customer survey) data, observations from store visits, and publicly available information.},
  archive      = {J_EJOR},
  author       = {Fouad Ben Abdelaziz and Bacel Maddah and Tülay Flamand and Jimmy Azar},
  doi          = {10.1016/j.ejor.2023.06.027},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {211-226},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Store-wide space planning balancing impulse and convenience},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal pricing and donation policy for fresh goods.
<em>EJOR</em>, <em>312</em>(1), 198–210. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a socially responsible food-retailer’s operational planning problem for a continuously deteriorating inventory over two periods with the consideration of donation and quality-sensitive customers. Each year, millions of tonnes of food are wasted causing economic, environmental, and social misfortunes, while at the same time millions are undernourished. Besides expired items, edible foods are often deliberately disposed of to attract quality-sensitive consumers. We address this issue by presenting an optimization model that incorporates a retailer’s corporate social responsibility act, in the form of charitable donations, and makes use of the internet of things (IoT)-enabled condition tracking technologies to accurately estimate the effective (true) quality of the goods and its impacts on consumer demand. We formulate a quality-dependent newsvendor problem (QDNP) to determine the stocking quantity and the regular price of the goods at the beginning of the selling season, and the second-period price and donation policy at the end of the first period. The optimal donation policy at the end of the first period depends on the quality (time to expiration), on-hand inventory, and donation reward. Moreover, for a given inventory level, expected food waste is always greater in the absence of donations. QDNP outperforms the no-donation model, particularly when the uncertainty is high and/or the length of the second period is short. Interestingly, the two models react to an increase in uncertainty oppositely: QDNP orders more to alleviate future shortages, whereas, no-donation policy orders less to avoid future disposal costs at the end of the selling season.},
  archive      = {J_EJOR},
  author       = {Armağan Özbilge and Elkafi Hassini and Mahmut Parlar},
  doi          = {10.1016/j.ejor.2023.06.020},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {198-210},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal pricing and donation policy for fresh goods},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analytical formulation for explaining the variations in
traffic states: A fundamental diagram modeling perspective with
stochastic parameters. <em>EJOR</em>, <em>312</em>(1), 182–197. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the simplicity and practicality of (deterministic) fundamental diagram models in highway traffic flow theory, the wide scattering effect observed in empirical data remains highly controversial, particularly for explaining traffic state variations. Owing to the analytical properties of the fundamental diagram modeling approach, in this study, we proposed an analytical and quantitative method for analyzing traffic state variations. We investigated the scattering effect in the fundamental diagram and proposed two stochastic fundamental diagram (SFD) models with lognormal and skew-normal distributions to explain the variations in traffic states. The first SFD model assumes that the scattering effect results from stochasticity in both the free-flow speed and the speed at critical density. Both random variables were assumed to follow the lognormal distribution. In the second SFD model, an integrated error term that was assumed to follow the skew-normal distribution over different density ranges was appended to the deterministic fundamental diagram. The properties of these two SFD models were analyzed and compared, and the parameters in these SFD models were calibrated using real-world loop detector data. The observed scatters from the empirical data were reproduced well by the simulated fundamental diagram model, indicating the validity of the proposed SFD models for explaining traffic state variations. Using these two analytical SFD models, we can analyze the stochastic capacity of freeways with closed forms. More importantly, the sources of stochasticity in freeway capacity can be traced in terms of randomly distributed parameters in fundamental diagram models.},
  archive      = {J_EJOR},
  author       = {Qixiu Cheng and Yuqian Lin and Xuesong (Simon) Zhou and Zhiyuan Liu},
  doi          = {10.1016/j.ejor.2023.07.005},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {182-197},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Analytical formulation for explaining the variations in traffic states: A fundamental diagram modeling perspective with stochastic parameters},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Does battery management matter? Performance evaluation and
operating policies in a self-climbing robotic warehouse. <em>EJOR</em>,
<em>312</em>(1), 164–181. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our research is motivated by battery management in a new self-climbing robotic (SCR) system. The SCR system fully depends on battery-powered robots for tote movements. Therefore, battery management plays an important role and considerably impacts the system performance. This paper investigates the decision of battery charging technology (fast charging versus slow charging) taking into account the battery degradation, the battery charging policy (priority charging policy and dedicated charging policy), and the optimal number of chargers in the system. The paper also optimizes battery management in the SCR system by establishing semi-open queuing networks (SOQNs). The analytical models are solved by the approximate mean value analysis and are validated by simulation models. We find several interesting managerial insights: (1) In the operational policies, although fast charging can decrease the throughput time, we find a new condition when slow charging outperforms fast charging in robotic warehouses. (2) The priority charging policy is more cost-effective than the dedicated charging policy. (3) We also find a decision tool to determine the optimal number of chargers to satisfy the maximum allowed throughput time with the minimum cost.},
  archive      = {J_EJOR},
  author       = {Wanying Chen and Yeming Gong and Qi Chen and Hongwei Wang},
  doi          = {10.1016/j.ejor.2023.06.025},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {164-181},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Does battery management matter? performance evaluation and operating policies in a self-climbing robotic warehouse},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Transnational remanufacturing decisions under carbon taxes
and tariffs. <em>EJOR</em>, <em>312</em>(1), 150–163. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the influence of carbon taxes and tariffs on transnational closed-loop supply chains, this paper establishes three remanufacturing modes of an original equipment manufacturer (OEM) in an exporting country. In one remanufacturing mode, the OEM conducts remanufacturing itself, and in the other two modes, the OEM authorizes a retailer in the importing country to engage in remanufacturing. Next, we analyse the optimal pricing and carbon emissions reduction decisions of the OEM and retailer in the different modes and further study how different levels of carbon tax and tariff combinations impact OEM remanufacturing decisions, the social welfare of importing countries and the environment. The results show the following. (1) When the carbon tariff is high, the optimal sales of remanufactured products increase. However, this does not contribute to the continuation of the product system; thus, it is short sighted for the government to hastily set high carbon tariffs to discourage the import of new products to protect domestic enterprises. (2) Carbon tariffs cannot effectively encourage the OEM to invest in emission reduction because carbon tariffs are passed on to consumers in importing countries through price adjustment. However, carbon tax may be an indirect factor affecting the OEM&#39;s willingness to invest in emission reduction. (3) The OEM favours allowing the retailer to remanufacture when the carbon emissions of the remanufactured products are similar to those of new products. Co-investment in emission reduction has the potential to align the profit maximization of the OEM with the social welfare maximization of the importing country. (4) It is not profitable for the importing government to set high carbon tariffs to protect its own enterprises.},
  archive      = {J_EJOR},
  author       = {Wei Li and Peilin Wang and Wencheng Cheng and Kai Nie},
  doi          = {10.1016/j.ejor.2023.06.019},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {150-163},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Transnational remanufacturing decisions under carbon taxes and tariffs},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Admission and pricing optimization of on-street parking with
delivery bays. <em>EJOR</em>, <em>312</em>(1), 138–149. (<a
href="https://doi.org/10.1016/j.ejor.2023.07.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze a parking lot, modeled as a loss queue, with passenger and delivery vehicles. The arrival process of delivery vehicles is exogenous, while that of passenger vehicles is a function of the parking price rate and accessibility. The aim of the parking operator is to maximize the revenue generated from passenger vehicles while providing a sufficient service level for delivery vehicles, in terms of their probability to find an available parking spot. Two levels of control are exercised: pricing and admission. From a Markov decision process approach, we prove that the optimal policy is a state-dependent reservation threshold policy that randomizes in at most one state. When some parking spots should be reserved for delivery vehicles, the price rate is selected to saturate the service level constraint, whereas when it is optimal not to restrict the parking lot accessibility, the price can also be selected as the unique local maximum of the revenue or to incentivize all potential passenger vehicles to arrive. Pricing should be used as a primary tool to control the flow of passenger vehicles. In complement, admission control is exercised with a limited use of reservation only when the service level guarantee for delivery vehicles is high.},
  archive      = {J_EJOR},
  author       = {Benjamin Legros and Jan C. Fransoo},
  doi          = {10.1016/j.ejor.2023.07.001},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {138-149},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Admission and pricing optimization of on-street parking with delivery bays},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-visit flexible-docking vehicle routing problem with
drones for simultaneous pickup and delivery services. <em>EJOR</em>,
<em>312</em>(1), 125–137. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates a multi-visit flexible-docking vehicle routing problem that uses a truck and drone fleet to fulfill pickup and delivery requests in rural areas. In this collaborative truck–drone system, each drone may serve multiple customers per trip (multi-visit services), dock to the same or different truck from where it launched (flexible docking), and perform simultaneous pickup and delivery. These characteristics complicate the temporal, spatial, and loading synchronization for trucks and drones, making the decisions of order allocation and vehicle routing highly interdependent and intractable. This problem is formulated as a mixed-integer linear programming model and solved by a tailored adaptive large neighborhood search metaheuristic. Numerical experiments are conducted on sparse rural networks to demonstrate the efficiency of the proposed method. We observe that the proposed truck–drone system shows an average cost saving of 34% compared to the truck-only case. Moreover, deep insights into the impacts of multi-visit services, flexible docking, and simultaneous pickup and delivery on the performance of the truck–drone system are discussed.},
  archive      = {J_EJOR},
  author       = {Jie Jiang and Ying Dai and Fei Yang and Zujun Ma},
  doi          = {10.1016/j.ejor.2023.06.021},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {125-137},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A multi-visit flexible-docking vehicle routing problem with drones for simultaneous pickup and delivery services},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A branch-and-cut algorithm for the connected max-k-cut
problem. <em>EJOR</em>, <em>312</em>(1), 117–124. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Connected Max- k k -Cut Problem is an extension of the well-known Max-Cut Problem. The objective is to partition a graph into k k connected subgraphs by maximizing the cost of inter-partition edges. We propose a new integer linear program for the problem and a branch-and-cut algorithm. We also explore graph isomorphism to structure the instances and facilitate their resolution. We conduct extensive computational experiments on both randomly generated instances and instances from the literature where we compare the quality of our method against existing algorithms. The experimental results show that, if k &gt; 2 k&amp;gt;2 , our approach strictly outperforms those from the literature.},
  archive      = {J_EJOR},
  author       = {Patrick Healy and Nicolas Jozefowiez and Pierre Laroche and Franc Marchetti and Sébastien Martin and Zsuzsanna Róka},
  doi          = {10.1016/j.ejor.2023.06.015},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {117-124},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A branch-and-cut algorithm for the connected max-k-cut problem},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-objective mixed integer linear programming model for
thesis defence scheduling. <em>EJOR</em>, <em>312</em>(1), 92–116. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the thesis defence scheduling problem, a critical academic scheduling management process, which has been overshadowed in the literature by its counterparts, course timetabling and exam scheduling. Specifically, we address the single defence assignment type of thesis defence scheduling problems, where each committee is assigned to a single defence, scheduled for a specific day, hour and room. We formulate a multi-objective mixed-integer linear programming model, which aims to be applicable to a broader set of cases than other single defence assignment models present in the literature, which have a focus on the characteristics of their universities. For such a purpose, we introduce a different decision variable, propose constraint formulations that are not regulation and policy specific, and cover and offer new takes on the more common objectives seen in the literature. We also include new objective functions based on our experience with the problem at our university and by applying knowledge from other academic scheduling problems. We also propose a two-stage solution approach. The first stage is employed to find the number of schedulable defences, enabling the optimisation of instances with unschedulable defences. The second stage is an implementation of the augmented ϵ ϵ -constraint method, which allows for the search of a set of different and non-dominated solutions while skipping redundant iterations. The methodology is tested for case-studies from our university, significantly outperforming the solutions found by human schedulers. A novel instance generator for thesis scheduling problems is presented. Its main benefit is the generation of the availability of committee members and rooms in availability and unavailability blocks, resembling their real-world counterparts. A set of 96 randomly generated instances of varying sizes is solved and analysed regarding their relative computational performance, the number of schedulable defences and the distribution of the considered types of iterations. The proposed method can find the optimal number of schedulable defences and present non-dominated solutions within the set time limits for every tested instance.},
  archive      = {J_EJOR},
  author       = {João Almeida and Daniel Santos and José Rui Figueira and Alexandre P. Francisco},
  doi          = {10.1016/j.ejor.2023.06.031},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {92-116},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A multi-objective mixed integer linear programming model for thesis defence scheduling},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-armed bandit-based hyper-heuristics for combinatorial
optimization problems. <em>EJOR</em>, <em>312</em>(1), 70–91. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are significant research opportunities in the integration of Machine Learning (ML) methods and Combinatorial Optimization Problems (COPs). In this work, we focus on metaheuristics to solve COPs that have an important learning component. These algorithms must explore a solution space and learn from the information they obtain in order to find high-quality solutions. Among the metaheuristics, we study Hyper-Heuristics (HHs), algorithms that, given a number of low-level heuristics, iteratively select and apply heuristics to a solution. The HH we consider has a Markov model to produce sequences of low-level heuristics, which we combine with a Multi-Armed Bandit Problem (MAB)-based method to learn its parameters. This work proposes several improvements to the HH metaheuristic that yields a better learning for solving problem instances. Specifically, this is the first work in HHs to present Exponential Weights for Exploration and Exploitation (EXP3) as a learning method, an algorithm that is able to deal with adversarial settings. We also present a case study for the Vehicle Routing Problem with Time Windows (VRPTW), for which we include a list of low-level heuristics that have been proposed in the literature. We show that our algorithms can handle a large and diverse list of heuristics, illustrating that they can be easily configured to solve COPs of different nature. The computational results indicate that our algorithms are competitive methods for the VRPTW (2.16% gap on average with respect to the best known solutions), demonstrating the potential of these algorithms to solve COPs. Finally, we show how algorithms can even detect low-level heuristics that do not contribute to finding better solutions to the problem.},
  archive      = {J_EJOR},
  author       = {Felipe Lagos and Jordi Pereira},
  doi          = {10.1016/j.ejor.2023.06.016},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {70-91},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-armed bandit-based hyper-heuristics for combinatorial optimization problems},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lower and upper bounding procedures for the bin packing
problem with concave loading cost. <em>EJOR</em>, <em>312</em>(1),
56–69. (<a href="https://doi.org/10.1016/j.ejor.2023.06.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the one-dimensional bin packing problem with concave loading cost (BPPC), which commonly arises in less-than-truckload shipping services. Our contribution is twofold. First, we propose three lower bounds for this problem. The first one is the optimal solution of the continuous relaxation of the problem for which a closed form is proposed. The second one allows the splitting of items but not the fractioning of bins. The third one is based on a large-scale set partitioning formulation of the problem. In order to circumvent the challenges posed by the non-linearity of the objective function coefficients, we considered the inner-approximation of the concave load cost and derived a relaxed formulation that is solved by column generation. In addition, we propose two subset-sum-based heuristics. The first one is a constructive heuristic while the second one is a local search heuristic that iteratively attempts to improve the current solution by selecting pairs of bins and solving the corresponding subset sum-problem. We show that the worst-case performance of any BPPC heuristic and any concave loading cost function is bounded by 2. We present the results of an extensive computational study that was carried out on large set of benchmark instances. This study provides empirical evidence that the column generation-based lower bound and the local search heuristic consistently exhibit remarkable performance.},
  archive      = {J_EJOR},
  author       = {Mohamed Haouari and Mariem Mhiri},
  doi          = {10.1016/j.ejor.2023.06.028},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {56-69},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Lower and upper bounding procedures for the bin packing problem with concave loading cost},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). R-SALSA: A branch, bound, and remember algorithm for the
workload smoothing problem on simple assembly lines. <em>EJOR</em>,
<em>312</em>(1), 38–55. (<a
href="https://doi.org/10.1016/j.ejor.2023.06.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a simple assembly line balancing problem with given cycle time and number of stations. A quadratic objective function based on a so-called smoothness index SX levels the workloads of the stations. For this problem, called SALBP-SX, only a few solution procedures have been proposed in literature so far. In this paper, we extend and improve the branch-and-bound procedure SALSA ( S imple A ssembly L ine S moothing A lgorithm) of Walter et al. (2021) to a bidirectional branch, bound, and remember algorithm called R-SALSA ( R for remember). Like SALSA, it is based on a dynamic programming scheme which pre-determines potential workloads of the stations and provides a construction plan for possible station loads. This scheme is extended by the new concept of supporters and preventers which significantly enhances branching, bounding, and logical tests. Furthermore, a tailored heuristic that searches for improved initial solutions, a bidirectional branching scheme and additional dominance rules are integrated. In extensive computational experiments, we find out that our new procedure clearly outperforms all former exact solution procedures on benchmark data sets with up to 1000 tasks.},
  archive      = {J_EJOR},
  author       = {Philipp Schulze and Armin Scholl and Rico Walter},
  doi          = {10.1016/j.ejor.2023.06.007},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {38-55},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {R-SALSA: A branch, bound, and remember algorithm for the workload smoothing problem on simple assembly lines},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimizing grid capacity in preemptive electric vehicle
charging orchestration: Complexity, exact and heuristic approaches.
<em>EJOR</em>, <em>312</em>(1), 22–37. (<a
href="https://doi.org/10.1016/j.ejor.2023.05.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlike refueling an internal combustion engine vehicle, charging electric vehicles is time-consuming and results in higher energy consumption. Hence, charging stations will face several challenges in providing high-quality charging services when the adoption of electric vehicles increases. These charging infrastructures must satisfy charging demands without overloading the power grid. In this work, we investigate the problem of scheduling the charging of electric vehicles to reduce the maximum peak power while satisfying all charging demands. We consider a charging station where the installed chargers deliver a preemptive constant charging power. These chargers can either be identical or non-identical. For both cases, we address two optimization problems. First, we study the problem of finding the minimum number of chargers needed to plug a set of electric vehicles giving different arrival and departure times and required energies. We prove that this problem belongs to the complexity class P, and we provide polynomial-time algorithms. Then, we study the problem of minimizing the power grid capacity. For identical chargers, we prove that the problem is polynomial, whereas it is NP-hard in the case of non-identical chargers. We formulate these problems as a mixed-integer linear programming model for both cases. To obtain near-optimal solutions for the NP-hard problem, we propose a heuristic and an iterated local search metaheuristic. Through computational results, we demonstrate the effectiveness of the proposed approaches in terms of reducing the grid capacity.},
  archive      = {J_EJOR},
  author       = {I. Zaidi and A. Oulamara and L. Idoumghar and M. Basset},
  doi          = {10.1016/j.ejor.2023.05.039},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {22-37},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Minimizing grid capacity in preemptive electric vehicle charging orchestration: Complexity, exact and heuristic approaches},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review and classification on distributed permutation
flowshop scheduling problems. <em>EJOR</em>, <em>312</em>(1), 1–21. (<a
href="https://doi.org/10.1016/j.ejor.2023.02.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Distributed Permutation Flowshop Scheduling (DPFS) problem is one of the fastest-growing topics in the scheduling literature, which in turn is among the most prolific fields in Operational Research (OR). Although the problem has been formally stated only twelve years ago, the number of papers on the topic is growing at a rapid pace, and the rising interest –both from academics and practitioners– on distributed manufacturing paradigms seems to indicate that this trend will continue to increase. Possibly as a side effect of this steady growth, the state-of-the-art on many decision problems within the field is far from being clear, with substantial overlaps in the solution procedures, lack of (fair) comparisons against existing methods, or the use of different denominations for the same problem, among other issues. In this paper, we carry out a review of the DPFS literature aimed at providing a classification and notation for DPFS problems under a common framework. Within this framework, contributions are exhaustively presented and discussed, together with the state-of-the-art of the problems and lines for future research.},
  archive      = {J_EJOR},
  author       = {Paz Perez-Gonzalez and Jose M. Framinan},
  doi          = {10.1016/j.ejor.2023.02.001},
  journal      = {European Journal of Operational Research},
  month        = {1},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A review and classification on distributed permutation flowshop scheduling problems},
  volume       = {312},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
