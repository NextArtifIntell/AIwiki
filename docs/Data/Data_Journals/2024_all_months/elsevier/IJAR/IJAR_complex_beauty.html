<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJAR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijar---163">IJAR - 163</h2>
<ul>
<li><details>
<summary>
(2024). Convex expectations for countable-state uncertain processes
with càdlàg sample paths. <em>IJAR</em>, <em>175</em>, 109308. (<a
href="https://doi.org/10.1016/j.ijar.2024.109308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates convex expectations, mainly in the setting of uncertain processes with countable state space. In the general setting it shows how, under the assumption of downward continuity, a convex expectation on a linear lattice of bounded functions can be extended to a convex expectation on the measurable extended real functions. This result is especially relevant in the setting of uncertain processes: there, an easy way to obtain a convex expectation on the linear lattice of finitary bounded functions is to combine an initial convex expectation with a convex transition semigroup. Crucially, this work presents a sufficient condition on this semigroup which guarantees that the induced convex expectation is downward continuous, so that it can be extended to the set of measurable extended real functions. To conclude, this work looks at existing results on convex transition semigroups from the point of view of the aforementioned sufficient condition, in particular to construct a sublinear Poisson process.},
  archive      = {J_IJAR},
  author       = {Alexander Erreygers},
  doi          = {10.1016/j.ijar.2024.109308},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109308},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Convex expectations for countable-state uncertain processes with càdlàg sample paths},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximate inference on optimized quantum bayesian
networks. <em>IJAR</em>, <em>175</em>, 109307. (<a
href="https://doi.org/10.1016/j.ijar.2024.109307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a significant upsurge in the interest surrounding Quantum machine learning, with researchers actively developing methods to leverage the power of quantum technology for solving highly complex problems across various domains. However, implementing gate-based quantum algorithms on noisy intermediate quantum devices (NISQ) presents notable challenges due to limited quantum resources and inherent noise. In this paper, we propose an innovative approach for representing Bayesian networks on quantum circuits, specifically designed to address these challenges and highlight the potential of combining optimized circuits with quantum hybrid algorithms for Bayesian network inference. Our aim is to minimize the required quantum resource needed to implement a Quantum Bayesian network (QBN) and implement quantum approximate inference algorithm on a quantum computer. Through simulations and experiments on IBM Quantum computers, we show that our circuit representation significantly reduces the resource requirements without decreasing the performance of the model. These findings underscore how our approach can better enable practical applications of QBN on currently available quantum hardware.},
  archive      = {J_IJAR},
  author       = {Walid Fathallah and Nahla Ben Amor and Philippe Leray},
  doi          = {10.1016/j.ijar.2024.109307},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109307},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Approximate inference on optimized quantum bayesian networks},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dissection of the monotonicity property of binary
operations from a dominance point of view. <em>IJAR</em>, <em>175</em>,
109304. (<a href="https://doi.org/10.1016/j.ijar.2024.109304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we expound weaker forms of increasingness of binary operations on a lattice by reducing the number of variables involved in the classical formulation of the increasingness property as seen from the viewpoint of dominance between binary operations. We investigate the relationships among these weaker forms. Furthermore, we demonstrate the role of these weaker forms in characterizing the meet and join operations of a lattice and a chain in particular. Finally, we provide ample generic examples.},
  archive      = {J_IJAR},
  author       = {Yuntian Wang and Lemnaouar Zedam and Bao Qing Hu and Bernard De Baets},
  doi          = {10.1016/j.ijar.2024.109304},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109304},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A dissection of the monotonicity property of binary operations from a dominance point of view},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Selected papers from the first international joint
conference on conceptual knowledge structures. <em>IJAR</em>,
<em>175</em>, 109303. (<a
href="https://doi.org/10.1016/j.ijar.2024.109303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJAR},
  author       = {Inma P. Cabrera and Sébastien Ferré and Sergei Obiedkov},
  doi          = {10.1016/j.ijar.2024.109303},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109303},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Selected papers from the first international joint conference on conceptual knowledge structures},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed fusion-based algorithms for learning
high-dimensional bayesian networks: Testing ring and star topologies.
<em>IJAR</em>, <em>175</em>, 109302. (<a
href="https://doi.org/10.1016/j.ijar.2024.109302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning Bayesian Networks (BNs) from high-dimensional data is a complex and time-consuming task. Although there are approaches based on horizontal (instances) or vertical (variables) partitioning in the literature, none can guarantee the same theoretical properties as the Greedy Equivalence Search (GES) algorithm, except those based on the GES algorithm itself. This paper proposes a parallel distributed framework that uses GES as its local learning algorithm, obtaining results similar to those of GES and guaranteeing its theoretical properties but requiring less execution time. The framework involves splitting the set of all possible edges into clusters and constraining each framework node to only work with the received subset of edges. The global learning process is an iterative algorithm that carries out rounds until a convergence criterion is met. We have designed a ring and a star topology to distribute node connections. Regardless of the topology, each node receives a BN as input; it then fuses it with its own BN model and uses the result as the starting point for a local learning process, limited to its own subset of edges. Once finished, the result is then sent to another node as input. Experiments were carried out on a large repertory of domains, including large BNs up to more than 1000 variables. Our results demonstrate our proposal&#39;s effectiveness compared to GES and its fast version (fGES), generating high-quality BNs in less execution time.},
  archive      = {J_IJAR},
  author       = {Jorge D. Laborda and Pablo Torrijos and José M. Puerta and José A. Gámez},
  doi          = {10.1016/j.ijar.2024.109302},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109302},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Distributed fusion-based algorithms for learning high-dimensional bayesian networks: Testing ring and star topologies},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uncertainty-based knowledge distillation for bayesian deep
neural network compression. <em>IJAR</em>, <em>175</em>, 109301. (<a
href="https://doi.org/10.1016/j.ijar.2024.109301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models have been widely employed across various fields. In real-world scenarios, especially safety-critical applications, quantifying uncertainty is as crucial as achieving high accuracy. To address this concern, Bayesian deep neural networks (BDNNs) emerged to estimate two different types of uncertainty: Aleatoric and Epistemic. Nevertheless, implementing a BDNN on resource-constrained devices poses challenges due to the substantial computational and storage costs imposed by approximation inference techniques. Thus, efficient compression methods should be utilized. We propose an uncertainty-based knowledge distillation method to compress BDNNs. Knowledge distillation is a model compression technique that involves transferring knowledge from a complex network, known as the teacher network, to a simpler one, referred to as the student network. Our method incorporates uncertainty into knowledge distillation to address situations where inappropriate teacher supervision undermines compression performance. We utilize the Epistemic uncertainty of teacher predictions to tailor supervision for each sample individually to take into account teacher&#39;s limited knowledge. Additionally, we adjust the temperature parameter of the distillation process for each sample based on the Aleatoric uncertainty of the teacher predictions, ensuring that the student receives appropriate supervision even in the presence of ambiguous data. As a result, the proposed method enables the Bayesian student network to be trained under both appropriate supervision of the Bayesian teacher network and ground truth labels. We evaluated our method on the CIFAR-10, CIFAR-100, and RAF-DB datasets, demonstrating notable improvements in accuracy over state-of-the-art knowledge distillation-based methods. Furthermore, the robustness of our approach was assessed through testing weakly trained teacher networks and the analysis of blurred and low-resolution data, which have high uncertainty. Experimental results show that the proposed method outperformed existing methods.},
  archive      = {J_IJAR},
  author       = {Mina Hemmatian and Ali Shahzadi and Saeed Mozaffari},
  doi          = {10.1016/j.ijar.2024.109301},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109301},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Uncertainty-based knowledge distillation for bayesian deep neural network compression},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Belief rule learning and reasoning for classification based
on fuzzy belief decision tree. <em>IJAR</em>, <em>175</em>, 109300. (<a
href="https://doi.org/10.1016/j.ijar.2024.109300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The belief rules which extend the classical fuzzy IF-THEN rules with belief consequent parts have been widely used for classifier design due to their capabilities of building linguistic models interpretable to users and addressing various types of uncertainty. However, in the rule learning process, a high number of features generally results in a belief rule base with large size, which degrades both the classification accuracy and the model interpretability. Motivated by this challenge, the decision tree building technique which implements feature selection and model construction jointly is introduced in this paper to learn a compact and accurate belief rule base. To this end, a new fuzzy belief decision tree (FBDT) with fuzzy feature partitions and belief leaf nodes is designed: a fuzzy information gain ratio is first defined as the feature selection criterion for node fuzzy splitting and then the belief distributions are introduced to the leaf nodes to characterize the class uncertainty. Based on the initial rules extracted from the constructed FBDT, a joint optimization objective considering both classification accuracy and model interpretability is then designed to further reduce the rule redundancy. Experimental results based on real datasets show that the proposed FBDT-based classification method has much smaller rule base and better interpretability than other rule-based methods on the premise of competitive accuracy.},
  archive      = {J_IJAR},
  author       = {Lianmeng Jiao and Han Zhang and Xiaojiao Geng and Quan Pan},
  doi          = {10.1016/j.ijar.2024.109300},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109300},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Belief rule learning and reasoning for classification based on fuzzy belief decision tree},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Three-way conceptual knowledge updating in incomplete
contexts. <em>IJAR</em>, <em>175</em>, 109299. (<a
href="https://doi.org/10.1016/j.ijar.2024.109299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We usually encounter incomplete data in daily life due to the uncertainty of data and limitation of data acquisition technology. In formal concept analysis, the incomplete formal context is used to reflect uncertain relation between objects and attributes caused by missing data. The conceptual knowledge of the incomplete formal context is presented by a kind of three-way concept called partially-known formal concept. As time passes and technology matures, some initially missing data becomes obtainable, the incomplete formal context is updated accordingly, and the corresponding concepts change as well. However, obtaining partially-known concepts from the updated context based on definition is time-consuming and does not fully utilize the conceptual knowledge implicit in the original context. In order to make full use of existing conceptual knowledge and acquire new concepts quickly and efficiently, we discuss how to obtain new partially-known formal concepts by updating original partially-known formal concepts, and design corresponding concept updating algorithms. Finally, through data experiments, we validate that our proposed concept update algorithm can significantly improve the efficiency of concept acquisition, especially when the updating rate is small.},
  archive      = {J_IJAR},
  author       = {Ruisi Ren and Ling Wei and Jianjun Qi and Xiaosong Wei},
  doi          = {10.1016/j.ijar.2024.109299},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109299},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Three-way conceptual knowledge updating in incomplete contexts},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Chain graph structure learning based on minimal c-separation
trees. <em>IJAR</em>, <em>175</em>, 109298. (<a
href="https://doi.org/10.1016/j.ijar.2024.109298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chain graphs are a comprehensive class of graphical models that describe conditional independence information, encompassing both Markov networks and Bayesian networks as particular instances. In this paper, we propose a computationally feasible algorithm for the structural learning of chain graphs based on the idea of “dividing and conquering”, decomposing the learning problem into a set of minimal scale problems on its decomposed subgraphs. To this aim, we propose the concept of minimal c-separation trees in chain graphs and provide a mechanism to generate them, based on which we conduct structural learning using the divide and conquer technique. Experimental studies under various settings demonstrate that the presented structural learning algorithm for chain graphs generally outperforms existing methods. The code of this work is available at https://github.com/luyaoTan/mtlc .},
  archive      = {J_IJAR},
  author       = {Luyao Tan and Yi Sun and Yu Du},
  doi          = {10.1016/j.ijar.2024.109298},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109298},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Chain graph structure learning based on minimal c-separation trees},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Iterative algorithms for solving one-sided partially
observable stochastic shortest path games. <em>IJAR</em>, <em>175</em>,
109297. (<a href="https://doi.org/10.1016/j.ijar.2024.109297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world scenarios often involve dynamic interactions among competing agents, where decisions are made considering actions taken by others. These situations can be modeled as partially observable stochastic games ( POSG s), with zero-sum variants capturing strictly competitive interactions (e.g., security scenarios). While such models address a broad range of problems, they commonly focus on infinite-horizon scenarios with discounted-sum objectives. Using the discounted-sum objective, however, can lead to suboptimal solutions in cases where the length of the interaction does not directly affect the gained rewards of the players. We thus focus on games with undiscounted objective and an indefinite horizon where every realization of the game is guaranteed to terminate after some unspecified number of turns. To manage the computational complexity of solving POSG s in general, we restrict to games with one-sided partial observability where only one player has imperfect information while their opponent is provided with full information about the current situation. We introduce two novel algorithms based on the heuristic search value iteration ( HSVI ) algorithm that iteratively solve sequences of easier-to-solve approximations of the game using fundamentally different approaches for constructing the sequences: (1) in GoalHorizon , the game approximations are based on a limited number of turns in which players can change their actions, (2) in GoalDiscount , the game approximations are constructed using an increasing discount factor. We provide theoretical qualitative guarantees for algorithms, and we also experimentally demonstrate that these algorithms are able to find near-optimal solutions on pursuit-evasion games and a game modeling privilege escalation problem from computer security.},
  archive      = {J_IJAR},
  author       = {Petr Tomášek and Karel Horák and Branislav Bošanský},
  doi          = {10.1016/j.ijar.2024.109297},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109297},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Iterative algorithms for solving one-sided partially observable stochastic shortest path games},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy implications-based transformation approaches from
semi-three-way decision spaces to three-way decision spaces and their
applications. <em>IJAR</em>, <em>175</em>, 109296. (<a
href="https://doi.org/10.1016/j.ijar.2024.109296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision spaces, as an important component of three-way decisions, greatly enrich their theoretical development and application prospects. Meanwhile, fuzzy implications, as a vital class of fuzzy logic connectives, have made great contributions to the solution of practical problems, especially complex decision-making problems. This paper considers the collaborative effect of the two, which inject new vitality into the theoretical development and application prospects of fuzzy implications and three-way decision spaces. As a vital component of three-way decision spaces, (semi-)decision evaluation functions have been widely studied based on fuzzy logic connectives and become a research hotspot. Specifically, this paper focuses on fuzzy implications-based transformation approaches from semi-three-way decision spaces to three-way decision spaces and their applications. Firstly, we present some novel fuzzy implications-based transformation approaches from semi-decision evaluation functions to decision evaluation functions, and construction approaches of semi-decision evaluation functions involving the existing semi-decision evaluation functions, fuzzy sets, interval-valued fuzzy sets and fuzzy relations. Secondly, we discuss the relationship between our approaches and the known construction approaches of three-way decision spaces. Notably, our approaches cover all existing approaches except the uninorms-based approaches. Finally, by the experiment results, we obtain our approaches are feasible, effective, superior to the known three-way decision spaces approaches and have good anti-noise ability. And, the parameter ρ of our approaches is also effective and stable.},
  archive      = {J_IJAR},
  author       = {Yiding Wang and Junsheng Qiao and Tengbiao Li},
  doi          = {10.1016/j.ijar.2024.109296},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109296},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Fuzzy implications-based transformation approaches from semi-three-way decision spaces to three-way decision spaces and their applications},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximations of system w for inference from strongly and
weakly consistent belief bases. <em>IJAR</em>, <em>175</em>, 109295. (<a
href="https://doi.org/10.1016/j.ijar.2024.109295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we investigate approximations of the inductive inference operator system W that has been shown to exhibit desirable inference properties and to extend both system Z, and thus rational closure, and c-inference. For versions of these inference operators that are extended to also cover inference from belief bases that are only weakly consistent, we first show that extended system Z and extended c-inference are captured by extended system W. Then we introduce general functions for generating inductive inference operators: the combination of two inductive inference operators by union, and the completion of an inductive inference operator by an arbitrary set of axioms. We construct the least inductive inference operator extending system Z and c-inference that is closed under system P and show that it is still strictly extended by extended system W. Furthermore, we introduce an inductive inference operator that strictly extends extended system W and that is strictly extended by lexicographic inference. This leads to a comprehensive map of inference relations between rational closure and extended c-inference on the one side and lexicographic inference on the other side with extended system W and its approximations at its centre, where all relationships also hold for the unextended versions.},
  archive      = {J_IJAR},
  author       = {Jonas Haldimann and Christoph Beierle},
  doi          = {10.1016/j.ijar.2024.109295},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109295},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Approximations of system w for inference from strongly and weakly consistent belief bases},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On permutations dependent operators. <em>IJAR</em>,
<em>175</em>, 109294. (<a
href="https://doi.org/10.1016/j.ijar.2024.109294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce permutations dependent operators. The motivation for studying such a concept arises from standard fuzzy integrals, where permutations play a crucial role. In contrast to standard fuzzy integrals, our construction allows any permutation of the basic set in a formula to be considered, rather than limiting it to permutations that reorder the components of the input vector monotonically. We herein present an approach to integration with respect to sets of permutation pairs, i.e., databases in which each vector has a preselected permutation. This new operator generalizes several concepts known in the literature. We investigate the properties of this new concept and highlight its practical utility in image processing.},
  archive      = {J_IJAR},
  author       = {Stanislav Basarik and Lenka Halčinová},
  doi          = {10.1016/j.ijar.2024.109294},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109294},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {On permutations dependent operators},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Three-way concept lattice based on boolean formal context.
<em>IJAR</em>, <em>175</em>, 109286. (<a
href="https://doi.org/10.1016/j.ijar.2024.109286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of formal concept analysis (FCA) is an important mathematical method for knowledge representation and knowledge discovery. The Boolean formal context is proposed by introducing Boolean matrices and logical operations into FCA. Based on the concept lattice of the Boolean formal context and the column vector(row-vector)-oriented concept lattice of the Boolean formal context, this paper proposes the column vector(row vector)-induced three-way concept lattice of the Boolean formal context and the column vector(row vector)-induced three-way column vector(row vector)-oriented concept lattice of the Boolean formal context, and proves their rationality. Then, the isomorphism between the three-way concept lattice of the Boolean formal context and the three-way concept lattice of the general formal context is proved.},
  archive      = {J_IJAR},
  author       = {Dong-Yun Niu and Ju-Sheng Mi},
  doi          = {10.1016/j.ijar.2024.109286},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109286},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Three-way concept lattice based on boolean formal context},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An implementation of nonmonotonic reasoning with
c-representations using an SMT solver. <em>IJAR</em>, <em>175</em>,
109285. (<a href="https://doi.org/10.1016/j.ijar.2024.109285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A qualitative conditional “If A then usually B” establishes a plausible connection between the antecedent A and the consequent B. As a semantics for conditional knowledge bases containing such conditionals, ranking functions order possible worlds by mapping them to a degree of plausibility. c-Representations are special ranking functions that are obtained by assigning individual integer impacts to the conditionals in a knowledge base R R and by defining the rank of each possible world as the sum of these impacts of falsified conditionals. c-Inference is the nonmonotonic inference relation taking all c-representations of a given knowledge base R R into account. In this paper, we show how c-inference can be realized as a satisfiability modulo theories problem (SMT), which allows an implementation by an appropriate SMT solver. Moreover, we show that this leads to the first implementation fully realizing c-inference because it does not require a predefined upper limit for the impacts assigned to the conditionals. We develop a transformation of the constraint satisfaction problem characterizing c-inference into a solvable-equivalent SMT problem, prove its correctness, and illustrate it by a running example. Furthermore, we provide a corresponding implementation using the SMT solver Z3. We develop and implement a randomized generation scheme for knowledge bases and queries, and evaluate our SMT-based implementation of c-inference with respect to such randomly generated knowledge bases. Our evaluation demonstrates the feasibility of our approach as well as the superiority in comparison to former implementations of c-inference.},
  archive      = {J_IJAR},
  author       = {Martin von Berg and Arthur Sanin and Christoph Beierle},
  doi          = {10.1016/j.ijar.2024.109285},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109285},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {An implementation of nonmonotonic reasoning with c-representations using an SMT solver},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Logical syllogisms with “almost all, most, many, a few” and
“several.” <em>IJAR</em>, <em>175</em>, 109284. (<a
href="https://doi.org/10.1016/j.ijar.2024.109284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper delves into logical syllogisms featuring intermediate quantifiers. In our previous works, we established the validity of logical syllogisms involving fundamental intermediate quantifiers “Almost all”, “Most”, and “Many”. In this paper, we focus on syllogisms incorporating also the quantifiers “Several” and “A few (A little)”.},
  archive      = {J_IJAR},
  author       = {Petra Murinová and Vilém Novák},
  doi          = {10.1016/j.ijar.2024.109284},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109284},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Logical syllogisms with “Almost all, most, many, a few” and “Several”},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decision with belief functions and generalized independence:
Two impossibility theorems. <em>IJAR</em>, <em>175</em>, 109283. (<a
href="https://doi.org/10.1016/j.ijar.2024.109283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster-Shafer theory of evidence is a framework that is expressive enough to represent both ignorance and probabilistic information. However, decision models based on belief functions proposed in the literature face limitations in a sequential context: they either abandon the principle of dynamic consistency, restrict the combination of lotteries, or relax the requirement for transitive and complete comparisons. This work formally establishes that these requirements are indeed incompatible when any form of compensation is considered. It then demonstrates that these requirements can be satisfied in non-compensatory frameworks by introducting and characterizing a dynamically consistent rule based on first-order dominance.},
  archive      = {J_IJAR},
  author       = {Helene Fargier and Romain Guillaume},
  doi          = {10.1016/j.ijar.2024.109283},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109283},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Decision with belief functions and generalized independence: Two impossibility theorems},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Grounded semantics and principle-based analysis for
incomplete argumentation frameworks. <em>IJAR</em>, <em>175</em>,
109282. (<a href="https://doi.org/10.1016/j.ijar.2024.109282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete Argumentation Frameworks (IAFs) enrich classical abstract argumentation with arguments and attacks whose actual existence is questionable. The usual reasoning approaches rely on the notion of completion, i.e. standard AFs representing “possible worlds” compatible with the uncertain information encoded in the IAF. Recently, extension-based semantics for IAFs that do not rely on the notion of completion have been defined, using instead new versions of conflict-freeness and defense that take into account the (certain or uncertain) nature of arguments and attacks. In this paper, we give new insights on both the “completion-based” and the “direct” reasoning approaches. First, we adapt the well-known grounded semantics to this framework in two different versions that do not rely on completions. After determining that our new semantics are polynomially computable, we provide a principle-based analysis of these semantics, as well as the “direct” semantics previously defined in the literature, namely the complete, preferred and stable semantics. Finally, we also provide new results regarding the satisfaction of principles by the classical “completion-based” semantics.},
  archive      = {J_IJAR},
  author       = {Jean-Guy Mailly},
  doi          = {10.1016/j.ijar.2024.109282},
  journal      = {International Journal of Approximate Reasoning},
  month        = {12},
  pages        = {109282},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Grounded semantics and principle-based analysis for incomplete argumentation frameworks},
  volume       = {175},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust support function machines for set-valued data
classification. <em>IJAR</em>, <em>174</em>, 109281. (<a
href="https://doi.org/10.1016/j.ijar.2024.109281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support function machines (SFMs) have been proposed to handle set-valued data, but they are sensitive to outliers and unstable for re-sampling due to the use of the hinge loss function. To address these problems, we propose a robust SFM model with proximity functions. We first define a family of proximity functions that are used to convert set-valued data into continuous functions in a Banach space, and then we use the margin maximization in a Banach space to construct the pinball SFMs (PinSFMs). We study some properties of the proposed model, and it is interesting to observe that the optimal measure of the proposed model has a specific representation under the total variation norm. Using the representation of the optimal measure, we convert an infinite-dimensional optimization problem into a finite-dimensional optimization problem. Unlike SFMs, we employ a sampling strategy to tackle the finite-dimensional optimization problem. We theoretically show that the sparse solution determines the sparsity of the sampling points though the sampling strategy causes uncertainty for the sampling points. In addition, we achieve kernel versions of proximity functions, and the attractive property of this kernelization is that the proposed model is convex even if indefinite kernels are employed. Experiments on a series of data sets are performed to demonstrate that the proposed model is superior to some existing models in the presence of outliers.},
  archive      = {J_IJAR},
  author       = {Zhizheng Liang and Yuhan Min},
  doi          = {10.1016/j.ijar.2024.109281},
  journal      = {International Journal of Approximate Reasoning},
  month        = {11},
  pages        = {109281},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Robust support function machines for set-valued data classification},
  volume       = {174},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Three-way concept lattice from adjunctive positive and
negative concepts. <em>IJAR</em>, <em>174</em>, 109272. (<a
href="https://doi.org/10.1016/j.ijar.2024.109272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way concept lattices (TCLs) have been widely explored due to their clear hierarchical structures, concise visual description and good interpretability. In contrast to classic formal contexts, lattice-valued fuzzy contexts exhibit great capability in describing and representing concepts with uncertainty. Different from conventional approaches to research of TCLs, this paper focuses on investigating the algebraic structure and properties of three-way concept lattice (TCL) stemmed from the positive concept lattice and negative concept lattice in a lattice-valued formal context. Several associated concept lattices such as the Cartesian product of positive concept lattice and negative lattice (i.e., pos-neg lattice), lattices induced from the partition of the pos-neg lattice, and their relationship are explored. Specifically, the isomorphism, embedding and order-preserving mappings between them are built. The quotient set of pos-neg lattice when being defined a specific equivalence relation on it is a complete lattice and each equivalence class is a lower semi-lattice. It is further declared that the structure of TCL is intrinsically and determined wholly by the pos-neg lattice. A practical application of the built theory of TCL is provided to sort alternatives in multi-criteria decision making.},
  archive      = {J_IJAR},
  author       = {Binghan Long and Tingquan Deng and Yiyu Yao and Weihua Xu},
  doi          = {10.1016/j.ijar.2024.109272},
  journal      = {International Journal of Approximate Reasoning},
  month        = {11},
  pages        = {109272},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Three-way concept lattice from adjunctive positive and negative concepts},
  volume       = {174},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neighborhood margin rough set: Self-tuning neighborhood
threshold. <em>IJAR</em>, <em>174</em>, 109271. (<a
href="https://doi.org/10.1016/j.ijar.2024.109271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neighborhood threshold in the neighborhood rough set has a significant impact on the neighborhood relation. When the neighborhood threshold of an object exceeds the critical value, the labels of objects in the neighborhood are not completely consistent, and the critical value of each object often differs. Most existing neighborhood rough set models cannot adaptively regulate the neighborhood threshold. In this paper, we introduce a novel neighborhood rough set model that incorporates a self-tuning mechanism for the neighborhood threshold, taking into account the distribution of objects across different areas. The neighborhood margin is a measure proposed to assess the condition of neighborhoods, and it is calculated by subtracting the neighborhood threshold from the closest distance between heterogeneous elements. The neighborhood margin accurately represents the local state of the neighborhood, taking into account decision information. The margin neighborhood is proposed with a self-tuning the neighborhood threshold. Finally, we introduce the margin neighborhood rough set model and margin neighborhood-based attribute reduction algorithm, and explore the relationship between the proposed model and the neighborhood rough set model. The experiment examines the performance of reducts under various measures, and demonstrates that the neighborhood margin rough set reduces the uncertainty of neighborhood granules effectively, leading to excellent classification performance compared to other neighborhood-based SOTA models.},
  archive      = {J_IJAR},
  author       = {Mingjie Cai and Haichao Wang and Feng Xu and Qingguo Li},
  doi          = {10.1016/j.ijar.2024.109271},
  journal      = {International Journal of Approximate Reasoning},
  month        = {11},
  pages        = {109271},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Neighborhood margin rough set: Self-tuning neighborhood threshold},
  volume       = {174},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Formal and cognitive reasoning. <em>IJAR</em>, <em>174</em>,
109270. (<a href="https://doi.org/10.1016/j.ijar.2024.109270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJAR},
  author       = {Christoph Beierle and Marco Ragni and Kai Sauerwald and Frieder Stolzenburg and Matthias Thimm},
  doi          = {10.1016/j.ijar.2024.109270},
  journal      = {International Journal of Approximate Reasoning},
  month        = {11},
  pages        = {109270},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Formal and cognitive reasoning},
  volume       = {174},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Description lattices of generalised convex hulls.
<em>IJAR</em>, <em>174</em>, 109269. (<a
href="https://doi.org/10.1016/j.ijar.2024.109269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a new approach to tackle lattice generation for complex and heterogeneous data using the concept of convexity. This is a work that we have already carried out, albeit intuitively [11] where we proposed the NextPriorityConcept algorithm for generating a meet-semilattice of concepts based on suitable descriptions and strategies. Now, we revisit the essential properties of our description spaces using a stronger formalism based on the properties of closure operators.},
  archive      = {J_IJAR},
  author       = {Christophe Demko and Karell Bertet and Jean-François Viaud and Cyril Faucher and Damien Mondou},
  doi          = {10.1016/j.ijar.2024.109269},
  journal      = {International Journal of Approximate Reasoning},
  month        = {11},
  pages        = {109269},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Description lattices of generalised convex hulls},
  volume       = {174},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the enumeration of non-dominated matroids with imprecise
weights. <em>IJAR</em>, <em>174</em>, 109266. (<a
href="https://doi.org/10.1016/j.ijar.2024.109266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many works within robust combinatorial optimisation consider interval-valued costs or constraints. While most of these works focus on finding a unique solution following a robust criteria such as minimax, a few consider the problem of characterising a set of possibly optimal solutions. This paper is situated within this line of work, and considers the problem of exactly enumerating the set of possibly optimal matroids under interval-valued costs. We show in particular that each solution in this set can be obtained through a polynomial procedure, and provide an efficient algorithm to achieve the enumeration.},
  archive      = {J_IJAR},
  author       = {Tom Davot and Tuan-Anh Vu and Sébastien Destercke and David Savourey},
  doi          = {10.1016/j.ijar.2024.109266},
  journal      = {International Journal of Approximate Reasoning},
  month        = {11},
  pages        = {109266},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {On the enumeration of non-dominated matroids with imprecise weights},
  volume       = {174},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of three-way decision: Triadic understanding,
organization, and perspectives. <em>IJAR</em>, <em>173</em>, 109268. (<a
href="https://doi.org/10.1016/j.ijar.2024.109268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A theory of three-way decision is about thinking, problem-solving, and computing in threes or through triads. In this paper, we review fifteen years of research on three-way decision by using the philosophy-theory-application triad and the who-what-when triad. First, we discuss the philosophy, theory, and application of three-way decision. At the philosophy level, we delve into the philosophical roots and fundamental nature of three-way decision to reveal the underlying philosophical thinking. At the theory level, we provide an insightful analysis of the theory and methodology of three-way decision. At the application level, we examine the integration of three-way decision with other theories and their applications and effectiveness in real-world scenarios. Second, we focus on bibliometrics analytics by using the who-what-when triad, which attempts to answer a fundamental question of “who did what when”. We propose a 3 × 3 3×3 model by applying the 3 × 3 3×3 method of three-way decision. The first 3 is the author-topic-time triad. The second 3 represents a three-level analysis for each of the first three: (1) categorizing authors into the three levels of prolific authors, frequent authors, and occasional authors, (2) classifying topics into the three levels of the core topics, emerging topics, and to-be-explored topics, and (3) dividing articles into the three levels of initial investigations, further developments, and most recent studies. Finally, we perform a bibliometrics analysis of three-way decision articles by using the 3 × 3 3×3 model of three-way decision. The results not only reveal the current status and trend of three-way decision research but also provide a road map for future research.},
  archive      = {J_IJAR},
  author       = {Langwangqing Suo and Han Yang and Qiaoyi Li and Hai-Long Yang and Yiyu Yao},
  doi          = {10.1016/j.ijar.2024.109268},
  journal      = {International Journal of Approximate Reasoning},
  month        = {10},
  pages        = {109268},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A review of three-way decision: Triadic understanding, organization, and perspectives},
  volume       = {173},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identifying arguments within a text: Categorizing errors and
their impact in arguments’ relation prediction. <em>IJAR</em>,
<em>173</em>, 109267. (<a
href="https://doi.org/10.1016/j.ijar.2024.109267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic identification of argument units within a text is a crucial task, as it is the first step that should be performed by an end-to-end argument mining system. In this work, we propose an approach for categorizing errors in predicted argument units, which allows the evaluation of segmentation models from an argumentative perspective. We assess the ability of several models to generalize knowledge across different text domains and, through the proposed categorization, we show differences in their behavior that may not be noticeable using standard classification metrics. Furthermore, we assess how the errors in predicted argument units impact on a task that rely on accurate unit identification, an aspect that has not been studied in previous research, and that helps to evaluate the usability of an imperfect segmentation model beyond the segmentation task itself.},
  archive      = {J_IJAR},
  author       = {Federico M. Schmidt and Sebastian Gottifredi and Alejandro J. García},
  doi          = {10.1016/j.ijar.2024.109267},
  journal      = {International Journal of Approximate Reasoning},
  month        = {10},
  pages        = {109267},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Identifying arguments within a text: Categorizing errors and their impact in arguments&#39; relation prediction},
  volume       = {173},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pairwise comparison matrices with uniformly ordered
efficient vectors. <em>IJAR</em>, <em>173</em>, 109265. (<a
href="https://doi.org/10.1016/j.ijar.2024.109265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our primary interest is understanding reciprocal matrices all of whose efficient vectors are ordinally the same, i.e., there is only one efficient order (we call these matrices uniformly ordered, UO). These are reciprocal matrices for which no efficient vector produces strict order reversals. A reciprocal matrix is called column ordered (CO) if each column is ordinally the same. Efficient vectors for a CO matrix with the same order of the columns always exist. For example, the entry-wise geometric mean of some or all columns of a reciprocal matrix is efficient and, if the matrix is CO, has the same order of the columns. A necessary, but not sufficient, condition for UO is that the matrix be CO and then the only efficient order should be satisfied by the columns (possibly weakly). In the case n = 3 n=3 , CO is necessary and sufficient for UO, but not for n &gt; 3 n&amp;gt;3 . We characterize the 4-by-4 UO matrices and identify the three possible alternate orders when the matrix is CO (and give entry-wise conditions for their occurrence). We also describe the simple perturbed consistent matrices that are UO. Some of the technology developed for this purpose is of independent interest.},
  archive      = {J_IJAR},
  author       = {Susana Furtado and Charles R. Johnson},
  doi          = {10.1016/j.ijar.2024.109265},
  journal      = {International Journal of Approximate Reasoning},
  month        = {10},
  pages        = {109265},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Pairwise comparison matrices with uniformly ordered efficient vectors},
  volume       = {173},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The most likely common cause. <em>IJAR</em>, <em>173</em>,
109264. (<a href="https://doi.org/10.1016/j.ijar.2024.109264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The common cause principle for two random variables A and B is examined in the case of causal insufficiency, when their common cause C is known to exist, but only the joint probability of A and B is observed. As a result, C cannot be uniquely identified (the latent confounder problem). We show that the generalized maximum likelihood method can be applied to this situation and allows identification of C that is consistent with the common cause principle. It closely relates to the maximum entropy principle. Investigation of the two binary symmetric variables reveals a non-analytic behavior of conditional probabilities reminiscent of a second-order phase transition. This occurs during the transition from correlation to anti-correlation in the observed probability distribution. The relation between the generalized likelihood approach and alternative methods, such as predictive likelihood and minimum common entropy, is discussed. The consideration of the common cause for three observed variables (and one hidden cause) uncovers causal structures that defy representation through directed acyclic graphs with the Markov condition.},
  archive      = {J_IJAR},
  author       = {A. Hovhannisyan and A.E. Allahverdyan},
  doi          = {10.1016/j.ijar.2024.109264},
  journal      = {International Journal of Approximate Reasoning},
  month        = {10},
  pages        = {109264},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {The most likely common cause},
  volume       = {173},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attribute reduction with fuzzy divergence-based weighted
neighborhood rough sets. <em>IJAR</em>, <em>173</em>, 109256. (<a
href="https://doi.org/10.1016/j.ijar.2024.109256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighborhood rough sets are well-known as an interesting approach for attribute reduction in numerical/continuous data tables. Nevertheless, in most existing neighborhood rough set models, all attributes are assigned the same weights. This may undermine the capacity to select important attributes, especially for high-dimensional datasets. To establish attribute weights, in this study, we will utilize fuzzy divergence to evaluate the distinction between each attribute with the whole attributes in classifying the objects to the decision classes. Then, we construct a new model of fuzzy divergence-based weighted neighborhood rough sets, as well as propose an efficient attribute reduction algorithm. In our method, reducts are considered under the scenario of the α -certainty region, which is introduced as an extension of the positive region. Several related properties will show that attribute reduction based on the α -certainty region can significantly enhance the ability to identify optimal attributes due to reducing the influence of noisy information. To validate the effectiveness of the proposed algorithm, we conduct experiments on 12 benchmark datasets. The results demonstrate that our algorithm not only significantly reduces the number of attributes compared to the original data but also enhances classification accuracy. In comparison to some other state-of-the-art algorithms, the proposed algorithm also outperforms in terms of classification accuracy for almost all of datasets, while also maintaining a highly competitive reduct size and computation time.},
  archive      = {J_IJAR},
  author       = {Nguyen Ngoc Thuy and Sartra Wongthanavasu},
  doi          = {10.1016/j.ijar.2024.109256},
  journal      = {International Journal of Approximate Reasoning},
  month        = {10},
  pages        = {109256},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Attribute reduction with fuzzy divergence-based weighted neighborhood rough sets},
  volume       = {173},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contribution functions for quantitative bipolar
argumentation graphs: A principle-based analysis. <em>IJAR</em>,
<em>173</em>, 109255. (<a
href="https://doi.org/10.1016/j.ijar.2024.109255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a principle-based analysis of contribution functions for quantitative bipolar argumentation graphs that quantify the contribution of one argument to another. The introduced principles formalise the intuitions underlying different contribution functions as well as expectations one would have regarding the behaviour of contribution functions in general. As none of the covered contribution functions satisfies all principles, our analysis can serve as a tool that enables the selection of the most suitable function based on the requirements of a given use case.},
  archive      = {J_IJAR},
  author       = {Timotheus Kampik and Nico Potyka and Xiang Yin and Kristijonas Čyras and Francesca Toni},
  doi          = {10.1016/j.ijar.2024.109255},
  journal      = {International Journal of Approximate Reasoning},
  month        = {10},
  pages        = {109255},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Contribution functions for quantitative bipolar argumentation graphs: A principle-based analysis},
  volume       = {173},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Difference operators on fuzzy sets. <em>IJAR</em>,
<em>173</em>, 109254. (<a
href="https://doi.org/10.1016/j.ijar.2024.109254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the properties of the difference operator on crisp sets, a fuzzy difference operator in fuzzy logic is defined as a continuous binary operator on the closed unit interval with some boundary conditions. In this paper, the structures and properties of fuzzy difference operators are studied. The main results are: (1) Using the axiomatic approach, some generalizations of classical tautologies for fuzzy difference operators are obtained. (2) Based on the model theoretic approach, the fuzzy difference operator constructed by a nilpotent t-norm and a strong negation is characterized. (3) the paper discusses the relationship between the fuzzy difference operator and symmetric difference operator which was raised in [3] .},
  archive      = {J_IJAR},
  author       = {Bo Wen Fang},
  doi          = {10.1016/j.ijar.2024.109254},
  journal      = {International Journal of Approximate Reasoning},
  month        = {10},
  pages        = {109254},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Difference operators on fuzzy sets},
  volume       = {173},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust weighted fuzzy margin-based feature selection with
three-way decision. <em>IJAR</em>, <em>173</em>, 109253. (<a
href="https://doi.org/10.1016/j.ijar.2024.109253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection has shown noticeable benefits to the tasks of machine learning and data mining, and an extensive variety of feature selection methods has been proposed to remove redundant and irrelevant features. However, most of the existing methods aim to find a feature subset to perfectly fit data with the minimum empirical risk, thus causing the problems of overfitting and noise sensitivity. In this study, a robust weighted fuzzy margin-based feature selection is proposed for uncertain data with noise. Concretely, a robust weighted fuzzy margin based on fuzzy rough sets is first introduced to evaluate the significance of different features. Then, a gradient ascent algorithm based on the noise filtering strategy and three-way decision is developed to optimize the sample and feature weights to further enlarge the fuzzy margin. Finally, an adaptive feature selection algorithm based on the robust weighted fuzzy margin is presented to generate an optimal feature subset with a large margin. Extensive experiments on the UCI benchmark datasets show that the proposed method could obtain high-quality feature subsets and outperform other representative methods under different noise rates.},
  archive      = {J_IJAR},
  author       = {Zhenxi Chen and Gong Chen and Can Gao and Jie Zhou and Jiajun Wen},
  doi          = {10.1016/j.ijar.2024.109253},
  journal      = {International Journal of Approximate Reasoning},
  month        = {10},
  pages        = {109253},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Robust weighted fuzzy margin-based feature selection with three-way decision},
  volume       = {173},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Beyond conjugacy for chain event graph model selection.
<em>IJAR</em>, <em>173</em>, 109252. (<a
href="https://doi.org/10.1016/j.ijar.2024.109252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chain event graphs are a family of probabilistic graphical models that generalise Bayesian networks and have been successfully applied to a wide range of domains. Unlike Bayesian networks, these models can encode context-specific conditional independencies as well as asymmetric developments within the evolution of a process. More recently, new model classes belonging to the chain event graph family have been developed for modelling time-to-event data to study the temporal dynamics of a process. However, existing Bayesian model selection algorithms for chain event graphs and its variants rely on all parameters having conjugate priors. This is unrealistic for many real-world applications. In this paper, we propose a mixture modelling approach to model selection in chain event graphs that does not rely on conjugacy. Moreover, we show that this methodology is more amenable to being robustly scaled than the existing model selection algorithms used for this family. We demonstrate our techniques on simulated datasets.},
  archive      = {J_IJAR},
  author       = {Aditi Shenvi and Silvia Liverani},
  doi          = {10.1016/j.ijar.2024.109252},
  journal      = {International Journal of Approximate Reasoning},
  month        = {10},
  pages        = {109252},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Beyond conjugacy for chain event graph model selection},
  volume       = {173},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy object-induced network three-way concept lattice and
its attribute reduction. <em>IJAR</em>, <em>173</em>, 109251. (<a
href="https://doi.org/10.1016/j.ijar.2024.109251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept cognition and knowledge discovery under network data combine formal concept analysis with complex network analysis. However, in real life, network data is uncertain due to some limitations. Fuzzy sets are a powerful tool to deal with uncertainty and imprecision. Therefore, this paper focuses on concept-cognitive learning in fuzzy network formal contexts. Fuzzy object-induced network three-way concept (network OEF-concept) lattices and their properties are mainly investigated. In addition, three fuzzy network weaken-concepts are proposed. As the real data is too large, attribute reduction can simplify concept-cognitive learning by removing redundant attributes. Thus, the paper proposes attribute reduction methods that can keep the concept lattice structure isomorphic and the set of extents of granular concepts unchanged. Finally, an example is given to show the attribute reduction process of a fuzzy network three-way concept lattice. Attribute reduction experiments are conducted on nine datasets, and the results prove the feasibility of attribute reduction.},
  archive      = {J_IJAR},
  author       = {Miao Liu and Ping Zhu},
  doi          = {10.1016/j.ijar.2024.109251},
  journal      = {International Journal of Approximate Reasoning},
  month        = {10},
  pages        = {109251},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Fuzzy object-induced network three-way concept lattice and its attribute reduction},
  volume       = {173},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning multi-granularity decision implication in
correlative data from a logical perspective. <em>IJAR</em>,
<em>173</em>, 109250. (<a
href="https://doi.org/10.1016/j.ijar.2024.109250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal Concept Analysis (FCA) is a method rooted in order theory, with the aim of analyzing and visually representing concepts. Decision implication serves as a fundamental means of knowledge representation in FCA in the case of decision-making. This paper extends the scope of knowledge discovery within FCA in single domains to the realm of multi-domains, with introducing a framework for knowledge representation and reasoning within correlative data from the perspectives of cross-domain and multi-granularity. Firstly, we delve into the acquisition and modeling of decision knowledge within correlative data, and introduce the concept of multi-granularity decision implication. We then establish multi-granularity decision implication logic to study the completeness, non-redundancy and optimality of multi-granularity decision implications and introduce inference rules with semantical compatibility. Furthermore, we define lattice fusion decision context to seamlessly integrate information within correlative data and construct a multi-granularity decision implication basis (MGDIB) based on lattice fusion decision context. Finally, we conduct an experiment of generating MGDIB based on GroupLens_MovieLens dataset.},
  archive      = {J_IJAR},
  author       = {Shaoxia Zhang and Yanhui Zhai and Deyu Li and Chao Zhang},
  doi          = {10.1016/j.ijar.2024.109250},
  journal      = {International Journal of Approximate Reasoning},
  month        = {10},
  pages        = {109250},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Learning multi-granularity decision implication in correlative data from a logical perspective},
  volume       = {173},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized possibility computation tree logic with
frequency and its model checking. <em>IJAR</em>, <em>173</em>, 109249.
(<a href="https://doi.org/10.1016/j.ijar.2024.109249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been significant research in the field of possibilistic temporal logic. However, existing works have not yet addressed the issue of frequency, which is a common form of uncertainty in the real world. This article aims to fill this gap by incorporating frequency information into possibilistic temporal logic and focusing on the model-checking problem of generalized possibility computation tree logic (GPoCTL) with frequency information. Specifically, we introduce generalized possibility computation tree logic with frequency (GPoCTL F ). Although its syntax can be considered as an extension of frequency constraints of the always operator (□) in GPoCTL, they are fundamentally different in semantics and model-checking methods. To facilitate this extension, useful frequency words such as “always”, “usually”, “often”, “sometimes”, “occasionally”, “rarely”, “hardly ever” and “never” are defined as fuzzy frequency operators in this article. Therefore, this article focuses on investigating the model-checking problem of the frequency-constrained always operator. In addition, we analyze the relationship between some GPoCTL F path formulas and GPoCTL path formulas. Then, we provide a model-checking algorithm for GPoCTL F and analyze its time complexity. Finally, an example of a social network is used to illustrate the calculation process of the proposed method and its potential applications.},
  archive      = {J_IJAR},
  author       = {Qing He and Wuniu Liu and Yongming Li},
  doi          = {10.1016/j.ijar.2024.109249},
  journal      = {International Journal of Approximate Reasoning},
  month        = {10},
  pages        = {109249},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Generalized possibility computation tree logic with frequency and its model checking},
  volume       = {173},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring the 3-dimensional variability of websites’
user-stories using triadic concept analysis. <em>IJAR</em>,
<em>173</em>, 109248. (<a
href="https://doi.org/10.1016/j.ijar.2024.109248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Configurable software systems and families of similar software systems are increasingly being considered by industry to provide software tailored to each customer&#39;s needs. Their development requires managing software variability, i.e. commonalities, differences and constraints. A primary step is properly analyzing the variability of software, which can be done at various levels, from specification to deployment. In this paper, we focus on the software variability expressed through user-stories, viz. short formatted sentences indicating which user role can perform which action at the specification level. At this level, variability is usually analyzed in a two dimension view, i.e. software described by features, and considering the roles apart. The novelty of this work is to model the three dimensions of the variability (i.e. software, roles, features) and explore it using Triadic Concept Analysis (TCA), an extension of Formal Concept Analysis. The variability exploration is based on the extraction of 3-dimensional implication rules. The adopted methodology is applied to a case study made of 65 commercial web sites in four domains, i.e. manga, martial arts sports equipment, board games including trading cards, and video-games. This work highlights the diversity of information provided by such methodology to draw directions for the development of a new product or for building software variability models.},
  archive      = {J_IJAR},
  author       = {Alexandre Bazin and Thomas Georges and Marianne Huchard and Pierre Martin and Chouki Tibermacine},
  doi          = {10.1016/j.ijar.2024.109248},
  journal      = {International Journal of Approximate Reasoning},
  month        = {10},
  pages        = {109248},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Exploring the 3-dimensional variability of websites&#39; user-stories using triadic concept analysis},
  volume       = {173},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic explorations in factorizing boolean data via formal
concepts. <em>IJAR</em>, <em>173</em>, 109247. (<a
href="https://doi.org/10.1016/j.ijar.2024.109247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We use now available psychological data involving human concepts, objects covered by these concepts, and binary attributes describing the objects to explore selected semantic aspects of Boolean matrix factorization. Our basic perspective derives from the intuitive requirement that the factors computed from data should represent natural categories latently present in the data. This idea is examined for factorization algorithms that utilize formal concepts to build factors. We provide several experimental observations which imply that the inspected factorization methods deliver semantically sound factors that resemble significant human concepts of the examined domains.},
  archive      = {J_IJAR},
  author       = {Radim Belohlavek and Martin Trnecka},
  doi          = {10.1016/j.ijar.2024.109247},
  journal      = {International Journal of Approximate Reasoning},
  month        = {10},
  pages        = {109247},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Semantic explorations in factorizing boolean data via formal concepts},
  volume       = {173},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Special issue: Thirteenth international symposium on
imprecise probabilities: Theories and applications (ISIPTA’2023).
<em>IJAR</em>, <em>172</em>, 109246. (<a
href="https://doi.org/10.1016/j.ijar.2024.109246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJAR},
  author       = {Ignacio Montes and Enrique Miranda and Barbara Vantaggi},
  doi          = {10.1016/j.ijar.2024.109246},
  journal      = {International Journal of Approximate Reasoning},
  month        = {9},
  pages        = {109246},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Special issue: thirteenth international symposium on imprecise probabilities: theories and applications (ISIPTA’2023)},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bimorphisms and attribute implications in heterogeneous
formal contexts. <em>IJAR</em>, <em>172</em>, 109245. (<a
href="https://doi.org/10.1016/j.ijar.2024.109245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal concept analysis is a powerful mathematical framework based on mathematical logic and lattice theory for analyzing object-attribute relational systems. Over the decades, Formal concept analysis has evolved from its theoretical foundations into a versatile methodology applied across various disciplines. A heterogeneous formal context provides a feasible generalization of a formal context, enabling diverse truth-degrees of objects, attributes, and fuzzy relations. In our paper, we present extended theoretical results on heterogeneous formal contexts, including bimorphisms, Galois connections, and heterogeneous attribute implications. We recall the basic notions and properties of the heterogeneous formal context and its concept lattice. Moreover, we present extended results on bimorphisms and Galois connections in a heterogeneous formal context, including a self-contained proof of the main result. We include examples of introduced notions in heterogeneous formal contexts and two-valued logic. We propose the extension of attribute implications for heterogeneous formal contexts and explore their validity. By embracing heterogeneity in Formal concept analysis, we enrich its extended theoretical foundations and pave the way for innovative applications across diverse domains, including personal data protection and cybersecurity.},
  archive      = {J_IJAR},
  author       = {Ľubomír Antoni and Peter Eliaš and Ján Guniš and Dominika Kotlárová and Stanislav Krajči and Ondrej Krídlo and Pavol Sokol and Ľubomír Šnajder},
  doi          = {10.1016/j.ijar.2024.109245},
  journal      = {International Journal of Approximate Reasoning},
  month        = {9},
  pages        = {109245},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Bimorphisms and attribute implications in heterogeneous formal contexts},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Arrow relations in lattices of integer partitions.
<em>IJAR</em>, <em>172</em>, 109244. (<a
href="https://doi.org/10.1016/j.ijar.2024.109244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give a complete characterisation of the single and double arrow relations of the standard context K(Ln) of the lattice Ln of partitions of any positive integer n under the dominance order, thereby addressing an open question of Ganter, 2020/2022.},
  archive      = {J_IJAR},
  author       = {Asma&#39;a Almazaydeh and Mike Behrisch and Edith Vargas-García and Andreas Wachtel},
  doi          = {10.1016/j.ijar.2024.109244},
  journal      = {International Journal of Approximate Reasoning},
  month        = {9},
  pages        = {109244},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Arrow relations in lattices of integer partitions},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aggregation of fuzzy graphs. <em>IJAR</em>, <em>172</em>,
109243. (<a href="https://doi.org/10.1016/j.ijar.2024.109243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our study is centered on the aggregation of fuzzy graphs, looking for conditions under which the aggregation process yields another fuzzy graph. We conduct an in-depth analysis of the preservation of several important properties and structures inherent to fuzzy graphs, like paths, cycles, or bridges. In addition we obtain appropriate criteria for when the aggregation of complete fuzzy graphs is again a complete fuzzy graph.},
  archive      = {J_IJAR},
  author       = {Francisco Javier Talavera and Carlos Bejines and Sergio Ardanza-Trevijano and Jorge Elorza},
  doi          = {10.1016/j.ijar.2024.109243},
  journal      = {International Journal of Approximate Reasoning},
  month        = {9},
  pages        = {109243},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Aggregation of fuzzy graphs},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). General inferential limits under differential and pufferfish
privacy. <em>IJAR</em>, <em>172</em>, 109242. (<a
href="https://doi.org/10.1016/j.ijar.2024.109242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy (DP) is a class of mathematical standards for assessing the privacy provided by a data-release mechanism. This work concerns two important flavors of DP that are related yet conceptually distinct: pure ε -differential privacy ( ε -DP) and Pufferfish privacy. We restate ε -DP and Pufferfish privacy as Lipschitz continuity conditions and provide their formulations in terms of an object from the imprecise probability literature: the interval of measures. We use these formulations to derive limits on key quantities in frequentist hypothesis testing and in Bayesian inference using data that are sanitised according to either of these two privacy standards. Under very mild conditions, the results in this work are valid for arbitrary parameters, priors and data generating models. These bounds are weaker than those attainable when analysing specific data generating models or data-release mechanisms. However, they provide generally applicable limits on the ability to learn from differentially private data – even when the analyst&#39;s knowledge of the model or mechanism is limited. They also shed light on the semantic interpretations of the two DP flavors under examination, a subject of contention in the current literature. 1},
  archive      = {J_IJAR},
  author       = {James Bailie and Ruobin Gong},
  doi          = {10.1016/j.ijar.2024.109242},
  journal      = {International Journal of Approximate Reasoning},
  month        = {9},
  pages        = {109242},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {General inferential limits under differential and pufferfish privacy},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The logic behind desirable sets of things, and its filter
representation. <em>IJAR</em>, <em>172</em>, 109241. (<a
href="https://doi.org/10.1016/j.ijar.2024.109241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We identify the (filter representation of the) logic behind the recent theory of coherent sets of desirable (sets of) things, which generalise coherent sets of desirable (sets of) gambles as well as coherent choice functions, and show that this identification allows us to establish various representation results for such coherent models in terms of simpler ones.},
  archive      = {J_IJAR},
  author       = {Gert de Cooman and Arthur Van Camp and Jasper De Bock},
  doi          = {10.1016/j.ijar.2024.109241},
  journal      = {International Journal of Approximate Reasoning},
  month        = {9},
  pages        = {109241},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {The logic behind desirable sets of things, and its filter representation},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Frequentist belief update under ambiguous evidence in social
networks. <em>IJAR</em>, <em>172</em>, 109240. (<a
href="https://doi.org/10.1016/j.ijar.2024.109240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a frequentist approach to belief updating in the framework of Dempster-Shafer Theory (DST). We propose several mechanisms that allow the gathering of possibly ambiguous pieces of evidence over time to obtain a belief mass assignment. We then use our approach to study the impact of ambiguous evidence on the belief distribution of agents in social networks. We illustrate our approach by taking three representative situations. In the first one, we suppose that there is an unknown state of nature, and agents form belief in the set of possible states. Nature constantly sends a signal which reflects the true state with some probability but which can also be ambiguous. In the second situation, there is no ground truth, and agents are against or in favor of some ethical or societal issues. In the third situation, there is no ground state either, but agents have opinions on left, center, and right political parties. We show that our approach can model various phenomena often observed in social networks, such as polarization or bounded confidence effects.},
  archive      = {J_IJAR},
  author       = {Michel Grabisch and M. Alperen Yasar},
  doi          = {10.1016/j.ijar.2024.109240},
  journal      = {International Journal of Approximate Reasoning},
  month        = {9},
  pages        = {109240},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Frequentist belief update under ambiguous evidence in social networks},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A naïve bayes regularized logistic regression estimator for
low-dimensional classification. <em>IJAR</em>, <em>172</em>, 109239. (<a
href="https://doi.org/10.1016/j.ijar.2024.109239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce the estimator&#39;s variance and prevent overfitting, regularization techniques have attracted great interest from the statistics and machine learning communities. Most existing regularized methods rely on the sparsity assumption that a model with fewer parameters predicts better than one with many parameters. This assumption works particularly well in high-dimensional problems. However, the sparsity assumption may not be necessary when the number of predictors is relatively small compared to the number of training instances. This paper argues that shrinking the coefficients towards a low-variance data-driven estimate could be a better regularization strategy for such situations. For low-dimensional classification problems, we propose a naïve Bayes regularized logistic regression (NBRLR) that shrinks the logistic regression coefficients toward the naïve Bayes estimate to provide a reduction in variance. Our approach is primarily motivated by the fact that naïve Bayes is functionally equivalent to logistic regression if naïve Bayes&#39; conditional independence assumption holds. Under standard conditions, we prove the consistency of the NBRLR estimator. Extensive simulation and empirical experimental results show that NBRLR is a competitive alternative to various state-of-the-art classifiers, especially on low-dimensional datasets.},
  archive      = {J_IJAR},
  author       = {Yi Tan and Ben Sherwood and Prakash P. Shenoy},
  doi          = {10.1016/j.ijar.2024.109239},
  journal      = {International Journal of Approximate Reasoning},
  month        = {9},
  pages        = {109239},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A naïve bayes regularized logistic regression estimator for low-dimensional classification},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time series clustering and classification. <em>IJAR</em>,
<em>172</em>, 109238. (<a
href="https://doi.org/10.1016/j.ijar.2024.109238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJAR},
  author       = {Pierpaolo D&#39;Urso and Livia De Giovanni and Elizabeth Ann Maharaj},
  doi          = {10.1016/j.ijar.2024.109238},
  journal      = {International Journal of Approximate Reasoning},
  month        = {9},
  pages        = {109238},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Time series clustering and classification},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Markov conditions and factorization in logical credal
networks. <em>IJAR</em>, <em>172</em>, 109237. (<a
href="https://doi.org/10.1016/j.ijar.2024.109237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine the recently proposed language of Logical Credal Networks , a powerful representation formalism that combines probabilities and logic. In particular we investigate the consequences of distinct Markov conditions upon their underlying semantics. We introduce the notion of structure for a Logical Credal Network and show that a structure without directed cycles leads to a well-known factorization result. For networks with directed cycles, we discuss the differences between Markov conditions, factorization results, and specification requirements. We consider several scenarios in causal reasoning that can be tackled by the formalism, in particular looking at partial identifiability and cycles.},
  archive      = {J_IJAR},
  author       = {Fabio G. Cozman and Radu Marinescu and Junkyu Lee and Alexander Gray and Ryan Riegel and Debarun Bhattacharjya},
  doi          = {10.1016/j.ijar.2024.109237},
  journal      = {International Journal of Approximate Reasoning},
  month        = {9},
  pages        = {109237},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Markov conditions and factorization in logical credal networks},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic collective argumentation: Constructing the revision
and contraction operators. <em>IJAR</em>, <em>172</em>, 109234. (<a
href="https://doi.org/10.1016/j.ijar.2024.109234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collective argumentation has always focused on obtaining rational collective argumentative decisions. One approach that has been extensively studied in the literature is the aggregation of individual extensions of an argumentation framework. However, previous studies have only examined aggregation processes in static terms, focusing on preserving semantic properties at a given time. In contrast, this paper investigates whether decisions remain rational when the preservation process is dynamic, meaning that it can incorporate new information. To address the dynamic nature of collective argumentation, we introduce the revision and contraction operators. These operators reflect the idea that when an individual or a group learns something new by accepting or rejecting an argument, they have to update their collective decision accordingly. Our study examines whether the order of revising individual opinions and aggregating them affects the final outcome, i.e., whether aggregation and revision commute.},
  archive      = {J_IJAR},
  author       = {Weiwei Chen and Shier Ju},
  doi          = {10.1016/j.ijar.2024.109234},
  journal      = {International Journal of Approximate Reasoning},
  month        = {9},
  pages        = {109234},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Dynamic collective argumentation: Constructing the revision and contraction operators},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incremental reduction of imbalanced distributed mixed data
based on k-nearest neighbor rough set. <em>IJAR</em>, <em>172</em>,
109218. (<a href="https://doi.org/10.1016/j.ijar.2024.109218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incremental feature selection methods have garnered significant research attention in improving the efficiency of feature selection for dynamic datasets. However, there is currently a dearth of research on incremental feature selection methods specifically targeted for unbalanced mixed-type data. Furthermore, the widely used neighborhood rough set algorithm exhibits low classification efficiency for imbalanced data distribution and performs poorly in classifying mixed samples. Motivated by these two challenges, we investigate the use of an incremental feature reduction algorithm based on k- nearest neighbors and mutual information in this study. Firstly, we enhance the capabilities of the neighborhood rough set model by incorporating the concept of k- nearest neighbors, thereby improving its ability to handle samples with varying densities. Subsequently, we apply information entropy theory and combine neighborhood mutual information with the maximum relevance minimum redundancy criterion to construct a novel feature importance evaluation function. This function is utilized as the evaluation metric for feature selection. Finally, an incremental feature selection algorithm is designed based on the above static algorithm. Experiments were conducted on twelve public datasets to evaluate the robustness of the proposed feature metrics and the performance of the incremental feature selection algorithm. The experimental results validated the robustness of the proposed metrics and demonstrated that our incremental algorithm is effective and efficient in feature reduction for updating unbalanced mixed data.},
  archive      = {J_IJAR},
  author       = {Weihua Xu and Changchun Liu},
  doi          = {10.1016/j.ijar.2024.109218},
  journal      = {International Journal of Approximate Reasoning},
  month        = {9},
  pages        = {109218},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Incremental reduction of imbalanced distributed mixed data based on k-nearest neighbor rough set},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Kernel multi-granularity double-quantitative rough set based
on ensemble empirical mode decomposition: Application to stock price
trends prediction. <em>IJAR</em>, <em>172</em>, 109217. (<a
href="https://doi.org/10.1016/j.ijar.2024.109217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As financial markets grow increasingly complex and dynamic, accurately predicting stock price trends becomes crucial for investors and financial analysts. Effectively identifying and selecting the most predictive attributes has become a challenge in stock trends prediction. To address this problem, this study proposes a new attribute reduction model. A rough set theory model is built by simplifying the prediction process and combining it with the long short-term memory network (LSTM) to enhance the accuracy of stock trends prediction. Firstly, the Ensemble Empirical Mode Decomposition (EEMD) is utilized to decompose the stock price data into a multi-granularity information system. Secondly, due to the numerical characteristics of stock data, a kernel function is applied to construct binary relationships. Thirdly, recognizing the noise inherent in stock data, the double-quantitative rough set theory is utilized to improve fault tolerance during the construction of decision attributes&#39; lower and upper approximations. Moreover, calculate the correlation between conditional and decision attributes, and retain highly correlated conditional attributes for prediction. The kernel multi-granularity double-quantitative rough set based on the EEMD (EEMD-KMGDQRS) model proposed identifies the key factors behind stock data. Finally, the efficacy of the proposed model is validated by selecting 356 stocks from diverse industries in the Shanghai and Shenzhen stock markets as experimental samples. The results show that the proposed model improves the generalization of attribute reduction results through a fault tolerance mechanism by combining kernel function with multi-granularity double-quantitative rough set, thereby enhancing the accuracy of stock trends prediction in subsequent LSTM prediction processes.},
  archive      = {J_IJAR},
  author       = {Lin Zhang and Juncheng Bai and Bingzhen Sun and Yuqi Guo and Xiangtang Chen},
  doi          = {10.1016/j.ijar.2024.109217},
  journal      = {International Journal of Approximate Reasoning},
  month        = {9},
  pages        = {109217},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Kernel multi-granularity double-quantitative rough set based on ensemble empirical mode decomposition: Application to stock price trends prediction},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ClusterLP: A novel cluster-aware link prediction model in
undirected and directed graphs. <em>IJAR</em>, <em>172</em>, 109216. (<a
href="https://doi.org/10.1016/j.ijar.2024.109216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction models endeavor to understand the distribution of links within graphs and forecast the presence of potential links. With the advancements in deep learning, prevailing methods typically strive to acquire low-dimensional representations of nodes in networks, aiming to capture and retain the structure and inherent characteristics of networks. However, the majority of these methods primarily focus on preserving the microscopic structure, such as the first- and second-order proximities of nodes, while largely disregarding the mesoscopic cluster structure, which stands out as one of the network&#39;s most prominent features. Following the homophily principle, nodes within the same cluster exhibit greater similarity to each other compared to those from different clusters, suggesting that they should possess analogous vertex representations and higher probabilities of linkage. In this study, we develop a straightforward yet efficient Cluster -aware L ink P rediction framework ( ClusterLP ), with the objective of directly leveraging cluster structures to predict links among nodes with maximum accuracy in both undirected and directed graphs. Specifically, we posit that establishing links between nodes with similar representation vectors and cluster tendencies is more feasible in undirected graphs, whereas nodes in directed graphs are inclined to point towards nodes with akin representation vectors and greater influence. We tailor the implementation of ClusterLP for undirected and directed graphs, respectively, and experimental findings using multiple real-world networks demonstrate the high competitiveness of our models in the realm of link prediction tasks. The code utilized in our implementation is accessible at https://github.com/ZINUX1998/ClusterLP .},
  archive      = {J_IJAR},
  author       = {Shanfan Zhang and Wenjiao Zhang and Zhan Bu and Xia Zhang},
  doi          = {10.1016/j.ijar.2024.109216},
  journal      = {International Journal of Approximate Reasoning},
  month        = {9},
  pages        = {109216},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {ClusterLP: A novel cluster-aware link prediction model in undirected and directed graphs},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A possible worlds semantics for trustworthy
non-deterministic computations. <em>IJAR</em>, <em>172</em>, 109212. (<a
href="https://doi.org/10.1016/j.ijar.2024.109212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of trustworthiness, central to many fields of human inquiry, has recently attracted the attention of various researchers in logic, computer science, and artificial intelligence (AI). Both conceptual and formal approaches for modeling trustworthiness as a (desirable) property of AI systems are emerging in the literature. To develop logics fit for this aim means to analyze both the non-deterministic aspect of AI systems and to offer a formalization of the intended meaning of their trustworthiness. In this work we take a semantic perspective on representing such processes, and provide a measure on possible worlds for evaluating them as trustworthy. In particular, we intend trustworthiness as the correspondence within acceptable limits between a model in which the theoretical probability of a process to produce a given output is expressed and a model in which the frequency of showing such output as established during a relevant number of tests is measured. From a technical perspective, we show that our semantics characterizes the probabilistic typed natural deduction calculus introduced in D&#39;Asaro and Primiero (2021) [12] and further extended in D&#39;Asaro et al. (2023) [13] . This contribution connects those results on trustworthy probabilistic processes with the mainstream method in modal logic, thereby facilitating the understanding of this field of research for a larger audience of logicians, as well as setting the stage for an epistemic logic appropriate to the task.},
  archive      = {J_IJAR},
  author       = {Ekaterina Kubyshkina and Giuseppe Primiero},
  doi          = {10.1016/j.ijar.2024.109212},
  journal      = {International Journal of Approximate Reasoning},
  month        = {9},
  pages        = {109212},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A possible worlds semantics for trustworthy non-deterministic computations},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial of the special issue “synergies between machine
learning and reasoning.” <em>IJAR</em>, <em>171</em>, 109207. (<a
href="https://doi.org/10.1016/j.ijar.2024.109207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJAR},
  author       = {Sébastien Destercke and Jérôme Mengin and Henri Prade},
  doi          = {10.1016/j.ijar.2024.109207},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109207},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Editorial of the special issue “Synergies between machine learning and reasoning”},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synergies between machine learning and reasoning - an
introduction by the kay r. Amel group. <em>IJAR</em>, <em>171</em>,
109206. (<a href="https://doi.org/10.1016/j.ijar.2024.109206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a tentative and original survey of meeting points between Knowledge Representation and Reasoning (KRR) and Machine Learning (ML), two areas which have been developed quite separately in the last four decades. First, some common concerns are identified and discussed such as the types of representation used, the roles of knowledge and data, the lack or the excess of information, or the need for explanations and causal understanding. Then, the survey is organised in seven sections covering most of the territory where KRR and ML meet. We start with a section dealing with prototypical approaches from the literature on learning and reasoning: Inductive Logic Programming, Statistical Relational Learning, and Neurosymbolic AI, where ideas from rule-based reasoning are combined with ML. Then we focus on the use of various forms of background knowledge in learning, ranging from additional regularisation terms in loss functions, to the problem of aligning symbolic and vector space representations, or the use of knowledge graphs for learning. Then, the next section describes how KRR notions may benefit to learning tasks. For instance, constraints can be used as in declarative data mining for influencing the learned patterns; or semantic features are exploited in low-shot learning to compensate for the lack of data; or yet we can take advantage of analogies for learning purposes. Conversely, another section investigates how ML methods may serve KRR goals. For instance, one may learn special kinds of rules such as default rules, fuzzy rules or threshold rules, or special types of information such as constraints, or preferences. The section also covers formal concept analysis and rough sets-based methods. Yet another section reviews various interactions between Automated Reasoning and ML, such as the use of ML methods in SAT solving to make reasoning faster. Then a section deals with works related to model accountability, including explainability and interpretability, fairness and robustness. Finally, a section covers works on handling imperfect or incomplete data, including the problem of learning from uncertain or coarse data, the use of belief functions for regression, a revision-based view of the EM algorithm, the use of possibility theory in statistics, or the learning of imprecise models. This paper thus aims at a better mutual understanding of research in KRR and ML, and how they can cooperate. The paper is completed by an abundant bibliography.},
  archive      = {J_IJAR},
  author       = {Ismaïl Baaj and Zied Bouraoui and Antoine Cornuéjols and Thierry Denœux and Sébastien Destercke and Didier Dubois and Marie-Jeanne Lesot and João Marques-Silva and Jérôme Mengin and Henri Prade and Steven Schockaert and Mathieu Serrurier and Olivier Strauss and Christel Vrain},
  doi          = {10.1016/j.ijar.2024.109206},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109206},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Synergies between machine learning and reasoning - An introduction by the kay r. amel group},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revisiting analogical proportions and analogical inference.
<em>IJAR</em>, <em>171</em>, 109202. (<a
href="https://doi.org/10.1016/j.ijar.2024.109202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider analogical proportions which are statements of the form “ a → a→ is to b → b→ as c → c→ is to d → d→ ”, understood as a comparative formulation between vectors of items described on the same set of attributes. Analogical proportions and analogical inference have been extensively studied in the last decade, in particular by the authors of this paper. Some important remarks have been made regarding these proportions on i) the role of ordered pairs in them; ii) the large number of them associated with taxonomic trees; and more recently iii) their close relationship with multi-valued dependencies. We offer a renewed presentation of these facts together with some new insights on analogical proportions, emphasizing the role of equivalence classes of ordered pairs. Moreover, not all consequences had been drawn for a better understanding of analogical inference. This is the main purpose of this paper. In particular, it is advocated that analogical proportions whose four members are equal on some attributes are better predictors in general for classification purposes than analogical proportions for which there does not exist such attribute. This is confirmed by experimental results also reported in the paper. Thus this paper can be read both as an introductory survey on recent advances on analogical proportions and as a study on the impact of particular patterns on analogical inference, a topic never considered before.},
  archive      = {J_IJAR},
  author       = {Myriam Bounhas and Henri Prade},
  doi          = {10.1016/j.ijar.2024.109202},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109202},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Revisiting analogical proportions and analogical inference},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning decision catalogues for situated decision making:
The case of scoring systems. <em>IJAR</em>, <em>171</em>, 109190. (<a
href="https://doi.org/10.1016/j.ijar.2024.109190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we formalize the problem of learning coherent collections of decision models, which we call decision catalogues, and illustrate it for the case where models are scoring systems. This problem is motivated by the recent rise of algorithmic decision-making and the idea to improve human decision-making through machine learning, in conjunction with the observation that decision models should be situated in terms of their complexity and resource requirements: Instead of constructing a single decision model and using this model in all cases, different models might be appropriate depending on the decision context. Decision catalogues are supposed to support a seamless transition from very simple, resource-efficient to more sophisticated but also more demanding models. We present a general algorithmic framework for inducing such catalogues from training data, which tackles the learning task as a problem of searching the space of candidate catalogues systematically and, to this end, makes use of heuristic search methods. We also present a concrete instantiation of this framework as well as empirical studies for performance evaluation, which, in a nutshell, show that greedy search is an efficient and hard-to-beat strategy for the construction of catalogues of scoring systems.},
  archive      = {J_IJAR},
  author       = {Stefan Heid and Jonas Hanselle and Johannes Fürnkranz and Eyke Hüllermeier},
  doi          = {10.1016/j.ijar.2024.109190},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109190},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Learning decision catalogues for situated decision making: The case of scoring systems},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards an effective practice of learning from data and
knowledge. <em>IJAR</em>, <em>171</em>, 109188. (<a
href="https://doi.org/10.1016/j.ijar.2024.109188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss some recent advances on combining data and knowledge in the context of supervised learning using Bayesian networks. A first set of advances concern the computational efficiency of learning and inference, and they include a software-level boost based on compiling Bayesian network structures into tractable circuits in the form of tensor graphs , and algorithmic improvements based on exploiting a type of knowledge called unknown functional dependencies. The used tensor graphs capitalize on a highly optimized tensor operation (matrix multiplication) which brings orders of magnitude speedups in circuit training and evaluation. The exploitation of unknown functional dependencies yields exponential reductions in the size of tractable circuits and gives rise to the notion of causal treewidth for offering a corresponding complexity bound. Beyond computational efficiency, we discuss empirical evidence showing the promise of learning from a combination of data and knowledge, in terms of data hungriness and robustness against noise perturbations. Sometimes, however, an accurate Bayesian network structure may not be available due to the incompleteness of human knowledge, leading to modeling errors in the form of missing dependencies or missing variable values. On this front, we discuss another set of advances for recovering from certain types of modeling errors. This is achieved using Testing Bayesian networks which dynamically select parameters based on the input evidence, and come with theoretical guarantees on full recovery under certain conditions.},
  archive      = {J_IJAR},
  author       = {Yizuo Chen and Haiying Huang and Adnan Darwiche},
  doi          = {10.1016/j.ijar.2024.109188},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109188},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Towards an effective practice of learning from data and knowledge},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A statistical approach to learning constraints.
<em>IJAR</em>, <em>171</em>, 109184. (<a
href="https://doi.org/10.1016/j.ijar.2024.109184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A constraint-based model represents knowledge about a domain by a set of constraints, which must be satisfied by solutions in that domain. These models may be used for reasoning, decision making and optimisation. Unfortunately, modelling itself is a hard and error-prone task that requires expertise. The automation of this process is often referred to as constraint acquisition and has been pursued for over 20 years. Methods typically learn constraints by testing candidates against a dataset of solutions and non-solutions, and often use some form of machine learning to decide which should be learned. However, few methods are robust under errors in the data, some cannot handle large sets of candidates, and most are computationally expensive even for small problems. We describe a statistical approach based on sequential analysis that is robust, fast and scalable to large biases. Its correctness depends on an assumption that does not always hold but which is, we show using Bayesian analysis, reasonable in practice.},
  archive      = {J_IJAR},
  author       = {Steven Prestwich and Nic Wilson},
  doi          = {10.1016/j.ijar.2024.109184},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109184},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A statistical approach to learning constraints},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explaining answers generated by knowledge graph embeddings.
<em>IJAR</em>, <em>171</em>, 109183. (<a
href="https://doi.org/10.1016/j.ijar.2024.109183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Completion of large-scale knowledge bases, such as DBPedia or Freebase, often relies on embedding models that turn symbolic relations into vector-based representations. Such embedding models are rather opaque to the human user. Research in interpretability has emphasized non-relational classifiers, such as deep neural networks, and has devoted less effort to opaque models extracted from relational structures, such as knowledge graph embeddings. We introduce techniques that produce explanations, expressed as logical rules, for predictions based on the embeddings of knowledge graphs. Algorithms build explanations out of paths in an input knowledge graph, searched through contextual and heuristic cues.},
  archive      = {J_IJAR},
  author       = {Andrey Ruschel and Arthur Colombini Gusmão and Fabio Gagliardi Cozman},
  doi          = {10.1016/j.ijar.2024.109183},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109183},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Explaining answers generated by knowledge graph embeddings},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantified neural markov logic networks. <em>IJAR</em>,
<em>171</em>, 109172. (<a
href="https://doi.org/10.1016/j.ijar.2024.109172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Markov Logic Networks (MLNs) are discrete generative models in the exponential family. However, specifying these rules requires considerable expertise and can pose a significant challenge. To overcome this limitation, Neural MLNs (NMLNs) have been introduced, enabling the specification of potential functions as neural networks. Thanks to the compact representation of their neural potential functions, NMLNs have shown impressive performance in modeling complex domains like molecular data. Despite the superior performance of NMLNs, their theoretical expressiveness is still equivalent to that of MLNs without quantifiers. In this paper, we propose a new class of NMLN, called Quantified NMLN, that extends the expressivity of NMLNs to the quantified setting. Furthermore, we demonstrate how to leverage the neural nature of NMLNs to employ learnable aggregation functions as quantifiers, increasing expressivity even further. We demonstrate the competitiveness of Quantified NMLNs over original NMLNs and state-of-the-art diffusion models in molecule generation experiments.},
  archive      = {J_IJAR},
  author       = {Peter Jung and Giuseppe Marra and Ondřej Kuželka},
  doi          = {10.1016/j.ijar.2024.109172},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109172},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Quantified neural markov logic networks},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Reprint of: Some thoughts about transfer learning. What
role for the source domain? <em>IJAR</em>, <em>171</em>, 109146. (<a
href="https://doi.org/10.1016/j.ijar.2024.109146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning is called for when the training and test data do not share the same input distributions ( P X S ≠ P X T PXS≠PXT ) or/and not the same conditional ones ( P Y | X S ≠ P Y | X T PY|XS≠PY|XT ). In the most general case, the input spaces and/or output spaces can be different: X S ≠ X T XS≠XT and/or Y S ≠ Y T YS≠YT . However, most work assume that X S = X T XS=XT . Furthermore, a common held assumption is that it is necessary that the source hypothesis be good on the source training data and that the “distance” between the source and the target domains be as small as possible in order to get a good (transferred) target hypothesis. This paper revisits the reasons for these beliefs and discusses the relevance of these conditions. An algorithm is presented which can deal with transfer learning problems where X S ≠ X T XS≠XT , and that furthermore brings a fresh perspective on the role of the source hypothesis (it does not have to be good) and on what is important in the distance between the source and the target domains (translations between them should belong to a limited set). Experiments illustrate the properties of the method and confirm the theoretical analysis. Determining beforehand a relevant source hypothesis remains an open problem, but the vista provided here helps understanding its role.},
  archive      = {J_IJAR},
  author       = {A. Cornuéjols},
  doi          = {10.1016/j.ijar.2024.109146},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109146},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Reprint of: Some thoughts about transfer learning. what role for the source domain?},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review on declarative approaches for constrained
clustering. <em>IJAR</em>, <em>171</em>, 109135. (<a
href="https://doi.org/10.1016/j.ijar.2024.109135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is an important Machine Learning task, which aims at discovering the implicit structure of data. Applying a clustering algorithm is easy but since clustering is an unsupervised task, tuning it so that the results is appropriate to the expert expectations is much less obvious. To overcome this, expert knowledge can be integrated into a clustering process; this is generally formalized as constraints on the desired output, thus leading to constrained clustering. There are two lines of research for clustering: distance based clustering, where data are grouped into clusters according to their dissimilarity and conceptual clustering, where a cluster must be a concept that is a set of objects and a set of properties that describe them. This second approach relies on Formal Concept Analysis and benefits from advances in Pattern Mining. [66] has shown the interest of declarative approaches for pattern mining and has led to a new research direction for clustering that is interested in the use of declarative frameworks, such as Integer Linear Programming, Constraint Programming or SAT. This has several advantages: finding a global optimum, integrating different kinds of constraints, even complex ones in a clustering process and even combining conceptual and distance-based clustering. In this paper we present an inventory of constraints and a survey of declarative methods for constrained clustering.},
  archive      = {J_IJAR},
  author       = {Thi-Bich-Hanh Dao and Christel Vrain},
  doi          = {10.1016/j.ijar.2024.109135},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109135},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A review on declarative approaches for constrained clustering},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semirings for probabilistic and neuro-symbolic logic
programming. <em>IJAR</em>, <em>171</em>, 109130. (<a
href="https://doi.org/10.1016/j.ijar.2024.109130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of probabilistic logic programming (PLP) focuses on integrating probabilistic models into programming languages based on logic. Over the past 30 years, numerous languages and frameworks have been developed for modeling, inference and learning in probabilistic logic programs. While originally PLP focused on discrete probability, more recent approaches have incorporated continuous distributions as well as neural networks, effectively yielding neuro-symbolic methods. We provide an overview and synthesis of this domain, thereby contributing a unified algebraic perspective on the different flavors of PLP, showing that many if not most of the extensions of PLP can be cast within a common algebraic logic programming framework, in which facts are labeled with elements of a semiring and disjunction and conjunction are replaced by addition and multiplication. This does not only hold for the PLP variations itself but also for the underlying execution mechanism that is based on (algebraic) model counting. In order to showcase and explain this unified perspective, we focus on the ProbLog language and its extensions.},
  archive      = {J_IJAR},
  author       = {Vincent Derkinderen and Robin Manhaeve and Pedro Zuidberg Dos Martires and Luc De Raedt},
  doi          = {10.1016/j.ijar.2024.109130},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109130},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Semirings for probabilistic and neuro-symbolic logic programming},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enriching interactive explanations with fuzzy temporal
constraint networks. <em>IJAR</em>, <em>171</em>, 109128. (<a
href="https://doi.org/10.1016/j.ijar.2024.109128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans often use expressions with vague terms which play a fundamental role for effective communication. These expressions are successfully modeled with fuzzy technology, but they are not usually integrated yet with Natural Language Processing models and techniques. Large-scale pre-trained language models yield excellent results in many language tasks, but they have some drawbacks such as their lack of transparency and thorough temporal reasoning capabilities. Therefore, the use of such models may provoke inconsistent or incorrect dialogues in the context of conversational agents which were aimed at providing users of intelligent systems with interactive explanations. In this paper, we propose a model for fuzzy temporal reasoning to overcome some inconsistencies detected in pre-trained language models in a specific application domain of a conversational agent carefully designed for providing users with explanations which are endowed with a good balance between naturalness and fidelity. More precisely, starting from a knowledge graph that provides an intuitive representation of the entities and relations in the application domain, we describe how to map the temporal information onto a fuzzy temporal constraint network. This formalism allows to represent imprecise temporal information and provides mechanisms for checking consistency in conversations. In addition, as a proof of concept, we have developed TimeVersa, a conversational agent which integrates the proposed model into an application domain (i.e., a virtual assistant for tourists) that requires handling imprecise temporal constraints. We illustrate in a use case how the agent can identify temporal inconsistencies and answer queries related to temporal information properly. Results after a user study report that users&#39; perception of consistency is significantly higher in a conversation with TimeVersa than in a similar conversation using the well-known GPT-3 Large Language Model, when vague temporal information is involved. The proposed approach is a step forward for developing conversational agents operating in application domains that require temporal reasoning under uncertainty.},
  archive      = {J_IJAR},
  author       = {Mariña Canabal-Juanatey and Jose M. Alonso-Moral and Alejandro Catala and Alberto Bugarín-Diz},
  doi          = {10.1016/j.ijar.2024.109128},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109128},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Enriching interactive explanations with fuzzy temporal constraint networks},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CCN+: A neuro-symbolic framework for deep learning with
requirements. <em>IJAR</em>, <em>171</em>, 109124. (<a
href="https://doi.org/10.1016/j.ijar.2024.109124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For their outstanding ability of finding hidden patterns in data, deep learning models have been extensively applied in many different domains. However, recent works have shown that, if a set of requirements expressing inherent knowledge about the problem at hand is given, then neural networks often fail to comply with them. This represents a major drawback for deep learning models, as requirements compliance is normally considered a necessary condition for standard software deployment. In this paper, we propose a novel neuro-symbolic framework able to make any neural network compliant by design to a given set of requirements over the output space expressed in full propositional logic. This framework, called CCN + , integrates the requirements into the output layer of the neural network by applying multiple inference rules that ensure compliance with the requirements and adapts the standard binary cross-entropy loss function to the requirement output layer. As a result, not only the outputted predictions are guaranteed to be compliant with the requirements, but the neural network itself learns how to exploit the domain knowledge expressed by the requirements to get better performance. We conduct an extensive experimental evaluation of CCN + on 19 real-world multi-label classification datasets with propositional logic requirements, including a challenging dataset for autonomous driving. Our experimental analysis confirms that CCN + is able to outperform both its neural counterparts and the state-of-the-art models.},
  archive      = {J_IJAR},
  author       = {Eleonora Giunchiglia and Alex Tatomir and Mihaela Cătălina Stoian and Thomas Lukasiewicz},
  doi          = {10.1016/j.ijar.2024.109124},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109124},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {CCN+: A neuro-symbolic framework for deep learning with requirements},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the failings of shapley values for explainability.
<em>IJAR</em>, <em>171</em>, 109112. (<a
href="https://doi.org/10.1016/j.ijar.2023.109112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable Artificial Intelligence (XAI) is widely considered to be critical for building trust into the deployment of systems that integrate the use of machine learning (ML) models. For more than two decades Shapley values have been used as the theoretical underpinning for some methods of XAI, being commonly referred to as SHAP scores. Some of these methods of XAI now rank among the most widely used, including in high-risk domains. This paper proves that the existing definitions of SHAP scores will necessarily yield misleading information about the relative importance of features for predictions. The paper identifies a number of ways in which misleading information can be conveyed to human decision makers, and proves that there exist classifiers which will yield such misleading information. Furthermore, the paper offers empirical evidence that such theoretical limitations of SHAP scores are routinely observed in ML classifiers.},
  archive      = {J_IJAR},
  author       = {Xuanxiang Huang and Joao Marques-Silva},
  doi          = {10.1016/j.ijar.2023.109112},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109112},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {On the failings of shapley values for explainability},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient computation of counterfactual bounds.
<em>IJAR</em>, <em>171</em>, 109111. (<a
href="https://doi.org/10.1016/j.ijar.2023.109111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We assume to be given structural equations over discrete variables inducing a directed acyclic graph, namely, a structural causal model , together with data about its internal nodes . The question we want to answer is how can we compute bounds for partially identifiable counterfactual queries from such an input. We start by giving a map from structural casual models to credal networks . This allows us to compute exact counterfactual bounds via algorithms for credal nets on a subclass of structural causal models. Exact computation is going to be inefficient in general given that, as we show, causal inference is NP-hard even on polytrees. We target then approximate bounds via a causal EM scheme. We evaluate their accuracy by providing credible intervals on the quality of the approximation ; we show through a synthetic benchmark that the EM scheme delivers accurate results in a fair number of runs. In the course of the discussion, we also point out what seems to be a neglected limitation to the trending idea that counterfactual bounds can be computed without knowledge of the structural equations. We also present a real case study on palliative care to show how our algorithms can readily be used for practical purposes .},
  archive      = {J_IJAR},
  author       = {Marco Zaffalon and Alessandro Antonucci and Rafael Cabañas and David Huber and Dario Azzimonti},
  doi          = {10.1016/j.ijar.2023.109111},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109111},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Efficient computation of counterfactual bounds},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Beyond tree-shaped credal probabilistic circuits.
<em>IJAR</em>, <em>171</em>, 109047. (<a
href="https://doi.org/10.1016/j.ijar.2023.109047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic circuits are a class of probabilistic generative models that allow us to compute different types of probabilistic queries in polynomial time . Unlike many of the mainstream approaches for generative modeling, they can compute exact likelihoods, marginals, and expectations. Yet, assessing the reliability of their inferences is not straightforward. Credal probabilistic circuits are the imprecise counterpart of probabilistic circuits allowing, among other queries, computations of cautious inferences and sensitivity analyses. In this work, we propose an efficient algorithm to compute the lower and upper expectations for factorizing functions using a credal probabilistic circuit. We discuss under what structural assumptions and types of factorizing functions the algorithm works. We prove that such algorithm has polynomial time complexity in the input size. In the general case, we prove that computing cautious inferences using credal probabilistic circuits is an NP-hard problem, yet the proposed algorithm can be used as an approximation . Some experiments show how the approximation degrades with the complexity of the model structure.},
  archive      = {J_IJAR},
  author       = {David R. Montalván Hernández and Tijn Centen and Thomas Krak and Erik Quaeghebeur and Cassio de Campos},
  doi          = {10.1016/j.ijar.2023.109047},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109047},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Beyond tree-shaped credal probabilistic circuits},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reasoning and learning in the setting of possibility theory
- overview and perspectives. <em>IJAR</em>, <em>171</em>, 109028. (<a
href="https://doi.org/10.1016/j.ijar.2023.109028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Possibility theory stands halfway between logical and probabilistic representation frameworks. Possibility theory, as a setting for handling epistemic uncertainty, may have a qualitative or a quantitative flavor depending on the way conditioning is defined. In particular, qualitative possibility theory is totally compatible with classical logic, while quantitative possibility theory is related to statistics. This feature suggests the possibility theory setting as an interesting candidate for interfacing reasoning and learning. The potential of the possibilistic representation framework for reasoning, explanation and learning tasks is particularly highlighted.},
  archive      = {J_IJAR},
  author       = {Didier Dubois and Henri Prade},
  doi          = {10.1016/j.ijar.2023.109028},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109028},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Reasoning and learning in the setting of possibility theory - Overview and perspectives},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning horn envelopes via queries from language models.
<em>IJAR</em>, <em>171</em>, 109026. (<a
href="https://doi.org/10.1016/j.ijar.2023.109026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an approach for systematically probing a trained neural network to extract a symbolic abstraction of it, represented as a Boolean formula. We formulate this task within Angluin&#39;s exact learning framework, where a learner attempts to extract information from an oracle (in our work, the neural network) by posing membership and equivalence queries. We adapt Angluin&#39;s algorithm for Horn formula to the case where the examples are labelled w.r.t. an arbitrary Boolean formula in CNF (rather than a Horn formula). In this setting, the goal is to learn the smallest representation of all the Horn clauses implied by a Boolean formula—called its Horn envelope—which in our case correspond to the rules obeyed by the network. Our algorithm terminates in exponential time in the worst case and in polynomial time if the target Boolean formula can be closely approximated by its envelope. We also show that extracting Horn envelopes in polynomial time is as hard as learning CNFs in polynomial time. To showcase the applicability of the approach, we perform experiments on BERT based language models and extract Horn envelopes that expose occupation-based gender biases.},
  archive      = {J_IJAR},
  author       = {Sophie Blum and Raoul Koudijs and Ana Ozaki and Samia Touileb},
  doi          = {10.1016/j.ijar.2023.109026},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {109026},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Learning horn envelopes via queries from language models},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Questionable stepwise explanations for a robust additive
preference model. <em>IJAR</em>, <em>171</em>, 108982. (<a
href="https://doi.org/10.1016/j.ijar.2023.108982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study Multiple Criteria Decision Aiding (MCDA) problems modeled using an additive value function. We consider an epistemic framework in which the preferences of the decision-maker are imprecisely specified, yielding a robust additive preference model. In this context, we are interested in explaining recommendations derived from such robust model using a transitive sequence of preference swaps. Previous work laid the foundations for explaining the necessary preference relation through a sequence of necessary preference swaps. We extend this to take into account non-necessary preference, yielding to so-called “questionable explanations”: a chain of alternatives which is non-increasing w.r.t. preference of the decision-maker. This approach provides additional descriptive power for explaining robust recommendations. We propose an efficient resolution engine based on Mixed-Integer Linear Programs, and we conduct numerical experiments to assess the benefit of our explanation strategy.},
  archive      = {J_IJAR},
  author       = {Manuel Amoussou and Khaled Belahcène and Christophe Labreuche and Nicolas Maudet and Vincent Mousseau and Wassila Ouerdane},
  doi          = {10.1016/j.ijar.2023.108982},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {108982},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Questionable stepwise explanations for a robust additive preference model},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Embeddings as epistemic states: Limitations on the use of
pooling operators for accumulating knowledge. <em>IJAR</em>,
<em>171</em>, 108981. (<a
href="https://doi.org/10.1016/j.ijar.2023.108981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various neural network architectures rely on pooling operators to aggregate information coming from different sources. It is often implicitly assumed in such contexts that vectors encode epistemic states, i.e. that vectors capture the evidence that has been obtained about some properties of interest, and that pooling these vectors yields a vector that combines this evidence. We study, for a number of standard pooling operators, under what conditions they are compatible with this idea, which we call the epistemic pooling principle. While we find that all the considered pooling operators can satisfy the epistemic pooling principle, this only holds when embeddings are sufficiently high-dimensional and, for most pooling operators, when the embeddings satisfy particular constraints (e.g. having non-negative coordinates). We furthermore show that these constraints have important implications on how the embeddings can be used in practice. In particular, we find that when the epistemic pooling principle is satisfied, in most cases it is impossible to verify the satisfaction of propositional formulas using linear scoring functions, with two exceptions: (i) max-pooling with embeddings that are upper-bounded and (ii) Hadamard pooling with non-negative embeddings. This finding helps to clarify, among others, why Graph Neural Networks sometimes under-perform in reasoning tasks. Finally, we also study an extension of the epistemic pooling principle to weighted epistemic states, which are important in the context of non-monotonic reasoning, where max-pooling emerges as the most suitable operator.},
  archive      = {J_IJAR},
  author       = {Steven Schockaert},
  doi          = {10.1016/j.ijar.2023.108981},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {108981},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Embeddings as epistemic states: Limitations on the use of pooling operators for accumulating knowledge},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning from fuzzy labels: Theoretical issues and
algorithmic solutions. <em>IJAR</em>, <em>171</em>, 108969. (<a
href="https://doi.org/10.1016/j.ijar.2023.108969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we study the problem of learning from fuzzy labels (LFL), a form of weakly supervised learning in which the supervision target is not precisely specified but is instead given in the form of possibility distributions, that express the imprecise knowledge of the annotating agent. While several approaches for LFL have been proposed in the literature, including generalized risk minimization (GRM), instance-based methods and pseudo label-based learning, both their theoretical properties and their empirical performance have scarcely been studied. We address this gap by: first, presenting a review of the previous results relative to the sample complexity and generalization bounds for GRM and instance-based methods; second, studying both their computational complexity, by proving in particular the impossibility of efficiently solving LFL using GRM, as well as impossibility theorems. We then propose a novel pseudo label-based learning method, called Random Resampling-based Learning (RRL), which directly draws from ensemble learning and possibility theory and study its learning- and complexity-theoretic properties, showing that it achieves guarantees similar to those for GRM while being computationally efficient. Finally, we study the empirical performance of several state-of-the-art LFL algorithms on wide set of synthetic and real-world benchmark datasets, by which we confirm the effectiveness of the proposed RRL method. Additionally, we describe directions for future research, and highlight opportunities for further interaction between machine learning and uncertainty representation theories.},
  archive      = {J_IJAR},
  author       = {Andrea Campagner},
  doi          = {10.1016/j.ijar.2023.108969},
  journal      = {International Journal of Approximate Reasoning},
  month        = {8},
  pages        = {108969},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Learning from fuzzy labels: Theoretical issues and algorithmic solutions},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An attribute ranking method based on rough sets and
interval-valued fuzzy sets. <em>IJAR</em>, <em>170</em>, 109215. (<a
href="https://doi.org/10.1016/j.ijar.2024.109215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature importance is a complex issue in machine learning, as determining a superior attribute is vague, uncertain, and dependent on the model. This study introduces a rough-fuzzy hybrid (RAFAR) method that merges various techniques from rough set theory and fuzzy set theory to tackle uncertainty in attribute importance and ranking. RAFAR utilizes an interval-valued fuzzy matrix to depict preference between attribute pairs. This research focuses on constructing these matrices from datasets and identifying suitable rankings based on these matrices. The concept of interval-valued weight vectors is introduced to represent attribute importance, and their additive and multiplicative compatibility is examined. The properties of these consistency types and the efficient algorithms for solving related problems are discussed. These new theoretical findings are valuable for creating effective optimization models and algorithms within the RAFAR framework. Additionally, novel approaches for constructing pairwise comparison matrices and enhancing the scalability of RAFAR are suggested. The study also includes experimental results on benchmark datasets to demonstrate the accuracy of the proposed solutions.},
  archive      = {J_IJAR},
  author       = {Bich Khue Vo and Hung Son Nguyen},
  doi          = {10.1016/j.ijar.2024.109215},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109215},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {An attribute ranking method based on rough sets and interval-valued fuzzy sets},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Testing the fit of data and external sets via an imprecise
sargan-hansen test. <em>IJAR</em>, <em>170</em>, 109214. (<a
href="https://doi.org/10.1016/j.ijar.2024.109214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In empirical sciences such as psychology, the term cumulative science mostly refers to the integration of theories, while external (prior) information may also be used in statistical inference. This external information can be in the form of statistical moments and is subject to various types of uncertainty, e.g., because it is estimated, or because of qualitative uncertainty due to differences in study design or sampling. Before using it in statistical inference, it is therefore important to test whether the external information fits a new data set, taking into account its uncertainties. As a frequentist approach, the Sargan-Hansen test from the generalized method of moments framework is used in this paper. It tests, given a statistical model, whether data and point-wise external information are in conflict. A separability result is given that simplifies the Sargan-Hansen test statistic in most cases. The Sargan-Hansen test is then extended to the imprecise scenario with (estimated) external sets using stochastically ordered credal sets. Furthermore, an exact small sample version is derived for normally distributed variables. As a Bayesian approach, two prior-data conflict criteria are discussed as a test for the fit of external information to the data. Two simulation studies are performed to test and compare the power and type I error of the methods discussed. Different small sample scenarios are implemented, varying the moments used, the level of significance, and other aspects. The results show that both the Sargan-Hansen test and the Bayesian criteria control type I errors while having sufficient or even good power. To facilitate the use of the methods by applied scientists, easy-to-use R functions are provided in the R script in the supplementary materials.},
  archive      = {J_IJAR},
  author       = {Martin Jann},
  doi          = {10.1016/j.ijar.2024.109214},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109214},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Testing the fit of data and external sets via an imprecise sargan-hansen test},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Imprecision in martingale- and test-theoretic prequential
randomness. <em>IJAR</em>, <em>170</em>, 109213. (<a
href="https://doi.org/10.1016/j.ijar.2024.109213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a prequential approach to algorithmic randomness, probabilities for the next outcome can be forecast ‘on the fly’ without the need for fully specifying a probability measure on all possible sequences of outcomes, as is the case in the more standard approach. We take the first steps in allowing for probability intervals instead of precise probabilities on this prequential approach, based on ideas borrowed from our earlier imprecise-probabilistic, standard account of algorithmic randomness. We define what it means for an infinite sequence ( I 1 , x 1 , I 2 , x 2 , … ) (I1,x1,I2,x2,…) of successive interval forecasts I k Ik and subsequent binary outcomes x k xk to be random, both in a martingale-theoretic and a test-theoretic sense. We prove that these two versions of prequential randomness coincide, we compare the resulting prequential randomness notions with the more standard ones, and we investigate where the prequential and standard randomness notions coincide.},
  archive      = {J_IJAR},
  author       = {Floris Persiau and Gert de Cooman},
  doi          = {10.1016/j.ijar.2024.109213},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109213},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Imprecision in martingale- and test-theoretic prequential randomness},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distribution-free inferential models: Achieving
finite-sample valid probabilistic inference, with emphasis on quantile
regression. <em>IJAR</em>, <em>170</em>, 109211. (<a
href="https://doi.org/10.1016/j.ijar.2024.109211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel distribution-free Inferential Model (IM) construction that provides valid probabilistic inference across a broad spectrum of distribution-free problems, even in finite sample settings. More specifically, the proposed IM has the capability to assign (imprecise) probabilities to assertions of interest about any feature of the unknown quantities under examination, and these probabilities are well-calibrated in a frequentist sense. It is also shown that finite-sample confidence regions can be derived from the IM for any such features. Particular emphasis is placed on quantile regression, a domain where uncertainty quantification often takes the form of set estimates for the regression coefficients in applications. Within this context, the IM facilitates the acquisition of these set estimates, ensuring they are finite-sample confidence regions. It also enables the provision of finite-sample valid probabilistic assignments for any assertions of interest about the regression coefficients. As a result, regardless of the type of uncertainty quantification desired, the proposed framework offers an appealing solution to quantile regression.},
  archive      = {J_IJAR},
  author       = {Leonardo Cella},
  doi          = {10.1016/j.ijar.2024.109211},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109211},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Distribution-free inferential models: Achieving finite-sample valid probabilistic inference, with emphasis on quantile regression},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attribute reduction for heterogeneous data based on
monotonic relative neighborhood granularity. <em>IJAR</em>,
<em>170</em>, 109210. (<a
href="https://doi.org/10.1016/j.ijar.2024.109210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neighborhood rough set model serves as an important tool for handling attribute reduction tasks involving heterogeneous attributes. However, measuring the relationship between conditional attributes and decision in the neighborhood rough set model is a crucial issue. Most studies have utilized neighborhood information entropy to measure the relationship between attributes. When using neighborhood conditional information entropy to measure the relationships between the decision and conditional attributes, it lacks monotonicity, consequently affecting the rationality of the final attribute reduction subset. In this paper, we introduce the concept of neighborhood granularity and propose a new form of relative neighborhood granularity to measure the relationship between the decision and conditional attributes, which exhibits monotonicity. Moreover, our approach for measuring neighborhood granularity avoids the logarithmic function computation involved in neighborhood information entropy. Finally, we conduct comparative experiments on 12 datasets using two classifiers to compare the results of attribute reduction with six other attribute reduction algorithms. The comparison demonstrates the advantages of our measurement approach.},
  archive      = {J_IJAR},
  author       = {Jianhua Dai and Zhilin Zhu and Min Li and Xiongtao Zou and Chucai Zhang},
  doi          = {10.1016/j.ijar.2024.109210},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109210},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Attribute reduction for heterogeneous data based on monotonic relative neighborhood granularity},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tuning fuzzy SPARQL queries. <em>IJAR</em>, <em>170</em>,
109209. (<a href="https://doi.org/10.1016/j.ijar.2024.109209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the last years, the study of fuzzy database query languages has attracted the attention of many researchers. In this line of research, our group has proposed and developed FSA-SPARQL ( Fuzzy Sets and Aggregators based SPARQL ), which is a fuzzy extension of the Semantic Web query language SPARQL. FSA-SPARQL works with fuzzy RDF datasets and allows the definition of fuzzy queries involving fuzzy conditions through fuzzy connectives and aggregators. However, there are two main challenges to be solved for the practical applicability of FSA-SPARQL . The first problem is the lack of fuzzy RDF data sources. The second is how to customize fuzzy queries on fuzzy RDF data sources. Our research group has also recently proposed a fuzzy logic programming language called F A S I L L FASILL that offers powerful tuning capabilities that can accept applications in many fields. The purpose of this paper is to show how the F A S I L L FASILL tuning capabilities serve to accomplish in a unified framework both challenges in FSA-SPARQL : data fuzzification and query customization. More concretely, from a FSA-SPARQL to F A S I L L FASILL transformation, data fuzzification and query customization in FSA-SPARQL become F A S I L L FASILL tuning problems. We have validated the approach with queries against datasets from online communities.},
  archive      = {J_IJAR},
  author       = {Jesús M. Almendros-Jiménez and Antonio Becerra-Terón and Ginés Moreno and José A. Riaza},
  doi          = {10.1016/j.ijar.2024.109209},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109209},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Tuning fuzzy SPARQL queries},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conditional independence collapsibility for acyclic directed
mixed graph models. <em>IJAR</em>, <em>170</em>, 109208. (<a
href="https://doi.org/10.1016/j.ijar.2024.109208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collapsibility refers to the property that, when marginalizing over some variables that are not of interest from the full model, the resulting marginal model of the remaining variables is equivalent to the local model induced by the subgraph on these variables. This means that when the marginal model satisfies collapsibility, statistical inference results based on the marginal model and the local model are consistent. This has significant implications for small-sample data, modeling latent variable data, and reducing the computational complexity of statistical inference. This paper focuses on studying the conditional independence collapsibility of acyclic directed mixed graph (ADMG) models. By introducing the concept of inducing paths in ADMGs and exploring its properties, the conditional independence collapsibility of ADMGs is characterized equivalently from both graph theory and statistical perspectives.},
  archive      = {J_IJAR},
  author       = {Weihua Li and Yi Sun and Pei Heng},
  doi          = {10.1016/j.ijar.2024.109208},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109208},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Conditional independence collapsibility for acyclic directed mixed graph models},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Being bayesian about learning bayesian networks from ordinal
data. <em>IJAR</em>, <em>170</em>, 109205. (<a
href="https://doi.org/10.1016/j.ijar.2024.109205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a Bayesian approach for inferring Bayesian network (BN) structures from ordinal data. Our approach can be seen as the Bayesian counterpart of a recently proposed frequentist approach, referred to as the ‘ordinal structure expectation maximization’ (OSEM) method. Like for the OSEM method, the key idea is to assume that each ordinal variable originates from a Gaussian variable that can only be observed in discretized form, and that the dependencies in the latent Gaussian space can be modeled by BNs; i.e. by directed acyclic graphs (DAGs). Our Bayesian method combines the ‘structure MCMC sampler’ for DAG posterior sampling, a slightly modified version of the ‘Bayesian metric for Gaussian networks having score equivalence’ (BGe score), the concept of the ‘extended rank likelihood’, and a recently proposed algorithm for posterior sampling the parameters of Gaussian BNs. In simulation studies we compare the new Bayesian approach and the OSEM method in terms of the network reconstruction accuracy. The empirical results show that the new Bayesian approach leads to significantly improved network reconstruction accuracies.},
  archive      = {J_IJAR},
  author       = {Marco Grzegorczyk},
  doi          = {10.1016/j.ijar.2024.109205},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109205},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Being bayesian about learning bayesian networks from ordinal data},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Triple perturbed consistent matrix and the efficiency of its
principal right eigenvector. <em>IJAR</em>, <em>170</em>, 109204. (<a
href="https://doi.org/10.1016/j.ijar.2024.109204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let A be a pairwise comparison matrix obtained from a consistent one by perturbing three entries above the main diagonal, x , y , z x,y,z , and the corresponding reciprocal entries, in a way that there is a submatrix of size 2 containing the three perturbed entries and not containing a diagonal entry. In this paper we describe the relations among x , y , z x,y,z with which A always has its principal right eigenvector efficient. Previously, and only for a few cases of this problem, R. Fernandes and S. Furtado (2022) proved the efficiency of the principal right eigenvector of A . In this paper, we continue to use the strong connectivity of a certain digraph associated with A and its principal right eigenvector to characterize the vector efficiency. For completeness, we show that the existence of a sink in this digraph is equivalent to the inefficiency of the principal right eigenvector of A .},
  archive      = {J_IJAR},
  author       = {Rosário Fernandes and Susana Palheira},
  doi          = {10.1016/j.ijar.2024.109204},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109204},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Triple perturbed consistent matrix and the efficiency of its principal right eigenvector},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consequence relations and data science: From galois mappings
to data interpretation. <em>IJAR</em>, <em>170</em>, 109203. (<a
href="https://doi.org/10.1016/j.ijar.2024.109203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concepts of a consequence relation and operation, though very abstract and theoretical, may be related to specific categories of information systems (i.e. mathematical frontends of data tables); as it has been demonstrated by D. Vakarelov, there exist correspondence between Pawlak information systems and Scott as well as Tarski consequence operations. This line of research goes (via representation ) from abstract concepts to data. In this paper we would like to take the opposite direction: from data (via construction ) to consequence relations. The main emphasis is laid here not on general categories of consequence relations (e.g. Scott or Tarski ones) but on concrete operators that can be retrieved from information systems (e.g. different examples of Scott consequence). To this end, we employ Galois connections and adjunctions ( en masse called Galois mappings) and study the consequence relations that can be built via these maps. The main novelty of our research comes from the investigation of consequence relations induced by adjunctions rather than monotone Galois connections, which have been the main subject of studies so far. Surprisingly, the operations obtained from adjunctions possess a number of counter-intuitive properties, which (in turn) request some intelligible interpretations. And this is our next objective: to make sense of these consequence relations in the context of information processing.},
  archive      = {J_IJAR},
  author       = {Marcin Wolski and Anna Gomolińska},
  doi          = {10.1016/j.ijar.2024.109203},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109203},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Consequence relations and data science: From galois mappings to data interpretation},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Logics for the new AI spring. <em>IJAR</em>, <em>170</em>,
109199. (<a href="https://doi.org/10.1016/j.ijar.2024.109199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJAR},
  author       = {Tommaso Flaminio and Hykel Hosni},
  doi          = {10.1016/j.ijar.2024.109199},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109199},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Logics for the new AI spring},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uncertainty propagation in stereo matching using copulas.
<em>IJAR</em>, <em>170</em>, 109191. (<a
href="https://doi.org/10.1016/j.ijar.2024.109191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This contribution presents a concrete example of uncertainty propagation in a stereo matching pipeline. It considers the problem of matching pixels between pairs of images whose radiometry is uncertain and modeled by possibility distributions. Copulas serve as dependency models between variables and are used to propagate the imprecise models. The propagation steps are detailed in the simple case of the Sum of Absolute Difference cost function for didactic purposes. The method results in an imprecise matching cost curve. To reduce computation time, a sufficient condition for conserving possibility distributions after the propagation is also presented. Finally, results are compared with Monte Carlo simulations, indicating that the method produces envelopes capable of correctly estimating the matching cost.},
  archive      = {J_IJAR},
  author       = {Roman Malinowski and Sébastien Destercke and Loïc Dumas and Emmanuel Dubois and Emmanuelle Sarrazin},
  doi          = {10.1016/j.ijar.2024.109191},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109191},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Uncertainty propagation in stereo matching using copulas},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neighborhood-based argumental community support in the
context of multi-topic debates. <em>IJAR</em>, <em>170</em>, 109189. (<a
href="https://doi.org/10.1016/j.ijar.2024.109189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The formal characterization of abstract argumentation has allowed the study of many exciting characteristics of the argumentation process. Nevertheless, while helpful in many aspects, abstraction diminishes the knowledge representation capabilities available to describe naturally occurring features of argumentative dialogues; one of these elements is the consideration of the topics involved in a discussion. In studying dialogical processes, participants recognize that some topics are closely related to the original issue; in contrast, others are more distant from the central subject or refer to unrelated matters. Consequently, it is reasonable to study different argumentation semantics that considers a discussion&#39;s focus to evaluate acceptability. In this work, we introduce the necessary representational elements required to reflect the focus of a discussion. We propose a novel extension of the semantics for multi-topic abstract argumentation frameworks , acknowledging that every argument has its own zone of relevance in the argumentation framework, leading to the concepts of neighborhoods and communities of legitimate defenses. Furthermore, other semantic elaborations are defined and discussed around this structure.},
  archive      = {J_IJAR},
  author       = {Irene M. Coronel and Melisa G. Escañuela Gonzalez and Diego C. Martinez and Gerardo I. Simari and Maximiliano C.D. Budán},
  doi          = {10.1016/j.ijar.2024.109189},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109189},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Neighborhood-based argumental community support in the context of multi-topic debates},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shortest-length and coarsest-granularity constructs
vs. Reducts: An experimental evaluation. <em>IJAR</em>, <em>170</em>,
109187. (<a href="https://doi.org/10.1016/j.ijar.2024.109187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of rough set theory, super-reducts represent subsets of attributes possessing the same discriminative power as the complete set of attributes when it comes to distinguishing objects across distinct classes in supervised classification problems. Within the realm of super-reducts, the concept of reducts holds significance, denoting subsets that are irreducible. Contrastingly, constructs, while serving the purpose of distinguishing objects across different classes, also exhibit the capability to preserve certain shared characteristics among objects within the same class. In essence, constructs represent a subtype of super-reducts that integrates information both inter-classes and intra-classes. Despite their potential, constructs have garnered comparatively less attention than reducts. Both reducts and constructs find application in the reduction of data dimensionality. This paper exposes key concepts related to constructs and reducts, providing insights into their roles. Additionally, it conducts an experimental comparative study between optimal reducts and constructs, considering specific criteria such as shortest length and coarsest granularity, and evaluates their performance using classical classifiers. The outcomes derived from employing seven classifiers on sixteen datasets lead us to propose that both coarsest granularity reducts and constructs prove to be effective choices for dimensionality reduction in supervised classification problems. Notably, when considering the optimality criterion of the shortest length, constructs exhibit clear superiority over reducts, which are found to be less favorable. Moreover, a comparative analysis was conducted between the results obtained using the coarsest granularity constructs and a technique from outside of rough set theory, specifically correlation-based feature selection. The former demonstrated statistically superior performance, providing further evidence of its efficacy in comparison.},
  archive      = {J_IJAR},
  author       = {Manuel S. Lazo-Cortés and Guillermo Sanchez-Diaz and Nelva N. Almanza Ortega},
  doi          = {10.1016/j.ijar.2024.109187},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109187},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Shortest-length and coarsest-granularity constructs vs. reducts: An experimental evaluation},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot learning based on hierarchical feature fusion via
relation networks. <em>IJAR</em>, <em>170</em>, 109186. (<a
href="https://doi.org/10.1016/j.ijar.2024.109186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning, which aims to identify new classes with few samples, is an increasingly popular and crucial research topic in the machine learning. Recently, the development of deep learning has deepened the network structure of a few-shot model, thereby obtaining deeper features from the samples. This trend led to an increasing number of few-shot learning models pursuing more complex structures and deeper features. However, discarding shallow features and blindly pursuing the depth of sample feature levels is not reasonable. The features at different levels of the sample have different information and characteristics. In this paper, we propose a few-shot image classification model based on deep and shallow feature fusion and a coarse-grained relationship score network (HFFCR). First, we utilize networks with different depth structures as feature extractors and then fuse the two kinds of sample features. The fused sample features collect sample information at different levels. Second, we condense the fused features into a coarse-grained prototype point. Prototype points can better represent the information in this class and improve classification efficiency. Finally, we construct a relationship score network, concatenating the prototype points and query samples into a feature map and sending it into the network to calculate the relationship score. The classification criteria for learnable relationship scores reflect the information difference between the two samples. Experiments on three datasets show that HFFCR has advanced performance.},
  archive      = {J_IJAR},
  author       = {Xiao Jia and Yingchi Mao and Zhenxiang Pan and Zicheng Wang and Ping Ping},
  doi          = {10.1016/j.ijar.2024.109186},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109186},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Few-shot learning based on hierarchical feature fusion via relation networks},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical variable clustering based on the predictive
strength between random vectors. <em>IJAR</em>, <em>170</em>, 109185.
(<a href="https://doi.org/10.1016/j.ijar.2024.109185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A rank-invariant clustering of variables is introduced that is based on the predictive strength between groups of variables, i.e., two groups are assigned a high similarity if the variables in the first group contain high predictive information about the behaviour of the variables in the other group and/or vice versa. The method presented here is model-free, dependence-based and does not require any distributional assumptions. Various general invariance and continuity properties are investigated, with special attention to those that are beneficial for the agglomerative hierarchical clustering procedure. A fully non-parametric estimator is considered whose excellent performance is demonstrated in several simulation studies and by means of real-data examples.},
  archive      = {J_IJAR},
  author       = {Sebastian Fuchs and Yuping Wang},
  doi          = {10.1016/j.ijar.2024.109185},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109185},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Hierarchical variable clustering based on the predictive strength between random vectors},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intensions and extensions of granules: A two-component
treatment. <em>IJAR</em>, <em>169</em>, 109182. (<a
href="https://doi.org/10.1016/j.ijar.2024.109182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of a granule (of knowledge) originated from Zadeh, where granules appeared as references to words (phrases) of a natural (or an artificial) language. According to Zadeh&#39;s program, “a granule is a collection of objects drawn together by similarity or functionality and considered therefore as a whole”. Pawlak&#39;s original theory of rough sets and its different generalizations have a common property: all systems rely on a given background knowledge represented by the system of base sets. Since the members of a base set have to be treated similarly, base sets can be considered as granules. The background knowledge has a conceptual structure, and it contains information that does not appear on the level of base granules, so such information cannot be taken into consideration in approximations. A new problem arises: is there any possibility of constructing a system modeling the background knowledge better? A two-component treatment can be a solution to this problem. After giving the formal language of granules involving the tools for approximations, a logical calculus containing approximation operators is introduced. Then, a two-component semantics (treating intensions and extensions of granule expressions) is defined. The authors show the connection between the logical calculus and the two-component semantics.},
  archive      = {J_IJAR},
  author       = {Tamás Mihálydeák and Tamás Kádek and Dávid Nagy and Mihir K. Chakraborty},
  doi          = {10.1016/j.ijar.2024.109182},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109182},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Intensions and extensions of granules: A two-component treatment},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature selection for multi-label learning based on
variable-degree multi-granulation decision-theoretic rough sets.
<em>IJAR</em>, <em>169</em>, 109181. (<a
href="https://doi.org/10.1016/j.ijar.2024.109181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning (MLL) suffers from the high-dimensional feature space teeming with irrelevant and redundant features. To tackle this, several multi-label feature selection (MLFS) algorithms have emerged as vital preprocessing steps. Nonetheless, existing MLFS methods have their shortcomings. Primarily, while they excel at harnessing label-feature relationships, they often struggle to leverage inter-feature information effectively. Secondly, numerous MLFS approaches overlook the uncertainty in the boundary domain, despite its critical role in identifying high-quality features. To address these issues, this paper introduces a novel MLFS algorithm, named VMFS. It innovatively integrates multi-granulation rough sets with three-way decision, leveraging multi-granularity decision-theoretic rough sets (MGDRS) with variable degrees for optimal performance. Initially, we construct coarse decision (RDC), fine decision (RDF), and uncertainty decision (RDU) functions for each object based on MGDRS with variable degrees. These decision functions then quantify the dependence of attribute subsets, considering both deterministic and uncertain aspects. Finally, we employ the dependency to assess attribute importance and rank them accordingly. Our proposed method has undergone rigorous evaluation on various standard multi-label datasets, demonstrating its superiority. Experimental results consistently show that VMFS significantly outperforms other algorithms on most datasets, underscoring its effectiveness and reliability in multi-label learning tasks.},
  archive      = {J_IJAR},
  author       = {Ying Yu and Ming Wan and Jin Qian and Duoqian Miao and Zhiqiang Zhang and Pengfei Zhao},
  doi          = {10.1016/j.ijar.2024.109181},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109181},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Feature selection for multi-label learning based on variable-degree multi-granulation decision-theoretic rough sets},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Desirable gambles based on pairwise comparisons.
<em>IJAR</em>, <em>169</em>, 109180. (<a
href="https://doi.org/10.1016/j.ijar.2024.109180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a model for imprecise probability information based on bounds on probability ratios, instead of bounds on events. This model is studied in the language of coherent sets of desirable gambles, which provides an elegant mathematical formulation and a more expressive power. The paper provides methods to check avoiding sure loss and coherence, and to compute the natural extension. The relationships with other formalisms such as imprecise multiplicative preferences, the constant odd ratio model, or comparative probability are analyzed.},
  archive      = {J_IJAR},
  author       = {Serafín Moral},
  doi          = {10.1016/j.ijar.2024.109180},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109180},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Desirable gambles based on pairwise comparisons},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multidimensional fuzzy sets: Negations and an algorithm for
multi-attribute group decision making. <em>IJAR</em>, <em>169</em>,
109171. (<a href="https://doi.org/10.1016/j.ijar.2024.109171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multidimensional fuzzy sets (MFS) is a new extension of fuzzy sets on which the membership values of an element in the universe of discourse are increasingly ordered vectors on the set of real numbers in the interval [ 0 , 1 ] [0,1] . This paper aims to investigate fuzzy negations on the set of increasingly ordered vectors on [ 0 , 1 ] [0,1] , i.e. on L ∞ ( [ 0 , 1 ] ) L∞([0,1]) , MFN in short, with respect to some partial order. In this paper we study partial orders, giving special attention to admissible orders on L n ( [ 0 , 1 ] ) Ln([0,1]) and L ∞ ( [ 0 , 1 ] ) L∞([0,1]) . In addition, we study the possibility of existence of strong multidimensional fuzzy negations and some properties and methods to construct such operators. In particular, we define the ordinal sums of n-dimensional negations and ordinal sums of multidimensional fuzzy negations on a multidimensional product order. A multi-attribute group decision making algorithm is presented.},
  archive      = {J_IJAR},
  author       = {Landerson Santiago and Benjamin Bedregal},
  doi          = {10.1016/j.ijar.2024.109171},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109171},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Multidimensional fuzzy sets: Negations and an algorithm for multi-attribute group decision making},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A study of rough inclusion on algebras with quasi-boolean
base. <em>IJAR</em>, <em>169</em>, 109170. (<a
href="https://doi.org/10.1016/j.ijar.2024.109170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-rough algebra has emerged from the rough set theory, which is a quasi-Boolean algebra with a few additional axioms. Four types of abstract rough inclusion are defined in pre-rough algebra which give rise to four different implication operators within this algebra. Properties of these four implications are studied from the angle of residuation. Logics of pre-rough algebra with respect to different implications are presented.},
  archive      = {J_IJAR},
  author       = {Anirban Saha and Jayanta Sen and Mihir Kumar Chakraborty},
  doi          = {10.1016/j.ijar.2024.109170},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109170},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A study of rough inclusion on algebras with quasi-boolean base},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An auto-weighted enhanced horizontal collaborative fuzzy
clustering algorithm with knowledge adaption mechanism. <em>IJAR</em>,
<em>169</em>, 109169. (<a
href="https://doi.org/10.1016/j.ijar.2024.109169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among the multi-source data clustering tasks, there is a kind of frequently encountered tasks where only one of the multi-source datasets is available for sake of privacy and other reasons. The only available dataset is called local dataset, and the other are called external datasets. The horizontal collaborative fuzzy clustering (HCFC) model is a typical one that can deal with such clustering tasks. In HCFC, each external dataset is used through the knowledge mined from it rather than itself. The knowledge expressed as a knowledge partition matrix is fused into the clustering process of the local dataset. Reviewing the existing HCFC models, we can find three issues that need improvement. Firstly, the existing HCFC models quantify the collaboration contribution of each external knowledge by a hyperparameter at dataset-level, and moreover, do not distinguish the collaboration contributions of objects in the same external dataset. This may lead to counterintuitive clustering results. Focused on this issue, this paper proposes an enhanced HCFC (EHCFC) algorithm that extends the collaboration from dataset-level to object-level, and assigns different weights to objects based on the information amount provided by objects. Through EHCFC, a more flexible collaboration and a more intuitive clustering result can be reached. Secondly, the collaboration mechanisms of the existing HCFC models require that the dimensionalities of the partition matrices of external datasets and local dataset are the same, which makes the HCFC algorithms unable to work in many real situations. Focused on this limitation, a knowledge adaption mechanism based on relative entropy and spectral clustering is proposed resulting in a further refined EHCFC-KA algorithm, i.e., EHCFC with knowledge adaption. The proposed knowledge adaption mechanism makes both the HCFC algorithms and the EHCFC algorithm effective and successful in more application scenarios. Finally, we define two indexes in terms of consistency (the consistency of the clustering result with external knowledge) to evaluate the performance of collaborative clustering. Experiments on synthetic datasets and UCI public datasets demonstrate that the proposed EHCFC and EHCFC-KA algorithms outperform the existing HCFC algorithms and achieve significantly better intuitive collaborative clustering performance.},
  archive      = {J_IJAR},
  author       = {Huilin Yang and Fusheng Yu and Witold Pedrycz and Life Fellow, IEEE and Zonglin Yang and Jiaqi Chang and Jiayin Wang},
  doi          = {10.1016/j.ijar.2024.109169},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109169},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {An auto-weighted enhanced horizontal collaborative fuzzy clustering algorithm with knowledge adaption mechanism},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application of tropical optimization for solving
multicriteria problems of pairwise comparisons using log-chebyshev
approximation. <em>IJAR</em>, <em>169</em>, 109168. (<a
href="https://doi.org/10.1016/j.ijar.2024.109168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a decision-making problem to find absolute ratings of alternatives that are compared in pairs under multiple criteria, subject to constraints in the form of two-sided bounds on ratios between the ratings. Given matrices of pairwise comparisons made according to the criteria, the problem is formulated as the log-Chebyshev approximation of these matrices by a common consistent matrix (a symmetrically reciprocal matrix of unit rank) to minimize the approximation errors for all matrices simultaneously. We rearrange the approximation problem as a constrained multiobjective optimization problem of finding a vector that determines the approximating consistent matrix. The problem is then represented in the framework of tropical algebra, which deals with the theory and applications of idempotent semirings and provides a formal basis for fuzzy and interval arithmetic. We apply methods and results of tropical optimization to develop a new approach for handling the multiobjective optimization problem according to various principles of optimality. New complete solutions in the sense of the max-ordering, lexicographic ordering and lexicographic max-ordering optimality are obtained, which are given in a compact vector form ready for formal analysis and efficient computation. We present numerical examples of solving multicriteria problems of rating four alternatives from pairwise comparisons to illustrate the technique and compare it with others.},
  archive      = {J_IJAR},
  author       = {Nikolai Krivulin},
  doi          = {10.1016/j.ijar.2024.109168},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109168},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Application of tropical optimization for solving multicriteria problems of pairwise comparisons using log-chebyshev approximation},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A probabilistic modal logic for context-aware trust based on
evidence. <em>IJAR</em>, <em>169</em>, 109167. (<a
href="https://doi.org/10.1016/j.ijar.2024.109167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust is an extremely helpful construct when reasoning under uncertainty. Thus, being able to logically formalize the concept in a suitable language is important. However, doing so is problematic for three reasons. First, in order to keep track of the contextual nature of trust, situation trackers are required inside the language. Second, in order to produce trust estimations, agents rely on evidence personally gathered or reported by other agents; this requires elements in the language that can track which agents are used as referrals and how much weight is placed on their opinions. Finally, trust is subjective in nature, thus, personal thresholds are needed to track the trust-propensity of different evaluators. In this paper we propose an interpretation of a probabilistic modal language à la Hennessy-Milner in order to capture a context-aware quantitative notion of trust based on evidence. We also provide an axiomatization for the language and prove soundness, completeness, and decidability results.},
  archive      = {J_IJAR},
  author       = {Alessandro Aldini and Gianluca Curzi and Pierluigi Graziani and Mirko Tagliaferri},
  doi          = {10.1016/j.ijar.2024.109167},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109167},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A probabilistic modal logic for context-aware trust based on evidence},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparing machine learning algorithms by union-free generic
depth. <em>IJAR</em>, <em>169</em>, 109166. (<a
href="https://doi.org/10.1016/j.ijar.2024.109166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a framework for descriptively analyzing sets of partial orders based on the concept of depth functions. Despite intensive studies in linear and metric spaces, there is very little discussion on depth functions for non-standard data types such as partial orders. We introduce an adaptation of the well-known simplicial depth to the set of all partial orders, the union-free generic (ufg) depth. Moreover, we utilize our ufg depth for a comparison of machine learning algorithms based on multidimensional performance measures. Concretely, we provide two examples of classifier comparisons on samples of standard benchmark data sets. Our results demonstrate promisingly the wide variety of different analysis approaches based on ufg methods. Furthermore, the examples outline that our approach differs substantially from existing benchmarking approaches, and thus adds a new perspective to the vivid debate on classifier comparison. 1},
  archive      = {J_IJAR},
  author       = {Hannah Blocher and Georg Schollmeyer and Malte Nalenz and Christoph Jansen},
  doi          = {10.1016/j.ijar.2024.109166},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109166},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Comparing machine learning algorithms by union-free generic depth},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Systematic attribute reductions based on double granulation
structures and three-view uncertainty measures in interval-set decision
systems. <em>IJAR</em>, <em>169</em>, 109165. (<a
href="https://doi.org/10.1016/j.ijar.2024.109165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reductions eliminate redundant information to become valuable in data reasoning. In the data context of interval-set decision systems (ISDSs), attribute reductions rely on granulation structures and uncertainty measures; however, the current structures and measures exhibit the singleness limitations, so their enrichments imply corresponding improvements of attribute reductions. Aiming at ISDSs, a fuzzy-equivalent granulation structure is proposed to improve the existing similar granulation structure, dependency degrees are proposed to enrich the existing condition entropy by using algebra-information fusion, so 3 × 2 3×2 attribute reductions are systematically formulated to contain both a basic reduction algorithm (called CAR) and five advanced reduction algorithms. At the granulation level, the similar granulation structure is improved to the fuzzy-equivalent granulation structure by removing the granular repeatability, and two knowledge structures emerge. At the measurement level, dependency degrees are proposed from the algebra perspective to supplement the condition entropy from the information perspective, and mixed measures are generated by fusing dependency degrees and condition entropies from the algebra-information viewpoint, so three-view and three-way uncertainty measures emerge to acquire granulation monotonicity/non-monotonicity. At the reduction level, the two granulation structures and three-view uncertainty measures two-dimensionally produce 3 × 2 3×2 heuristic reduction algorithms based on attribute significances, and thus five new algorithms emerge to improve an old algorithm (i.e., CAR). As finally shown by data experiments, 3 × 2 3×2 -systematic construction measures and attribute reductions exhibit the effectiveness and development, comparative results validate the three-level improvements of granulation structures, uncertainty measures, and reduction algorithms on ISDSs. This study resorts to tri-level thinking to enrich the theory and application of three-way decision.},
  archive      = {J_IJAR},
  author       = {Xin Xie and Xianyong Zhang},
  doi          = {10.1016/j.ijar.2024.109165},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109165},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Systematic attribute reductions based on double granulation structures and three-view uncertainty measures in interval-set decision systems},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Overlap function-based fuzzy β-covering relations and fuzzy
β-covering rough set models. <em>IJAR</em>, <em>169</em>, 109164. (<a
href="https://doi.org/10.1016/j.ijar.2024.109164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an extension of the fuzzy covering, fuzzy β -covering has garnered significant scholarly concern. However, certain limitations impede its practical application. To address the issue of inaccurate characterization of object relationships caused by the current fuzzy β -neighborhood operator, four new operators were developed, which exhibit both symmetry and reflexivity through the utilization of established fuzzy β -neighborhood operators, overlap functions and grouping functions. Furthermore, we demonstrate that these operators satisfy the fuzzy β -covering relation, and utilize the fuzzy β -covering relations on the basis of overlap functions to propose new fuzzy β -covering rough set model. Additionally, incorporating the attribute significance, an attribute reduction algorithm is designed. Ultimately, we substantiate the rationality and superiority of our proposed algorithm by conducting a sequence of experiments. Meanwhile, we analyze the impacts of varying overlap functions and β values on the algorithm&#39;s performance.},
  archive      = {J_IJAR},
  author       = {Yaoyao Fan and Xiaohong Zhang and Jingqian Wang},
  doi          = {10.1016/j.ijar.2024.109164},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109164},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Overlap function-based fuzzy β-covering relations and fuzzy β-covering rough set models},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New results of (u,n)-implications satisfying
i(r,i(s,t))=i(i(r,s),i(r,t)). <em>IJAR</em>, <em>169</em>, 109163. (<a
href="https://doi.org/10.1016/j.ijar.2024.109163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized Frege&#39;s law has been extensively explored by numerous scholars in the field of fuzzy mathematics, particularly within the framework of fuzzy logic. This study aims to further investigate the ( U , N ) (U,N) -implications that satisfy this law and presents a multitude of novel findings. First, to efficiently determine the satisfiability of the generalized Frege&#39;s law for any ( U , N ) (U,N) -implication, two new necessary conditions have been introduced that are simple and practical: for the fuzzy negation N , it must be noncontinuous, and its values in the interval [ 0 , e ] [0,e] should remain the constant 1. Next, the necessary and sufficient conditions for any ( U , N ) (U,N) -implication to satisfy the generalized Frege&#39;s law are provided. Several complete characterizations are described depending on the position of α in [ e , 1 ] [e,1] . To be more specific, the full characterization is achieved when α = e α=e ( α = 1 α=1 ) and a disjunctive uninorm with a continuous underlying t-norm (t-conorm). The necessary and sufficient conditions are presented when α ∈ ] e , 1 [ α∈]e,1[ and U is a locally internal and disjunctive uninorm.},
  archive      = {J_IJAR},
  author       = {Cheng Zhang and Feng Qin},
  doi          = {10.1016/j.ijar.2024.109163},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109163},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {New results of (U,N)-implications satisfying I(r,I(s,t))=I(I(r,s),I(r,t))},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimating the coverage measure and the area explored by a
line-sweep sensor on the plane. <em>IJAR</em>, <em>169</em>, 109162. (<a
href="https://doi.org/10.1016/j.ijar.2024.109162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a method for determining the area explored by a line-sweep sensor during an area-covering mission in a two-dimensional plane. Accurate knowledge of the explored area is crucial for various applications in robotics, such as mapping, surveillance, and coverage optimization. The proposed method leverages the concept of coverage measure of the environment and its relation to the topological degree in the plane, to estimate the extent of the explored region. In addition, we extend the approach to uncertain coverage measure values using interval analysis. This last contribution allows for a guaranteed characterization of the explored area, essential considering the often critical character of area-covering missions. Finally, this paper also proposes a novel algorithm for computing the topological degree in the 2-dimensional plane, for all the points inside an area of interest, which differs from existing solutions that compute the topological degree for single points. The applicability of the method is evaluated through a real-world experiment.},
  archive      = {J_IJAR},
  author       = {Maria Costa Vianna and Eric Goubault and Luc Jaulin and Sylvie Putot},
  doi          = {10.1016/j.ijar.2024.109162},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109162},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Estimating the coverage measure and the area explored by a line-sweep sensor on the plane},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uncertainty quantification in logistic regression using
random fuzzy sets and belief functions. <em>IJAR</em>, <em>168</em>,
109159. (<a href="https://doi.org/10.1016/j.ijar.2024.109159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evidential likelihood-based inference is a new approach to statistical inference in which the relative likelihood function is interpreted as a possibility distribution. By expressing new data as a function of the parameter and a random variable with known probability distribution, one then defines a random fuzzy set and an associated predictive belief function representing uncertain knowledge about future observations. In this paper, this approach is applied to binomial and multinomial regression. In the binomial case, the predictive belief function can be computed by numerically integrating the possibility distribution of the posterior probability. In the multinomial case, the solution is obtained by a combination of constrained nonlinear optimization and Monte Carlo simulation. In both cases, computations can be considerably simplified using a normal approximation to the relative likelihood. Numerical experiments show that decision rules based on predictive belief functions make it possible to reach lower error rates for different rejection rates, as compared to decisions based on posterior probabilities.},
  archive      = {J_IJAR},
  author       = {Thierry Denœux},
  doi          = {10.1016/j.ijar.2024.109159},
  journal      = {International Journal of Approximate Reasoning},
  month        = {5},
  pages        = {109159},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Uncertainty quantification in logistic regression using random fuzzy sets and belief functions},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast and robust clustering of general-shaped structures with
tk-merge. <em>IJAR</em>, <em>168</em>, 109152. (<a
href="https://doi.org/10.1016/j.ijar.2024.109152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world applications, the group of provenance of data can be inherently uncertain, the data values can be imprecise and some of them can be wrong. We handle uncertain, imprecise and noisy data in clustering problems with general-shaped structures. We do it under very weak parametric assumptions with a two-step hybrid robust clustering algorithm based on trimmed k-means and hierarchical agglomeration. The algorithm has low computational complexity and effectively identifies the clusters also in presence of data contamination. We also present natural generalizations of the approach as well as an adaptive procedure to estimate the amount of contamination in a data-driven fashion. Our proposal outperforms state-of-the-art robust, model-based methods in our numerical simulations and real-world applications related to color quantization for image analysis, human mobility patterns based on GPS data, biomedical images of diabetic retinopathy, and weather data.},
  archive      = {J_IJAR},
  author       = {Luca Insolia and Domenico Perrotta},
  doi          = {10.1016/j.ijar.2024.109152},
  journal      = {International Journal of Approximate Reasoning},
  month        = {5},
  pages        = {109152},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Fast and robust clustering of general-shaped structures with tk-merge},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). L-valued covering-based rough sets and corresponding
decision-making applications. <em>IJAR</em>, <em>168</em>, 109151. (<a
href="https://doi.org/10.1016/j.ijar.2024.109151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering L to be a complete residuated lattice, by introducing the notion of L -valued covering on an L -set (as a universe), and then an L -valued neighborhood based on it, we present the concept of L -valued covering-based rough sets. We mainly address the following issues in this paper: Firstly, we present four types of L -valued neighborhood operators and study some of their respective properties. Secondly, we construct L -valued lower (resp., upper) approximation operators and then discuss some of their properties. Finally, we try to propose a kind of MADM problem based on an L -valued covering-based rough set model (for L = [ 0 , 1 ] L=[0,1] ).},
  archive      = {J_IJAR},
  author       = {Kamal El-Saady and Amal Rashed and Ayat A. Temraz},
  doi          = {10.1016/j.ijar.2024.109151},
  journal      = {International Journal of Approximate Reasoning},
  month        = {5},
  pages        = {109151},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {L-valued covering-based rough sets and corresponding decision-making applications},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extended papers from the 11th international symposium on
imprecise probabilities: Theories and applications. <em>IJAR</em>,
<em>168</em>, 109150. (<a
href="https://doi.org/10.1016/j.ijar.2024.109150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJAR},
  author       = {Jasper De Bock and Gert De Cooman and Cassio P. de Campos},
  doi          = {10.1016/j.ijar.2024.109150},
  journal      = {International Journal of Approximate Reasoning},
  month        = {5},
  pages        = {109150},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Extended papers from the 11th international symposium on imprecise probabilities: Theories and applications},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-label feature selection based on fuzzy rough sets with
metric learning and label enhancement. <em>IJAR</em>, <em>168</em>,
109149. (<a href="https://doi.org/10.1016/j.ijar.2024.109149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection based on fuzzy rough sets, as a key step of multi-label data preprocessing, has been widely concerned by scholars in recent years. Most of the existing multi-label feature selection algorithms directly treat labels as logical labels and use a single distance metric to describe similarity. However, the variability of label descriptions and the limitations of a single distance measure should not be overlooked. In this paper, we propose a fuzzy rough set model with metric learning and label enhancement. Specifically, we use a kernel membership label enhancement algorithm based on JS divergence to convert logical labels into numerical labels, which not only reflects the importance of different labels, but also takes into account the differences in label distribution. In addition, a multi-metric learning algorithm is proposed for multi-label learning, in which the metric distance function under the label space and feature space can be learned autonomously. Then, based on the proposed model, we propose a novel multi-label feature selection algorithm based on metric learning and fuzzy rough sets. On this basis, a fast multi-label feature selection algorithm is further designed to improve the computational efficiency. In the experiments, compared with other nine algorithms on real-world datasets, the results show the superiority of the proposed algorithm.},
  archive      = {J_IJAR},
  author       = {Mingjie Cai and Mei Yan and Pei Wang and Feng Xu},
  doi          = {10.1016/j.ijar.2024.109149},
  journal      = {International Journal of Approximate Reasoning},
  month        = {5},
  pages        = {109149},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Multi-label feature selection based on fuzzy rough sets with metric learning and label enhancement},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Strictly frequentist imprecise probability. <em>IJAR</em>,
<em>168</em>, 109148. (<a
href="https://doi.org/10.1016/j.ijar.2024.109148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strict frequentism defines probability as the limiting relative frequency in an infinite sequence. What if the limit does not exist? We present a broader theory, which is applicable also to data that exhibit diverging relative frequencies. In doing so, we develop a close connection with the theory of imprecise probability: the cluster points of relative frequencies yield a coherent upper prevision. We show that a natural frequentist definition of conditional probability recovers the generalized Bayes rule. Finally, we prove constructively that, for a finite set of elementary events, there exists a sequence for which the cluster points of relative frequencies coincide with a prespecified set which demonstrates the naturalness, and arguably completeness, of our theory.},
  archive      = {J_IJAR},
  author       = {Christian Fröhlich and Rabanus Derr and Robert C. Williamson},
  doi          = {10.1016/j.ijar.2024.109148},
  journal      = {International Journal of Approximate Reasoning},
  month        = {5},
  pages        = {109148},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Strictly frequentist imprecise probability},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Three-phase multi-criteria ranking considering three-way
decision framework and criterion fuzzy concept. <em>IJAR</em>,
<em>168</em>, 109147. (<a
href="https://doi.org/10.1016/j.ijar.2024.109147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The criterion fuzzy concept refers to a fuzzy set that represents the decision-maker&#39;s subjective preference for each criterion within the universe of criteria. Addressing the challenge of ranking all alternatives based on a given criterion fuzzy concept is a novel research direction in the field of fuzzy multi-criteria ranking issues. This paper proposes a three-phase approach for multi-criteria ranking in fuzzy environments, which combines the criterion fuzzy concept and three-way decision thinking. The proposed approach not only analyzes the decision-making characteristics of all alternatives but also facilitates their ranking. During the first phase, a qualitative classification method based on the criterion fuzzy concept and ideal solutions is defined, which divides all alternatives into three independent decision sub-regions. During the second phase, by analyzing the priority relationships among the alternatives within every sub-region, three local ranking rules for alternatives are proposed to determine the ranking of alternatives in each classification region. During the third phase, the semantic relations among three classification regions are considered to give an overall ranking of all alternatives. Finally, combined with two existing quantitative ranking indicators, multiple data sets are employed to verify the feasibility and superiority of the proposed three-phase multi-criteria ranking approach.},
  archive      = {J_IJAR},
  author       = {Kai Zhang and Jianhua Dai},
  doi          = {10.1016/j.ijar.2024.109147},
  journal      = {International Journal of Approximate Reasoning},
  month        = {5},
  pages        = {109147},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Three-phase multi-criteria ranking considering three-way decision framework and criterion fuzzy concept},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy implications - a (dis)similarity perspective.
<em>IJAR</em>, <em>168</em>, 109145. (<a
href="https://doi.org/10.1016/j.ijar.2024.109145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy implications continue to remain an important class among the fuzzy logic connectives, having found utility in contexts outside of logical inference too. Recently, fuzzy implications have been shown to be a fertile source for obtaining distance functions with very beneficial properties. In this work, we show that fuzzy implications can also be a good wellspring of fuzzy compatibility relations with myriad properties. Quite interestingly, the converse also holds good, i.e., we also show that we can represent any fuzzy implication through a pair ( d , E d,E ), where d is a distance function - called a pseudo-monometric - and E is a mono-similarity fuzzy relation. This representation helps us to propose an equivalent formulation of the problem of characterisation of QL-implications, that has the potential to offer computational savings in verifying if a QL-operation can be a QL-implication and also throws open further avenues of fruitful theoretical exploration.},
  archive      = {J_IJAR},
  author       = {Kavit Nanavati and Megha Gupta and Balasubramaniam Jayaram},
  doi          = {10.1016/j.ijar.2024.109145},
  journal      = {International Journal of Approximate Reasoning},
  month        = {5},
  pages        = {109145},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Fuzzy implications - A (dis)similarity perspective},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimality, necessity and sufficiency for argumentation and
explanation. <em>IJAR</em>, <em>168</em>, 109143. (<a
href="https://doi.org/10.1016/j.ijar.2024.109143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss explanations for formal (abstract and structured) argumentation – the question whether and why a certain argument or claim can be accepted (or not) under various extension-based semantics. We introduce a flexible framework, which can act as the basis for many different types of explanations. For example, we can have simple or comprehensive explanations in terms of arguments for or against a claim, arguments that (indirectly) defend a claim, the evidence (knowledge base) that supports or is incompatible with a claim, and so on. We show how selection based on necessity and sufficiency can be captured in our basic framework and discuss a real-life application.},
  archive      = {J_IJAR},
  author       = {AnneMarie Borg and Floris Bex},
  doi          = {10.1016/j.ijar.2024.109143},
  journal      = {International Journal of Approximate Reasoning},
  month        = {5},
  pages        = {109143},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Minimality, necessity and sufficiency for argumentation and explanation},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature selection of dominance-based neighborhood rough set
approach for processing hybrid ordered data. <em>IJAR</em>,
<em>167</em>, 109134. (<a
href="https://doi.org/10.1016/j.ijar.2024.109134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a fundamental application of rough set theory in identifying significant features and reducing data dimensionality. For ordered data (OD), existing studies of feature selection mainly aim at ODs with specific criteria, i.e., single-valued, interval-valued, or set-valued criteria. However, these studies are inapplicable to ODs simultaneously including the three criteria, namely, hybrid ODs (HODs). To fill such a gap, this paper investigates feature selection of HODs using dominance-based neighborhood rough sets (DNRSs). Firstly, we introduce a kind of DNRS model for HODs, examine its properties, and establish its relationships with other dominance-based rough sets. Corresponding to DNRSs of two different target concepts in HODs, we propose feature selections based on approximation accuracies, and the two feature selections are proven to be equivalent by the complementarity property of DNRSs. For the computation of the proposed feature selection, we construct discernibility criterion set, which is then employed to define the family of approximation discernibility criterion sets (ADCSF) and its minimal description (MD-ADCSF). All reducts and the most discriminative reduct are computed through MD-ADCSF, and the algorithms of MD-ADCSF and the most discriminative reduct are achieved in matrix form. Finally, we verify validity and effectiveness of the two algorithms by comparison experiments on nine real UCI datasets.},
  archive      = {J_IJAR},
  author       = {Jiayue Chen and Ping Zhu},
  doi          = {10.1016/j.ijar.2024.109134},
  journal      = {International Journal of Approximate Reasoning},
  month        = {4},
  pages        = {109134},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Feature selection of dominance-based neighborhood rough set approach for processing hybrid ordered data},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Paralinear distance and its algorithm for hierarchical
clustering of high-dimensional discrete variables. <em>IJAR</em>,
<em>167</em>, 109133. (<a
href="https://doi.org/10.1016/j.ijar.2024.109133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variable clustering is an important tool for mining association rules and explaining the latent mechanisms responsible for generating data. In this work, we aim to study the hierarchical variable clustering algorithm based on the paralinear distance between discrete variables. Firstly, we study the paralinear distance with the multinomial distribution , and point out that any distance with additivity on the graphical tree model has a unique form on the paralinear distance. And then, we suggest a novel hierarchical clustering algorithm, which can determine the local relationships of observed variables as sibling groups and singletons in each level, where the hierarchical structures are indicated between the levels. Furthermore, we show the probably approximately correct (PAC) property of the algorithm, and find out that its sample complexity is sensitive to the diameter of the tree. Finally, by using GPU computation, we demonstrate our discoveries and the applications of our learning algorithms through large-scale experiments on both synthetic and real-world data. Extensive empirical results show that the proposed method is efficient for discovering local structures and latent information.},
  archive      = {J_IJAR},
  author       = {Shuai Wang and Lizhu Hao and Xiaofei Wang and Jianhua Guo},
  doi          = {10.1016/j.ijar.2024.109133},
  journal      = {International Journal of Approximate Reasoning},
  month        = {4},
  pages        = {109133},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Paralinear distance and its algorithm for hierarchical clustering of high-dimensional discrete variables},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluating uncertainty with vertical barrier models.
<em>IJAR</em>, <em>167</em>, 109132. (<a
href="https://doi.org/10.1016/j.ijar.2024.109132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vertical Barrier Models (VBM) are a family of imprecise probability models that generalise a number of well known distortion/neighbourhood models (such as the Pari-Mutuel Model, the Linear-Vacuous Model, and others) while still being relatively simple. Several of their properties were established in previous works; in this paper we explore, in a finite framework, further facets of these models: their interpretation as neighbourhood models, the structure of their credal set in terms of maximum number of its extreme points , the result of merging operations with VBMs, the properties of their mass function, the conditions for VBMs to be belief functions or maxitive measures and the approximation of other models by VBMs.},
  archive      = {J_IJAR},
  author       = {Enrique Miranda and Renato Pelessoni and Paolo Vicig},
  doi          = {10.1016/j.ijar.2024.109132},
  journal      = {International Journal of Approximate Reasoning},
  month        = {4},
  pages        = {109132},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Evaluating uncertainty with vertical barrier models},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph neural networks-based preference learning method for
object ranking. <em>IJAR</em>, <em>167</em>, 109131. (<a
href="https://doi.org/10.1016/j.ijar.2024.109131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preference learning refers to the task of predicting the ranking of a collection of alternatives based on observed or revealed preference information. Object ranking is a critical problem within the domain of preference learning, which can be described as learning a ranking function based on training data in a ranked form. Some existing parametric preference learning methods are difficult to balance the relationship between expressive power and training cost. To deal with this issue, we introduce the concept of graph neural networks (GNNs) into preference learning, and propose a GNNs-based preference learning method. Our method is composed of three stages to cope with preference learning, i.e. preference relation graph construction, preference relation prediction, and object preference ranking. In the first stage, we map preference information onto the graph structure, and construct a directed graph with objects as nodes and preference relations between objects as edges. In the second stage, we formulate relation prediction as an edge classification problem on the graph, design a model consisting of multi-layer perceptron (MLP) and GNNs to extract edge features. In the third stage, we build a comparator neural network structure , which takes pairwise preference information as input and the score of each object as output, and the ranking of object scores is the objects&#39; preference order . Experiments on preference learning datasets demonstrate that, compared to baselines, our method can achieve marked performance gains in terms of object ranking scenario.},
  archive      = {J_IJAR},
  author       = {Zhenhua Meng and Rongheng Lin and Budan Wu},
  doi          = {10.1016/j.ijar.2024.109131},
  journal      = {International Journal of Approximate Reasoning},
  month        = {4},
  pages        = {109131},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Graph neural networks-based preference learning method for object ranking},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constructing overlap functions on bounded posets via
multiplicative generators. <em>IJAR</em>, <em>167</em>, 109129. (<a
href="https://doi.org/10.1016/j.ijar.2024.109129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overlap functions are an important class of aggregation operators on [0,1] that have been proposed for applications in image processing , classification, etc. Later, Paiva et al. lifted overlap functions on [0,1] to complete lattices . In this paper, we continue to study overlap functions on bounded posets so as to lift the continuity in the notion of overlap functions from [0,1] to bounded posets mainly from the topological aspects. More precisely, we introduce the notion of overlap functions on bounded posets. And then, we consider the multiplicative generator triples of overlap functions on bounded posets, and investigate constructions of overlap functions by multiplicative generator triples.},
  archive      = {J_IJAR},
  author       = {Jing Lu and Bin Zhao},
  doi          = {10.1016/j.ijar.2024.109129},
  journal      = {International Journal of Approximate Reasoning},
  month        = {4},
  pages        = {109129},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Constructing overlap functions on bounded posets via multiplicative generators},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The interior of inconsistency in a knowledge base.
<em>IJAR</em>, <em>166</em>, 109127. (<a
href="https://doi.org/10.1016/j.ijar.2024.109127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Looking inside local inconsistencies arising in different parts of a knowledge base may help us better frame the inconsistency of the knowledge base . Moreover, as possible changes of the inconsistency due to removing some formulas from the knowledge base, local inconsistencies play an important role in identifying contributions of formulas to the inconsistency in the knowledge base. In this paper, we focus on local inconsistencies arising in all inconsistent subsets of a knowledge base and their relations with the inconsistency in the whole knowledge base. We call inconsistencies in all the inconsistent subsets of a knowledge base the interior of inconsistency of the knowledge base, and characterize the interior of inconsistency in two directions. One is the distribution of local inconsistencies over the power set of the knowledge base and relations between them. It focuses on local appearances of the inconsistency in different parts of the knowledge base. The other is the hierarchical structure of the interior of inconsistency due to different deviations of local inconsistencies from the inconsistency of the knowledge base. This direction is more interested in the aspect of each local inconsistency as a potential change of the inconsistency due to removing some formulas. Then we consider the interior of inconsistency of a knowledge base from syntactic and semantic perspectives, respectively.},
  archive      = {J_IJAR},
  author       = {Kedian Mu},
  doi          = {10.1016/j.ijar.2024.109127},
  journal      = {International Journal of Approximate Reasoning},
  month        = {3},
  pages        = {109127},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {The interior of inconsistency in a knowledge base},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Moderated revision. <em>IJAR</em>, <em>166</em>, 109126. (<a
href="https://doi.org/10.1016/j.ijar.2024.109126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we provide a new kind of belief revision operator that we call Moderated Revision. At first glance, it is a non-prioritized operator that combines a basic classical AGM operator with a credibility-limited one. The underlying idea is this: when new observation μ is received, it is accepted but with doubts, i.e., uncertainty. We use a revision operator to model the accepted part and a credibility-limited one to represent uncertainty, whenever necessary. In the presence of uncertainty, a selection of the old knowledge balances the result of the revision through a disjunction, allowing the agent to accept part of the new observation and remain unsettled about the rest.},
  archive      = {J_IJAR},
  author       = {Daniel Grimaldi and Maria Vanina Martinez and Ricardo O. Rodriguez},
  doi          = {10.1016/j.ijar.2024.109126},
  journal      = {International Journal of Approximate Reasoning},
  month        = {3},
  pages        = {109126},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Moderated revision},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New results on convergence in distribution of fuzzy random
variables. <em>IJAR</em>, <em>166</em>, 109125. (<a
href="https://doi.org/10.1016/j.ijar.2024.109125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study some properties of convergence in distribution of fuzzy random variables in the metric d p dp , more precisely, if this type of convergence is preserved when we apply some functions between the space of fuzzy sets and other metric spaces. In particular, we show that this convergence is preserved when we take the closed convex hull , the maximum, the minimum, the product and the quotient. Moreover, it is preserved when we apply some functionals, such as the value or the ambiguity. Finally, we show some results regarding convergence in distribution with respect to the metric d ∞ d∞ .},
  archive      = {J_IJAR},
  author       = {Miriam Alonso de la Fuente},
  doi          = {10.1016/j.ijar.2024.109125},
  journal      = {International Journal of Approximate Reasoning},
  month        = {3},
  pages        = {109125},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {New results on convergence in distribution of fuzzy random variables},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RCAviz: Exploratory search in multi-relational datasets
represented using relational concept analysis. <em>IJAR</em>,
<em>166</em>, 109123. (<a
href="https://doi.org/10.1016/j.ijar.2024.109123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conceptual structures built with Formal Concept Analysis (FCA) and its extensions are appropriate constructs for supporting Exploratory Search (ES). FCA indeed classifies a set of objects described by Boolean attributes in a concept lattice which is prone to (intra-lattice) navigation. Relational Concept Analysis (RCA), for its part, classifies several sets of objects connected through multiple binary relationships by using logical operators (quantifiers) which can be approximate. The output is a set of interconnected concept lattices, thus adding inter-lattice navigation opportunities. In this paper, we describe the web platform RCAviz, which aims to support such intra- and inter-lattice navigation. The user can select a subset of objects and attributes as a starting point for navigation. Then RCAviz shows the associated concept and its close intra- and inter-lattice neighbors. The user can access to the objects and attributes introduced and inherited in a concept. They then can navigate, i.e. zoom and pan the current view, and move from one concept to another. Additional views show the previous and the next conceptual structures, as well as an history which allows the user to browse its navigation. A navigation example is shown on a real dataset to illustrate the potential of RCAviz for ES.},
  archive      = {J_IJAR},
  author       = {Marianne Huchard and Pierre Martin and Emile Muller and Pascal Poncelet and Vincent Raveneau and Arnaud Sallaberry},
  doi          = {10.1016/j.ijar.2024.109123},
  journal      = {International Journal of Approximate Reasoning},
  month        = {3},
  pages        = {109123},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {RCAviz: Exploratory search in multi-relational datasets represented using relational concept analysis},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aggregation of random elements over bounded lattices.
<em>IJAR</em>, <em>166</em>, 109122. (<a
href="https://doi.org/10.1016/j.ijar.2024.109122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aggregation functions are widely used to fuse information from different sources in a unique value. In many cases, the aggregated information is related to some experimental measure or random sampling of a population. In this direction, it is reasonable to consider aggregation of random elements. In this paper, the concept of aggregation functions of random elements over bounded lattices , which are measurable functions from a probability space to a bounded lattice, is presented. In particular, starting from a partially ordered set , a measurable space is constructed. Random elements are considered to be measurable functions from a probability space to the measurable space . The concept of aggregation of random elements over bounded lattices is defined by generalizing the monotonicity and the boundary conditions in terms of stochastic orders . Several types, such as the induced, random and degenerated aggregations of random elements over bounded lattices are defined and some coherence properties are studied. Particular examples regarding the aggregation of random variables , random graphs and random semi-positive matrices are provided.},
  archive      = {J_IJAR},
  author       = {Juan Baz and Irene Díaz and Susana Montes},
  doi          = {10.1016/j.ijar.2024.109122},
  journal      = {International Journal of Approximate Reasoning},
  month        = {3},
  pages        = {109122},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Aggregation of random elements over bounded lattices},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computing crisp bisimulations for fuzzy structures.
<em>IJAR</em>, <em>166</em>, 109121. (<a
href="https://doi.org/10.1016/j.ijar.2024.109121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an efficient algorithm for computing the partition corresponding to the greatest crisp bisimulation of a given finite fuzzy labeled graph . Its complexity is of order O ( ( m log ⁡ l + n ) log ⁡ n ) O((mlog⁡l+n)log⁡n) , where n , m and l are the number of vertices, the number of nonzero edges and the number of different fuzzy degrees of edges of the input graph, respectively. We also study a similar problem for the setting with counting successors, which corresponds to the case with qualified number restrictions in description logics and graded modalities in modal logics. In particular, we provide an efficient algorithm with the complexity O ( ( m log ⁡ m + n ) log ⁡ n ) O((mlog⁡m+n)log⁡n) for the considered problem in that setting.},
  archive      = {J_IJAR},
  author       = {Linh Anh Nguyen and Dat Xuan Tran},
  doi          = {10.1016/j.ijar.2024.109121},
  journal      = {International Journal of Approximate Reasoning},
  month        = {3},
  pages        = {109121},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Computing crisp bisimulations for fuzzy structures},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interval r-sheffer strokes and interval fuzzy sheffer
strokes endowed with admissible orders. <em>IJAR</em>, <em>166</em>,
109120. (<a href="https://doi.org/10.1016/j.ijar.2024.109120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy Sheffer stroke is a new class of fuzzy connectives introduced by Baczyński et al., which generalizes the Sheffer stroke operation in classical logic. However, the investigation on interval extensions of fuzzy Sheffer strokes is still missing in the literature. To fill this gap, in this paper, we introduce two interval generalizations of fuzzy Sheffer strokes. Firstly, we propose the notion of interval R -Sheffer strokes based on interval directional monotonicity, studying their properties, characterization, representability and constructions. And then, we introduce the concept of interval fuzzy Sheffer strokes endowed with admissible orders. In particular, we present and compare three construction methods for interval fuzzy Sheffer strokes with respect to ≤ α , β ≤α,β orders.},
  archive      = {J_IJAR},
  author       = {Yifan Zhao and Hua-Wen Liu},
  doi          = {10.1016/j.ijar.2024.109120},
  journal      = {International Journal of Approximate Reasoning},
  month        = {3},
  pages        = {109120},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Interval R-sheffer strokes and interval fuzzy sheffer strokes endowed with admissible orders},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic dominance and statistical preference for random
variables coupled by arbitrary copulas. <em>IJAR</em>, <em>166</em>,
109113. (<a href="https://doi.org/10.1016/j.ijar.2023.109113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, results have been published showing that first order stochastic dominance implies statistical preference and diff-stochastic dominance, when the copula relating the compared variables is either Archimedean , the product copula, or one of the Fréchet-Hoeffding bounds. In the present paper, we rely on known results on multivariate stochastic orders to extend these results and simplify the proofs. The results are expanded in two directions: First, we show that it suffices for the copula to be symmetric. Second, we reveal that first stochastic dominance entails a wider range of stochastic preferences beyond statistical preference and diff-stochastic dominance. We further analyze whether first stochastic dominance implies statistical preference for the case of asymmetric copulas. We observe that, when at least one of the marginal cumulative distribution functions has no discontinuity jumps , the family of asymmetric copulas for which the implication holds is at least as large as the one for which it does not.},
  archive      = {J_IJAR},
  author       = {Inés Couso and Luciano Sánchez},
  doi          = {10.1016/j.ijar.2023.109113},
  journal      = {International Journal of Approximate Reasoning},
  month        = {3},
  pages        = {109113},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Stochastic dominance and statistical preference for random variables coupled by arbitrary copulas},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastically ordered aggregation operators. <em>IJAR</em>,
<em>166</em>, 109110. (<a
href="https://doi.org/10.1016/j.ijar.2023.109110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In aggregation theory, there exists a large number of aggregation functions that are defined in terms of rearrangements in increasing order of the arguments. Prominent examples are the Ordered Weighted Operator and the Choquet and Sugeno integrals . Following a probability approach, ordering random variables by means of stochastic orders can be also a way to define aggregations of random variables. However, stochastic orders are not total orders, thus pairs of incomparable distributions can appear. This paper is focused on the definition of aggregations of random variables that take into account the stochastic ordination of the components of the input random vectors. Three alternatives are presented, the first one by using expected values and admissible permutations , then a modification for multivariate Gaussian random vectors and a third one that involves a transformation of the initial random vectors in new ones whose components are ordered with respect to the usual stochastic order. A deep theoretical study of the properties of all the proposals is made. A practical example regarding temperature prediction is provided},
  archive      = {J_IJAR},
  author       = {Juan Baz and Franco Pellerey and Irene Díaz and Susana Montes},
  doi          = {10.1016/j.ijar.2023.109110},
  journal      = {International Journal of Approximate Reasoning},
  month        = {3},
  pages        = {109110},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Stochastically ordered aggregation operators},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Some notes on possibilistic randomisation with t-norm based
joint distributions in strategic-form games. <em>IJAR</em>,
<em>166</em>, 109109. (<a
href="https://doi.org/10.1016/j.ijar.2023.109109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article continues the investigation started in [18] on the role of possibilistic mixed strategies in strategic-form games. In this earlier work we assumed, as standard in possibility theory, that joint possibility distributions were computed by combining possibilistic mixed strategies with the minimum t-norm. In this paper, we investigate the consequences of defining joint possibility distributions by using any continuous t-norm, with players&#39; expected utilities based on the Choquet integral . We characterise under which conditions a pair of possibilistic mixed strategies is an equilibrium, generalising the results first presented in [18] , and also show that the set of equilibria in possibilistic mixed strategies depends on the set of idempotent elements of a t-norm and not just on the chosen t-norm.},
  archive      = {J_IJAR},
  author       = {Esther Anna Corsi and Hykel Hosni and Enrico Marchioni},
  doi          = {10.1016/j.ijar.2023.109109},
  journal      = {International Journal of Approximate Reasoning},
  month        = {3},
  pages        = {109109},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Some notes on possibilistic randomisation with t-norm based joint distributions in strategic-form games},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relevance, recovery and recuperation: A prelude to ring
withdrawal. <em>IJAR</em>, <em>166</em>, 109108. (<a
href="https://doi.org/10.1016/j.ijar.2023.109108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce recuperative withdrawals , belief change operators that satisfy recuperation, a postulate weaker than recovery, all the AGM postulates for contraction except recovery and another postulate which is a slightly stronger condition than conjunctive inclusion. Furthermore, we present a constructive definition for a class of operators —named ring withdrawals — which are such that the outcome of a ring withdrawal of a belief set K by a sentence α is obtained by adding to the set of most plausible models ‖ K ‖ ‖K‖ all the worlds which are as close to ‖ K ‖ ‖K‖ as its closest ¬ α -worlds. Ring withdrawals satisfy the Lindström and Rabinowicz&#39;s interpolation thesis. We show that the classes of recuperative withdrawals and of ring withdrawals are identical. Additionally we show that the class of ring withdrawals is not contained in and does not contain the class of AGM contractions or the class of severe withdrawals. Finally we present methods for defining an operator of ring withdrawal by means of a severe withdrawal operator and by means of an AGM contraction operator, and vice-versa.},
  archive      = {J_IJAR},
  author       = {Eduardo Fermé and Marco Garapa and Abhaya Nayak and Maurício D.L. Reis},
  doi          = {10.1016/j.ijar.2023.109108},
  journal      = {International Journal of Approximate Reasoning},
  month        = {3},
  pages        = {109108},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Relevance, recovery and recuperation: A prelude to ring withdrawal},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Some thoughts about transfer learning. What role for the
source domain? <em>IJAR</em>, <em>166</em>, 109107. (<a
href="https://doi.org/10.1016/j.ijar.2023.109107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning is called for when the training and test data do not share the same input distributions ( P X S ≠ P X T PXS≠PXT ) or/and not the same conditional ones ( P Y | X S ≠ P Y | X T PY|XS≠PY|XT ). In the most general case, the input spaces and/or output spaces can be different: X S ≠ X T XS≠XT and/or Y S ≠ Y T YS≠YT . However, most work assume that X S = X T XS=XT . Furthermore, a common held assumption is that it is necessary that the source hypothesis be good on the source training data and that the “distance” between the source and the target domains be as small as possible in order to get a good (transferred) target hypothesis. This paper revisits the reasons for these beliefs and discusses the relevance of these conditions. An algorithm is presented which can deal with transfer learning problems where X S ≠ X T XS≠XT , and that furthermore brings a fresh perspective on the role of the source hypothesis (it does not have to be good) and on what is important in the distance between the source and the target domains (translations between them should belong to a limited set). Experiments illustrate the properties of the method and confirm the theoretical analysis. Determining beforehand a relevant source hypothesis remains an open problem, but the vista provided here helps understanding its role.},
  archive      = {J_IJAR},
  author       = {A. Cornuéjols},
  doi          = {10.1016/j.ijar.2023.109107},
  journal      = {International Journal of Approximate Reasoning},
  month        = {3},
  pages        = {109107},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Some thoughts about transfer learning. what role for the source domain?},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A three-way decision approach for dynamically expandable
networks. <em>IJAR</em>, <em>166</em>, 109105. (<a
href="https://doi.org/10.1016/j.ijar.2023.109105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional deep learning models are designed to work on a single task. They are required to be trained from scratch each time new tasks are added. This leads to overhead in training time. Continual deep learning models with dynamically expandable network architecture aim to handle this issue. The key idea in these models is to find a balance between the properties of stability (preserving the learned information) and plasticity (updating and accommodating the new information) also sometimes referred to as the stability-plasticity dilemma. The stability and plasticity of the model critically depends on three-way division of nodes into freeze, partially regularize and duplicate nodes. Freezing more nodes result in high stability but typically low plasticity. On the other hand, duplicating more nodes result in high plasticity but may not have an effective stability. In this paper, we introduce an approach called three-way decisions based dynamically expandable networks or 3WDDEN and its memory-based version called 3WDDEN-replay. The proposed approaches use game-theoretic rough sets to determine effective thresholds for three-way division of nodes by considering a tradeoff game between stability and plasticity. Experimental results of 3WDDEN on MNIST variant datasets show an overall improvement of 3.8% in accuracy compared to standard dynamically expandable network approach or DEN. 3WDDEN-replay further adds to accuracy with additional memory cost.},
  archive      = {J_IJAR},
  author       = {Usman Wajid and Muhammad Hamza and Muhammad Taimoor Khan and Nouman Azam},
  doi          = {10.1016/j.ijar.2023.109105},
  journal      = {International Journal of Approximate Reasoning},
  month        = {3},
  pages        = {109105},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A three-way decision approach for dynamically expandable networks},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatial unity for the apperception engine. <em>IJAR</em>,
<em>165</em>, 109106. (<a
href="https://doi.org/10.1016/j.ijar.2023.109106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a logical approach for computational agents to spatially explore their environment, extending on the Kant-inspired logical unification methods of the Apperception Engine . Evaluating models of the Regional Connection Calculus as Alexandroff Topologies, we axiomatise connectedness and unity of space. We further define dimensionality for tolerance spaces and prove that locally verifiable properties guarantee global consistency of space as the existence of isomorphisms to grids, turbands or tori. Finally, we provide a generally competent and explainable computational agent that unifies intuition in space, the Spatial Apperception Engine .},
  archive      = {J_IJAR},
  author       = {Arie Soeteman and Michiel van Lambalgen},
  doi          = {10.1016/j.ijar.2023.109106},
  journal      = {International Journal of Approximate Reasoning},
  month        = {2},
  pages        = {109106},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Spatial unity for the apperception engine},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph representation learning method based on three-way
partial order structure. <em>IJAR</em>, <em>165</em>, 109104. (<a
href="https://doi.org/10.1016/j.ijar.2023.109104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data , handling massive datasets to extract valuable information has become increasingly critical. Knowledge representation emerges as a pivotal method to address this challenge. In the domain of knowledge representation, there exist two primary approaches: symbolic representation and vector representation . The integration of symbolic and vector representations to harness their respective strengths has become the cutting-edge approach to address challenges in the field of knowledge representation. This paper proposes a method that integrates a partial order formal structure analysis (POFSA) with graph representation learning . Specifically, we initially construct three-way partial order structure graphs, then create an attribute graph based on this structure, which can be processed by the graph representation learning methods. Finally, we utilize the graph representation learning to construct embeddings for three-way attribute partial order structure diagram (APOSD). We comprehensively assesse these embeddings across eight different datasets and present the results. The experiments indicate the feasibility of our proposed approach which is proven a novel approach of combining symbolic and vector representations for handling complex data and implicit knowledge.},
  archive      = {J_IJAR},
  author       = {Enliang Yan and Shikuan Hao and Tao Zhang and Tianyong Hao and Qiliang Chen and Jianping Yu},
  doi          = {10.1016/j.ijar.2023.109104},
  journal      = {International Journal of Approximate Reasoning},
  month        = {2},
  pages        = {109104},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Graph representation learning method based on three-way partial order structure},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Medical decision support in the light of interactive
granular computing: Lessons from the ovufriend project. <em>IJAR</em>,
<em>165</em>, 109103. (<a
href="https://doi.org/10.1016/j.ijar.2023.109103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main aim of the paper is to discuss the architecture for the future Intelligent Systems (IS&#39;s) and Decision Support Systems (DS&#39;s) dealing with complex phenomena such as supporting medical decisions (diagnosis and therapy) and to emphasize challenges in designing such systems. More precisely, the paper presents arguments for developing a specialized computing model based on the interactive granular computing paradigm which can help to design IS&#39;s and DS&#39;s more close to the prototypes of real life decision making. In this regard, the paper brings to the fore different experiences faced during designing other medical IS&#39;s or DS&#39;s.As a starting step, the paper considers the experience of developing the OvuFriend platform and outlines some possible extension of it in the framework of the proposed architecture on the basis of Interactive Granular Computing (IGrC) model. Specifically, our attempt is to analyze a scheme, which is being used in the platform of OvuFriend for determining health risks and possibilities of a woman to conceive a child, from the perspective of IGrC. The target of the paper is two fold. Firstly, to show how the underlying AI algorithm of this scheme can be related with the notion of computing in the context of IGrC. Secondly, to identify possible extensions of the existing scheme so that it becomes more dynamic, interactive, and close to personalized medicine.},
  archive      = {J_IJAR},
  author       = {Soma Dutta and Andrzej Skowron and Łukasz Sosnowski},
  doi          = {10.1016/j.ijar.2023.109103},
  journal      = {International Journal of Approximate Reasoning},
  month        = {2},
  pages        = {109103},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Medical decision support in the light of interactive granular computing: Lessons from the ovufriend project},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy rough unlearning model for feature selection.
<em>IJAR</em>, <em>165</em>, 109102. (<a
href="https://doi.org/10.1016/j.ijar.2023.109102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In big data era, some data, becoming meaningless or illegal over time and space, need to be deleted from historical knowledge. It is a challenging problem, called machine unlearning, to efficiently forget the information of those outdated data from historical models. Some unlearning techniques have been proposed in loss-well-defined classification models , such as SVM , Random Forest , and Federated learning model. Yet, it is under study to remove outdated data from learned feature selection in fuzzy rough philosophy. To narrow this gap, we propose a fuzzy rough unlearning model for feature selection. Specifically, the outdated information is first identified in a compact set , called unlearning set, that remarkably shrinks the search space of feature selection. Then, the unlearning mechanisms containing two main theorems are proposed by leveraging unlearning set, followed by a feature selection unlearning algorithm. Theoretical analyses verify that the proposed unlearning algorithm is equivalent to the traditional algorithm retraining on the remaining data with the beginning of historical results. Experimentally, extensive results on 20 datasets demonstrate that our proposed unlearning methods perform effectively with remarkably less time cost. For the source code of ARU , please refer to: https://github.com/yuxin370/ARU .},
  archive      = {J_IJAR},
  author       = {Yuxin Tang and Suyun Zhao and Hong Chen and Cuiping Li and Junhai Zhai and Qiangjun Zhou},
  doi          = {10.1016/j.ijar.2023.109102},
  journal      = {International Journal of Approximate Reasoning},
  month        = {2},
  pages        = {109102},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Fuzzy rough unlearning model for feature selection},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An answer set programming-based implementation of epistemic
probabilistic event calculus. <em>IJAR</em>, <em>165</em>, 109101. (<a
href="https://doi.org/10.1016/j.ijar.2023.109101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe a general procedure for translating Epistemic Probabilistic Event Calculus (EPEC) action language domains into Answer Set Programs (ASP), and show how the Python-driven features of the ASP solver Clingo can be used to provide efficient computation in this probabilistic setting. EPEC supports probabilistic, epistemic reasoning in domains containing narratives that include both an agent&#39;s own action executions and environmentally triggered events. Some of the agent&#39;s actions may be belief-conditioned, and some may be imperfect sensing actions that alter the strengths of previously held beliefs. We show that our ASP implementation can be used to provide query answers that fully correspond to EPEC&#39;s own declarative, Bayesian-inspired semantics.},
  archive      = {J_IJAR},
  author       = {Fabio Aurelio D&#39;Asaro and Antonis Bikakis and Luke Dickens and Rob Miller},
  doi          = {10.1016/j.ijar.2023.109101},
  journal      = {International Journal of Approximate Reasoning},
  month        = {2},
  pages        = {109101},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {An answer set programming-based implementation of epistemic probabilistic event calculus},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Confidence assessment in safety argument structure -
quantitative vs. Qualitative approaches. <em>IJAR</em>, <em>165</em>,
109100. (<a href="https://doi.org/10.1016/j.ijar.2023.109100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some safety standards (e.g., ISO 26262 in automotive industry) propose the use of argument structures to justify that the high-level safety properties of a system have been ensured. The goal structuring notation (GSN) is a graphical tool used to represent these argument structures. However, this approach does not address the uncertainties that may affect the validity of the arguments. Thus, some authors proposed to complement GSN patterns with a quantitative confidence assessment procedure. In this paper, we first present a refined procedure that expresses the relation between premises (pieces of evidence) and the conclusion (top-goal to be demonstrated) using logical expressions. Then using Dempster-Shafer theory, we quantify uncertainty on each expression to build an explicit mathematical formula for propagating uncertainty to the conclusion. Inputs for the propagation model are collected from experts and transformed into numerical values using an improved elicitation model. Afterwards, we introduce a purely qualitative alternative to the quantitative procedure based on the theory of qualitative capacities. Finally, we adapt the propagation and elicitation models to this framework.},
  archive      = {J_IJAR},
  author       = {Yassir Idmessaoud and Didier Dubois and Jérémie Guiochet},
  doi          = {10.1016/j.ijar.2023.109100},
  journal      = {International Journal of Approximate Reasoning},
  month        = {2},
  pages        = {109100},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Confidence assessment in safety argument structure - Quantitative vs. qualitative approaches},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nature of decision valuations in elimination of redundant
attributes. <em>IJAR</em>, <em>165</em>, 109091. (<a
href="https://doi.org/10.1016/j.ijar.2023.109091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information systems are the basic building blocks of the theory of rough sets which, based on information signatures of objects, develops strategies for classifying concepts and/or deriving significant information about decision attributes . During such processes of aggregating decision information, one needs to focus on the aspects of designing its representation and considering various ways for reducing attributes. We introduce a general mathematical apparatus of decision valuations that are aimed at representing information derivable from data. We establish a strong connection between the notion of attribute reduction considered in the context of decision valuations and the analogous notions developed in relational databases , semigraphoid models of conditional independence statements, etc. Based on different decision making strategies, we discuss different properties of decision valuations and explore different examples in the light of those properties. We also investigate interrelationships among those properties. Going back to attribute reduction, i.e. elimination of redundant attributes, we consider the prevalent property of discernibility and compare it with the properties of semigraphoid models, such as weak union and decomposition.},
  archive      = {J_IJAR},
  author       = {Soma Dutta and Dominik Ślęzak},
  doi          = {10.1016/j.ijar.2023.109091},
  journal      = {International Journal of Approximate Reasoning},
  month        = {2},
  pages        = {109091},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Nature of decision valuations in elimination of redundant attributes},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical variable clustering via copula-based divergence
measures between random vectors. <em>IJAR</em>, <em>165</em>, 109090.
(<a href="https://doi.org/10.1016/j.ijar.2023.109090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers rank-invariant clustering of continuous data via copula-based Φ-dependence measures. The general theoretical framework establishes dependence quantification between random vectors (groups of variables), which is used for measuring the similarity between variable clusters in an agglomerative hierarchical procedure afterwards. Special attention is devoted to meta-elliptical copulas, where we present an improved kernel estimator for the density generator and a corresponding bandwidth selector. This allows for non-Gaussian similarities also capturing e.g. tail dependence. Further, a fully non-parametric estimator is considered, enabling cluster detection in contexts where other measures fail. The theory is supported by simulations and a real data example, focusing on cluster analysis of continuous variables.},
  archive      = {J_IJAR},
  author       = {Steven De Keyser and Irène Gijbels},
  doi          = {10.1016/j.ijar.2023.109090},
  journal      = {International Journal of Approximate Reasoning},
  month        = {2},
  pages        = {109090},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Hierarchical variable clustering via copula-based divergence measures between random vectors},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Coherence and avoidance of sure loss for standardized
functions and semicopulas. <em>IJAR</em>, <em>165</em>, 109089. (<a
href="https://doi.org/10.1016/j.ijar.2023.109089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss avoidance of sure loss and coherence results for semicopulas and standardized functions, i.e., for grounded, 1-increasing functions with value 1 at ( 1 , 1 , … , 1 ) (1,1,…,1) . We characterize the existence of a k -increasing n -variate function C fulfilling A ⩽ C ⩽ B A⩽C⩽B for standardized n -variate functions A , B A,B and discuss methods for constructing such functions. Our proofs also include procedures for extending functions on some countably infinite mesh to functions on the unit box. We provide a characterization when A respectively B coincides with the pointwise infimum respectively supremum of the set of all k -increasing n -variate functions C fulfilling A ⩽ C ⩽ B A⩽C⩽B .},
  archive      = {J_IJAR},
  author       = {Erich Peter Klement and Damjana Kokol Bukovšek and Blaž Mojškerc and Matjaž Omladič and Susanne Saminger-Platz and Nik Stopar},
  doi          = {10.1016/j.ijar.2023.109089},
  journal      = {International Journal of Approximate Reasoning},
  month        = {2},
  pages        = {109089},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Coherence and avoidance of sure loss for standardized functions and semicopulas},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A probabilistic analysis of selected notions of iterated
conditioning under coherence. <em>IJAR</em>, <em>165</em>, 109088. (<a
href="https://doi.org/10.1016/j.ijar.2023.109088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that basic conditionals satisfy some desirable basic logical and probabilistic properties, such as the compound probability theorem. However checking the validity of these becomes trickier when we switch to compound and iterated conditionals. Herein we consider de Finetti&#39;s notion of conditional both in terms of a three-valued object and as a conditional random quantity in the betting framework. We begin by recalling the notions of conjunction and disjunction among conditionals in selected trivalent logics. Then we analyze the notions of iterated conditioning in the frameworks of the specific three-valued logics introduced by Cooper-Calabrese, by de Finetti, and by Farrel. By computing some probability propagation rules we show that the compound probability theorem and other important properties are not always preserved by these formulations. Then, for each trivalent logic we introduce an iterated conditional as a suitable random quantity which satisfies the compound prevision theorem as well as some other desirable properties . We also check the validity of two generalized versions of Bayes&#39; Rule for iterated conditionals. We study the p-validity of generalized versions of Modus Ponens and two-premise centering for iterated conditionals. Finally, we observe that all the basic properties are satisfied within the framework of iterated conditioning followed in recent papers by Gilio and Sanfilippo in the setting of conditional random quantities.},
  archive      = {J_IJAR},
  author       = {Lydia Castronovo and Giuseppe Sanfilippo},
  doi          = {10.1016/j.ijar.2023.109088},
  journal      = {International Journal of Approximate Reasoning},
  month        = {2},
  pages        = {109088},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A probabilistic analysis of selected notions of iterated conditioning under coherence},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploiting fuzzy rough entropy to detect anomalies.
<em>IJAR</em>, <em>165</em>, 109087. (<a
href="https://doi.org/10.1016/j.ijar.2023.109087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection has been used in a wide range of fields. However, most of the current detection methods are only applicable to certain data, ignoring uncertain information such as fuzziness in the data. Fuzzy rough set theory , as an essential mathematical model for granular computing , provides an effective method for processing uncertain data such as fuzziness. Fuzzy rough entropy has been proposed in fuzzy rough set theory and has been employed successfully in data analysis tasks such as feature selection. However, it mainly uses the intersection operation, which may not effectively reflect the similarity between high-dimensional objects. In response to the two challenges mentioned above, distance-based fuzzy rough entropy and its correlation measures are proposed. Further, the proposed fuzzy rough entropy is used to construct the anomaly detection model and the Fuzzy Rough Entropy-based Anomaly Detection (FREAD) algorithm is designed. Finally, the FREAD algorithm is compared and analyzed with some mainstream anomaly detection algorithms (including COF, DIS, INFLO, LDOF, LoOP , MIX, ODIN , SRO, and VarE algorithms) on some publicly available datasets. Experimental results indicate that the FREAD algorithm significantly outperforms other algorithms in terms of performance and flexibility. The code is publicly available online at https://github.com/optimusprimeyy/FREAD .},
  archive      = {J_IJAR},
  author       = {Sihan Wang and Zhong Yuan and Chuan Luo and Hongmei Chen and Dezhong Peng},
  doi          = {10.1016/j.ijar.2023.109087},
  journal      = {International Journal of Approximate Reasoning},
  month        = {2},
  pages        = {109087},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Exploiting fuzzy rough entropy to detect anomalies},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data complexity: An FCA-based approach. <em>IJAR</em>,
<em>165</em>, 109084. (<a
href="https://doi.org/10.1016/j.ijar.2023.109084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose different indices for measuring the complexity of a dataset in terms of Formal Concept Analysis (FCA). We extend the lines of the research about the “closure structure” and the “closure index” based on minimum generators of intents (aka closed itemsets). We would try to capture statistical properties of a dataset, not just extremal characteristics, such as the size of a passkey. For doing so we introduce an alternative approach where we measure the complexity of a dataset w.r.t. five significant elements that can be computed in a concept lattice , namely intents (closed sets of attributes), pseudo-intents, proper premises, keys (minimal generators), and passkeys (minimum generators). Then we define several original indices allowing us to estimate the complexity of a dataset. Moreover we study the distribution of all these different elements and indices in various real-world and synthetic datasets . Finally, we investigate the relations existing between these significant elements and indices, and as well the relations with implications and association rules .},
  archive      = {J_IJAR},
  author       = {Alexey Buzmakov and Egor Dudyrev and Sergei O. Kuznetsov and Tatiana Makhalova and Amedeo Napoli},
  doi          = {10.1016/j.ijar.2023.109084},
  journal      = {International Journal of Approximate Reasoning},
  month        = {2},
  pages        = {109084},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Data complexity: An FCA-based approach},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Outlier detection for partially labeled categorical data
based on conditional information entropy. <em>IJAR</em>, <em>164</em>,
109086. (<a href="https://doi.org/10.1016/j.ijar.2023.109086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Labeling a large amount of data is exceptionally costly and practically infeasible, and thus available data may have missing labels. In this article, we investigate outlier detection for partially labeled categorical data based on conditional information entropy. Firstly, the equivalence class in a partially labeled categorical decision information system (p-CDIS) is introduced, so that the missing labels can be predicted by use of conditional probability . Then, conditional information entropy in a p-CDIS is calculated, which provides a more comprehensive measure of uncertainty. Additionally, the relative information entropy and relative cardinality in a p-CDIS are proposed. Next, the degree of outlierness and the weight function are presented to find outlier factors. Finally, an outlier detection method in a p-CDIS based on conditional information entropy is proposed, and a corresponding conditional information entropy algorithm (CEOF) is designed. To evaluate the stability of the CEOF algorithm, experiments are performed on ten UCI Machine Learning Repository datasets. Compared with five other algorithms, the proposed method is shown to have good effectiveness and adaptability for categorical data .},
  archive      = {J_IJAR},
  author       = {Zhengwei Zhao and Rongrong Wang and Dan Huang and Zhaowen Li},
  doi          = {10.1016/j.ijar.2023.109086},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109086},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Outlier detection for partially labeled categorical data based on conditional information entropy},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A direct approach to representing algebraic domains by
formal contexts. <em>IJAR</em>, <em>164</em>, 109085. (<a
href="https://doi.org/10.1016/j.ijar.2023.109085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is to establish closer links between domain theory and Formal Concept Analysis (FCA). We propose the notion of an optimised concept for a formal context, which has some properties similar to an intent. With the tool of optimised concepts, we show that the class of formal contexts has directly corresponded with algebraic domains. Meanwhile, two subclasses of formal contexts are identified to characterize algebraic L-domains and Scott domains. As an application, we resolve the open problem of how to reconstruct bounded complete continuous domains in the languages of attribute continuous contexts. Finally, we extend our presentation of algebraic domains to a categorical equivalence.},
  archive      = {J_IJAR},
  author       = {Xiangnan Zhou and Longchun Wang and Qingguo Li},
  doi          = {10.1016/j.ijar.2023.109085},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109085},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A direct approach to representing algebraic domains by formal contexts},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient method of renewing object-induced three-way
concept lattices involving decreasing attribute-granularity levels.
<em>IJAR</em>, <em>164</em>, 109083. (<a
href="https://doi.org/10.1016/j.ijar.2023.109083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In three-way concept analysis, changing (decreasing or increasing) attribute-granularity levels is needed to seek desirable information. Reconstructing three-way concept lattices often requires huge computation and long elapsed time when attribute-granularity levels are changed. To avoid this problem, a good strategy is indirectly renewing three-way concept lattices . Our paper studies how to renew object-induced three-way concept lattices involving decreasing attribute-granularity levels. Firstly, we analyze changes of object-induced three-way concept lattices when attribute-granularity levels are decreased. To classify changes of object-induced three-way concepts, we classify these concepts into six categories, derive sufficient and necessary conditions of identifying these categories, and investigate their properties. To explore changes of covering relations among object-induced three-way concepts, we classify covering relations into three categories, and identify them by finding which are the destructors of deleted object-induced three-way concepts before the decrease, and analyzing which are children concepts of object-induced three-way concepts as destructors after the decrease. Secondly, by using the above analysis results, we put forward a novel algorithm called OEL-Collapse to renew object-induced three-way concept lattices when attribute-granularity levels are decreased. Finally, experiments are conducted to illustrate the efficiency of the OEL-Collapse algorithm.},
  archive      = {J_IJAR},
  author       = {Junping Xie and Jing Yang and Jinhai Li and Debby D. Wang},
  doi          = {10.1016/j.ijar.2023.109083},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109083},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {An efficient method of renewing object-induced three-way concept lattices involving decreasing attribute-granularity levels},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Some general fusion and transformation frames for merging
basic uncertain information. <em>IJAR</em>, <em>164</em>, 109082. (<a
href="https://doi.org/10.1016/j.ijar.2023.109082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Basic Uncertain Information (BUI) is a recently introduced type of uncertain data that has rapidly undergone development and practical application. The existing aggregation operators designed for BUI solely encompass the weighted mean and Choquet integral . The present study puts forth a set of general information fusion frameworks and methodologies aimed at gathering BUI granules. The first mode yields BUI granules as its output, whereas the subsequent two modes generate outputs in the form of interval values. The paper includes numerical examples and applications that correspond to the presented findings. The present study conducts an analysis of various mathematical properties pertaining to the three BUI fusion modes that have been proposed. These properties include idempotency, monotonicities, certainty derived inclusion, certainty monotonicity, homogeneities, non-symmetricity, comonotone additivities, and continuities. The proposals and analyses presented in this work are of a general nature and have the potential to inspire various practical specifications.},
  archive      = {J_IJAR},
  author       = {LeSheng Jin and Ronald R. Yager and Radko Mesiar and Zhen-Song Chen},
  doi          = {10.1016/j.ijar.2023.109082},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109082},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Some general fusion and transformation frames for merging basic uncertain information},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel information fusion method using improved entropy
measure in multi-source incomplete interval-valued datasets.
<em>IJAR</em>, <em>164</em>, 109081. (<a
href="https://doi.org/10.1016/j.ijar.2023.109081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-source data is a comprehensive data type that combines multiple sources of information or datasets. Compared to point-valued data, interval-valued data provides a more accurate representation of the uncertainty and variability associated with objects. In practical situations, data obtained from multiple sources may contain missing values for various reasons. Therefore, it is essential to develop multi-source information fusion technology in order to achieve information fusion or information extraction from multi-source incomplete data. This paper aims to explore the information fusion problem of multi-source incomplete interval-valued datasets. The primary contributions of this study involve utilizing the principle of statistical distribution and KL divergence to establish a metric for measuring the similarity between intervals. Firstly, this approach helps to reduce the problem of disregarding internal information within interval values, which can result in the loss of valuable information. Secondly, we establish an interval fuzzy similarity relation based on the mentioned concept of similarity among interval values. Moreover, we investigate the uncertainty measurement of incomplete interval-valued decision datasets and design an emerging information entropy fusion method. Finally, we comprehensively evaluate the effectiveness of the proposed method. Experimental results indicate that the proposed approach has advantage over the maximum, minimum, mean, and information entropy fusion method based on tolerance relationship. In addition, the distance metric used in this article can improve the fusion classification effect compared to several common interval-valued distance measures .},
  archive      = {J_IJAR},
  author       = {Weihua Xu and Ke Cai and Debby D. Wang},
  doi          = {10.1016/j.ijar.2023.109081},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109081},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A novel information fusion method using improved entropy measure in multi-source incomplete interval-valued datasets},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Three-way decisions with evaluative linguistic expressions.
<em>IJAR</em>, <em>164</em>, 109080. (<a
href="https://doi.org/10.1016/j.ijar.2023.109080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of three-way decisions (3WD) requires dividing a finite, non-empty universe into three disjoint sets called positive, negative, and boundary regions. Three types of decisions are then made on the objects in each region: acceptance, rejection, and abstention (or non-commitment), respectively. Until today, a large number of 3WD extensions and applications have been proposed; some of the most recent ones also include aspects of linguistics. In this article, we first propose an innovative linguistic interpretation of three-way decisions, where the positive, negative, and boundary regions are constructed by means of the so-called evaluative linguistic expressions . These are expressions of natural language, such as small, medium, very short, quite roughly strong, extremely good, etc., and they are described within a logical theory based on the formal system of higher-order fuzzy logic. Furthermore, in line with our linguistic 3WD approach, we introduce the novel notion of linguistic rough sets, thus contributing to the development of Rough Set Theory . Finally, we connect the theory of linguistic three-way decisions with the standard 3WD model based on probabilistic rough sets, establishing conditions under which the two approaches coincide. Our results highlight connections between two different research areas: three-way decisions and the theory of evaluative linguistic expressions .},
  archive      = {J_IJAR},
  author       = {Stefania Boffa and Davide Ciucci},
  doi          = {10.1016/j.ijar.2023.109080},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109080},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Three-way decisions with evaluative linguistic expressions},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Special issue on concept lattices and their applications
(CLA 2020). <em>IJAR</em>, <em>164</em>, 109079. (<a
href="https://doi.org/10.1016/j.ijar.2023.109079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {...},
  archive      = {J_IJAR},
  author       = {Francisco José Valverde-Albacete and Martin Trnecka and Sadok Ben Yahia},
  doi          = {10.1016/j.ijar.2023.109079},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109079},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Special issue on concept lattices and their applications (CLA 2020)},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Changing behaviour under unfairness: An evolutionary model
of the ultimatum game. <em>IJAR</em>, <em>164</em>, 109078. (<a
href="https://doi.org/10.1016/j.ijar.2023.109078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experimental results on the Ultimatum Game indicate that receivers may reject non-zero offers, even though that seems irrational. The explanation is that, when players are treated unfairly, they can act against strict rationality. This paper discusses an evolutionary model of the Ultimatum Game describing how populations of players change their behaviour in time. We prove an analytical result that establishes under what conditions receivers tend to reject unfair offers. The response to unfair offers is also shown to be sensitive to different degrees of unfairness. We then introduce a Bayesian game to translate our result from populations to individual players.},
  archive      = {J_IJAR},
  author       = {Arioli Gianni and Lucchetti Roberto and Valente Giovanni},
  doi          = {10.1016/j.ijar.2023.109078},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109078},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Changing behaviour under unfairness: An evolutionary model of the ultimatum game},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GFDC: A granule fusion density-based clustering with
evidential reasoning. <em>IJAR</em>, <em>164</em>, 109075. (<a
href="https://doi.org/10.1016/j.ijar.2023.109075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density-based clustering algorithms are known for their ability to detect irregular clusters, but they have limitations when it comes to dealing with clusters of varying densities. In this paper, we propose a new clustering algorithm called granule fusion density-based clustering with evidential reasoning (GFDC). The approach introduces the concept of sparse degree, which measures both the local density and global density of samples. The sparse degree of samples reflects the stability of samples. Moreover, a core-granule is composed of the neighborhood granule of a sample, of which the sparse degree is minimum in its neighborhood. Then, the core-granules are generated based on the sparse degree and are insensitive to clusters with varying densities. The core samples, which consist of samples in core-granules, are used to form initial clusters through fusion strategies. Additionally, an assignment method is developed from Dempster-Shafer theory to assign border samples and identify outliers. The experimental results demonstrate the effectiveness of GFDC on extensive synthetic and real-world datasets.},
  archive      = {J_IJAR},
  author       = {Mingjie Cai and Zhishan Wu and Qingguo Li and Feng Xu and Jie Zhou},
  doi          = {10.1016/j.ijar.2023.109075},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109075},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {GFDC: A granule fusion density-based clustering with evidential reasoning},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improvements proposed to noisy-OR derivatives for
multi-causal analysis: A case study of simultaneous electromagnetic
disturbances. <em>IJAR</em>, <em>164</em>, 109068. (<a
href="https://doi.org/10.1016/j.ijar.2023.109068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-causal analysis, the independence of causal influence (ICI) assumed by the noisy-OR (NOR) model can be used to predict the probability of the effect when several causes are present simultaneously, and to identify (when it fails) inter-causal dependence (ICD) between them. The latter is possible only if the probability of observing the multi-causal effect is available for comparison with a corresponding NOR estimate. Using electromagnetic interference in an integrated circuit as a case study , the data corresponding to the probabilities of observing failures (effect) due to the injection of individual (single cause) and simultaneous electromagnetic disturbances having different frequencies (multiple causes) were collected. This data is initially used to evaluate the NOR model and its existing derivatives, which have been proposed to reduce the error in predictions for higher-order multi-causal interactions that make use of the available information on lower-order interactions. Then, to address the identified limitations of the NOR and its existing derivatives, a new deterministic model called Super-NOR is proposed, which is based on correction factors estimated from the available ICD information.},
  archive      = {J_IJAR},
  author       = {Lokesh Devaraj and Qazi Mashaal Khan and Alastair R. Ruddle and Alistair P. Duffy and Richard Perdriau and Mohsen Koohestani},
  doi          = {10.1016/j.ijar.2023.109068},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109068},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Improvements proposed to noisy-OR derivatives for multi-causal analysis: A case study of simultaneous electromagnetic disturbances},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Polyadic relational concept analysis. <em>IJAR</em>,
<em>164</em>, 109067. (<a
href="https://doi.org/10.1016/j.ijar.2023.109067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal concept analysis is a mathematical framework based on lattice theory that aims at representing the information contained in binary object-attribute datasets (called formal contexts) in the form of a lattice of so-called formal concepts. Since its introduction, it has been extended to more complex types of data. In this paper, we are interested in two of those extensions: relational concept analysis and polyadic concept analysis that allow to process, respectively, relational data and n -ary relations. We present a framework for polyadic relational concept analysis that extends relational concept analysis to relational datasets that are made of n -ary relations. We show its basic properties and that it is a valid extension of relational concept analysis.},
  archive      = {J_IJAR},
  author       = {Bazin Alexandre and Galasso Jessie and Kahn Giacomo},
  doi          = {10.1016/j.ijar.2023.109067},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109067},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Polyadic relational concept analysis},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Change in quantitative bipolar argumentation: Sufficient,
necessary, and counterfactual explanations. <em>IJAR</em>, <em>164</em>,
109066. (<a href="https://doi.org/10.1016/j.ijar.2023.109066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a formal approach to explaining change of inference in Quantitative Bipolar Argumentation Frameworks (QBAFs). When drawing conclusions from a QBAF and updating the QBAF to then again draw conclusions (and so on), our approach traces changes – which we call strength inconsistencies – in the partial order over argument strengths that a semantics establishes on some arguments of interest, called topic arguments . We trace the causes of strength inconsistencies to specific arguments, which then serve as explanations. We identify sufficient, necessary, and counterfactual explanations for strength inconsistencies and show that strength inconsistency explanations exist if and only if an update leads to strength inconsistency. We define a heuristic-based approach to facilitate the search for strength inconsistency explanations, for which we also provide an implementation.},
  archive      = {J_IJAR},
  author       = {Timotheus Kampik and Kristijonas Čyras and José Ruiz Alarcón},
  doi          = {10.1016/j.ijar.2023.109066},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109066},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Change in quantitative bipolar argumentation: Sufficient, necessary, and counterfactual explanations},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A preferential interpretation of MultiLayer perceptrons in a
conditional logic with typicality. <em>IJAR</em>, <em>164</em>, 109065.
(<a href="https://doi.org/10.1016/j.ijar.2023.109065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we investigate the relationships between a multipreferential semantics for defeasible reasoning in knowledge representation and a multilayer neural network model . Weighted knowledge bases for a simple description logic with typicality are considered under a (many-valued) “concept-wise” multipreference semantics. The semantics is used to provide a preferential interpretation of MultiLayer Perceptrons (MLPs). A model checking and an entailment based approach are exploited in the verification of conditional properties of MLPs.},
  archive      = {J_IJAR},
  author       = {Mario Alviano and Francesco Bartoli and Marco Botta and Roberto Esposito and Laura Giordano and Daniele Theseider Dupré},
  doi          = {10.1016/j.ijar.2023.109065},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109065},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A preferential interpretation of MultiLayer perceptrons in a conditional logic with typicality},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Construction methods of fuzzy implications on bounded
posets. <em>IJAR</em>, <em>164</em>, 109064. (<a
href="https://doi.org/10.1016/j.ijar.2023.109064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fuzzy implication on bounded lattices was introduced by Palmeira et al., and the method of extending fuzzy implications on bounded lattices by using retraction was provided. However, we find that the extension of fuzzy implications on bounded lattices can also be realized through homomorphism . In order to get better results, we will continue to study this topic in this paper. In particular, we will focus on the construction methods of fuzzy implications on bounded posets . More precisely, we will give some construction methods of fuzzy implications via 0 , 1 0,1 -homomorphism on bounded posets. Then we further study two special kinds of fuzzy implications, ( Q , N ) (Q,N) -implications and R Q RQ -implications on bounded posets, where Q Q is a quasi-overlap function. Finally, we discuss the distributive laws and the importation laws of ( Q , N ) (Q,N) -implications and R Q RQ -implications over a quasi-overlap function Q Q .},
  archive      = {J_IJAR},
  author       = {Mei Wang and Xiaohong Zhang and Humberto Bustince and Javier Fernandez},
  doi          = {10.1016/j.ijar.2023.109064},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109064},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Construction methods of fuzzy implications on bounded posets},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How to choose a completion method for pairwise comparison
matrices with missing entries: An axiomatic result. <em>IJAR</em>,
<em>164</em>, 109063. (<a
href="https://doi.org/10.1016/j.ijar.2023.109063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since there exist several completion methods to estimate the missing entries of pairwise comparison matrices, practitioners face a difficult task in choosing the best technique. Our paper contributes to this issue: we consider a special set of incomplete pairwise comparison matrices that can be represented by a weakly connected directed acyclic graph, and study whether the derived weights are consistent with the partial order implied by the underlying graph. According to previous results from the literature, two popular procedures, the incomplete eigenvector and the incomplete logarithmic least squares methods fail to satisfy the required property. Here, the recently introduced lexicographically optimal completion combined with any of these weighting methods is shown to avoid ordinal violation in the above setting. Our finding provides a powerful argument for using the lexicographically optimal completion to determine the missing elements in an incomplete pairwise comparison matrix.},
  archive      = {J_IJAR},
  author       = {László Csató},
  doi          = {10.1016/j.ijar.2023.109063},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109063},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {How to choose a completion method for pairwise comparison matrices with missing entries: An axiomatic result},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel approach to discretizing information systems
associated with neighborhood rough sets. <em>IJAR</em>, <em>164</em>,
109062. (<a href="https://doi.org/10.1016/j.ijar.2023.109062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By effectively capturing the similarity relationship between objects, neighborhood rough set models offer a highly advantageous approach to analyzing numerical data . However, it is computationally demanding to construct granular structures by calculating the distance between all objects in the universe. In this paper, we propose a novel approach to discretizing information systems associated with neighborhood rough sets. Firstly, a unique bilayer, quasi discretization-based neighborhood, is developed with the aim of minimizing the time required for model generation. Most of the current evaluation indices for a rough set model primarily focus on the evaluation of the lower and upper approximations , rather than the granular structure of the model. We introduce two evaluation indices for binary relations , namely, the Gaussian balance index and the quality index. These indices aim to provide a comprehensive assessment of the granular structure in terms of quantity and quality. Moreover, we present two extension models for discretization neighborhood rough sets and devise three attribute reduction algorithms. In order to evaluate the performance of the models, three comparative experiments are conducted. The results obviously reveal the high efficiency and effectiveness of the proposed models.},
  archive      = {J_IJAR},
  author       = {Di Zhang and Ping Zhu},
  doi          = {10.1016/j.ijar.2023.109062},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109062},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A novel approach to discretizing information systems associated with neighborhood rough sets},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ωA-IvE methodology: Admissible interleaving entropy methods
applied to video streaming traffic classification. <em>IJAR</em>,
<em>164</em>, 109061. (<a
href="https://doi.org/10.1016/j.ijar.2023.109061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on the width-based interval fuzzy entropy notion, considering the interval data diameter as a measure of the lack of knowledge and uncertainty related to the precise membership degrees of elements in an interval-valued fuzzy set . The w -preserving notion relates the uncertainty from input to output in system information . Such a concept generates a new entropy by applying width-based average functions and admissible order to compare interval data and define width-based fuzzy connectives in data fuzzy computations. A new admissible total order is introduced, requesting just one injective and increasing function, illustrated by a Decimal Digit Interleaving (DDI) function. The proposal methods are based on the admissible interleaving order and related expressions for width-based interval entropy considering different conditions for composition among width-based interval fuzzy operators, as negations with equilibrium and average functions, also including idempotent aggregation function and restricted equivalence functions. Finally, we illustrate the application of the proposed methods for solving a video streaming traffic classification problem. The admissible interleaving entropy analysis is performed over the attributes modeling the FuzzyNetClass approach, a computational model for traffic classification related to video streaming, exploring the integration of inference systems based on interval-valued fuzzy logic and machine learning algorithms . The results by comparison with other width-based interval fuzzy entropy methods were promising and pointed to continuing study and research efforts.},
  archive      = {J_IJAR},
  author       = {Lidiane Costa da Silva and Eduardo Monks and Adenauer Yamin and Renata Reiser and Benjamín Bedregal},
  doi          = {10.1016/j.ijar.2023.109061},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109061},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {ωA-IvE methodology: Admissible interleaving entropy methods applied to video streaming traffic classification},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Concepts of neighbors and their application to
instance-based learning on relational data. <em>IJAR</em>, <em>164</em>,
109059. (<a href="https://doi.org/10.1016/j.ijar.2023.109059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs and other forms of relational data have become a widespread kind of data, and powerful methods to analyze and learn from them are needed. Formal Concept Analysis (FCA) is a mathematical framework for the analysis of symbolic datasets, which has been extended to graphs and relational data , like Graph-FCA. It encompasses various tasks such as pattern mining or machine learning , but its application generally relies on the computation of a concept lattice whose size can be exponential with the number of instances. We propose to follow an instance-based approach where the learning effort is delayed until a new instance comes in, and an inference task is set. This is the approach adopted in k-Nearest Neighbors, and this relies on a distance between instances. We define a conceptual distance based on FCA concepts, and from there the notion of concepts of neighbors, which can be used as a basis for instance-based reasoning. Those definitions are given for both classical FCA and Graph-FCA. We provide efficient algorithms for computing concepts of neighbors, and we demonstrate their inference capabilities by presenting three different applications: query relaxation, knowledge graph completion, and relation extraction.},
  archive      = {J_IJAR},
  author       = {H. Ambre Ayats and Peggy Cellier and Sébastien Ferré},
  doi          = {10.1016/j.ijar.2023.109059},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109059},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Concepts of neighbors and their application to instance-based learning on relational data},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Verified propagation of imprecise probabilities in
non-linear ODEs. <em>IJAR</em>, <em>164</em>, 109044. (<a
href="https://doi.org/10.1016/j.ijar.2023.109044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We combine reachability analysis and probability bounds analysis, which allow for imprecisely known random variables (multivariate intervals or p-boxes) to be specified as the initial states of a dynamical system . In combination, the methods allow for the temporal evolution of p-boxes to be rigorously computed, and they give interval probabilities for formal verification problems, also called failure probability calculations in reliability analysis. The methodology places no constraints on the input probability distribution or p-box and can handle dependencies generally in the form of copulas . We also provide a consonant approximation method for multivariate p-boxes, which allows for the prediction sets of dynamical systems to be efficiently computed. The presented methodology is rigorous and automatically verified, as both the dynamics and uncertainties are represented and solved with guaranteed enclosures.},
  archive      = {J_IJAR},
  author       = {Ander Gray and Marcelo Forets and Christian Schilling and Scott Ferson and Luis Benet},
  doi          = {10.1016/j.ijar.2023.109044},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109044},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Verified propagation of imprecise probabilities in non-linear ODEs},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Classical iterative proportional scaling of log-linear
models with rational maximum likelihood estimator. <em>IJAR</em>,
<em>164</em>, 109043. (<a
href="https://doi.org/10.1016/j.ijar.2023.109043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we investigate multipartition models , the subset of log-linear models for which one can perform the classical iterative proportional scaling (IPS) algorithm to numerically compute the maximum likelihood estimate (MLE). Multipartition models include families of models such as hierarchical models and balanced, stratified staged trees. We define a sufficient condition , called the Generalized Running Intersection Property (GRIP), on the matrix representation of a multipartition model under which the classical IPS algorithm produces the exact MLE in one cycle. In this case, the MLE is a rational function of the data. Additionally we connect the GRIP to the toric fiber product and to previous results for hierarchical models and balanced, stratified staged trees. This leads to a characterization of balanced, stratified staged trees in terms of the GRIP.},
  archive      = {J_IJAR},
  author       = {Jane Ivy Coons and Carlotta Langer and Michael Ruddy},
  doi          = {10.1016/j.ijar.2023.109043},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109043},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Classical iterative proportional scaling of log-linear models with rational maximum likelihood estimator},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inversion of bayesian networks. <em>IJAR</em>, <em>164</em>,
109042. (<a href="https://doi.org/10.1016/j.ijar.2023.109042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational autoencoders and Helmholtz machines use a recognition network (encoder) to approximate the posterior distribution of a generative model (decoder). In this paper we establish some necessary and some sufficient properties of a recognition network so that it can model the true posterior distribution exactly. These results are derived in the general context of probabilistic graphical modelling / Bayesian networks , for which the network represents a set of conditional independence statements. We derive both global conditions, in terms of d-separation, and local conditions for the recognition network to have the desired qualities. It turns out that for the local conditions the perfectness property (for every node, all parents are joined) plays an important role.},
  archive      = {J_IJAR},
  author       = {Jesse van Oostrum and Peter van Hintum and Nihat Ay},
  doi          = {10.1016/j.ijar.2023.109042},
  journal      = {International Journal of Approximate Reasoning},
  month        = {1},
  pages        = {109042},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Inversion of bayesian networks},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
