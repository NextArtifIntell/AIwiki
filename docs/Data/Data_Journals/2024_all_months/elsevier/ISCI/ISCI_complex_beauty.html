<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ISCI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="isci---1308">ISCI - 1308</h2>
<ul>
<li><details>
<summary>
(2024). Dynamic-memory event-triggered secure consensus for
nonlinear MASs with constrained scaling attacks. <em>ISCI</em>,
<em>685</em>, 121312. (<a
href="https://doi.org/10.1016/j.ins.2024.121312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a dynamic-memory event-triggered scheme (DMETS) to defend against a class of constrained scaling attacks for nonlinear leader-following multi-agent systems (MASs). Our scheme takes into account a time-varying memory package, which allows for the extension of the scheme to either an event-triggered scheme (ETS) or a memory-based event-triggered scheme (METS) with system signals. We model and analyze the characteristics of the time-constrained scaling attack, and obtain sufficient conditions of security consensus for nonlinear MASs based on the attack duration parameters. Moreover, we derive the dynamic-memory gains and the event-triggered matrices that vary with the attacks scaling factor. Finally, we present simulation results to demonstrate the effectiveness and superiority of our proposed DMETS in controlling MASs under insecure network environments.},
  archive      = {J_ISCI},
  author       = {Qingcao Zhang and Qing An and Yin Chen and Housheng Su},
  doi          = {10.1016/j.ins.2024.121312},
  journal      = {Information Sciences},
  month        = {12},
  pages        = {121312},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic-memory event-triggered secure consensus for nonlinear MASs with constrained scaling attacks},
  volume       = {685},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Overlapping community-driven dynamic consensus reaching
model of large-scale group decision making in social network.
<em>ISCI</em>, <em>685</em>, 121290. (<a
href="https://doi.org/10.1016/j.ins.2024.121290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale group decision-making (LSGDM) serves as a pivotal tool for facilitating consistent decision results through intricate interactions among individuals within the network. However, the impact of complex trust relationships within overlapping communities on consensus is often overlooked in many studies. Moreover, the dynamic interaction between overlapping communities and the consensus reaching process (CRP) is seldom taken into account. This paper aims to build an overlapping community-driven consensus reaching model for addressing LSGDM challenges in social network. Given the advantages of intuitionistic fuzzy numbers (IFNs) in uncertain information representation, IFNs are used to express evaluation information and trust information. Firstly, a novel overlapping community detection method is developed to divide subgroups and detect overlapping communities. Secondly, to determine reliable subgroup weights, this paper constructs a weight determination model that considers multiple factors and their internal correlations. Then, an overlapping community-driven dynamic consensus model is proposed, which provides a new way to resolve the opinion conflicts, considering the dynamic change of CRP. Simultaneously, the reverse effect of opinion adjustment on the social trust network is considered. Finally, the practicality of the proposed model is demonstrated through illustrative cases. Furthermore, through a comparative analysis, the superiority of the proposed model is demonstrated and the efficiency improvement for CRP is verified.},
  archive      = {J_ISCI},
  author       = {Fei Teng and Xinran Liu and Peide Liu},
  doi          = {10.1016/j.ins.2024.121290},
  journal      = {Information Sciences},
  month        = {12},
  pages        = {121290},
  shortjournal = {Inf. Sci.},
  title        = {Overlapping community-driven dynamic consensus reaching model of large-scale group decision making in social network},
  volume       = {685},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective evolutionary architectural pruning of deep
convolutional neural networks with weights inheritance. <em>ISCI</em>,
<em>685</em>, 121265. (<a
href="https://doi.org/10.1016/j.ins.2024.121265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the ongoing success of artificial intelligence applications, the deployment of deep learning models on end devices remains challenging due to the limited onboard computational resources. A way to tackle this challenge is model compression through network pruning, which removes unnecessary parameters to reduce model size without significantly affecting performance. However, existing iterative methods require designated pruning rates and obtain a single pruned model, which lacks the flexibility to adapt to devices with heterogeneous computational capabilities. This paper considers network pruning in Deep Convolutional Neural Networks (DCNNs) and proposes a novel algorithm for structured filter pruning in DCNNs using a multi-objective evolutionary approach with a novel weights inheritance scheme and representation scheme to reduce the time cost of the optimization process. The proposed method provides solutions with multiple levels of tradeoff between performance and efficiency for various hardware specifications on edge devices. Experimental results demonstrate the effectiveness of the proposed framework in optimizing popular DCNN models in terms of model complexity and accuracy. Notably, the framework successfully made significant reductions in floating-point operations ranging from 40% to 90% of VGG-16/19 and ResNet-56/110 with negligible loss in accuracy on the CIFAR-10/100 dataset.},
  archive      = {J_ISCI},
  author       = {K.T. Chung and C.K.M. Lee and Y.P. Tsang and C.H. Wu and Ali Asadipour},
  doi          = {10.1016/j.ins.2024.121265},
  journal      = {Information Sciences},
  month        = {12},
  pages        = {121265},
  shortjournal = {Inf. Sci.},
  title        = {Multi-objective evolutionary architectural pruning of deep convolutional neural networks with weights inheritance},
  volume       = {685},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy exponential-approximation ET hybrid impulsive control
for networked nonlinear singular jump systems under state reconstruction
and random actuator attacks. <em>ISCI</em>, <em>684</em>, 121298. (<a
href="https://doi.org/10.1016/j.ins.2024.121298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates fuzzy exponential-approximation event-triggered (ET) hybrid impulsive control for networked nonlinear singular Markovian jump systems (SMJSs) under state reconstruction mechanism and random actuator attacks. A mode-dependent exponential-approximation event-triggered (EET) mechanism is introduced by redefining error function so as to decrease event-triggering rate. In accordance with the suggested EET mechanism and via introducing an exponential adjusting function, a mode-dependent fuzzy exponential-approximation event-triggered hybrid impulsive (EEHI) controller comprising impulsive controller and state-feedback controller is proposed. The H ∞ H∞ stochastic admissibility criteria for fuzzy SMJSs under random actuator attacks are acquired by constructing an impulse-time-related and Markovian-jump-mode-related Lyapunov-Krasovskii (L-K) functional as well as exploiting singular value decomposition (SVD). The fuzzy EEHI controller gains are derived from solving linear matrix inequalities. A simulation instance of single-link robot arm is presented and confirms that the suggested methodology is effective.},
  archive      = {J_ISCI},
  author       = {Yujing Pang and Guangming Zhuang and Xiangpeng Xie and Yanqian Wang},
  doi          = {10.1016/j.ins.2024.121298},
  journal      = {Information Sciences},
  month        = {12},
  pages        = {121298},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy exponential-approximation ET hybrid impulsive control for networked nonlinear singular jump systems under state reconstruction and random actuator attacks},
  volume       = {684},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust multi-rate fusion state estimation for networked
nonlinear systems via a dynamic event-timing-triggered mechanism.
<em>ISCI</em>, <em>684</em>, 121295. (<a
href="https://doi.org/10.1016/j.ins.2024.121295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the scenario of remote state estimation using multi-rate asynchronous sampling sensor data for perturbed nonlinear systems. The sensors are categorized into N groups with different sampling rates according to the designed event-triggered mechanism. Subsequently, the measurement data from each sensor group is transmitted to the remote state observer through independent scheduling protocols and communication networks at the sampling instants. To address this problem, this paper introduces a novel multi-rate continuous-discrete observer framework with a dynamic event-timing-triggered mechanism. The multi-rate continuous-discrete observer framework fuses sampled outputs from different rates into continuous output signals, enabling the derivation of continuous state estimation. The dynamic event-timing-triggered mechanism presents a versatile and unified framework for both time-triggered and event-triggered mechanisms. Through the utilization of a hybrid system framework, it is proven that the state estimation error remains input-to-state stable concerning measurement noise and disturbance inputs. The proposed multi-rate continuous-discrete observer is applicable to design a new type of event-triggered high-gain observer. Numerical simulations are conducted to demonstrate the efficacy of the proposed methodology.},
  archive      = {J_ISCI},
  author       = {Xincheng Zhuang and Yang Tian and Haoping Wang},
  doi          = {10.1016/j.ins.2024.121295},
  journal      = {Information Sciences},
  month        = {12},
  pages        = {121295},
  shortjournal = {Inf. Sci.},
  title        = {Robust multi-rate fusion state estimation for networked nonlinear systems via a dynamic event-timing-triggered mechanism},
  volume       = {684},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LDSPool: Latent dirichlet structure pooling with
hierarchical graph context representation. <em>ISCI</em>, <em>684</em>,
121293. (<a href="https://doi.org/10.1016/j.ins.2024.121293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In graph data analysis, particularly the graph classification task, a discriminative graph-level representation is significant to improve classification performance. For the performance improvement, recent studies have applied pooling methods to graph neural networks. However, the existing pooling approaches lose the initial graph structural information when incorporating each node. When a latent structure obtained from the pooling operation is given, the nodes in each latent structure have a different significance compared with the original graph. This structural information discrepancy between initial and latent structures leads to an inadequate graph representation when the existing methods generate the graph result. Motivated by this, we propose latent Dirichlet structure pooling (LDSPool) with a hierarchical graph context representation. After independently learning both structures, the proposed LDSPool incorporates the original graph and latent structure to reduce the structural discrepancy. We employ latent Dirichlet allocation (LDA) to extract the latent structure from the original graph. To validate the performance of LDSPool, we benchmarked five public graph datasets and seven existing pooling methods. The experimental results and ablation studies demonstrate that LDSPool achieves better performance than previous methods.},
  archive      = {J_ISCI},
  author       = {Min Seok Lee and Seok Woo Yang and Sung Won Han},
  doi          = {10.1016/j.ins.2024.121293},
  journal      = {Information Sciences},
  month        = {12},
  pages        = {121293},
  shortjournal = {Inf. Sci.},
  title        = {LDSPool: Latent dirichlet structure pooling with hierarchical graph context representation},
  volume       = {684},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An infrared and visible image fusion using knowledge
measures for intuitionistic fuzzy sets and swin transformer.
<em>ISCI</em>, <em>684</em>, 121291. (<a
href="https://doi.org/10.1016/j.ins.2024.121291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objectives of infrared and visible image fusion are to generate a single image that includes significant objects and rich texture information. However, the current deep-learning methods ignore uncertainty in the decision-making process during the fusion phase. To address this issue, we propose a novel infrared and visible image fusion method using a Swin Transformer and knowledge measures of intuitionistic fuzzy sets (IFSs) named SWKIF-Fusion. This model employs a Swin Transformer-based pre-trained module for feature extraction, which is the most effective module for modeling long-range dependencies. The fusion process of SWKIF-Fusion integrates the proposed knowledge measure of IFSs. IFSs inherently possess a high capability to handle uncertainty, and the knowledge measure of IFSs provides uncertainty quantification. This integration in the fusion phase mitigates the uncertainty in the decision-making process. This fusion of IFSs, knowledge measures, and the Swin Transformer-based deep learning model enhances the overall performance, as demonstrated through experiments on the TNO, Roadscene, OTCBVS, M3FD, and MSRS datasets. This study also fills the gap in developing knowledge measures for IFSs by proposing novel general construction methods. It presents a theoretically sound framework for knowledge measures of IFSs using well-established mathematical concepts such as t-norms, t-conorms, automorphisms, and aggregation operators.},
  archive      = {J_ISCI},
  author       = {Muhammad Jabir Khan and Shu Jiang and Weiping Ding and Jiashuang Huang and Haipeng Wang},
  doi          = {10.1016/j.ins.2024.121291},
  journal      = {Information Sciences},
  month        = {12},
  pages        = {121291},
  shortjournal = {Inf. Sci.},
  title        = {An infrared and visible image fusion using knowledge measures for intuitionistic fuzzy sets and swin transformer},
  volume       = {684},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event-triggered quasi-time-varying h∞ filtering for switched
systems via multiple trigger-dependent lyapunov functionals.
<em>ISCI</em>, <em>684</em>, 121289. (<a
href="https://doi.org/10.1016/j.ins.2024.121289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the event-triggered filtering problem for switched systems from the perspective of switched impulsive systems (SISs) by exploiting the characteristics of trigger and impulse behavior. By constructing multiple trigger-dependent Lyapunov functionals (MTDLFs), an event-triggered quasi-time-varying (ET-QTV) H ∞ H∞ filtering scheme is developed. Since the MTDLFs properly capture the event-induced impulse property of SISs, they release less conservatism. The filtering stability in the scenario of frequent plant switching during an interevent interval is also guaranteed by incorporating the average dwell time switching. The filtering synthesis condition is formulated as a set of QTV matrix inequalities defined over a finite time horizon, based on which a sum of squares-based filter design algorithm is presented further. Additionally, the derivation of a lower bound on interevent intervals is clarified for the event-triggering mechanism (ETM) to exclude the Zeno phenomenon. Finally, the effectiveness and potential practicability of the proposed filtering scheme are validated using a morphing aircraft model.},
  archive      = {J_ISCI},
  author       = {Yanhui Tong and Steven X. Ding and Bixuan Huang and Yueying Wang},
  doi          = {10.1016/j.ins.2024.121289},
  journal      = {Information Sciences},
  month        = {12},
  pages        = {121289},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered quasi-time-varying h∞ filtering for switched systems via multiple trigger-dependent lyapunov functionals},
  volume       = {684},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An extended belief rule-based system with hybrid sampling
strategy for imbalanced rule base. <em>ISCI</em>, <em>684</em>, 121288.
(<a href="https://doi.org/10.1016/j.ins.2024.121288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced dataset is an important focus for classification. As the mainstream of addressing imbalanced dataset, data-level methods are trapped in facing difficultly-determined subjective parameters, and the inconsistency between new minority samples and original minority samples simultaneously. To address it, this paper develops an extended belief-rule-based (EBRB) system with hybrid sampling strategy, which is a white-box classifier. The hybrid sampling strategy is composed of an under-sampling process and an oversampling process, in which subjective parameters are not involved. The under-sampling is to identify and remove overlapping majority rules by iteratively determining an appropriate objective threshold for calculating the inconsistency degree of rule base, and to determine and remove redundant non-overlapping majority rules by using the density of non-overlapping rules in clustered groups. The oversampling is to design a differential evolution based iterative process to generate new minority rules in groups by minimizing the inconsistency of rule base. The distribution of original dataset is maintained extremely by balancing rules in clustered majority and minority groups, respectively. This EBRB system is used for the auxiliary diagnosis of thyroid nodules, and its superior performance is highlighted by the comparison with existing EBRB systems, representative data-level methods, and algorithm-level methods.},
  archive      = {J_ISCI},
  author       = {Bingbing Hou and Chao Fu and Min Xue},
  doi          = {10.1016/j.ins.2024.121288},
  journal      = {Information Sciences},
  month        = {12},
  pages        = {121288},
  shortjournal = {Inf. Sci.},
  title        = {An extended belief rule-based system with hybrid sampling strategy for imbalanced rule base},
  volume       = {684},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimality and duality for nonconvex fuzzy optimization
using granular differentiability method. <em>ISCI</em>, <em>684</em>,
121287. (<a href="https://doi.org/10.1016/j.ins.2024.121287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the optimality and duality for a class of nonconvex fuzzy optimization problems under granular differentiability. We first derive optimality conditions for fuzzy optimization problems with fuzzy inequality constraints based on granular differentiability and granular F F -convexity. Then, Wolfe type and Mond-Weir type dual models corresponding to the primal problems are described, where their weak, strong, and strict converse dual theorems are explored to illustrate the connection between the optimal solutions of the primal and the dual models. Meanwhile, several examples are provided to support the corresponding theoretical results.},
  archive      = {J_ISCI},
  author       = {Fangfang Shi and Guoju Ye and Wei Liu and Savin Treanţǎ},
  doi          = {10.1016/j.ins.2024.121287},
  journal      = {Information Sciences},
  month        = {12},
  pages        = {121287},
  shortjournal = {Inf. Sci.},
  title        = {Optimality and duality for nonconvex fuzzy optimization using granular differentiability method},
  volume       = {684},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable machine learning for high frequency trading
dynamics discovery. <em>ISCI</em>, <em>684</em>, 121286. (<a
href="https://doi.org/10.1016/j.ins.2024.121286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-frequency trading (HFT) plays an essential role in the financial market. However, discovering and revealing trading dynamics remains a challenge in Fintech. In this study, we propose a novel explainable machine learning approach: Feature-Interpolation-based Dimension Reduction SCAN (FIDR-SCAN) to address the challenge by creating a trading map. The trading map deciphers an HFT security’s trading dynamics by marking the status of each transaction, grouping transactions in clusters, and identifying the trading markers. The proposed method presents new feature interpolation techniques to build a more informative and explainable feature space, unveiling hidden trading behaviors. It mines HFT data in their low-dimensional embedding to seek exceptional trading markers and classify the statuses of transactions. We validate the meaningfulness and effectiveness of the trading markers discovered by FIDR-SCAN in trading as well as examining its special characteristics. Additionally, we apply the proposed algorithm to cryptocurrency data and achieve reliable performance. We design AI trading algorithms by reusing trading markers identified during explainable trading dynamics discovery, applying them to HFT stock and cryptocurrency markets, besides constructing trading machines using identified trading markers. To the best of our knowledge, this study is the first to use interpretable machine learning to reveal HFT trading dynamics.},
  archive      = {J_ISCI},
  author       = {Henry Han and Jeffrey Yi-Lin Forrest and Jiacun Wang and Shuining Yuan and Fei Han and Diane Li},
  doi          = {10.1016/j.ins.2024.121286},
  journal      = {Information Sciences},
  month        = {12},
  pages        = {121286},
  shortjournal = {Inf. Sci.},
  title        = {Explainable machine learning for high frequency trading dynamics discovery},
  volume       = {684},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing multimodal depression detection with intra- and
inter-sample contrastive learning. <em>ISCI</em>, <em>684</em>, 121282.
(<a href="https://doi.org/10.1016/j.ins.2024.121282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal depression detection (MDD) has garnered significant interest in recent years. Current methods typically integrate multimodal information within samples to distinguish positive from negative samples, but they often neglect the relationships between samples. Despite similarities within the same class, individual variations exist. By leveraging these relationships, we can provide supervision signals for both inter- and intra-class samples, thereby enhancing the discriminative power of user representations. Inspired by this observation, we introduce IISFD, a novel approach that concurrently exploits intra-sample contrastive learning and inter-sample contrastive learning with hard negative sampling. This method comprehensively considers information both within individual samples and across samples. Specifically, we decompose the multimodal inputs of each sample, including audio, vision and text, into modality-common features and modality-specific features. To obtain better decomposed feature representations, we integrate intra-sample contrastive learning and inter-sample contrastive learning with hard negative sampling. Additionally, detailed modal information is obtained through unimodal reconstruction. By passing the decomposed features through a carefully designed multimodal fusion module, we obtain more discriminative user representations. Experimental results on two publicly available datasets demonstrate the superiority of our model, highlighting its effectiveness in leveraging both intra- and inter-sample information for enhanced MDD.},
  archive      = {J_ISCI},
  author       = {Meiling Li and Yuting Wei and Yangfu Zhu and Siqi Wei and Bin Wu},
  doi          = {10.1016/j.ins.2024.121282},
  journal      = {Information Sciences},
  month        = {12},
  pages        = {121282},
  shortjournal = {Inf. Sci.},
  title        = {Enhancing multimodal depression detection with intra- and inter-sample contrastive learning},
  volume       = {684},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FedNor: A robust training framework for federated learning
based on normal aggregation. <em>ISCI</em>, <em>684</em>, 121274. (<a
href="https://doi.org/10.1016/j.ins.2024.121274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing data security and data silo issues in Edge Intelligence, this paper proposes a Byzantine-resilient framework (FedNor) for Federated Learning (FL). FedNor integrates robust statistical methods with personalized FL strategies to enhance resilience against malicious updates while maintaining model generalization capabilities. The framework comprises two key components: the Robust Normal Aggregation (RN) module and the Personalized Fusion (PF) module. The RN module employs normality tests to identify and rectify anomalous updates, thereby ensuring the integrity and quality of model updates. Concurrently, the PF module incorporates data distribution considerations when integrating global and local models to optimize model security and accuracy. Experimental results demonstrate FedNor&#39;s effectiveness in mitigating eight distinct poisoning attacks on the MNIST datasets, with minimal accuracy degradation ranging from 0.42% to 1.96%. Furthermore, FedNor limits the backdoor attack success rate on the CIFAR-10 datasets to below 20%, while maintaining accuracy comparable to personalized FL schemes.},
  archive      = {J_ISCI},
  author       = {Shuo Xu and Hui Xia and Rui Zhang and Peishun Liu and Yu Fu},
  doi          = {10.1016/j.ins.2024.121274},
  journal      = {Information Sciences},
  month        = {12},
  pages        = {121274},
  shortjournal = {Inf. Sci.},
  title        = {FedNor: A robust training framework for federated learning based on normal aggregation},
  volume       = {684},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transfer entropy on collective motion with undeclared loose
leader–follower (LLF) structure. <em>ISCI</em>, <em>684</em>, 121248.
(<a href="https://doi.org/10.1016/j.ins.2024.121248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During an emergency or evacuation, individuals focus on the movement of their neighbors and follow those in sight, even without social affiliation, forming the undeclared Loose Leader-Follower (LLF) group, rather than the usual assumption of following certain rules in most of evacuation models. Inspired by the real-life experience and experimental data, the study develops a novel stochastic process-based evacuation model, integrated the LLF structure in collective motion to clarify the mechanism underlying individual interaction and refine the walking process according to attainable information. Transfer entropy (TE), a model-free measure of the direction of information flow, is used to detect the role of the individuals in the LLF structure from the time-series reconstructed motion information (e.g., the walking coordinate series). To reduce the error of the role detection, according to the 3σ principle for TE values, the detection threshold is decided based on the surrogate walking data. For simulation of their motion decision in the LLF structure, the TE is integrated into the walking behavior mode (TE-POMDP) using the Partially Observable Markov Decision Process (POMDP), that produces their motion behavior under the typical attained information condition. The results show that the TE-POMDP can provide more realistic trajectories. Additionally, we find that a ‘Delta-like’ formation of leading group distribution was presented and remained stable in the procession after a short period of confusion in early stage.},
  archive      = {J_ISCI},
  author       = {Jie Xu and Hui Zhang and Yihan Shi and Ying Xiangli},
  doi          = {10.1016/j.ins.2024.121248},
  journal      = {Information Sciences},
  month        = {12},
  pages        = {121248},
  shortjournal = {Inf. Sci.},
  title        = {Transfer entropy on collective motion with undeclared loose leader–follower (LLF) structure},
  volume       = {684},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discrete-time event-triggered type-2 fuzzy wavelet neural
network control for multi-motor servo system. <em>ISCI</em>,
<em>683</em>, 121297. (<a
href="https://doi.org/10.1016/j.ins.2024.121297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a discrete-time event-triggered adaptive neural network control scheme for a multi-motor servo system (MMSS) to realize a desired position tracking performance. First, a discrete-time model of the MMSS, including a dead-zone and a nonlinear friction, is established based on the Euler’s discretization. Then, a discrete-time adaptive neural network controller is designed by integrating a type-2 fuzzy wavelet neural network (T2FWNN) and the backstepping technology. The neural network is not only used to estimate uncertain nonlinearities, but also can handle the non-causal problem caused by the conventional backstepping method. Meanwhile, a fixed threshold event-triggered mechanism along with the incorporation of a dead-zone operator is superimposed into the actual controller thus saving communicational resources. Besides, stability analysis proves that all the signals in the closed MMSS are bounded, and the position tracking error converges to a small neighborhood of the origin. Finally, abundant simulation experience results demonstrate the effectiveness and robustness of the proposed scheme.},
  archive      = {J_ISCI},
  author       = {Hao Li and Shaohua Luo and Ya Zhang and Yinquan Yu and Hassen M. Ouakad},
  doi          = {10.1016/j.ins.2024.121297},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121297},
  shortjournal = {Inf. Sci.},
  title        = {Discrete-time event-triggered type-2 fuzzy wavelet neural network control for multi-motor servo system},
  volume       = {683},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A generalized weighted evidence fusion algorithm based on
quantum modeling. <em>ISCI</em>, <em>683</em>, 121285. (<a
href="https://doi.org/10.1016/j.ins.2024.121285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of evidence theory, the Dempster-Shafer framework is widely used for combining evidence. However, it often produces counterintuitive results when dealing with highly conflicting evidence. To mitigate this issue, the weighted evidence fusion method has gained popularity. However, with the generalization of the mass function from the perspective of quantum theory, the weighting of conflicting evidence under quantum effects remains an open issue. To address this issue, a generalized weighted evidence fusion algorithm based on quantum modeling is proposed in this study. First, when quantum interference effects are considered, Dempster&#39;s rule is generalized into a generalized evidence combination rule based on quantum modeling. Second, a generalized quantum evidence distance is proposed to measure the similarity of quantum evidence in the presence of phase-term interference. Third, a global and nonlinear quantum evidence weighting operator is designed to reduce the impact of conflicting quantum evidence. Then, based on this operator and the similarities between pieces of quantum evidence, the weighted quantum evidence is fused to yield the final conclusion using the proposed generalized combination rule. Finally, the rationality, reliability, and accuracy of the proposed method are effectively proven through experiments using a few numerical examples and applications.},
  archive      = {J_ISCI},
  author       = {Kaiyi Zhao and Pinle Qin and Saihua Cai and Ruizhi Sun and Zeqiu Chen and Jiayao Li},
  doi          = {10.1016/j.ins.2024.121285},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121285},
  shortjournal = {Inf. Sci.},
  title        = {A generalized weighted evidence fusion algorithm based on quantum modeling},
  volume       = {683},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evasion on general GAN-generated image detection by
disentangled representation. <em>ISCI</em>, <em>683</em>, 121267. (<a
href="https://doi.org/10.1016/j.ins.2024.121267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images generated by the Generative Adversarial Network (GAN) are too realistic to be distinguished by humans. Recently, some detection methods have been proposed to distinguish between generated and real images. However, these methods rely on specific detection techniques and can be easily detected by other types of detection methods. This study aims to investigates the security of the GAN-generated image detection method by devising a method to evade general detection. The features related and unrelated to differentiating between real and generated images are disentangled by a GAN model in our model. The unrelated features contain information about the image content, while the related feature provides useful information for identifying generated images. Our method then camouflages a generated image by using its unrelated features and the related features of real images. The main advantages of our model include its ability to generalize to different detectors and adapt to the prior information about detectors. Experimental results confirm the superior evasion capability of our proposed method compared to other detector-dependent and independent methods across different popular detection methods.},
  archive      = {J_ISCI},
  author       = {Patrick P.K. Chan and Chuanxin Zhang and Haitao Chen and Jingwen Deng and Xiao Meng and Daniel S. Yeung},
  doi          = {10.1016/j.ins.2024.121267},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121267},
  shortjournal = {Inf. Sci.},
  title        = {Evasion on general GAN-generated image detection by disentangled representation},
  volume       = {683},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Category correlations embedded semantic centers hashing for
cross-modal retrieval. <em>ISCI</em>, <em>683</em>, 121262. (<a
href="https://doi.org/10.1016/j.ins.2024.121262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the merits in rapid query speed and space-efficient storage, cross-modal hashing approaches have garnered growing attention in research circles. Existing hashing methodologies have exhibited commendable performance. Nonetheless, there still remain several unresolved considerations warranting further investigation: 1) To leverage semantic relations embedded within labels, the majority of hashing methods adopt a direct learning approach to establish mappings between the hamming space and the label space, which fails to further excavate the semantic information. 2) As binary codes impose strict constraints on effective regression, the classical least squares regression exploited in hash function learning manifests limited efficiency. To address the above issues, a novel hashing framework, i.e., Category correlAtions embedded semanTic Centers Hashing (CATCH) is proposed in this paper. The main contributions of the proposed method lie in the following two aspects. For hash code learning, CATCH constructs semantic centers for each category with underlying category co-occurrence considered to enhance the discrimination of binary codes. For hash function learning, CATCH introduces adaptive margins in hash codes to ease the strict binary regression target, obtaining more discriminative and robust hash functions. Several experiments revealed the effectiveness of CATCH. The source code is available at https://github.com/fanwentao0955/CATCH .},
  archive      = {J_ISCI},
  author       = {Wentao Fan and Chenwen Yang and Kaiyi Luo and Min Zhang and Huaxiong Li},
  doi          = {10.1016/j.ins.2024.121262},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121262},
  shortjournal = {Inf. Sci.},
  title        = {Category correlations embedded semantic centers hashing for cross-modal retrieval},
  volume       = {683},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Quantized based dynamic-output-feedback guaranteed-cost
control of interval-type-2 takagi-sugeno fuzzy systems under DoS
attacks. <em>ISCI</em>, <em>683</em>, 121238. (<a
href="https://doi.org/10.1016/j.ins.2024.121238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the issue of quantized guaranteed-cost dynamic-output-feedback control for uncertain-nonlinear NCSs with DoS attacks. Firstly, the interval-type-2 Takagi-Sugeno fuzzy model is built to deal with the nonlinear NCSs. Secondly, to reduce the burden on communication resources, the dynamic quantization is introduced from measurement-output and control-input. Considering the existence of DoS attacks in network channel, the DoS attacks model is constructed by binary-Markov-chain. This paper aims to obtain the controller and quantizers with DoS attacks. Some sufficient conditions of uncertain-nonlinear NCSs are received to ensure the stochastic stability and guaranteed-cost performance. Finally, an example is simulated to prove the advantage of proposed method.},
  archive      = {J_ISCI},
  author       = {Hengqian Li and Xisheng Zhan and Qingsheng Yang and Jie Wu and Huaicheng Yan},
  doi          = {10.1016/j.ins.2024.121238},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121238},
  shortjournal = {Inf. Sci.},
  title        = {Quantized based dynamic-output-feedback guaranteed-cost control of interval-type-2 takagi-sugeno fuzzy systems under DoS attacks},
  volume       = {683},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable data-driven q-learning control for a class of
discrete-time linear autonomous systems. <em>ISCI</em>, <em>682</em>,
121283. (<a href="https://doi.org/10.1016/j.ins.2024.121283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explaining what a reinforcement learning (RL) control agent learns play a crucial role in the safety critical control domain. Most of the approaches in the state-of-the-art focused on imitation learning methods that uncover the hidden reward function of a given control policy. However, these approaches do not uncover what the RL agent learns effectively from the agent-environment interaction. The policy learned by the RL agent depends in how good the state transition mapping is inferred from the data. When the state transition mapping is wrongly inferred implies that the RL agent is not learning properly. This can compromise the safety of the surrounding environment and the agent itself. In this paper, we aim to uncover the elements learned by data-driven RL control agents in a special class of discrete-time linear autonomous systems. Here, the approach aims to add a new explainable dimension to data-driven control approaches to increase their trust and safe deployment. We focus on the classical data-driven Q-learning algorithm and propose an explainable Q-learning (XQL) algorithm that can be further expanded to other data-driven RL control agents. Simulation experiments are conducted to observe the effectiveness of the proposed approach under different scenarios using several discrete-time models of autonomous platforms.},
  archive      = {J_ISCI},
  author       = {Adolfo Perrusquía and Mengbang Zou and Weisi Guo},
  doi          = {10.1016/j.ins.2024.121283},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121283},
  shortjournal = {Inf. Sci.},
  title        = {Explainable data-driven Q-learning control for a class of discrete-time linear autonomous systems},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RLclean: An unsupervised integrated data cleaning framework
based on deep reinforcement learning. <em>ISCI</em>, <em>682</em>,
121281. (<a href="https://doi.org/10.1016/j.ins.2024.121281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data cleaning, a prerequisite to subsequent data analysis, has always been the focus of data science research. Datasets with errors can severely detract from the quality of downstream analytical results. Unfortunately, despite the proliferation of various data cleaning methods, it remains a time-consuming problem and frequently entails considerable labor expenses. In reality, errors are often heterogeneous and require different solutions. As a result, stand-alone methods often inadequate for addressing dirty data with multiple types of errors, while studies have demonstrated that combining such methods always require human intervention and the result remains unsatisfactory. In this paper, we propose an unsupervised integrated data cleaning framework, namely RLclean. Based on deep reinforcement learning, RLclean takes advantages of multiple data cleaning techniques, enabling it to effectively clean multiple types of errors and achieve satisfactory results. Additionally, it eliminates the need for costly human involvement, as the cleaning strategy is learned by data-driven, which further allows the framework to self-adapt to diverse domains. RLclean mainly consists of two parts: (i) an integrated error detection model that unites multiple techniques to detect different types of errors from multiple views; and (ii) an integrated data repair model that learns the optimal repair operations and repairs dirty data in an unsupervised manner. Extensive experiments on benchmark datasets have demonstrated the superiority of RLclean over state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Jinfeng Peng and Derong Shen and Tiezheng Nie and Yue Kou},
  doi          = {10.1016/j.ins.2024.121281},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121281},
  shortjournal = {Inf. Sci.},
  title        = {RLclean: An unsupervised integrated data cleaning framework based on deep reinforcement learning},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). M2GDL: Multi-manifold guided dictionary learning based
oversampling and data validation for highly imbalanced classification
problems. <em>ISCI</em>, <em>682</em>, 121280. (<a
href="https://doi.org/10.1016/j.ins.2024.121280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lack of diversity in synthetic data and inaccurate approximations of the minority class distribution are two main challenges with most oversampling techniques. This paper proposes a multi-manifold guided dictionary learning (M2GDL) approach for minority class oversampling. The proposed approach checks whether synthetic data points are useful and whether minority-class samples are important for data generation. The approach utilizes a linear combination of multiple manifolds by leveraging the inherent substructures of the data. Different data manifolds are constructed from the minority class training data and evaluated using a novel criterion. The importance of each sample is calculated within each manifold and then weighted according to the manifolds’ scores. Samples with the highest scores are identified as significant, and their K nearest neighbors are used to form a data dictionary for generating artificial data. The proposed sample generation method is achieved through the iterative solution of an optimization problem. Synthetic samples are then validated based on their proximity to the minority-class combinatorial manifold. Empirical evaluations across 22 datasets with varying degrees of class imbalance demonstrate that the proposed method outperforms recent oversampling approaches, particularly in scenarios with high imbalance.},
  archive      = {J_ISCI},
  author       = {Tayyebe Feizi and Mohammad Hossein Moattar and Hamid Tabatabaee},
  doi          = {10.1016/j.ins.2024.121280},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121280},
  shortjournal = {Inf. Sci.},
  title        = {M2GDL: Multi-manifold guided dictionary learning based oversampling and data validation for highly imbalanced classification problems},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive multi-label structure preserving network for
cross-modal retrieval. <em>ISCI</em>, <em>682</em>, 121279. (<a
href="https://doi.org/10.1016/j.ins.2024.121279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To integrate the label structures, which describe semantic correlations among labels, into the learned common representations, many existing methods leverage the label embeddings learned according to label structures, to map the data of different modalities into a common representation space. However, these methods cannot fully discover the semantic correlation between labels. In this paper, we propose an Adaptive Multi-label Structure Preserving Network (AMLSPN) to dynamically learn the multi-label correlations and multi-label embeddings for learning common representations, which can preserve the label structures. Our method introduces a series of multi-label correlation matrices to capture the structures of multi-label nodes in the multi-label graph. Moreover, we present a novel hierarchical correlation loss to supervise the learning process of these multi-label correlation matrices. Additionally, we introduce a group GCN to enhance the training speed of our model. Extensive evaluations on three benchmark datasets demonstrate that our proposed AMLSPN outperforms the state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Jie Zhu and Hui Zhang and Junfen Chen and Bojun Xie and Jianan Liu and Junsan Zhang},
  doi          = {10.1016/j.ins.2024.121279},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121279},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive multi-label structure preserving network for cross-modal retrieval},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Tensor double arc-tangent norm minimization for multi-view
clustering. <em>ISCI</em>, <em>682</em>, 121278. (<a
href="https://doi.org/10.1016/j.ins.2024.121278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor structures are widely utilized in clustering tasks due to their ability to represent high-order relationships among multi-view data. The rank and decomposition of tensors are essential characteristics that have recently received considerable attention. Most approaches approximate tensor rank using the tensor nuclear norm (TNN) and non-convex rank functions. We introduce a multi-view clustering method based on an enhanced self-expression with a tensor double arc-tangent norm. Initially leveraging tensor singular value decomposition, this method impartially approximates the true rank of the tensor, avoiding rank overestimation. The enhanced self-expression further utilizes the latent connections among the original data. Then, we propose an improved alternating direction method of multipliers (ADMM) for rapid optimization of the model. Experiments conducted on six datasets confirm the effectiveness of the proposed model.},
  archive      = {J_ISCI},
  author       = {Jie Zhang and Xiaoqian Zhang and Chao Luo and Yuqin Chen and Zhenwen Ren},
  doi          = {10.1016/j.ins.2024.121278},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121278},
  shortjournal = {Inf. Sci.},
  title        = {Tensor double arc-tangent norm minimization for multi-view clustering},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Clean affinity matrix induced hyper-laplacian regularization
for unsupervised multi-view feature selection. <em>ISCI</em>,
<em>682</em>, 121276. (<a
href="https://doi.org/10.1016/j.ins.2024.121276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most previous unsupervised multi-view feature selection (UMFS) methods have achieved appealing performance by exploring the consistency among multiple views. However, they have the following shortcomings: (1) They often fail to consider the potential inconsistency that might be caused by view-specific characteristics from the perspective of sparsity. (2) The previously learned hyper-graph might be affected by noise, thereby reducing the quality of the generated graph. To tackle these issues, this paper proposes a clean affinity matrix induced hyper-Laplacian regularization (CAHR) method for UMFS. Firstly, the initial affinity matrix is decomposed into the consistent and inconsistent parts, then a novel diversity penalty term is introduced to enforce the sparsity of the inconsistent part across views, thereby making the consistent part be cleaner. Secondly, a unified affinity matrix is generated by fusing the consistent factors of the initial affinity matrix in a self-weighted manner, thereby considering the consistency of multi-view data. Based on the unified affinity matrix, a hyper-Laplacian matrix is further constructed, which can maintain high-order manifold structure of data. Finally, a loss function is designed to find the best mapping for feature selection. Comprehensive experiments demonstrate that the proposed method significantly outperforms several state-of-the-art UMFS methods.},
  archive      = {J_ISCI},
  author       = {Peng Song and Shixuan Zhou and Jinshuai Mu and Meng Duan and Yanwei Yu and Wenming Zheng},
  doi          = {10.1016/j.ins.2024.121276},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121276},
  shortjournal = {Inf. Sci.},
  title        = {Clean affinity matrix induced hyper-laplacian regularization for unsupervised multi-view feature selection},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new defuzzification method and ranking method for type-2
fuzzy numbers. <em>ISCI</em>, <em>682</em>, 121275. (<a
href="https://doi.org/10.1016/j.ins.2024.121275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The type-2 fuzzy number (T2 FN) is a special type-2 fuzzy set whose all secondary membership functions are fuzzy numbers. This paper proposes a new defuzzification method and ranking method for T2 FNs. The defuzzification method can be expressed in a closed-form formula or can be divided into two computational steps. The first step computes the centroid of each secondary membership function to obtain a type-reduced set using the method derived from generalizing the existing alpha-cut defuzzification methods by introducing a parameter that controls the importance of secondary membership degrees, and the second step calculates the centroid of the type-reduced set. The defuzzified values are used to provide position information of T2 FNs. Secondly, we define a function to calculate the area enclosed by the image of the type-reduced set and the coordinate axes, and prove that this function is continuous. The values of this function are used to provide shape information of T2 FNs. Finally, to rank T2 FNs, we define a family of quasi-orders based on their position and shape information, and illustrate the validity and rationality of these quasi-orders through examples.},
  archive      = {J_ISCI},
  author       = {Wei Zhang},
  doi          = {10.1016/j.ins.2024.121275},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121275},
  shortjournal = {Inf. Sci.},
  title        = {A new defuzzification method and ranking method for type-2 fuzzy numbers},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive archive differential evolution with non-linear
population size reduction and selective pressure. <em>ISCI</em>,
<em>682</em>, 121273. (<a
href="https://doi.org/10.1016/j.ins.2024.121273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the best differential evolution (DE) variants, jSO has attracted the attention of many researchers. However, jSO still has a few drawbacks that limit its performance, it fails to fully exploit the potential of dominant individuals, it overuses of archives, and it cannot effectively balance convergence and diversity. In order to effectively overcome these deficiencies, this paper proposes a novel jSO variant called NLPSR-jSO. NLPSR-jSO introduces a novel Non-Linear Population Size Reduction scheme to balance exploration and exploitation performance while adaptively allocating more evaluation resources to dominant individuals to fully realize their potential. Moreover, NLPSR-jSO presents a new mechanism named Adaptive Archive Usage, which prevents archive overuse and improves the accuracy of the solution. A modified Rank-Based Selective Pressure strategy is integrated into the mutation strategy to increase the diversity and prevent premature convergence. The strategies proposed by NLPSR-jSO effectively solve the above-mentioned problems of jSO, and the cooperation of these strategies significantly improves the performance of jSO. The proposed NLPSR-jSO was compared with seven state-of-the-art DE variants using the CEC 2018 test suite. The experimental results show that the solution accuracy and convergence speed of NLPSR-jSO are significantly better than those of the compared algorithms.},
  archive      = {J_ISCI},
  author       = {Benben Zhou and Ying Huang},
  doi          = {10.1016/j.ins.2024.121273},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121273},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive archive differential evolution with non-linear population size reduction and selective pressure},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Algebraic analysis of pairwise comparisons with
non-reciprocal property. <em>ISCI</em>, <em>682</em>, 121272. (<a
href="https://doi.org/10.1016/j.ins.2024.121272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The law of comparative judgement usually implies the reciprocal property of pairwise comparisons. But time error and position preference could yield some judgements that contradict this identity assumption. This paper proposes an algebraic approach to dealing with the challenge of non-reciprocal property in pairwise comparisons. The concept of non-reciprocal pairwise comparison matrix (NrPCM) is used to characterize the situation of non-reciprocal property. Algebraic analysis of NrPCMs is carried out, where a linear space is constructed by proposing a set of basis. Then the linear space is decomposed into the direct sum of some subspaces. The properties of the space are analyzed such as inner product, decomposition and coordinate. Finally, we apply the algebraic method to investigate the Condorcet paradox under the impact of indifferent voters. A novel transformation formula of non-reciprocal pairwise comparisons is proposed, where the non-reciprocal property holds. It is revealed that the occurrence of voting paradox can be understood clearly according to the transitivity property of NrPCMs.},
  archive      = {J_ISCI},
  author       = {Yuan-Kai Hu and Fang Liu and Yu-Ru Cai},
  doi          = {10.1016/j.ins.2024.121272},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121272},
  shortjournal = {Inf. Sci.},
  title        = {Algebraic analysis of pairwise comparisons with non-reciprocal property},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic trust network-driven consensus modeling with
endogenous adjustment and exogenous modification under a quasi-z-number
environment. <em>ISCI</em>, <em>682</em>, 121271. (<a
href="https://doi.org/10.1016/j.ins.2024.121271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Z-number is widely used in decision-making because of its unique dual ability to capture human knowledge and facilitate judgments on realistic issues. To improve the applicability of Z-numbers, this paper puts forward the concept of quasi-Z-number and studies the social network and consensus models with quasi-Z-information to address multi-attribute group decision-making problems. First, a dynamic trust network among decision makers (DMs) is constructed. The endogenous adjustment mechanism is presented due to the interaction among DMs. Second, a feedback mechanism for non-consensus opinions is established. In the feedback, an exogenous modification mechanism is constructed through the minimal modification consensus model to help non-consensus DMs improve their consensus level. Furthermore, a minimum tolerance increment consensus model is proposed to cope with the situation where the consensus threshold is not reached within a specified number of iterations. Third, the practicability of the proposed decision-making system is illustrated by the case of a green energy investment in which all technicalities are shown. Its comprehensive performance is exhibited in the sensitivity analysis. The validity of the information form and methodology is demonstrated in the comparative analysis.},
  archive      = {J_ISCI},
  author       = {Feng Wang and Xiaobing Yu and Wenguan Luo and Jiangfeng Hao},
  doi          = {10.1016/j.ins.2024.121271},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121271},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic trust network-driven consensus modeling with endogenous adjustment and exogenous modification under a quasi-Z-number environment},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dictionary-based multi-instance learning method with
universum information. <em>ISCI</em>, <em>682</em>, 121264. (<a
href="https://doi.org/10.1016/j.ins.2024.121264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-instance learning (MIL) is a generalized form of supervised learning that attempts to extract useful information from sets of instances, known as bags. In practice, besides positive and negative bags, we can also collect universum bags. These universum bags contain instances that do not fit within the defined positive or negative classes; they may belong to a third class or other categories, similar to universum instances in classical machine learning. Additionally, dictionary learning can be used to eliminate noise hidden in the data and enhance the performance of the learning tool. In this paper, we propose a new dictionary-based multi-instance learning method with universum data (UDMIL). In the proposed model, universum bags are considered prior knowledge within the training data for classifier construction. We construct three types of dictionaries for positive bags, negative bags, and universum bags to enhance the sparsity of the training data and develop a better classifier. In addition, we introduce an alternative learning framework to solve the proposed model and acquire the MIL classifier for prediction. Extensive experiments show that the proposed method achieves superior performance.},
  archive      = {J_ISCI},
  author       = {Fan Cao and Bo Liu and Kai Wang and Yanshan Xiao and Jinghui He and Jian Xu},
  doi          = {10.1016/j.ins.2024.121264},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121264},
  shortjournal = {Inf. Sci.},
  title        = {Dictionary-based multi-instance learning method with universum information},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extracting process-aware decision models from object-centric
process data. <em>ISCI</em>, <em>682</em>, 121263. (<a
href="https://doi.org/10.1016/j.ins.2024.121263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organizations execute decisions within business processes on a daily basis whilst having to take into account multiple stakeholders who might require multiple point of views of the same process. Moreover, the complexity of the information systems running these business processes is generally high as they are linked to databases storing all the relevant data and aspects of the processes. Given the presence of multiple objects within an information system which support the processes in their enactment, decisions are naturally influenced by both these perspectives, logged in object-centric process logs. However, the discovery of such decisions from object-centric process logs is not straightforward as it requires to correctly link the involved objects whilst considering the sequential constraints that business processes impose as well as correctly discovering what a decision actually does. This paper proposes the first object-centric decision-mining algorithm called Integrated Object-centric Decision Discovery Algorithm (IODDA). IODDA is able to discover how a decision is structured as well as how a decision is made. Moreover, IODDA is able to discover which activities and object types are involved in the decision-making process. Next, IODDA is demonstrated with the first artificial knowledge-intensive process logs whose log generators are provided to the research community.},
  archive      = {J_ISCI},
  author       = {Alexandre Goossens and Johannes De Smedt and Jan Vanthienen},
  doi          = {10.1016/j.ins.2024.121263},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121263},
  shortjournal = {Inf. Sci.},
  title        = {Extracting process-aware decision models from object-centric process data},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature selection based on neighborhood complementary
entropy for heterogeneous data. <em>ISCI</em>, <em>682</em>, 121261. (<a
href="https://doi.org/10.1016/j.ins.2024.121261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications, there exists a large amount of heterogeneous data consisting of a mixture of numerical and categorical data, which are more complex and difficult to handle than a single class. In recent years, feature selection for heterogeneous data has received more and more attention from scholars. However, the current research on feature selection for heterogeneous data seldom takes into account the fineness of the granularity structure and the complementary information contained in the complements of each granularity. Addressing the shortcomings of existing efforts, this paper introduces complementary entropy into the neighborhood rough set model to define an uncertainty measurement system in heterogeneous data, and constructs the corresponding feature selection algorithm. First, the neighborhood complementary entropy and its associated uncertainty measures based on neighborhood relation are defined, and the relevant theoretical properties of these uncertainty measures are investigated. Then, based on the proposed uncertainty measures, a significance function is defined to assess the importance of candidate features. Next, a feature selection method for heterogeneous data is designed using neighborhood complementary entropy. Finally, the feasibility of the method proposed in this paper is demonstrated through an experimental comparative analysis with various existing feature selection methods.},
  archive      = {J_ISCI},
  author       = {Jianhua Dai and Wenxiang Chen and Liyun Xia},
  doi          = {10.1016/j.ins.2024.121261},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121261},
  shortjournal = {Inf. Sci.},
  title        = {Feature selection based on neighborhood complementary entropy for heterogeneous data},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transformations of solution semantics of interval linear
equations system. <em>ISCI</em>, <em>682</em>, 121260. (<a
href="https://doi.org/10.1016/j.ins.2024.121260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A solution x to a system of interval linear equations A x = b Ax=b possesses its own semantics, which may involve combinations of tolerance, control, left- and right-localized semantics. In scenarios where the need arises to persist with a solution x despite changes in its semantics, corresponding adjustments in the interval information of the system become necessary. Our focus is on perturbing the original interval matrix A to produce a transformed matrix A ′ A′ , ensuring that the solution x to A ′ x = b A′x=b aligns with the new semantics. We present a series of theorems using quadratic programming concepts to determine A ′ A′ in a manner that closely approximates A . Several applications are provided to illustrate the practical utility of our approach.},
  archive      = {J_ISCI},
  author       = {Phantipa Thipwiwatpotjana and Artur Gorka and Worrawate Leela-apiradee},
  doi          = {10.1016/j.ins.2024.121260},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121260},
  shortjournal = {Inf. Sci.},
  title        = {Transformations of solution semantics of interval linear equations system},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Observer-based guaranteed-cost bipartite time-varying
formation tracking control for multiagent systems subject to
communication delays. <em>ISCI</em>, <em>682</em>, 121259. (<a
href="https://doi.org/10.1016/j.ins.2024.121259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper centers on the guaranteed-cost bipartite time-varying formation tracking control for multiagent systems with nonuniform time-varying communication delays under the framework of a distributed observer. An integral quadratic cost function is presented, founded on formation tracking and observation error. Firstly, distributed state observers, using the relative measurement output between neighbors, are established so that the leader and follower can accurately estimate each agent&#39;s unmeasurable state. Subsequently, a bipartite formation tracking protocol is proposed, incorporating estimation information and nonuniform time-varying communication delays. This protocol aims to achieve bipartite time-varying formation tracking for multiagent systems. Next, a new augmented Lyapunov-Krasovskii functional with delay-product and triple integral terms is constructed. By integrating the second-order Bessel-Legendre inequality technique, the delay-dependent reciprocally convex combination inequality method, and the free weight matrix technique, a new guaranteed-cost bipartite time-varying formation tracking criterion is developed, offering less conservatism. Compared to certain existing delay conditions, the stability conditions assure a greater allowable upper bound of delay. Finally, a numerical example is conducted to confirm the validity and superiority of the theoretical findings.},
  archive      = {J_ISCI},
  author       = {Zhen Tang and Ziyang Zhen and Zhengen Zhao and Geert Deconinck},
  doi          = {10.1016/j.ins.2024.121259},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121259},
  shortjournal = {Inf. Sci.},
  title        = {Observer-based guaranteed-cost bipartite time-varying formation tracking control for multiagent systems subject to communication delays},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Topological reduction approaches for fuzzy relation systems
and their applications to text categorization. <em>ISCI</em>,
<em>682</em>, 121258. (<a
href="https://doi.org/10.1016/j.ins.2024.121258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy relation systems are important knowledge representation systems in fuzzy rough sets. In this paper, we explore attribute reduction from a topological perspective for fuzzy relation systems. First, using general fuzzy relations as a foundation, we provide an improved definition of topological reduction for fuzzy relation systems. Next, we propose the notion of topological reduction for fuzzy relation decision systems. Moreover, we create corresponding reduction algorithms to identify all topological reducts based on discernibility matrices. Because of the feature redundancy issue with the term frequency-inverse document frequency (TF-IDF) algorithm in text categorization, we suggest a hybrid feature selection algorithm that combines the TF-IDF algorithm and topological reduction algorithm. Comparative analyses of Chinese and English text datasets demonstrated the effectiveness and practicality of our proposed hybrid feature selection approach.},
  archive      = {J_ISCI},
  author       = {Xiuwei Gao and Yehai Xie},
  doi          = {10.1016/j.ins.2024.121258},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121258},
  shortjournal = {Inf. Sci.},
  title        = {Topological reduction approaches for fuzzy relation systems and their applications to text categorization},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Switching adaptive dynamic event-triggered consensus of
nonlinear multi-agent systems under DoS attacks and communication delay.
<em>ISCI</em>, <em>682</em>, 121257. (<a
href="https://doi.org/10.1016/j.ins.2024.121257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the issue of achieving security consensus in multi-agent systems (MASs) that are susceptible to denial-of-service attacks (DoS-As) and time-varying communication delays (TCD). We have developed a novel unified model to describe DoS-As and TCD. Firstly, a new switching adaptive dynamic event-triggered mechanism (SADETM) is proposed to conserve communication resources during DoS-As and TCD. The mechanism transforms into three event-triggered strategies adapted to highly dynamic MASs. Then, a consensus control protocol is designed through consensus errors based on SADETM. Finally, the sufficient conditions for ensuring the stability of MASs are solved by combining the Lyapunov-Krasovskii functional (LKF) method and the linear matrix inequality (LMI) technique. The effectiveness of this method is verified through simulation examples.},
  archive      = {J_ISCI},
  author       = {Yimin Wang and Shuanghe Yu and Ying Zhao},
  doi          = {10.1016/j.ins.2024.121257},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121257},
  shortjournal = {Inf. Sci.},
  title        = {Switching adaptive dynamic event-triggered consensus of nonlinear multi-agent systems under DoS attacks and communication delay},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Outlier detection method based on improved DPC algorithm and
centrifugal factor. <em>ISCI</em>, <em>682</em>, 121255. (<a
href="https://doi.org/10.1016/j.ins.2024.121255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection aims to identify data anomalies exhibiting significant deviations from normal patterns. However, existing outlier detection methods based on k -nearest neighbors often struggle with challenges such as increasing outlier counts and cluster formation issues. Additionally, selecting appropriate nearest-neighbor parameters presents a significant challenge, as researchers commonly evaluate detection accuracy across various k values. To enhance the accuracy and robustness of outlier detection, in this paper we propose an outlier detection method based on the improved DPC algorithm and centrifugal factor. Initially, we leverage k -nearest neighbors, k -reciprocal nearest neighbors, and Gaussian kernel function to determine the local density of samples, particularly addressing scenarios where the DPC algorithm struggles to identify cluster centers in sparse clusters. Subsequently, to reduce the DPC algorithm’s computational complexity, we screen the samples based on mutual nearest neighbor counts and select cluster centers accordingly. Non-central points are then distributed using k -nearest neighbors, k -reciprocal nearest neighbors, and reverse k -nearest neighbors. The centrifugal factor, whose magnitude reflects the outlier degree of samples, is then computed by calculating the ratio of the local kernel density at the cluster center to that of samples. Finally, we propose a method for choosing the nearest neighbor parameter, k . To comprehensively evaluate the outlier detection performance of the proposed algorithm, we conduct experiments on 12 complex synthetic datasets and 25 public real-world datasets, comparing the results with 12 state-of-the-art outlier detection methods.},
  archive      = {J_ISCI},
  author       = {Hao Xia and Yu Zhou and Jiguang Li and Xuezhen Yue and Jichun Li},
  doi          = {10.1016/j.ins.2024.121255},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121255},
  shortjournal = {Inf. Sci.},
  title        = {Outlier detection method based on improved DPC algorithm and centrifugal factor},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved deep temporal convolutional network for new
energy stock index prediction. <em>ISCI</em>, <em>682</em>, 121244. (<a
href="https://doi.org/10.1016/j.ins.2024.121244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of the stock indexes in the new energy market is of significant importance to both investors and policymakers. However, in response to the volatility and uncertainty characteristic of the new energy market, most scholars currently focus on training prediction methods using features from a single time scale, which cannot capture the fluctuations of new energy stock indexes under different time scales. Therefore, in this paper, a hybrid deep learning model Multi-kernel Parallel TemporalNet (MKP-TemporalNet) is proposed for predicting new energy stock indexes. This model initially incorporates an attention mechanism to calibrate the feature importance of multivariate time series dynamically, and then combines the characteristics of improved Temporal Convolutional Networks (iTCN) and Bidirectional Gated Recurrent Units (BiGRU) to enhance prediction accuracy effectively. In particular, the novelty of the iTCN lies in the development of a multi-kernel parallel convolution structure within a residual layout at the core of the temporal convolution module, to address the low efficiency of traditional TCN&#39;s single kernel convolution in extracting temporal features from input sequences at different time scales. Results from evaluating MKP-TemporalNet against several popular machine learning models on six new energy stock indexes confirm its predictive effectiveness in the new energy sector.},
  archive      = {J_ISCI},
  author       = {Wei Chen and Ni An and Manrui Jiang and Lifen Jia},
  doi          = {10.1016/j.ins.2024.121244},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121244},
  shortjournal = {Inf. Sci.},
  title        = {An improved deep temporal convolutional network for new energy stock index prediction},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A q-learning driven competitive surrogate assisted
evolutionary optimizer with multiple oriented mutation operators for
expensive problems. <em>ISCI</em>, <em>682</em>, 121224. (<a
href="https://doi.org/10.1016/j.ins.2024.121224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms (SAEAs) prevail in the solution of computationally expensive optimization problems. However, with the growth of problem scale and complexity, the high-dimensional problem space greatly restricts their effectiveness and applicability. This paper proposes a Q-learning driven competitive surrogate-assisted evolutionary optimizer with multiple oriented mutation operators (CSEO-MOMO) to improve the prediction effectiveness and accuracy of SAEAs in different scenarios of optimization problems. CSEO-MOMO constructs isomorphic models with different complexities during iteration. The Q-learning method is employed to pick the proper model for prediction based on the state feedback of the iterative population. To explore the search space more comprehensively and increase the probability of finding a better solution, two competitive sub-populations coevolve with personalized mutation operators, of which different oriented optimal tractive base vectors are nominated to guide the mutation direction. In addition, a tailored infilling strategy concerning both the performance of the iterative individuals and their spatial distribution is used to winnow out the individuals with great potential for real evaluation. A suit of high-dimensional CEC benchmarks of different properties and an openly shared topology optimization problem are used for the effectiveness and efficiency verification of CSEO-MOMO. The experimental results reveal that CSEO-MOMO trumps seven excellent SAEAs in solving high-dimensional complex problems and possesses better accuracy and robustness under various fitness landscape scenarios. (The relevant MATLAB code of CSEO-MOMO is publicly available in the first author’s GitHub repository: https://github.com/qinna-zhu/CSEO-MOMO .)},
  archive      = {J_ISCI},
  author       = {Qinna Zhu and Haibo Yu and Li Kang and Jianchao Zeng},
  doi          = {10.1016/j.ins.2024.121224},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121224},
  shortjournal = {Inf. Sci.},
  title        = {A Q-learning driven competitive surrogate assisted evolutionary optimizer with multiple oriented mutation operators for expensive problems},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural schrödinger bridge for unpaired real-world image
deraining. <em>ISCI</em>, <em>682</em>, 121199. (<a
href="https://doi.org/10.1016/j.ins.2024.121199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the significant differences between domains, current unpaired learning methods struggle to accurately map the relationship between rainy and clear images. To this end, we introduce a neural Schrödinger bridge (NSB) for unpaired real-world image deraining, which utilizes the stochastic differential equations to capture the mapping relationships between rainy and clear domains. Meanwhile, we frame the deraining process as a Lagrangian problem using the Kullback-Leibler divergence between the data distribution and the model distribution. Additionally, by leveraging the capabilities of the contrastive language-image pre-training model (CLIP), our research shows that the CLIP prior helps differentiate between rainy and clear images. Building on this, we reformulate the Schrödinger bridge problem as a series of adversarial learning tasks using both image and prompt representations. To our knowledge, our approach is the first to use the Schrödinger bridge in unpaired image deraining. Extensive experiments show that our proposed NSB model outperforms existing unpaired deraining methods in both quantitative and qualitative evaluations.},
  archive      = {J_ISCI},
  author       = {Yuanbo Wen and Tao Gao and Ting Chen},
  doi          = {10.1016/j.ins.2024.121199},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121199},
  shortjournal = {Inf. Sci.},
  title        = {Neural schrödinger bridge for unpaired real-world image deraining},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SKYPER: Legal case retrieval via skeleton-aware hypergraph
embedding in the hyperbolic space. <em>ISCI</em>, <em>682</em>, 121162.
(<a href="https://doi.org/10.1016/j.ins.2024.121162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legal Case Retrieval (LCR) plays a significant role in ensuring judicial justice in various legal systems and has recently received increasing attention in Information Retrieval (IR) research. Existing LCR methods typically encode documents into low-dimensional vectors by using either bag of keywords or pretrained language models. However, such approaches generally overlook the interactions among numerous cases and the hierarchy skeleton between event and event type. In this paper, we propose to construct an event-aware knowledge hypergraph for representing legal cases. And we put forward a SK eleton-aware h YPER graph representation framework named SKYPER , to learn the case embeddings. Concretely, a global skeleton aggregates coarse-grained type information and roughly locates a case. A local skeleton learns the fine-grained information and precisely locates a case. And SKYPER also uses hyperbolic space strengthens the hierarchy between event and event type and avoids vocabulary mismatch. At the retrieval stage, the SKYPER learned case embedding is leveraged for further case similarity matching with a few annotated similarity ranking data. Extensive experiments demonstrate that SKYPER outperforms existing models on the public LCR datasets LeCard and COLIEE20-T1 in both supervised and unsupervised settings. Especially, the retrieval efficiency is improved by a large margin.},
  archive      = {J_ISCI},
  author       = {Shiyao Yan and Zequn Zhang},
  doi          = {10.1016/j.ins.2024.121162},
  journal      = {Information Sciences},
  month        = {11},
  pages        = {121162},
  shortjournal = {Inf. Sci.},
  title        = {SKYPER: Legal case retrieval via skeleton-aware hypergraph embedding in the hyperbolic space},
  volume       = {682},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Social network group decision-making method based on
stochastic multi-criteria acceptability analysis for probabilistic
linguistic term sets. <em>ISCI</em>, <em>681</em>, 121269. (<a
href="https://doi.org/10.1016/j.ins.2024.121269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In social network group decision-making (SNGDM) problems, decision-makers (DMs) often express their opinions or preferences using probabilistic linguistic term sets (PLTSs). In this paper, a novel SNGDM method for probabilistic linguistic information is proposed. Firstly, to obtain the prioritization of DMs in the clustering process, a DM clustering method for SNGDM is developed considering the influence of trust relationships and opinions similarity among DMs. Then, to satisfy the requirements of the consensus reaching process in SNGDM, a dynamic consensus threshold calculation method based on an optimization model is introduced. Furthermore, in the consensus measure stage, a novel consensus measure method for both DMs and subgroups is proposed, using a stochastic multi-criteria acceptability analysis (SMAA) method. Based on the consensus measure method, a novel SNGDM method based on SMAA for PLTSs is proposed. Finally, a case study of service quality evaluation in institutional pensions is used to illustrate the effectiveness of the proposed method. The results of case show that the proposed method can adjust consensus thresholds dynamically based on each round of collective opinions, and can solve the SNGDM problems when DMs can not provide their preferences for criteria weights.},
  archive      = {J_ISCI},
  author       = {Zhiwei Xu and Haiyan Xu and Peng Li and Cuiping Wei},
  doi          = {10.1016/j.ins.2024.121269},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121269},
  shortjournal = {Inf. Sci.},
  title        = {Social network group decision-making method based on stochastic multi-criteria acceptability analysis for probabilistic linguistic term sets},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MFTM-informer: A multi-step prediction model based on
multivariate fuzzy trend matching and informer. <em>ISCI</em>,
<em>681</em>, 121268. (<a
href="https://doi.org/10.1016/j.ins.2024.121268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-step forecasting is a critical process in various fields, such as disaster warning and financial analysis. Nevertheless, achieving precise multi-step forecasting is challenging due to the intricate nature of the factors influencing the time series, most of which are highly nonlinear and nonstationary. In this paper, a multi-step forecasting model named MFTM-Informer, employing a multiple input multiple output strategy for multivariate trend matching is proposed. The dependent variable and the influencing factors are initially decomposed using multivariate variational modal decomposition to minimize noise. Afterwards, the decomposed data are reconstructed into multivariate trends and fluctuations using sample entropy, enabling the development of tailored forecasting strategies based on data characteristics. A multivariate trend is predicted using an enhanced pattern matching model, while the high-frequency fluctuation is modelled using Informer. Finally, the outcomes are combined to generate multi-step predictions. To validate the performance of the proposed model, we observed its performance on three real-world datasets, including Brent crude oil prices, European Union Allowance future prices, and Standard &amp; Poor’s 500 index. Results indicate that the model surpasses all the benchmark models in terms of multiple evaluation metrics and forecast ranges, highlighting its effectiveness and robustness in multi-step forecasting.},
  archive      = {J_ISCI},
  author       = {Lu-Tao Zhao and Yue Li and Xue-Hui Chen and Liu-Yi Sun and Ze-Yu Xue},
  doi          = {10.1016/j.ins.2024.121268},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121268},
  shortjournal = {Inf. Sci.},
  title        = {MFTM-informer: A multi-step prediction model based on multivariate fuzzy trend matching and informer},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Class incremental learning with KL constraint and
multi-strategy exemplar selection for classification based on MMFA
model. <em>ISCI</em>, <em>681</em>, 121266. (<a
href="https://doi.org/10.1016/j.ins.2024.121266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class incremental learning (CIL) can learn new classes continuously by updating the model rather than retraining a model from scratch with all seen classes like traditional offline learning, therefore, CIL is more suitable for classification in dynamic environments, where new classes are captured progressively. However, the key knowledge of old classes will be lost due to the update mode of CIL, leading to the catastrophic forgetting (CF) problem. In this paper, a novel CIL method with Kullback-Leibler constraint and multi-strategy exemplar selection (CIL-KLMES) is proposed for classification based on max-margin factor analysis (MMFA) model. To handle the CF problem, CIL-KLMES imposes a Kullback-Leibler (KL) divergence term on the important parameters when updating the model to restrict the parameters&#39; distribution to be similar, thus preventing the updated model from deviating too much from the previous model and preserving the knowledge of old classes. Moreover, CIL-KLMES selects a few representative exemplars from old classes based on the robust description of data distribution and classification decision boundary. By replaying representative exemplars to update the model together with new class data, the key knowledge of old classes can be further preserved. Therefore, the CF problem can be alleviated sufficiently. Experimental results demonstrate the effectiveness of CIL-KLMES.},
  archive      = {J_ISCI},
  author       = {Yang Li and Lan Du and Jian Chen},
  doi          = {10.1016/j.ins.2024.121266},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121266},
  shortjournal = {Inf. Sci.},
  title        = {Class incremental learning with KL constraint and multi-strategy exemplar selection for classification based on MMFA model},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast correntropy-based multi-view clustering with prototype
graph factorization. <em>ISCI</em>, <em>681</em>, 121256. (<a
href="https://doi.org/10.1016/j.ins.2024.121256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a consequence of the ability to incorporate information from different perspectives, multi-view clustering has gained significant attention. Nevertheless, 1) its high computational cost, particularly when processing large-scale and high-dimensional multi-view data, restricts its applications in practice; and 2) complex noise in real-world data also challenges the robustness of existing algorithms. To tackle the above challenges, we develop a fast correntropy-based multi-view clustering algorithm with prototype graph factorization (FCMCPF). FCMCPF first adopts prototype graphs to effectively mitigate the complexity associated with graph construction, thereby reducing it from a quadratic complexity to a linear one. Then, it decomposes these prototype graphs under the correntropy criterion to robustly find the cluster indicator matrix without any post-processing. To solve the non-convex and non-linear model, we devise a fast half-quadratic-based strategy to first convert it into a convex formulation and then swiftly complete the optimization via the matrix properties of orthogonality and trace. The extensive experiments conducted on noisy and real-world datasets illustrate that FCMCPF is highly efficient and robust compared to other advanced algorithms, with comparable or even superior clustering effectiveness.},
  archive      = {J_ISCI},
  author       = {Ben Yang and Jinghan Wu and Xuetao Zhang and Zhiping Lin and Feiping Nie and Badong Chen},
  doi          = {10.1016/j.ins.2024.121256},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121256},
  shortjournal = {Inf. Sci.},
  title        = {Fast correntropy-based multi-view clustering with prototype graph factorization},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dual-topological graph memory network for anti-noise
multivariate time series forecasting. <em>ISCI</em>, <em>681</em>,
121253. (<a href="https://doi.org/10.1016/j.ins.2024.121253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series (MTS) forecasting plays an essential role in the automation and optimization process of intelligent applications. However, capturing correlations and dependencies among variables in MTS data remains a major challenge for the forecasting models. Although existing methods explain these complex relationships by deeply analyzing variables and intervariable dependencies in MTS data, they tend to be affected by the noise interference prevalent in real-world data, which increases the difficulty for forecasting models to characterize the real features, and thus makes it difficult to achieve satisfactory forecasting results. To address these challenges, this paper designs a dual-topological graph memory (DualGM) network for anti-noise multivariate time series forecasting. The core idea is to analyze the complex relationships in MTS data in detail by constructing dual-topological graphs and to learn and retain the comprehensive information of sequence features by employing a bidirectional self-attention memory module. Specifically, the model first constructs the MTS data as a graph structure and creates a probability topological graph and a distance topological graph based on the similarity between the samples, which helps the model recognize and filter the noise more efficiently in noisy environments, and valuable information is extracted from the noisy data. Then, the topological neighborhood features of the MTS data in each layer are summarized via multilayer graph groups, and the probability and distance spatial information is fused using a bidirectional self-attention mechanism to further enhance the memory and retention of the topological features, thus improving the accuracy of the forecasting model. The experimental results on four real datasets demonstrate that the DualGM model outperforms previously reported methods under various settings; in particular, the RSE values of the DualGM model are higher than those of the second-best results by 12%, 37%, 0.8% and 16% on the four datasets. Moreover, the DualGM model provides a valuable solution for multivariate time series forecasting under noise interference.},
  archive      = {J_ISCI},
  author       = {Minglan Zhang and Linfu Sun and Jing Yang and Yisheng Zou},
  doi          = {10.1016/j.ins.2024.121253},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121253},
  shortjournal = {Inf. Sci.},
  title        = {A dual-topological graph memory network for anti-noise multivariate time series forecasting},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep fair clustering with multi-level decorrelation.
<em>ISCI</em>, <em>681</em>, 121252. (<a
href="https://doi.org/10.1016/j.ins.2024.121252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fair clustering aims to prevent sensitive attributes (e.g., race or gender) from dominating the clustering process. However, real-world datasets, often characterized by low quality and high dimensionality, restrict existing fair clustering methods from achieving satisfactory outcomes. Typically, these sensitive attributes are intricately intertwined with other attributes in high-dimensional continuous data, forming backgrounds or entities within the data. The integration results in a significant correlation of features and samples across different clusters, thereby hindering the model&#39;s ability to explore the intrinsic structure. To address these issues, we propose a novel fair clustering method that incorporates multi-level decorrelation constraints. Our goal is to extract inherent fair structural information under the interference of sensitive attributes, enhancing both the validity and fairness of the model. Specifically, we introduce a new cluster-wise similarity metric based on the partition correlation coefficient, which facilitates cluster-level decorrelation and captures cluster-discriminative properties. Furthermore, by incorporating softmax-formulated decorrelation at the sample-level and feature-level , we concurrently explore representations that favor fairness. These three components are seamlessly integrated into our clustering framework, yielding a more robust and confident data partition. Experiments conducted on six commonly-used datasets demonstrate the effectiveness of our proposed method.},
  archive      = {J_ISCI},
  author       = {Xiang Wang and Liping Jing and Huafeng Liu and Jian Yu and Weifeng Geng and Gencheng Ye},
  doi          = {10.1016/j.ins.2024.121252},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121252},
  shortjournal = {Inf. Sci.},
  title        = {Deep fair clustering with multi-level decorrelation},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Three-way open intent classification with nearest
centroid-based representation. <em>ISCI</em>, <em>681</em>, 121251. (<a
href="https://doi.org/10.1016/j.ins.2024.121251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open intent classification aims to identify the unknown (open) intents and simultaneously classify the known ones under the open-world assumption. However, the existing studies still face two challenges, i.e., coarse-grained representation learning and uncertain decision boundary. On the one hand, previous methods viewed each class as a unified entity during representation learning, which fails to capture the fine-grained intra-class data structure. On the other hand, traditional two-way decision for open classification struggle to classify the uncertain samples distributed at the edge of the decision boundary, increasing the risk of misclassification. To overcome these limitations, we present a three-way open intent classification method that utilizes the nearest centroid to learn representations, named 3WNC-Open. Specifically, we learn a structured representation by extracting fine-grained information from the sub-classes within each class. Then, we design a three-way open classification strategy to handle uncertainty, initially identifying uncertain samples and then processing them using an effective alternative approach. Experiments on challenging datasets demonstrate that 3WNC-Open outperforms strong baselines.},
  archive      = {J_ISCI},
  author       = {Yanhua Li and Jiafen Liu and Longhao Yang and Chaofan Pan and Xiangkun Wang and Xin Yang},
  doi          = {10.1016/j.ins.2024.121251},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121251},
  shortjournal = {Inf. Sci.},
  title        = {Three-way open intent classification with nearest centroid-based representation},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy langevin fractional delay differential equations under
granular derivative. <em>ISCI</em>, <em>681</em>, 121250. (<a
href="https://doi.org/10.1016/j.ins.2024.121250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analytical studies of the class of the fuzzy Langevin fractional delay differential equations (FLFDDEs) are frequently complex and challenging. It is necessary to construct an effective technique for the solution of FLFDDEs. This article presents an explicit analytical representation of the solution to the class of FLFDDEs with the general fractional orders under granular differentiability. The closed-form solution to the FLFDDEs is extracted for both the homogeneous and non-homogeneous cases using the Laplace transform technique and presented in terms of the delayed Mittag-Leffler type function with double infinite series. Moreover, the existence and uniqueness of the solutions of the FLFDDEs are investigated using the generalized contraction principle. An illustrative example is provided to support the proposed technique. To add to the originality of the presented work, the FLFDDEs with constant delay are solved by applying vibration theory and visualizing their graphs to support the theoretical results.},
  archive      = {J_ISCI},
  author       = {Ghulam Muhammad and Muhammad Akram and Nawab Hussain and Tofigh Allahviranloo},
  doi          = {10.1016/j.ins.2024.121250},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121250},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy langevin fractional delay differential equations under granular derivative},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Effective semi-supervised graph clustering with pairwise
constraints. <em>ISCI</em>, <em>681</em>, 121249. (<a
href="https://doi.org/10.1016/j.ins.2024.121249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised graph clustering with constraints has received considerable attention in the last decade. They use pre-given constraints to guide the clustering process and improve the performance. Nonetheless, most of related research works still face two main issues: (1) cannot-link problem: how to ensure that instances under the cannot-link constraint are located in different clusters as much as possible. (2) The high computational cost caused by eigendecomposition. To tackle these problems, this paper proposes a novel method for directly solving the clustering indicator matrix without high complexity computational steps. Then, we propose an effective and simple algorithm guided by the pre-given constraints, which is able to simultaneously optimize the associated multiple pairs of constraints, allowing the associated constraints to achieve the related co-optimal solution. Extensive experiments are conducted to verify that our approach significantly reduces the violation rate of the prior constraints and the clustering performance of the proposed method outperforms seven other state-of-the-art semi-supervised clustering methods on 16 real benchmark datasets.},
  archive      = {J_ISCI},
  author       = {Jingwei Chen and Shiyu Xie and Hui Yang and Feiping Nie},
  doi          = {10.1016/j.ins.2024.121249},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121249},
  shortjournal = {Inf. Sci.},
  title        = {Effective semi-supervised graph clustering with pairwise constraints},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Decisions on blockchain adoption and echelon utilization in
the closed-loop supply chain for electric vehicles under carbon trading
policy. <em>ISCI</em>, <em>681</em>, 121247. (<a
href="https://doi.org/10.1016/j.ins.2024.121247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid increase in ownership of new energy vehicles has resulted in a surge in retired power batteries, necessitating the development of an efficient recycling system. Given the application of blockchain in recycling, we analyze the blockchain adoption and echelon utilization decisions for the manufacturer in a closed-loop supply chain under the carbon trading policy and offer four distinct models: 1) without echelon utilization and without blockchain, 2) without echelon utilization but with blockchain, 3) echelon utilization without blockchain, and 4) echelon utilization with blockchain. Equilibrium decisions and profits are derived across these models. The results show: adopting blockchain technology is consistently the optimal choice for the manufacturer irrespective of echelon utilization business, and can enhance the recycling quantity. The manufacturer’s decision regarding echelon utilization depends on the recycling competition coefficient between the manufacturer and the echelon utilizer. If the competition coefficient falls below a threshold, the manufacturer engages in echelon utilization business; Otherwise, the manufacturer refrains from engaging in echelon utilization activities. The carbon emission reduction level is independent of the manufacturer’s involvement in echelon utilization but is improved by the adoption of blockchain. Additionally, conducting Nash negotiation on profit allocation is beneficial for both members.},
  archive      = {J_ISCI},
  author       = {Chuan Zhang and Jian-Chi Li and Yu-Xin Tian and He-Shuang Li},
  doi          = {10.1016/j.ins.2024.121247},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121247},
  shortjournal = {Inf. Sci.},
  title        = {Decisions on blockchain adoption and echelon utilization in the closed-loop supply chain for electric vehicles under carbon trading policy},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Single sample-oriented attribute reduction for rule learning
with formal concept analysis. <em>ISCI</em>, <em>681</em>, 121243. (<a
href="https://doi.org/10.1016/j.ins.2024.121243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective tool for data mining, formal concept analysis can yield interpretable decision rules using attribute reduction. Currently, existing reduction methods within the framework of formal concept analysis result in all samples sharing the same conditional attributes, thereby overlooking the distinctions between rules extracted from different samples. To address this problem, we present a novel attribute reduction method for single samples. For this purpose, a single sample-oriented reduction framework is established by incorporating a discernibility attribute vector and an algorithm for calculating reducts based on the matrix representation of the discernibility attribute vector. Furthermore, the process of obtaining a new reduct from the original reduct is discussed by considering incremental learning. Given that attributes included in reducts are crucial conditions for decision-making, intent-minimal granular rules are generated through attribute reduction, and a reduction-based method for measuring the completeness of the rule set is discussed. Finally, to accomplish the classification task, a minimal rule-based classification model (MRCM) is proposed. The experimental results show that the MRCM has the same classification ability as the unreduced rules, and the rules with higher completeness tend to exhibit better classification performance.},
  archive      = {J_ISCI},
  author       = {Jiaojiao Niu and Degang Chen and Wenyan Tie},
  doi          = {10.1016/j.ins.2024.121243},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121243},
  shortjournal = {Inf. Sci.},
  title        = {Single sample-oriented attribute reduction for rule learning with formal concept analysis},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anomaly detection with dual-channel heterogeneous graph
based on hypersphere learning. <em>ISCI</em>, <em>681</em>, 121242. (<a
href="https://doi.org/10.1016/j.ins.2024.121242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection is essential for identifying irregular patterns and outliers within complex network structures in domains like social networks, cybersecurity, finance, and transportation systems. It helps detect security breaches, fraud, and errors, improving decision-making and system reliability. Although current methodologies have advanced the unsupervised detection of graph anomalies, they frequently fail to fully address the nuanced specificities of graph anomalies, such as anomalous nodes, edges, and subgraphs. To overcome this limitation, the study presents MulDualGNN, a unique dual-channel heterogeneous graph anomaly detection framework. MulDualGNN incorporates a global substructure-aware GNN and a local substructure-aware GNN to capture both global and local substructure properties for accurate anomaly detection. Our model incorporates a multi-hypersphere learning target function, which includes macroscopic and mesoscopic hyperspheres. These hyperspheres measure abnormal nodes that deviate from most normal nodes in the entire graph and community structure, respectively. To overcome the model collapse problem in multi-hypersphere learning, our model utilizes the EmbSim similarity function to optimize the training target. The effectiveness and performance advantages of the proposed method are evaluated through extensive experiments on five datasets. The results demonstrate the superior performance of our approach in graph anomaly detection tasks.},
  archive      = {J_ISCI},
  author       = {Qing Li and Guanzhong Wu and Hang Ni and Tao You},
  doi          = {10.1016/j.ins.2024.121242},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121242},
  shortjournal = {Inf. Sci.},
  title        = {Anomaly detection with dual-channel heterogeneous graph based on hypersphere learning},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive fuzzy quantized prescribed performance
synchronization of uncertain non-strict feedback chaotic systems with
time-varying actuator failure. <em>ISCI</em>, <em>681</em>, 121241. (<a
href="https://doi.org/10.1016/j.ins.2024.121241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses an adaptive fuzzy prescribed performance synchronization for a class of uncertain non-strict feedback chaotic systems subject to input quantization and time-varying actuator faults. The proposed approach utilizes fuzzy logic systems to estimate uncertainties. In addition, multiplicative and additive faults are considered simultaneously, which may occur either separately or simultaneously. To address the challenge, based on the backstepping scheme and a filter, an intermediate controller is conducted to compensate for the interference between actuator faults and quantification, in which a damping term and a positive time-varying function are introduced. Moreover, treating the error system as a constrained system, a simplified nonlinear mapping is employed to achieve asymmetric prescribed performance synchronization. Unlike traditional methods that rely on barrier Lyapunov functions and switch functions, the proposed approach eliminates the need for a switch function and extends the action scope to cover all synchronization errors. The analysis demonstrates that even if actuator faults and input quantization coexist, all signals in the closed-loop system remain bounded, and synchronization errors remain within the prescribed performance range. Finally, synchronization simulations are conducted on a nonlinear gyroscope system and a Non-autonomous chaotic Micro-Electro-Mechanical-System to reveal the validity of the proposed scheme.},
  archive      = {J_ISCI},
  author       = {Hanlin Dong and Chengdai Huang and Jinde Cao and Heng Liu},
  doi          = {10.1016/j.ins.2024.121241},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121241},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fuzzy quantized prescribed performance synchronization of uncertain non-strict feedback chaotic systems with time-varying actuator failure},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collaborative filtering with representation learning in the
frequency domain. <em>ISCI</em>, <em>681</em>, 121240. (<a
href="https://doi.org/10.1016/j.ins.2024.121240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of recommender systems, collaborative filtering is the method of predicting the ratings of a set of items given by a set of users based on partial knowledge of the ratings. Commonly, items and users are represented via vectors, and to predict ratings, approaches such as vector inner-product (aka matrix factorization) or more advanced nonlinear functions are applied. In this paper, while we adopt the common vectorial representation, we consider a general model in which the ratings are smooth functions of the item representations. Smoothness ensures similar items with nearby vectors will also get similar ratings as we expect from a human rater. We represent user smooth scoring functions in a so-called frequency domain and learn their representations alongside item representations using 1) an iterative optimization approach that maps items and users alternatively, and 2) a feedforward neural network consisting of interpretable layers. We also address the challenge of the distribution shift from observed to unobserved ratings (aka missing-not-at-random) with insights from the frequency domain. We evaluate the predictive power of our method and its robustness in missed-not-at-random settings on four popular benchmarks. Despite its simplicity and interpretability, our method yields a remarkable performance compared to the state-of-the-art. 1},
  archive      = {J_ISCI},
  author       = {Ali Shirali and Reza Kazemi and Arash Amini},
  doi          = {10.1016/j.ins.2024.121240},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121240},
  shortjournal = {Inf. Sci.},
  title        = {Collaborative filtering with representation learning in the frequency domain},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Entropy-based guidance of deep neural networks for
accelerated convergence and improved performance. <em>ISCI</em>,
<em>681</em>, 121239. (<a
href="https://doi.org/10.1016/j.ins.2024.121239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks have dramatically increased our capacity to learn from large, high-dimensional datasets across innumerable disciplines. However, their decisions are not easily interpretable, their computational costs are high, and building and training them are not straightforward processes. To add structure to these efforts, we derive new mathematical results to efficiently measure the changes in entropy as fully-connected and convolutional neural networks process data. By measuring the change in entropy as networks process data effectively, patterns critical to a well-performing network can be visualized and identified. Entropy-based loss terms are developed to improve dense and convolutional model accuracy and efficiency by promoting the ideal entropy patterns. Experiments in image compression, image classification, and image segmentation on benchmark datasets demonstrate these losses guide neural networks to learn rich latent data representations in fewer dimensions, converge in fewer training epochs, and achieve higher accuracy.},
  archive      = {J_ISCI},
  author       = {Mackenzie J. Meni and Ryan T. White and Michael L. Mayo and Kevin R. Pilkiewicz},
  doi          = {10.1016/j.ins.2024.121239},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121239},
  shortjournal = {Inf. Sci.},
  title        = {Entropy-based guidance of deep neural networks for accelerated convergence and improved performance},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving technical efficiency in data envelopment analysis
for efficient firms: A case on chinese banks. <em>ISCI</em>,
<em>681</em>, 121237. (<a
href="https://doi.org/10.1016/j.ins.2024.121237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data Envelopment Analysis (DEA) as a data-oriented benchmarking tool is considered a powerful and promising instrument for performance evaluation in various application areas. In DEA, the set of all decision-making units (DMUs) is divided into efficient and inefficient subsets. Inefficient DMUs are improved by reducing the input and/or increasing the output, and as far as we know, efficient DMUs are abandoned with the conclusion that they are all technically and relatively efficient, and no further analysis has been suggested in the literature. In this article, we first show that there is a gap between the actual efficiency and the efficiency estimated using benchmarking tools such as DEA. This means that there is no guarantee that the efficient DMUs characterized by DEA are really efficient. Thus, there is a gap in improving the technical efficiency of efficient DMUs. In this paper, we attempt to close this gap by introducing a method to improve efficient DMUs. First, we introduce a random variable as a corrector of efficiency evaluation, and then an inverse DEA model (IDEA) is proposed to improve efficient DMUs. To demonstrate the actual applicability of the proposed approach, we present an illustrative empirical application using 106 Chinese bank data from 2021.},
  archive      = {J_ISCI},
  author       = {Alireza Amirteimoori and Tofigh Allahviranloo},
  doi          = {10.1016/j.ins.2024.121237},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121237},
  shortjournal = {Inf. Sci.},
  title        = {Improving technical efficiency in data envelopment analysis for efficient firms: A case on chinese banks},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Harnessing membership function dynamics for stability
analysis of t-s fuzzy systems. <em>ISCI</em>, <em>681</em>, 121236. (<a
href="https://doi.org/10.1016/j.ins.2024.121236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main goal of this paper is to develop a new less conservative linear matrix inequality (LMI) condition for the asymptotic stability of continuous-time Takagi-Sugeno fuzzy systems. A key advantage of this new condition is its independence from the bounds on the time-derivatives of the membership functions (MFs), a requirement that presents in the existing approaches. This is achieved by introducing a novel fuzzy Lyapunov function that incorporates an augmented state vector. Notably, this augmented state vector includes MFs and allows their dynamics to be integrated into the proposed LMI condition. This inclusion of additional information about MFs reduces the conservativeness of the suggested stability condition. Finally, examples are given to demonstrate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Donghwan Lee and Do Wan Kim},
  doi          = {10.1016/j.ins.2024.121236},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121236},
  shortjournal = {Inf. Sci.},
  title        = {Harnessing membership function dynamics for stability analysis of T-S fuzzy systems},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Carbon emissions forecasting based on tensor decomposition
with multi-source data fusion. <em>ISCI</em>, <em>681</em>, 121235. (<a
href="https://doi.org/10.1016/j.ins.2024.121235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately forecasting carbon dioxide emissions is crucial for policymakers and researchers aiming to combat climate change and develop effective emission reduction strategies. This study introduces an innovative method that leverages multi-source social media information to address the challenges of insufficient information and data uncertainty in carbon emission time series forecasting. We propose a combined Tensor-LSTM-ARIMA model for predicting carbon emissions, utilizing tensor decomposition data analysis methods. The results indicate that this combined model effectively captures the complex relationships within heterogeneous data, outperforming baseline models in prediction accuracy. Furthermore, the study demonstrates that unstructured social media data can enhance structured time series data, providing a new perspective for comprehensively understanding the variables influencing carbon emission predictions.},
  archive      = {J_ISCI},
  author       = {Xiaofeng Xu and Xiaoxi Cao and Lean Yu},
  doi          = {10.1016/j.ins.2024.121235},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121235},
  shortjournal = {Inf. Sci.},
  title        = {Carbon emissions forecasting based on tensor decomposition with multi-source data fusion},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bipartite containment control of multi-agent systems subject
to adversarial inputs based on zero-sum game. <em>ISCI</em>,
<em>681</em>, 121234. (<a
href="https://doi.org/10.1016/j.ins.2024.121234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate bipartite containment control problem of multi-agent systems (MASs) with signed directed graph under adversarial inputs. Firstly, we define the bipartite containment error and establish the equivalence between the bipartite containment error converging to zero and the achievement of bipartite containment control. Subsequently, we prove that the bounded L 2 L2 -gain bipartite containment problem under adversarial inputs can be reformulated as a multi-player zero-sum differential graphical game problem and can be solved via the solution to the coupled Hamilton-Jacobi-Isaacs (HJI) equation. To address this, we propose a policy iteration (PI) algorithm and prove its convergence under different updating cases. The proposed algorithm is implemented by neural networks (NNs) and a numerical simulation example is provided to show its effectiveness.},
  archive      = {J_ISCI},
  author       = {Sijia Fan and Feng Peng and Xiaokun Liu and Tong Wang and Jianbin Qiu},
  doi          = {10.1016/j.ins.2024.121234},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121234},
  shortjournal = {Inf. Sci.},
  title        = {Bipartite containment control of multi-agent systems subject to adversarial inputs based on zero-sum game},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient semi-supervised clustering with pairwise
constraint propagation for multivariate time series. <em>ISCI</em>,
<em>681</em>, 121233. (<a
href="https://doi.org/10.1016/j.ins.2024.121233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised clustering is an effective method, which improves the clustering performance based on pairwise constraints. However, state-of-the-art methods suffer from two issues: 1) due to the high dimensionality and multiple variables of multivariate time series (MTS) data, the competitive similarity approach DTW is time consuming on large-scale MTS data. 2) Traditional semi-supervised clustering methods could not make full use of pairwise constraints information, which affects clustering performance. To deal with these issues, we propose an efficient semi-supervised clustering with pairwise constraint propagation for MTS data. First, two approximate distance measure methods are designed based on dynamic time warping (DTW) from the perspectives of boundary and dimension reduction, which greatly improve the efficiency of clustering without sacrificing its accuracy. Then, a graph-based clustering method with pairwise constraints propagation (GCPCP) is advanced on multivariate time series data. In GCPCP, the pairwise constraint propagation matrix and the affinity matrix are jointly optimized to exploit the dependence between them, which finally improves the clustering performance. Experimental results on 12 multivariate time series datasets show the effectiveness and efficiency of our proposed method.},
  archive      = {J_ISCI},
  author       = {Guoliang He and Dawei Jin and Wenjun Jiang and Zongkun Zhao and Lifang Dai and Zhiwen Yu and C.L. Philip Chen},
  doi          = {10.1016/j.ins.2024.121233},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121233},
  shortjournal = {Inf. Sci.},
  title        = {Efficient semi-supervised clustering with pairwise constraint propagation for multivariate time series},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attributed graph clustering under the contrastive mechanism
with cluster-preserving augmentation. <em>ISCI</em>, <em>681</em>,
121225. (<a href="https://doi.org/10.1016/j.ins.2024.121225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attributed graph clustering is a fundamental task in complex network analysis. Many existing graph clustering methods utilize graph representation learning techniques to learn node representations, subsequently applying K-means for clustering. Despite the significant attention and promising outcomes of graph contrastive learning in graph representation learning, we find two essential problems that need to be solved. (1) How to achieve augmentation for contrast that preserves the cluster structure of a given graph? (2) How to design an effective contrastive learning mechanism that collaborates with clustering? Therefore, we propose an attributed graph clustering method under the contrastive mechanism with cluster-preserving augmentation, integrating node representation learning and clustering into a unified framework. Specifically, we construct a contrasting view based on a generated k NN graph and edge betweenness centrality to preserve the cluster structure in the original graph. Meanwhile, a multilevel contrast mechanism based on pseudo-label-guided negative sampling is proposed to maximize the agreement between node representations in multiple latent spaces. We jointly optimize a specific clustering objective during the contrastive process, leading to refined cluster distribution directly in training. Extensive experiments on several datasets demonstrate that our proposed model consistently outperforms existing state-of-the-art methods on clustering.},
  archive      = {J_ISCI},
  author       = {Yimei Zheng and Caiyan Jia and Jian Yu},
  doi          = {10.1016/j.ins.2024.121225},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121225},
  shortjournal = {Inf. Sci.},
  title        = {Attributed graph clustering under the contrastive mechanism with cluster-preserving augmentation},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Structure modification based PID neural network decoupling
control for nonlinear multivariable systems. <em>ISCI</em>,
<em>681</em>, 121222. (<a
href="https://doi.org/10.1016/j.ins.2024.121222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, a structure modification based PID neural network (PIDNN) decoupling strategy is proposed to solve the difficulty in controller caused by the strong coupling in nonlinear multivariable systems. Incomplete differential neurons are first introduced into the hidden layer of the PIDNN, which achieving a decreased amount of control overshoot and better control stability. Then, an improved integration strategy is incorporated in the hidden layer structure, resulting in expedited convergence speed in the PIDNN control. Furthermore, intelligent optimization algorithms are employed to improve the convergence rate of the proposed PIDNN. The stability of the proposed controller is analyzed, and an adaptive learning rate scheme is derived. Finally, to confirm the effectiveness of the controller, three examples and the analysis of experimental results are provided.},
  archive      = {J_ISCI},
  author       = {Luocheng Yang and Jie Ding and Hui Ge},
  doi          = {10.1016/j.ins.2024.121222},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121222},
  shortjournal = {Inf. Sci.},
  title        = {Structure modification based PID neural network decoupling control for nonlinear multivariable systems},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Relation coarsest partition method to observability of
probabilistic boolean networks. <em>ISCI</em>, <em>681</em>, 121221. (<a
href="https://doi.org/10.1016/j.ins.2024.121221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using the relational coarsest partition (RCP) method, this article aims to study the observability problem of probabilistic Boolean networks (PBNs). The key step to solving this problem is to find the parallel cycle and the coarsest refinement partition of the given initial partition. Firstly, several definitions of observability for PBNs are proposed, and the connections between finite-time observability with positive probability (FTOPP), asymptotical observability (AO), and finite-time observability with probability one (FTOPO) are revealed. Secondly, by defining the appropriate transition relation, the RCP method is introduced into PBNs. In addition, based on the output signal mapping set, the initial partition is constructed. Thirdly, the concept of a parallel cycle for PBNs is proposed, and two algorithms are presented for computing the cycle and parallel cycle of PBNs. Moreover, with the help of the RCP method, a series of criteria are derived to solve the observability problem of PBNs, which works more efficiently. Fourth, when PBN is unobservable, an algorithm is proposed to design the state-flipping set with the smallest number of states, which can make the unobservable PBN observable. To show the validity and effectiveness of the obtained results, examples are finally given.},
  archive      = {J_ISCI},
  author       = {Yalu Li and Haitao Li},
  doi          = {10.1016/j.ins.2024.121221},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121221},
  shortjournal = {Inf. Sci.},
  title        = {Relation coarsest partition method to observability of probabilistic boolean networks},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Asynchronous SGD with stale gradient dynamic adjustment for
deep learning training. <em>ISCI</em>, <em>681</em>, 121220. (<a
href="https://doi.org/10.1016/j.ins.2024.121220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Asynchronous stochastic gradient descent (ASGD) is a computationally efficient algorithm, which speeds up deep learning training and plays an important role in distributed deep learning. However, ASGD suffers from the stale gradient problem, i.e., the gradient of worker may mismatch the weight of parameter server. This problem seriously affects the model performance and even causes the divergence. To address this issue, this paper designs a dynamic adjustment scheme via the momentum algorithm, which uses both stale penalty and stale compensation , i.e., stale penalty is to reduce the trust in stale gradient, stale compensation is to compensate the hurt of stale gradient. Based on this dynamic adjustment scheme, this paper proposes a dynamic asynchronous stochastic gradient descent algorithm (DASGD), which dynamically adjusts the compensation factor and the penalty factor via stale size. Moreover, we prove that DASGD is convergent under some mild assumptions. Finally, we build a real distributed training cluster to evaluate our DASGD on Cifar10 and ImageNet datasets. Compared with four SOTA baselines, experiment results confirm the superior performance of DASGD. More specifically, our DASGD has nearly the same test accuracy as SGD on Cifar10 and ImageNet , and only uses around 27.6% and 40.8% training time that of SGD, respectively.},
  archive      = {J_ISCI},
  author       = {Tao Tan and Hong Xie and Yunni Xia and Xiaoyu Shi and Mingsheng Shang},
  doi          = {10.1016/j.ins.2024.121220},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121220},
  shortjournal = {Inf. Sci.},
  title        = {Asynchronous SGD with stale gradient dynamic adjustment for deep learning training},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Matrix-based incremental feature selection method using
weight-partitioned multigranulation rough set. <em>ISCI</em>,
<em>681</em>, 121219. (<a
href="https://doi.org/10.1016/j.ins.2024.121219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incremental feature selection methods have gained increasing research attention as they improve the efficiency of feature selection for dynamic datasets. Multigranulation rough set, as an extension of rough set theory, allows for a comprehensive and rational analysis of problems from multiple hierarchical and granular perspectives. However, existing research on granularity partitioning relies on the decision maker&#39;s subjective experience, which lacks convincing power. In this paper, we propose a generalized multigranulation neighborhood rough set based on weight partition model, using a matrix form. We discuss several properties and define a new entropy measure to evaluate feature importance. A heuristic feature selection algorithm is developed based on this entropy to search for the optimal subset. Furthermore, we discuss dynamic updating mechanism and design two incremental feature selection algorithms. Finally, we conduct experiments on 12 public datasets to evaluate the performance of the proposed algorithms and validate their effectiveness and efficiency in feature selection for both static and dynamic datasets.},
  archive      = {J_ISCI},
  author       = {Weihua Xu and Qinyuan Bu},
  doi          = {10.1016/j.ins.2024.121219},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121219},
  shortjournal = {Inf. Sci.},
  title        = {Matrix-based incremental feature selection method using weight-partitioned multigranulation rough set},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient high utility itemset mining without the join
operation. <em>ISCI</em>, <em>681</em>, 121218. (<a
href="https://doi.org/10.1016/j.ins.2024.121218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of mining high-utility itemsets in a database given a minimum threshold is attracting more and more interest due to its many applications. Existing algorithms such as the vertical ones have the advantages of high scalability, efficiency and extensibility. However, they depend on a costly join operation to generate new itemsets. To overcome this limitation, this paper proposes a novel vertical algorithm, FOTH (Fast sOrted iTemset searcH), which employs a novel effective data structure, the IndexSet. The IndexSet self-propagates to produce sub-IndexSets, eliminating the need to perform join operations, which considerably reduces the memory and computation requirements. Experiments were conducted on eight benchmark databases to compare the performance of FOTH with four state-of-the-art list-based algorithms. The results show that FOTH outperforms the other algorithms on dense databases.},
  archive      = {J_ISCI},
  author       = {Yihe Yan and Xinzheng Niu and Zhiheng Zhang and Philippe Fournier-Viger and Libin Ye and Fan Min},
  doi          = {10.1016/j.ins.2024.121218},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121218},
  shortjournal = {Inf. Sci.},
  title        = {Efficient high utility itemset mining without the join operation},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design and analysis of finite-time convergent complex-valued
zeroing neural networks with application to time-variant complex matrix
inversion. <em>ISCI</em>, <em>681</em>, 121217. (<a
href="https://doi.org/10.1016/j.ins.2024.121217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, for obtaining the inverses of time-variant complex matrices, four new kinds of recurrent neural network models [named modified finite-time convergent complex-valued zeroing neural network (MFTCVZNN) models] are put forward by constructing three different error functions. Besides, a high-performance finite-time activation function (HFTAF) is applied to the four MFTCVZNN models, which improves the comprehensive performance of the models. The analytical discussion indicates that the states of these MFTCVZNN models can tend to the time variant solutions in a limited time with the upper bound being analyzed, and the convergence efficiency is significantly improved by the application of the HFTAF. The simulation consequences validate that the analysis is correct and the MFTCVZNN models are effective for finding the inverses of time-variant complex matrices. Furthermore, comparative experiments are conducted for showing the superiority of the MFTCVZNN models in terms of convergence over the existing models.},
  archive      = {J_ISCI},
  author       = {Lin Xiao and Yunrui Xie and Qiuyue Zuo and Ping Tan and Ping Liu and Yongjun He},
  doi          = {10.1016/j.ins.2024.121217},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121217},
  shortjournal = {Inf. Sci.},
  title        = {Design and analysis of finite-time convergent complex-valued zeroing neural networks with application to time-variant complex matrix inversion},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive finite-time optimal fuzzy control for novel
constrained uncertain nonstrict feedback mixed multiagent systems via
modified dynamic surface control. <em>ISCI</em>, <em>681</em>, 121216.
(<a href="https://doi.org/10.1016/j.ins.2024.121216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the finite-time stability is discussed for the novel nonlinear mixed multiagent systems (MASs) with unmodeled dynamics and constraints. Each agent is characterized as a state or output feedback system structured in the nonstrict form. The improved finite-time dynamic surface control (DSC) and the fuzzy actor-critic networks collectively constitute a novel optimal input. The fuzzy logic systems (FLSs) is introduced to approximate the unknown parts in the derivation process. By using the nonlinear transformation rules (NTRs), all the states or output are made to operate strictly within the predefined boundary conditions. The unmodeled dynamics can be solved by the constructed dynamic signals. By the aid of the compensating signals, the filtering errors can be countervailed in the DSC. The stability analysis demonstrates that all the signals are semi-globally practical finite-time stable (SGPFS). The feasibility of this scheme is explained intuitively by two simulations.},
  archive      = {J_ISCI},
  author       = {Yu Hua and Tianping Zhang},
  doi          = {10.1016/j.ins.2024.121216},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121216},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive finite-time optimal fuzzy control for novel constrained uncertain nonstrict feedback mixed multiagent systems via modified dynamic surface control},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring view-specific label relationships for multi-view
multi-label feature selection. <em>ISCI</em>, <em>681</em>, 121215. (<a
href="https://doi.org/10.1016/j.ins.2024.121215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of multi-view multi-label (MVML) learning, features are distributed across various views, each offering multiple semantic representations. While existing approaches aim to balance commonality and complementarity within the view space, the inconsistency in label space has been underexplored, revealing the inadequacy of assuming uniform labels. Thus, there is a pressing need to explore the relationship among view-specific labels. Our method diverges from previous approaches by focusing on imposing constraints tailored to learning view-specific labels. We aim to preserve common characteristics through inter-view relationships while retaining specific traits inherent to each view&#39;s instances. By employing these strategies, we establish a clear mapping between labels and feature representations, enabling precise feature weighting. Convergence to the optimal feature set is achieved through multiplicative updating rules. Our method demonstrates superiority across most of cases through comprehensive experimental analysis compared to existing state-of-the art alternatives.},
  archive      = {J_ISCI},
  author       = {Pingting Hao and Weiping Ding and Wanfu Gao and Jialong He},
  doi          = {10.1016/j.ins.2024.121215},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121215},
  shortjournal = {Inf. Sci.},
  title        = {Exploring view-specific label relationships for multi-view multi-label feature selection},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-task evolutionary algorithm for solving the problem
of transfer targets. <em>ISCI</em>, <em>681</em>, 121214. (<a
href="https://doi.org/10.1016/j.ins.2024.121214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multi-task optimisation, aimed at handling multiple optimisation problems simultaneously, has received great attention in the field of evolutionary algorithms. Research on multi-task evolutionary algorithms mostly focuses on solving the problem of effective transfer, which usually transfers the extracted effective knowledge to the matching selection stage or environment selection stage. However, the impact of these transfer targets on algorithm performance is rarely studied. To solve the problem of transfer targets, we propose a multi-task evolutionary algorithm with a hybrid knowledge transfer strategy (MTEA-HKTS). Firstly, we determined three transfer targets and designed knowledge transfer strategies for each stage by analysing the population changes in the differential evolution algorithm. Secondly, a knowledge transfer strategy is devised to control the transfer targets. Finally, we designed a new archive update strategy that uses a distribution model constructed for recent generations of populations to calculate gene similarity. The experimental results on the multi-task benchmark problems show that the transfer targets affect the performance of the multi-task optimisation algorithm, and verify the superiority of the proposed MTEA-HKTS algorithm.},
  archive      = {J_ISCI},
  author       = {Ben Zhao and Zhihua Cui and JinQian Yang and Xingjuan Cai and Jianghui Cai and Jinjun Chen},
  doi          = {10.1016/j.ins.2024.121214},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121214},
  shortjournal = {Inf. Sci.},
  title        = {A multi-task evolutionary algorithm for solving the problem of transfer targets},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relation-preserving masked modeling for semi-supervised
time-series classification. <em>ISCI</em>, <em>681</em>, 121213. (<a
href="https://doi.org/10.1016/j.ins.2024.121213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we address the challenge of label sparsity in time-series classification using semi-supervised learning that effectively leverages numerous unlabeled instances. Our approach introduces a pioneering framework for semi-supervised time-series classification based on masked time-series modeling, a recent advancement in self-supervised learning that can effectively capture intricate temporal structures in time series. The proposed method first extracts the intrinsic semantic information from unlabeled instances by considering diverse temporal resolutions and using various masking ratios during model training. Subsequently, we combine the semantic information captured from unlabeled instances with supervisory features obtained from labeled instances that encompass hard-to-learn class information to enhance classification performance. Extensive experiments on semi-supervised time-series classification demonstrate the superiority of the proposed method by achieving state-of-the-art performance.},
  archive      = {J_ISCI},
  author       = {Sangho Lee and Chihyeon Choi and Youngdoo Son},
  doi          = {10.1016/j.ins.2024.121213},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121213},
  shortjournal = {Inf. Sci.},
  title        = {Relation-preserving masked modeling for semi-supervised time-series classification},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Q-learning based tracking control with novel finite-horizon
performance index. <em>ISCI</em>, <em>681</em>, 121212. (<a
href="https://doi.org/10.1016/j.ins.2024.121212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A data-driven method is designed to realize the model-free finite-horizon optimal tracking control (FHOTC) of unknown linear discrete-time systems based on Q-learning in this paper. First, a novel finite-horizon performance index (FHPI) that only depends on the next-step tracking error is introduced. Then, an augmented system is formulated, which incorporates with the system model and the trajectory model. Based on the novel FHPI, a derivation of the augmented time-varying Riccati equation (ATVRE) is provided. We present a data-driven FHOTC method that uses Q-learning to optimize the defined time-varying Q-function. This allows us to estimate the solutions of the ATVRE without the system dynamics. Finally, the validity and features of the proposed Q-learning-based FHOTC method are demonstrated by means of conducting comparative simulation studies.},
  archive      = {J_ISCI},
  author       = {Wei Wang and Ke Wang and Zixin Huang and Chaoxu Mu and Haoxian Shi},
  doi          = {10.1016/j.ins.2024.121212},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121212},
  shortjournal = {Inf. Sci.},
  title        = {Q-learning based tracking control with novel finite-horizon performance index},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Density-based clustering with differential privacy.
<em>ISCI</em>, <em>681</em>, 121211. (<a
href="https://doi.org/10.1016/j.ins.2024.121211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, differentially private clustering has received increasing attention. However, most existing differentially private clustering algorithms cannot achieve better results when handling non-convex datasets. To enhance knowledge extraction from data while protecting users&#39; sensitive information, we propose a density-based clustering algorithm with differential privacy. Specifically, we incorporate differential privacy mechanisms into the density-based clustering paradigm to enhance the effectiveness of differentially private clustering on non-convex datasets. Firstly, to avoid privacy leakage, we employ the Laplace mechanism for inject noise into the density during the density estimation stage. Then, we design a privacy budget allocation scheme in the cluster expansion stage to make it harder for attackers to access private information. Theoretical analysis demonstrates that our algorithm satisfies ϵ -differential privacy. Experimental outcomes in synthetic and real-world datasets show that our introduced algorithm can obtain high-quality clustering results when dealing with non-convex datasets. In the approximation experiments, it is evident that our algorithm outperforms others in terms of approximation.},
  archive      = {J_ISCI},
  author       = {Fuyu Wu and Mingjing Du and Qiang Zhi},
  doi          = {10.1016/j.ins.2024.121211},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121211},
  shortjournal = {Inf. Sci.},
  title        = {Density-based clustering with differential privacy},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel multi-modal incremental tensor decomposition for
anomaly detection in large-scale networks. <em>ISCI</em>, <em>681</em>,
121210. (<a href="https://doi.org/10.1016/j.ins.2024.121210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network traffic anomaly detection is a crucial task for today&#39;s network monitoring and maintenance. However, with the rapid growth of network data volume, the data structure has become more and more complex, showing multi-modal characteristics, which makes traffic anomaly detection face a great challenge. The earlier proposed anomaly detection methods have the following deficiencies, i ) Most of them are static or dynamic detection methods that only grow along the temporal modality. ii) Lower detection rate or higher computational cost. To address these deficiencies, this article proposes a traffic anomaly detection framework based on multi-modal incremental tensor decomposition, which has the following three highlights, i ) Constructing traffic data as a tensor model to fully mine the correlation between data, and the proposed framework is applicable to the situation where traffic data grows dynamically along multiple modes. ii) Using the multi-modal incremental tensor decomposition method to process dynamically growing data without decomposing all the data, greatly reducing computational cost and improving data quality. iii) Using the XGBoost classification algorithm for anomaly detection to improve detection accuracy. Finally, the results of experiments on two real network traffic datasets NSL-KDD and CICDDOS 2019 show that the proposed framework can achieve a high detection rate of 99.21%, and has the characteristics of good scalability and fast detection speed.},
  archive      = {J_ISCI},
  author       = {Rongqiao Fan and Qiyuan Fan and Xue Li and Puming Wang and Jing Xu and Xin Jin and Shaowen Yao and Peng Liu},
  doi          = {10.1016/j.ins.2024.121210},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121210},
  shortjournal = {Inf. Sci.},
  title        = {A novel multi-modal incremental tensor decomposition for anomaly detection in large-scale networks},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Density peaks clustering based on density voting and
neighborhood diffusion. <em>ISCI</em>, <em>681</em>, 121209. (<a
href="https://doi.org/10.1016/j.ins.2024.121209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density Peaks Clustering (DPC) is a well-known clustering technique in the data mining field with fewer parameters as well as no iteration. However, when dealing with datasets containing multiple peaks, DPC may subjectively choose the wrong cluster centers through the decision graph. Additionally, DPC requires a considerable amount of time to estimate density and relative distance. Moreover, DPC is sensitive to the value of cut-off distance. To overcome these issues, a density peaks clustering algorithm based on density voting and neighborhood diffusion (DPC-DVND) is proposed. Firstly, the proposed algorithm utilizes the k nearest neighbors and KD-tree to enhance the efficiency of computing local density and relative distance. Secondly, this study selects the potential cluster centers by density voting and applies the number of votes instead of density to calculate the feasibility of each potential center becoming a cluster center, so that the centers of low-density clusters can be better distinguished. Finally, two neighborhood density diffusion rules are designed to propagate labels and form the core structure of clusters. Experiments on synthetic, real, and image datasets are performed to compare different methods. Results show that DPC-DVND outperforms other state-of-the-art algorithms in terms of effectiveness and efficiency.},
  archive      = {J_ISCI},
  author       = {Wenke Zang and Jing Che and Linlin Ma and Xincheng Liu and Aoyu Song and Jingwen Xiong and Yuzhen Zhao and Xiyu Liu and Yawen Chen and Hui Li},
  doi          = {10.1016/j.ins.2024.121209},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121209},
  shortjournal = {Inf. Sci.},
  title        = {Density peaks clustering based on density voting and neighborhood diffusion},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combination of dependent and partially reliable gaussian
random fuzzy numbers. <em>ISCI</em>, <em>681</em>, 121208. (<a
href="https://doi.org/10.1016/j.ins.2024.121208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian random fuzzy numbers are random fuzzy sets generalizing Gaussian random variables and possibility distributions. They define belief functions on the real line that can be conveniently combined by the product-intersection rule under the independence assumption. In this paper, we introduce various extensions of this rule to account for dependence and partial reliability of the pieces of evidence. We first provide formulas for the combination of an arbitrary number of Gaussian random fuzzy numbers whose dependence is described by a correlation matrix, and we introduce a minimum-conflict combination operation. To account for partially reliable evidence, we then introduce two discounting operations called possibilistic and evidential discounting, as well as several combination operators based on different assumptions, each one parameterized by a correlation matrix and a vector of discounting coefficients. We demonstrate the application of these operators to the combination of predictions with different sets of inputs in machine learning, and show that performance can be enhanced by optimizing the parameters of the combination operators.},
  archive      = {J_ISCI},
  author       = {Thierry Denœux},
  doi          = {10.1016/j.ins.2024.121208},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121208},
  shortjournal = {Inf. Sci.},
  title        = {Combination of dependent and partially reliable gaussian random fuzzy numbers},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel auxiliary signal design algorithm for weak fault
isolation based on zonotopic optimization. <em>ISCI</em>, <em>681</em>,
121207. (<a href="https://doi.org/10.1016/j.ins.2024.121207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel active isolation method for weak faults based on zonotopes is proposed. First, a zonotopic filter is designed to estimate the system state; subsequently, an auxiliary signal is designed based on the obtained state set, and the auxiliary signal is added to both the normal and fault models to ensure that the intersection of their state sets is empty. Then, the intersection solution process is transformed into an optimization problem. Finally, simulation results from a numerical simulation and an experiment on a DC–DC circuit platform verify that the auxiliary signal designed using this method is more optimal and less conservative compared with other auxiliary signal design methods.},
  archive      = {J_ISCI},
  author       = {Zi-Yun Wang and Yu-Qian Chen and Qian-Yi Shen and Yan Wang and Ju H. Park},
  doi          = {10.1016/j.ins.2024.121207},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121207},
  shortjournal = {Inf. Sci.},
  title        = {A novel auxiliary signal design algorithm for weak fault isolation based on zonotopic optimization},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fixed-time synchronization of multilayered complex dynamic
networks via quantized variable-gain saturated control. <em>ISCI</em>,
<em>681</em>, 121206. (<a
href="https://doi.org/10.1016/j.ins.2024.121206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies fixed-time (FxT) quantitative synchronization of multilayered complex dynamic networks (CDNs). First, a new FxT stability theorem is established and two new estimations of the settling time of stability are acquired, which are more accurate than the existing ones. Then, by using the improved theorem, several sufficient conditions ensuring FxT synchronization of a multilayered CDN are derived via two classes of innovative quantized variable-gain saturated controllers, and some high-precision estimates of the synchronous settling time (SST) are attained. In general, the saturation function used to replace the signum function is nonlinear and even includes the odd-even requirement on the exponent, and no quantization is involved in the developed FxT controllers. However, in our design, the classical linear saturation function is employed and the input signals of the controllers are also quantized. Therefore, our proposed strategies are more practical and easier to implement. Besides, different from the traditional 2-norm/1-norm-based approaches, a novel nonsmooth Lyapunov function is constructed so that the resultant estimates of the SST are unrelated to either the network size or the node&#39;s dimension, which are less conservative and closer to the actual synchronized time. Lastly, some numerical examples are given to validate the theoretical results.},
  archive      = {J_ISCI},
  author       = {Jinyao Shi and Peipei Zhou and Qiang Jia and Shuiming Cai},
  doi          = {10.1016/j.ins.2024.121206},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121206},
  shortjournal = {Inf. Sci.},
  title        = {Fixed-time synchronization of multilayered complex dynamic networks via quantized variable-gain saturated control},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intuitionistic fuzzy local information c-means algorithm for
image segmentation. <em>ISCI</em>, <em>681</em>, 121205. (<a
href="https://doi.org/10.1016/j.ins.2024.121205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation allows us to separate an image into distinct, non-overlapping parts by utilizing specific features such as hue, texture, and shape. The technique is prevalent in different domains, including target detection, medical imaging, and pattern recognition owing to its importance in analyzing the image. The fuzzy C-means (FCM) algorithm is a popular method for image segmentation and pattern recognition. However, uncertainty and unknown noise in the data impair the effectiveness of the algorithm. Alternatively, uncertainty in real world can be addressed by the intuitionistic fuzzy set (IFS). This article presents a new approach to image representation using IFS and local information about the image. We introduce the concept of filtering into the intuitionistic fuzzy set and utilize a specially designed exponential distance for IFS. We propose the intuitionistic fuzzy local information C-means (IFLICM) algorithm. The goal of IFLICM is to increase the tolerance to noise and the maintain the details in image better than existing FCM variants. We test the performance of our algorithm on a public dataset and compare it with existing FCM methods and Double Deep-Image-Prior (Double-DIP). The experimental results demonstrate that IFLICM is highly effective in image segmentation and outperforms existing methods.},
  archive      = {J_ISCI},
  author       = {Hanshuai Cui and Zheng Xie and Wenyi Zeng and Rong Ma and Yinghui Zhang and Qian Yin and Zeshui Xu},
  doi          = {10.1016/j.ins.2024.121205},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121205},
  shortjournal = {Inf. Sci.},
  title        = {Intuitionistic fuzzy local information C-means algorithm for image segmentation},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed random swap: An efficient algorithm for minimum
sum-of-squares clustering. <em>ISCI</em>, <em>681</em>, 121204. (<a
href="https://doi.org/10.1016/j.ins.2024.121204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The clustering model known as Minimum Sum-of-Squares Clustering (MSSC) is widely used, with the popular k-means algorithm serving as its local minimizer. It is well-known that solutions of k-means can result in substantial deviations from the true global optimum of MSSC. While numerous heuristics and metaheuristics have been proposed to overcome this limitation, none have gained dominant acceptance in academic literature. This is likely related to challenges such as intricate implementations and a multitude of tunable parameters. In this paper, we dispute the belief that simplifying an algorithm for MSSC inherently means sacrificing quality. We present the Distributed Random Swap ( DRS-means ) algorithm, which is designed to enhance clustering performance for the MSSC problem. This algorithm can be interpreted as an iterative method that refines the solution generated by the k-means algorithm during each iteration. The enhancement is achieved by selecting points based on specific probability distributions. These distributions are carefully designed to improve and speed up the exploration phase. The proposed algorithm is straightforward to implement. DRS-means offers a user-friendly solution with state-of-the-art results, making it suitable for a wide range of research fields.},
  archive      = {J_ISCI},
  author       = {Olzhas Kozbagarov and Rustam Mussabayev},
  doi          = {10.1016/j.ins.2024.121204},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121204},
  shortjournal = {Inf. Sci.},
  title        = {Distributed random swap: An efficient algorithm for minimum sum-of-squares clustering},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SDA-FC: Bridging federated clustering and deep generative
model. <em>ISCI</em>, <em>681</em>, 121203. (<a
href="https://doi.org/10.1016/j.ins.2024.121203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated clustering (FC) is an extension of centralized clustering in federated settings. The key here is how to construct a global similarity measure without sharing private data, since the local similarity may be insufficient to group local data correctly, and the similarity of samples across clients cannot be directly measured due to privacy constraints. Obviously, the most straightforward way to analyze FC is to employ methods extended from centralized ones, such as K-means (KM) and fuzzy c-means (FCM). However, they are vulnerable to non independent-and-identically-distributed (non-IID) data among clients. To handle this, we propose a pretty simple and effective federated clustering framework instantiated with generative adversarial network (GAN), named synthetic data aided federated clustering (SDA-FC) . It trains generative adversarial network locally in each client and uploads the generated synthetic data to the server, where KM or FCM is performed on the synthetic data. The synthetic data can make the model immune to the non-IID problem and enable us to capture the global similarity characteristics more effectively without sharing private data. Comprehensive experiments reveal the advantages of SDA-FC, including superior performance in addressing the non-IID problem and the device failures. The code is available at https://github.com/Jarvisyan/SDA-FC .},
  archive      = {J_ISCI},
  author       = {Jie Yan and Jing Liu and Yi-Zi Ning and Zhong-Yuan Zhang},
  doi          = {10.1016/j.ins.2024.121203},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121203},
  shortjournal = {Inf. Sci.},
  title        = {SDA-FC: Bridging federated clustering and deep generative model},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inductive link prediction on temporal networks through
causal inference. <em>ISCI</em>, <em>681</em>, 121202. (<a
href="https://doi.org/10.1016/j.ins.2024.121202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of inductive temporal link prediction is to forecast future edges associated with nodes unseen during training, which is a crucial task in the field of temporal network analysis. Existing methods mainly make predictions by learning from the node/edge attributes or investigating the node substructures. However, the deficiency of attributes limits the application scope of the attribute-aware methods, while the performance of the substructure-aware models is hindered by neglecting the node correlations or introducing structure bias. In addition, current inductive temporal link prediction methods struggle to generalize the learned network evolution pattern across different networks. To address these issues, we propose a Causal LInk Prediction (CLIP) framework for the inductive temporal link prediction task. Specifically, building upon the existing anonymous distance encoding strategy, we propose to eliminate the structure bias for estimating the true distance between nodes, which is achieved by the backdoor adjustment through the do -calculus, followed by decoupling the distance encoding vector to approximate the result. Moreover, to better adapt to the realistic scenarios, we further leverage the node substructures by considering the substructure features as the intervention on the basis of the true distance between nodes. In addition, our proposed approach achieves true inductive temporal link prediction by learning the universal evolution pattern across various temporal networks, which is accomplished through training on the synthetic dynamic graph data generated from the powerlaw cluster networks. We conduct extensive experiments on four real-world temporal networks, i.e., SuperUser, MathOverflow, AskUbuntu and StackOverflow, and the experimental results demonstrate that CLIP outperforms the baselines in terms of AP and AUC. In addition, experiments on the synthetic test graph data with various distributions showcase the remarkable generalization ability of CLIP.},
  archive      = {J_ISCI},
  author       = {Zhiqiang Pan and Fei Cai and Wanyu Chen and Taihua Shao and Yupu Guo and Honghui Chen},
  doi          = {10.1016/j.ins.2024.121202},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121202},
  shortjournal = {Inf. Sci.},
  title        = {Inductive link prediction on temporal networks through causal inference},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-and knowledge-driven belief rule learning for hybrid
classification. <em>ISCI</em>, <em>681</em>, 121201. (<a
href="https://doi.org/10.1016/j.ins.2024.121201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In hybrid classification problems, apart from labeled data, some related expert knowledge may also be obtained. If the partial information from these two sources can be jointly used well, the performance may be effectively improved. To this end, we develop a new framework for hybrid classification by modeling the uncertain data and knowledge in the form of belief rules under the framework of belief function theory. First, a data-driven belief rule learning algorithm is proposed to learn a compact and interpretable belief rule model from labeled training data. Then, a knowledge-driven belief rule learning algorithm is proposed to learn a model which is complementary to that learned from data via active learning strategy. Finally, the genetic integration of belief rules is developed in order to integrate data-driven belief rules with knowledge-driven ones to reduce the rule redundancy and rule conflict by considering both classification accuracy and model interpretability. Experiments based on both simulated and real data sets demonstrate the superiority of the proposed model for integrating data and knowledge.},
  archive      = {J_ISCI},
  author       = {Xiaojiao Geng and Haonan Ma and Lianmeng Jiao and Zhi-Jie Zhou},
  doi          = {10.1016/j.ins.2024.121201},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121201},
  shortjournal = {Inf. Sci.},
  title        = {Data-and knowledge-driven belief rule learning for hybrid classification},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). NMNN: Newtonian mechanics-based natural neighbor algorithm.
<em>ISCI</em>, <em>681</em>, 121200. (<a
href="https://doi.org/10.1016/j.ins.2024.121200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural neighbor (NaN) algorithm, as a parameter-free alternative to KNN, is widely used in various fields such as pattern recognition and machine learning. However, the original NaN algorithm only takes the Euclidean distance of the samples as the only criterion for similarity calculation. It does not reasonably reflect the relationship between the samples and affects convergence and accuracy. Newtonian mechanics considers the effect of forces from many perspectives. Consequently, in this paper, Newtonian mechanics is introduced to calculate the relationship between samples, then the Newtonian mechanics-based Natural Neighbor algorithm (NMNN) is proposed. At first, it introduces Newton&#39;s first, second, and third laws and the idea of gravity in the natural neighbor algorithm. Then, it computes the mass of the samples by the natural neighbor density. Moreover, it updates the similarity matrix through Newtonian mechanics, which makes the calculation results more accurate. The formation process of the natural neighbor can be regarded as the spontaneous mutual attraction of samples based on traction. Finally, the experimental results show that the convergence performance of the NMNN algorithm is better than that of the NaN algorithm, and it can achieve better results in applications such as unbalanced data, clustering, and outlier detection.},
  archive      = {J_ISCI},
  author       = {Wentong Wang and Lijun Yang and Juntao Yang and Jinghui Zhang and Dongming Tang and Tao Liu},
  doi          = {10.1016/j.ins.2024.121200},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121200},
  shortjournal = {Inf. Sci.},
  title        = {NMNN: Newtonian mechanics-based natural neighbor algorithm},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Q-learning-based non-zero sum games for markov jump
multiplayer systems under actor-critic NNs structure. <em>ISCI</em>,
<em>681</em>, 121196. (<a
href="https://doi.org/10.1016/j.ins.2024.121196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the problem of non-zero sum games for Markov jump multiplayer systems (MJMSs) using the reinforcement Q -learning method. Firstly, the Q -functions for each player are derived from the system states and the control inputs. On this basis, by incorporating the integral reinforcement learning scheme and the actor-critic neural networks structure, we design a novel reinforcement learning approach for MJMSs. It should be noted that the designed algorithm does not require any information about the system dynamics and transition probabilities. Furthermore, the stochastic stability and Nash equilibrium of MJMSs can be ensured by the designed algorithm. Finally, a simulation example is presented to illustrate the effectiveness of the designed approach.},
  archive      = {J_ISCI},
  author       = {Yun Wang and Jiawei Xia and Jing Wang and Hao Shen},
  doi          = {10.1016/j.ins.2024.121196},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121196},
  shortjournal = {Inf. Sci.},
  title        = {Q-learning-based non-zero sum games for markov jump multiplayer systems under actor-critic NNs structure},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On homology groups for pairwise comparisons method.
<em>ISCI</em>, <em>681</em>, 121195. (<a
href="https://doi.org/10.1016/j.ins.2024.121195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we introduce pairwise comparisons matrix classification based on homology groups of graphs with unique vertices. Algebraic topology transforms a sequence of topological objects (such as graphs associated with pairwise comparison matrices) into algebraic objects such as homology groups. It is the first attempt to use this tool to classify matrices of pairwise comparisons based on the triads in which the inconsistency occurs. The Koczkodaj inconsistency indicator was used in this study.},
  archive      = {J_ISCI},
  author       = {Waldemar W. Koczkodaj and Witold Pedrycz and Alexander Pigazzini and Yingli Song and Jacek Szybowski},
  doi          = {10.1016/j.ins.2024.121195},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121195},
  shortjournal = {Inf. Sci.},
  title        = {On homology groups for pairwise comparisons method},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A regret theory-based even swaps method with complex
linguistic information and its application in early-stage lung cancer
treatment selection. <em>ISCI</em>, <em>681</em>, 121194. (<a
href="https://doi.org/10.1016/j.ins.2024.121194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer is the cancer with the highest morbidity and mortality rate, and selecting treatment options for early-stage lung cancer patients is of great significance in improving cure rate. To help individuals make rational decisions, the even swap method, a multiple criteria decision-making (MCDM) model, provides an effective mechanism to make tradeoffs between criteria; however, the original even swap method ignored psychological characteristics of individuals and could not deal with complex linguistic information. To deal with the early-stage lung cancer treatment selection problem, this paper introduces generalized probabilistic linguistic term sets (GPLTSs) to describe complex linguistic information and proposes a generalized probabilistic linguistic even swap method based on the regret theory. Firstly, the upper and lower bounds corresponding to linguistic expressions are extracted to represent the uncertainty of GPLTSs. Then, a regret-rejoice function is introduced to express psychological characteristics of individuals when they making tradeoffs between criteria. Afterwards, a regret theory-based even swap method is proposed to rank alternatives. The proposed method is validated in the selection of early-stage lung cancer treatment options. Sensitivity analysis and comparative analysis are given to show the feasibility of the proposed method.},
  archive      = {J_ISCI},
  author       = {Huchang Liao and Yangchao Xu and Ran Fang},
  doi          = {10.1016/j.ins.2024.121194},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121194},
  shortjournal = {Inf. Sci.},
  title        = {A regret theory-based even swaps method with complex linguistic information and its application in early-stage lung cancer treatment selection},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid response dynamic multi-objective optimization
algorithm based on multi-arm bandit model. <em>ISCI</em>, <em>681</em>,
121192. (<a href="https://doi.org/10.1016/j.ins.2024.121192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multi-objective optimization is a relatively challenging problem within the field of multi-objective optimization. Nevertheless, these problems have significant real-world applications. The key to addressing dynamic multi-objective problems effectively is promptly tracking changes in the Pareto set (PS) and Pareto front (PF). Dynamic multi-objective optimization encompasses various types of problems, and a single-type response strategy proves effective for some specific scenarios. However, as problem complexity and diversity increase, a single-type response strategy often falls short in solving dynamic multi-objective optimization problems. To address this issue, this paper proposes a hybrid response dynamic multi-objective optimization algorithm. The suggested algorithm utilizes the multi-arm bandit model to adaptively adjust the proportion of different response strategies for each type of multi-objective optimization problem. Furthermore, it achieves rapid convergence through an enhanced two-stage MOEA/D. Experiments demonstrate the effectiveness of the strategies employed in the proposed algorithm and its competitiveness compared to other state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Xiaolin Hu and Lingyu Wu and Mingzhang Han and Xinchao Zhao and Xinzhu Sang},
  doi          = {10.1016/j.ins.2024.121192},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121192},
  shortjournal = {Inf. Sci.},
  title        = {Hybrid response dynamic multi-objective optimization algorithm based on multi-arm bandit model},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attentive multi-granularity perception network for person
search. <em>ISCI</em>, <em>681</em>, 121191. (<a
href="https://doi.org/10.1016/j.ins.2024.121191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person search is an extremely challenging task that seeks to identify individuals through joint person detection and person re-identification from uncropped real scene images. Previous studies primarily focus on learning rich features to enhance identification. However, arbitrary feature enhancement strategies may introduce unwanted background noise. Moreover, different scenarios usually exhibit varying pedestrian appearances or even intricate occlusions, leading to inconsistent/incomplete pedestrian features in different images. In this paper, we introduce a novel Attentive Multi-granularity Perception (AMP) module seamlessly integrated into our AMPN network. This module specifically addresses appearance variations and occlusions within a person&#39;s Region of Interest (RoI). The AMP module harnesses discriminative relationship features from various local regions, significantly enhancing identification accuracy. It comprises two principal components: the Pedestrian Perception Enhancement (PPE) block and the Background Interference Suppressor (BIS). The PPE block introduces a Spatial-wise Feature Mixer and a Channel-wise Feature Mixer, which effectively capture and refine discriminative relation features. Simultaneously, the BIS operates in parallel with the PPE block, enriching the discriminative relation features and enhancing the distinctiveness between the foreground and background. Our AMP module is plug-and-play and can integrate with other person search models. Extensive experiments validate our model&#39;s merits, achieving state-of-the-art performance on CUHK-SYSU and a 4.8% mAP gain over SeqNet on PRW at a desirable speed. Our code is accessible at https://github.com/zqx951102/AMPN .},
  archive      = {J_ISCI},
  author       = {Qixian Zhang and Jun Wu and Duoqian Miao and Cairong Zhao and Qi Zhang},
  doi          = {10.1016/j.ins.2024.121191},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121191},
  shortjournal = {Inf. Sci.},
  title        = {Attentive multi-granularity perception network for person search},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PC-SSRDE: A paradigm crossover-based differential evolution
algorithm with search space reduction. <em>ISCI</em>, <em>681</em>,
121188. (<a href="https://doi.org/10.1016/j.ins.2024.121188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization of complex problems has always been a difficult task in the realm of evolutionary computation, as complex problems often have a large search space. Adding more dimensions to the decision variables also makes the search space more complicated, which slows down the algorithm. However, as the number of locally optimal solutions to the complex problem grows exponentially, it becomes easy for the algorithm to land in a local optimal region. In light of this background, this paper proposes a paradigm-crossover-based differential evolution algorithm with search space reduction and diversity exploration. During the evolution process, the proposed algorithm obtains the correlation coefficient for each dimension of the problem. Based on this correlation, it generates a paradigm that participates in crossover, accelerating the population’s movement towards promising regions.When the algorithm faces premature convergence and stagnation, it executes search space reduction and diversity exploration at the dimensional level to discard the unpromising search space and enhance the population diversity in the promising search space. We compared our proposed algorithm with eight state-of-the-art evolutionary algorithms in the CEC2017-BC test set to confirm its effectiveness, and the experimental results demonstrated its notable advantages for solution accuracy and convergence speed on high-dimensional complex problems.},
  archive      = {J_ISCI},
  author       = {Ying Huang and Liang Xing and Baolei Li and Benben Zhou},
  doi          = {10.1016/j.ins.2024.121188},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121188},
  shortjournal = {Inf. Sci.},
  title        = {PC-SSRDE: A paradigm crossover-based differential evolution algorithm with search space reduction},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiview ensemble clustering of hypergraph p-laplacian
regularization with weighting and denoising. <em>ISCI</em>,
<em>681</em>, 121187. (<a
href="https://doi.org/10.1016/j.ins.2024.121187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiview clustering has gained attention for its ability to incorporate complementary information from multiple sources of data, leading to better clustering results. However, these methods don&#39;t sufficiently mine high-dimensional information of non-linear subspace or ignore important high-level information between basic partitions (BPs), which are obtained via single-view clustering that could help to overcome differences between heterogeneous feature spaces and defined in Eq. (4) . Additionally, existing multiview ensemble clustering methods neglect the noise arising from the generation phase. In light of this, we first propose a novel multiview subspace clustering method with hypergraph p-Laplacian regularization and denoising. Specifically, to utilize the high-dimensional information, a hypergraph p-Laplacian regularized term is added to the model along with low-rank subspace learning to capture the different hierarchical structures in the data. A denoising algorithm based on KMeans and K-nearest neighbor is used to minimize the noise of similarity matrix. Then utilizing this approach as a backbone, a multiview ensemble clustering of hypergraph p-Laplacian regularization with weighting and denoising method is proposed. A hybrid strategy and a novel global weighting ensemble strategy is further proposed to extract high-level information across all the BPs. By integrating hypergraph p-Laplacian operator, low-rank subspace learning, denoising, and weighting ensemble strategy in a unified framework, this ensemble approach adequately learns latent structures and complementary information. Experimental results on multiple datasets demonstrate the efficacy of this approach.},
  archive      = {J_ISCI},
  author       = {Dacheng Zheng and Zhiwen Yu and Wuxing Chen and Weiwen Zhang and Qiying Feng and Yifan Shi and Kaixiang Yang},
  doi          = {10.1016/j.ins.2024.121187},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121187},
  shortjournal = {Inf. Sci.},
  title        = {Multiview ensemble clustering of hypergraph p-laplacian regularization with weighting and denoising},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fast dual-module hybrid high-dimensional feature selection
algorithm. <em>ISCI</em>, <em>681</em>, 121185. (<a
href="https://doi.org/10.1016/j.ins.2024.121185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When dealing with large-scale datasets, high-dimensional feature selection plays a crucial role in improving the performance and interpretability of machine learning models. However, it still faces the problems of the “dimensionality curse” and high computational cost in dealing with high-dimensional datasets. In this paper, we develop a dual-module hybrid feature selection algorithm based on correlation filtering and a multi-objective evolutionary algorithm based on dynamic variation distance (HMOFS-CFDVD), which aims to reduce the computational cost of high-dimensional features and search space. Firstly, a coarse-grained feature filtering method based on correlation is proposed, enabling the algorithm to quickly identify potentially better feature subsets in the later stages. After that, a fine-grained feature selection is further implemented based on the multi-objective evolutionary algorithm with sample variation distance to obtain a high-quality feature subset. This stage incorporates a novel population initialization method with self-regulation, an adaptive evolution strategy, an optimal sample selection mechanism based on dynamic sample distance, and an improved diversity mechanism to enhance the evolutionary performance. Moreover, the feature relevance metric is introduced as a third objective to improve the overall algorithm&#39;s performance. Experimental results on 12 high-dimensional feature datasets demonstrate that the proposed HMOFS-CFDVD achieves high accuracy and produces a smaller subset of features.},
  archive      = {J_ISCI},
  author       = {Geying Yang and Junjiang He and Xiaolong Lan and Tao Li and Wenbo Fang},
  doi          = {10.1016/j.ins.2024.121185},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121185},
  shortjournal = {Inf. Sci.},
  title        = {A fast dual-module hybrid high-dimensional feature selection algorithm},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An error analysis for deep binary classification with
sigmoid loss. <em>ISCI</em>, <em>681</em>, 121166. (<a
href="https://doi.org/10.1016/j.ins.2024.121166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have demonstrated remarkable efficacy in diverse classification tasks. In this paper, we specifically focus on the predictive performance in deep binary classification problems with the sigmoid loss. Given that sigmoid loss is categorized as a non-convex and bounded loss function, it exhibits potential resilience against the disruptive impact of outlier noises. We first derive the convergence rate of the excess misclassification risk for deep ReLU neural networks with the sigmoid loss, a result that attains minimax optimality. To the best of our acknowledge, we are the first to derive the convergence rate for the sigmoid loss. Moreover, we extend our analysis to derive a faster convergence rate under margin assumptions. This achievement renders our findings comparable to those of commonly employed convex loss functions operating under analogous assumptions. Lastly, we undertake a comprehensive validation of the robustness inherent in the sigmoid loss across diverse datasets.},
  archive      = {J_ISCI},
  author       = {Changshi Li and Yuling Jiao and Jerry Zhijian Yang},
  doi          = {10.1016/j.ins.2024.121166},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121166},
  shortjournal = {Inf. Sci.},
  title        = {An error analysis for deep binary classification with sigmoid loss},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-feature hybrid network for traffic flow prediction
based on mobility patterns. <em>ISCI</em>, <em>681</em>, 121157. (<a
href="https://doi.org/10.1016/j.ins.2024.121157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Future flow prediction in spatiotemporal traffic data is a critical requirement for real-world applications, particularly for multi-feature and large-scale data with intricate forecasting mechanisms and varied predictability. Prior sequence-to-sequence studies have demonstrated the superiority of attention learning in prediction tasks by effectively capturing reliable dependencies/correlations. However, despite the promising results, the single-feature input pattern of traffic prediction causes an information utilization bottleneck. In this paper, we focus on discovering the cause-effect relationship of traffic dynamics by fusing the origin–destination (OD) flow. To achieve both high accuracy and universality, we design a scalable composition architecture—a Multi-Feature Hybrid Network (MFHN)—based on the existing framework of spatiotemporal feature modeling. In particular, we break with the preprocessing convention of feature composition and propose a Hybrid-Correlation mechanism by integrating similar subseries of the OD flow. Furthermore, inspired by graph learning, we introduce the mobility pattern based on the OD flow, which reveals the node-to-node dependencies. In the experiment, we consider various prediction tasks with state-of-the-art baseline models and find that the MFHN yields competitive accuracy in short- and long-term prediction.},
  archive      = {J_ISCI},
  author       = {Xuesong Wu and Tianlu Pan and Linlin You and Zhaocheng He},
  doi          = {10.1016/j.ins.2024.121157},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121157},
  shortjournal = {Inf. Sci.},
  title        = {Multi-feature hybrid network for traffic flow prediction based on mobility patterns},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-stage group decision making methodology with hesitant
fuzzy preference relations under social network: Multiplicative
consistency determination and personalized feedback. <em>ISCI</em>,
<em>681</em>, 121155. (<a
href="https://doi.org/10.1016/j.ins.2024.121155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some social network group decision making (SNGDM) researches may overlook two issues: (1) the impact of consistency on decision reliability and decision makers’ (DMs’) status in social network, and (2) DMs’ personalization during consensus reaching process. In response to these two issues, a two-stage SNGDM model is proposed for hesitant fuzzy preference relations (HFPRs). In the first stage, multiplicative consistency determination and improvement of HFPRs are achieved. For complete and incomplete HFPRs, several programming models are constructed to classify consistency types. When it comes to inconsistent HFPRs, an inconsistency fixing method is designed to ensure the original HFPRs as much as possible. With the improvement of DMs’ consistency, their status in social network will be dynamically enhanced. In the second stage, two programming models are devised to elicit the reasonable individual priority weight vector in consistent HFPR. Further, minimum adjustment cost-based personalized feedback mechanism is invented to attain the optimal personalized adjustment coefficient and recommendation, and achieve the harmonious unity of individual personalization and group consensus. Finally, the superiority of our proposal is verified by comparative analysis and illustrative example.},
  archive      = {J_ISCI},
  author       = {Mengqi Li and Zhaoyang Wang and Yejun Xu and Weijia Dai},
  doi          = {10.1016/j.ins.2024.121155},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121155},
  shortjournal = {Inf. Sci.},
  title        = {Two-stage group decision making methodology with hesitant fuzzy preference relations under social network: Multiplicative consistency determination and personalized feedback},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Federated bayesian optimization via compressed sensing.
<em>ISCI</em>, <em>681</em>, 121148. (<a
href="https://doi.org/10.1016/j.ins.2024.121148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Bayesian optimization (FBO) has been introduced in recent years to avoid privacy leakage when multiple clients involve in finishing a global optimization task. Parameter-sharing-based FBOs, as one branch of FBOs, however, compromise the optimization efficacy due to the reduced fitting ability of parameterized Gaussian processes (GPs). In this work, we propose a data-sharing federated framework based on compressed sensing by directly sharing perturbed decision variables of raw data. Specifically, decision variables of raw data in each client are perturbed to a certain level by controlling the reconstruction rate to make the reconstructed data similar to but indistinguishable from the real raw data. By doing this, the reconstructed data can be used as the perturbed raw data to be shared with other clients. Then, a curator is randomly selected at each round of surrogate updates to train a global GP model using the union of perturbed and real data set, helping explore the whole search space. Additionally, we put forward a novel standard for evaluating privacy levels in BO algorithms, promoting fair performance benchmarks. Compared to other FBOs, the proposed algorithm has demonstrated to be very effective without compromising privacy, as evidenced by experimental results on the CEC2005 benchmark.},
  archive      = {J_ISCI},
  author       = {Qiqi Liu and Leming Wu and Yaochu Jin},
  doi          = {10.1016/j.ins.2024.121148},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121148},
  shortjournal = {Inf. Sci.},
  title        = {Federated bayesian optimization via compressed sensing},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Strengthening LLM ecosystem security: Preventing mobile
malware from manipulating LLM-based applications. <em>ISCI</em>,
<em>681</em>, 120923. (<a
href="https://doi.org/10.1016/j.ins.2024.120923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language model (LLM) platform vendors have begun to make their models available for developers to build for different use cases. However, the emergence of LLM-based applications may raise security and privacy issues, and even LLM-based applications may be susceptible to malware. To strengthen LLM ecosystem security, it&#39;s crucial to develop malware detection algorithms for various platforms. We pay attention to Android malware because the Android platform is widely used and vulnerable. Existing single feature based-solutions cannot effectively describe applications, and aged models fail to detect new malware as Android platform develops and malware evolves. Therefore, existing detection methods are ill-suited for evolved malware that may manipulate LLM-based applications. To tackle the above problems, we design EvolveDroid, an anti-aging Android malware detection system. On the one hand, EvolveDroid utilizes different view features to reflect malware behavior from multiple dimensions, and maximizes the advantages of each feature type through feature aggregation. On the other hand, EvolveDroid learns good representation of applications through contrastive learning and generates pseudo labels by measuring the distance between unknown samples and existing samples for model updating. Extensive evaluations show that EvolveDroid outperforms state-of-the-art (sota) solutions in detection performance and slowing model aging.},
  archive      = {J_ISCI},
  author       = {Lu Huang and Jingfeng Xue and Yong Wang and Junbao Chen and Tianwei Lei},
  doi          = {10.1016/j.ins.2024.120923},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {120923},
  shortjournal = {Inf. Sci.},
  title        = {Strengthening LLM ecosystem security: Preventing mobile malware from manipulating LLM-based applications},
  volume       = {681},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EEG emotion recognition using EEG-SWTNS neural network
through EEG spectral image. <em>ISCI</em>, <em>680</em>, 121198. (<a
href="https://doi.org/10.1016/j.ins.2024.121198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development in deep learning models provide considerable advancements in emotion recognition by electroencephalogram (EEG). However, existing approaches primarily focus on temporal and frequency domain features of EEG signals, neglecting spatial domain features in model information integration. Therefore, this study proposed a novel EEG input format, called EEG spectral image (ESI), which integrates spatial domain features using Azimuthal Equidistant Projection (AEP) and frequency domain features through differential entropy (DE). To better utilize this fine-grained data format, we propose the EEG Swin Transformer (EEG-SWTNS), which combines the window attention mechanism with shifted window partitioning. Window attention mechanism can concentrate on affective information within various regions and use shifted window partitioning to disrupt aggregated emotional representations for more granular features. Different from traditional graph neural networks, this method leverages the spatial locality of region information, leading to enhanced performance in EEG-based emotion recognition. Experiments conducted on SEED and SEED IV datasets demonstrate superior performance compared to baseline methods and the state-of-the-art models. Relative improvements of 0.6% and 0.08% are observed in subject-dependent experiments, while accuracies of 80.07% and 66.72% are achieved in subject-independent experiments without utilizing transfer learning techniques.},
  archive      = {J_ISCI},
  author       = {Mengpu Cai and Junxiang Chen and Chengcheng Hua and Guilin Wen and Rongrong Fu},
  doi          = {10.1016/j.ins.2024.121198},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121198},
  shortjournal = {Inf. Sci.},
  title        = {EEG emotion recognition using EEG-SWTNS neural network through EEG spectral image},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model reference adaptive controller with interpretable fuzzy
rules for linear MIMO systems. <em>ISCI</em>, <em>680</em>, 121189. (<a
href="https://doi.org/10.1016/j.ins.2024.121189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a method for fuzzy model reference adaptive control system design for a partially known multi-input multi-output (MIMO) linear dynamic plant. Differential or convolutional equations can describe the plant to be controlled, and the fuzzy controller is assumed to be from the MIMO sector-bounded nonstationary nonlinearities class. The task is to obtain robust adaptive stabilization. Some absolute stability theorems and integral evaluations of the state and control vectors are applied in the MIMO fuzzy adaptive controller design procedure for the first time. A method for automatically obtaining a near-optimal nonlinear dynamic reference model is described. A practical step-by-step procedure of the MIMO adaptive fuzzy controller design is proposed, resulting in highly interpretable MIMO fuzzy control rules based on triangular fuzzy sets and strong triangular fuzzy partition. An example of the fuzzy controller design according to the proposed procedure is given.},
  archive      = {J_ISCI},
  author       = {Jacek Kluska and Krzysztof Wiktorowicz},
  doi          = {10.1016/j.ins.2024.121189},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121189},
  shortjournal = {Inf. Sci.},
  title        = {Model reference adaptive controller with interpretable fuzzy rules for linear MIMO systems},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Coupled double consensus multi-graph fusion for multi-view
clustering. <em>ISCI</em>, <em>680</em>, 121186. (<a
href="https://doi.org/10.1016/j.ins.2024.121186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view graph clustering (MVGC) is a technique that combines information from multiple views to perform clustering analysis on graph data. However, the consensus information between the different views is not fully utilized. Additionally, the influence of noise is inevitable, leading to insufficient robustness of the algorithm. To address these issues, this paper proposes coupled double consensus multi-graph fusion for multi-view clustering method (CDCMGF). Specifically, we first utilize the self-expressive property of the original data to obtain similarity graphs. Next, we further integrate the fusion of multiple similarity graphs into a consensus graph. However, the consensus information from different views is still not fully utilized, and there is some noise. Then, we utilize the self-expressive property of the consensus graph to obtain a much cleaner consensus graph. Fourth, we stack the two consensus graphs into a tensor, which is subjected to the constraint of the tensor nuclear norm (TNN). Then, the two consensus graphs reinforce each other, allowing for the comprehensive utilization of the consensus information from different views and reducing the influence of noise. Ultimately, by utilizing the augmented Lagrange multiplier method (ALM), the four steps outlined above are unified into a framework. The CDCMGF achieves a performance improvement of up to 64.86%, and the experimental results from various public datasets indicate that the CDCMGF algorithm outperforms the state-of-the-art algorithms. In other words, these experimental results validate the importance of fully utilizing the consensus information among the different views. The code is publicly available at https://github.com/TongWuahpu/CDCMGF .},
  archive      = {J_ISCI},
  author       = {Tong Wu and Gui-Fu Lu},
  doi          = {10.1016/j.ins.2024.121186},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121186},
  shortjournal = {Inf. Sci.},
  title        = {Coupled double consensus multi-graph fusion for multi-view clustering},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancement of the performance of high-dimensional fuzzy
classification with feature combination optimization. <em>ISCI</em>,
<em>680</em>, 121183. (<a
href="https://doi.org/10.1016/j.ins.2024.121183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high-dimensional classification, an important issue is how to enhance the performance of the classification processing mechanism. Various dimensionality reduction-based techniques such as feature selection and feature extraction have been developed to deal with high-dimensional classification tasks, but they usually suffer from the issues of information loss and low interpretability to a certain extent. This study develops an enhanced version of fuzzy clustering through feature combination optimization to improve classification performance for high-dimensional data. First, we propose a correlation-based feature combination strategy based on the underlying internal relationship of features, through which we can decompose an original high-dimensional feature into multiple combinations of low-dimensional features. Then, we optimize each feature combination to achieve a sound overall classification performance by allocating a group of weights to the decomposed feature subsets in the combination. We apply the method of Fuzzy C-Means to address the low-dimensional classification of the original dataset with respect to the decomposed feature subsets, and solve the optimization problem using Quantum Particle Swarm Optimization. For different feature combinations, we identify the one, along with its optimal weight distribution under which the optimal classification performance of the dataset is the largest, as the optimal feature combination. Finally, we compare the proposed method with two classical methods over 13 real publicly available datasets, and the results show that the proposed method can achieve significant improvement in comparison with the two baseline methods on both the training and testing sets, and has good robustness and sound interpretability.},
  archive      = {J_ISCI},
  author       = {Xiaoan Tang and Yuxin Wei and Kaijie Xu and Qiang Zhang},
  doi          = {10.1016/j.ins.2024.121183},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121183},
  shortjournal = {Inf. Sci.},
  title        = {Enhancement of the performance of high-dimensional fuzzy classification with feature combination optimization},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tensor nonconvex unified prior for tensor recovery.
<em>ISCI</em>, <em>680</em>, 121176. (<a
href="https://doi.org/10.1016/j.ins.2024.121176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor data, such as hyperspectral images and multi-frame videos, have gained significant attention in practical applications. However, the inherent degradation phenomena during data acquisition, including noise and missing pixels, give rise to a series of ill-posed inverse problems that need to be addressed. Currently, the rational exploration of prior knowledge for tensor recovery, including global low-rankness and local smoothness, has emerged as a common concern. Inspired by recent notable works, this paper proposes a novel tensor non-convex unified prior term, which employs weighted tensor Schatten p -norm as a rank surrogate function in the gradient domain. The new prior can yield a regularizer that effectively captures low-rankness and smoothness, and is applied to tensor completion and tensor robust principal component analysis models. An efficient algorithm is developed by using the alternating direction method of multipliers and its convergence analysis is also provided. Extensive experimental results demonstrate that the proposed method outperforms the state-of-the-art methods, particularly in cases of high missing rates and strong noise levels .},
  archive      = {J_ISCI},
  author       = {Yumo Wu and Jianing Sun and Junping Yin},
  doi          = {10.1016/j.ins.2024.121176},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121176},
  shortjournal = {Inf. Sci.},
  title        = {Tensor nonconvex unified prior for tensor recovery},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transport capacity optimization for high-speed rail network
considering flexible train composition and additional capacity pool.
<em>ISCI</em>, <em>680</em>, 121175. (<a
href="https://doi.org/10.1016/j.ins.2024.121175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To balance the limited capacity and constantly changing demand in the high-speed rail network, a transport capacity optimization problem is investigated by adjusting train composition through uncoupling/coupling operations at the origin station, scheduling additional trains from the capacity pool, and optimizing the seat allocation among ODs. To make joint decisions, a two-stage stochastic programming model is formulated to minimize both operating cost and penalty cost for unsatisfied passengers, while incorporating various constraints such as flow conservation, loading capacity, flexible composition, etc. The two-stage model is linearized into a mixed-integer linear programming model, which can be effectively solved for small networks but is still intractable to solve for realistic networks. Therefore, a Lagrangian relaxation algorithm is proposed integrating parallel computing and sub-gradient method. Finally, two sets of case tests, including a toy network and a real-world case of a high-speed rail network in China, are implemented to show the performance of the proposed approach. The results illustrate that the parallel heuristic algorithm could generate a high-quality solution with a slight discrepancy from the optimal solution, while achieving a commendable computation time. Furthermore, the findings emphasize the advantages of applying flexible train composition and additional capacity pool in the high-speed railway system for cost-saving and supply–demand matching.},
  archive      = {J_ISCI},
  author       = {Ziyan Feng and Xiang Li and Jianjun Wu and Ximing Chang},
  doi          = {10.1016/j.ins.2024.121175},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121175},
  shortjournal = {Inf. Sci.},
  title        = {Transport capacity optimization for high-speed rail network considering flexible train composition and additional capacity pool},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DSGN: Log-based anomaly diagnosis with dynamic semantic gate
networks. <em>ISCI</em>, <em>680</em>, 121174. (<a
href="https://doi.org/10.1016/j.ins.2024.121174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing log anomaly diagnosis methods still face challenges in the lack of statistical features of log messages and insufficient exploitation of textual semantic features. In order to tackle this issue, we propose a novel approach called Dynamic Semantic Gating Network (DSGN). The core idea of DSGN is to enrich the semantic representation of log texts by selectively utilizing statistical information, thus achieving an organic integration of statistical and semantic features. Specifically, DSGN incorporates a variational encoding module to encode statistical features, and a log content-aware graph convolutional network module to capture semantic features from the log context. Furthermore, DSGN introduces a dynamic semantic threshold mechanism that dynamically adjusts the information flow based on the confidence level of semantic features and feeds it into the classifier. This design not only helps train a more robust classifier, but also leverages the advantages of both statistical and semantic features while avoiding overfitting caused by using statistical features. Experimental results show that the DSGN model achieves significant performance improvements on seven public datasets, with a macro-average F1 score exceeding 83% and a micro-average F1 score exceeding 81%, outperforming existing baseline techniques and demonstrating its substantial advantages.},
  archive      = {J_ISCI},
  author       = {Haitian Yang and Degang Sun and Yan Wang and Weiqing Huang},
  doi          = {10.1016/j.ins.2024.121174},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121174},
  shortjournal = {Inf. Sci.},
  title        = {DSGN: Log-based anomaly diagnosis with dynamic semantic gate networks},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reaching heterogeneous group consensus with classification
error for sorting medical emerging technology service providers.
<em>ISCI</em>, <em>680</em>, 121173. (<a
href="https://doi.org/10.1016/j.ins.2024.121173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve diversity services and boost diagnostic accuracy, more and more emerging technologies are applied to assist medical treatment. The medical emerging technology service provider selection is a noteworthy problem for hospital risk management. Thus, we develop a heterogeneous group AHPSort (GAHPsort) to provide the recommendation for hospitals and explore the consensus of GAHPSort to avoid the conflict. Specifically, by considering the difference of decision makers&#39; evaluation standard, we design a group sorting consensus of GAHPSort from the angle of sorting result via pairwise comparison of decision makers. Meanwhile, we construct asymmetrical classification error cost function to describe classification error costs of different decision makers&#39; preferences. Further, a minimum adjustment model based on sorting consensus index with classification error is established. Considering that the results of technology providers in the same class are close, this paper develops the distinction between the inter-class and the between-class distances to depict the weak opinion consensus and extend the minimum adjustment model. Besides, in order to avoid the unexplainable evaluation, we design the semantic tolerance and further improve the minimum adjustment model. Finally, we utilize two cases to validate our proposed method via comparison analysis.},
  archive      = {J_ISCI},
  author       = {Yuanyuan Fu and Decui Liang and Alessio Ishizaka and Dengfeng Li},
  doi          = {10.1016/j.ins.2024.121173},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121173},
  shortjournal = {Inf. Sci.},
  title        = {Reaching heterogeneous group consensus with classification error for sorting medical emerging technology service providers},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed inference for the quantile regression model
based on the random weighted bootstrap. <em>ISCI</em>, <em>680</em>,
121172. (<a href="https://doi.org/10.1016/j.ins.2024.121172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adoption of quantile regression has become increasingly prevalent because of its robustness and comprehensiveness compared to the ordinary least squares approach. However, in analyzing distributed data, it is challenging to estimate the unknown parameter and construct its confidence interval, while the existing related method suffers from coverage distortion at tail quantiles with levels close to 0 or 1, caused by the nuisance parameter estimation. This paper proposes a novel distributed statistical inference method for the quantile regression model by incorporating the random weighted bootstrap method to circumvent the nuisance parameter estimation problem. A modified random weighted bootstrap is also developed to suit the case when the number of machines is relatively small. The new methods are communication efficient and have reasonable finite sample performance at tail quantiles. Theoretical properties are established. Simulations and real data analysis are also devoted to verifying the theoretical properties and illustrating the finite sample performance.},
  archive      = {J_ISCI},
  author       = {Peiwen Xiao and Xiaohui Liu and Anna Li and Guangming Pan},
  doi          = {10.1016/j.ins.2024.121172},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121172},
  shortjournal = {Inf. Sci.},
  title        = {Distributed inference for the quantile regression model based on the random weighted bootstrap},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IDEA: Invariant defense for graph adversarial robustness.
<em>ISCI</em>, <em>680</em>, 121171. (<a
href="https://doi.org/10.1016/j.ins.2024.121171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the success of graph neural networks (GNNs), their vulnerability to adversarial attacks poses tremendous challenges for practical applications. Existing defense methods suffer from severe performance decline under unseen attacks, due to either limited observed adversarial examples or pre-defined heuristics. To address these limitations, we analyze the causalities in graph adversarial attacks and conclude that causal features are key to achieve graph adversarial robustness, owing to their determinedness for labels and invariance across attacks. To learn these causal features, we innovatively propose an I nvariant causal DE fense method against adversarial A ttacks (IDEA). We derive node-based and structure-based invariance objectives from an information-theoretic perspective. IDEA ensures strong predictability for labels and invariant predictability across attacks, which is provably a causally invariant defense across various attacks. Extensive experiments demonstrate that IDEA attains state-of-the-art defense performance under all five attacks on all five datasets. The implementation of IDEA is available at https://github.com/TaoShuchang/IDEA_repo .},
  archive      = {J_ISCI},
  author       = {Shuchang Tao and Qi Cao and Huawei Shen and Yunfan Wu and Bingbing Xu and Xueqi Cheng},
  doi          = {10.1016/j.ins.2024.121171},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121171},
  shortjournal = {Inf. Sci.},
  title        = {IDEA: Invariant defense for graph adversarial robustness},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel discrete differential evolution algorithm combining
transfer function with modulo operation for solving the multiple
knapsack problem. <em>ISCI</em>, <em>680</em>, 121170. (<a
href="https://doi.org/10.1016/j.ins.2024.121170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an efficient method for solving multiple knapsack problem (MKP) using discrete differential evolution is proposed. Firstly, an integer programming model of MKP suitable for discrete evolutionary algorithm is established. Secondly, a new method for discretizing continuous evolutionary algorithm is proposed based on the combination of transfer function and modulo operation. Therefrom, a new discrete differential evolution algorithm (named TMDDE) is proposed. Thirdly, the algorithm GROA is proposed to eliminate infeasible solutions of MKP. On this basis, a new method for solving MKP using TMDDE is proposed. Finally, the performance of TMDDE using S-shaped, U-shaped, V-shaped, and Taper-shaped transfer functions combined with modulo operation is compared, respectively. It is pointed out that T3-TMDDE which used Taper-shaped transfer function T3 is the best. The comparison results of solving 30 MKP instances show that the performance of T3-TMDDE is better than five advanced evolutionary algorithms. It not only indicates that TMDDE is more competitive for solving MKP, but also demonstrates that the proposed discretization method is an effective method.},
  archive      = {J_ISCI},
  author       = {Lina Wang and Yichao He and Xizhao Wang and Zihang Zhou and Haibin Ouyang and Seyedali Mirjalili},
  doi          = {10.1016/j.ins.2024.121170},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121170},
  shortjournal = {Inf. Sci.},
  title        = {A novel discrete differential evolution algorithm combining transfer function with modulo operation for solving the multiple knapsack problem},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Least total logistic distance metric algorithm and its
variable step-size version. <em>ISCI</em>, <em>680</em>, 121169. (<a
href="https://doi.org/10.1016/j.ins.2024.121169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classical mean-square error (MSE)-based adaptive filtering algorithms are useful for noise-free inputs. However, if the input signal of the adaptive filter with such an adaptive filtering algorithm is corrupted by noise, it will suffer from serious degradation of steady-state performance. To address the problem, a new adaptive filtering algorithm is proposed in this work. This algorithm not only uses the total method to compensate the bias caused by noisy input but also minimizes the cost function based on logistic distance metric (LDM) to achieve robustness against impulsive noise. Compared with the existing algorithms, the proposed least total logistic distance metric (LTLDM) algorithm has less misalignment when the input signal is disturbed by noise and has good robustness to impulsive noise. This work also tackles the crucial trade-off between convergence rate and misalignment by developing a variable step-size for LTLDM. In addition, to give deep insight into the stochastic behavior of the proposed LTLDM, its mean-square deviation is analyzed at steady state. The advantage of LTLDM and the accuracy of theoretical expressions are verified by extensive simulations.},
  archive      = {J_ISCI},
  author       = {Qin Song and Yanglong Gu and Jingen Ni},
  doi          = {10.1016/j.ins.2024.121169},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121169},
  shortjournal = {Inf. Sci.},
  title        = {Least total logistic distance metric algorithm and its variable step-size version},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-label feature selection based on nonlinear mapping.
<em>ISCI</em>, <em>680</em>, 121168. (<a
href="https://doi.org/10.1016/j.ins.2024.121168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is one of the important pre-processing methods for dimensionality reduction in multi-label learning tasks, which has attracted extensive attention in recent years. Most of the existing approaches transform feature data into the label space during the feature-label mapping process by assuming linear relationship between the feature and label spaces. However, the linearity assumption does not hold in most cases, especially for high-dimensional spaces. This work proposes a novel dimension reduction model for multi-label data by using nonlinear mapping (NMFS). The model introduces a point-to-point sigmoid function to describe the intrinsic relationship from data space to label space. The proposed method improves the generalization ability of feature selection by limiting the range of data transformation to the interval [0,1] which is consistent with the predicted values of the labels. The feature weight matrix is constrained by the l 2 , 1 l2,1 -norm to ensure its sparsity, which forms the basis of feature selection. The variables in the NMFS model are iteratively updated using the gradient momentum optimization strategy, and a sparse weight-coefficient matrix is obtained for multi-label feature ordering. Experimental results on 14 multi-label data sets verify the effectiveness of the proposed method, and show the proposed method is superior to the most advanced multi-label feature selection methods.},
  archive      = {J_ISCI},
  author       = {Yan Wang and Changzhong Wang and Tingquan Deng and Wenqi Li},
  doi          = {10.1016/j.ins.2024.121168},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121168},
  shortjournal = {Inf. Sci.},
  title        = {Multi-label feature selection based on nonlinear mapping},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Probability-based event-triggered asynchronous control for
fuzzy jump systems. <em>ISCI</em>, <em>680</em>, 121167. (<a
href="https://doi.org/10.1016/j.ins.2024.121167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates asynchronous control strategies for a specific class of nonlinear semi-Markov jump systems using the T-S fuzzy model. The primary objective is to overcome bandwidth constraints and enhance system performance. A novel probabilistic event-triggered protocol is introduced, aimed at reducing the frequency of packet transmissions efficiently. Unlike conventional static event-triggered protocols, this developed probabilistic event-triggered protocol adeptly harnesses the dynamic nature of network-induced delays. Moreover, by incorporating probabilistic delay division, a novel control law associated with the delay probability segmentation variable is skillfully designed. Discrepancies between system and controller modes are addressed by adopting a hidden semi-Markov model. This approach leads to the derivation of comprehensive criteria ensuring the stochastic stability of the closed-loop system. Finally, a practical example is presented, demonstrating the efficacy and practicality of the proposed theoretical results.},
  archive      = {J_ISCI},
  author       = {Xiaoqiu Lv and Jun Cheng and Huaicheng Yan and Dan Zhang and Wenhai Qi},
  doi          = {10.1016/j.ins.2024.121167},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121167},
  shortjournal = {Inf. Sci.},
  title        = {Probability-based event-triggered asynchronous control for fuzzy jump systems},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Higher-order knowledge-enhanced recommendation with
heterogeneous hypergraph multi-attention. <em>ISCI</em>, <em>680</em>,
121165. (<a href="https://doi.org/10.1016/j.ins.2024.121165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in recommender systems have focused on integrating knowledge graphs (KGs) to leverage their auxiliary information. The core idea of KG-enhanced recommenders is to incorporate rich semantic information for more accurate recommendations. However, two main challenges persist: i) Neglecting complex higher-order interactions in the KG-based user-item network, potentially leading to sub-optimal recommendations, and ii) Dealing with the heterogeneous modalities of input sources, such as user-item bipartite graphs and KGs, which may introduce noise and inaccuracies. To address these issues, we present a novel Knowledge-enhanced Heterogeneous Hypergraph Recommender System (KHGRec). KHGRec captures group-wise characteristics of both the interaction network and the KG, modeling complex connections in the KG. Using a collaborative knowledge heterogeneous hypergraph (CKHG), it employs two hypergraph encoders to model group-wise interdependencies and ensure explainability. Additionally, it fuses signals from the input graphs with cross-view self-supervised learning and attention mechanisms. Extensive experiments on four real-world datasets show our model&#39;s superiority over various state-of-the-art baselines, with an average 5.18% relative improvement. Additional tests on noise resilience, missing data, and cold-start problems demonstrate the robustness of our KHGRec framework. Our model and evaluation datasets are publicly available at https://github.com/viethungvu1998/KHGRec .},
  archive      = {J_ISCI},
  author       = {Darnbi Sakong and Viet Hung Vu and Thanh Trung Huynh and Phi Le Nguyen and Hongzhi Yin and Quoc Viet Hung Nguyen and Thanh Tam Nguyen},
  doi          = {10.1016/j.ins.2024.121165},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121165},
  shortjournal = {Inf. Sci.},
  title        = {Higher-order knowledge-enhanced recommendation with heterogeneous hypergraph multi-attention},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linkable ring signature scheme with stronger security
guarantees. <em>ISCI</em>, <em>680</em>, 121164. (<a
href="https://doi.org/10.1016/j.ins.2024.121164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ring signatures enable a user to sign messages on behalf of an arbitrary set of users, called the ring. The signer-anonymity property guarantees that the signature does not reveal which member of the ring signed the message. The notion of linkable ring signatures (LRS) is an extension of the concept of ring signatures such that there is a public way of determining whether two signatures have been produced by the same signer. However, the existing LRS schemes may not be competent in some scenarios since they exhibit a gap to bridge as reflected on the security guarantees such as the absence of quantum-resistance, inadequate security notions, and a reliance on the random oracle heuristic . In this paper, we present a framework for LRS that provides stronger security guarantees. We instantiate the framework from standard lattice assumptions and prove the security in the standard model. Furthermore, we implement our scheme and conduct experimental evaluations, which demonstrate that the performances are practical for typical settings.},
  archive      = {J_ISCI},
  author       = {Mingxing Hu and Zhen Liu and Xiaojun Ren and Yunhong Zhou},
  doi          = {10.1016/j.ins.2024.121164},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121164},
  shortjournal = {Inf. Sci.},
  title        = {Linkable ring signature scheme with stronger security guarantees},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Partial label feature selection via label disambiguation and
neighborhood mutual information. <em>ISCI</em>, <em>680</em>, 121163.
(<a href="https://doi.org/10.1016/j.ins.2024.121163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial label learning aims to learn from training instances, each of which is associated with a set of candidate labels but only one is a ground-truth label. Feature selection is an effective method to improve the generalization capability of the learning model; however, partial label feature selection work is exceptionally challenging due to the limitation and ambiguity of label information. Therefore, this paper proposes a partial label feature selection algorithm based on label disambiguation and neighborhood mutual information. Firstly, neighborhood granularity is utilized to determine the neighborhoods of instances to disambiguate the candidate labels. Secondly, based on label confidence induced by disambiguation, feature relevance and redundancy are measured by neighborhood mutual information, which avoids the negative impact of data discretization on feature selection and directly handles continuous features. Concurrently, the kappa coefficient is employed to estimate the label consistency for describing the influences of feature changes on the label space. Then, the significance of each feature is evaluated by fusing feature relevance, feature redundancy, and label consistency. Finally, the effectiveness of the proposed algorithm is verified by comparing the proposed algorithm with four base classifiers and other feature selection methods. Furthermore, the feasibility of the proposed disambiguation method is demonstrated through comparison with four state-of-the-art disambiguation methods.},
  archive      = {J_ISCI},
  author       = {Jinfei Ding and Wenbin Qian and Yihui Li and Wenji Yang and Jintao Huang},
  doi          = {10.1016/j.ins.2024.121163},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121163},
  shortjournal = {Inf. Sci.},
  title        = {Partial label feature selection via label disambiguation and neighborhood mutual information},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Copyright protection framework for federated learning models
against collusion attacks. <em>ISCI</em>, <em>680</em>, 121161. (<a
href="https://doi.org/10.1016/j.ins.2024.121161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) models are constructed by multiple participants who provide their training datasets and collaborate in joint training. However, training and deployment processes have encountered various challenges in terms of intellectual property protection, such as illegal theft and data leakage. Existing FL protection frameworks focus on each client independently and verify the model ownership. When they are under collusion attacks (i.e., when multiple clients negotiate to steal together), they cannot accurately identify the clients that have stolen the model. To address this challenge, a novel watermarking protection scheme against collusion attacks for federated learning is proposed in this work. It employs anti-collusion coding to design unique watermark information for each client, which can effectively detect colluders. Furthermore, it utilizes a specific regularized loss function for watermark information embedding along with the incorporation of skip connections to embed the watermark information within each batch normalization layer. The experimental results demonstrated that embedding different watermark information into each client did not affect the accuracy of the original task. The accuracy was approximately 100% when identifying the colluders. The embedding and extraction times for the original task were only 1.53% and 0.29%, respectively. Further, it exhibited high robustness against various common attacks, including fine-tuning, shearing, and collusion attacks.},
  archive      = {J_ISCI},
  author       = {Yuling Luo and Yuanze Li and Sheng Qin and Qiang Fu and Junxiu Liu},
  doi          = {10.1016/j.ins.2024.121161},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121161},
  shortjournal = {Inf. Sci.},
  title        = {Copyright protection framework for federated learning models against collusion attacks},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SCICL: A sparse classifiers induced contrastive learning
method. <em>ISCI</em>, <em>680</em>, 121160. (<a
href="https://doi.org/10.1016/j.ins.2024.121160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective self-supervised learning method for pre-training feature embeddings, contrastive learning aims at capturing the consistent information between augmented views of the input sample. The consistent information is considered to be discriminative, yet the precise semantics it entails remain elusive. Through experimentation, we further discover that consistent information is related to both invariant information between augmented views and partially varying information, but it may not necessarily be discriminative. Furthermore, our theoretical analysis reveals that employing sparse classifiers to ensure the invariance of soft labels can effectively assist neural networks in capturing discriminative features. Building upon the insights, we leverage sparse classifiers in combination with contrastive learning to ensure that the soft labels and the learned representations of different augmented views remain aligned simultaneously and call the method Sparse Classifiers Induced Contrastive Learning (SCICL). Extensive experimental results on various datasets and backbones show that SCICL can lead to stable improvements in performance, demonstrating that SCICL can facilitate the network in extracting more discriminative feature representations.},
  archive      = {J_ISCI},
  author       = {Ruojin Zhou and Hongjie Zhang and Bo Gong and Ling Jing},
  doi          = {10.1016/j.ins.2024.121160},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121160},
  shortjournal = {Inf. Sci.},
  title        = {SCICL: A sparse classifiers induced contrastive learning method},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The model for the repeated propagation of information from
constant spreaders based on individual cognition levels. <em>ISCI</em>,
<em>680</em>, 121159. (<a
href="https://doi.org/10.1016/j.ins.2024.121159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On social media platforms, high-impact disseminators act as fixed sources of crucial news, consistently affecting information dissemination. Throughout the process of repeated information dissemination, the audience’s cognition gradually evolves, thereby shaping the pattern and effectiveness of information dissemination. In this study, we present a comprehensive analytical framework and a model for repeated information dissemination, to explain the dynamics of information flow from fixed communicators on social media platforms as well as the dynamic evolution of audience cognition. The model incorporates periodic information sources and considers the directionality of propagation. Through quantitative analysis, we assess the evolution of audience cognition during repeated dissemination and investigate the impact of source complexity, dissemination periodicity, audience psychological fatigue, and cognitive disparities on dissemination effectiveness. Theoretical analysis reveals periodic solutions and threshold conditions for persistence in information dissemination. Furthermore, our research finds that moderate propaganda frequency and intensity can enhance dissemination effectiveness; whereas excessive propaganda may induce fatigue and reduce audience cognition efficacy. Empirical validation of the model demonstrates its effectiveness, offering new perspectives and scientific basis for understanding mechanisms of social media information dissemination and optimizing strategies for news dissemination.},
  archive      = {J_ISCI},
  author       = {Yan Wang and Chunzhang Miao and Chuanbiao Wang and Mo Yang and Mingyu Cui and Yanjun Lin},
  doi          = {10.1016/j.ins.2024.121159},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121159},
  shortjournal = {Inf. Sci.},
  title        = {The model for the repeated propagation of information from constant spreaders based on individual cognition levels},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A federated GAN network-based evolutionary constrained
optimization approach to integrated coal mine energy system.
<em>ISCI</em>, <em>680</em>, 121158. (<a
href="https://doi.org/10.1016/j.ins.2024.121158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integrated coal mine energy system (ICMES) is a kind of system with multiple scenarios, variables and parameters, which belongs to dynamic constrained multi-objective optimization problem (DCMOP). One of the challenges in solving ICMES lies in searching for feasible solutions when the frequency of changes is quick. To solve the above mentioned issues, this paper proposes a federated GAN network-based evolutionary constrained optimization for ICMES (FGECO). Firstly, multiple GAN networks are utilized in the framework of federated learning (FL) to estimate the distribution of feasible regions that satisfy each constraint. Following that, they are fused to realize the intersection of all feasible regions, and generate one feasible region that can meet all constrained requirements. Subsequently, an initial population with guidance of evolution is generated based on the proposed shared GAN network model. Finally, FGECO is compared with four popular dynamic constrained multi-objective evolutionary algorithms (DCMOEAs) on ICMES. Experimental results indicate its superiority.},
  archive      = {J_ISCI},
  author       = {Na Hu and Chi Zhang and Miao Rong and Na Geng and Dunwei Gong},
  doi          = {10.1016/j.ins.2024.121158},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121158},
  shortjournal = {Inf. Sci.},
  title        = {A federated GAN network-based evolutionary constrained optimization approach to integrated coal mine energy system},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-class imbalance problem: A multi-objective solution.
<em>ISCI</em>, <em>680</em>, 121156. (<a
href="https://doi.org/10.1016/j.ins.2024.121156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-class imbalance problems are frequently encountered in real-world applications of machine learning. They have fundamentally complex trade-offs between classes. Existing literature tends to use a predetermined rebalancing strategy and mainly focuses on overall performance measures. However, in many real-world problems, the true level of imbalance and the relative importance between classes are unknown, making it difficult to predetermine the rebalancing strategy and the evaluation criterion. In this paper, we explicitly consider the between-class trade-off issue in the multi-class imbalance problem. We consider all the classes to be important and find a set of optimal trade-offs for the decision-maker to choose from. To reduce the computational cost of this process and make it a practical method, we seek the help of selective ensemble and multiple undersampling rates, and propose the Multi-class Multi-objective Selective Ensemble (MMSE) framework. We further equip the objective modeling with margins to reduce the number of objectives when the task has many classes. Experimental results show that our proposed methods successfully obtain diverse and highly competitive solutions within an acceptable running time.},
  archive      = {J_ISCI},
  author       = {Yi-Xiao He and Dan-Xuan Liu and Shen-Huan Lyu and Chao Qian and Zhi-Hua Zhou},
  doi          = {10.1016/j.ins.2024.121156},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121156},
  shortjournal = {Inf. Sci.},
  title        = {Multi-class imbalance problem: A multi-objective solution},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). First-order rule partitions-based decomposition technique of
type-1 and interval type-2 rule-based fuzzy systems for computational
and memory efficiency. <em>ISCI</em>, <em>680</em>, 121154. (<a
href="https://doi.org/10.1016/j.ins.2024.121154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rule-based fuzzy systems are widely adopted in various fields for their effectiveness in reducing uncertainties. However, large rule bases present significant computational and memory challenges, especially for real-time applications. To overcome this limitation, this paper introduces a novel first-order rule partitions-based decomposition technique (FORPs-DT) for type-1 (T1) and interval type-2 (IT2) fuzzy logic systems (FLSs). This method involves decomposing the universe of discourse, membership functions (MFs), and fuzzy sets (FSs) by defining conditions for non-zero firing levels (intervals). Significantly, this approach allows the construction of subfuzzy systems with separate knowledge bases while maintaining the input–output relationship. The paper provides detailed explanations and visual representations of FORPs-DT and proposes a case of identical FORPs to illustrate its simplicity and resource optimization benefits. Extensive experiments demonstrate the superiority of this technique, showcasing not only reduced execution time and memory usage but also enhanced performance through identical partitions, which allows an increase in the number of FSs without additional computational or memory overhead.},
  archive      = {J_ISCI},
  author       = {Abdessamad El Mobaraky and Khalid Kouiss and Ahmed Chebak},
  doi          = {10.1016/j.ins.2024.121154},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121154},
  shortjournal = {Inf. Sci.},
  title        = {First-order rule partitions-based decomposition technique of type-1 and interval type-2 rule-based fuzzy systems for computational and memory efficiency},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new “e-e” paradigm to construct multi-BPAs based belief
jensen divergence in the evidence theory. <em>ISCI</em>, <em>680</em>,
121153. (<a href="https://doi.org/10.1016/j.ins.2024.121153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present study solves two problems in the evidence theory. The first problem is the belief entropies have rarely been exploited to induce a belief Jensen divergence family. We provide a solution by proposing two general paradigms, i.e. the “I-P-E” (Information theory-Probability theory-Evidence theory) and “E-E” (Evidence theory-Evidence theory) paradigms. Particularly, the “E-E” paradigm defines the first belief Jensen divergence family that is induced by belief entropies. The second problem is the “E-E” paradigm has rarely been generalized to multiple evidence-based belief Jensen divergences. We settle it by proposing a new Belief Jensen-PGDI (Pignistic Gini Deng Impurity) divergence as a gap filler. To ensure the divergence&#39;s feasibility in mathematics, we make two auxiliary works: the Enhanced Pignistic transformation is refined, and a new belief entropy called PGDI is constructed. Several axiomatic properties are also proven for the new divergence, guaranteeing its theoretical rigorousness. We successfully apply this divergence in two evidence fusion challenges, empirically verifying its practicality.},
  archive      = {J_ISCI},
  author       = {Jiaxu Zhang and Shengchun Wang and Juan Tan and Liang Wang},
  doi          = {10.1016/j.ins.2024.121153},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121153},
  shortjournal = {Inf. Sci.},
  title        = {A new “E-e” paradigm to construct multi-BPAs based belief jensen divergence in the evidence theory},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised domain adaptation with hard-sample dividing and
processing strategy. <em>ISCI</em>, <em>680</em>, 121152. (<a
href="https://doi.org/10.1016/j.ins.2024.121152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Unsupervised Domain Adaptation(UDA), the hard samples cause serious negative transfer to model performance. However, the existing UDA methods don’t fully pay attention to the fine-grained processing of hard samples in target and source domains. To address these problems, the UDA framework with Hard-sample Dividing and Processing Strategy (HDPS) is proposed in this paper. In HDPS, we define sample division criteria in target domain and source domain respectively and divide the samples into easy samples, hard samples with low confidence and hard samples with high confidence. We further design systematic processing strategy of the three types of samples. Specifically, we firstly define geometric metrics based on the class prototype to divide the hard samples and eliminate them in source domain. We further design two weight allocation strategies based on sample classification entropy in target domain. Finally, we build a teacher-student guidance mechanism to learn the discriminative features of hard samples. The HDPS framework can be easily loaded to other methods as a plug-in, can promote the diversity feature learning of samples, and significantly improve the discriminant performance of the model. Extensive experiments on six benchmark datasets verify that HDPS is effective and superior to most existing UDA methods.},
  archive      = {J_ISCI},
  author       = {Chunmei He and Kang Zhou and Jing Tang and Shengyu Wu and Zhengchun Ye},
  doi          = {10.1016/j.ins.2024.121152},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121152},
  shortjournal = {Inf. Sci.},
  title        = {Unsupervised domain adaptation with hard-sample dividing and processing strategy},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Takagi-sugeno fuzzy sampled-data observer design for
nonlinear permanent magnet synchronous generator-based wind turbine
systems using auxiliary function-based integral inequality technique.
<em>ISCI</em>, <em>680</em>, 121151. (<a
href="https://doi.org/10.1016/j.ins.2024.121151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on designing the fuzzy sampled-data observer (FSDO) scheme for nonlinear permanent magnet synchronous generator (PMSG)-based wind turbine systems (WTS). The primary objective of this problem is to solve an unmeasurable state problem under the mismatched premise variables conditions among system, observer, and controller, respectively. To do this, firstly, the proposed wind turbine model is described in a Takagi-Sugeno fuzzy model due to the complex nonlinearities in PMSG-based WTS. Next, based on the measured output signals and sampled estimated states, the FSDO is designed to understand some unmeasurable state variables of the studied system. Then, a novel auxiliary function-based integral inequality (AFBII) is presented to approximate the integral quadratic terms related to sampling information. Thanks to the proposed AFBII technique and the introduction of slack variables, several new and less conservative stability requirements are derived in the formulations of linear matrix inequalities (LMIs) using the looped Lyapunov function. Finally, the simulation studies for the considered wind turbine model are validated numerically, and then some comparative results are provided to show the superiority and applicability of the theoretical observations.},
  archive      = {J_ISCI},
  author       = {Pratap Anbalagan and Jae Hoon Jeong and Young Hoon Joo},
  doi          = {10.1016/j.ins.2024.121151},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121151},
  shortjournal = {Inf. Sci.},
  title        = {Takagi-sugeno fuzzy sampled-data observer design for nonlinear permanent magnet synchronous generator-based wind turbine systems using auxiliary function-based integral inequality technique},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). State estimation for proportional delayed complex-valued
memristive neural networks. <em>ISCI</em>, <em>680</em>, 121150. (<a
href="https://doi.org/10.1016/j.ins.2024.121150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper addresses the issue of state estimation for a kind of complex-valued memristive neural networks (CVMNNs) accompanied by proportional delays, without applying regular split method of CVMNNs. By virtue of constructing pertinent Lyapunov functional (LF), and deploying matrix inequality techniques, various delay-dependent principles for scrutinizing the asymptotical stability of the estimation error system of the CVMNNs are constituted by linear matrix inequalities (LMIs) with CV variables. Examples are portrayed to manifest the validity and accuracy of the raised principles, and demonstrated applications in image security.},
  archive      = {J_ISCI},
  author       = {Yongkang Zhang and Liqun Zhou},
  doi          = {10.1016/j.ins.2024.121150},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121150},
  shortjournal = {Inf. Sci.},
  title        = {State estimation for proportional delayed complex-valued memristive neural networks},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-attention and forgetting fusion knowledge tracking
algorithm. <em>ISCI</em>, <em>680</em>, 121149. (<a
href="https://doi.org/10.1016/j.ins.2024.121149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracking is a method to determine students’ potential knowledge states based on their historical learning trajectory and to track students’ knowledge states in real-time to foretell their future learning circumstances. To solve the problem that existing algorithms ignore weak analysis of feature independence between different test questions, we propose the algorithm SATFKT . SATFKT integrates difficulty division and discrimination of test questions into input features. This helps knowledge tracking tasks better model and analyze students’ mastery of knowledge concepts. An algorithm, SAFFKT , is also proposed to further solve the problem of existing algorithms neglecting students’ memory and forgetting behavior. SAFFKT is formed by adding a forgotten update layer and a memory reading layer to the original hierarchical structure of SATFKT. The forgotten update layer helps the knowledge tracking task process the forgetting before the students answer questions. After students have finished answering questions, the knowledge state is further updated by the memory reading layer based on the answers. These two additional network modules help the model simulate students’ learning and forgetting behaviors more realistically. Compared with traditional knowledge tracking models and other models that consider forgetting behavior, our model predicts higher AUC values and proves the effectiveness of SAFFKT.},
  archive      = {J_ISCI},
  author       = {Jianfeng Song and Yukai Wang and Chu Zhang and Kun Xie},
  doi          = {10.1016/j.ins.2024.121149},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121149},
  shortjournal = {Inf. Sci.},
  title        = {Self-attention and forgetting fusion knowledge tracking algorithm},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Open-world structured sequence learning via dense target
encoding. <em>ISCI</em>, <em>680</em>, 121147. (<a
href="https://doi.org/10.1016/j.ins.2024.121147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structured sequences are popularly used to describe graph data with time-evolving node features and edges. A typical real-world scenario of structured sequences is that unknown class labels continuously arrive and thus the training and testing often across different class spaces. This scenario is also referred to as the open-world learning problem on structured sequences . In this paper, we present a new Dense Open-world Structured Sequence Learning model (DOSSL for short) to learn graph streams in the open-world learning setting. To capture both structural and temporal information, DOSSL uses a GNN-based stochastic recurrent neural network for learning node representation in graph streams, then a truncated Laplacian distribution to describe the latent distribution of graph nodes, and a sampling function is used to generate node representations. Further, DOSSL learns dense target embeddings for the known classes to improve the compactness of known class distribution and reserve enough space for open-world unknown classes. The ultimate open-world classifier is optimized to detect the samples from unknown classes under the constraints of DVAE loss, label loss, class uncertainty loss, and dense target loss. Through empirical analysis conducted on real-world datasets, it has been demonstrated that the advanced technique known as DOSSL exhibits the ability to acquire precise node classifiers by harnessing the power of graph streams.},
  archive      = {J_ISCI},
  author       = {Qin Zhang and Ziqi Liu and Qincai Li and Haolong Xiang and Zhizhi Yu and Junyang Chen and Peng Zhang and Xiaojun Chen},
  doi          = {10.1016/j.ins.2024.121147},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121147},
  shortjournal = {Inf. Sci.},
  title        = {Open-world structured sequence learning via dense target encoding},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diverse randomized value functions: A provably pessimistic
approach for offline reinforcement learning. <em>ISCI</em>,
<em>680</em>, 121146. (<a
href="https://doi.org/10.1016/j.ins.2024.121146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline Reinforcement Learning (RL) faces challenges such as distributional shift and unreliable value estimation, especially for out-of-distribution (OOD) actions. To address these issues, existing uncertainty-based methods penalize the value function with uncertainty quantification and require numerous ensemble networks, leading to computational challenges and suboptimal outcomes. In this paper, we introduce a novel strategy that employs diverse randomized value functions to estimate the posterior distribution of Q -values. This approach provides robust uncertainty quantification and estimates the lower confidence bounds (LCB) of Q -values. By applying moderate value penalties for OOD actions, our method fosters a provably pessimistic approach. We also emphasize diversity within randomized value functions and enhance efficiency by introducing a diversity regularization method, thereby reducing the requisite number of networks. These modules result in reliable value estimation and efficient policy learning from offline data. Theoretical analysis shows that our method recovers the provably efficient LCB-penalty under linear MDP assumptions. Extensive empirical results demonstrate that our proposed method significantly outperforms baseline methods in terms of performance and parametric efficiency.},
  archive      = {J_ISCI},
  author       = {Xudong Yu and Chenjia Bai and Hongyi Guo and Changhong Wang and Zhen Wang},
  doi          = {10.1016/j.ins.2024.121146},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121146},
  shortjournal = {Inf. Sci.},
  title        = {Diverse randomized value functions: A provably pessimistic approach for offline reinforcement learning},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse feature selection and rare value prediction in
imbalanced regression. <em>ISCI</em>, <em>680</em>, 121145. (<a
href="https://doi.org/10.1016/j.ins.2024.121145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection addresses the dimensionality-reduction problem by determining a subset of available features, which facilitates the construction of effective prediction models. However, with regression tasks where the target variable is continuous and imbalanced, ordinary feature-selection techniques cannot be simply used without adjustment. This paper proposes SerEnet, a novel method of sparse feature selection in imbalanced regression, which explores both feature selection and estimation simultaneously by minimizing the Squared Error-Relevance with respect to a cutoff t ( S E R t SERt ), subject to a sparse penalty. Specifically, S E R t SERt considers the performance of target variables with relevance greater than t in the target-variable domain and emphasizes the error of rare values. Moreover, SerEnet can effectively identify features that contribute significantly to rare cases, thereby reducing the dominant influence of common instances on feature selection, and improving prediction performance for both rare values and overall data. Experimental results on simulated and real datasets show that SerEnet outperformed several algorithms in terms of prediction performance on continuous-imbalanced data.},
  archive      = {J_ISCI},
  author       = {Ying Guan and Guang-Hui Fu},
  doi          = {10.1016/j.ins.2024.121145},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121145},
  shortjournal = {Inf. Sci.},
  title        = {Sparse feature selection and rare value prediction in imbalanced regression},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RuMER-RL: A hybrid framework for sparse knowledge graph
explainable reasoning. <em>ISCI</em>, <em>680</em>, 121144. (<a
href="https://doi.org/10.1016/j.ins.2024.121144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph (KG) reasoning is a crucial technology for ensuring the accuracy and utility of KGs. However, robust and explainable reasoning on sparse KGs is challenging due to the lack of information and truncated paths. To address this issue, we introduce RuMER-RL, a hybrid reasoning framework comprising three modules: Rule Mining (RM), Embedding Representation (ER), and Reinforcement Learning (RL). The ER and RM modules collaborate to enhance the embedding models and rule quality, generating additional triples to mitigate the sparsity of the KG. The RL module models multi-hop KG reasoning as a Markov Decision Process (MDP), employing dynamic anticipation, action space expansion, and curiosity-driven strategies to enrich the reasoning process and mitigate sparsity. Additionally, we reshape the reward function by incorporating embedding representation, rule matching, and curiosity rewards to guide the training and optimization of the policy network. Extensive experiments on six sparse KG datasets demonstrate that RuMER-RL outperforms state-of-the-art models in terms of link prediction accuracy and interpretability.},
  archive      = {J_ISCI},
  author       = {Zefan Zeng and Qing Cheng and Yuehang Si and Zhong Liu},
  doi          = {10.1016/j.ins.2024.121144},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121144},
  shortjournal = {Inf. Sci.},
  title        = {RuMER-RL: A hybrid framework for sparse knowledge graph explainable reasoning},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonconvex fusion penalties for high-dimensional hierarchical
categorical variables. <em>ISCI</em>, <em>680</em>, 121143. (<a
href="https://doi.org/10.1016/j.ins.2024.121143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical categorical data is commonly encountered in social science, genetics, and other fields. The interactions between variables in hierarchical structures introduce complexity in modeling and predicting. We focus on modeling the high-dimensional linear models with hierarchical categorical variables and introduce an efficient method. The proposed method offers computational advantages when dealing with high-dimensional categorical data. In the theoretical part, we demonstrate the uniqueness of the solution and show that the proposed estimator converges the least square solution under the high probability. Additionally, we showcase the effectiveness of our method on two real-world datasets, a cancer-reg dataset and an adult dataset, and simulated datasets, where our method outperforms comparative approaches in terms of predictive accuracy, variable selection, and model complexity.},
  archive      = {J_ISCI},
  author       = {Zixuan Zhao and Yuehan Yang},
  doi          = {10.1016/j.ins.2024.121143},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121143},
  shortjournal = {Inf. Sci.},
  title        = {Nonconvex fusion penalties for high-dimensional hierarchical categorical variables},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Traffic prediction based on spatial-temporal disentangled
generative models. <em>ISCI</em>, <em>680</em>, 121142. (<a
href="https://doi.org/10.1016/j.ins.2024.121142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the underlying spatial-temporal patterns in a traffic network is crucial for accurate predictions. However, current deep learning techniques often struggle to effectively identify the generative factors hidden in spatial-temporal traffic data, leading to a lack of interpretability. To address this challenge, we have developed an innovative generative model called Spatial-Temporal Disentangled Neural Relational Inference (STDNRI) for traffic prediction and disentangling interpretable generative factors within observed traffic network data. In this study, we assume that spatial-temporal data is dominated by three generative factors: time-correlated factors, spatial-correlated factors and spatial-temporal joint correlation factors. Based on information bottleneck theory, we establish a novel objective function to maximize the disentanglement of different factors. To model the probability distributions of three factors, we propose three graph neural network encoders to represent time-correlated factors using a graph containing only self-loops, and denote spatial-correlated factors as well as spatial-temporal joint correlation factors adopting a fully-connected graph without self-loops. Then, graph neural network decoder with a spatial-temporal message passing mechanism is used to generate the final predictions. Several comprehensive experiments were conducted based on two real datasets from NYC Yellow Taxi and SHMetro. The results indicate that our STDNRI outperforms ten existing competitive models in terms of high prediction accuracy and provides excellent interpretability for generative factors. Furthermore, the disentangled interpretable factors can afford valuable insights for planners, urban developers, and other stakeholders to gain a deeper understanding of the dynamics of the traffic network, thus enabling more informed decision-making.},
  archive      = {J_ISCI},
  author       = {Xinyu Gao and Hongtao Li and Haina Zhang and Jiang Xue and Shaolong Sun and Wenzheng Liu},
  doi          = {10.1016/j.ins.2024.121142},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121142},
  shortjournal = {Inf. Sci.},
  title        = {Traffic prediction based on spatial-temporal disentangled generative models},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). OPT-CO: Optimizing pre-trained transformer models for
efficient COVID-19 classification with stochastic configuration
networks. <em>ISCI</em>, <em>680</em>, 121141. (<a
href="https://doi.org/10.1016/j.ins.2024.121141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building upon pre-trained ViT models, many advanced methods have achieved significant success in COVID-19 classification. Many scholars pursue better performance by increasing model complexity and parameters. While these methods can enhance performance, they also require extensive computational resources and extended training times. Additionally, the persistent challenge of overfitting, due to limited COVID-19 dataset sizes, remains a hurdle. To address these challenges, we proposed a novel method to optimize pre-trained transformer models for efficient COVID-19 classification with stochastic configuration networks (SCNs), referred to as OPT-CO. We proposed two optimization methods: sequential optimization (SeOp) and parallel optimization (PaOp), by incorporating optimizers in a sequential and parallel manner, respectively. Our method can enhance model performance without necessitating a significant parameter expansion. Additionally, we introduced OPT-CO-SCN to avoid overfitting problems through the adoption of random projection for head augmentation. The experiments were carried out to evaluate the performance of our proposed model based on two publicly available datasets. Based on the evaluation results, our method achieved superior, performance surpassing other state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Ziquan Zhu and Lu Liu and Robert C. Free and Ashiq Anjum and John Panneerselvam},
  doi          = {10.1016/j.ins.2024.121141},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121141},
  shortjournal = {Inf. Sci.},
  title        = {OPT-CO: Optimizing pre-trained transformer models for efficient COVID-19 classification with stochastic configuration networks},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Greedy deep stochastic configuration networks ensemble with
boosting negative correlation learning. <em>ISCI</em>, <em>680</em>,
121140. (<a href="https://doi.org/10.1016/j.ins.2024.121140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep stochastic configuration networks (DSCNs) employ data-dependent supervision mechanism to randomly assign node parameters and incrementally construct the deep neural network structure, thereby ensuring the model&#39;s universal approximation property. To build a random neural networks ensemble model with better generalization performance, we propose a novel greedy deep stochastic configuration networks ensemble model based on boosting negative correlation learning, termed as GDSCNE. Firstly, greedy optimization strategy based on inequality constraints is utilized to generate random parameters of base components with multi-layer architecture, which can accelerate the decline of network residuals when configuring a new node. Additionally, boosting negative correlation learning framework is presented for the base components ensemble process, which uses least square approach with negative correlation learning penalty term to update the ensemble output weights for each base component, subsequently, boosting method is applied to construct a stronger ensemble model by adaptive weighting through the results of base components. Finally, we evaluated GDSCNE on the popular regression benchmark datasets from the KEEL, experimental results demonstrate that GDSCNE outperforms state-of-the-art random learning algorithms in terms of regression accuracy and generalization performance across several regression datasets with varying sizes.},
  archive      = {J_ISCI},
  author       = {Chenglong Zhang and Yang Wang and David Zhang},
  doi          = {10.1016/j.ins.2024.121140},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121140},
  shortjournal = {Inf. Sci.},
  title        = {Greedy deep stochastic configuration networks ensemble with boosting negative correlation learning},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Competitive net influence maximization on intergroup debate
effect. <em>ISCI</em>, <em>680</em>, 121139. (<a
href="https://doi.org/10.1016/j.ins.2024.121139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intergroup debate effect describes that how divergences between groups mobilize members to act in the interest of the group, thus intensifying conflicts. In online social networks, such debates can cause an explosion of information discussions and amplify the influence. Therefore, the Intergroup Debate Independent Cascade (IDIC) Model is proposed. The Controversial Net Influence Maximization (CNIM) problem is introduced to select individuals who post information to maximize the net influence. Since the objective function is non-submodular, the Sandwich framework decomposes the objective function into submodular upper and lower bounds, thus providing data-dependent approximate solution. Moreover, these bounds extended to the broader problem of net influence maximization under the Heterogeneous Competitive Independent Cascade (HCIC) model, where the probability depends on the type of information. To solve this broader problem, we propose the Heterogeneous Competitive Influence Sampling based Greedy (HCISG) Algorithm based on the reverse sampling and further refine it to obtain the Improved HCISG algorithm, in addition to introducing a pruning strategy for the bounds. Conclusively, evaluations on simulated and realistic datasets demonstrate the efficiency of the Improved HCISG Algorithm. We find that more cohesive groups bring about greater information explosions in intergroup debates, which resonates with group conflicts as described by social identity theory.},
  archive      = {J_ISCI},
  author       = {Jialing Dai and Jianming Zhu and Guoqing Wang},
  doi          = {10.1016/j.ins.2024.121139},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121139},
  shortjournal = {Inf. Sci.},
  title        = {Competitive net influence maximization on intergroup debate effect},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hypergraph-based convex semi-supervised unconstraint
symmetric matrix factorization for image clustering. <em>ISCI</em>,
<em>680</em>, 121138. (<a
href="https://doi.org/10.1016/j.ins.2024.121138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised symmetric nonnegative matrix factorization (SNMF) has been extensively utilized in both linear and nonlinear data clustering tasks. However, the current SNMF model&#39;s non-convex objective function faces challenges in global optimization and time efficiency. In this study, we leverage label information to propose a convex and unconstrained symmetric matrix factorization (SMF) model that is thoroughly analyzed for its convexity properties. In order to capture high-order relationships among data, a hypergraph is utilized in the model, which is computationally simple, translation invariant, and naturally normalized. Moreover, based on the analysis and the corresponding experiments in the paper, the model exhibits robustness towards outliers to some extent. Due to the convexity of our proposed model without constraint, it can be efficiently optimized using the Conjugate Gradient (CG) method, one of the most efficient methods available. Therefore, we propose a novel Convex Combination-based Sufficient Descent CG (CSDCG) method, which outperforms other methods across 284 optimization problems within the CUTEst library. In order to evaluate the effectiveness of the proposed method, the semi-supervised clustering experiments are conducted on the eight datasets by comparison with ten state-of-the-art matrix factorization (MF) methods. The experiment results demonstrate its superiority over the other compared methods to handle the clustering problem with better performance and less computational time. The code is available at https://github.com/Pokemer/HCSSMF .},
  archive      = {J_ISCI},
  author       = {Wenjun Luo and Zezhong Wu and Nan Zhou},
  doi          = {10.1016/j.ins.2024.121138},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121138},
  shortjournal = {Inf. Sci.},
  title        = {Hypergraph-based convex semi-supervised unconstraint symmetric matrix factorization for image clustering},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Surrogate-assisted evolutionary framework with an ensemble
of teaching-learning and differential evolution for expensive
optimization. <em>ISCI</em>, <em>680</em>, 121137. (<a
href="https://doi.org/10.1016/j.ins.2024.121137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-Assisted Evolutionary Algorithms (SAEAs) integrate Evolutionary Algorithms (EAs) with surrogate models to reduce the actual number of expensive function evaluations and have been widely used in solving Expensive Optimization Problems (EOPs). However, because of the insufficient diversity of new solutions, SAEAs often fall into local optima and result in evolutionary stagnation when dealing with complex problems. To improve the diversity of new solutions, this paper introduces a S urrogate- A ssisted evolutionary F ramework with an ensemble of T eaching-learning and D ifferential evolution (SAF-TD), which successfully integrates the strengths of both EAs to produce more diverse and effective solutions. The main contributions are summarized as follows: First, a novel framework that effectively integrates two distinct EAs using a radial basis function surrogate model and strategic sampling is introduced. Second, a mutation strategy with a supervisory mechanism is proposed to enhance mutation effectiveness and avoid stagnation. Third, a volatility index derived from dimensional improvements is incorporated into parameter control to address fitness-dependent weaknesses. Experiments on five expensive optimization functions and the CEC2017 test suite across multiple dimensions were conducted to evaluate the performance of SAF-TD. The results demonstrate that SAF-TD is highly competitive compared with state-of-the-art SAEAs and exhibits excellent performance in solving EOPs.},
  archive      = {J_ISCI},
  author       = {Xin Lin and Zhenyu Meng},
  doi          = {10.1016/j.ins.2024.121137},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121137},
  shortjournal = {Inf. Sci.},
  title        = {Surrogate-assisted evolutionary framework with an ensemble of teaching-learning and differential evolution for expensive optimization},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Opt2Vec - a continuous optimization problem representation
based on the algorithm’s behavior: A case study on problem
classification. <em>ISCI</em>, <em>680</em>, 121134. (<a
href="https://doi.org/10.1016/j.ins.2024.121134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Characterization of the optimization problem is a crucial task in many recent optimization research topics (e.g., explainable algorithm performance assessment, and automated algorithm selection and configuration). The state-of-the-art approaches use exploratory landscape analysis to represent the optimization problem, where for each one, a set of features is extracted using a set of candidate solutions sampled by a sampling strategy over the whole decision space. This paper proposes a novel representation of continuous optimization problems by encoding the information found in the interaction between an algorithm and an optimization problem. The new problem representation is learned using the information from the states/positions in the optimization run trajectory (i.e., the candidate solutions visited by the algorithm). With the novel representation, the problem can be characterized dynamically during the optimization run, instead of using a set of candidate solutions from the whole decision space that have never been observed by the algorithm. The novel optimization problem representation is called Opt2Vec and uses an autoencoder type of neural network to encode the information found in the interaction between an optimization algorithm and optimization problem into an embedded subspace. The Opt2Vec representation efficiency is shown by enabling different optimization problems to be successfully identified using only the information obtained from the optimization run trajectory.},
  archive      = {J_ISCI},
  author       = {Peter Korošec and Tome Eftimov},
  doi          = {10.1016/j.ins.2024.121134},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121134},
  shortjournal = {Inf. Sci.},
  title        = {Opt2Vec - a continuous optimization problem representation based on the algorithm&#39;s behavior: A case study on problem classification},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ORKM: Online regularized k-means clustering for online
multi-view data. <em>ISCI</em>, <em>680</em>, 121133. (<a
href="https://doi.org/10.1016/j.ins.2024.121133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data generated from different sources are sometimes referred to as multi-view data, and as online multi-view data if a time dimension is involved in generating the data. This paper concerns clustering online multi-view data where overfitting and computation intensity are existent challenges. Here we propose an Online Regularized K -Means Clustering (ORKMC) method to tackle these challenges. Specifically, we use a matrix factorization strategy to identify the cluster indicator matrix and cluster mean matrix for all generated data points; and this strategy also includes a clustering complexity regularization term to harness the possible overfitting or overclustering. To reduce computation intensity, we propose an online update step in clustering where clustering is performed on only the latest view data at each update. Through a simulation study and analysis of two real-world data examples, we show that the proposed ORKMC method performs better than the current widely-used clustering methods in terms of clustering accuracy and computation efficiency. Finally, we develop an R package ORKM to implement ORKMC.},
  archive      = {J_ISCI},
  author       = {Guangbao Guo and Miao Yu and Guoqi Qian},
  doi          = {10.1016/j.ins.2024.121133},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121133},
  shortjournal = {Inf. Sci.},
  title        = {ORKM: Online regularized K-means clustering for online multi-view data},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A robust reconstruction method based on local bayesian
estimation combined with CURE clustering. <em>ISCI</em>, <em>680</em>,
121132. (<a href="https://doi.org/10.1016/j.ins.2024.121132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to their good approximation accuracy and local fitting characteristics, the moving least squares (MLS) and moving total least squares (MTLS) methods are widely used in various engineering fields. However, neither of these two methods is robust and they cannot effectively deal with outliers in measurement data. To eliminate the negative influence of outliers and achieve robust reconstruction, a novel MTLS method is proposed in this paper, which introduces local Bayesian estimation combined with clustering using representatives (CURE) algorithm. In the support domain, this method adopts a two-step process to remove the abnormal points and adjust the weights of discrete points through compound weighting. Bayesian estimation is first performed on discrete points to derive the reference model, and the residuals are calculated as the input of CURE clustering. The points with large residuals are classified into one cluster and removed. The remaining points undergo repeated processing until the iteration concludes. A gradient weight function based on the residuals and a compact support weight function are combined to determine the final estimated value using weighted Bayesian estimation. The simulations and experiments demonstrate that the proposed reconstruction method achieves excellent accuracy and robustness, surpassing several existing methods when handling highly contaminated datasets.},
  archive      = {J_ISCI},
  author       = {Tianqi Gu and Cheng Kang and Dawei Tang and Shuwen Lin and Tianzhi Luo},
  doi          = {10.1016/j.ins.2024.121132},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121132},
  shortjournal = {Inf. Sci.},
  title        = {A robust reconstruction method based on local bayesian estimation combined with CURE clustering},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). MIFuGP: Boolean network inference from multivariate time
series using fuzzy genetic programming. <em>ISCI</em>, <em>680</em>,
121129. (<a href="https://doi.org/10.1016/j.ins.2024.121129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Boolean network inference is essential for gaining insights into gene regulatory networks through multivariate gene expression time series. However, most existing algorithms cannot accurately reconstruct large-scale Boolean networks due to the complex and diverse relationships among genes and the overfitting problem. To address these problems, a novel inference algorithm using a mutual information-based fuzzy genetic programming approach (MIFuGP) is proposed to infer large-scale Boolean networks accurately. To represent complex regulatory relationships in Boolean networks, MIFuGP encodes Boolean functions as syntax tree programs. Taking the dependency between genes into account, MIFuGP fully extracts the mutual information from the syntax trees to alleviate the bloat problem. MIFuGP also provides a novel fitness function to make full use of state-transitions and topology information, together with a fuzzy logic control strategy to reduce the overfitting problem. Extensive experiments validate that MIFuGP significantly outperforms state-of-the-art algorithms on both real-world gene regulatory networks and artificial Boolean networks.},
  archive      = {J_ISCI},
  author       = {Xiang Liu and Yan Wang and Shan Liu and Zhicheng Ji and Shan He},
  doi          = {10.1016/j.ins.2024.121129},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121129},
  shortjournal = {Inf. Sci.},
  title        = {MIFuGP: Boolean network inference from multivariate time series using fuzzy genetic programming},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LPRR: Locality preserving robust regression based jointly
sparse feature extraction. <em>ISCI</em>, <em>680</em>, 121128. (<a
href="https://doi.org/10.1016/j.ins.2024.121128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Jointly sparse projection learning attracts considerable attention due to its strong interpretability in feature extraction. To address the challenges related to weak discriminating representation in supervised feature extraction, we propose a more powerful regression framework. Based on the framework, we exhibit a new regression model called locality preserving robust regression (LPRR). In LPRR, we first combine the reconstruction error minimization and the projection variance maximization to explore the structured information of the data. Then, the label information is utilized and the low rank representation can be learned to explore the latent correlation structures among different classes. Furthermore, L 2 , 1 L2,1 -norm is applied to measure the loss function and regularization terms, enhancing the robustness of the model and ensuring the joint sparsity of the projection matrix. An iterative algorithm is elaborately designed to achieve the optimal solutions of LPRR, in which the subproblem of LPRR can be regarded as a general quadratic problem on the Stiefel manifold. The convergence and the computational complexity of LPRR are analyzed rigorously. Finally, comprehensive experiments demonstrate the competitive performance of the proposed algorithm.},
  archive      = {J_ISCI},
  author       = {Yufei Zhu and Jiajun Wen and Zhihui Lai and Jie Zhou and Heng Kong},
  doi          = {10.1016/j.ins.2024.121128},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121128},
  shortjournal = {Inf. Sci.},
  title        = {LPRR: Locality preserving robust regression based jointly sparse feature extraction},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SAST: A self-attention based method for skill translation in
t-shaped expert finding. <em>ISCI</em>, <em>680</em>, 121116. (<a
href="https://doi.org/10.1016/j.ins.2024.121116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, organizations are seeking professionals who can both excel in their areas of expertise and collaborate effectively across different disciplines. This demand has given rise to the concept of T-shaped experts who possess a deep understanding of one topic domain and a broad knowledge of several others. This combination allows these professionals to be more creative, flexible, and adaptable in problem-solving by leveraging their diverse perspectives and experiences. To find T-shaped experts in any skill area, we need to measure how deep and wide their knowledge is. In this paper, we present a novel translation-based method to estimate each user&#39;s depth of knowledge in a given skill area. The proposed method leverages a self-attention-based multi-label classification network to identify the most relevant translations for each skill that belongs to the given skill area. We utilize two new methods based on binary cross-entropy and focal loss to determine whether a user&#39;s expertise shape matches the T-shaped. We evaluate the proposed method using the standard benchmark datasets. The experimental results on three collections of the StackOverflow dataset demonstrate the superiority of the proposed methods in comparison with existing baselines.},
  archive      = {J_ISCI},
  author       = {Zohreh Fallahnejad and Hamid Beigy},
  doi          = {10.1016/j.ins.2024.121116},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121116},
  shortjournal = {Inf. Sci.},
  title        = {SAST: A self-attention based method for skill translation in T-shaped expert finding},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adversarial compact wrapping classifier learning for open
set recognition. <em>ISCI</em>, <em>680</em>, 121114. (<a
href="https://doi.org/10.1016/j.ins.2024.121114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining the limited and compact class acceptance region has become a key bottleneck in classifier design since Open Set Recognition (OSR) requires the classifier to successfully identify those of interest and reject other exceptions. The imperfect match between actual feature distribution of a class and its classification acceptance area is a critical barrier to performance enhancement in recent existing OSR algorithms. Therefore, we propose adversarial compact wrapping classifier learning for OSR, which achieves better feature representation and classification surface division through alternating learning of classifiers and compact wrapping points (CWPs). The core of the algorithm model lies in the confrontational game between CWP and the classifier. First, a new deep and compact hyperspherical crown classifier is designed, which expands neurons to achieve limited and compact classification surface division, improves the classification performance of known classes, and reduces the risk of open space. Then, the CWP algorithm is used to construct negative class sample points that tightly wrap the class feature distribution, and a joint optimization framework of CWP and classifier is constructed. The classifier improves the discrepancy between the class acceptance area of the classification and the actual class distribution area through adversarial learning with CWP, further controls the risk of unknown open spaces, and optimizes the learned feature distribution. It is worth noting that we have developed the CWP to allow concave feature distributions. Experimental results show that the proposed algorithm is significantly superior to recent comparison algorithms on various benchmark datasets and significantly improves OSR performance on the TinyImageNet dataset.},
  archive      = {J_ISCI},
  author       = {Lin Zhang and Minghua Wan and Pu Huang and Guowei Yang},
  doi          = {10.1016/j.ins.2024.121114},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121114},
  shortjournal = {Inf. Sci.},
  title        = {Adversarial compact wrapping classifier learning for open set recognition},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-confidence and consensus-based group decision making
methods and applications. <em>ISCI</em>, <em>680</em>, 121110. (<a
href="https://doi.org/10.1016/j.ins.2024.121110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the field of intelligent decision making continues to evolve, research on multi-attribute group decision making (MAGDM) is advancing at a steady pace. Nevertheless, existing research seldom addresses the aggregated solution of self-confidence and consensus in decision making information with diverse possibilities, despite its relevance to uncertain decision making environments. Consequently, this paper presents an approach to self-confidence and consensus-based group decision making. Firstly, the method provides a way for transforming three-parameter interval grey numbers into randomized decision making information. This establishes the foundation for the computation of possibility decision making information for uncertain decisions. Then, a method based on self-confidence and consensus is developed to determine the decision makers (DMs) weights, which is derived from the randomized decision making information. Next, a novel self-confidence index ( SCI SCI ) for computing self-confidence and a new group consensus index ( GCI GCI ) for computing consensus are demonstrated, and a reliability index ( REI REI ) method for randomized decision making information is given, which is used to identify high self-confidence and high consensus decision making information to improve the quality of decisions. Subsequently, a possibility ranking method is constructed based on pairwise comparisons of alternatives, taking into account density preferences, in order to obtain final possibility ranking conclusions. Finally, an illustrative example is provided to illustrate the concrete implementation process of the methods employed in this research. The efficacy of the proposed method is also demonstrated through a comparative analysis with the other methods.},
  archive      = {J_ISCI},
  author       = {Pingtao Yi and Shiye Wang and Weiwei Li},
  doi          = {10.1016/j.ins.2024.121110},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121110},
  shortjournal = {Inf. Sci.},
  title        = {Self-confidence and consensus-based group decision making methods and applications},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). KGCF: Social relationship-aware graph collaborative
filtering for recommendation. <em>ISCI</em>, <em>680</em>, 121102. (<a
href="https://doi.org/10.1016/j.ins.2024.121102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing popularity of recommendation techniques and social networks, social network recommendation has become a significant research field, i.e., predicting a user&#39;s preferences based on her or his historical interaction data, because the social relationships of users can not only enrich their interaction information, but also imply the accurate characterization of their preferences. Although there are some existing studies that predict users&#39; preferences by using the characteristics of social relationships, their time complexity and hardware resource consumption are often very expensive, which limits the feasibility in large-scale real-world scenarios. To address these issues, in this paper, we propose a simple and effective K -core Graph Collaborative Filtering (KGCF) model to incorporate the user&#39;s social features into a recommendation framework. The user&#39;s interaction information is auto-encoded linearly by incorporating the social relationship graph into the user&#39;s interaction information and constructing a multi-layer graph filter. The linear autoencoder graph filter alleviates the highly sparse data problem and dramatically reduces the training time and hardware resource consumption. Experimental results on several real-world datasets show the superior effectiveness and spatiotemporal efficiency compared with the existing baselines, especially the training speed is significantly accelerated for large-scale datasets.},
  archive      = {J_ISCI},
  author       = {Yunliang Chen and Tianyu Xie and Haofeng Chen and Xiaohui Huang and Ningning Cui and Jianxin Li},
  doi          = {10.1016/j.ins.2024.121102},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121102},
  shortjournal = {Inf. Sci.},
  title        = {KGCF: Social relationship-aware graph collaborative filtering for recommendation},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive neural sliding mode control of an uncertain
permanent magnet linear motor system with unknown input backlash in
laser processing. <em>ISCI</em>, <em>680</em>, 121087. (<a
href="https://doi.org/10.1016/j.ins.2024.121087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a novel robust and high-precision control scheme is developed for a permanent magnet linear motor system in large-range laser processing subject to unknown system uncertainties and input backlash. First, to enhance the robustness of the controller, an adaptive neural sliding mode control (SMC) scheme is proposed. Besides, to address the system uncertainties, a novel simplified radial basis neural network (RBFNN) is applied in the adaptive SMC scheme. Subsequently, considering that the unexpected chattering introduced by SMC strategy, another RBFNN is employed to approximate the optimal switching gain. In addition, considering that the nonlinear input backlash caused by actuator can also cause the fluctuation of the input signal, an inverse backlash model with the method of reverse compensation is proposed to further minimize the effect of the input backlash on control accuracy. Finally, simulation results, validation experiments, and laser processing experiments are provided to demonstrate that the proposed control scheme significantly reduces the impact of chattering and input backlash. Additionally, it exhibits outstanding control accuracy.},
  archive      = {J_ISCI},
  author       = {Wang Xintian and Mei Xuesong and Yang Jiankun and Wang Xiaodong and Sun Zheng and Liu Bin and Lu Haibo},
  doi          = {10.1016/j.ins.2024.121087},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121087},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive neural sliding mode control of an uncertain permanent magnet linear motor system with unknown input backlash in laser processing},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A staged diversity enhancement method for constrained
multiobjective evolutionary optimization. <em>ISCI</em>, <em>680</em>,
121081. (<a href="https://doi.org/10.1016/j.ins.2024.121081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing the convergence and diversity of solutions simultaneously under constraints is a challenge in solving constrained multiobjective optimization problems. In existing multiobjective optimization algorithms, general diversity maintenance mechanisms have difficulty determining all optimal solutions in discrete feasible regions. This paper proposes a staged constrained multiobjective optimization algorithm with a diversity enhancement method (SDEM), which can explore potential discrete feasible regions by retaining well-distributed offspring. Specifically, after solutions have converged to optimal feasible regions by niching-based constraint dominance in the early stage, the SDEM improves the diversity of solutions through a proposed diversity enhancement dominance principle in the mid-term. Finally, the optimize objective functions and constraints of all solutions are optimized under constraint dominance to balance convergence, diversity, and feasibility during the three stages. Experiments on four well-known test suites and six real-world case studies demonstrate that the SDEM is competitive with or comparable to seven state-of-the-art constrained multiobjective evolutionary algorithms.},
  archive      = {J_ISCI},
  author       = {Fan Yu and Qun Chen and Jinlong Zhou and Yange Li},
  doi          = {10.1016/j.ins.2024.121081},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121081},
  shortjournal = {Inf. Sci.},
  title        = {A staged diversity enhancement method for constrained multiobjective evolutionary optimization},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predicting air quality using a multi-scale spatiotemporal
graph attention network. <em>ISCI</em>, <em>680</em>, 121072. (<a
href="https://doi.org/10.1016/j.ins.2024.121072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As urbanization accelerates, air quality has become a pressing concern. Accurate air quality prediction is essential for informed governmental decision-making and for protecting public health. Variations in air quality are influenced by complex multi-scale spatiotemporal processes. Existing research primarily relies on capturing single spatiotemporal features of air quality to predict changes. Meanwhile, when constructing spatiotemporal dynamic graphs, the inherent characteristics of the input data and the comprehensive effects of both global and local influences are not fully considered. To address these problems, we propose a graph-attention-based approach, named Multi-scale Spatiotemporal Graph Attention Network (MSTGAN). MSTGAN addresses the intricate spatiotemporal patterns of air quality across various scales through three key components: (1) a multistation transformer to model the temporal patterns of air quality at individual monitoring stations; (2) a bilinear spatiotemporal attention mechanism to capture the spatiotemporal dynamic global dependencies among all stations in a region; and (3) a set of spatiotemporal dependence graph-coupled Chebyshev graph convolution gate recurrent units to extract and aggregate the local spatiotemporal features of interrelated stations. Experiments conducted on three real-world datasets demonstrated that MSTGAN achieved significant improvements of 4.2%, 3.9%, and 7.8% in the mean absolute error, root mean square error, and R 2 evaluation metrics, respectively, compared to seven state-of-the-art time-series forecasting methods. This code is publicly available at https://github.com/HPSCIL/MSTGAN-airquality-prediction .},
  archive      = {J_ISCI},
  author       = {Xinmeng Zhou and Jingyi Wang and Junyi Wang and Qingfeng Guan},
  doi          = {10.1016/j.ins.2024.121072},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121072},
  shortjournal = {Inf. Sci.},
  title        = {Predicting air quality using a multi-scale spatiotemporal graph attention network},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid approach for estimating monotonic change points in
the parameters of simple linear profiles in multistage processes.
<em>ISCI</em>, <em>680</em>, 121050. (<a
href="https://doi.org/10.1016/j.ins.2024.121050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a hybrid method is proposed for estimating monotonic change points in multistage processes where, at each stage, the quality of the process is represented by simple linear profile models. In the case of monotonic changes, the change type is not known a priori, and the only assumption is that the changes are non-decreasing or non-increasing in nature. In the proposed method, a support vector machine (SVM) algorithm is first developed to identify the parameters experiencing a change in each process stage. Then, the second SVM algorithm is applied to identify the type of change occurring in the related parameters. Finally, considering the identified parameters and change types, the maximum likelihood estimator (MLE) is proposed to estimate the change points of the process under different scenarios, including single and multiple change points, upward and downward step changes, increasing and decreasing linear trends, shift in both parameters of the profiles, shift in different stages of the process, and weak and strong autocorrelation coefficients. The performance of the proposed method is evaluated through extensive simulation experiments. The results indicate that the proposed method recognizes the patterns and estimates the monotonic change points accurately.},
  archive      = {J_ISCI},
  author       = {Shabnam Sepasi and Majid Khedmati},
  doi          = {10.1016/j.ins.2024.121050},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121050},
  shortjournal = {Inf. Sci.},
  title        = {A hybrid approach for estimating monotonic change points in the parameters of simple linear profiles in multistage processes},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Use of a theory of expected information for sparse data and
adverse events in clinical trials and other biomedical studies.
<em>ISCI</em>, <em>680</em>, 121027. (<a
href="https://doi.org/10.1016/j.ins.2024.121027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We argue for a novel contemporary information-theoretic approach to supplement current statistical and AI methods for design and analysis of biomedical studies such as stage I-III clinical trials or cohort studies with limited sample sizes and the potential for adverse events, and as a basis for decision support systems that address these issues. Current methodologies in trials have faced criticism, and the growing volume of available digital medical records suggests a fresh perspective. The wealth of high-dimensional data offers new opportunities. To tackle them, we wish to draw attention to multiple uses of the zeta function. The several practical advantages of this unusual feature are not evident a priori , so they are extensively discussed. To tackle the challenges posed by sparse data, rare event analysis, we propose the combination of work of Black Swan Event (BSE) Theorists with extension of the Theory of Expected Information (TEI), from the 1970s, which is still employed in certain widely used bioinformatics algorithms and data mining practices. Our extension incorporates expectations of information derived from finite data, integrating over degrees of belief about physical probabilities. It is extended to predictive methods for selecting patients for clinical trials, which are “Glass Box”. This framework leads to a set of methods utilizing the incomplete zeta function ς(s,n) summed over n observations, where s can take various meaningful values. Our findings indicate that formulations and algorithms built around such zeta functions can replace many statistics and computations in biomedical studies. Whenever we see a count n of something, possibly including a knowledge or degree of belief represented by a virtual count, it may appear as ς(s,n) in an appropriate new formulae. The “Glass Box” methods based on this often outperformed “Black Box” Machine Learning. These methods align with both frequentist and Bayesian approaches but also accommodate sparse data and justify intuitive rules-of-thumb (e.g., α = 0.05 significance threshold and the “rule of three” in trials). Furthermore, they provide “Glass Box” “explainable” AI, enhancing transparency and interpretability. This project received support from a South Korean government grant, specifically the Electronics and Telecommunications Research Institute (ETRI) grant 23ZS1100, focused on advancing Core Technology Research for Self-Improving Integrated Artificial Intelligence Systems.},
  archive      = {J_ISCI},
  author       = {B. Robson and OK Baek},
  doi          = {10.1016/j.ins.2024.121027},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121027},
  shortjournal = {Inf. Sci.},
  title        = {Use of a theory of expected information for sparse data and adverse events in clinical trials and other biomedical studies},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synergy-incorporated bayesian petri net: A method for mining
“AND/OR” relation and synergy effect with application in probabilistic
reasoning. <em>ISCI</em>, <em>680</em>, 121019. (<a
href="https://doi.org/10.1016/j.ins.2024.121019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian networks (BNs) are widely used for knowledge representation and reasoning. However, they suffer from the following limitations: 1) They are unable to explicitly learn “AND” relations and synergy effects from data; 2) They do not depict “AND” relations among causes directly, which sometimes leads to the high complexity of constructing conditional probability tables (CPTs); and 3) During their knowledge representation and reasoning, they fail to express any synergy (catalytic or inhibitory) effect that a non-causal variable may have on a reasoning rule. To address the mentioned issues, this study proposes a method for mining and modelling “AND/OR” relations and synergy effects called Synergy-incorporated Bayesian Petri Net (SBPN). The method integrates a BN with Petri net concepts. It can directly learn “AND/OR” relations and synergy effects from data, harnessing the power of Petri nets to model “AND/OR” relations in BNs, resulting in a compact CPT. Synergy effects are easily depicted via the SBPN, and their influence on the reasoning procedure can be formally expressed using the SBPN. Experimental results on open datasets demonstrate the effectiveness and advantages of the proposed method for knowledge mining and probabilistic reasoning.},
  archive      = {J_ISCI},
  author       = {Xiaoliang Wang and Faming Lu and MengChu Zhou and Qingtian Zeng and Yunxia Bao},
  doi          = {10.1016/j.ins.2024.121019},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {121019},
  shortjournal = {Inf. Sci.},
  title        = {Synergy-incorporated bayesian petri net: A method for mining “AND/OR” relation and synergy effect with application in probabilistic reasoning},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning for encouraging cooperation in a
multiagent system. <em>ISCI</em>, <em>680</em>, 120996. (<a
href="https://doi.org/10.1016/j.ins.2024.120996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Success in cooperative tasks may be compromised if cooperative stagnation and failure from information sharing occur. However, information sharing may require excessive memory. Other methods must be developed to encourage agents to take actions in accordance with the needs of the team. In this study, a method called the cooperative tendency model using Q-learning (CTM-Q) is proposed for a partial-communication multiagent team. Each agent maintains and records its tendency values (encouraging cooperation) and Q-values (encouraging goal-seeking) as input for a payoff function that is used to select actions. Each agent selects the action with the highest payoff value for the current state. The method improves learning performance, enabling agents to rapidly reach a consensus. In simulations, the proposed method accelerated learning for multiagent cooperative applications and outperformed competing methods in solution speed, convergence time, and stability.},
  archive      = {J_ISCI},
  author       = {Wei-Cheng Jiang and Hong-Hao Huang and Yu-Teng Wang},
  doi          = {10.1016/j.ins.2024.120996},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {120996},
  shortjournal = {Inf. Sci.},
  title        = {Reinforcement learning for encouraging cooperation in a multiagent system},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GNN-MgrPool: Enhanced graph neural networks with
multi-granularity pooling for graph classification. <em>ISCI</em>,
<em>680</em>, 120965. (<a
href="https://doi.org/10.1016/j.ins.2024.120965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have gained sufficient attention and are applied to various domain tasks. At present, numerous pooling approaches are being proposed to aggregate node features and obtain node embeddings. However, current GNNs are black-box models that typically use a flat or single pooling step to aggregate nodes, which only considers the similarity between nodes within the cluster. These approaches ignore the influence of relationships within and between clusters in the learning process. To address this issue, we propose a novel multi-granular pooling method that aggregates nodes by simultaneously considering density and relationships among nodes and clusters. This method allows us to obtain multi-granular node-embedding clusters from GNN layers. The clusters in the current layer are built upon those in the previous layer, and these clusters change from fine to coarse as the number of clusters decreases during learning, which is achieved by using multi-granular pooling (MgrPool). Additionally, there is an inclusion relation between adjacent layers, and the node representation of each layer is established through the ratio of node distance within clusters to that between clusters. Finally, we conducted several experiments on node and graph classification tasks by combining GNN models with this pooling approach. The results demonstrate that our GNN-MgrPool model outperforms similar state-of-the-art algorithms and largely improves the interpretability of the learning process.},
  archive      = {J_ISCI},
  author       = {Haichao Sun and Guoyin Wang and Qun Liu and Yike Guo},
  doi          = {10.1016/j.ins.2024.120965},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {120965},
  shortjournal = {Inf. Sci.},
  title        = {GNN-MgrPool: Enhanced graph neural networks with multi-granularity pooling for graph classification},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Differentially private federated learning with local
momentum updates and gradients filtering. <em>ISCI</em>, <em>680</em>,
120960. (<a href="https://doi.org/10.1016/j.ins.2024.120960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential Privacy (DP) is applied in Federated Learning (FL) for defending against various privacy attacks. Existing methods based on Gaussian mechanism require the operations of clipping and adding noise, leading to significant accuracy degradation. In this paper, we propose a novel FL scheme named DPFL-LMG to provide user-level DP guarantee while maintaining a high model accuracy. Our main idea is to mitigate the negative effects of the clipping on the model convergence by decreasing the L 2 L2 norm of local updates and the cross-client update variance. Specifically, our method includes two techniques, Local Momentum Updates (LMU) and Gradients Filtering (GF). LMU combines local updates of different rounds in a momentum way. It can significantly decrease the cross-client update variance by weakening the gradient noise in local updates caused by stochastic gradient descent (SGD) algorithm. GF estimates the gradient noise in each element of local updates by observing the element-wise variance. Elements with large noise are considered unnecessary and are zeroed out for the reduction of local update norms. We theoretically analyze the privacy guarantee and the convergence of our method. Experiments demonstrate that DPFL-LMG can effectively mitigate the accuracy degradation caused by clipping and outperform previous DPFL methods in the accuracy.},
  archive      = {J_ISCI},
  author       = {Shuaishuai Zhang and Jie Huang and Peihao Li and Chuang Liang},
  doi          = {10.1016/j.ins.2024.120960},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {120960},
  shortjournal = {Inf. Sci.},
  title        = {Differentially private federated learning with local momentum updates and gradients filtering},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prescribed-time consensus of time-varying open multi-agent
systems with delays on time scales. <em>ISCI</em>, <em>680</em>, 120957.
(<a href="https://doi.org/10.1016/j.ins.2024.120957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we focus on prescribed-time leader-following consensus problems for a class of time-varying open multi-agent systems (OMASs) with time delays on time scales. To achieve this objective, we propose a novel segmented state feedback control protocol which contains a time-varying scalar function. It ensures prescribed-time consensus can be achieved while the monotonicity of Lyapunov function is unknown. On this basis, impulsive signals dependent on the leader are further introduced at each opening instant to avoid the possibility of the controller norm being too large. During the process of theoretical analysis, we further innovatively extend Halanay-like inequalities on time scales to resolve theoretical analysis difficulties caused by time delays. Based on time scale theory and Lyapunov stability theory, sufficient conditions depending on system parameters and controller parameters for achieving prescribed-time consensus can be derived. Besides, considering absolute information of each agent cannot be completely obtained, we further design one observer system to reconstruct information of the original system, guaranteeing it can still reach consensus within the pre-set time. Finally, two simulation examples are used to illustrate the validity of our proposed theory.},
  archive      = {J_ISCI},
  author       = {Boling Zhou and Ju H. Park and Yongqing Yang and Rixu Hao and Yu Jiao},
  doi          = {10.1016/j.ins.2024.120957},
  journal      = {Information Sciences},
  month        = {10},
  pages        = {120957},
  shortjournal = {Inf. Sci.},
  title        = {Prescribed-time consensus of time-varying open multi-agent systems with delays on time scales},
  volume       = {680},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite/fixed-time cluster synchronization for directed and
multiplex coupled dynamic networks. <em>ISCI</em>, <em>679</em>, 121136.
(<a href="https://doi.org/10.1016/j.ins.2024.121136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article deals with finite/fixed-time cluster synchronization (FnTCS/FdTCS) issue for directed and multiplex coupled dynamic networks (MCDNs). Finite/fixed-time synchronization of multiplex networks has become a popular research topic, which indicates that, state information is utilized for synchronization, and the settling time depends on original condition for a range of finite time, while the time is bounded with arbitrary original value for fixed-time one. Through constructing appropriate feedback control protocol, FnTCS and FdTCS matters for MCDNs are settled under re-arranging variables&#39; order technique. The present model contains the case that outer matrices (OMs) can be directed, with competitive elements, and not even connected, while previous and related researches assumed that OMs were undirected, cooperative and connected, so existing results can be improved for more general and broader regulations. This strategy above is presented to solve directed CDNs with multiweights from angle of inner and outer matrices, and we prove that if the weighted group of added OMs for each dimension is strongly connected, then cluster synchronization rules are established in finite/fixed time. Moreover, we also earn finite/fixed-time synchronization criteria when the cluster is single. In addition, the issue of FnTCS/FdTCS is developed for directed and multiplex coupled reaction-diffusion networks (MCRDNs) as an application. The validity of these gained results is verified by simulated examples.},
  archive      = {J_ISCI},
  author       = {Shanrong Lin and Xiwei Liu},
  doi          = {10.1016/j.ins.2024.121136},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121136},
  shortjournal = {Inf. Sci.},
  title        = {Finite/fixed-time cluster synchronization for directed and multiplex coupled dynamic networks},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effective drug-target affinity prediction via generative
active learning. <em>ISCI</em>, <em>679</em>, 121135. (<a
href="https://doi.org/10.1016/j.ins.2024.121135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug-target affinity (DTA) prediction is a critical early-stage task in drug discovery. Recently, deep learning has demonstrated remarkable efficacy in DTA prediction. However, acquiring experimentally verified data for target proteins proves to be a time-consuming, labor-intensive, and costly endeavor. In this study, we introduce an innovative generative active learning method for DTA prediction, referred to as GAL-DTA. GAL-DTA comprises two modules, data augmentation and generator fine-tuning. In the data augmentation module, the algorithm uses an optimized generator to produce informative and diverse molecules, thereby enhancing training of the predictor. The generator fine-tuning module introduces Fisher&#39;s informativeness and molecule diversity as objectives and employs the Pareto ranking algorithm to compute rewards. The final generator is fine-tuned using the policy-gradient method. GAL-DTA performs data augmentation by directly generating diverse and informative data, effectively reducing annotation costs while preserving model performance. Extensive experiments on independent test sets involving four target proteins consistently demonstrated that GAL-DTA achieves superior performance, resulting in an average reduction of 8.402% in mean squared error.},
  archive      = {J_ISCI},
  author       = {Yuansheng Liu and Zhenran Zhou and Xiaofeng Cao and Dongsheng Cao and Xiangxiang Zeng},
  doi          = {10.1016/j.ins.2024.121135},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121135},
  shortjournal = {Inf. Sci.},
  title        = {Effective drug-target affinity prediction via generative active learning},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incorporating recklessness to collaborative filtering based
recommender systems. <em>ISCI</em>, <em>679</em>, 121131. (<a
href="https://doi.org/10.1016/j.ins.2024.121131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are intrinsically tied to a reliability/coverage dilemma: The more reliable we desire the forecasts, the more conservative the decision will be and thus, the fewer items will be recommended. This causes a detriment to the predictive capability of the system, as it is only able to estimate potential interest in items for which there is a consensus in their evaluation, rather than being able to estimate potential interest in any item. In this paper, we propose the inclusion of a new term in the learning process of matrix factorization-based recommender systems, called recklessness, that takes into account the variance of the output probability distribution of the predicted ratings. In this way, gauging this recklessness measure we can force more spiky output distribution, enabling the control of the risk level desired when making decisions about the reliability of a prediction. Experimental results demonstrate that recklessness not only allows for risk regulation but also improves the quantity and quality of predictions provided by the recommender system.},
  archive      = {J_ISCI},
  author       = {Diego Pérez-López and Fernando Ortega and Ángel González-Prieto and Jorge Dueñas-Lerín},
  doi          = {10.1016/j.ins.2024.121131},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121131},
  shortjournal = {Inf. Sci.},
  title        = {Incorporating recklessness to collaborative filtering based recommender systems},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive type-2 fuzzy-neural switching control for
wastewater treatment process under several operating conditions.
<em>ISCI</em>, <em>679</em>, 121130. (<a
href="https://doi.org/10.1016/j.ins.2024.121130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effluent ammonia and total nitrogen variation lead to multiple operating conditions in wastewater treatment process (WWTP), which challenges the control strategies based on a single control model. Therefore, it is essential to design suitable control strategies for WWTP to enhance the control performance under different operating conditions. In this paper, an adaptive type-2 fuzzy-neural switching control (AT2FSC) strategy is proposed to solve this problem. First, a soft-sensing model is developed based on fuzzy neural network and influent data in WWTP to estimate the effluent ammonia nitrogen and total nitrogen status. Then, the online operating conditions are determined by the critical values of effluent ammonia nitrogen and total nitrogen. Second, the corresponding fuzzy rules are devised for different operating conditions and a type 2 fuzzy switching model (AT2FSM) is constructed to capture the operating status changes of WWTP. Then, the proposed AT2FSC can design the switching control strategy according to AT2FSM to adapt to the current operating condition. Third, the Lyapunov theorem ensures the stability of the proposed AT2FSC method. Then, it facilitates the further application of AT2FSC in WWTP. Finally, the performance of AT2FSC under various operating conditions is validated on the benchmark simulation model No.1 (BSM1). Simulation results under four different operating conditions demonstrate that the proposed AT2FSC strategy can reduce the excess peak of effluent ammonia and total nitrogen while maintaining the operating performance.},
  archive      = {J_ISCI},
  author       = {Honggui Han and Feifan Yang and Haoyuan Sun and Junfei Qiao},
  doi          = {10.1016/j.ins.2024.121130},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121130},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive type-2 fuzzy-neural switching control for wastewater treatment process under several operating conditions},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel behavior-enhanced long- and short-term interest model
for sequential recommendation. <em>ISCI</em>, <em>679</em>, 121127. (<a
href="https://doi.org/10.1016/j.ins.2024.121127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of modern recommender systems, user-item interaction data often exhibit sequential patterns in relation to various behaviors, such as clicks and purchases on e-commerce platforms. The objective of heterogeneous sequential recommendation (HSR) is to predict each user&#39;s next item of interest under a specific behavior based on these interactions. However, existing approaches to HSR struggle to fully capture item transition relationships, as they consider these relationships from a single dimension and at a coarse-grained level. To bridge this gap, we propose the novel Behavior-enhanced Long- and Short-term Interest (BLSI) model, which explores fine-grained item transition relationships in both local and global dimensionalities. At its core, BLSI incorporates a behavior-enhanced self-attention network (BSAN) to capture short-term user preferences. BSAN distinguishes the effects of different behaviors and considers cross-type behavior influences during the linear projection and attention score calculation stages. Additionally, BLSI employs a heterogeneous graph neural network (HGNN) to model long-term user interests by discriminatively aggregating the information of neighboring nodes according to their behavior transition relationships. Furthermore, a gating mechanism is implemented to adaptively fuse short- and long-term preferences for personalized recommendations. Extensive experimental results on three datasets demonstrate that BLSI significantly outperforms state-of-the-art recommendation methods, highlighting the advantages of leveraging sequentiality and behavioral heterogeneity.},
  archive      = {J_ISCI},
  author       = {Xiaolong Jiang and Heli Sun and Liang He},
  doi          = {10.1016/j.ins.2024.121127},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121127},
  shortjournal = {Inf. Sci.},
  title        = {Novel behavior-enhanced long- and short-term interest model for sequential recommendation},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TFFS: A trainable federal fusion strategy for multistep time
series forecasting. <em>ISCI</em>, <em>679</em>, 121126. (<a
href="https://doi.org/10.1016/j.ins.2024.121126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a trainable federal fusion strategy (TFFS) for multistep time series forecasting (MSTSF) that unifies the current strategies. First, we designed a feature fusion embedding scheme (FFES) that integrates sharing features and all future steps in a trainable mode to overcome the drawback of cumulative errors. Second, multitask learning was designed to train each step in a parallel mode, enabling each step to share a common feature with the others while keeping each step’s personality. Finally, a multiple-input multiple-output scheme (MIMOS) was developed to forecast future step values in semi-series mode, which increases the flexibility. Owing to this design, TFFS provides the following advantages for MSTSF: 1) TFFS is free of cumulative errors in future horizons during training. 2) TFFS provides accurate multistep forecasting results, requiring only one model training. 3) Sharing common features while retaining each step’s personality increases forecasting accuracy. We conducted many experiments on univariate and multivariate time-series datasets to validate the effectiveness of TFFS with seven common deep learning structures. The experimental results confirmed the state-of-the-art performance of the proposed method. Additionally, we extensively and systematically compared each strategy for MSTSF with deep learning.},
  archive      = {J_ISCI},
  author       = {Xiaorui Shao and Chang-Soo Kim},
  doi          = {10.1016/j.ins.2024.121126},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121126},
  shortjournal = {Inf. Sci.},
  title        = {TFFS: A trainable federal fusion strategy for multistep time series forecasting},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anchor-guided global view reconstruction for multi-view
multi-label feature selection. <em>ISCI</em>, <em>679</em>, 121124. (<a
href="https://doi.org/10.1016/j.ins.2024.121124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-view multi-label learning (MVML), the accuracy of feature weights is pivotal for establishing feature order. However, conventional MVML methods often struggle with integrating distinct information from multiple views effectively, leading to unclear segmentation and potential noise introduction. To address this challenge, this paper proposes an anchor-based latent representation method for global view learning in MVML. Specifically, we encode inherent information from each view to derive a candidate multi-view representation. Anchors extracted from both the candidate view and the global view are then constrained to approximate equality in the latent space. Furthermore, a carefully designed view matrix serves as supplement, seamlessly integrated into the reconstruction process to augment information. The convergence of results is subsequently validated using multiplicative update rules. Experimental findings showcase the superior performance of our proposed method across various multi-view datasets.},
  archive      = {J_ISCI},
  author       = {Pingting Hao and Kunpeng Liu and Wanfu Gao},
  doi          = {10.1016/j.ins.2024.121124},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121124},
  shortjournal = {Inf. Sci.},
  title        = {Anchor-guided global view reconstruction for multi-view multi-label feature selection},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Achieving federated logistic regression training towards
model confidentiality with semi-honest TEE. <em>ISCI</em>, <em>679</em>,
121115. (<a href="https://doi.org/10.1016/j.ins.2024.121115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the distributed machine learning field, federated learning (FL) serves as a highly effective framework for dismantling data silos and integrating data from multiple sources. However, the flourishing of FL still encounters significant challenges, particularly in the realms of data security and information privacy. In recent years, plenty of privacy-preserving FL schemes have been proposed, yet few of them support global model confidentiality protection for the training server. In this paper, by combining Trusted Execution Environment (TEE) and homomorphic encryption, we propose a TEE-assisted federated logistic regression training scheme with model confidentiality protection, named TFLR. Specifically, we first formalize a cryptography-TEE hybrid security model under the multi-party cooperative computation scenario. Subsequently, within this hybrid security model, we design a series of secure computation protocols with semi-honest TEE to execute non-linear operations while maintaining the encryption form of global model parameters. Therefore, the global model of the training server can be well protected. In addition, TFLR incorporates a double masking technique, further fortifying the privacy of data owners&#39; local updates. Detailed security analysis shows that TFLR is able to protect all sensitive information of data owners and the training server. Furthermore, we evaluate the performance of TFLR with real machine learning datasets, and the results substantiate that TFLR is indeed efficient.},
  archive      = {J_ISCI},
  author       = {Fengwei Wang and Hui Zhu and Xingdong Liu and Yandong Zheng and Hui Li and Jiafeng Hua},
  doi          = {10.1016/j.ins.2024.121115},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121115},
  shortjournal = {Inf. Sci.},
  title        = {Achieving federated logistic regression training towards model confidentiality with semi-honest TEE},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature selection for multi-labeled data based on label
enhancement technique and mutual information. <em>ISCI</em>,
<em>679</em>, 121113. (<a
href="https://doi.org/10.1016/j.ins.2024.121113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label data, the importance of each label within the logical label vector varies for each sample, and there exist inherent correlations among the labels. However, the logical label vector fails to capture these nuances. Consequently, relying solely on this vector for feature selection in multi-label data results in underutilization of supervisory information. To address this issue, this paper introduces a novel label enhancement algorithm. This algorithm leverages neighborhood information derived from features to transform the logical label vector into a label distribution that effectively reflects label differences and correlations. Subsequently, we propose a feature selection algorithm tailored for multi-label data, which incorporates both the transformed label distribution and mutual information. This algorithm not only accounts for the mutual information between features and label distributions but also captures the mutual information among features themselves. Finally, we evaluate our proposed feature selection algorithm against five state-of-the-art multi-label feature selection algorithms on ten publicly available datasets. The experimental results reveal that our algorithm outperforms its competitors in six distinct evaluation metrics, achieving an average performance improvement of approximately 9%. This substantial enhancement underscores the efficacy of our algorithm in handling complex multi-label data.},
  archive      = {J_ISCI},
  author       = {Qinli Zhang and Suping Liu and Jun Wang and Zhaowen Li and Ching-Feng Wen},
  doi          = {10.1016/j.ins.2024.121113},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121113},
  shortjournal = {Inf. Sci.},
  title        = {Feature selection for multi-labeled data based on label enhancement technique and mutual information},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent decision modeling for optimizing railway cold
chain service networks under uncertainty. <em>ISCI</em>, <em>679</em>,
121112. (<a href="https://doi.org/10.1016/j.ins.2024.121112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Railway cold chain service network design (RCC-SND) aims to optimize the utilization of stations and lines as well as train allocations in a manner that minimizes costs while satisfying the service requirements of shippers. Furthermore, the uncertainties associated with freight demand, transportation costs, quality loss, station handling capacity, and arc capacity make the RCC-SND a complex decision-making problem. To tackle this challenge, we first formulate a Mixed-Integer Nonlinear Programming (MINLP) model to determine hub locations, freight wagon flows, and service frequency. To cope with uncertain parameters with varying degrees of uncertainty incorporated in the model, we extend the problem using fuzzy programming and further convert it to its crisp counterpart. A real-world cases study in Southwest China is performed to validate the proposed model, whose results provide different strategies for decision-makers with varying preferences. There are some main findings: As the number of hubs increases from 5 to 6, a maximum total cost savings of 1.99% can be achieved. Railway operators may opt for different decision preferences, for decisions prioritizing economic efficiency, the cost can decrease by 2.69% compared to deterministic optimization.},
  archive      = {J_ISCI},
  author       = {Mi Gan and Dandan Li and Zhu Yao and Hao Yu and Qichen Ou},
  doi          = {10.1016/j.ins.2024.121112},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121112},
  shortjournal = {Inf. Sci.},
  title        = {Intelligent decision modeling for optimizing railway cold chain service networks under uncertainty},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Component importance preference-based evolutionary graph
neural architecture search. <em>ISCI</em>, <em>679</em>, 121111. (<a
href="https://doi.org/10.1016/j.ins.2024.121111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, graph neural architecture search (GNAS) has become an increasingly hot research topic as a promising technique for automatically searching graph neural networks (GNNs) with no or little domain expertise. The search space and optimization strategy are the core factors of GNAS. However, the search space of existing GNAS methods is limited, and their optimization strategies treat components indiscriminately. In the current study, a more expressive search space is first designed. Subsequently, it is illustrated that components contribute different importance to data-specific tasks or datasets, and this study assumes component importance as a probability parameter. To this end, a component importance preference-based evolutionary GNAS method (called CIPE) is proposed. CIPE defines component importance and its preference selection and updating method. Subsequently, the designed importance preference-guided multipoint crossover and multistrategy mutation operators are applied to the evolutionary process. Finally, the effectiveness of CIPE is verified for transductive and inductive tasks. The experimental results demonstrate the validity of the component importance assumption and the superiority of CIPE compared with the state-of-the-art handcrafted GNNs and GNAS methods on all eight datasets. The mean accuracy obtained by CIPE on the datasets Cora, CiteSeer, PubMed, Cornell, Texas, Wisconsin, and Chameleon is 83.84%, 73.23%, 80.28%, 78.38%, 86.49%, 82.35%, and 73.59%, respectively. Specifically, the mean accuracy is improved by 2.71% and 5.28% on the datasets Texas and Chameleon, respectively. The mean F1-score obtained by CIPE on the dataset PPI is 99.37%, with an improvement of 0.24%. The code is available at https://github.com/chnyliu/CIPE .},
  archive      = {J_ISCI},
  author       = {Yang Liu and Jing Liu and Yingzhi Teng},
  doi          = {10.1016/j.ins.2024.121111},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121111},
  shortjournal = {Inf. Sci.},
  title        = {Component importance preference-based evolutionary graph neural architecture search},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Short-term subway passenger flow forecasting approach based
on multi-source data fusion. <em>ISCI</em>, <em>679</em>, 121109. (<a
href="https://doi.org/10.1016/j.ins.2024.121109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate short-term subway passenger flow forecasting is essential in improving the efficiency of daily operation and the management of subway system. Existing research often overlooks the impacts of randomness and unevenness in passenger flows caused by population migrations, also predominantly emphasizes feature selection while neglecting effective feature fusion. To address this gap, we propose a novel hybrid subway passenger flow forecasting approach adopting multi-source data fusion technique. Firstly, the dual processing module consisting of Grey Relation Analysis and SHapley Additive exPlanations is used to gather influencing features. Then, the multivariate empirical mode decomposition decomposes the selected features into multidimensional intrinsic mode functions. To discern and extract the effective components from the decomposed intrinsic mode functions, secondary feature selection module based on Spearman Correlation Coefficient is performed. Finally, the determined components are categorized into three classes by combining recurrence plot and picture information entropy, each class is assigned suitable predictor to ensure accurate forecasting. Experimental results based on three real subway passenger flow datasets from Guangzhou, Beijing, and Chengdu verifies the effectiveness and robustness of the proposed approach. Therefore, the introduction of population migration index and the effective fusion of information are significant to improve subway passenger flow forecasting.},
  archive      = {J_ISCI},
  author       = {Yifan Cheng and Hongtao Li and Shaolong Sun and Wenzheng Liu and Xiaoyan Jia and Yang Yu},
  doi          = {10.1016/j.ins.2024.121109},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121109},
  shortjournal = {Inf. Sci.},
  title        = {Short-term subway passenger flow forecasting approach based on multi-source data fusion},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Three-way decision based on three-way preference measures
and three-level dominance relations in interval-valued systems.
<em>ISCI</em>, <em>679</em>, 121108. (<a
href="https://doi.org/10.1016/j.ins.2024.121108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-valued systems facilitate data decision, and their preference measures and dominance relations become pivotal for three-way decision (3WD). However, the recent D-type preference measure and partial-overall dominance relation between intervals respectively exhibit the weak representation and incomplete hierarchy, so corresponding results need further development. Aiming at interval-valued systems, an S-type measure is proposed to constitute three-way preference measures, and three-level dominance relations are established, so criss-cross knowledge granulations motivate systematic 3WD models and applications. First, the S-type preference measure is proposed from the sigmoid function, it exhibits good learning semantics and mathematical properties, and its supplementation and improvement induce three-way preference measures. Then, by three-level constructions, three-way preference measures are applied for sorting and classification, and the S-type measure exhibits decision effectiveness and recognition superiority. Furthermore, hierarchical three-way preference measures induce three-level dominance relations, and vertical-horizontal condition granulations generate multiple 3WD models on preference decision classes. Finally, all 3WD strategies from criss-cross dominance relations are comprehensively compared and selected via classification error rates; by data experiments, the S-type measure and its hierarchical relations become effective and optimal for 3WD, and the corresponding 3WD approaches outperform the existing methods from the D-type measure and partial-overall relation.},
  archive      = {J_ISCI},
  author       = {Benwei Chen and Xianyong Zhang and Zhiying Lv},
  doi          = {10.1016/j.ins.2024.121108},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121108},
  shortjournal = {Inf. Sci.},
  title        = {Three-way decision based on three-way preference measures and three-level dominance relations in interval-valued systems},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blockchain-based crowdsourced deep reinforcement learning as
a service. <em>ISCI</em>, <em>679</em>, 121107. (<a
href="https://doi.org/10.1016/j.ins.2024.121107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Reinforcement Learning (DRL) has emerged as a powerful paradigm for solving complex problems. However, its full potential remains inaccessible to a broader audience due to its complexity, which requires expertise in training and designing DRL solutions, high computational capabilities, and sometimes access to pre-trained models. This necessitates the need for hassle-free services that increase the availability of DRL solutions to a variety of users. To enhance the accessibility to DRL services, this paper proposes a novel blockchain-based crowdsourced DRL as a Service (DRLaaS) framework. The framework provides DRL-related services to users, covering two types of tasks: DRL training and model sharing. Through crowdsourcing, users could benefit from the expertise and computational capabilities of workers to train DRL solutions. Model sharing could help users gain access to pre-trained models, shared by workers in return for incentives, which can help train new DRL solutions using methods in knowledge transfer. The DRLaaS framework is built on top of a Consortium Blockchain to enable traceable and autonomous execution. Smart Contracts are designed to manage worker and model allocation, which are stored using the InterPlanetary File System (IPFS) to ensure tamper-proof data distribution. The framework is tested on several DRL applications, proving its efficacy.},
  archive      = {J_ISCI},
  author       = {Ahmed Alagha and Hadi Otrok and Shakti Singh and Rabeb Mizouni and Jamal Bentahar},
  doi          = {10.1016/j.ins.2024.121107},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121107},
  shortjournal = {Inf. Sci.},
  title        = {Blockchain-based crowdsourced deep reinforcement learning as a service},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Topological clustering particle swarm optimizer based on
adaptive resonance theory for multimodal multi-objective problems.
<em>ISCI</em>, <em>679</em>, 121106. (<a
href="https://doi.org/10.1016/j.ins.2024.121106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multi-objective optimization problems aim to identify multiple equivalent Pareto-optimal solution sets in the decision space, each associated with the same Pareto front in the objective space. It remains challenging to combine multimodal multi-objective optimization algorithms with appropriate machine learning techniques to balance diversity and convergence and acquire complete and evenly distributed Pareto-optimal solution sets and fronts. Therefore, we propose a particle swarm optimizer named TCAPSO, which is based on topological clustering via adaptive resonance theory. This algorithm leverages incremental learning to construct a topology, which adaptively learns from new solutions while retaining previously valuable information. The knowledge accumulated within the topology is fully applied during the algorithmic iterations, wherein a learnable solution generator and discriminator are developed. The generator advances solutions toward promising regions by employing a neighborhood construction strategy that utilizes topological node adjacency. The discriminator selects solutions by integrating historical crowding information from topological nodes in the decision space with crowding distance in the objective space, ensuring that the solutions are uniformly distributed across both spaces. In comparative experiments across 34 multimodal multi-objective benchmark problems, TCAPSO outperformed 10 advanced multimodal multi-objective algorithms, surpassing the closest competitors by 21.64% and 10.95% respectively in the decision and objective spaces.},
  archive      = {J_ISCI},
  author       = {Qi Yao and Shunkun Yang and Qi Shao and Chong Bian and Mengdan Wu},
  doi          = {10.1016/j.ins.2024.121106},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121106},
  shortjournal = {Inf. Sci.},
  title        = {Topological clustering particle swarm optimizer based on adaptive resonance theory for multimodal multi-objective problems},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computation of choquet integrals: Analytical approach for
continuous functions. <em>ISCI</em>, <em>679</em>, 121105. (<a
href="https://doi.org/10.1016/j.ins.2024.121105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the continuous case, analytical computations of the Choquet integral are limited, despite being commonly used in various applications. One can either use the definition, which is computationally demanding and impractical, or apply already existing formulas restricted only to monotone nonnegative functions on a real interval starting at zero. This article aims to present more convenient computational formulas for continuous functions without imposing restrictions on their monotonicity given any real interval. First, a more general approach to monotone functions is provided for both positive and negative functions. Then, reordering techniques are introduced to compute the Choquet integral of an arbitrary continuous function, and with these, a monotone equivalent to every function can be constructed. This equivalent function preserves the final Choquet integral value, implying that only formulas for monotone functions are required. In addition to general fuzzy measures, the article assumes particular cases of distorted Lebesgue measures and distorted probabilities as the most commonly used fuzzy measures.},
  archive      = {J_ISCI},
  author       = {Zuzana Ontkovičová and Vicenç Torra},
  doi          = {10.1016/j.ins.2024.121105},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121105},
  shortjournal = {Inf. Sci.},
  title        = {Computation of choquet integrals: Analytical approach for continuous functions},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consensus reaching in LSGDM: Overlapping community detection
and bounded confidence-driven feedback mechanism. <em>ISCI</em>,
<em>679</em>, 121104. (<a
href="https://doi.org/10.1016/j.ins.2024.121104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The surge of social media has made large-scale group decision-making (LSGDM) crucial in real-world decision-making. The intricacies of trust relationships within social networks that emerged from relations in social media affect both the clustering and the consensus of large groups. However, existing research often neglects the impact of overlapping social trust networks on group consensus. To fill this gap, this study introduces a novel consensus-reaching process (CRP) that integrates overlapping community detection and ELICIT-based optimization models under bounded confidence. Initially, the Lancichinetti-Fortunato method (LFM) is employed to identify overlapping community structures within social trust networks, delineating several subgroups and identifying corresponding non-overlapping and overlapping decision-makers (DMs). Subsequently, the PageRank (PR) algorithm is utilized to compute both global and local weights for individuals, facilitating a rational aggregation of collective and subgroup opinions. Next, two-stage Extended Comparative Linguistic Expressions With Symbolic Translation (ELICIT)-based optimization consensus models under bounded confidence are designed, aiming to provide optimal feedback for guiding DMs&#39; preference adjustments. Since overlapping DMs may belong to multiple subgroups, a weighted influence feedback mechanism is introduced to mitigate conflicting guidance from these multiple affiliations. Finally, we demonstrate the effectiveness and superiority of our proposed method through numerical validation and comparative analysis against existing approaches.},
  archive      = {J_ISCI},
  author       = {Ying-Ming Wang and Hui-Hui Song and Bapi Dutta and Diego García-Zamora and Luis Martínez},
  doi          = {10.1016/j.ins.2024.121104},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121104},
  shortjournal = {Inf. Sci.},
  title        = {Consensus reaching in LSGDM: Overlapping community detection and bounded confidence-driven feedback mechanism},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Manifold neighboring envelope sample generation mechanism
for imbalanced ensemble classification. <em>ISCI</em>, <em>679</em>,
121103. (<a href="https://doi.org/10.1016/j.ins.2024.121103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For existing imbalanced ensemble (IE) methods, the sample subsets are constructed from the same dataset, which usually suffer from low quality (diversity and separability) of the subsets, so a manifold neighboring envelope sample generation mechanism (MNESG) and an imbalanced ensemble algorithm based on the mechanism (MNESG-IE) are proposed to solve this problem. First, for the original balanced subsets (OBS), a manifold neighboring sample envelope projection mechanism (MNSEP) is designed to mine the local correlation information between the samples and their nearest neighbors in the subsets. Second, the fuzzy c-means clustering (FCM) is used to further mine the global correlation information among similar samples in the subsets. Third, the sample distribution consistency preservation mechanism (SDCPM) is designed to enhance the consistency of the sample distribution before and after clustering. To better reduce the three accumulated losses above, the three steps are conducted simultaneously, thereby realizing the MNESG, which can transform the OBS into two new types of high quality envelope sample subsets − neighboring envelope sample (NES) subsets and neighboring cluster envelope sample (NCES) subsets. Finally, base classifiers are trained on the NES subsets and NCES subsets, and then fused by a two-dimensional sparse fusion mechanism (2D-SFM). Various representative IE algorithms on over thirty benchmark datasets are considered for verification. The results show that compared with the state-of-the-art IE algorithms, MNESG-IE achieves 17.79%, 17.90%, 23.61%, 18.08% improvement in terms of ACC, AUC, F-M and G-M, respectively. The major originality of the paper is: (a) proposing the MNSEP to mine the local correlation information for improving the quality of the subsets; (b) proposing the MNESG to generate high quality subsets by mining local and global correlation information simultaneously; and (c)forming an IE algorithm to better solve the imbalanced classification problem.},
  archive      = {J_ISCI},
  author       = {Yiwen Wang and Yongming Li and Yinghua Shen and Fan Li and Pin Wang},
  doi          = {10.1016/j.ins.2024.121103},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121103},
  shortjournal = {Inf. Sci.},
  title        = {Manifold neighboring envelope sample generation mechanism for imbalanced ensemble classification},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EEG-based TSK fuzzy graph neural network for driver
drowsiness estimation. <em>ISCI</em>, <em>679</em>, 121101. (<a
href="https://doi.org/10.1016/j.ins.2024.121101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of brain-computer interface (BCI), electroencephalogram (EEG) is considered to be one of the best physiological signals to detect the fatigue state of drivers due to its advantages of extremely high time resolution and low use cost. However, since EEG is sensitive to noise/artifacts, and there is non-stationarity and low signal-to-noise ratio in inter-subject/intra-subject, the accurate estimation of driver drowsiness state remains challenging. Therefore, this paper proposes the EEG-based TSK fuzzy graph neural network (TSKG) to solve the regression problem of driver drowsiness estimation by combining transfer learning (TL), graph convolutional neural network (GCN), information theory, and TSK fuzzy neural network. TSKG extracts the relevant features in EEG through mutual information minimization and regards the fuzzy rules as graph structure data. The extracted relevant features and the original features are used to optimize the fuzzy rules through GCN. TSKG is tested on the fatigue driving dataset, and Root Mean Square Error (RMSE) and Correlation Coefficient (CC) are 0.1681 and 0.7118, respectively. Especially when dealing with difficult samples, TSKG has significantly better generalization performance.},
  archive      = {J_ISCI},
  author       = {Haotian Chen and Jialiang Xie},
  doi          = {10.1016/j.ins.2024.121101},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121101},
  shortjournal = {Inf. Sci.},
  title        = {EEG-based TSK fuzzy graph neural network for driver drowsiness estimation},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Molecular sequence classification using efficient kernel
based embedding. <em>ISCI</em>, <em>679</em>, 121100. (<a
href="https://doi.org/10.1016/j.ins.2024.121100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The alarming spread of diseases across the globe has become a major concern for global healthcare agencies. The research community is actively involved in inventing better and more efficient ways of detecting and treating diseases to solve this global challenge. The abundance of molecular sequence data has eased the path for researchers to develop Machine Learning (ML) based solutions. The performance of the ML models used to classify molecular sequences depends heavily on the type of embedding used to obtain an appropriate numerical representation of the molecular sequences. In recent years, many embedding approaches have been introduced for molecular sequence analysis. However, there is still a need for improvement as far as the efficiency of the methods is concerned (i.e., the ability to capture pairwise relationships and patterns effectively, which could affect the classification performance). To provide a solution to this problem, we propose an efficient kernel-based technique for embedding generation from molecular sequences, which involves computing a kernel matrix using the Sinkhorn-Knopp algorithm and the normalized pairwise distances between k -mers in a manner that satisfies the constraints of a probability distribution. Further, kernel principal component analysis (PCA) is applied to get the top PCs, which are then used as the final embedding. As a result of the experiments, we obtained an ROC-AUC score of 0.657 for our method, which is higher than the scores obtained using baselines. This clearly shows that the low-dimensional embedding obtained through the proposed approach provides an efficient and effective solution for molecular sequence analysis.},
  archive      = {J_ISCI},
  author       = {Sarwan Ali and Tamkanat E. Ali and Taslim Murad and Haris Mansoor and Murray Patterson},
  doi          = {10.1016/j.ins.2024.121100},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121100},
  shortjournal = {Inf. Sci.},
  title        = {Molecular sequence classification using efficient kernel based embedding},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel adaptive neighborhood rough sets based on sparrow
search algorithm and feature selection. <em>ISCI</em>, <em>679</em>,
121099. (<a href="https://doi.org/10.1016/j.ins.2024.121099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighborhood rough sets-based methods have been widely used for feature selection. However, the existing methods have some problems in neighborhood construction, such as the application of the same neighborhood radius for all samples. Thus, this paper proposed a novel adaptive neighborhood rough set model based on Sparrow Search Algorithm (SSA) to tackle the above problems, and applied the model to feature selection. First, we reconsidered the problems mentioned above from the viewpoint of optimization where the neighborhood radius of the target sample is considered as the solution to the optimization, and the maximum percentage of the label of the neighborhood formed is considered as the target to the optimization. Second, SSA is introduced to design the adaptive neighborhood construction to tackle the optimization problem where all candidate neighborhood radii of the target sample are considered as sparrows, the maximum and minimum distances between the target sample and other samples are considered as the search range, and the maximum label rate defined in this paper is considered as the search target. Then, a novel adaptive neighborhood rough set model is proposed by using the adaptive neighborhood construction. Third, we proposed a feature selection algorithm based on the adaptive neighborhood rough set model. Finally, the experimental results on seventeen datasets demonstrate the effectiveness of our algorithm. The running time of the proposed algorithm is at least one time less than classical algorithms under the condition that the classification performance is better, the accuracy increases 3% and the balanced accuracy increases 4%.},
  archive      = {J_ISCI},
  author       = {Caihui Liu and Bowen Lin and Duoqian Miao},
  doi          = {10.1016/j.ins.2024.121099},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121099},
  shortjournal = {Inf. Sci.},
  title        = {A novel adaptive neighborhood rough sets based on sparrow search algorithm and feature selection},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two fractional order cumulative residual time series
measures based on rényi entropy. <em>ISCI</em>, <em>679</em>, 121098.
(<a href="https://doi.org/10.1016/j.ins.2024.121098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the study of time series analysis, Kullback-Leibler divergence can measure the difference between the distribution diverges of time series, and transfer entropy is usually used to quantify the causal influence among time series. In order to analyze the relationship between time series more comprehensively, two novel fractional order times series measures, i.e., Rényi cumulative residual Kullback-Leibler (RCRKL) and Rényi cumulative residual transfer entropy (RCRTE), are proposed in this paper. Some mathematical properties of RCRKL are proved as a distance metric, and the zeros and bounds of RCRTE are studied. Then, some examples on synthetic data are provided to study the effect of parameter changes on metric values. Finally, the proposed two fractional-order time series measures are applied to pavement rutting time series, for which a RCRKL-based clustering is designed and the causal relationships between influence factors and rutting are detected by RCETE. The results demonstrate that the RCRKL-based clustering algorithm performs better than those based on the baseline distance measures. Meanwhile, RCRTE can also detect the true causality between rutting and its influence factors and reject the false causality. In summary, the proposed RCRKL and RCRTE take the advantages of both cumulative residual entropy and Rényi entropy, and provide a more comprehensive insight for time series analysis.},
  archive      = {J_ISCI},
  author       = {Jinren Zhang and Jinde Cao and Xinli Shi and Wei Huang and Tao Ma and Xingye Zhou},
  doi          = {10.1016/j.ins.2024.121098},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121098},
  shortjournal = {Inf. Sci.},
  title        = {Two fractional order cumulative residual time series measures based on rényi entropy},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI vs linguistic-based human judgement: Bridging the gap in
pursuit of truth for fake news detection. <em>ISCI</em>, <em>679</em>,
121097. (<a href="https://doi.org/10.1016/j.ins.2024.121097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the negative aspects of the world becoming more digitized has been fake news, i.e., online disinformation – false, often fabricated reports of events, written and read on websites. The term has already entered collective consciousness and become an inseparable element of scientific discourse. Once a piece of news goes online, stopping it from spreading may become a complicated matter. Literature suggests that the two main pillars of the effective fight against fake news are education and detection. Thus, this paper describes a multidisciplinary study performed by a group of scientists representing two distinct fields - AI and linguistics. In their joint study, they compared, formally evaluated and explored the intersection between two approaches to fake news detection, i.e., the automated one, using a machine-learning-based tool, and the linguistic-based human judgement, using the data from two disinformation campaigns, sourced from two open benchmark fake news datasets. The study focused on the news&#39; headlines as an effective proxy for the identification of fake news. In accordance with the achieved results, the paper argues that in the fight against fake news, the two approaches have the potential of augmenting and enhancing each other, utilizing the state-of-the-art technologies and linguistic knowledge. In addition, this paper provides a list of the linguistic features characteristic of possible disinformation, which is the most comprehensive collection of this kind in the subject literature to date.},
  archive      = {J_ISCI},
  author       = {Aleksandra Pawlicka and Marek Pawlicki and Rafał Kozik and Agnieszka Andrychowicz-Trojanowska and Michał Choraś},
  doi          = {10.1016/j.ins.2024.121097},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121097},
  shortjournal = {Inf. Sci.},
  title        = {AI vs linguistic-based human judgement: Bridging the gap in pursuit of truth for fake news detection},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generic network sparsification via degree- and
subgraph-based edge sampling. <em>ISCI</em>, <em>679</em>, 121096. (<a
href="https://doi.org/10.1016/j.ins.2024.121096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network (or graph) sparsification accelerates many downstream analyses. For graph sparsification, sampling methods derived from local heuristic considerations are common in practice, due to their efficiency in generating sparse subgraphs using only local information. Filtering-based edge sampling is the most typical approach in this respect, yet it heavily depends on an appropriate definition of edge importance. Instead, we propose a generalized node-focused edge sampling framework by preserving scaled/expected local node characteristics. Apart from expected degrees, these local node characteristics include the expected number of triangles and the expected number of non-closed wedges associated with a node. From a technical point of view, we adapt a game-theoretic sampling method from uncertain graph generation to obtain sparse subgraphs that approximate the expected local properties. We include a tolerance threshold for much faster convergence. Within this framework, we provide appropriate algorithmic variants for sparsification. Moreover, we propose a network measure called tri-wedge assortativity for the selection of the most suitable variant when sparsifying a given network. Extensive experimental studies on functional climate, observed real-world, and synthetic networks show the effectiveness of our method in preserving overall structural network properties – on average consistently better than the state of the art.},
  archive      = {J_ISCI},
  author       = {Zhen Su and Yang Liu and Jürgen Kurths and Henning Meyerhenke},
  doi          = {10.1016/j.ins.2024.121096},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121096},
  shortjournal = {Inf. Sci.},
  title        = {Generic network sparsification via degree- and subgraph-based edge sampling},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph transformer embedded deep learning for short-term
passenger flow prediction in urban rail transit systems: A multi-gate
mixture-of-experts model. <em>ISCI</em>, <em>679</em>, 121095. (<a
href="https://doi.org/10.1016/j.ins.2024.121095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban rail transit (URT) plays a crucial role in mitigating urban traffic congestion by offering faster and higher-quality travel services. Short-term passenger flow predictions have practical significance for metro management and operation. However, the complex spatiotemporal characteristics and the relationship between entry and exit passenger flows make it challenging to detect the dynamic evolution patterns. This study proposes a Spatio-Temporal Graph Transformer (STGT) under the multi-task learning framework, utilizing Graph Transformer network and gated residual units to select and aggregate features. To account for the correlation between entry and exit passenger flow prediction tasks, the STGT model integrates a Multi-gate Mixture-of-Experts (MMoE) approach, which combines different expert networks for diverse input and explicitly learns to model passenger flow relationships in various scenarios. Metro-related characteristics such as weather conditions, train operation characteristics, and accessibility of nearby bus stops are incorporated to enhance prediction accuracy. Experimental evaluations are conducted using real-world historical passenger travel records from the Beijing subway. The results demonstrate the superior robustness and advantages of the STGT-MMoE model over basic and advanced benchmarks for passenger flow prediction tasks. These findings provide compelling evidence to address the challenges of short-term inflow and outflow prediction in urban rail transit systems.},
  archive      = {J_ISCI},
  author       = {Songhua Hu and Jianhua Chen and Wei Zhang and Guanhua Liu and Ximing Chang},
  doi          = {10.1016/j.ins.2024.121095},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121095},
  shortjournal = {Inf. Sci.},
  title        = {Graph transformer embedded deep learning for short-term passenger flow prediction in urban rail transit systems: A multi-gate mixture-of-experts model},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shadowed set approximations of l-fuzzy sets. <em>ISCI</em>,
<em>679</em>, 121094. (<a
href="https://doi.org/10.1016/j.ins.2024.121094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedrycz shadowed sets are three-way approximations of fuzzy sets by transforming the infinite levels of fuzzy set membership grades in the unit interval [ 0 , 1 ] [0,1] into three levels. The three levels represent qualitatively the sets of the white, grey, and black members of a shadowed set. In this paper, we generalize the notion of shadowed sets to the case of L-fuzzy sets by making three new contributions. First, we consider two representations of a shadowed set. One is a three-valued L-fuzzy set and the other is three pairwise disjoint sets. Second, we introduce two methods for constructing a shadowed set. One divides a finite lattice based on the notion of a pair of a set of designated core membership grades and a set of designated null membership grades. The other uses a pair of threshold sets, which generalizes the method that uses a pair of thresholds. We study formal properties of the two methods and show that they are equivalent. Finally, based on a distance function on a lattice, we present a simple method to build the sets of designated core and null membership grades.},
  archive      = {J_ISCI},
  author       = {Li Zhang and Yiyu Yao and Ping Zhu},
  doi          = {10.1016/j.ins.2024.121094},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121094},
  shortjournal = {Inf. Sci.},
  title        = {Shadowed set approximations of L-fuzzy sets},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event-based secure control for cyber-physical systems
against false data injection attacks. <em>ISCI</em>, <em>679</em>,
121093. (<a href="https://doi.org/10.1016/j.ins.2024.121093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly studies an event-based secure control problem for cyber-physical systems against false data injection (FDI) attacks. First, a dynamic event-triggered transmission protocol is established to schedule the transmitted data from the sensor to the controller. Subsequently, an imperfect FDI attack model is constructed considering the real network environment, which would bypass the traditional residual-based detection methods. To overcome this drawback, an attack detection strategy based on secure history information is designed, which effectively mitigates the negative impact of uncertainty on the detection results. Based on the detection results, an event-based secure linear quadratic Gaussian control scheme is designed, which can guarantee system performance and reduce the communication load effectively. Finally, a simulation experiment verifies that the proposed control method outperforms other algorithms in the literature, and the detection accuracy is increased by 91% to 98%.},
  archive      = {J_ISCI},
  author       = {Jinyan Li and Xiao-Meng Li and Zhijian Cheng and Hongru Ren and Hongyi Li},
  doi          = {10.1016/j.ins.2024.121093},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121093},
  shortjournal = {Inf. Sci.},
  title        = {Event-based secure control for cyber-physical systems against false data injection attacks},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Multi-group consensus of multi-agent systems subject to
semi-markov jump topologies against hybrid cyber-attacks. <em>ISCI</em>,
<em>679</em>, 121092. (<a
href="https://doi.org/10.1016/j.ins.2024.121092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent systems are widely used in practice. The existing results on the consensus of multi-agent systems mainly focus on the complete consensus, which can not deal with the situation of the system in the face of multiple tasks. In this paper, the multi-group consensus problem of multi-agent systems with semi-Markov jump topologies against hybrid cyber-attacks is studied. The purpose is to ensure that the multi-agent systems can achieve different consensus goals when they encounter hybrid cyber-attacks, and to solve the problem of time-varying communication topology between agents modeled by the semi-Markov process. Additionally, two types of cyber-attacks are taken into account in a single framework through two independent sets of Bernoulli sequences. Subsequently, a necessary condition is established to guide the system toward achieving the multi-group consensus objective. Lastly, a series of illustrative examples are presented to underscore the validity of the designed controller.},
  archive      = {J_ISCI},
  author       = {Duomei Li and Feng Li and Jianwei Xia and Xihong Fei and Hao Shen},
  doi          = {10.1016/j.ins.2024.121092},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121092},
  shortjournal = {Inf. Sci.},
  title        = {Multi-group consensus of multi-agent systems subject to semi-markov jump topologies against hybrid cyber-attacks},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ACD-DE: An adaptive cluster division differential evolution
for mitigating population diversity deficiency. <em>ISCI</em>,
<em>679</em>, 121091. (<a
href="https://doi.org/10.1016/j.ins.2024.121091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential Evolution (DE) is a simple but powerful population based evolutionary algorithm, which was widely used to solve various complex optimization problems. However, even recently proposed state-of-the-art DE variants tend to get trapped in local minima due to insufficient population diversity in the later stages of evolution. In this paper, an A daptive C luster D ivision D ifferential E volution (ACD-DE) algorithm was proposed to mitigate population diversity deficiency. The main highlights are summarized as follows: Firstly, a novel cluster division based mutation strategy was proposed to enhance the diversity of difference vectors during the mutation operation. Secondly, a population diversity detection indicator was used to assess the stagnation level of individuals, enabling stagnation management to be launched based on different stagnation levels. Thirdly, an effective evolution guidance mechanism was proposed by adjusting certain parameters in the D -dimensional vectors of outlier individuals that significantly deviate from the current population. Fourthly, novel parameter adaptations were employed to dynamically adjust the control parameters, including the scale factor F , crossover rate CR , and population size PS , during evolution. To validate the ACD-DE algorithm, extensive experiments were conducted on 88 benchmark functions from the CEC2013, CEC2014, and CEC2017 test suites, focusing on the optimization accuracy, convergence speed, time complexity, and component effectiveness. The results demonstrate the superiority of our ACD-DE algorithm compared to state-of-the-art DE variants.},
  archive      = {J_ISCI},
  author       = {Zhenyu Meng and Xin Lin and Dewang Chen},
  doi          = {10.1016/j.ins.2024.121091},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121091},
  shortjournal = {Inf. Sci.},
  title        = {ACD-DE: An adaptive cluster division differential evolution for mitigating population diversity deficiency},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph contrastive learning for source localization in social
networks. <em>ISCI</em>, <em>679</em>, 121090. (<a
href="https://doi.org/10.1016/j.ins.2024.121090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world scenarios, rapidly and accurately identifying sources of fake news or disease outbreaks is crucial for public safety. Existing deep learning methods for source localization tasks entirely rely on supervised learning, which requires a large amount of labeled data. Recently, the emerging self-supervised learning (SSL) methods have significantly reduced the reliance on labeled data. Nevertheless, the investigation of SSL for source localization tasks remains unexplored. In this work, we are the first to adapt SSL for source localization tasks, specifically employing graph contrastive learning (GCL). Yet, directly applying GCL to source localization tasks faces two challenges: 1) existing data augmentation strategies are not well-suited for source localization tasks; 2) extremely low-dimensional node features potentially compromise the quality of learned node representations. To address these challenges, we introduce a S ource L ocalization with G raph C ontrastive L earning ( SL-GCL ) framework. Firstly, we propose a data augmentation strategy which exploits the inherent stochasticity of propagation. Secondly, we design a feature enrichment module to expand the feature dimensions. Finally, our experiments on six real-world networks demonstrate that SL-GCL outperforms state-of-the-art methods and exhibits remarkable transferability across different networks and propagation patterns.},
  archive      = {J_ISCI},
  author       = {Qing Bao and Ying Jiang and Wang Zhang and Pengfei Jiao and Jing Su},
  doi          = {10.1016/j.ins.2024.121090},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121090},
  shortjournal = {Inf. Sci.},
  title        = {Graph contrastive learning for source localization in social networks},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Protocol-based SMC for singularly perturbed systems with
switching parameters and deception attacks. <em>ISCI</em>, <em>679</em>,
121089. (<a href="https://doi.org/10.1016/j.ins.2024.121089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research paper investigates a protocol-based sliding mode control (SMC) approach for singularly perturbed systems with switching parameters and random occurring deception attacks. The mode switching behavior of the original system is regulated using a semi-Markov process, and a novel and more efficient mode monitoring method is proposed, distinct from the conventional hidden Markov model. Furthermore, to reduce the triggering rate while maintaining control performance, a probability-based event triggering protocol is introduced. By employing the proposed scheme along with Lyapunov theory, sufficient criteria for parameter correlation are established to ensure asymptotic stability. The designed sliding mode control incorporates a convergence factor to enhance the control performance. Finally, the feasibility and practicality of the proposed control strategy are verified through simulations using two practical models.},
  archive      = {J_ISCI},
  author       = {Chuangchun Shen and Jiangming Xu and Jun Cheng and Huaicheng Yan and Jinde Cao},
  doi          = {10.1016/j.ins.2024.121089},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121089},
  shortjournal = {Inf. Sci.},
  title        = {Protocol-based SMC for singularly perturbed systems with switching parameters and deception attacks},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Chaotic image encryption algorithm based on bit-level
feedback adjustment. <em>ISCI</em>, <em>679</em>, 121088. (<a
href="https://doi.org/10.1016/j.ins.2024.121088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a fast bit-level chaotic image encryption algorithm. The goal is to make the difference between 0 and 1 in the bit-level ciphertext as small as possible. By introducing the concept of the difference between 0 and 1, constantly adjust the number of binary 0 and 1 in the ciphertext, and the difference is fed back to the encryption system until the difference reaches the preset accuracy, so as to quickly achieve a secure encryption effect. To verify the security of the algorithm, this paper selects multiple chaotic systems for testing and applies different chaotic systems to the encryption algorithm. Moreover, the proposed algorithm is compared with the bit-level and non-bit-level image encryption algorithms proposed by other scholars in recent years, and the results show that the proposed algorithm has higher security than other algorithms.},
  archive      = {J_ISCI},
  author       = {Yining Su and Xingyuan Wang and Hao Gao},
  doi          = {10.1016/j.ins.2024.121088},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121088},
  shortjournal = {Inf. Sci.},
  title        = {Chaotic image encryption algorithm based on bit-level feedback adjustment},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mixture of deep networks for facial age estimation.
<em>ISCI</em>, <em>679</em>, 121086. (<a
href="https://doi.org/10.1016/j.ins.2024.121086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, our objective is to simultaneously explore the learning of ordinal relationships among age labels and address the challenge of heterogeneous data resulting from the non-stationary aging process through an advanced mixture model of deep networks. Drawing upon the pivotal insight that the non-stationary aging process can be decomposed into a series of stationary subprocesses, we employ a divide-and-conquer strategy. This involves initially partitioning the age spectrum into multiple groups and subsequently training a specialized deep network, referred to as an “expert”, for each distinct group. These experts are not functionally independent; instead, they are interconnected through specialized model designs and a joint training mechanism that consolidates them into a unified system. As a result, the learning of ordinal relationships is consistently maintained by solving the age-related tasks across the entire age label set. The final age estimation is accomplished through a hierarchical classification approach, leveraging the collective outputs from all the experts. Extensive experiments involving several well-known datasets for age estimation have demonstrated the superior performance of our proposed model over several existing state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Qilu Zhao and Jiawei Liu and Weibo Wei},
  doi          = {10.1016/j.ins.2024.121086},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121086},
  shortjournal = {Inf. Sci.},
  title        = {Mixture of deep networks for facial age estimation},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature selection for label distribution learning based on
the statistical distribution of data and fuzzy mutual information.
<em>ISCI</em>, <em>679</em>, 121085. (<a
href="https://doi.org/10.1016/j.ins.2024.121085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label distribution learning (LDL) is an emerging framework in machine learning. Fuzzy mutual information is mutual information under a fuzzy environment and plays an important role in handling uncertainty. This paper explores feature selection for LDL data based on the statistical distribution of data and fuzzy mutual information. The similarity between the feature values in the feature space is first defined by means of the statistical distribution of the data, and a threshold is introduced to control the similarity. Then, the fuzzy similarity relation for each feature subset is established via the similarity. This method utilizes adjustable fuzzy similarity radii to establish a fuzzy similarity relation and improve the classification ability of the data. The decision relation in the label space is then presented, and the decision class of each sample is constructed. Subsequently, two feature selection algorithms based on fuzzy mutual information are designed to remove the irrelevant features by employing a strategy that considers the correlation between the features and labels as well as the redundancy between the features in the LDL data. Finally, the experimental results show that the designed algorithms can effectively measure the uncertainty of LDL data and outperform four state-of-the-art feature selection algorithms. Specifically, our algorithms, LDFM and LDFMR, demonstrate their superiority by achieving overall average ranking improvements of 63.64% and 58.52%, respectively, across six evaluation metrics compared to the other four algorithms.},
  archive      = {J_ISCI},
  author       = {Hengyan You and Pei Wang and Zhaowen Li},
  doi          = {10.1016/j.ins.2024.121085},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121085},
  shortjournal = {Inf. Sci.},
  title        = {Feature selection for label distribution learning based on the statistical distribution of data and fuzzy mutual information},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient ensemble learning method based on
multi-objective feature selection. <em>ISCI</em>, <em>679</em>, 121084.
(<a href="https://doi.org/10.1016/j.ins.2024.121084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning (EL) boosts model prediction performance across various domains through two main steps: generating individual classifiers (ICs) and combining them. Creating accurate and diverse ICs is crucial for a strong ensemble, while selecting the best ICs, known as ensemble selection (ES), is critical yet challenging due to the accuracy-diversity trade-off and the lack of agreed-upon diversity metrics. This paper introduces an EL strategy that uses multi-objective feature selection (MOFS) and a feature relevance-guided selection to tackle these challenges. Our approach uses a hybrid MOFS algorithm to produce accurate and diverse ICs, and then it employs a novel knowledge-based feature-relevance-guided metric for precise diversity assessment during ES. The ES issue is cast as an optimization problem, aiming to maximize both diversity and accuracy, and an efficient ES algorithm is developed to select optimal ICs. Extensive tests on public datasets and a real-world prediction task demonstrate the effectiveness of our method, especially in achieving high accuracy.},
  archive      = {J_ISCI},
  author       = {Xiaojun Zhou and Weijun Yuan and Qian Gao and Chunhua Yang},
  doi          = {10.1016/j.ins.2024.121084},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121084},
  shortjournal = {Inf. Sci.},
  title        = {An efficient ensemble learning method based on multi-objective feature selection},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Document-level relation extraction with multi-semantic
knowledge interaction. <em>ISCI</em>, <em>679</em>, 121083. (<a
href="https://doi.org/10.1016/j.ins.2024.121083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction has gained increasing attention because of its capability to discover relationship facts between entity pairs within a document. Existing studies only leverage semantic information derived from mentions, entities, and entity pairs, but overlook rich semantics embedded within relation labels that encapsulate implicit semantic knowledge capable of enhancing relation prediction. This paper proposes a multi-semantic interaction method for document-level relation extraction. First, we model relation labels and employ a template-based method to extract and incorporate their semantic features. Next, a relation label self-interaction module is introduced to capture complex semantic associations among relation labels. Then, we propose two distillation strategies with and without distantly supervised datasets. Finally, experimental results on three datasets demonstrate that our method outperforms previous methods in terms of F1 and IgnF1.},
  archive      = {J_ISCI},
  author       = {Wenlong Hou and Wenda Wu and Xianhui Liu and Weidong Zhao},
  doi          = {10.1016/j.ins.2024.121083},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121083},
  shortjournal = {Inf. Sci.},
  title        = {Document-level relation extraction with multi-semantic knowledge interaction},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An iterative correction method for practically LPN solving.
<em>ISCI</em>, <em>679</em>, 121080. (<a
href="https://doi.org/10.1016/j.ins.2024.121080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The LPN problem, lying at the core of many cryptographic constructions for lightweight and post-quantum cryptography, has recently received much attention. Accordingly, BKW, Gauss algorithm, and their improved or hybrid variants have been proposed to solve the LPN problem. In this paper, we propose an intelligent method for LPN solving from a wholly new perspective by iterative correcting the secret, which can successfully reduce the dimension of the LPN problem. While the challenge is that there are so many independent secret variables of the given checking parity equations with noise in LPN problems, a set of rules should be developed to effectively direct and correct the secret. To solve this problem, we skillfully introduce the genetic algorithm to simulate the process of iterative correction and further add vaccination technology to guide and speed up the iterative process. Owing to the small memory and data consumption of our algorithm, we conducted experiments and, for the first time, solved the largest practical LPN (256,1/8) instance in 30 days, which shows the superiority of our method. To the best of our knowledge, this is the first time the iterative correction method and the intelligent algorithm have been successfully applied to LPN problems.},
  archive      = {J_ISCI},
  author       = {Man Kang and Lin Jiao and Yongqiang Li and Mingsheng Wang},
  doi          = {10.1016/j.ins.2024.121080},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121080},
  shortjournal = {Inf. Sci.},
  title        = {An iterative correction method for practically LPN solving},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An ensemble dual model assisted MOEA/d for tackling medium
scale expensive multiobjective optimization. <em>ISCI</em>,
<em>679</em>, 121079. (<a
href="https://doi.org/10.1016/j.ins.2024.121079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many surrogate-assisted evolutionary algorithms (SAEAs) have been developed to address expensive multi-objective optimization problems (EMOPs). However, existing research primarily focuses on low-dimensional EMOPs. In this article, we propose an ensemble dual model-assisted multi-objective evolutionary algorithm based on decomposition to tackle medium-scale EMOPs. The proposed approach includes two key insights. First, a new ensemble strategy is proposed to improve both the prediction ability and computation efficiency of surrogates in tackling medium-scale EMOPs. Second, we develop an improved computing resource allocation strategy and an operator pool to enhance convergence capabilities. The improved computing resource allocation strategy gives more computing resources to the subproblems with poor fitness values, while the operator pool is used to generate promising offspring set in higher dimensions. Experimental results from three sets of expensive multi-objective test suites demonstrate that our proposed algorithm significantly outperforms seven compared SAEAs.},
  archive      = {J_ISCI},
  author       = {Zeyuan Yan and Yuren Zhou and Weigang Wu and Wei Zheng},
  doi          = {10.1016/j.ins.2024.121079},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121079},
  shortjournal = {Inf. Sci.},
  title        = {An ensemble dual model assisted MOEA/D for tackling medium scale expensive multiobjective optimization},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ConvFishNet: An efficient backbone for fish classification
from composited underwater images. <em>ISCI</em>, <em>679</em>, 121078.
(<a href="https://doi.org/10.1016/j.ins.2024.121078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the purpose of monitoring fish health, managing aquaculture, and comprehending marine ecology, there is a growing interest in the automatic classification of different fish species. Recent developments in machine vision-based classification methods, known for their speed and non-destructive nature, have led to the introduction of various automatic categorization approaches. Drawing inspiration from FishNet, a new architecture model named ConvFishNet has been proposed. This model incorporates large convolutional kernels and depth-wise separable convolutions to reduce the number of parameters in the model. Additionally, the PixelShuffle has been developed to enhance the upsampling information and improve fish classification performance. While maintaining precision in fish classification, the model achieves a lightweight design with only 0.83G. Compared with the FishNet model, the new model reduces parameters by 80 %. The model demonstrates a precision of 88.44 % on the WildFish dataset subset and 99.8 % on the Fish4knowledge dataset, surpassing existing methods including FishNet. This method shows promise for fish classification in challenging underwater environments, such as marine and aquaculture settings, and further investigation is planned for the future.},
  archive      = {J_ISCI},
  author       = {Huishan Qu and Gai-Ge Wang and Yun Li and Xin Qi and Mengjie Zhang},
  doi          = {10.1016/j.ins.2024.121078},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121078},
  shortjournal = {Inf. Sci.},
  title        = {ConvFishNet: An efficient backbone for fish classification from composited underwater images},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A space sampling based large-scale many-objective
evolutionary algorithm. <em>ISCI</em>, <em>679</em>, 121077. (<a
href="https://doi.org/10.1016/j.ins.2024.121077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale multiobjective optimization problems have attracted increasing attention in both engineering applications and scientific research. Academically, large-scale multiobjective problems involve hundreds or thousands of decision variables. Due to the large decision space, the performance of traditional multiobjective evolutionary algorithms decreases dramatically when dealing with large-scale multiobjective problems, especially many-objective problems. With this in mind, a space sampling based large-scale many-objective evolutionary algorithm (LSMaOEA) is proposed in this article. Specifically, a space sampling method is developed that alternately performs upper/lower-linkage sampling and individual-linkage sampling to sample a set of individuals in the decision space. An environmental selection strategy based on nondominated sorting and reference vector association is proposed. Thus, the proposed LSMaOEA can alleviate excessively dense sampling at boundaries and improve the diversity of existing space sampling based algorithms for large-scale many-objective problems. In the experiments, the proposed algorithm is assessed by comparing it with eight state-of-the-art multi/many-objective evolutionary algorithms. The evaluation is conducted using two popular indicators across nine challenging multiobjective optimization benchmark problems with up to 2000 decision variables. The extensive experimental results consistently reveal that the proposed algorithm outperforms all the compared algorithms.},
  archive      = {J_ISCI},
  author       = {Xiaoxin Gao and Fazhi He and Yansong Duan and Chuanlong Ye and Junwei Bai and Chen Zhang},
  doi          = {10.1016/j.ins.2024.121077},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121077},
  shortjournal = {Inf. Sci.},
  title        = {A space sampling based large-scale many-objective evolutionary algorithm},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-granularity detector for enhanced small object
detection under sample imbalance. <em>ISCI</em>, <em>679</em>, 121076.
(<a href="https://doi.org/10.1016/j.ins.2024.121076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper delves into the realm of object detection models, pinpointing challenges posed by inadequate performance in discerning small objects, as well as examining the inherent imbalance between positive and negative samples. To address these issues, we introduce the Multi-Granularity Detector (MgD), which represents a sophisticated fusion of multi-granularity feature extraction (MFE) and sequential three-way selection (S3WS). Within the MFE framework, three multi-granularity customizable deformable convolutions span three layers of feature maps that are meticulously tailored for nuanced object analysis across spectra of diverse sizes. Notably, this innovative approach enhances the accuracy of small object detection, thereby improving the overall object detection efficacy. The S3WS mechanism was introduced to rectify the imbalance between positive and negative samples. Within this framework, regional proposals undergo scrutiny, with additional positive samples judiciously selected from the positive and boundary regions. This selection process relies on multiple evaluation functions and two dynamic thresholds that are strategically applied layer by layer. The results of exhaustive experiments using the COCO benchmark unequivocally establish the excellent performance of MgD at the system level. When enhanced with the MFE and S3WS ( AP 63.1→64.0, A P / A P s AP/APs 1.97→1.42), SwinV2-G surpassed prevailing state-of-the-art results, whereas MgD 1 ( A P = AP= 53.9, A P / A P s = AP/APs= 1.35) ignificantly enhanced the detection of small objects. In addition, the MFE and S3WS can be seamlessly integrated into ConvNet and transformer-based detectors, yielding significant improvements.},
  archive      = {J_ISCI},
  author       = {Dong Chen and Duoqian Miao and Xuerong Zhao},
  doi          = {10.1016/j.ins.2024.121076},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121076},
  shortjournal = {Inf. Sci.},
  title        = {Multi-granularity detector for enhanced small object detection under sample imbalance},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extensive experimental comparison among multilabel methods
focused on ranking performance. <em>ISCI</em>, <em>679</em>, 121074. (<a
href="https://doi.org/10.1016/j.ins.2024.121074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilabel classification is a growing paradigm in the fields of data mining and machine learning. In multilabel learning, each input sample can belong to more than one binary class (termed “label”) in a multilabel framework, with contrasts with the standard single-label learning scenario. The challenge of producing a better classifier lies in the advantageous use of the correlations among different labels. In recent years, many multilabel models have been proposed, making it difficult to decide which methods to use. In this paper, we present the most comprehensive ranking performance comparison carried out thus far among numerous methods. We conduct a comprehensive analysis by comparing several configurations of 56 distinct methods, resulting in a total of 173 trained models. In addition, we utilize an extensive collection of problems involving 65 datasets. Furthermore, we analyze the effectiveness of the tested techniques by evaluating their performance with six different ranking performance metrics. Our findings indicate that while certain strategies consistently rank highly among the top-performing models, the most effective methods are strongly correlated with the specific metrics used to assess their performance. Finally, we examine many behavioral aspects of the different approaches.},
  archive      = {J_ISCI},
  author       = {Nicolás E. García-Pedrajas and José M. Cuevas-Muñoz and Gonzalo Cerruela-García and Aida de Haro-García},
  doi          = {10.1016/j.ins.2024.121074},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121074},
  shortjournal = {Inf. Sci.},
  title        = {Extensive experimental comparison among multilabel methods focused on ranking performance},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interval type-2 fuzzy stochastic configuration networks for
soft sensor modeling of industrial processes. <em>ISCI</em>,
<em>679</em>, 121073. (<a
href="https://doi.org/10.1016/j.ins.2024.121073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft sensors have been widely applied to predict key variables that are difficult to measure for industrial process modeling. In this paper, a novel randomized interval type-2 fuzzy neural network with parallel learning, called IT2F-PSCN, is presented for soft sensor modeling of industrial processes. It trains the upper and lower bounds of the interval type-2 fuzzy logic system separately to facilitate type reduction, thereby integrating the fuzzy logic system with stochastic configuration networks. To achieve the appropriate structure and parameters of the model, we develop a two-phase training scheme. In the first phase, a sparse rule interpolation method with stochastic configuration is applied to generate new fuzzy rules. In the second phase, the hidden layer is constructed through parallel stochastic configuration to enhance the nonlinear representational capacity. The validity of IT2F-PSCN is confirmed by a series of experiments, including four benchmark data modelings, simulation on the Tennessee Eastman process, and soft sensor modeling for the slurry grade of the first rougher in a zinc flotation process. The experimental results indicate that the proposed IT2F-PSCN performs favorably compared with other methods.},
  archive      = {J_ISCI},
  author       = {Changqing Yuan and Yongfang Xie and Shiwen Xie and Zhaohui Tang},
  doi          = {10.1016/j.ins.2024.121073},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121073},
  shortjournal = {Inf. Sci.},
  title        = {Interval type-2 fuzzy stochastic configuration networks for soft sensor modeling of industrial processes},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ImFTP: Deep imbalance learning via fuzzy transition and
prototypical learning. <em>ISCI</em>, <em>679</em>, 121071. (<a
href="https://doi.org/10.1016/j.ins.2024.121071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although many methods have been proposed for tackling the class-imbalance problem, they still suffer from the insufficient feature representative capability and the overfitting problem. This paper proposes a new deep im balance learning approach based on the F uzzy set T heory and the P rototypical learning mechanism, abbreviated as imFTP for short, which consists of an adaptive smooth sampling module, a self-learnable prototypical learning module, and a fuzzy transition module. The adaptive smooth sampling module adaptively adjusts the sampling frequency of different classes to ensure their adequate opportunity to participate in the training process, which can mitigate the overfitting problem. The self-learnable prototypical learning module devises a clustering distance based Softmax cross-entropy loss and an intra-class clustering loss to improve the feature representation and discrimination capability of the model. The fuzzy transition module utilizes the fuzzy set theory to transform sample features effectively, which further enhances the feature representation capability of the model, meanwhile alleviates the overfitting problem. Experimental results on 15 benchmark datasets demonstrate that our method outperforms the best competitor by more than 3% in terms of the Macro-F1 metric, which is very significant.},
  archive      = {J_ISCI},
  author       = {Yaxin Hou and Weiping Ding and Chongsheng Zhang},
  doi          = {10.1016/j.ins.2024.121071},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121071},
  shortjournal = {Inf. Sci.},
  title        = {ImFTP: Deep imbalance learning via fuzzy transition and prototypical learning},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HSFE: A hierarchical spatial-temporal feature enhanced
framework for traffic flow forecasting. <em>ISCI</em>, <em>679</em>,
121070. (<a href="https://doi.org/10.1016/j.ins.2024.121070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, spatio-temporal fusion strategy is a key direction in traffic flow prediction. Current work employs a higher degree of spatio-temporal self-attention in order to capture spatio-temporal dependencies. However, the features to which this approach is applied are more targeted, increasing the computational complexity of the process and making it more difficult to capture long-range dependencies. This paper proposes a new framework for predicting traffic flow that enhances spatio-temporal features at multiple levels. The framework includes a periodic embedding module that captures temporal periodicity and encodes input data into more representative feature vectors for model training. Also, a component for fusing parallel channel attention has been designed to adaptively weigh the aggregation of features from global, local, and aggregated channels. This enhances the attention given to important feature information in the model. In addition, a multilevel sequential feature fusion enhancer has been designed that ensures feature processing at different levels. Experimental results on four public transportation datasets demonstrate that the innovative approach enhances the MAE metrics by an average of 2.50%, respectively, over all metrics in the baseline models. Notably, it reduces training time by approximately 50%. This paper also discusses ablation experiments to evaluate the performance of each module.},
  archive      = {J_ISCI},
  author       = {Jungang Lou and Xinye Zhang and Ruiqin Wang and Zhenfang Liu and Kang Zhao and Qing Shen},
  doi          = {10.1016/j.ins.2024.121070},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121070},
  shortjournal = {Inf. Sci.},
  title        = {HSFE: A hierarchical spatial-temporal feature enhanced framework for traffic flow forecasting},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). GBTM: Community detection and network reconstruction for
noisy and time-evolving data. <em>ISCI</em>, <em>679</em>, 121069. (<a
href="https://doi.org/10.1016/j.ins.2024.121069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection and network reconstruction are two major concerns in network analysis. However, these two tasks are extremely challenging since most of the existing methods are not suitable for noisy and red time-evolving data, which are common in real world situations. To cope with this, we propose a novel method called the group-based binary time-evolving mixture (GBTM) model to detect communities and recover network structures jointly. This is the first to study address the challenges of community detection and network reconstruction in scenarios where data are dynamic and cannot be directly observed. In this work, the hidden Markov method is employed to capture the temporal evolution of node connections. In addition, we develop the grouped Baum-Welch algorithm for parameter estimation using a forward-backward procedure. Our GBTM model shows that conducting community detection and network reconstruction simultaneously can yield synergistic benefits. Furthermore, we introduce an innovative Bayesian information criterion (BIC) for determining the number of communities. The results of various simulations under different settings and two real-world networks show that the proposed GBTM model outperforms the existing community detection or network reconstruction methods and has great potential for solving time-evolving and noisy network problems.},
  archive      = {J_ISCI},
  author       = {Xiao Chen and Jie Hu and Yu Chen},
  doi          = {10.1016/j.ins.2024.121069},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121069},
  shortjournal = {Inf. Sci.},
  title        = {GBTM: Community detection and network reconstruction for noisy and time-evolving data},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive large neighborhood search algorithm with
reinforcement search strategy for solving extended cooperative multi
task assignment problem of UAVs. <em>ISCI</em>, <em>679</em>, 121068.
(<a href="https://doi.org/10.1016/j.ins.2024.121068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the increasing complexity of military operations, the use of multiple heterogeneous unmanned aerial vehicles (UAVs) is essential for efficiently executing complex missions. This paper introduces an extended cooperative multi-task assignment problem (ECMTAP), which involves deploying heterogeneous UAVs from different base stations to accomplish specific missions, with a focus on minimizing overall mission completion time. ECMTAP categorizes targets into various types, each associated with unique task sets including {reconnaissance}, {attack, evaluation}, and {reconnaissance, attack, evaluation}. ECMTAP requires that attack tasks follow reconnaissance tasks, and evaluation tasks follow attack tasks, adding complexity due to specific timing constraints on each task. To tackle this problem, we propose a novel algorithm, the reinforcement search strategy-based adaptive large neighborhood search (RSALNS). To enhance the search capability, RASLNS utilizes two key destroy-repair operations: the intra-target tasks adjustment strategy and the evaluation tasks adjustment strategy. The former operation dismantles and reconstructs task sequences within a target, potentially resulting in suboptimal assignment of evaluation tasks, while the latter operation reassigns these tasks based on the first operation&#39;s output. Extensive experiments validate the effectiveness of the RSALNS algorithm in solving the ECMTAP, demonstrating its capability to generate high-quality solutions efficiently.},
  archive      = {J_ISCI},
  author       = {Yougang Xiao and Yuhan Li and Huan Liu and Yingguo Chen and Yalin Wang and Guohua Wu},
  doi          = {10.1016/j.ins.2024.121068},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121068},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive large neighborhood search algorithm with reinforcement search strategy for solving extended cooperative multi task assignment problem of UAVs},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identifying vital nodes through augmented random walks on
higher-order networks. <em>ISCI</em>, <em>679</em>, 121067. (<a
href="https://doi.org/10.1016/j.ins.2024.121067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Empirical networks possess considerable heterogeneity of node connections, resulting in a small portion of nodes playing crucial roles in network structure and function. Yet, how to characterize nodes&#39; influence and identify vital nodes is by far still unclear in the study of networks with higher-order interactions. In this paper, we introduce a multi-order graph obtained by incorporating the higher-order bipartite graph and the classical pairwise graph and design a Higher-order Augmented Random Walk (HoRW) model through random walking on the proposed multi-order graph. This representation preserves as much information about the higher-interacting network as possible. In contrast to random walks along pairwise interactions only, performing more walks along the multi-order graph assists in not only identifying the most important nodes but also distinguishing nodes that ranked in the middle and bottom. Numerical results indicate that the proposed method effectively addresses the localization problem of certain classical centralities. Moreover, our method outperforms classical centralities in identifying vital nodes and can scale to various network tasks, including information spread maximization and network dismantling problems. Generally, the proposed higher-order representation and the random walk model provide novel insights and potent tools for studying higher-order mechanisms and functionality.},
  archive      = {J_ISCI},
  author       = {Yujie Zeng and Yiming Huang and Xiao-Long Ren and Linyuan Lü},
  doi          = {10.1016/j.ins.2024.121067},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121067},
  shortjournal = {Inf. Sci.},
  title        = {Identifying vital nodes through augmented random walks on higher-order networks},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TODEAR: Promoting explainable TKG reasoning through temporal
offset enhanced dynamic embedding and adaptive reinforcement learning.
<em>ISCI</em>, <em>679</em>, 121066. (<a
href="https://doi.org/10.1016/j.ins.2024.121066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Reinforcement Learning (RL) is utilized in Temporal Knowledge Graph (TKG) reasoning to generate analyzable reasoning paths, which achieves explainable reasoning on queries. The process of generating high-quality reasoning paths is facing two major challenges. The first is to construct an efficient entity embedding model from the complex temporal dependencies among entities. The second is to design a fine-grained reward mechanism for the reasoner based on the deep semantics of exploration paths. Motivated by the two challenges, a TKG reasoning framework based on T emporal O ffset Enhanced D ynamic E mbedding and A daptive R einforcement Learning ( TODEAR ) is proposed in this paper. Firstly, a temporal offset enhanced dynamic embedding model with a distance scoring function is designed to fully exploit the complex temporal dependencies among entities. In order to capture the evolutionary patterns of historical facts, it encodes both the relational structures of the TKG and the temporal offsets between events and queries. Then, a fine-grained adaptive reward mechanism is designed to optimize the reasoner. It generates real-time rewards by analyzing the logic and semantics of exploration paths to mitigate the adverse effects of sparse rewards. Extensive experiments on four benchmark datasets show that TODEAR significantly outperforms the state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Ye Qian and Fuhui Sun and Xiaoyan Wang and Li Pan},
  doi          = {10.1016/j.ins.2024.121066},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121066},
  shortjournal = {Inf. Sci.},
  title        = {TODEAR: Promoting explainable TKG reasoning through temporal offset enhanced dynamic embedding and adaptive reinforcement learning},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving consensus in social network group decision-making:
Emphasizing overlapping subgroups and interactive behaviors.
<em>ISCI</em>, <em>679</em>, 121065. (<a
href="https://doi.org/10.1016/j.ins.2024.121065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multilevel nature of social networks and the multiple identities of decision makers (DMs) have led to the co-existence of overlapping and non-overlapping subgroups in social network group decision-making. This paper focuses on three issues in an intuitionistic fuzzy environment in this situation. Firstly, some unknown trust relationships exist between DMs belonging to different subgroups. Secondly, interactions between DMs and subgroups affect the final consensus result. Thirdly, opinions of DMs belonging to multiple subgroups simultaneously (i.e., key DMs) affect the opinions of these overlapping subgroups to varying degrees. To address the first issue, a trust propagation operator considering trust influence and trust decay is proposed to estimate the trust values between DMs belonging to different subgroups. To solve the second issue, we describe interactions within and between subgroups by factors such as trust value and overlapping level. To manage the third issue, we introduce the Choquet integral to gather opinions and construct an interactive behavior-driven hierarchical consensus model to obtain the group opinion for the non-additive interactions between DMs and subgroups. Finally, the effectiveness and applicability of the method are verified through illustrative examples and comparisons.},
  archive      = {J_ISCI},
  author       = {Yanxin Xu and Yanbing Ju and Zaiwu Gong and Junpeng Sun and Peiwu Dong and Tian Ju and Enrique Herrera-Viedma},
  doi          = {10.1016/j.ins.2024.121065},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121065},
  shortjournal = {Inf. Sci.},
  title        = {Improving consensus in social network group decision-making: Emphasizing overlapping subgroups and interactive behaviors},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A decomposition framework based on memorized binary search
for large-scale optimization problems. <em>ISCI</em>, <em>679</em>,
121063. (<a href="https://doi.org/10.1016/j.ins.2024.121063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative co-evolution (CC) is an evolutionary framework for dealing with large-scale optimization problems. The divide-and-conquer strategy is widely used in CC. The large-scale problem is decomposed into multiple smaller and easier to optimize subcomponents to reduce the complexity and improve the optimization performance. However, CC typically requires appropriate decomposition methods and numerous functional evaluations. To address this problem, this study proposes a new decomposition framework known as hierarchical differential grouping (HDG). Hierarchy 1 is used to identify the separable and nonseparable variables. The core of the HDG is Hierarchy 2, where a memorized binary search is used to group nonseparable variables into multiple subcomponents. Hierarchy 3 merges the variables with indirect interactions. Finally, Hierarchy 4 implements sequential decomposition for the larger subcomponents. Furthermore, this study theoretically analyzes the computational resources consumed by HDG to decompose large-scale problems. The experimental results demonstrate that HDG outperforms other state-of-the-art differential grouping methods in terms of both the decomposition accuracy and computational complexity. HDG combined with the covariance matrix adaptive evolution strategy can be competitive on multiple benchmark functions.},
  archive      = {J_ISCI},
  author       = {Qingwei Liang and Jeng-Shyang Pan and Shu-Chuan Chu and Lingping Kong and Wei Li},
  doi          = {10.1016/j.ins.2024.121063},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121063},
  shortjournal = {Inf. Sci.},
  title        = {A decomposition framework based on memorized binary search for large-scale optimization problems},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Edge conditional node update graph neural network for
multivariate time series anomaly detection. <em>ISCI</em>, <em>679</em>,
121062. (<a href="https://doi.org/10.1016/j.ins.2024.121062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement in cyber-physical systems, the increasing number of sensors has significantly complicated manual monitoring of system states. Consequently, graph-based time series anomaly detection methods have gained attention due to their ability to explicitly represent relationships between sensors. However, these methods often apply a uniform source node representation across all connected target nodes, even when updating different target node representations. Moreover, the graph attention mechanism, commonly used to infer unknown graph structures, could constrain the diversity of source node representations. In this paper, we introduce the Edge Conditional Node Update Graph Neural Network (ECNU-GNN). Our model, equipped with an edge conditional node update module, dynamically transforms source node representations based on connected edges to represent target nodes aptly. We validate performance on three real-world datasets: SWaT, WADI, and PSM. Our model demonstrates 5.4%, 12.4%, and 6.0% higher performance, respectively, compared to baseline models with best F1 scores. Our code is available at https://github.com/hayoung-jo/ECNU-GNN .},
  archive      = {J_ISCI},
  author       = {Hayoung Jo and Seong-Whan Lee},
  doi          = {10.1016/j.ins.2024.121062},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121062},
  shortjournal = {Inf. Sci.},
  title        = {Edge conditional node update graph neural network for multivariate time series anomaly detection},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A class-aware representation refinement framework for graph
classification. <em>ISCI</em>, <em>679</em>, 121061. (<a
href="https://doi.org/10.1016/j.ins.2024.121061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) are widely used for graph representation learning. Despite its prevalence, GNN suffers from two drawbacks in the graph classification task, the neglect of graph-level relationships, and the generalization issue. Each graph is treated separately in GNN message passing/graph pooling, and existing methods to address overfitting operate on each individual graph. This makes the graph representations learnt less effective in the downstream classification. In this paper, we propose a Class-Aware Representation rEfinement (CARE) framework for the task of graph classification. CARE computes simple yet powerful class representations and injects them to steer the learning of graph representations towards better class separability. CARE is a plug-and-play framework that is highly flexible and able to incorporate arbitrary GNN backbones without significantly increasing the computational cost. We also theoretically prove that CARE has a better generalization upper bound than its GNN backbone through Vapnik-Chervonenkis (VC) dimension analysis. Our extensive experiments with 11 well-known GNN backbones on 9 benchmark datasets validate the superiority and effectiveness of CARE over its GNN counterparts.},
  archive      = {J_ISCI},
  author       = {Jiaxing Xu and Jinjie Ni and Yiping Ke},
  doi          = {10.1016/j.ins.2024.121061},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121061},
  shortjournal = {Inf. Sci.},
  title        = {A class-aware representation refinement framework for graph classification},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rules-reduced fuzzy neural network-based learning control
for multiple constraints robots using online identification and
compensation methods. <em>ISCI</em>, <em>679</em>, 121060. (<a
href="https://doi.org/10.1016/j.ins.2024.121060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel fuzzy-learning adaptive control approach for uncertain robotic systems with input dead zone and output saturation constraints. To address the input dead zone and output saturation and improve the control stability of the robot, an internal model compensation method was proposed, which utilizes online identification of an arctanh function to approximate the output saturation of actuators. The paper also introduces an adaptive learning control system based on a rules-reduced fuzzy neural network (RRFNN) algorithm, which considers the dead zone and output saturation function to enhance control performance, and an adaptive law driven by approximation mistakes is employed to handle multiple constraints. Furthermore, the controller utilizes the integral Lyapunov stability theorem and RRFNN to design the fuzzy-learning adaptive control law, ensuring global convergence and stability of the control system. Extensive simulations and experiments on a robotic manipulator are conducted to verify the feasibility of the proposed control method. Without the proposed method, the robot’s joint tracking error exceeds 0.5 rad, while with the proposed controller, it is less than 0.05 rad and does not violate output saturation constraints. Thus, the proposed method can realize the desired performance and overcome multiple constraints.},
  archive      = {J_ISCI},
  author       = {Du Xu and Bowen Xu and Tete Hu and Lairong Yin},
  doi          = {10.1016/j.ins.2024.121060},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121060},
  shortjournal = {Inf. Sci.},
  title        = {Rules-reduced fuzzy neural network-based learning control for multiple constraints robots using online identification and compensation methods},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse recovery under nonnegativity and sum-to-one
constraints. <em>ISCI</em>, <em>679</em>, 121059. (<a
href="https://doi.org/10.1016/j.ins.2024.121059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse recovery under nonnegativity and sum-to-one constraints is a special form of the linear regression problem, where the solution is required to simultaneously satisfy sparsity, nonnegativity, and sum-to-one restraints. Existing algorithms for this task mainly utilize the penalty technique to convert the sparsity constraint into a regularization term. Therefore, the sparsity is determined via tuning the associated penalty parameter, which is time-consuming in practice. This paper exploits projected gradient descent to directly tackle the constrained problem without involving the penalty parameter and ℓ 0 ℓ0 -norm approximation. The addition of the ℓ 0 ℓ0 -norm constraint with a specific upper bound enables the proposed algorithm to explicitly control sparsity. The developed method is termed as modified iterative hard thresholding (MIHT), comprised of two iterative steps, namely, gradient descent and nonconvex projection. For the latter, the constraint set consists of the ℓ 0 ℓ0 -norm, nonnegativity, and sum-to-one constraints. We devise an efficient algorithm to address the nonconvex projection and then prove that this method produces an optimal solution. Furthermore, we establish the convergence of the MIHT, including objective value and variable sequence. Numerical experiments using financial and hyperspectral data demonstrate that the MIHT is superior to state-of-the-art methods in terms of prediction error and recovery accuracy.},
  archive      = {J_ISCI},
  author       = {Xiao-Peng Li and Chi-Sing Leung and Hing Cheung So},
  doi          = {10.1016/j.ins.2024.121059},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121059},
  shortjournal = {Inf. Sci.},
  title        = {Sparse recovery under nonnegativity and sum-to-one constraints},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-layer self-representation enhanced deep subspace
clustering with self-supervision. <em>ISCI</em>, <em>679</em>, 121058.
(<a href="https://doi.org/10.1016/j.ins.2024.121058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep subspace clustering typically employs a self-representation layer to accurately capture the similarity relationships among data points. While current techniques enhance self-representation matrices through optimized network structures and balanced regularization strategies, they often overlook comprehensive learning of global data characteristics. Moreover, scalability to large datasets is limited due to the proportional growth of the self-representation matrix with dataset size, presenting computational challenges. To address these issues, we introduce the Cross-Layer Self-Representation Enhanced Deep Subspace Clustering with Self-Supervision method. This novel approach features a hierarchical self-representation fusion mechanism that enriches the understanding of data relationships across different layers. In addition, we employ a contrastive learning strategy to refine data representation learning further. Crucially, we develop a joint framework that surmounts previous limitations in processing large-scale data. Our method&#39;s effectiveness and superiority are conclusively demonstrated through extensive experimental validation.},
  archive      = {J_ISCI},
  author       = {Lifan Peng and Xiaoqian Zhang and Youdong He and Siyu Chen and Yufeng Chen},
  doi          = {10.1016/j.ins.2024.121058},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121058},
  shortjournal = {Inf. Sci.},
  title        = {Cross-layer self-representation enhanced deep subspace clustering with self-supervision},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SFL: A semantic-based federated learning method for POI
recommendation. <em>ISCI</em>, <em>679</em>, 121057. (<a
href="https://doi.org/10.1016/j.ins.2024.121057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional POI recommendation systems use a centralized data storage approach to train models, posing significant risks of privacy breaches. Federated learning offers an effective solution to address user privacy concerns. However, in existing federated learning setups, client data remains isolated from each other, making it challenging to achieve cross-client collaborative training and severely limiting the performance of POI models. Additionally, the sparsity of local client data makes it difficult for local models to effectively learn local personalized knowledge, and low-quality local models further degrade the performance of the global model. Furthermore, the potential of semantic information in representing deep user behavior characteristics hasn&#39;t been fully explored in federated POI recommendation. Therefore, this paper proposes a semantic-based federated learning method (SFL), introducing edge devices to facilitate cross-client personalized knowledge collaboration. We design a semantic-based collaborative optimization strategy to learn and utilize semantic information from client trajectories without sensitive data, guiding edge devices to mine shared user knowledge for achieving knowledge collaboration among similar clients. Simultaneously, the semantic information from client trajectories is utilized to enhance local data, thereby improving the personalized capabilities of local models. Extensive experiments on public datasets demonstrate that SFL outperforms several strong baselines in terms of performance.},
  archive      = {J_ISCI},
  author       = {Xunan Dong and Jun Zeng and Junhao Wen and Min Gao and Wei Zhou},
  doi          = {10.1016/j.ins.2024.121057},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121057},
  shortjournal = {Inf. Sci.},
  title        = {SFL: A semantic-based federated learning method for POI recommendation},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Taking another step: A simple approach to high-dimensional
bayesian optimization. <em>ISCI</em>, <em>679</em>, 121056. (<a
href="https://doi.org/10.1016/j.ins.2024.121056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scaling Bayesian optimization to high-dimensional problems is a meaningful but challenging task. Most of current approaches assume only a few variables are effective to the objective function or the objective function is additively separable, therefore are not suitable when the problem violates these assumptions. In this work, we propose a simple and efficient approach to extend Bayesian optimization to high dimensions. The proposed approach does not make these two assumptions. In each iteration, after locating a candidate point by the global Gaussian process model, we train a local Gaussian process model around the candidate point and locate a new point using the local model. Instead of evaluating the solution located by the global model, we evaluate the solution located by the local model. This simple taking-another-step approach is shown to be able to improve Bayesian optimization&#39;s performance significantly on high-dimensional optimization problems. The proposed algorithm also shows competitive performance when compared with four high-dimensional Bayesian optimization algorithms and four surrogate-assisted evolutionary algorithms.},
  archive      = {J_ISCI},
  author       = {Yuqian Gui and Dawei Zhan and Tianrui Li},
  doi          = {10.1016/j.ins.2024.121056},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121056},
  shortjournal = {Inf. Sci.},
  title        = {Taking another step: A simple approach to high-dimensional bayesian optimization},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable rumor detection based on grey clustering: Fusion
of manual features and deep learning features. <em>ISCI</em>,
<em>679</em>, 121055. (<a
href="https://doi.org/10.1016/j.ins.2024.121055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The importance of rumor detection on social media is self-evident. However, many existing studies have focused on exploring potential features in text content and propagation patterns, while neglecting a key aspect—the explainability of the model. The comment content can provide support for the credibility of the detection. Nevertheless, most studies that use comments encode them into specific models, rarely considering their semantic attitudes and standpoints, making it difficult for models to explain why a post is a rumor. In this study, we propose an E xplainable rumor detection model based on Grey clustering called MDE-Grey, which combines M anual features and D eep learning features. In terms of manual features, we constructed a relevant vocabulary based on the specific comment environment of rumors to capture comment standpoints. In terms of deep learning features, we have designed a GCN sub network that includes two attention mechanisms to capture noteworthy content in posts and comments. Finally, we constructed a new grey clustering model to fuse the two types of features and obtain the final prediction. In the grey clustering model, we designed new whitening functions to capture the intrinsic relationship between features and rumor categories, ensuring the traceability of prediction results. The experiments on three datasets and case studies have demonstrated the effectiveness of the MDE-Grey model in detecting rumors and explaining the results.},
  archive      = {J_ISCI},
  author       = {Xianlong Tan and Shuhua Mao and Xinping Xiao and Yingjie Yang},
  doi          = {10.1016/j.ins.2024.121055},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121055},
  shortjournal = {Inf. Sci.},
  title        = {Explainable rumor detection based on grey clustering: Fusion of manual features and deep learning features},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Restoration towards decomposition: A simple approach for
domain generalization. <em>ISCI</em>, <em>679</em>, 121053. (<a
href="https://doi.org/10.1016/j.ins.2024.121053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain generalization (DG) aims to train a model capable of generalizing to unseen target domains by utilizing data from multiple disjoint source domains. Previous domain generalization methods primarily utilize data augmentation and domain-invariant feature learning. However, since the target domain is unknown, data augmentation methods struggle to generate images or features that closely resemble the target domain. In addition, existing domain-invariant feature learning methods are incapable of achieving complete decoupling, resulting in misalignment of feature distribution between the source and target domains. Hence, in this work, we propose a new perspective to address domain generalization by focusing on learning the ability to transform the target domain visual representations into those of the source domain. If the style of the unknown target domain can be transformed into the style of the known source domain, the adverse effects of domain shift can be effectively mitigated. Following this line of thought, we have developed a meta-learning task named “feature restoration” aimed at training a model to acquire this capability. Specifically, feature restoration involves replacing the domain-specific components within the visual representations of the target domain with those of the source domain. Experimental results on five DG benchmarks reveal that our method can achieve state-of-the-art performance. Ablation studies and visualization results further demonstrate the rationality and effectiveness of our design.},
  archive      = {J_ISCI},
  author       = {Mengwei Li and Zilei Wang and Xiaoming Hu},
  doi          = {10.1016/j.ins.2024.121053},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121053},
  shortjournal = {Inf. Sci.},
  title        = {Restoration towards decomposition: A simple approach for domain generalization},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LegalAsst: Human-centered and AI-empowered machine to
enhance court productivity and legal assistance. <em>ISCI</em>,
<em>679</em>, 121052. (<a
href="https://doi.org/10.1016/j.ins.2024.121052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose autonomous software (namely, LegalAsst ) as a step toward an AI-empowered but human-centered machine focused on enhancing court productivity and legal assistance. LegalAsst aims to provide explainable, traceable, and controllable legal assistance and references for lawyers, judges, government officials, and the general public. To achieve this goal, it collates, processes, distills, and visualizes the whole judgment procedure. It streamlines and semi-automates the judgment procedure through case analysis, legislation analysis, and judicial decision-making. Specifically, to make laws and cases easier to navigate and understand, we incorporate structured representations to perform them. Then based on structured representations, we take a step further by introducing a decision-tree-based judgment, making the entire judging process visible and tractable. Our system not only tracks the procedural aspects of judgments but also incorporates modification capabilities, enabling the consideration of the most up-to-date legislation and societal factors to generate more adaptable judgment outcomes. 1},
  archive      = {J_ISCI},
  author       = {Wenjuan Han and Jiaxin Shen and Yanyao Liu and Zhan Shi and Jinan Xu and Fangxu Hu and Hao Chen and Yan Gong and Xueli Yu and Huaqing Wang and Zhijing Liu and Yajie Yang and Tianshui Shi and Mengyao Ge},
  doi          = {10.1016/j.ins.2024.121052},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121052},
  shortjournal = {Inf. Sci.},
  title        = {LegalAsst: Human-centered and AI-empowered machine to enhance court productivity and legal assistance},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating adaptive fuzzy embedding with topology and
property hypergraphs: Enhancing membership degree-aware knowledge graph
reasoning. <em>ISCI</em>, <em>679</em>, 121051. (<a
href="https://doi.org/10.1016/j.ins.2024.121051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs (KG) leverage the Resource Description Framework (RDF) to model clear and static resources, enabling the revelation of latent meanings through embedding and reasoning. However, their effectiveness diminishes when facing the inherent vagueness and dynamism of real-world information. To overcome this limitation, we introduce a novel adaptive fuzzy RDF KG embedding approach. This method represents fuzzy knowledge by integrating topological structures and descriptive properties while generating membership degrees to enhance the reasoning capabilities of KG. Specifically, our approach introduces a way to create embeddings based on local and global topological pattern mining. Then, path quality-based adaptive learning is implemented. Next, we incorporate entity descriptive information and construct a property hypergraph from another perspective to learn embeddings. By creatively combining these three components, our method can generate a fuzzy membership degree to aid knowledge reasoning. To thoroughly assess the method&#39;s effectiveness, experiments were conducted around four key questions, evaluating algorithm performance compared with other work and assessing knowledge reasoning effectiveness based on logical inference rules on Unmanned Aerial Vehicle (UAV) datasets.},
  archive      = {J_ISCI},
  author       = {Yufeng Ma and Yajie Dou and Xiangqian Xu and Yuejin Tan and Kewei Yang},
  doi          = {10.1016/j.ins.2024.121051},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121051},
  shortjournal = {Inf. Sci.},
  title        = {Integrating adaptive fuzzy embedding with topology and property hypergraphs: Enhancing membership degree-aware knowledge graph reasoning},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-paced method for transfer partial label learning.
<em>ISCI</em>, <em>679</em>, 121043. (<a
href="https://doi.org/10.1016/j.ins.2024.121043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In partial label learning (PLL) problem, each training sample corresponds to a group of candidate labels, in which only one label is the ground-truth label (correct label). Almost all the existing PLL algorithms attempt to eliminate the ambiguity of the candidate label sets by treating all labels indiscriminately. However, this kind of approach lacks the consideration of the complexity between the labels and the instances in the training process. Encouraged by the extensive researches of the self-paced learning (SPL) and transfer learning (TL) in various fields, this paper introduces SPL and TL together to address the PLL problem and proposes a new SPL framework, which is called self-paced method for transfer partial label learning (SPTPLL). The proposed model utilizes transfer learning model to share the parameters and regularization terms of the Support Vector Machine (SVM), which can transfer knowledge from the source task to the target task. Additionally, we implement the self-paced learning scheme by choosing a suitable self-paced function to enhance the robustness of the proposed model. In the process of learning iteration, the priority of training examples with their candidate labels is ranked through self-paced learning to control the learning process. Finally, we demonstrate the superior performance of the proposed method through a large number of experiments compared with state-of-the-art baseline methods.},
  archive      = {J_ISCI},
  author       = {Bo Liu and Zhiyu Zheng and Yanshan Xiao and Peng Sun and Xiaokai Li and Shilei Zhao and Yongsheng Huang and Tiantian Peng},
  doi          = {10.1016/j.ins.2024.121043},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121043},
  shortjournal = {Inf. Sci.},
  title        = {Self-paced method for transfer partial label learning},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). IDP-FL: A fine-grained and privacy-aware federated learning
framework for deep neural networks. <em>ISCI</em>, <em>679</em>, 121035.
(<a href="https://doi.org/10.1016/j.ins.2024.121035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL), as a distributed machine learning paradigm, essentially promises that multiple parties can jointly train the model collaboratively without sharing local data. Recent research demonstrates that the adversary can deduce the sensitive data through shared model updates. To protect the data privacy of the participants, differential privacy (DP) is deployed in various FL scenarios due to the lightweight computational overhead. However, the trade-off between the availability and privacy of local models is the fundamental problem that needs to be solved in DP applications. In this paper, we propose a fine-grained and privacy-aware FL framework (iDP-FL) to enable training data and model parameters to satisfy confidentiality while markedly improving the model&#39;s prediction accuracy. Specifically, we first design an individualized perturbation noise (IPN) algorithm that adds different artificial noises dependent on the importance of each participant&#39;s model weight. Then, we propose a perturbation mechanism on the aggregator side, a DP protection method under the premise of loss function convergence, which prevents the global model parameters from being stolen by malicious adversaries. Moreover, to achieve lightweight protection throughout the learning, we present an advanced bilateral perturbation (ABP) protocol to perform iterative training. Theoretical analysis indicates that iDP-FL provides the DP guarantee, which yields superior prediction accuracy and excellent privacy-preserving with the same privacy level. Finally, extensive experiments conducted on real-world datasets demonstrate that our approach shows significant advantages with limited privacy budgets, especially at small privacy losses.},
  archive      = {J_ISCI},
  author       = {Junpeng Zhang and Hui Zhu and Fengwei Wang and Yandong Zheng and Zhe Liu and Hui Li},
  doi          = {10.1016/j.ins.2024.121035},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121035},
  shortjournal = {Inf. Sci.},
  title        = {IDP-FL: A fine-grained and privacy-aware federated learning framework for deep neural networks},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved dendritic learning: Activation function analysis.
<em>ISCI</em>, <em>679</em>, 121034. (<a
href="https://doi.org/10.1016/j.ins.2024.121034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study conducted a thorough evaluation of an improved dendritic learning (DL) framework, focusing specifically on its application in power load forecasting. The objective was to optimise the activation functions within the synapses and somas of DL to enhance their adaptability across diverse real-world scenarios. Through a rigorous analysis involving 25 experiments across five activation functions (sigmoid, hyperbolic tangent (tanh), rectified linear unit (ReLU), leaky ReLU, and exponential linear unit (ELU)), we elucidated their impacts on both regression and classification performance. Notably, the leaky ReLU–tanh combination demonstrated exceptional mean performance and effectiveness across 14 benchmark datasets from the University of California Irvine Machine Learning Repository, surpassing alternative combinations. When applied to power load forecasting, this combination outperformed other models, particularly transformer and LSTM. These findings underscore the significant advantages of the leaky ReLU–tanh-based DL framework in accurately predicting electricity load in smart grids, as evidenced by the lowest mean absolute error (39.27), root mean squared error (29.13), and mean absolute percentage error (2.84).},
  archive      = {J_ISCI},
  author       = {Yizheng Wang and Yang Yu and Tengfei Zhang and Keyu Song and Yirui Wang and Shangce Gao},
  doi          = {10.1016/j.ins.2024.121034},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121034},
  shortjournal = {Inf. Sci.},
  title        = {Improved dendritic learning: Activation function analysis},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge-embedded constrained multiobjective evolutionary
algorithm based on structural network control principles for
personalized drug targets recognition in cancer. <em>ISCI</em>,
<em>679</em>, 121033. (<a
href="https://doi.org/10.1016/j.ins.2024.121033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The structural network control principle for identifying personalized drug targets (SNCPDTs) is a kind of constrained multiobjective optimization (CMO) problem with NP-hard features, which makes traditional mathematical methods difficult to adopt. Therefore, this study designs a knowledge-embedded multitasking constrained multiobjective evolutionary algorithm (KMCEA) to solve the SNCPDTs by mining relevant knowledge. Specifically, the relationships between two optimization objectives (minimizing the number of driver nodes and maximizing prior-known drug-target information) and constraints (guaranteeing network control) are analyzed from the perspective of CMO. We find that two objectives are difficult to optimize; thus two single-objective auxiliary tasks are created to optimize two objectives respectively, so as to maintain diversity along the Pareto front. Furthermore, we find that two optimization objectives have a complex reverse relation and a simple positive relation with constraints, respectively; thus, a population initialization method and a local auxiliary task are designed for two single-objective auxiliary tasks, respectively, so as to improve the performance of the algorithm on two objective functions. Finally, KMCEA is used to solve two kinds of models with three kinds of datasets. Compared with various methods, KMCEA can not only effectively discover clinical combinatorial drugs but also better solve the SNCPDTs regarding convergence and diversity.},
  archive      = {J_ISCI},
  author       = {Kangjia Qiao and Jing Liang and Wei-Feng Guo and Zhuo Hu and Kunjie Yu and P.N. Suganthan},
  doi          = {10.1016/j.ins.2024.121033},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121033},
  shortjournal = {Inf. Sci.},
  title        = {Knowledge-embedded constrained multiobjective evolutionary algorithm based on structural network control principles for personalized drug targets recognition in cancer},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-stage particle swarm optimization with dual-indicator
fusion ranking for multi-objective problems. <em>ISCI</em>,
<em>679</em>, 121032. (<a
href="https://doi.org/10.1016/j.ins.2024.121032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elite solutions guiding population evolution are often used as one of main ideas to improve the performance of multi-objective particle swarm optimization (MOPSO). However, in most research work, sole Pareto dominance criterion is often used to evaluate solutions. This sole criterion may easily cause some problems, such as the premature convergence. In this study, we propose an MOPSO variant with dual-indicator fusion ranking (TPSO-DF), to evaluate elite solutions and to guide search without sacrificing diversity. In TPSO-DF, two indicators are introduced by using the convergence and diversity information, respectively. Both indicators are then fusioned in a ranking measure to focus on valuable information and to filter out solutions with these valuable information. Meanwhile, an adaptive global leader selection strategy is introduced to take full advantage of valuable information and to guide population evolution toward the optimal direction. As another contribution of this study, a two-stage hybrid mutation strategy is designed by utilizing the valuable information differently in different evolutionary states of the algorithm to enhance performance. Compared to eight representative multi-objective evolutionary algorithms, the performance of TPSO-DF is validated by extensive experiments on ZDT and DTLZ test suites, as well as one practical problem. Experimental results show that TPSO-DF can achieve competitive performance on most of the test functions.},
  archive      = {J_ISCI},
  author       = {Qing Xu and Yuhao Chen and Cisong Shi and Junhong Huang and Wei Li},
  doi          = {10.1016/j.ins.2024.121032},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121032},
  shortjournal = {Inf. Sci.},
  title        = {Two-stage particle swarm optimization with dual-indicator fusion ranking for multi-objective problems},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hierarchical mission planning system for multi-uncrewed
ground vehicles using fast cost evaluation and ant colony optimisation.
<em>ISCI</em>, <em>679</em>, 121029. (<a
href="https://doi.org/10.1016/j.ins.2024.121029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mission Planning for Multi-Uncrewed Ground Vehicle (multi-UGV) missions is a key functional module for achieving effective autonomy and coordination within a fleet of vehicles. However, the complexity of mission planning is compounded by the interconnected sub-problems and the challenging environments encountered by UGVs. Aiming to devise efficient and effective techniques to tackle the intricacies of mission planning in complex and cluttered environments, this paper presents an algorithmic architecture tailored for hierarchical multi-UGV mission planning systems. Specifically, this paper designs a Modified Cost Approximation Method integrated with two-layer environmental modelling for fast estimation of the travelling cost graphs of target points. A Hybrid Clustering Method that merges k -means clustering with a marginal cost-based assignment is proposed to streamline task decomposition and task assignment. Furthermore, a three-layer path planner is developed by integrating A*, post-processing steps, and Multi-operator Continuous Ant Colony optimisation, aiming to find paths with reduced cost for UGVs in challenging terrains. To evaluate the proposed techniques, a benchmark set for multi-UGV mission planning problems is designed using the robotic simulation platform CoppeliaSim. Simulation results demonstrate the superior performance of the proposed planning techniques.},
  archive      = {J_ISCI},
  author       = {Jing Liu and Sreenatha Anavatti and Matthew Garratt and Hussein A. Abbass},
  doi          = {10.1016/j.ins.2024.121029},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121029},
  shortjournal = {Inf. Sci.},
  title        = {A hierarchical mission planning system for multi-uncrewed ground vehicles using fast cost evaluation and ant colony optimisation},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PCFS: An intelligent imbalanced classification scheme with
noisy samples. <em>ISCI</em>, <em>679</em>, 121020. (<a
href="https://doi.org/10.1016/j.ins.2024.121020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced classification is an important research direction in machine learning. In this field, imbalanced data with noise is a challenging problem. Although many methods have been proposed to solve it, the problem remains open. If there is a method by which the information of noise and normal samples can be properly expressed at the same time, good results will be achieved. Therefore, this paper proposes the Polynomial Curve Fitting Sampling scheme, called PCFS, which uses random partition vectors and danger samples to obtain the characteristics of samples and noise respectively. The polynomial is then used to curve fit these data and fuse their features, and then adjusted the boundary between the majority and minority classes of the imbalanced datasets. After undersampling, ensemble learning is used for further improvement. Compared with the seven state-of-the-art algorithms on 15 imbalanced datasets, the effect of the proposed method is more excellent. In particular, it has obvious advantages in high noise and high imbalance rate datasets. Also, PCFS has been applied to the recognition of electric larceny in power industry and achieved good results. This shows that our method has a bright future in dealing with practical problems of complex imbalances. The implementation of the proposed PCFS in programming language Python is available at https://github.com/a2nie/PCFS .},
  archive      = {J_ISCI},
  author       = {Lei Jiang and Peng Chen and Jing Liao and Caoqing Jiang and Wei Liang and Neal N. Xiong},
  doi          = {10.1016/j.ins.2024.121020},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121020},
  shortjournal = {Inf. Sci.},
  title        = {PCFS: An intelligent imbalanced classification scheme with noisy samples},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collaborative denoised graph contrastive learning for
multi-modal recommendation. <em>ISCI</em>, <em>679</em>, 121017. (<a
href="https://doi.org/10.1016/j.ins.2024.121017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks, with their capacity to capture complex hierarchical relations, are extensively employed in multi-modal recommendation. Previous graph-based multi-modal recommendation studies primarily focus on integrating multi-modal features that capture the neighbor relations as auxiliary information. However, such methods heavily rely on graph structure properties for collaborative relations. Furthermore, while the massive implicit feedbacks alleviate the data sparsity issue, the drawback is that they are not as reliable in accurately reflecting users true interests. We propose a Collaborative Denoised Graph Contrastive Learning framework named CDGCL for multi-modal recommendation. Specifically, we present a novel modality-aware item representation with contrastive learning to capture the modality-aware collaborative relations. Besides, we develop a Multi-Policy Denoised module (MPD) to filter out irrelevant interactions. Extensive experiments that include cold-start and warm-start experimental scenarios demonstrate the superiority of CDGCL over baselines.},
  archive      = {J_ISCI},
  author       = {Fuyong Xu and Zhenfang Zhu and Yixin Fu and Ru Wang and Peiyu Liu},
  doi          = {10.1016/j.ins.2024.121017},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121017},
  shortjournal = {Inf. Sci.},
  title        = {Collaborative denoised graph contrastive learning for multi-modal recommendation},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new ensemble intuitionistic fuzzy-deep forecasting model:
Consolidation of the IFRFs-bENR with LSTM. <em>ISCI</em>, <em>679</em>,
121007. (<a href="https://doi.org/10.1016/j.ins.2024.121007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among forecasting model families, the intuitionistic fuzzy-based forecasting model stands out due to its comprehensive approach to uncertainty, considering possible degrees of hesitation. This study offers a forecasting model that consolidates intuitionistic fuzzy regression functions based on elastic net regularization (IFRFs-bENR) with LSTM. The proposed consolidated model, unlike existing models, is capable of modelling both linear and nonlinear structures that coexist between inputs and outputs. Another noteworthy aspect of the consolidated forecasting model is its method of determining model hyperparameters through a systematic optimization process using GA, in contrast to the trial-and-error approach prevalent in most literature studies. The validity and consistency of the model were assessed by running the model 50 times with the optimal hyperparameter values obtained for the consolidated model. And thus, the experimental probability distributions of the forecasts were also obtained. The proposed consolidated model also outperforms its peers in this aspect. The consolidated forecasting model was applied to different sets of time series, including TAIEX, DJI, SSEC, and IstEX. The findings indicate that the proposed consolidated model produces more accurate forecasts compared to various selected benchmark models. All abbreviations used in the article are defined in Supplementary Table 1 under the List of Abbreviations.},
  archive      = {J_ISCI},
  author       = {Ozge Cagcag Yolcu and Ufuk Yolcu},
  doi          = {10.1016/j.ins.2024.121007},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121007},
  shortjournal = {Inf. Sci.},
  title        = {A new ensemble intuitionistic fuzzy-deep forecasting model: Consolidation of the IFRFs-bENR with LSTM},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The EEG signals steganography based on wavelet packet
transform-singular value decomposition-logistic. <em>ISCI</em>,
<em>679</em>, 121006. (<a
href="https://doi.org/10.1016/j.ins.2024.121006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-computer interface (BCI) technology is widely used in online medicine for the diagnosis and treatment of brain diseases. However, during brain-computer interaction, Electroencephalogram (EEG) signals and private information may be leaked when transmitted through unsecured Internet channels. To protect private information and EEG signal security, this paper proposes a steganography algorithm based on Wavelet Packet Transform-Singular Value Decomposition-Logistic (WPT-SVD-Logistic). The algorithm utilized wavelet packet transform (WPT) to conceal more private information while maintaining better perceptual fidelity. After two-level WPT processing, the EEG signal is decomposed into 4 sub-band signals, and then the singular value decomposition (SVD) method is used to embed private information into these sub-band signals. Additionally, the algorithm employed the Logistic map to confuse private information further and enhance its security. Experimental results show that WPT is more suitable for information hiding in EEG signals. The average peak signal-to-noise ratio of the algorithm on four different datasets is 96.5 dB, indicating that adding private information has a weak impact on the EEG signal. Compared with similar methods, this algorithm has smaller errors and stronger robustness, so it has more potential to become the main means of EEG signal steganography.},
  archive      = {J_ISCI},
  author       = {Dong Wen and Wenlong Jiao and Xiaoling Li and Xianglong Wan and Yanhong Zhou and Xianling Dong and Haiqing Song and Wei Han and Tiange Liu and Dingna Duan},
  doi          = {10.1016/j.ins.2024.121006},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121006},
  shortjournal = {Inf. Sci.},
  title        = {The EEG signals steganography based on wavelet packet transform-singular value decomposition-logistic},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multiscale neural architecture search framework for
multimodal fusion. <em>ISCI</em>, <em>679</em>, 121005. (<a
href="https://doi.org/10.1016/j.ins.2024.121005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal fusion, a machine learning technique, significantly enhances decision-making by leveraging complementary information extracted from different data modalities. The success of multimodal fusion relies heavily on the design of the fusion scheme. However, this process traditionally depends on manual expertise and exhaustive trials. To tackle this challenge, researchers have undertaken studies on DARTS-based Neural Architecture Search (NAS) variants to automate the search of fusion schemes. In this paper, we present theoretical and empirical evidence that highlights the presence of catastrophic search bias in DARTS-based multimodal fusion methods. This bias traps the search into a deceptive optimal childnet, rendering the entire search process ineffective. To circumvent this phenomenon, we introduce a novel NAS framework for multimodal fusion, featuring a robust search strategy and a meticulously designed multi-scale fusion search space. Significantly, the proposed framework is capable of capturing modality-specific information across multiple scales while achieving an automatic balance between intra-modal and inter-modal information. We conduct extensive experiments on three commonly used multimodal classification tasks from different domains and compare the proposed framework against state-of-the-art approaches. The experimental results demonstrate the superior robustness and high efficiency of the proposed framework.},
  archive      = {J_ISCI},
  author       = {Jindi Lv and Yanan Sun and Qing Ye and Wentao Feng and Jiancheng Lv},
  doi          = {10.1016/j.ins.2024.121005},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121005},
  shortjournal = {Inf. Sci.},
  title        = {A multiscale neural architecture search framework for multimodal fusion},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatio-temporal communication network traffic prediction
method based on graph neural network. <em>ISCI</em>, <em>679</em>,
121003. (<a href="https://doi.org/10.1016/j.ins.2024.121003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The function of network traffic prediction plays an important role in many network operations such as security, path planning and congestion control etc. Most traditional traffic prediction methods only consider temporal correlation but ignore spatial correlation, which may result in limited accuracy. In this paper, we propose an effective traffic prediction method based on the graph multi-head attention convolution neural network model, termed as FlowDiviner, which combines graph convolutional network (GCN) and multi-head attention mechanism in its encoder-decoder architecture. Specifically, GCN is used to extract spatial correlation from complex network topologies and multi-head attention mechanism is used to capture dynamic temporal correlations based on monitored traffic behaviors. Meanwhile, a middle attention module is introduced between encoder and decoder to model the relationship between historical and future timesteps of traffic, thus it can alleviate the error accumulation and improve accuracy. The experiments based on both real-life dataset as well as synthetically generated traffic traces show that FlowDiviner can effectively obtain temporal and spatial correlation from the network historical traffic data, and the test results of all metrics are significantly improved from the baseline schemes.},
  archive      = {J_ISCI},
  author       = {Liang Qin and Huaxi Gu and Wenting Wei and Zhe Xiao and Zexu Lin and Lu Liu and Ning Wang},
  doi          = {10.1016/j.ins.2024.121003},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121003},
  shortjournal = {Inf. Sci.},
  title        = {Spatio-temporal communication network traffic prediction method based on graph neural network},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HSeq2Seq: Hierarchical graph neural network for accurate
mobile traffic forecasting. <em>ISCI</em>, <em>679</em>, 120982. (<a
href="https://doi.org/10.1016/j.ins.2024.120982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical graph neural networks (HGNNs) provide a feasible method for modeling complex spatiotemporal dependencies during mobile traffic forecasting. However, most existing studies have adopted spatial node clustering methods to construct a coarsened graph that overlooks the temporal correlation within the original station graph. Furthermore, existing state-of-the-art methods fail to fully exploit the cross-regional feature impacts on stations, which limits their ability to model nonlocal spatial dependency. To overcome these limitations, we proposed a hierarchical sequence-to-sequence (HSeq2Seq) approach that combines HGNNs with a sequence-to-sequence architecture (Seq2Seq) for mobile traffic forecasting. First, a spatiotemporal node clustering method was designed to construct the hierarchical structure. Second, a convolution encoder was employed to extract the local spatiotemporal features from a hierarchical perspective, and a novel attention-based feature fusion module was built to capture the nonlocal spatiotemporal features by identifying both the intra- and cross-regional feature impacts on the stations. Finally, a recurrent decoder is introduced to reweight the spatiotemporal features and recursively produce the final prediction. Extensive experiments on two real-world datasets demonstrate that our model outperforms state-of-the-art methods, while the ablation study also verifies the effectiveness of the spatiotemporal node clustering and the attention-based feature fusion module.},
  archive      = {J_ISCI},
  author       = {Rihui Xie and Xuefeng Guan and Jun Cao and Xinglei Wang and Huayi Wu},
  doi          = {10.1016/j.ins.2024.120982},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120982},
  shortjournal = {Inf. Sci.},
  title        = {HSeq2Seq: Hierarchical graph neural network for accurate mobile traffic forecasting},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards safe and sustainable reinforcement learning for
real-time strategy games. <em>ISCI</em>, <em>679</em>, 120980. (<a
href="https://doi.org/10.1016/j.ins.2024.120980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combining Deep Neural Networks with Reinforcement Learning, known as Deep Reinforcement Learning (DRL), is revolutionizing fields like medicine, industry, and gaming. DRL has achieved groundbreaking results, particularly in complex Real-Time Strategy (RTS) games such as StarCraft II and Dota 2, serving as benchmarks for testing RL algorithms&#39; robustness and safety. Despite these successes, DRL algorithms face challenges, including high computational costs and a lack of safety-aware approaches. Training these algorithms requires extensive computational resources, leading to a significant divide between algorithms developed on supercomputers and those feasible on standard hardware. This also raises sustainability concerns due to increased CO 2 emissions. Additionally, most RL algorithms are risk-neutral, limiting their deployment in safety-critical systems. We present a novel model-based DRL approach, the Safe Observations Rewards Actions Costs Learning Ensemble (S-ORACLE), to address these challenges. S-ORACLE balances robust safety awareness with minimized risk and computational efficiency. Empirical validation across complex game environments—Deep RTS, ELF: MiniRTS, MicroRTS, Deep Warehouse, and StarCraft II—demonstrates that S-ORACLE outperforms state-of-the-art methods by significantly improving safety performance, reducing computational costs, and lowering environmental impact, while maintaining high efficiency and adaptability in training.},
  archive      = {J_ISCI},
  author       = {Per-Arne Andersen and Morten Goodwin and Ole-Christoffer Granmo},
  doi          = {10.1016/j.ins.2024.120980},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120980},
  shortjournal = {Inf. Sci.},
  title        = {Towards safe and sustainable reinforcement learning for real-time strategy games},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning evolving prototypes for imbalanced data stream
classification with limited labels. <em>ISCI</em>, <em>679</em>, 120979.
(<a href="https://doi.org/10.1016/j.ins.2024.120979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world data streams often exhibit long-tailed distributions with heavy class imbalance, posing great challenges for data stream classification, especially in the case of label scarcity and concept drift. Several active learning methods have been proposed to address this problem by selecting the most valuable instances for labeling. However, existing methods often struggle to dynamically identify the most valuable instances that truly represent the current concept while still requiring a large label budget. In this work, we propose a new algorithm, LEPID, to combine dynamic micro-cluster concept modeling and local entropy modeling to select current important concepts and prototypes. Specifically, we give greater weight to concept drift prototypes and minority prototypes to focus more on those regions that represent current concepts. We use a local entropy strategy based on micro-clusters to select the most valuable instances for labeling and reduce the label budget. Extensive experiments on real-world and synthetic imbalanced datasets show that, compared to state-of-the-art algorithms, our method can naturally adapt to concept drift and dynamically capture the current and most valuable prototypes to achieve better results even in the case of label scarcity.},
  archive      = {J_ISCI},
  author       = {Zhonglin Wu and Hongliang Wang and Jingxia Guo and Qinli Yang and Junming Shao},
  doi          = {10.1016/j.ins.2024.120979},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120979},
  shortjournal = {Inf. Sci.},
  title        = {Learning evolving prototypes for imbalanced data stream classification with limited labels},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intermediate estimator based finite-time fault-tolerant
control for nonlinear switched stochastic systems. <em>ISCI</em>,
<em>679</em>, 120955. (<a
href="https://doi.org/10.1016/j.ins.2024.120955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The finite time fault-tolerant control problem for switched stochastic nonlinear systems with actuator and sensor faults is studied in this paper. Firstly, the finite-time intermediate estimator is considered to reconstructed the system state, sensor and actuator faults. The proposed observer involves the output estimation error feedback to improve the estimation accuracy. According to the estimator mentioned above, the fault-tolerant controller is proposed to reduce the fault impact. Using the average dwell time and piecewise Lyapunov functions, sufficient conditions for the nonlinear switched stochastic systems to achieve finite-time stochastic boundedness are obtained. Finally, two examples are proposed to illustrate the feasibility of above method.},
  archive      = {J_ISCI},
  author       = {Ping Yu and Jian Han and Xiuhua Liu and Xinjiang Wei},
  doi          = {10.1016/j.ins.2024.120955},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120955},
  shortjournal = {Inf. Sci.},
  title        = {Intermediate estimator based finite-time fault-tolerant control for nonlinear switched stochastic systems},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). K-cardinal specificity measures. <em>ISCI</em>,
<em>679</em>, 120943. (<a
href="https://doi.org/10.1016/j.ins.2024.120943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The specificity measures can indicate the degree to which a fuzzy subset or possibility distribution points to one and only one element, it can also express the degree of anxiety when decision-makers select one alternative from a set of alternatives. However, in the practical decision-making problems, people usually do not make single choice, but rather make multiple choices. So in this paper, we introduce the concept of k -cardinal specificity measures which promote Yager&#39;s work about specificity measures, it can show the degree of anxiety when decision-makers want to select k alternatives from a set of n alternatives when 1 ≤ k &lt; n 1≤k&amp;lt;n , some interesting properties about the k -cardinal specificity measures are also investigated.},
  archive      = {J_ISCI},
  author       = {Boquan Li and Zeshui Xu},
  doi          = {10.1016/j.ins.2024.120943},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120943},
  shortjournal = {Inf. Sci.},
  title        = {K-cardinal specificity measures},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Consensus of multiagent systems via a distributed
event-triggered intermittent control. <em>ISCI</em>, <em>679</em>,
120927. (<a href="https://doi.org/10.1016/j.ins.2024.120927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper respectively investigates the leader-following consensus by distributed event-triggered intermittent control (DETIC) and distributed event-triggered intermittent adaptive control (DETIAC) for multiagent systems (MASs). Different from traditional intermittent control, the starting and ending times of intermittent control are determined by distributed event-triggered mechanisms (ETMs), breaking the rigidity of mechanical intermittent control and further reducing the utilization of network resources. Especially, the designed distributed ETMs only use own real-time state information and its neighbors&#39; states at their latest triggering moment, which means that every agent doesn&#39;t require continue communication with neighbors. In addition, the adaptive control gain is introduced to DETIC, where the updating of adaptive gain only occurs during working time and does not require continue communication with other agents. Compared with DETIC, no extra communication is needed for updating the adaptive gain. Moreover, Zeno behavior is excluded under the proposed control strategies. Finally, two simulations validate the effectiveness of DETIC and DETIAC.},
  archive      = {J_ISCI},
  author       = {Yawen Zhou and Yanhua Yang and Yufeng Zhou and Li Chai},
  doi          = {10.1016/j.ins.2024.120927},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120927},
  shortjournal = {Inf. Sci.},
  title        = {Consensus of multiagent systems via a distributed event-triggered intermittent control},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved genetic salp swarm algorithm with population
partitioning for numerical optimization. <em>ISCI</em>, <em>679</em>,
120895. (<a href="https://doi.org/10.1016/j.ins.2024.120895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The metaheuristic method is effective in solving complex optimization problems. Among these methods, the Salp Swarm algorithm (SSA), inspired by the sailing and foraging behavior of the deep-sea salps population, has proven to be an effective method. However, in practice, SSA is prone to the problems of reduced population diversity and falling into local minima. In order to solve this problem, this paper combines several new techniques and introduces an improved version of SSA called Genetic Salp Swarm Algorithm (GSSA). Specifically, GSSA generates an initial population using a chaotic dyad-based learning method, reduces the dimensionality by a population partitioning technique and performs crossover and mutation operations on the reduced subspace, and finally acts on the optimal solution through three mutation operators to prevent the algorithm from stagnating in the local optimum. This novel GSSA algorithm is tested on 23 benchmark function test sets, CEC2017 and CEC2022. The results show that the GSSA algorithm converges faster and has higher accuracy.},
  archive      = {J_ISCI},
  author       = {Qinwei Fan and Shuai Zhao and Meiling Shang and Zhanli Wei and Xiaodi Huang},
  doi          = {10.1016/j.ins.2024.120895},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120895},
  shortjournal = {Inf. Sci.},
  title        = {An improved genetic salp swarm algorithm with population partitioning for numerical optimization},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HGDO: An oversampling technique based on hypergraph
recognition and gaussian distribution. <em>ISCI</em>, <em>679</em>,
120891. (<a href="https://doi.org/10.1016/j.ins.2024.120891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The synthetic minority oversampling technique (SMOTE) is the most prevalent solution in class imbalance learning. While SMOTE and its variant methods handle imbalanced data well in most cases, they fail to take full advantage of the structural information in the overall data, which leads to the propagation of noise. Some existing SMOTE variants remove noisy samples by adding an undersampling process. However, due to the complexity of the data distribution, it is difficult to accurately identify real noise samples, leading to lower modeling quality. To this end, we propose an oversampling technique based on hypergraph identification and Gaussian distribution (HGDO). First, neighborhood reconstruction is performed for each sample depending on the sparse representation to build a hypergraph model, and outlier and noisy samples are filtered according to this model. Then, the weight of each retained minority class sample is determined through the distribution relationship of hyperedges and vertices. Finally, new samples are generated based on the Laplacian matrix and Gaussian distribution to balance the dataset. The comprehensive experimental analysis demonstrates the superiority of HGDO over some popular SMOTE variants.},
  archive      = {J_ISCI},
  author       = {Liyan Jia and Zhiping Wang and Pengfei Sun and Peiwen Wang},
  doi          = {10.1016/j.ins.2024.120891},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120891},
  shortjournal = {Inf. Sci.},
  title        = {HGDO: An oversampling technique based on hypergraph recognition and gaussian distribution},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024e). Relation pruning and discriminative sampling over knowledge
graph for long-tail recommendation. <em>ISCI</em>, <em>679</em>, 120871.
(<a href="https://doi.org/10.1016/j.ins.2024.120871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-tail recommendations have gained significant attention owing to their potential economic market. However, the scarcity of interaction data for long-tail users/items and the popularity bias present challenges in capturing high-quality embeddings for long-tail users/items. This predicament further exacerbates the long-tail recommendation problem, as current approaches tend to exhibit a bias towards making recommendations for short-head users/items, resulting in a detrimental cycle for long-tail recommendation. To this end, we propose a novel knowledge graph-based approach called LTailKG to improve long-tail recommendations. LTailKG leverages the semantic information in knowledge graph to produce high-quality embeddings and augmented samples for generating satisfactory long-tail recommendations. First, LTailKG parameterizes each node and relation as vector representations. Next, LTailKG presents a relation pruning-based graph contrastive learning operation to generate additional self-supervised signals for long-tail users/items, thereby producing high-quality embeddings for them. Furthermore, LTailKG introduces a knowledge graph-driven discriminative sampling operation to select augmented positive and negative samples from the uninteracted item set, which enables LTailKG to excel at not only identifying long-tail items that better align with the user&#39;s interests but also extracting the genuine preferences of long-tail users. Extensive experiments on real-world datasets demonstrate the superiority of LTailKG over state-of-the-art approaches in terms of long-tail recommendation.},
  archive      = {J_ISCI},
  author       = {Zhipeng Zhang and Anqi Wang and Yao Zhang and Yonggong Ren and Wenqing Li and Bowen Wang and Masahiro Inuiguchi},
  doi          = {10.1016/j.ins.2024.120871},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120871},
  shortjournal = {Inf. Sci.},
  title        = {Relation pruning and discriminative sampling over knowledge graph for long-tail recommendation},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent emergency traffic signal control system with
pedestrian access. <em>ISCI</em>, <em>679</em>, 120805. (<a
href="https://doi.org/10.1016/j.ins.2024.120805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the integration of artificial intelligence and traffic systems, intelligent traffic systems are utilizing enhanced perception coverage and computational capabilities to provide data-intensive solutions, achieving higher levels of performance than traditional systems. This paper combines the D3QN algorithm from deep reinforcement learning with practical issues and proposes an intelligent emergency traffic signal control system based on Deep Reinforcement Learning (DRL). The system takes into account pedestrian movement and utilizes real-time traffic data and environmental information to model traffic flow and road conditions within a novel state space. It employs the Dueling Double Deep Q-Network (D3QN) to optimize signal control strategies. The system dynamically adjusts signal timings to enhance operational efficiency at intersections. By using the Weibull distribution to simulate realistic traffic congestion and actual traffic data from Shanyin Road in Hangzhou for validation, the results demonstrate that this method converges faster and is more stable compared to other methods, significantly reducing traffic congestion. Furthermore, by incorporating pedestrian movement, this method reduces pedestrian waiting times by 44.736% during peak periods and 22.95% during off-peak periods, while maintaining comparable vehicle queue lengths, delay times, and carbon dioxide emissions. This approach shows the potential improvement of smart urban mobility and resolving intersection congestion challenges.},
  archive      = {J_ISCI},
  author       = {Li-Juan Liu and Hua Si and Hamid Reza Karimi},
  doi          = {10.1016/j.ins.2024.120805},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120805},
  shortjournal = {Inf. Sci.},
  title        = {Intelligent emergency traffic signal control system with pedestrian access},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing resource allocation in UAV-assisted ultra-dense
networks for enhanced performance and security. <em>ISCI</em>,
<em>679</em>, 120788. (<a
href="https://doi.org/10.1016/j.ins.2024.120788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deployment of unmanned aerial vehicles (UAVs) in ultra-dense networks (UNDs) has significantly advanced network capabilities in 5G/6G environments, addressing coverage enhancement and security concerns. Our research presents a deep reinforcement learning (DRL) based approach designed to manage the increasing data traffic demands and limited communication resources in UAV-assisted UNDs. Traditional DRL methodologies often struggle with challenges like low sample efficiency and energy wastage, which can indirectly impact network security and stability. To address these concerns, we introduce the Stabilizing Transformers based Potential Driven Reinforcement Learning (STPD-RL) framework. STPD-RL optimizes critical network operations such as transmission link selection and power allocation, directly contributing to improved energy efficiency and robust network performance. Initially, we have refined the potential driven experience replay and implemented it into resource allocation in UAV-assisted UDN for the inaugural time. By assigning a potential energy function to each state in experience replay, users can employ intrinsic state supervision to learn from a spectrum of good and bad experiences. Subsequently, we have employed stabilizing transformers to hasten the learning trajectory for resource allocation policies, thereby enhancing the stability of model training. Furthermore, we have integrated potential driven experience replay and stabilizing transformers within the Proximal Policy Optimization algorithm, thus formulating our uniquely tailored STPD-PPO. In simulations with many users and base stations, STPD-PPO outperformed traditional PPO in metrics such as entropy loss, policy loss, and value loss. Results suggest that our STPD-PPO surpasses traditional DRL algorithms in several respects, including convergence rate, energy efficiency, total power consumption, and exploration capacity.},
  archive      = {J_ISCI},
  author       = {Pei-Gen Ye and Jun Zheng and Xiaojun Ren and Jinbin Huang and Zhenxin Zhang and Yan Pang and Guang Kou},
  doi          = {10.1016/j.ins.2024.120788},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120788},
  shortjournal = {Inf. Sci.},
  title        = {Optimizing resource allocation in UAV-assisted ultra-dense networks for enhanced performance and security},
  volume       = {679},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HCEG: A heterogeneous clustering ensemble learning approach
with gravity-based strategy for data assets intelligent pricing.
<em>ISCI</em>, <em>678</em>, 121082. (<a
href="https://doi.org/10.1016/j.ins.2024.121082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data pricing plays a pivotal role in fostering the growth of data markets, enhancing the efficiency of data utilization, and realizing the full potential of data value. Nevertheless, the intricate nature and specificity of data assets render accurate pricing a formidable challenge. To tackle this challenge, we adopt the “divide and conquer” approach and introduce a heterogeneous ensemble pricing model grounded in clustering strategies to enhance the precision of data asset pricing. Initially, our study generates 15 diverse pricing models as potential candidates, leveraging clustering strategies to achieve an adaptive aggregation of data assets. Notably, we introduce an innovative weight generation strategy based on the concept of universal gravitational force to integrate the pricing results. To validate the effectiveness of our Heterogeneous Clustering Ensemble Gravity-based pricing model (HCEG), we conduct computational experiments on transaction platform data assets. The results unequivocally demonstrate the superiority of the proposed HCEG pricing model in data asset pricing. Furthermore, our study delves deeper into the impact of clustering centers, feature selection, and integration strategies on the performance of the pricing model. This comprehensive analysis provides valuable insights for optimizing and enhancing the precision of data asset pricing.},
  archive      = {J_ISCI},
  author       = {Jun Hao and Jiaxin Yuan and Jianping Li},
  doi          = {10.1016/j.ins.2024.121082},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121082},
  shortjournal = {Inf. Sci.},
  title        = {HCEG: A heterogeneous clustering ensemble learning approach with gravity-based strategy for data assets intelligent pricing},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MCG-SLAM: Tightly coupled SLAM for multi-factor constraint
graph optimisation. <em>ISCI</em>, <em>678</em>, 121075. (<a
href="https://doi.org/10.1016/j.ins.2024.121075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous localization and mapping (SLAM) technology is a core component for achieving high-precision vehicle localization and navigation in the field of autonomous driving. Existing light detection and ranging (LiDAR) SLAM methods typically neglect intersensory constraints when estimating poses based on sensor observations, resulting in reduced accuracy in multi-sensor fusion scenarios. To address this, a tightly coupled SLAM method with multi-factor constraint graph optimisation, referred to as MCG-SLAM, is proposed. The initial odometry information obtained from the extended Kalman filter is used to optimise the state nodes in the multi-factor constraint graph. This is achieved by dynamically adjusting the noise covariance of the odometry factors, global positioning system factors, and loop closure factors, optimising the factor nodes within the multi-factor constraint graph, and continuously updating the multi-factor constraint graph to complete pose optimisation. Furthermore, a loop closure detection method based on the intensity and geometric information of the point cloud is introduced to identify loop closures and incorporate loop closure factors. In this paper, the MCG-SLAM method is comprehensively validated against mainstream LiDAR SLAM methods using the MulRan dataset. The results show that MCG-SLAM outperforms other methods by improving LiDAR SLAM accuracy in localization and mapping.},
  archive      = {J_ISCI},
  author       = {Qifeng Wang and Weigang Li and Lei Nie and Zhiqiang Tian and Yang Li},
  doi          = {10.1016/j.ins.2024.121075},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121075},
  shortjournal = {Inf. Sci.},
  title        = {MCG-SLAM: Tightly coupled SLAM for multi-factor constraint graph optimisation},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel cost-sensitive quality determination framework in
hot rolling steel industry. <em>ISCI</em>, <em>678</em>, 121054. (<a
href="https://doi.org/10.1016/j.ins.2024.121054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the hot rolling industry, a high-precision quality determination framework is the guarantee for intelligent decision-making regarding products. Conventional methods ignore the significance of faulty products, which are assigned the same attention as the qualified products. To overcome these limitations, this paper proposes a novel compensated cost-sensitive multi-layer perceptron with minority attention (CCS-MLP-MIAT) to construct a high-precision quality determination framework. We first transform an imbalanced multi-class ordinal industrial problem into multiple imbalanced binary ordinal classifications using one-versus-one (OVO) decomposition. Then, we implement a minority attention mechanism and a cost-sensitive loss for MLP. Subsequently, a novel cost compensation coefficient is introduced and determined by Artificial Hummingbird Algorithm (AHA) to further improve the identification rate of faulty products. The advantage lies in the model to allocate more attention to the faulty products, thus promoting intelligent decision-making of hot rolling production. The proposed method is validated on eight UCI benchmark datasets and two real-cases of hot-rolled strip crown by cross validation. Experimental results demonstrate that the excellent generalization and robustness of CCS-MLP-MIAT in addressing the quality determination of hot-rolled steel.},
  archive      = {J_ISCI},
  author       = {Cheng-Yan Ding and Jun-Cheng Ye and Long-Jun Wang and Jun-Xiang Cai and Wen Peng and Jie Sun and Dian-Hua Zhang},
  doi          = {10.1016/j.ins.2024.121054},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121054},
  shortjournal = {Inf. Sci.},
  title        = {A novel cost-sensitive quality determination framework in hot rolling steel industry},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bimodal deep learning model for subjectively enhanced
emotion classification in films. <em>ISCI</em>, <em>678</em>, 121049.
(<a href="https://doi.org/10.1016/j.ins.2024.121049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research delves into the concept of color grading in film, focusing on how color influences the emotional response of the audience. The study commenced by recalling state-of-the-art works that process audio–video signals and associated emotions by machine learning. Then, assumptions of subjective tests for refining and validating an emotion model for assigning specific emotional labels to selected film excerpts were presented. The insights gained from these subjective evaluations facilitated the creation of a comprehensive database of movie excerpts. This database was subsequently employed to both train and evaluate the efficacy of deep learning models. The latter half of the study shifts focus to the intelligent analysis of audio and video signals that form film excerpts. This involved exploring diverse methodologies for parameterizing these signals. Models that demonstrated the highest accuracy on the test dataset on audio/video only were amalgamated to forge a bimodal model, which integrates both audio and video signals for emotion classification. The bimodal model exhibited superior accuracy in tests compared to a model that solely relied on video signal classification. This enhancement in performance was achieved with only a marginal increase in the complexity and the number of parameters within the model.},
  archive      = {J_ISCI},
  author       = {Dawid Weber and Bozena Kostek},
  doi          = {10.1016/j.ins.2024.121049},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121049},
  shortjournal = {Inf. Sci.},
  title        = {Bimodal deep learning model for subjectively enhanced emotion classification in films},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A pacesetter-lévy multi-objective particle swarm
optimization with arnold chaotic map with opposition-based learning.
<em>ISCI</em>, <em>678</em>, 121048. (<a
href="https://doi.org/10.1016/j.ins.2024.121048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To accelerate the convergence of multi-objective optimization algorithm and achieve an optimization solution set with good diversity, this paper proposes the Pacesetter-Lévy Multi-Objective Particle Swarm Optimization using Arnold Chaotic Map with Opposition-Based Learning algorithm (PLMOPSOCO). Firstly, the Arnold Chaotic Map with Opposition-based Learning is proposed to generate some valuable particles in the stage of initialization while maintaining the diversity of population, which can speed up exploration. Secondly, a competition mechanism with k-means clustering is integrated to categorize particles into losers and winners. The flight direction of the loser particles is adjusted according to the Pacesetter-Lévy kinetic equation, an innovative approach to effectively enhance the population’s exploitative ability. Thirdly, a crossover mutation is implemented to assist particles to escape local optima and prevent population stagnation. Comparative studies on benchmark functions demonstrate that this new algorithm is more competitive in terms of both diversity and convergence when compared to several advanced multi-objective algorithms.},
  archive      = {J_ISCI},
  author       = {LanLan Kang and Yu Lai and Jia Wang and WenLiang Cao},
  doi          = {10.1016/j.ins.2024.121048},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121048},
  shortjournal = {Inf. Sci.},
  title        = {A pacesetter-lévy multi-objective particle swarm optimization with arnold chaotic map with opposition-based learning},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prompt2Rec: Prompt based user and item re-characterizing
method for recommendation. <em>ISCI</em>, <em>678</em>, 121046. (<a
href="https://doi.org/10.1016/j.ins.2024.121046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative Filtering (CF), which utilizes user-item interaction data is widely adopted in Recommendation System; however, CF encounters challenges such as the cold-start problem and data sparsity. To address this issue, research incorporating Natural Language Processing (NLP) has made progress in leveraging review texts that contain rich information about user preferences and item attributes. Nevertheless, the conventional approach of integrating the entire review text and using it as an input, which has been widely used in previous research, can be vulnerable to noise (i.e., data with little relevance to user preferences or item attributes). In this study, we propose a novel user and item re-characterizing method called Prompt2Rec, which introduces the Prompt-based learning paradigm of NLP. It generates key factors that newly defined essential user and item characteristics from review texts and uses them as new information to train the recommendation model. We validate our proposed method through experiments on five benchmark datasets. The results show that Prompt2Rec leads to improved performance compared to existing methods that rely on review texts. Furthermore, we explore the potential to provide explanations for recommendations by visualizing the model&#39;s attention weights on the key factors.},
  archive      = {J_ISCI},
  author       = {Seonjin Hwang and Younghoon Lee},
  doi          = {10.1016/j.ins.2024.121046},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121046},
  shortjournal = {Inf. Sci.},
  title        = {Prompt2Rec: Prompt based user and item re-characterizing method for recommendation},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). A performance indicator-based evolutionary algorithm for
expensive high-dimensional multi-/many-objective optimization.
<em>ISCI</em>, <em>678</em>, 121045. (<a
href="https://doi.org/10.1016/j.ins.2024.121045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted multi-objective evolutionary algorithms have shown considerable potential for solving optimization problems in which only a small number of expensive function evaluations are available. However, most existing research remains restricted to low-/medium-dimensional problems, with very little attention paid to addressing problems involving decision variables with more than 100 dimensions. In this study, a performance indicator-based evolutionary algorithm (PIEA) is proposed for expensive high-dimensional multi-/many-objective optimization. A surrogate model is employed to approximate the performance indicator rather than directly predicting the objective function, thus simplifying the optimization complexity and mitigating the impact of cumulative errors. An efficient indicator-based optimization strategy emphasising the balance between exploration and exploitation is designed for surrogate-assisted evolution and infill sampling. A history-based selection strategy is implemented to select a suitable indicator from the preset pool for each optimization cycle. An empirical study was conducted on two well-known benchmark suites, and the results demonstrate the superiority of the proposed algorithm over several state-of-the-art algorithms. Moreover, we integrate this concept into a classification-based framework, which further verifies its effectiveness.},
  archive      = {J_ISCI},
  author       = {Yang Li and Weigang Li and Songtao Li and Yuntao Zhao},
  doi          = {10.1016/j.ins.2024.121045},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121045},
  shortjournal = {Inf. Sci.},
  title        = {A performance indicator-based evolutionary algorithm for expensive high-dimensional multi-/many-objective optimization},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving small sample prediction performance via novel
nonlinear interpolation virtual sample generation with self-supervised
learning. <em>ISCI</em>, <em>678</em>, 121044. (<a
href="https://doi.org/10.1016/j.ins.2024.121044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the early stages of production processes, due to expensive experimental costs and demanding experimental conditions, the amounts of collected samples are relatively limited. Information and knowledge extracted from minimal experimental data may be distorted and unreliable. Tackling this task, some researchers have recommended virtual sample generation (VSG), aiming at improving prediction accuracy of forecasting models for small sample sets by creating informative artificial samples. To more effectively capture nonlinear feature representations in small data, in this paper, we propose a promising VSG method based on self-supervised learning architecture to generate optimal, feasible virtual samples. The suggested technology considers distilling nonlinear feature representations using a manifold algorithm. Based on these representations, we integrated Newton’s divided difference and Chebyshev interpolation to create nonlinear interpolation points. We feed those interpolation points into a U-net model and an encoder-decoder net model to produce virtual sample inputs and output, respectively. Additionally, in this paper, we developed a Siamese network model to select virtual samples resembling original data. In the experiments, two industrial datasets were utilized to demonstrate efficacy of the proposed method. These experimental results show that the proposed method can more successfully boost prediction accuracy compared to the other three cutting-edge VSG methods.},
  archive      = {J_ISCI},
  author       = {Liang-Sian Lin},
  doi          = {10.1016/j.ins.2024.121044},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121044},
  shortjournal = {Inf. Sci.},
  title        = {Improving small sample prediction performance via novel nonlinear interpolation virtual sample generation with self-supervised learning},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging the hierarchical symmetric 2-additive choquet
integral: Enhancing explainability and parallelizability in predictive
models. <em>ISCI</em>, <em>678</em>, 121031. (<a
href="https://doi.org/10.1016/j.ins.2024.121031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for transparent and efficient predictive models has grown significantly in the era of big data and complex decision-making. Explainable artificial intelligence (XAI) has emerged as a crucial field to address the “black box” nature of many state-of-the-art models, particularly in domains such as healthcare, where understanding the reasoning behind predictions is essential. However, a key challenge lies in developing models that balance explainability and accuracy while also being computationally efficient. This research introduces a pioneering algorithm that leverages the hierarchical symmetric 2-additive Choquet integral to enhance interpretability and parallelizability in predictive modeling, thereby addressing this critical research gap. Empirical evaluations on diverse datasets, both simulated and real, demonstrate that our algorithm outperforms traditional models in prediction accuracy. This advancement underscores the potential of our algorithm to serve as a versatile tool in the field of XAI, where clarity in the decision-making process is paramount. Our work thus presents a significant stride in developing algorithms that are not only accurate but also intuitively understandable, catering to the increasing demand for transparency in artificial intelligence applications.},
  archive      = {J_ISCI},
  author       = {Jih-Jeng Huang and Chin-Yi Chen},
  doi          = {10.1016/j.ins.2024.121031},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121031},
  shortjournal = {Inf. Sci.},
  title        = {Leveraging the hierarchical symmetric 2-additive choquet integral: Enhancing explainability and parallelizability in predictive models},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Communication-efficient federated learning via personalized
filter pruning. <em>ISCI</em>, <em>678</em>, 121030. (<a
href="https://doi.org/10.1016/j.ins.2024.121030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularity of mobile devices and the continuous growth of interactive data, FL (Federated Learning) has gradually become an effective mean to address the problems of privacy leakage and data silos. However, due to the heterogeneity and imbalance of participants, FL faces many challenges, including model accuracy, security, heterogeneous devices and data, privacy preservation, as well as communication overhead and efficiency. To address challenges such as high communication overhead and low model accuracy in FL, we innovatively introduce model pruning into the FL framework and propose a personalized filter pruning-based FL method named PF 2 Learning (Personalized Filter Pruning Federal Learning). This method achieves reasonable filter pruning for all local models by performing personalized pruning on each local model. Specifically, on the device side, we use a pruning strategy based on the norm geometric median, which also considers the order dependence between adjacent layers and evaluates the contribution of filters involved in pruning to optimize the pruning for local models at a unified pruning rate. On the server side, we calculate the unified pruning ratio of the model based on the contribution of participants&#39; model filters and training errors to maintain the consistency of the participants&#39; model structures. To validate the effectiveness of our proposed method, we conducted federated image classification tasks on ResNet-18, VGG-11, DenseNet-121, and InceptionNet-V1 models using CIFAR-10, FEMNIST, and ImageNet datasets. The experimental results show that PF 2 Learning outperforms most FL pruning methods and exhibits better model performance and accuracy.},
  archive      = {J_ISCI},
  author       = {Qi Min and Fei Luo and Wenbo Dong and Chunhua Gu and Weichao Ding},
  doi          = {10.1016/j.ins.2024.121030},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121030},
  shortjournal = {Inf. Sci.},
  title        = {Communication-efficient federated learning via personalized filter pruning},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards episode rules with non-overlapping frequency and
targeted mining. <em>ISCI</em>, <em>678</em>, 121028. (<a
href="https://doi.org/10.1016/j.ins.2024.121028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data mining has become a popular task due to the explosion of rich data. Frequent episode mining (FEM) is an effective technique for extracting valuable and crucial information from event sequences, playing a significant role in various fields such as market basket analysis, association analysis, and management sciences. A variety of FEM algorithms discover frequent episode rules using the frequency function and anti-monotony. Non-overlapping frequency works well for mining episode rules because it cuts down on unnecessary computations and still follows anti-monotonicity. Leveraging this technique, we propose the NONEPI+ algorithm for discovering rules that were previously overlooked. However, there are no algorithms that can be used to discover episode rules that contain target query rules. To fill the research gap in episode rule mining algorithms, we further propose a novel algorithm called TaER for targeted mining of episode rules, i.e., a set of rules containing specific query rules. TaER can successfully discover the episode rules that the users are more specifically interested in. It can provide direction for prediction tasks in many aspects, such as weather observation, network intrusion, e-commerce, and financial behavior prediction. All source code and datasets are available on GitHub https://github.com/DSI-Lab1/TaER .},
  archive      = {J_ISCI},
  author       = {Zefeng Chen and Wensheng Gan},
  doi          = {10.1016/j.ins.2024.121028},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121028},
  shortjournal = {Inf. Sci.},
  title        = {Towards episode rules with non-overlapping frequency and targeted mining},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized multikernel correntropy based broad learning
system for robust regression. <em>ISCI</em>, <em>678</em>, 121026. (<a
href="https://doi.org/10.1016/j.ins.2024.121026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging learning method belonging to the family of neural networks, the broad learning system (BLS) has been recently proved to be effective and efficient to perform regression tasks in various scenarios. However, if data are contaminated by some outliers or other more complex non-Gaussian noises, the learning performance of BLS may be severely compromised, due to its dependence on the conventional mean square error criterion. To enhance the robustness of BLS to deal with contaminated data, a new similarity measure termed generalized multikernel correntropy (GMKC) is proposed in this paper, and some important properties of this measure are investigated. On the basis of GMKC, a general BLS variant called GMKC-based BLS (GMKC-BLS), is subsequently developed to perform regression tasks with contaminated data. Since GMKC with its unique design actually builds a unified framework for many robust and popular metrics, GMKC-BLS is expected to be with excellent robustness and adaptability, and provides a competitive solution to the regression problems with contaminated data. Meanwhile, GMKC could be integrated with other neural network-based methods to further enhance their robustness. Experimental results on different regression datasets demonstrate the performance superiority of GMKC-BLS compared to the standard BLS and its robust variants.},
  archive      = {J_ISCI},
  author       = {Yunfei Zheng and Shiyuan Wang and Badong Chen},
  doi          = {10.1016/j.ins.2024.121026},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121026},
  shortjournal = {Inf. Sci.},
  title        = {Generalized multikernel correntropy based broad learning system for robust regression},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-agent cooperative area coverage: A two-stage planning
approach based on reinforcement learning. <em>ISCI</em>, <em>678</em>,
121025. (<a href="https://doi.org/10.1016/j.ins.2024.121025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent area coverage aims to accomplish the complete traversal of the target area through cooperation between agents. Focusing on the problems of low coverage efficiency and weak practicability in the existing methods, we propose a two-stage area coverage method based on multi-agent deep reinforcement learning. In the first stage, we convert the coverage path planning problem into an optimal grid selection problem, and according to the equivalence of agents in cooperative tasks, we propose a distributed coverage path planning algorithm based on QMIX and a grid coverage map. The second stage is to realize the cooperative navigation control in a constrained environment with obstacles and non-ideal communication conditions. To implement the stage, we design a hybrid attention mechanism to adaptively aggregate important feature information of adjacent agents and obstacles, which efficiently exploits the limited local perception and communication capabilities of agents to perform cooperative control. The experimental results show that the proposed two-stage multi-agent area coverage method can accomplish the area coverage task in the environment with random obstacles, and the area coverage efficiency and robustness are significantly better than other reinforcement learning based or traditional coverage algorithms. In addition, the results also verify that the proposed method has the advantage of adapting to the dynamic changes in the number of agents and the communication range.},
  archive      = {J_ISCI},
  author       = {Guohui Yuan and Jian Xiao and Jinhui He and Honyu Jia and Yaoting Wang and Zhuoran Wang},
  doi          = {10.1016/j.ins.2024.121025},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121025},
  shortjournal = {Inf. Sci.},
  title        = {Multi-agent cooperative area coverage: A two-stage planning approach based on reinforcement learning},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy preservation-based federated learning with uncertain
data. <em>ISCI</em>, <em>678</em>, 121024. (<a
href="https://doi.org/10.1016/j.ins.2024.121024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) belongs to distributed machine learning. It allows data information sharing between users while protecting their data privacy at the same time. However, in many real-world scenarios, the data collected by client devices may be affected by noise in the working environment, leading to the decreased accuracy and confidence. Therefore, it is necessary to take measures to reduce data uncertainty in order to enhance the performance of FL algorithms. Traditional FL methods encounter challenges in handling uncertain data, which motivates the introduction of multi-view learning in this paper which designs an FL model suitable for highly variable data characteristics. We first achieve information complementarity among data views while ensuring the consistency in data representation. Furthermore, we quantify data uncertainty using the reachable region of data noise, thereby improving model robustness. To maintain data privacy between clients, we design an adaptive Kalman filter-based differential protection security protocol. Clients use the protocol to process local data and upload it to the master server, which returns the updated model parameters to the clients. The experimental results demonstrate the effectiveness of the federated learning model proposed in this paper.},
  archive      = {J_ISCI},
  author       = {Fan Cao and Bo Liu and Jinghui He and Jian Xu and Yanshan Xiao},
  doi          = {10.1016/j.ins.2024.121024},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121024},
  shortjournal = {Inf. Sci.},
  title        = {Privacy preservation-based federated learning with uncertain data},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale graph clustering network. <em>ISCI</em>,
<em>678</em>, 121023. (<a
href="https://doi.org/10.1016/j.ins.2024.121023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep graph clustering, a fundamental yet formidable task in data analysis, aims to partition samples belonging to the same category into their respective clusters. Recently, significant advancements in graph self-supervised learning have been made through generative and contrastive learning methods. However, existing methods focus on directly aggregating neighboring node information during the feature extraction stage, thereby neglecting the crucial long-range correlations between nodes. Consequently, non-neighbor node information within the same category remains unexplored, leading to subpar performance in the clustering task. To address this issue, we propose a generative method named Multi-scale Graph Clustering Network (MGCN) to learn comprehensive and rich graph representations for deep graph clustering in the feature encoding stage. Specifically, we design a Multi-hop Adaptive Convolutional Module (MACM) integrated into MGCN, which effectively aggregates high-order neighbor node features in each layer of the network. Additionally, we develop an autoencoder to assist MACM in enhancing attribute information, which prevents the node&#39;s own features from being overshadowed in the multi-scale feature learning process. Experimental results demonstrate that our proposed MGCN method achieves significantly better clustering performance than existing methods on multiple public datasets.},
  archive      = {J_ISCI},
  author       = {Xiulai Li and Wei Wu and Bin Zhang and Xin Peng},
  doi          = {10.1016/j.ins.2024.121023},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121023},
  shortjournal = {Inf. Sci.},
  title        = {Multi-scale graph clustering network},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantum model regression for generating fuzzy numbers in
adiabatic quantum computing. <em>ISCI</em>, <em>678</em>, 121018. (<a
href="https://doi.org/10.1016/j.ins.2024.121018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of inherent fuzziness in real-world data, arising from uncertainties, complexities, and limitations of traditional statistical methods. We introduce a pioneering method leveraging Adiabatic Quantum Computing (AQC), based on an adiabatic quantum regression model, to generate fuzzy numbers—ideal tools owing to their extension of real numbers and robust arithmetic properties. This innovative approach overcomes challenges in Quantum Machine Learning (QML) and limitations of Noisy Intermediate-Scale Quantum (NISQ) computers, providing a solution superior to conventional statistical methods and addressing the crucial issue of exponential power increase. Unique to this work, we offer rare closed-form expressions to produce fuzzy numbers through AQC and emphasise the integration of random variables and fuzzy numbers to encapsulate uncertainty fully. We propose a novel transformation of the Cumulative Distribution Function (CDF) into triangular and trapezoidal fuzzy numbers using AQC, enabling a comprehensive description of probability distributions of random variables. Experimental results are detailed, demonstrating the significant applicability and breakthroughs of this research in addressing data fuzziness.},
  archive      = {J_ISCI},
  author       = {Kushal Anjaria},
  doi          = {10.1016/j.ins.2024.121018},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121018},
  shortjournal = {Inf. Sci.},
  title        = {Quantum model regression for generating fuzzy numbers in adiabatic quantum computing},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting anomalies with granular-ball fuzzy rough sets.
<em>ISCI</em>, <em>678</em>, 121016. (<a
href="https://doi.org/10.1016/j.ins.2024.121016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the existing anomaly detection methods are based on a single and fine granularity input pattern, which is susceptible to noisy data and inefficient for detecting anomalies. Granular-ball computing, as a novel multi-granularity representation and computation method, can effectively compensate for these shortcomings. We utilize the fuzzy rough sets to mine the potential uncertainty information in the data efficiently. The combination of granular-ball computing and fuzzy rough sets takes into account the benefits of both methods, providing great application and research value. However, this novel combination still needs to be explored, especially for unsupervised anomaly detection. In this study, we first propose the granular-ball fuzzy rough set model, and the relevant definitions in the model are given. Subsequently, we pioneeringly present an unsupervised anomaly detection method based on granular-ball fuzzy rough sets called granular-ball fuzzy rough sets-based anomaly detection (GBFRD). Our method introduces the granular-ball fuzzy rough granules-based outlier factor to characterize the outlier degree of an object effectively. The experimental results demonstrate that GBFRD exhibits superior performance compared to the state-of-the-art methods. The code is publicly available at https://github.com/Mxeron/GBFRD .},
  archive      = {J_ISCI},
  author       = {Xinyu Su and Zhong Yuan and Baiyang Chen and Dezhong Peng and Hongmei Chen and Yingke Chen},
  doi          = {10.1016/j.ins.2024.121016},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121016},
  shortjournal = {Inf. Sci.},
  title        = {Detecting anomalies with granular-ball fuzzy rough sets},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A retinal vessel segmentation network approach based on
rough sets and attention fusion module. <em>ISCI</em>, <em>678</em>,
121015. (<a href="https://doi.org/10.1016/j.ins.2024.121015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The morphological changes of retinal vessels are of significant diagnostic value for early ophthalmic diseases and can aid in distinguishing other conditions such as diabetes and cardiovascular diseases. However, precise segmentation poses a challenge due to the complex structure of retinal vessels. To address these issues, we propose a Rough Attention Fusion Module (RAFM). This module employs max-pooling and average-pooling to define the upper and lower bounds of feature significance, introducing upper and lower weight matrices to obtain more reasonable attention coefficients. This enables the model to more accurately focus on important features in retinal images. Additionally, we integrate the RAFM into the GTS U-Net model, a simplified version of the GT U-Net model, which enhances the segmentation accuracy while reducing computational complexity. Ultimately, we construct a retinal vessel segmentation network based on the RAFM along with Group Transformer. Finally, the network structure is tested on the public DRIVE color fundus image dataset, achieving an Accuracy, F1 score, and AUC of 0.9641, 0.8506, and 0.9820, respectively. In contrast to prevalent retinal vessel segmentation networks in the mainstream, our proposed network demonstrates certain strengths.},
  archive      = {J_ISCI},
  author       = {Ziqiang Gao and Linlin Zhou and Weiping Ding and Haipeng Wang},
  doi          = {10.1016/j.ins.2024.121015},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121015},
  shortjournal = {Inf. Sci.},
  title        = {A retinal vessel segmentation network approach based on rough sets and attention fusion module},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Outranking-based approaches for multiple criteria partially
ordered clustering: A review of existing algorithms, new proposals, and
experimental comparison. <em>ISCI</em>, <em>678</em>, 121014. (<a
href="https://doi.org/10.1016/j.ins.2024.121014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider clustering problems that involve categorizing alternatives into partially ordered, initially undefined groups based on their performance across multiple criteria. To achieve this, we use an outranking relation model to reflect the Decision Maker&#39;s preferences. We examine various algorithms that not only group the alternatives but also order the clusters in different ways. This analysis includes innovative approaches that use distances in the space of outranking relations or detailed relation profiles, and apply orthogonal non-negative factorization to outranking matrices. Additionally, we discuss a set of measures, including two novel ones, for assessing the effectiveness of clustering when the groupings are partially ordered. Our findings are based on comprehensive computational experiments on real-world and simulated datasets. Beyond evaluating various methods using four quality metrics and computational efficiency, we explore the influence of accessible preference structures and ordering techniques on the clustering outcomes.},
  archive      = {J_ISCI},
  author       = {Dariusz Grynia and Klaudia Dobrogojska and Miłosz Kadziński},
  doi          = {10.1016/j.ins.2024.121014},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121014},
  shortjournal = {Inf. Sci.},
  title        = {Outranking-based approaches for multiple criteria partially ordered clustering: A review of existing algorithms, new proposals, and experimental comparison},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving query efficiency of black-box attacks via the
preference of deep learning models. <em>ISCI</em>, <em>678</em>, 121013.
(<a href="https://doi.org/10.1016/j.ins.2024.121013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Black-box query attacks are effective at compromising deep-learning models using only the model&#39;s output. These attacks typically face challenges with low attack success rates (ASRs) when limited to fewer than ten queries per example. Recent approaches have improved ASRs due to the transferability of initial perturbations, yet they still suffer from inefficient querying. Our study introduces the Gradient-Aligned Attack (GAA) to enhance ASRs with minimal perturbation by focusing on the model&#39;s preference. We define a preference property where the generated adversarial example prefers to be misclassified as the wrong category with a high initial confidence. This property is further elucidated by the gradient preference, suggesting a positive correlation between the magnitude of a coefficient in a partial derivative and the norm of the derivative itself. Utilizing this, we devise the gradient-aligned CE (GACE) loss to precisely estimate gradients by aligning these coefficients between the surrogate and victim models, with coefficients assessed by the victim model&#39;s outputs. GAA, based on the GACE loss, also aims to achieve the smallest perturbation. Our tests on ImageNet, CIFAR10, and Imagga API show that GAA can increase ASRs by 25.7% and 40.3% for untargeted and targeted attacks respectively, while only needing minimally disruptive perturbations. Furthermore, the GACE loss reduces the number of necessary queries by up to 2.5x and enhances the transferability of advanced attacks by up to 14.2%, especially when using an ensemble surrogate model. Code is available at https://github.com/HaloMoto/GradientAlignedAttack .},
  archive      = {J_ISCI},
  author       = {Xiangyuan Yang and Jie Lin and Hanlin Zhang and Peng Zhao},
  doi          = {10.1016/j.ins.2024.121013},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121013},
  shortjournal = {Inf. Sci.},
  title        = {Improving query efficiency of black-box attacks via the preference of deep learning models},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Active learning-based isolation forest (ALIF): Enhancing
anomaly detection with expert feedback. <em>ISCI</em>, <em>678</em>,
121012. (<a href="https://doi.org/10.1016/j.ins.2024.121012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of anomalous behaviours is an emerging need in many applications, particularly in contexts where security and reliability are critical. The definition of anomaly varies depending on the domain; however, it is often impractical or too time consuming to obtain a fully labelled dataset. The use of unsupervised models to overcome the lack of labels often fails to catch domain-specific anomalies as they rely on general definitions of outliers. This paper suggests a novel approach to address this problem, Active Learning-based Isolation Forest (ALIF), reducing the number of required labels and tuning the detector to the definition of anomaly provided by the user. The proposed approach is particularly appealing in scenarios where users can interact and provide feedback to the anomaly detector. Smart monitoring software embedded with anomaly detection capabilities commonly relies on unsupervised models, lacking a way to adjust its prediction: ALIF is able to enhance the capabilities of such systems by exploiting user feedback during common operations. ALIF is a lightweight modification of the popular Isolation Forest that proved superior performance compared to other state-of-the-art algorithms in a multitude of real anomaly detection datasets.},
  archive      = {J_ISCI},
  author       = {Elisa Marcelli and Tommaso Barbariol and Davide Sartor and Gian Antonio Susto},
  doi          = {10.1016/j.ins.2024.121012},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121012},
  shortjournal = {Inf. Sci.},
  title        = {Active learning-based isolation forest (ALIF): Enhancing anomaly detection with expert feedback},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-level balancing multi-objective algorithm for
trapezoidal type-2 fuzzy flexible job shop problems. <em>ISCI</em>,
<em>678</em>, 121011. (<a
href="https://doi.org/10.1016/j.ins.2024.121011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty remains a critical issue in realistic applications in many fields. However, there is little literature considering trapezoidal interval type-2 fuzzy set (TIT2FS) in scheduling problems. To fill this gap, we propose a two-level balancing multi-objective optimization algorithm for a distributed flexible job shop scheduling problem (DFJSP), wherein two typical constraints are considered: the TIT2FS processing time and the transportation resource limitation. Two objectives are to be minimized: the TIT2FS fuzzy makespan and energy consumption. A two-level evolution mechanism is employed. The first level comprises two populations to optimize the two respective objectives, while the second level is composed of two populations to perform the convergence and diversity balancing tasks. Next, an efficient problem-specific initialization method with several heuristics is presented. Subsequently, different types of mutation and crossover operators are proposed under the consideration of problem knowledge. To further improve the performance of exploration and exploitation abilities, we present a balancing enhanced local search method. Finally, we performed detailed comparisons with four efficient algorithms. The results show that the two-level optimization algorithm was efficient in both convergence and diversity abilities, indicating that our algorithm can efficiently achieve a balance between these abilities.},
  archive      = {J_ISCI},
  author       = {Junqing Li and Jiake Li and Kaizhou Gao and Peiyong Duan},
  doi          = {10.1016/j.ins.2024.121011},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121011},
  shortjournal = {Inf. Sci.},
  title        = {Two-level balancing multi-objective algorithm for trapezoidal type-2 fuzzy flexible job shop problems},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Efficient byzantine-robust distributed inference with
regularization: A trade-off between compression and adversary.
<em>ISCI</em>, <em>678</em>, 121010. (<a
href="https://doi.org/10.1016/j.ins.2024.121010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large-scale distributed learning, the direct application of traditional inference is often not feasible, because it may contain multiple themes, such as communication costs, privacy issues, and Byzantine failures. Nowadays, the internet is vulnerable to attacks, and Byzantine failures frequently occur. For copying with Byzantine failures, the paper develops two Byzantine-robust distributed learning algorithms under a framework of communication-efficient surrogate likelihood. In our algorithms, we adopt the δ -approximate compressors, including sign-based operator and top k sparsification, to improve communication efficiency, and an unsophisticated thresholding of local gradient norms to guard against Byzantine failures. For accelerating convergence and achieving an optimal statistical error rate, error feedback is exploited in the second algorithm. The two algorithms are robust to arbitrary adversaries, although Byzantine workers don&#39;t adhere to the mandated compression mechanism. We explicitly establish statistical error rates, which imply that our algorithms don&#39;t sacrifice the quality of learning, and attain the order-optimal under some settings. In addition, we provide a trade-off between compression and adversary in the presence of Byzantine worker machines. Extensive numerical experiments validate our theoretical results and demonstrate a good performance of our algorithms.},
  archive      = {J_ISCI},
  author       = {Xingcai Zhou and Guang Yang and Le Chang and Shaogao Lv},
  doi          = {10.1016/j.ins.2024.121010},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121010},
  shortjournal = {Inf. Sci.},
  title        = {Efficient byzantine-robust distributed inference with regularization: A trade-off between compression and adversary},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Niche center identification differential evolution for
multimodal optimization problems. <em>ISCI</em>, <em>678</em>, 121009.
(<a href="https://doi.org/10.1016/j.ins.2024.121009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Niching techniques are commonly incorporated into evolutionary computation (EC) algorithms to address multimodal optimization problems (MMOPs). Nevertheless, identifying proper individuals as niche centers remains the main challenge in niching techniques. Generally, niche centers should possess promising fitness (fitness aspect) and should be dispersedly distributed in different search regions (distance aspect). In this study, we propose a novel niching technique known as niche center identification (NCI) and integrate it with differential evolution (DE) for tackling MMOPs, termed NCIDE. In NCI, niche centers are first identified from both the fitness and distance aspects. Individuals that are not niche centers are added to their nearest niche centers to form niches. Moreover, we develop a niche-level archival-adaptive parameter scheme (NAAPS) to adaptively adjust the parameters at the niche level and reduce their sensitivity. Meanwhile, with the help of an archive, we can preserve the identified optima and reinitialize stagnant individuals for further exploration. The experimental results on the CEC2013 multimodal benchmark test suite demonstrate that NCIDE significantly outperforms several state-of-the-art multimodal algorithms, including multiple competition winners from CEC2015 and GECCO2017-GECCO2019. Finally, NCIDE is applied to solve multimodal nonlinear equation system (NES) problems to further illustrate its practical applicability.},
  archive      = {J_ISCI},
  author       = {Shao-Min Liang and Zi-Jia Wang and Yi-Biao Huang and Zhi-Hui Zhan and Sam Kwong and Jun Zhang},
  doi          = {10.1016/j.ins.2024.121009},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121009},
  shortjournal = {Inf. Sci.},
  title        = {Niche center identification differential evolution for multimodal optimization problems},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lipschitz energy functional for anisotropic diffusion
applications. <em>ISCI</em>, <em>678</em>, 121008. (<a
href="https://doi.org/10.1016/j.ins.2024.121008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image denoising remains a key research problem because of its potential role as a pre-processing component in image processing, computer vision, and machine learning tasks. Of the available approaches for image denoising, those inspired by anisotropic diffusion processes have been a center of discussion for decades. Despite the efforts and promising results achieved by diffusion-inspired denoising methods, we noted insufficient attention on the design of energy functionals for anisotropic diffusion equations. Most researchers consider heuristic approaches to design diffusivity functionals, a practice that cannot provide mathematical explanations on why their approaches work. The current research presents a strictly convex and Lipschitz energy functional that guarantees a unique solution for an evolutionary process. Based on this functional, we derive an anisotropic diffusion equation for image denoising applications. Experimental results show that an algorithm corresponding to the proposed equation is computationally efficient, and generates informative and visually appealing images with competitive values of peak signal-to-noise ratio and structural similarity. Guided by the compelling properties of our energy functional, we provide an additional insight to describe quality of the results. Implementation codes and test datasets of the proposed approach are publicly accessible at the MATLAB File Exchange ( https://www.mathworks.com/matlabcentral/fileexchange/160108-lipschitz-diffusion-inspired-energy-functional ).},
  archive      = {J_ISCI},
  author       = {Baraka Maiseli},
  doi          = {10.1016/j.ins.2024.121008},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121008},
  shortjournal = {Inf. Sci.},
  title        = {Lipschitz energy functional for anisotropic diffusion applications},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DSDRec: Next POI recommendation using deep semantic
extraction and diffusion model. <em>ISCI</em>, <em>678</em>, 121004. (<a
href="https://doi.org/10.1016/j.ins.2024.121004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantics play a crucial role in many AI tasks, yet the lack of high-quality textual data in LBSNs hampers deep semantic feature learning. Sparse user check-in records, characterized by significant spatial or temporal intervals (cut points), create challenges in understanding users&#39; real mobile preferences. However, prior studies often rely on shallow semantic signals from independent textual properties and overlook these cut points when modeling spatio-temporal context. This work proposes a recommender model named DSDRec for the next POI recommendation. To alleviate the shortage of high-quality textual data in LBSNs, we take prompt engineering to freely obtain rich semantic texts (a.k.a., prompt sentences) from the discrete trajectory sequences and then use a pre-trained language model to acquire high-quality deep semantic features based on the functional prompt sentences. To mitigate the risk caused by the cut points, we propose an effective method, Spatio-Temporal Area Encoding, to depict the global spatial and temporal relationship of check-ins in trajectory. Besides, to study the potential of diffusion models in the next POI recommendation, we stacked an improved diffusion model to assist the recommender in learning more abstract interaction information. Comprehensive experiments conducted on two real-world datasets validate the competitive performance of DSDRec over previous SOTA approaches.},
  archive      = {J_ISCI},
  author       = {Ziwei Wang and Jun Zeng and Lin Zhong and Ling Liu and Min Gao and Junhao Wen},
  doi          = {10.1016/j.ins.2024.121004},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121004},
  shortjournal = {Inf. Sci.},
  title        = {DSDRec: Next POI recommendation using deep semantic extraction and diffusion model},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IFNN: Enhanced interpretability and optimization in FNN via
adam algorithm. <em>ISCI</em>, <em>678</em>, 121002. (<a
href="https://doi.org/10.1016/j.ins.2024.121002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This investigation seeks to reconcile the interpretability of artificial intelligence with the imperative of maintaining optimal performance, through the introduction of the IFNN model. This model represents a sophisticated iteration of the Fuzzy Neural Network (FNN) paradigm, engineered for enhanced interpretability. At the heart of this innovation lies the application of the Adam optimization algorithm, integrated into a tri-layered architectural construct. This approach is deliberately designed to elevate the models&#39; accuracy across an array of datasets, thereby positioning the IFNN model as an example of an interpretable AI system that does not compromise on precision. A seminal aspect of this model is its capacity to transmute logical neurons within the intermediary layer into clear fuzzy rules. This transformative process propels the model beyond the confines of traditional AI frameworks, ushering in a new era of transparency in the AI decision-making arena. Such progress is achieved through a meticulous fuzzy rule-based examination, anchored by an exhaustive appraisal of interpretability metrics, including but not limited to sensitivity, completeness, and the analysis of fuzzy rule consequents. These logical neurons, the progenitors of the aforementioned fuzzy rules, endow the model with the ability to engage in deep, interpretable analyses of data. The IFNN model has been tested through statistical analysis, interpretability assessments, and empirical validation against real-world datasets about sepsis identification, showcasing its unparalleled ability to unlock and articulate the complex knowledge embedded within data. This model represents a significant evolution in AI methodologies, providing a clear window into the rationale underpinning its decisions, achieved through an advanced fuzzy rule-based methodology and a full spectrum of interpretability metrics.},
  archive      = {J_ISCI},
  author       = {Paulo Vitor de Campos Souza and Mauro Dragoni},
  doi          = {10.1016/j.ins.2024.121002},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121002},
  shortjournal = {Inf. Sci.},
  title        = {IFNN: Enhanced interpretability and optimization in FNN via adam algorithm},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ESVI-GaMM: A fast network intrusion detection approach based
on the bayesian gamma mixture model. <em>ISCI</em>, <em>678</em>,
121001. (<a href="https://doi.org/10.1016/j.ins.2024.121001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the application of networks permeates various aspects of daily life, maintaining network security has become a crucial challenge. A network intrusion detection system (NIDS) functions as a critical technique for securing cyberspace and has gained considerable attention. Although researchers have made significant progress in developing NIDSs, challenges still exist in high-speed networks with overwhelming network traffic. Existing methods largely focus on improving model detection accuracy and often overlook speed and computational efficiency. This oversight renders most current methods impractical for real-world high-speed network scenarios. To address this issue, we propose an innovative and efficient network intrusion detection algorithm, namely, the Bayesian gamma mixture model (GaMM) classifier. With the recently proposed extended stochastic variational inference (ESVI) framework, we introduce lower-bound approximations to the evidence lower bound (ELBO), namely, the original variational object function. An analytically tractable Bayesian estimation algorithm for a GaMM is derived through stochastic optimization of the obtained lower bound and we validate its performance and computational efficiency on three publicly available datasets (CICMalmem2022, OPCUA, and CICIDS2018). The experimental results indicate that the proposed classifier not only achieves a detection performance comparable to that of other benchmark models but also significantly reduces both the training and detection times.},
  archive      = {J_ISCI},
  author       = {Wenda He and Xiangrui Cai and Yuping Lai and Xiaojie Yuan},
  doi          = {10.1016/j.ins.2024.121001},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121001},
  shortjournal = {Inf. Sci.},
  title        = {ESVI-GaMM: A fast network intrusion detection approach based on the bayesian gamma mixture model},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Selective privacy-preserving framework for large language
models fine-tuning. <em>ISCI</em>, <em>678</em>, 121000. (<a
href="https://doi.org/10.1016/j.ins.2024.121000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-tuning pre-trained large language models (LLMs) helps various downstream tasks, but brings serious privacy leaks when relying on large amounts of data for training. Differentially private stochastic gradient descent (DPSGD) has been designed to introduce noise during model updates to prevent privacy leaks. Nevertheless, fine-tuning LLMs via DPSGD limits the model utility since heavy perturbations are introduced on large high-dimensional gradients. Besides, existing privacy-preserving mechanisms directly perturb all tokens of the input sentences, which are too pessimistic to achieve good model performance. Therefore, this paper researches a selective privacy-preserving framework for fine-tuning LLMs. We propose a first-of-its-kind privacy notion called selective sequence local differential privacy (S-SeqLDP), which provides guarantees of indistinguishability only for the secret part of the sequences. Furthermore, we design a novel framework called SLDP-FT that enables S-SeqLDP-compliant large language model fine-tuning by perturbing the forward-pass embeddings with selective noises. We innovatively investigate the privacy forward weight that determines the noise magnitude of achieving selective privacy protection. Extensive experiments on three tasks demonstrate that our SLDP-FT achieves better model accuracy than state-of-the-art techniques when providing the same level of privacy protection.},
  archive      = {J_ISCI},
  author       = {Teng Wang and Lindong Zhai and Tengfei Yang and Zhucheng Luo and Shuanggen Liu},
  doi          = {10.1016/j.ins.2024.121000},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121000},
  shortjournal = {Inf. Sci.},
  title        = {Selective privacy-preserving framework for large language models fine-tuning},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multimodal multi-objective differential evolution with
series-parallel combination and dynamic neighbor strategy.
<em>ISCI</em>, <em>678</em>, 120999. (<a
href="https://doi.org/10.1016/j.ins.2024.120999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multi-objective optimization problems (MMOPs), which aim to identify as many optimal solutions as possible and exhibit multiple equivalent Pareto optimal solution sets (PSs) that correspond to the same Pareto optimal front (PF), commonly arise in a wide range of optimization problems in the real world. However, some dominated solutions that exhibit greater diversity in the decision space may be substituted by non-dominated solutions with a higher level of decision space crowding. To tackle this issue, this paper proposes a multimodal multi-objective differential evolution with series-parallel combination and dynamic neighbor strategy (MMODE_SPDN), which can balance convergence, objective space diversity and decision space diversity. Specifically, two archives are initially updated serially followed by the overall update of the parallel structure, in which the serial-first approach can enhance population diversity and the parallel structure can greatly reduce the amount of calculation. In addition, a dynamic neighbor strategy which utilizes adaptive selection among neighbors to generate difference vectors in the decision space and objective space and then adopts the main and auxiliary parent method during the mutation process is proposed. Furthermore, the utilization of an auxiliary archive and the clustering-based special crowding distance (CSCD) method are employed to facilitate the updating of the archive, thereby enhancing diversity. MMODE_SPDN is compared with other multimodal multi-objective optimization evolutionary algorithms (MMOEAs) on numerous test problems and the experimental results demonstrate that MMODE_SPDN exhibits superior performance.},
  archive      = {J_ISCI},
  author       = {Hu Peng and Wenwen Xia and Zhongtian Luo and Changshou Deng and Hui Wang and Zhijian Wu},
  doi          = {10.1016/j.ins.2024.120999},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120999},
  shortjournal = {Inf. Sci.},
  title        = {A multimodal multi-objective differential evolution with series-parallel combination and dynamic neighbor strategy},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Small-batch product quality prediction using a novel
discrete choquet fuzzy grey model with complex interaction information.
<em>ISCI</em>, <em>678</em>, 120997. (<a
href="https://doi.org/10.1016/j.ins.2024.120997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With manufacturing focused on multi-variety and small-batch intelligent production, the challenge is to guarantee and ensure good product quality. This paper proposes a novel small-batch product quality prediction approach considering complex interaction information. In this paper, first, to handle the complex nonlinear correlations among the manufacturing process variables, a kernel principal components analysis is used to extract the major features from the high-dimensional data. Second, we combine the discrete multivariate grey model and generalized discrete Choquet fuzzy integral to propose a discrete Choquet fuzzy grey model so as to capture the complex interaction information among the process variables. Next, an adjoint sensitivity analysis is applied to characterize the changes in the process variables on the predicted product quality index. We conduct an experiment on six semiconductor products made in China to validate the proposed model against a library of nine other methods. Our model yields an average reduction of 11.02% on MAPE, 20.47% on MSE, 13.56% on STD, and an average increase of 46.37% on EVS for six types of products. Our results inform that the proposed model is suitable for predicting manufacturing product quality when the process variables interact significantly, and we can prioritize the process variables for remedial action accordingly.},
  archive      = {J_ISCI},
  author       = {Qinzi Xiao and Mingyun Gao and Lin Chen and Mark Goh},
  doi          = {10.1016/j.ins.2024.120997},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120997},
  shortjournal = {Inf. Sci.},
  title        = {Small-batch product quality prediction using a novel discrete choquet fuzzy grey model with complex interaction information},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New approach for efficient malicious multiparty private set
intersection. <em>ISCI</em>, <em>678</em>, 120995. (<a
href="https://doi.org/10.1016/j.ins.2024.120995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multiparty Private Set Intersection (MPSI) protocol allows untrusted parties to compute the intersection of their sets without revealing any additional information. MPSI has found wide applications in fields such as advertising, vertical federated learning, privacy-preserving data mining, and private contact tracing. However, existing MPSI solutions face challenges in terms of security and efficiency. Some MPSI schemes are secure only against semi-honest adversaries and cannot effectively defend against malicious adversaries. Other schemes, while capable of withstanding malicious adversaries, exhibit efficiency problems, especially as the number of corrupt participants increases. A practical MPSI solution must maintain high security and efficiency, even when handling large-scale data and a majority of corrupted participants. This paper introduces a novel MPSI scheme named TH-PSI, built upon a new star-shaped topological network communication framework based on the trusted execution environment. TH-PSI has been rigorously proven to be secure within the standard Universal Composability framework, capable of thwarting malicious adversaries. To demonstrate the efficiency of TH-PSI, we conduct a comprehensive series of experiments. We implement the TH-PSI scheme and tested it in both LAN and WAN settings, involving up to 30 participants and datasets as large as 2 22 . We compare TH-PSI with state-of-the-art MPSI schemes, ENOC21 and NTY21, with a specific focus on their efficiency in the presence of malicious adversaries. Our experiments show that TH-PSI is an efficient solution capable of delivering results within a matter of seconds, even when dealing with data at the million-level and a majority of corrupted participants.},
  archive      = {J_ISCI},
  author       = {Siyi Lv and Yu Wei and Jingyu Jia and Xinhao Li and Tong Li and Zheli Liu and Xiaofeng Chen and Liang Guo},
  doi          = {10.1016/j.ins.2024.120995},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120995},
  shortjournal = {Inf. Sci.},
  title        = {New approach for efficient malicious multiparty private set intersection},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large group decision-making with a rough integrated
asymmetric cloud model under multi-granularity linguistic environment.
<em>ISCI</em>, <em>678</em>, 120994. (<a
href="https://doi.org/10.1016/j.ins.2024.120994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large group decision-making often contains strong uncertainty and randomness due to the complexity of decision-making problems. Moreover, existing methods about large group decision-making usually assume that the relationships among decision-makers are mutually independent, which will neglect the relevance of decision information to some extent. To address these limitations, this paper proposes a novel rough integrated asymmetric cloud model to tackle large group decision-making under multi-granularity linguistic environment. This model can not only flexibly portray decision-makers’ preferences, but also objectively handle the uncertainty and randomness in large group decision-making through the relevance of preferences. Firstly, a trust propagation model based on rough integrated asymmetric cloud is raised to consider the impact of uncertainty and randomness in the trust propagation on large group decision-making. Secondly, a new asymmetric cloud distance and similarity are proposed to overcome some defects of existing methods. Thirdly, a decision-maker weight calculation method based on the Shapley function is advanced to enhance the decision-making reasonableness. Next, an investment problem is solved by the proposed method. Finally, the effectiveness and superiority of the proposed method are demonstrated by the sensitivity and comparison analyses.},
  archive      = {J_ISCI},
  author       = {Jicun Jiang and Xiaodi Liu and Zengwen Wang and Weiping Ding and Shitao Zhang and Hao Xu},
  doi          = {10.1016/j.ins.2024.120994},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120994},
  shortjournal = {Inf. Sci.},
  title        = {Large group decision-making with a rough integrated asymmetric cloud model under multi-granularity linguistic environment},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiple dynamic targets enclosing control for a class of
nonlinear uncertain multiagent systems. <em>ISCI</em>, <em>678</em>,
120993. (<a href="https://doi.org/10.1016/j.ins.2024.120993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multiple dynamic targets enclosing control protocol is proposed in this paper for a class of nonlinear uncertain multiagent systems. To accomplish the mission of hunting multiple targets with double-integral nonlinear dynamics, a distributed estimator is established firstly for each agent by employing the signum function, leading to an estimation of the average position of multiple targets. Specifically, only partial information about the dynamic targets is utilized to construct the enclosing formation reference beacon. Furthermore, due to the existence of the system uncertainties, it is a challenging task to design the enclosing controller. To overcome this difficulty, an augmented system is constructed to compensate for the effect caused by the uncertainties, which is introduced afterwards into the control protocol design along with comprehensive theoretical analysis. Sufficient conditions are derived and proved under Lyapunov stability criterion to ensure the closed-loop stability of nonlinear multiagent systems. The effectiveness of the proposed control scheme is finally verified through the numerical simulations. More precisely, by appropriately picking control parameters α and β based on Lemma 3.1 , the designed formation reference beacon estimator is validated by achieving convergence of errors between the actual state and estimated states to zero. Meanwhile, the feasibility of the proposed enclosing control protocol is demonstrated simultaneously as it enables the regulation of enclosing errors using a self-designed parameter γ 0 γ0 . Additionally, the sensitivity analysis of the control parameters is presented, which indicates that the proposed reference beacon estimator remains robust to the variation of its control parameters, while larger values for the control parameters in the designed controller result in faster error convergence rates.},
  archive      = {J_ISCI},
  author       = {Bowen Xu and Dingding Qi and Dengxiu Yu and Zhen Wang},
  doi          = {10.1016/j.ins.2024.120993},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120993},
  shortjournal = {Inf. Sci.},
  title        = {Multiple dynamic targets enclosing control for a class of nonlinear uncertain multiagent systems},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-objective evolutionary algorithm for robust
positive-unlabeled learning. <em>ISCI</em>, <em>678</em>, 120992. (<a
href="https://doi.org/10.1016/j.ins.2024.120992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Positive and unlabeled (PU) learning is to learn a binary classifier with good generalization ability from PU data. A variety of PU learning algorithms with promising performance have been proposed. However, most of them assume that PU samples are “clean”, which is not true in real applications due to the existing noisy or redundant samples. Thus, how to obtain a robust PU classifier with better performance is a challenging problem. To this end, we propose a novel multi-objective evolutionary algorithm to tackle it, named BPUSS-MOEA. Specifically, we firstly transform the robust PU learning into a bi-objective PU sample selection (BPUSS) problem, in which two objectives are designed. One is the number of selected “clean” PU samples and the other is the PU accuracy. Then, a dual-coding scheme is designed to represent the selected “clean” PU samples and the labels of U samples. With the dual-coding scheme, a novel offspring generation strategy is developed to achieve the offsprings with high quality. To further improve the performance of BPUSS-MOEA, an effective population initialization strategy is designed. Experiments on 10 datasets with different noise levels show that compared with the state-of-the-arts, the proposed algorithm demonstrates its robustness in terms of the PU accuracy.},
  archive      = {J_ISCI},
  author       = {Jianfeng Qiu and Qi Tang and Ming Tan and Kaixuan Li and Juan Xie and Xiaoqiang Cai and Fan Cheng},
  doi          = {10.1016/j.ins.2024.120992},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120992},
  shortjournal = {Inf. Sci.},
  title        = {A multi-objective evolutionary algorithm for robust positive-unlabeled learning},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Multiple attribute decision making based on score function
of q-connection numbers, q-CNPWG aggregation operator of q-connection
numbers, and set pair analysis theory in the environments of q-rung
orthopair fuzzy numbers. <em>ISCI</em>, <em>678</em>, 120985. (<a
href="https://doi.org/10.1016/j.ins.2024.120985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new multiple attribute decision making (MADM) method in the environments of q-rung orthopair fuzzy numbers (q-ROFNs) based on the proposed score function of q-connection numbers (q-CNs), the proposed q-connection number power weighted geometric (q-CNPWG) aggregation operator (AO) of q-CNs, and the set pair analysis (SPA) theory. Firstly, we propose a score function of q-CNs based on the SPA theory, where we also present some properties of the proposed score function of q -CNs. Then, we propose the q-CNPWG AO for aggregating q-CNs, where we also present some properties of the proposed q-CNPWG AO of q-CNs. Finally, we propose a new MADM method in the environments of q -ROFNs based on the proposed score function of q -CNs, the proposed q -CNPWG AO of q-CNs, and the SPA theory. The proposed MADM method can overcome the drawbacks of existing MADM methods in the environments of q- ROFNs, where they cannot distinguish preference orders of alternatives in some situations. The proposed MADM method is very useful for MADM in the environments of q- ROFNs.},
  archive      = {J_ISCI},
  author       = {Kamal Kumar and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2024.120985},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120985},
  shortjournal = {Inf. Sci.},
  title        = {Multiple attribute decision making based on score function of q-connection numbers, q-CNPWG aggregation operator of q-connection numbers, and set pair analysis theory in the environments of q-rung orthopair fuzzy numbers},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). Flexi-BOPI: Flexible granularity pipeline inference with
bayesian optimization for deep learning models on HMPSoC. <em>ISCI</em>,
<em>678</em>, 120984. (<a
href="https://doi.org/10.1016/j.ins.2024.120984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve high-throughput deep learning (DL) model inference on heterogeneous multiprocessor systems-on-chip (HMPSoC) platforms, the use of pipelining for the simultaneous utilization of multiple resources has emerged as a promising solution. Nevertheless, current research faces two primary challenges: determining the optimal pipeline partitioning granularity, which directly influences the inference performance, and addressing the high time overhead of the search algorithms. To address these challenges, we propose Flexi-BOPI, a pipeline inference method for DL models of HMPSoCs. Flexi-BOPI offers flexible pipeline partitioning granularity down to a minimum size of a single core, enhancing the performance by better adapting to the diverse computational demands of different layers in DL models. Flexi-BOPI employs a Bayesian optimization-based search algorithm to significantly reduce the search overhead. In addition, we propose a surrogate model based on the heteroscedastic Gaussian process (HGP) to address the challenge of sample noise during the evaluation process. This approach can further reduce search overhead. Our experimental results demonstrate that the proposed method achieves significant improvements in inference performance and search overhead compared to existing methods.},
  archive      = {J_ISCI},
  author       = {Zhenyi Wang and Pengfei Yang and Bowen Zhang and Linwei Hu and Wenkai Lv and Chengmin Lin and Quan Wang},
  doi          = {10.1016/j.ins.2024.120984},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120984},
  shortjournal = {Inf. Sci.},
  title        = {Flexi-BOPI: Flexible granularity pipeline inference with bayesian optimization for deep learning models on HMPSoC},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data heterogeneity’s impact on the performance of frequent
itemset mining algorithms. <em>ISCI</em>, <em>678</em>, 120981. (<a
href="https://doi.org/10.1016/j.ins.2024.120981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent itemset mining (FIM) is a widely used task that extracts frequently occurring itemsets from data. Plenty of deterministic algorithms are available for this daunting task. However, experimental studies have not considered that data heterogeneity significantly impacts the algorithms&#39; performance, giving rise to unfair comparisons and biased conclusions. This paper seeks to advance by comparing cutting-edge algorithms using various frequency thresholds, considering the resulting data heterogeneity. An extensive experimental study is carried out, including the number of itemsets mined per second as the performance quality measure to compare algorithms. The experiments include defining eight metrics to quantify data heterogeneity, and their values vary the algorithms&#39; performance. The results revealed that some techniques (hypercube decomposition and k -items machine) are essential to achieve excellent performance on any dataset, and most algorithms behave similarly well when they include those techniques. As a final important point, different threshold values produce dissimilar data subsets (data heterogeneity is not an immutable data characteristic), so a previous study on the database characteristics with a few minimum support thresholds could be beneficial to select the best-suited FIM algorithm beforehand.},
  archive      = {J_ISCI},
  author       = {Antonio Manuel Trasierras and José María Luna and Philippe Fournier-Viger and Sebastián Ventura},
  doi          = {10.1016/j.ins.2024.120981},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120981},
  shortjournal = {Inf. Sci.},
  title        = {Data heterogeneity&#39;s impact on the performance of frequent itemset mining algorithms},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A guaranteed fixed-step convergence approach to discrete
sliding mode control of linear disturbed systems. <em>ISCI</em>,
<em>678</em>, 120978. (<a
href="https://doi.org/10.1016/j.ins.2024.120978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current methods for achieving fixed-time convergence in continuous sliding mode control are extensively studied, whereas there are limited studies on fixed-step convergence in discrete sliding mode control. The control objective of this paper aims to develop control schemes assuring that the number of convergence steps of the tracking error remains within the desired range, even as the initial value increases, and this paper proposes a guaranteed fixed-step convergence approach to form the reaching law. An upper bound on convergent steps, independent of the initial value, is established, thereby having the fixed-step convergence property. The performance assessment, including attractiveness, invariance, and convergence steps, is provided to meet the required specifications. The steady-state band results offer guidance in selecting parameters to achieve the control objective. To achieve fixed-step convergence of the tracking error, one can develop a dead-beat terminal sliding mode control scheme, where the tracking error is governed by the prescribed error dynamics. To illustrate the approach more concretely, specific designs are proposed for both switching and non-switching reaching laws aimed at ensuring fixed-step convergence. The simulation and experiment results validate the performance evaluation and demonstrate effectiveness of the proposed control schemes.},
  archive      = {J_ISCI},
  author       = {Zhengyang Zhu and Mingxuan Sun and Xiongxiong He},
  doi          = {10.1016/j.ins.2024.120978},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120978},
  shortjournal = {Inf. Sci.},
  title        = {A guaranteed fixed-step convergence approach to discrete sliding mode control of linear disturbed systems},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stability analysis of a class of singular fuzzy systems with
time delays via event-triggered sliding mode control. <em>ISCI</em>,
<em>678</em>, 120977. (<a
href="https://doi.org/10.1016/j.ins.2024.120977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the stability of singular fuzzy systems with time-delays is investigated by use of event triggered sliding mode control(ETSMC). For the impulse of singular systems can be caused at the instants of every event trigger executed, a new controller is designed to alleviate the impact of the impulse. It can avoid the effect of the impulse for the stability of the system. At the same time, the input matrices of the considered fuzzy systems could be different. And the common restrictions about them are removed in this paper. By use of the proposed method, the considered system can be stabilized via event-triggered sliding mode control. Furthermore, Zeno phenomenon of the considered system could be avoided under the proposed method. Finally, two examples are provided to illustrate the effectiveness of this method.},
  archive      = {J_ISCI},
  author       = {Jianyu Zhang and Yingying Wang and Yan Liu and Yamin Kang and Peiran Liu},
  doi          = {10.1016/j.ins.2024.120977},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120977},
  shortjournal = {Inf. Sci.},
  title        = {Stability analysis of a class of singular fuzzy systems with time delays via event-triggered sliding mode control},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Enhancing generalization in genetic programming
hyper-heuristics through mini-batch sampling strategies for dynamic
workflow scheduling. <em>ISCI</em>, <em>678</em>, 120975. (<a
href="https://doi.org/10.1016/j.ins.2024.120975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic Programming Hyper-heuristics (GPHH) have been successfully used to evolve scheduling rules for Dynamic Workflow Scheduling (DWS) as well as other challenging combinatorial optimization problems. The method of sampling training instances has a significant impact on the generalization ability of GPHH, yet they are rarely addressed in existing research. This article aims to fill this gap by proposing a GPHH algorithm with a sampling strategy to thoroughly investigate the impact of six instance sampling strategies on algorithmic generalization, including one rotation strategy, three mini-batch strategies, and two hybrid strategies. Experiments across four scenarios with varying settings reveal that: (1) mini-batch with random sampling can outperform rotation in generalizing to unseen workflow scheduling problems under the same computational cost; (2) employing a hybrid strategy that combines rotation and mini-batch further enhances the generalization ability of GPHH; and (3) mini-batch and hybrid strategies can effectively enable heuristics trained on small-scale training instances generalizing well to large-scale unseen ones. These findings highlight the potential of mini-batch strategies in GPHH, offering improved generalization performance while maintaining diversity and suggesting promising avenues for further exploration in GPHH domains.},
  archive      = {J_ISCI},
  author       = {Yifan Yang and Gang Chen and Hui Ma and Sven Hartmann and Mengjie Zhang},
  doi          = {10.1016/j.ins.2024.120975},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120975},
  shortjournal = {Inf. Sci.},
  title        = {Enhancing generalization in genetic programming hyper-heuristics through mini-batch sampling strategies for dynamic workflow scheduling},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CIRF: Importance of related features for plausible
counterfactual explanations. <em>ISCI</em>, <em>678</em>, 120974. (<a
href="https://doi.org/10.1016/j.ins.2024.120974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfactual explanation (CFE) provides actionable counterexamples and enhances the interpretability of the decision boundaries in deep neural networks and thereby has gained increasing interest in recent years. An ideal CFE should provide both plausible and practical examples that can alter the decision of a classifier as a plausible CFE grounded in the real world. Motivated by this issue, we propose a CFE framework for identifying related features (CIRF) to improve the plausibility of explanations. CIRF comprises the following two steps: i ) searching for the direction vectors that contain class information; ii ) investigating an optimal point using a projection-point, which determines the magnitude of manipulation along the direction. Our framework utilizes related features and the property of a latent space in a generative model, thereby highlighting the importance of related features. We derive points that have many related features, and show a performance gain of more than 11% on the IM1 metric compared to points that have fewer related features. We validate the versatility of CIRF by performing experiments using various domains and datasets, and the two interchangeable steps. CIRF exhibits remarkable performance in terms of plausibility across various domains, including tabular and image datasets.},
  archive      = {J_ISCI},
  author       = {Hee-Dong Kim and Yeong-Joon Ju and Jung-Ho Hong and Seong-Whan Lee},
  doi          = {10.1016/j.ins.2024.120974},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120974},
  shortjournal = {Inf. Sci.},
  title        = {CIRF: Importance of related features for plausible counterfactual explanations},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A membership function-dependent l∞ performance based output
interval estimation method for discrete-time takagi–sugeno fuzzy systems
applied to fault detection. <em>ISCI</em>, <em>678</em>, 120973. (<a
href="https://doi.org/10.1016/j.ins.2024.120973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the design process of traditional L ∞ L∞ methods, a common performance index is often considered in different fuzzy rules. This may introduce a certain conservatism when most of the whole fuzzy system operates under a certain fuzzy rule or a few fuzzy rules. Therefore, this paper focuses on robust interval estimation problems for discrete-time Takagi–Sugeno fuzzy systems, and a new membership function-dependent L ∞ L∞ performance index is proposed. The proposed L ∞ L∞ performance can ensure better results in practical engineering applications by using the priori knowledge that the model works most of the time on some specific fuzzy systems to design performance index. By means of fuzzy basis-dependent Lyapunov functions, a membership function-dependent L ∞ L∞ performance based interval estimation strategy applied to fault detection is presented. Through simulation analysis, the L ∞ L∞ index in this paper is better than the conventional one and a tighter interval estimation is obtained leading to more accurate and faster fault detection effects. Meanwhile, the simulation results of this method also reflect the membership function-dependent property well.},
  archive      = {J_ISCI},
  author       = {Yi Li and Jiuxiang Dong},
  doi          = {10.1016/j.ins.2024.120973},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120973},
  shortjournal = {Inf. Sci.},
  title        = {A membership function-dependent l∞ performance based output interval estimation method for discrete-time Takagi–Sugeno fuzzy systems applied to fault detection},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fairness based on anomaly score and adaptive weight in
network attack detection. <em>ISCI</em>, <em>678</em>, 120972. (<a
href="https://doi.org/10.1016/j.ins.2024.120972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent network systems have become an integral part of society, communication methods and corresponding protocols are the basis for the realization of information exchange in these systems. As network attacks often take advantage of the vulnerabilities in the protocols to launch attacks with different characteristics, many detection methods have been investigated by professionals. To address this challenge, we propose an approach that uses an algorithm for clustering to compute anomaly scores to initialize the classifier&#39;s sample weights and adaptively optimize these scores, which is then achieved by learning the adaptive weights for each group to achieve a group-level balance between different protocol attack groups. Our approach focuses on error-prone samples and aims to improve the adequate representation of a small number of protocol groups. At the same time, we reduce the inter-group difference and improve the accuracy of the classifier for better fairness. We construct closed-form solutions with adaptive weight assignment and use convex optimization to ensure theoretical convergence. To validate the theoretical superiority and accuracy of the methods, we conduct experiments on the KDD, NSLKDD, and CIC-IDS datasets and compared them to current state-of-the-art methods. Compared to the baseline method, our approach demonstrates improvements in both fairness indicators and accuracy across three datasets. These experimental results show that our proposed method outperforms existing methods in terms of performance. In addition, our technique exhibits robustness to noisy labels in various benchmark datasets. To enhance the reproducibility of the paper, we have uploaded the source code to GitHub at the following URL: https://github.com/dazhi-ui/Fairness_Detection .},
  archive      = {J_ISCI},
  author       = {Xuezhi Wen and Meiqi Gao and Nan Wang and Jiahui Ma and Dalin Zhang and Xibin Zhao and Jiqiang Liu},
  doi          = {10.1016/j.ins.2024.120972},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120972},
  shortjournal = {Inf. Sci.},
  title        = {Fairness based on anomaly score and adaptive weight in network attack detection},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Transferable adversarial attack based on sensitive
perturbation analysis in frequency domain. <em>ISCI</em>, <em>678</em>,
120971. (<a href="https://doi.org/10.1016/j.ins.2024.120971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, transferable adversarial attacks on deep neural networks (DNNs) have attracted significant attention. Although existing adversarial attacks have achieved high attack success rates in white-box scenarios, they perform poorly in black-box attack scenarios. To address the issue of low transferability in black-box adversarial attacks, we propose a frequency-sensitive perturbation-based black-box adversarial attack method to enhance transferability performance from the perspective of Fourier domain sensitivity. Initially, the Fourier sensitivity heatmaps of multiple substitute models are integrated to identify the common sensitive frequency region. Subsequently, the perturbations in the frequency domain are optimized through joint loss, thereby constraining the sensitive region and limiting the perturbations in the non-sensitive region. Finally, in each iteration, a spectral model enhancement is performed to simulate additional substitute models and reduce the spectral discrepancy between the substitute and target models. Extensive experimental results on benchmark datasets demonstrated the effectiveness of the proposed method. Compared to existing black-box adversarial attack methods, the proposed approach generates targeted and non-targeted adversarial samples with higher transfer success rates and good invisibility, thereby confirming its superiority.},
  archive      = {J_ISCI},
  author       = {Yong Liu and Chen Li and Zichi Wang and Hanzhou Wu and Xinpeng Zhang},
  doi          = {10.1016/j.ins.2024.120971},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120971},
  shortjournal = {Inf. Sci.},
  title        = {Transferable adversarial attack based on sensitive perturbation analysis in frequency domain},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stable predictive control of continuous stirred-tank
reactors using deep learning. <em>ISCI</em>, <em>678</em>, 120970. (<a
href="https://doi.org/10.1016/j.ins.2024.120970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a Lyapunov-based predictive control method utilizing deep learning techniques is proposed for driving continuous-time nonlinear processes towards the desired equilibrium point. Initially, a neural ordinary differential equation model is developed to learn the continuous-time dynamics from discrete-time sampling data. Subsequently, the theoretical conditions that the control Lyapunov function (CLF) developed on the learned continuous-time system is feasible to act on the actual system through a zero-order-holder are analyzed. Building upon the theoretical analysis and the constructed continuous-time dynamics, a deep neural network control Lyapunov function (DNN-CLF) controller is developed. Importantly, the DNN-CLF is independent of the affine system formulation, effectively addressing the challenge of designing the CLF. Benefiting from the stability guarantee provided by the established DNN-CLF, it is integrated into the model predictive control (MPC) framework to develop Lyapunov-based MPC to further improve the control performance. To ensure safety, considering error propagation and associated risks with enlarging the feasible region of the CLF, tubes are constructed and integrated into the MPC scheme. Finally, a numerical simulation of a chemical process is conducted to validate the efficiency of the proposed method.},
  archive      = {J_ISCI},
  author       = {Shulei Zhang and Runda Jia and Yankai Cao and Dakuo He and Feng Yu},
  doi          = {10.1016/j.ins.2024.120970},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120970},
  shortjournal = {Inf. Sci.},
  title        = {Stable predictive control of continuous stirred-tank reactors using deep learning},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incremental swarm coordination control with
self-triggered-organized topology and predictive-based control method.
<em>ISCI</em>, <em>678</em>, 120969. (<a
href="https://doi.org/10.1016/j.ins.2024.120969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on coordinating a swarm of multiple mobile robots with incremental joining units using an incremental-self-organized formation (ISOF) scheme. The ISOF scheme enables the assimilation of newly joined robots and autonomously establishes a feasible communication topology between the incremental and existing robots. To avoid redundant generation, the new communication topology is expanded and updated based on the existing topology while preserving the original structure. To realize the real-time update of control model and topology for generalized swarm system using the ISOF scheme, an incremental-self-triggered updating mechanism (ISTUM) is designed, and specific triggering conditions are defined. With the updated communication topology and control model, the incremental swarm system, subject to predefined constraints, can be controlled to achieve the desired formation objective using a model-predictive-control-based (MPC-based) protocol. The proposed control scheme aims to minimize the need for manual intervention in swarm reconstruction when incremental behaviour occurs, thereby enhancing the flexibility of swarm coordination. Simulation results demonstrate the effectiveness of the developed control scheme.},
  archive      = {J_ISCI},
  author       = {Hanzhen Xiao and Guanyu Lai and Yun Zhang and Dengxiu Yu and C.L. Philip Chen},
  doi          = {10.1016/j.ins.2024.120969},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120969},
  shortjournal = {Inf. Sci.},
  title        = {Incremental swarm coordination control with self-triggered-organized topology and predictive-based control method},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relaxed static output feedback control for discrete-time
takagi-sugeno fuzzy systems: A switching sequence convex optimization
algorithm. <em>ISCI</em>, <em>678</em>, 120966. (<a
href="https://doi.org/10.1016/j.ins.2024.120966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new switching sequence convex optimization (SSCO) algorithm is proposed for solving non-convex optimization problem with complex time-varying relaxation matrix structures that arises during output feedback design. Firstly, the introduced time-varying relaxation matrix combines the membership functions and the designed switching mechanism to adjust the positive and negative terms of the inequality constraints. As a result, relaxed controller design conditions with complex matrix structures are established. The proposed SSCO algorithm employs switching optimization variables and inner approximation strategy, which is able to compute non-convex optimization problems with complex matrix structures more flexibly and converge quickly. It is worth noting that the implementation of the SSCO algorithm requires a set of strictly feasible initial solutions. Therefore, an initialization iterative algorithm is proposed, which overcomes the difficulties of transforming the solving problem into a typical non-convex optimization problem and linearizing multiple different concave parts, by which a set of optimized feasible solutions are obtained. Finally, simulation examples are used to demonstrate the superiority of the design scheme proposed in this paper.},
  archive      = {J_ISCI},
  author       = {Jingjing Gao and Xiangpeng Xie and Jianwei Xia},
  doi          = {10.1016/j.ins.2024.120966},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120966},
  shortjournal = {Inf. Sci.},
  title        = {Relaxed static output feedback control for discrete-time takagi-sugeno fuzzy systems: A switching sequence convex optimization algorithm},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Long-short-view aware multi-agent reinforcement learning for
signal snippet distillation in delirium movement detection.
<em>ISCI</em>, <em>678</em>, 120963. (<a
href="https://doi.org/10.1016/j.ins.2024.120963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic movement analysis utilizing surveillance video is believed to be an important and convenient way for timely delirium detection in an Intensive Care Unit (ICU). However, video-based delirium movement detection (DMD) faces inherent challenges: 1) Irregular movements with large differences in the four limbs of a patient; 2) similar movements in delirium and normal situations, and large movement variations between patients experiencing delirium. To address the challenges 1, this paper proposes a Long-Short-View Aware Multi-Agent Reinforcement Learning (LS-MARL) method to identify the most representative movement snippet for DMD, considering that the global state provided by the long-view is important for guiding the agent&#39;s decision-making, but ignored in existing MARL methods. The proposed LS-MARL has two novel designs. First, a novel Teacher Auxiliary Policy (TAP) is developed for direction preperception of the representative movement snippet. Second, a new reward mechanism, Team Intrinsic Reward (TIR), is introduced to quantify the contribution of each agent. Experiments demonstrate that the proposed LS-MARL method outperforms state-of-the-art methods. Furthermore, to handle the second challenge, a new Self-Adjusting Ensemble Learning (SAEL) strategy is built to adaptively integrate an optimal classifier combination from multidomain features, which further improves the performance of classification tasks in the proposed LS-MARL method.},
  archive      = {J_ISCI},
  author       = {Qingtao Pan and Hao Wang and Jingjiao Lou and Yuyan Zhang and Bing Ji and Shuo Li},
  doi          = {10.1016/j.ins.2024.120963},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120963},
  shortjournal = {Inf. Sci.},
  title        = {Long-short-view aware multi-agent reinforcement learning for signal snippet distillation in delirium movement detection},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). First and second k banhatti indices of a fuzzy graph applied
to decision making. <em>ISCI</em>, <em>678</em>, 120961. (<a
href="https://doi.org/10.1016/j.ins.2024.120961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topological index of a graph is a numerical representation linked to the graph or the molecular structure associated with the graph, shedding light on its topological and structural properties. Different topological indices showcase unique attributes rooted in their degree, spectrum, and distance characteristics. Among these, the first and second K Banhatti indices, introduced by Kulli, involving both vertex and edge degrees, have garnered significant scholarly interest, prompting extensive discussions in graph theory. Within this research paper, a thorough exploration delves into the attributes surrounding the fuzzified first and second K Banhatti indices. This exploration is directed towards several bounds of the index and index of various structures like cycles, complete fuzzy graphs, complete bipartite graphs and stars. Relation between a fuzzy graph and its partial subgraphs, fuzzy graph and its complement graph in connection with the indices is also found. Additionally, the research paper investigates the first and second K Banhatti indices concerning graph operations such as the corona product and coalescence. Additionally, the paper outlines an algorithm designed to accurately compute the first and second K Banhatti indices and proposes an application in decision-making.},
  archive      = {J_ISCI},
  author       = {A. Josy and S. Mathew and J.N. Mordeson},
  doi          = {10.1016/j.ins.2024.120961},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120961},
  shortjournal = {Inf. Sci.},
  title        = {First and second k banhatti indices of a fuzzy graph applied to decision making},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Clustered federated learning based on nonconvex pairwise
fusion. <em>ISCI</em>, <em>678</em>, 120956. (<a
href="https://doi.org/10.1016/j.ins.2024.120956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates clustered federated learning (FL), a formulation of FL designed to handle non-i.i.d. data by partitioning devices into clusters, with each cluster optimizing a localized model for its data. We propose a clustered FL framework that incorporates a nonconvex penalty to pairwise differences of parameters. Without a priori knowledge of the set of devices in each cluster and the number of clusters, this framework can autonomously estimate cluster structures. To implement the proposed framework, we introduce a novel clustered FL method called Fusion Penalized Federated Clustering (FPFC). Building upon the standard alternating direction method of multipliers (ADMM), FPFC can perform partial updates at each communication round and allows parallel computation with a variable workload. These strategies significantly reduce the communication cost while ensuring privacy, thereby enhancing the practicality of FL. We also propose a new warmup strategy for hyperparameter tuning in FL settings and explore the asynchronous variant of FPFC (asyncFPFC). Theoretical analysis provides convergence guarantees for FPFC with general losses and establishes the statistical convergence rate under a linear model with squared loss. Extensive experiments have demonstrated the superiority of FPFC compared to current methods, including robustness and generalization capability.},
  archive      = {J_ISCI},
  author       = {Xue Yu and Ziyi Liu and Wu Wang and Yifan Sun},
  doi          = {10.1016/j.ins.2024.120956},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120956},
  shortjournal = {Inf. Sci.},
  title        = {Clustered federated learning based on nonconvex pairwise fusion},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploiting asymmetric influence between instances for label
enhancement. <em>ISCI</em>, <em>678</em>, 120954. (<a
href="https://doi.org/10.1016/j.ins.2024.120954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label learning, label enhancement (LE) aims to recover label distributions from logical labels, thereby reinforcing supervision information in the training set. Existing LE algorithms mainly leverage pairwise similarities between instances to recover label distributions. However, symmetric similarities, which are widely used, are incapable of reflecting individual differences between instances. In this paper, we propose an asymmetric influence between instances to fully explore the information contained in logical labels. First, we build a bipartite network and employ the mass diffusion algorithm on it to calculate the asymmetric influence between instances. Such asymmetry distinguishes the influence of an instance on others from the influence it receives from others. Second, to cope with the new influence, we construct a graph with self-connections. In this way, we allow instances to be influenced by themselves. Extensive experiments on thirteen benchmark datasets demonstrate the superiority of the proposed method over six state-of-the-art LE algorithms.},
  archive      = {J_ISCI},
  author       = {Heng-Ru Zhang and Peng-Cheng Li and Yuan-Yuan Xu and Fan Min},
  doi          = {10.1016/j.ins.2024.120954},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120954},
  shortjournal = {Inf. Sci.},
  title        = {Exploiting asymmetric influence between instances for label enhancement},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Dual-STI: Dual-path spatial-temporal interaction learning
for dynamic facial expression recognition. <em>ISCI</em>, <em>678</em>,
120953. (<a href="https://doi.org/10.1016/j.ins.2024.120953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning facial evaluation is crucial for dynamic facial expression recognition. Current recognition methods typically extract temporal features after spatial features to achieve low computation complexity. However, these methods struggle to model complex facial evaluations due to a lack of interaction between spatial and temporal features. This paper proposes a novel Dual-path Spatial-Temporal Interaction (Dual-STI) framework that concurrently extracts spatial and temporal features through two efficient paths. Specifically, Dual-STI comprises a spatial path and a temporal path. The spatial path contains several spatial transformers to capture robust facial features from each sampled frame, while the temporal path includes several temporal transformers to learn rich contextual facial features from the sequence of frames. To facilitate spatial-temporal interaction, Dual-STI features a distinct dual-path interaction module that adaptively fuses spatial and temporal features by combining spatial and temporal attention mechanisms. Additionally, comparative learning is introduced into the loss function to enhance this interaction. To evaluate the proposed method, extensive experiments are conducted on three popular benchmarks, namely DFEW, AFEW, and FERV39k. The experimental results demonstrate that the proposed Dual-STI achieves state-of-the-art performance with low computational complexity across all datasets. Notably, Dual-STI shows significant improvements in the “disgust” and “fear” categories, with precision increases of 3.45% and 2.1% on the DFEW dataset, respectively.},
  archive      = {J_ISCI},
  author       = {Min Li and Xiaoqin Zhang and Chenxiang Fan and Tangfei Liao and Guobao Xiao},
  doi          = {10.1016/j.ins.2024.120953},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120953},
  shortjournal = {Inf. Sci.},
  title        = {Dual-STI: Dual-path spatial-temporal interaction learning for dynamic facial expression recognition},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep graph clustering by integrating community structure
with neighborhood information. <em>ISCI</em>, <em>678</em>, 120951. (<a
href="https://doi.org/10.1016/j.ins.2024.120951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep graph clustering approaches employ deep graph neural networks to encode node embeddings and subsequently partition nodes based on these representations. Recent one-step methods have demonstrated progress; however, they often encounter issues during the representation learning phase. A primary challenge is that the encoding networks fail to capture the high-order structural information of the graph for effective clustering. We believe that combining the two distributions comprehensively characterizes the real node distribution in terms of neighborhood proximity and community aggregation to achieve better clustering. Additionally, the prevalent representation learning paradigms based on adjacency matrix reconstruction are computationally intensive and increase optimization challenges. This paper presents a novel deep graph clustering model, termed Deep Integration of Community structure and Neighborhood information (DICN). The model incorporates a graph self-attention mechanism to aggregate neighborhood-level node information, and utilizes a probabilistic generative model for edge community detection to captain community-level node information. These two-level embeddings are employed to compute explicit node membership distributions for the clustering loss. This ensures that the clustering objective effectively integrates both low-order and high-order node characteristics. The comprehensive learning process of DICN optimizes not only the node embeddings but also the clustering results by integrating the two-level losses from representation learning and the clustering loss with a weak guidance loss for clustering. Experiments on some benchmark datasets illustrate that DICN model has superior performance over existing state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Bianfang Chai and Zheng Li and Xiaopeng Zhao},
  doi          = {10.1016/j.ins.2024.120951},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120951},
  shortjournal = {Inf. Sci.},
  title        = {Deep graph clustering by integrating community structure with neighborhood information},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Objective contribution decomposition method and
multi-population optimization strategy for large-scale multi-objective
optimization problems. <em>ISCI</em>, <em>678</em>, 120950. (<a
href="https://doi.org/10.1016/j.ins.2024.120950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As problem complexity and data dimensionality increase, practical problems tend to have a large number of variables. Large-scale multi-objective optimization problems (LSMOPs) are a complex and difficult class of problems with numerous decision variables to be optimized. In addressing these problems using traditional evolutionary algorithms, achieving convergence is often difficult. The decomposition of decision variables and optimization is a more intuitive way to deal with this problem, which reduces the size of the problem to some extent. Thus, in this study, an objective contribution decomposition method and multi-population optimization strategy are proposed for handling LSMOPs. First, the decision variables are decomposed according to their contribution to the objectives. Further decomposition is performed based on the interactions among the decision variables. Then, multiple populations are generated to optimize the variable group and determine the information interaction among the subpopulations. In experimental results, the performance of the proposed algorithm was competitive in comparisons with six state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Jin Liu and Ruochen Liu},
  doi          = {10.1016/j.ins.2024.120950},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120950},
  shortjournal = {Inf. Sci.},
  title        = {Objective contribution decomposition method and multi-population optimization strategy for large-scale multi-objective optimization problems},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Secure intermittent impulsive consensus control for
fractional-order multiagent systems under denial-of-service and
deception attacks. <em>ISCI</em>, <em>678</em>, 120949. (<a
href="https://doi.org/10.1016/j.ins.2024.120949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the secure consensus problem of fractional-order multiagent systems (FOMASs) under denial-of-service (DoS) and deception attacks in the intermittent impulsive control framework. Unlike previous cyber attack models, the multiple attacks are considered, which the agent-to-agent communication channels and the controller-to-actuator channels are randomly subjected to deception and DoS attacks, respectively. Some random variables that follow the Bernoulli distribution are proposed, which are related to the communication channels between adjacent agents to describe deceptive attack behavior. To reduce control costs and resist cyber attacks, a novel intermittent impulsive control strategy is designed to make the FOMASs achieve consensus faster, when DoS attacks are sleeping. The designed intermittent impulsive control includes the advantages of discrete sampling control and intermittent control, which means that it can reduce the injection of erroneous data by constraining the frequency of information transmission. Furthermore, some sufficient criteria including the parameters of multiple attacks are yielded to ensure mean-square quasi-consensus of FOMASs. Finally, two examples are provided to validate the rationality for the presented security control method in this study from the perspective of numerical simulation experiments.},
  archive      = {J_ISCI},
  author       = {Taotao Hu and Xiaojun Zhang and Kaibo Shi},
  doi          = {10.1016/j.ins.2024.120949},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120949},
  shortjournal = {Inf. Sci.},
  title        = {Secure intermittent impulsive consensus control for fractional-order multiagent systems under denial-of-service and deception attacks},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dissipative sliding mode tracking control for discrete-time
singular t-s fuzzy systems via a preview target mechanism.
<em>ISCI</em>, <em>678</em>, 120946. (<a
href="https://doi.org/10.1016/j.ins.2024.120946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on the dissipative sliding mode preview tracking control (SMPTC) of discrete-time singular T-S fuzzy systems (STSFSs) via a preview target mechanism. Due to the presence of singular matrix and input matrices with fuzzy rules in the system, the existing preview control approaches cannot be directly adopted. As a result, a novel singular augmented error system (AES) is derived based on a general method. Furthermore, the tracking problem has been translated into the stabilisation of singular AES. A linear sliding mode surface (SMS) is proposed for singular AES, and a suitably SMPTC law is presented. Sufficiency conditions for relaxation are derived to guarantee that the sliding mode dynamics is admissible with the dissipative criterion, and the sliding mode region (SMR) can be reached. The difference singular matrix is fully considered in the whole design process such that the derived conditions can be checked easily. Finally, two examples have shown the effective tracking of the original output signal of system by utilising the proposed SMPTC law.},
  archive      = {J_ISCI},
  author       = {Zufeng Peng and Junchao Ren},
  doi          = {10.1016/j.ins.2024.120946},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120946},
  shortjournal = {Inf. Sci.},
  title        = {Dissipative sliding mode tracking control for discrete-time singular T-S fuzzy systems via a preview target mechanism},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A switching approach to repetitive control for takagi-sugeno
fuzzy systems. <em>ISCI</em>, <em>678</em>, 120944. (<a
href="https://doi.org/10.1016/j.ins.2024.120944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Repetitive control has learning properties and exhibits high accuracy in periodic control but struggles with nonlinearities and disturbances. To address this issue, the study presents a composite method of repetitive control and equivalent input disturbance based on the Takagi-Sugeno fuzzy model. The control structure takes into account both the continuous-discrete two-dimensional characteristics of the repetitive control and the membership function of the fuzzy system. As the first component of the control configuration, a repetitive controller is adopted for the high-precision tracking of periodic references. Then, an equivalent-input-disturbance estimator is used to compensate for exogenous disturbances. The closed-loop system is stabilized using the state feedback and the state observer. To ensure stability, membership function-dependent Lyapunov candidates are used to derive a less conservative stability condition. Consequently, all gains in the controller switch with the derivative sign of the premise variables. Finally, the developed approach is validated through comparisons with typical methods, demonstrating its effectiveness and advantages.},
  archive      = {J_ISCI},
  author       = {Shengnan Tian and Kang-Zhi Liu and Manli Zhang and Chengda Lu and Min Wu and Jinhua She},
  doi          = {10.1016/j.ins.2024.120944},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120944},
  shortjournal = {Inf. Sci.},
  title        = {A switching approach to repetitive control for takagi-sugeno fuzzy systems},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust graph embedding via attack-aid graph denoising.
<em>ISCI</em>, <em>678</em>, 120942. (<a
href="https://doi.org/10.1016/j.ins.2024.120942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of graphs directly affects the result of graph embedding since most existing models are vulnerable and highly sensitive to harmful/missing edges and imperceptible attacks. In this study, we propose a new robust graph embedding approach from a different point of view: Attack-aid Graph Denoising (AGD). AGD mitigates the impact of harmful and missing edges by leveraging adversarial attacks. Initially, AGD generates some auxiliary attacks on the topology by investigating their harm to classification accuracy. Subsequently, we derive a denoised adjacency matrix by removing these similar harmful edges and supplementing missing edges with flipping operations. Finally, we further extract the knowledge of topology to eliminate the influence of remaining harmful edges on the final embedding with Kullback-Leibler divergence. Extensive experiments have demonstrated that AGD not only shows its superiority over many state-of-the-art algorithms on the classification tasks but is also robust to various attacks.},
  archive      = {J_ISCI},
  author       = {Zhili Qin and Han Wang and Zhongjing Yu and Qinli Yang and Junming Shao},
  doi          = {10.1016/j.ins.2024.120942},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120942},
  shortjournal = {Inf. Sci.},
  title        = {Robust graph embedding via attack-aid graph denoising},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time series clustering based on polynomial fitting and
multi-order trend features. <em>ISCI</em>, <em>678</em>, 120939. (<a
href="https://doi.org/10.1016/j.ins.2024.120939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series clustering serves as a potent data mining method, facilitating the analysis of an extensive array of time series data without the prerequisite of any prior knowledge. It finds wide-ranging use across various sectors, including but not limited to, financial and medical data analysis, and sensor data processing. Given the high dimensionality, non-linearity, and redundancy characteristics associated with time series, conventional clustering algorithms frequently fall short in yielding satisfactory results when directly applied to this kind of data. As such, there is a critical need to judiciously select suitable feature extraction methods and dimension reduction techniques. This paper introduces a time series clustering algorithm, drawing primarily from polynomial fitting derivative features as a wellspring for feature extraction to achieve effective clustering results. Initially, Hodrick Prescott (HP) filtering comes into play for the processing of raw time series data, thereby eliminating noise and redundancy. Subsequently, polynomial curve fitting (PCF) is applied to the data to derive a globally continuous function fitting this time series. Next, by securing multi-order derivative values via this function, the time series is transformed into a multi-order derivative feature sequence. Lastly, we designed a polynomial function derivative features-based dynamic time warping (PFD_DTW) algorithm for determining the distance between two equal or unequal granular length time series, and subsequently a hierarchical clustering method anchored on the PFD_DTW distances for time series clustering after computing interspecies distances. The effectiveness of this method is corroborated by experimental results obtained from several practical datasets.},
  archive      = {J_ISCI},
  author       = {Yun Kang and Chongyan Wu and Bin Yu},
  doi          = {10.1016/j.ins.2024.120939},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120939},
  shortjournal = {Inf. Sci.},
  title        = {Time series clustering based on polynomial fitting and multi-order trend features},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatial-temporal graph transformer for object tracking
against noise spoofing interference. <em>ISCI</em>, <em>678</em>,
120936. (<a href="https://doi.org/10.1016/j.ins.2024.120936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving accurate object tracking against noise spoofing interference caused by similar backgrounds, similar objects, occlusion, or illumination variations is a challenge, especially since Siamese trackers largely ignore the spatial-temporal and part-level information of object structure. To handle this problem, we present a novel object tracking network with spatial-temporal awareness, which learns the correlation of local feature changes and extracts global spatial-temporal fusion features of the object to prevent noise spoofing interference. Specifically, our tracker integrates an object graph reconstruction representation module and a spatial-temporal graph Transformer module. The graph reconstruction representation module models the object structure and search region as part-to-part graph node correspondences, propagating object information to achieve part-level feature aggregation in the search region. The proposed spatial-temporal graph Transformer module fuses the temporal and spatial features of the object to enhance the contextual features and correlation between temporal and spatial feature variations, recognizing the noise spoofing interference to enhance the tracking performance. Meanwhile, our tracker learns object motion information to improve object state awareness, enhancing tracking accuracy under similar objects interference. Extensive experiments on six public datasets validate that our tracker outperforms related state-of-the-art trackers and achieves accurate tracking results against noise spoofing interference.},
  archive      = {J_ISCI},
  author       = {Ning Li and Haiwei Sang and Jiamin Zheng and Huawei Ma and Xiaoying Wang and Fu&#39;an Xiao},
  doi          = {10.1016/j.ins.2024.120936},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120936},
  shortjournal = {Inf. Sci.},
  title        = {Spatial-temporal graph transformer for object tracking against noise spoofing interference},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comprehensive consensus representation learning for
incomplete multiview subspace clustering. <em>ISCI</em>, <em>678</em>,
120935. (<a href="https://doi.org/10.1016/j.ins.2024.120935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete multiview clustering (IMVC) aims to address clustering problems caused by missing views. While some progress has been made, the current approaches still have some problems. First, the existing IMVC methods excessively rely on the original high-dimensional multiview data, leading to suboptimal results when the data are heavily contaminated. Second, the utilization of high-dimensional data often overlooks the complementarity of and consistency across multiple views. Third, the cluster structure of the input data is not adequately considered, which is detrimental to the resulting clustering performance. To address these problems, we propose a novel method: comprehensive consensus representation learning for incomplete multiview subspace clustering (CLR-IMVC). Specifically, CLR-IMVC assumes that all views are generated from a latent representation space. We model the original incomplete multiple views and the latent space to explore their correlations. Subsequently, we use the latent space to generate complete views and construct a subspace self-representation matrix for each view. Moreover, we innovatively treat the latent representation itself as new a view and likewise extract its self-representation matrix. Furthermore, we construct a third-order tensor by using these self-representation matrices and impose low-rank constraints on the tensor to explore the high-order correlations among the matrices. In addition, a consensus representation learning term is added to explore the consistency information between the views and the latent space, ultimately generating a robust clustering structure. Finally, the proposed method can be effectively solved by the augmented Lagrangian multiplier (ALM). Extensive experiments conducted on diverse datasets demonstrate the effectiveness of CLR-IMVC.},
  archive      = {J_ISCI},
  author       = {Xiaoxing Guo and Gui-Fu Lu},
  doi          = {10.1016/j.ins.2024.120935},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120935},
  shortjournal = {Inf. Sci.},
  title        = {Comprehensive consensus representation learning for incomplete multiview subspace clustering},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024e). PPMGS: An efficient and effective solution for distributed
privacy-preserving semi-supervised learning. <em>ISCI</em>,
<em>678</em>, 120934. (<a
href="https://doi.org/10.1016/j.ins.2024.120934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, distributed semi-supervised learning has attracted increasing research attention due to its tremendous practical value. A promising distributed semi-supervised learning method should not only achieve desirable classification performance but also protect data privacy in distributed scenarios. Existing approaches typically capture the similarities between data instances with privacy-preserving computations. This paradigm introduces extra computation and heuristic changes to the algorithm, resulting in sub-optimal solutions that are time-consuming. In current distributed semi-supervised learning, instance similarities are widely used to capture the underlying manifold or guide label propagation. This paper emphasizes that instance similarities are not necessary because the structure of data connections can be estimated using coarser-grained information. We propose a Privacy-preserving Mixture-distribution based Graph Smoothing (PPMGS) model for distributed privacy-preserving semi-supervised learning. Our motivation is to construct a graph based on a Gaussian mixture distribution instead of individual data instances, which better captures the underlying data distribution and improves model efficiency. PPMGS includes a privacy-preserving expectation-maximization (EM) phase to estimate the Gaussian mixture distribution depicting the input data and a mixture-distribution-based graph smoothing algorithm to learn a distribution-based classifier by fitting a few labeled samples. Experimental results show that the proposed PPMGS achieves 5%-10% higher accuracy and macro-F1 than state-of-the-art privacy-preserving semi-supervised learning methods. In terms of efficiency, it reduces time cost by 97% and communication cost by 96% in the most complex dataset. The numerical results demonstrate that our proposal outperforms state-of-the-art baselines in both efficiency and effectiveness.},
  archive      = {J_ISCI},
  author       = {Zhi Li and Chaozhuo Li and Zhoujun Li and Jian Weng and Feiran Huang and Zhibo Zhou},
  doi          = {10.1016/j.ins.2024.120934},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120934},
  shortjournal = {Inf. Sci.},
  title        = {PPMGS: An efficient and effective solution for distributed privacy-preserving semi-supervised learning},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synchronization-based semi-supervised data streams
classification with label evolution and extreme verification delay.
<em>ISCI</em>, <em>678</em>, 120933. (<a
href="https://doi.org/10.1016/j.ins.2024.120933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The critical need for classifying streaming data arises from its widespread use in real-world industries, where analyzing continuous, dynamic, and evolving data streams accurately and promptly is essential for informed decision-making and gaining predictive insights. Existing research mainly focuses on abundant supervision, overlooking the scarcity and delayed availability of labels, which can vary in timing. Addressing this, the article introduces a new learning method that employs a synchronization-based core support extraction technique. This technique is designed to manage changing concepts and delayed partial labeling by extracting key data points that act as pseudo-labels. Thanks to the concept of synchronization, these extracted key data points accurately represent the inherent local cluster structure in an intuitive manner and better maintain the class structure. Consequently, these pseudo-labels are utilized for classifying future incoming data batches. Furthermore, the method incorporates a knowledge base to summarize and represent all incoming streaming data. Building upon this knowledge base, an ensemble model for classification and an efficient new class detector are proposed. Both operate in a local fashion to ensure robust learning, even in complex class distributions. Evaluations on benchmark datasets reveal a consistent performance lead, surpassing established algorithms by up to 10%, achieving state-of-the-art results.},
  archive      = {J_ISCI},
  author       = {Salah Ud Din and Qinli Yang and Junming Shao and Cobbinah B. Mawuli and Aman Ullah and Waqar Ali},
  doi          = {10.1016/j.ins.2024.120933},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120933},
  shortjournal = {Inf. Sci.},
  title        = {Synchronization-based semi-supervised data streams classification with label evolution and extreme verification delay},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fixed-time synchronization of discontinuous proportional
delay inertial neural networks with uncertain parameters. <em>ISCI</em>,
<em>678</em>, 120931. (<a
href="https://doi.org/10.1016/j.ins.2024.120931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of fixed-time synchronization (FXS) for an assortment of discontinuous proportional delay inertial neural networks (DPDINNs) with uncertain parameters is addressed in this research. Through the utilization of fixed-time stability theory, reduced and non-reduced methods, constructing Lyapunov functionals (LFs), we establish two different control strategies to implement synchronization of DPDINNs with uncertain parameters in fixed-time. The appropriate synchronization criteria for algebraic inequalities conditions and settling times (STs) are derived. These criteria are less complicated and more convenient to verify than the calculation of matrix inequalities conditions. At last, we provide two numerical instances to confirm that our conclusions are accurate.},
  archive      = {J_ISCI},
  author       = {Yan Wan and Liqun Zhou},
  doi          = {10.1016/j.ins.2024.120931},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120931},
  shortjournal = {Inf. Sci.},
  title        = {Fixed-time synchronization of discontinuous proportional delay inertial neural networks with uncertain parameters},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Recursive state estimation for two-dimensional systems over
decode-and-forward relay channels: A local minimum-variance approach.
<em>ISCI</em>, <em>678</em>, 120928. (<a
href="https://doi.org/10.1016/j.ins.2024.120928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper is concerned with the recursive state estimation problem for a class of two-dimensional systems over decode-and-forward relay channels subject to packet dropouts. Taking into account the sensor&#39;s limited transmission ability, a decode-and-forward relay is deployed between the sensor and the remote estimator to enlarge the propagation distance and improve the communication quality. The packet dropout phenomenon is described by two sequences of mutually uncorrelated random variables that obey Bernoulli distributions. The main objective of this paper is to design a recursive state estimator for the underlying system with guaranteed estimation performance. An upper bound on the estimation error variance is firstly derived by resorting to some coupled difference equations, and then such an upper bound is locally optimized at each iteration through proper design of the estimator gain. Furthermore, the impacts of the packet dropouts and the decode-and-forward relay on the estimation performance are evaluated with rigorously theoretical analysis. Finally, an illustrative example is presented to validate the effectiveness of the proposed estimation scheme.},
  archive      = {J_ISCI},
  author       = {Fan Wang and Zidong Wang and Jinling Liang and Quanbo Ge and Steven X. Ding},
  doi          = {10.1016/j.ins.2024.120928},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120928},
  shortjournal = {Inf. Sci.},
  title        = {Recursive state estimation for two-dimensional systems over decode-and-forward relay channels: A local minimum-variance approach},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dynamic multi-objective evolutionary algorithm based on
mahalanobis distance and intra-cluster individual correlation
rectification. <em>ISCI</em>, <em>678</em>, 120922. (<a
href="https://doi.org/10.1016/j.ins.2024.120922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Responding quickly and accurately to environmental changes is a challenge in addressing dynamic multi-objective optimization problems (DMOPs). Although many dynamic multi-objective evolutionary algorithms (DMOEAs) have demonstrated impressive performance, there is still room for improvement in accurately predicting population behavior. To address this limitation, this paper proposes a prediction strategy based on Mahalanobis distance and intra-cluster individual correlation rectification (MCIR) to deal with DMOPs. First, a manifold clustering method is used to partition the Pareto set of the population into subpopulations, in which individuals with similar movement trends are grouped into clusters. Second, the Mahalanobis distance is introduced to systematically measure the relationships between clusters in adjacent environments. Time series models are established for each cluster center to predict their positions in the neighboring environment. On this basis, the movement characteristics of individuals within clusters are further rectified by calculating the correlation between intra-cluster individuals and the cluster center, facilitating more accurate tracking of the changing Pareto set/Pareto front. Finally, Gaussian noise is introduced to ensure the diversity of new individuals. The effectiveness of the MCIR algorithm is demonstrated by comparing it with four DMOEAs using 18 test instances. Experimental results confirm that MCIR holds great promise in addressing DMOPs.},
  archive      = {J_ISCI},
  author       = {Fangzhen Ge and Xing Hou and Debao Chen and Longfeng Shen and Huaiyu Liu},
  doi          = {10.1016/j.ins.2024.120922},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120922},
  shortjournal = {Inf. Sci.},
  title        = {A dynamic multi-objective evolutionary algorithm based on mahalanobis distance and intra-cluster individual correlation rectification},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). MOREM: An evolutionary multitasking optimization algorithm
for multi-objective recommendations. <em>ISCI</em>, <em>678</em>,
120921. (<a href="https://doi.org/10.1016/j.ins.2024.120921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective evolutionary algorithms (MOEAs) have been successfully applied in recommender systems, where the recommendation is modeled as a multi-objective optimization problem by considering both accuracy and non-accuracy metrics. However, to recommend to all users, the population individuals in most of the exiting MOEA-based recommendation algorithms are usually encoded in the form of matrix encoding, and with the increased number of users and items, it will lead to a large search space. To this end, in this paper, we propose a novel evolutionary multitasking algorithm MOREM to tackle the challenge of multi-objective recommendations, where a related auxiliary task is constructed by both user and item reduction to help solving the complex original task by knowledge transfer. Specifically, a task generation strategy for creating auxiliary task is firstly proposed to cluster users by user-rating information (i.e., user reduction), where only a part of important items (i.e., item reduction) are recommended for the central user within each cluster with the aim to greatly reduce the size of the matrix encoding. In addition, a novel knowledge transfer mechanism is proposed, which can effectively achieve knowledge migration between the two tasks. Experimental results on real-world datasets show that MOREM outperforms several state-of-the-art algorithms for multi-objective recommendations.},
  archive      = {J_ISCI},
  author       = {Lei Zhang and Sibo Liu and Haipeng Yang and Zihao Chen and Hongke Zhao},
  doi          = {10.1016/j.ins.2024.120921},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120921},
  shortjournal = {Inf. Sci.},
  title        = {MOREM: An evolutionary multitasking optimization algorithm for multi-objective recommendations},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quality and recognizability estimation video encryption
database. <em>ISCI</em>, <em>678</em>, 120919. (<a
href="https://doi.org/10.1016/j.ins.2024.120919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In literature about selective encryption of image and video content, image quality indices are usually used to gauge the degree of encryption. These methods have frequently been shown not to work well for the evaluation of encryption, mainly due to them being trained on predominantly high quality contents. The problem for creating a proper recognition index or visual encryption strength index is the lack of data to train on. In this paper we present the first database of encrypted video content, ranging from high quality to completely unrecognizable, together with human observer scores for quality and recognizability. We also provide a basic evaluation of visual quality indices on this database, directly and in different combination by fusion, to showcase that currently image and video quality indices are ill fit for the purpose of estimating video encryption strength/recognizably. This inability of quality indices to perform also showcases that this database fills the required blind spot of currently available data.},
  archive      = {J_ISCI},
  author       = {Heinz Hofbauer and Florent Autrusseau and Andreas Uhl},
  doi          = {10.1016/j.ins.2024.120919},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120919},
  shortjournal = {Inf. Sci.},
  title        = {Quality and recognizability estimation video encryption database},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An enhanced NSGA-II and a fast constraint repairing method
for combined heat and power dynamic economic emission dispatch.
<em>ISCI</em>, <em>678</em>, 120915. (<a
href="https://doi.org/10.1016/j.ins.2024.120915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an enhanced NSGA-II (ENSGA-II) is presented for the combined heat and power dynamic economic emission dispatch (CHPDEED). ENSGA-II produces offspring individuals by a novel crossover of the Cauchy distribution with adaptive location and scale parameters. It can not only sufficiently explore and exploit the decision space but also remain a relatively high population diversity. Also, ENSGA-II adopts a modified crowding distance to penalize crowded individuals, seeking to evenly distribute the individuals in the objective space. In addition, a fast constraint repairing method (FCRM) is proposed to significantly reduce the constraint violations and guide infeasible individuals to move towards feasible zones rapidly. The proposed ENSGA-II is applied to a number of multi-objective optimization problems and compared with the other eight multi-objective evolutionary algorithms (MOEAs). ENSGA-II is found to produce better results on most problems, such as smaller inverse generational distances, larger hypervolumes, larger coverage rates and smaller spacings. Therefore, ENSGA-II can obtain a satisfactory Pareto set with broad spread, high diversity, strong convergence and good evenness, and it is an efficient alternative for CHPDEED.},
  archive      = {J_ISCI},
  author       = {Dexuan Zou and Lejie Ma and Can Li},
  doi          = {10.1016/j.ins.2024.120915},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120915},
  shortjournal = {Inf. Sci.},
  title        = {An enhanced NSGA-II and a fast constraint repairing method for combined heat and power dynamic economic emission dispatch},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synergistic graph fusion via encoder embedding.
<em>ISCI</em>, <em>678</em>, 120912. (<a
href="https://doi.org/10.1016/j.ins.2024.120912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a method called graph fusion embedding, designed for multi-graph embedding with shared vertex sets. Under the framework of supervised learning, our method exhibits a remarkable and highly desirable synergistic effect: for sufficiently large vertex size, the accuracy of vertex classification consistently benefits from the incorporation of additional graphs. We establish the mathematical foundation for the method, including the asymptotic convergence of the embedding, a sufficient condition for asymptotic optimal classification, and the proof of the synergistic effect for vertex classification. Our comprehensive simulations and real data experiments provide compelling evidence supporting the effectiveness of our proposed method, showcasing the pronounced synergistic effect for multiple graphs from disparate sources.},
  archive      = {J_ISCI},
  author       = {Cencheng Shen and Carey Priebe and Jonathan Larson and Ha Trinh},
  doi          = {10.1016/j.ins.2024.120912},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120912},
  shortjournal = {Inf. Sci.},
  title        = {Synergistic graph fusion via encoder embedding},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The topological space of schur-concave copulas is
homeomorphic to the hilbert cube. <em>ISCI</em>, <em>678</em>, 120909.
(<a href="https://doi.org/10.1016/j.ins.2024.120909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Schur-concave copulas, a distinct subclass of copulas, have emerged as a crucial component in recent advancements of copula theory. In this paper, we employ techniques from infinite-dimensional topology to investigate the topological structure of the space of all Schur-concave copulas equipped with the uniform metric and its topological position in the (symmetric) copula space. Moreover, we show that there exists a homeomorphism from the copula space onto the Hilbert cube, which relates the symmetric copula space onto an end of the Hilbert cube and relates the Schur-concave copula space onto an end of the end of the Hilbert cube. As a consequence, the Schur-concave copula space has the fixed point property. Furthermore, we show that a subset of the family of all associative copulas is a Z -set in the Schur-concave copula space if and only if it is compact.},
  archive      = {J_ISCI},
  author       = {Dongming Liu},
  doi          = {10.1016/j.ins.2024.120909},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120909},
  shortjournal = {Inf. Sci.},
  title        = {The topological space of schur-concave copulas is homeomorphic to the hilbert cube},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Measuring the centrality of nodes in networks based on the
interstellar model. <em>ISCI</em>, <em>678</em>, 120908. (<a
href="https://doi.org/10.1016/j.ins.2024.120908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring the centrality of nodes in a network is a vital and significant task in analyzing the influence of nodes and information dissemination. Existing methods measure the centrality of nodes mainly from local, global and semi-global network perspectives. Currently, semi-global centrality metrics are valued due to the fact that they can achieve high accuracy close to that of global centrality metrics with a slight increase in time complexity over local centrality metrics. In this paper, a novel semi-global centrality metric based on the interstellar model is proposed. First, an interstellar model of information dissemination is constructed and a variable velocity is set for the information after it leaves the source node, while velocity at which the information arrives at the next node determines whether the information can be further forwarded. Then, the attraction slingshot effect is considered to express the facilitation provided by the nodes that forward the information. The centrality of a node can be measured by the number of all nodes, including itself, that can forward the information sent by that node. Experiments with some popular centrality metrics are conducted on some real-world networks, and the results show that the proposed centrality metric has better performance without significant increase in time complexity, and also provides a plausible explanation for information forwarding.},
  archive      = {J_ISCI},
  author       = {Kuo Chi and Ning Wang and Ting Su and Yongqin Yang and Hui Qu},
  doi          = {10.1016/j.ins.2024.120908},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120908},
  shortjournal = {Inf. Sci.},
  title        = {Measuring the centrality of nodes in networks based on the interstellar model},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A utility-based three-way group decision consensus model
with overlapping subgroups. <em>ISCI</em>, <em>678</em>, 120904. (<a
href="https://doi.org/10.1016/j.ins.2024.120904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a relative utility function-based consensus method for three-way group decision (TWGD) in a social network scenario where overlapping subgroups and non-overlapping subgroups co-exist. Firstly, we construct a three-way decision (TWD) model rooted in utility theory, which proposes a novel objective calculation method for the relative utility functions based on evaluation values. The relative utility matrices of decision makers (DMs) are derived on this basis. Secondly, a utility and trust-driven overlapping clustering algorithm is designed to maximize the overall trust level and the difference between subgroup clustering centers, aiming to divide the group into several manageable subgroups. In addition, we identify contrarian DMs, triggering a delegation-exit mechanism, and determine the weights of subgroups and DMs. Thirdly, a three-way group consensus decision model is formulated to provide targeted adjustment strategies for different types of DMs. To improve group consensus, we address the influence of key DMs on the opinions of overlapping subgroups with a minimum adjustment consensus model. Finally, we demonstrate the feasibility and scientificity of the proposed method through the illustrative example, sensitivity analysis, and comparative analysis.},
  archive      = {J_ISCI},
  author       = {Yanxin Xu and Yanbing Ju and Zaiwu Gong and Junpeng Sun and Peiwu Dong and Carlos Porcel and Enrique Herrera-Viedma},
  doi          = {10.1016/j.ins.2024.120904},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120904},
  shortjournal = {Inf. Sci.},
  title        = {A utility-based three-way group decision consensus model with overlapping subgroups},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new sensitivity analysis method for decision-making with
multiple parameters modification. <em>ISCI</em>, <em>678</em>, 120902.
(<a href="https://doi.org/10.1016/j.ins.2024.120902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today&#39;s world, addressing multi-criteria decision problems presents a considerable challenge due to their inherent complexity. Decision-makers face diverse and often conflicting factors that exceed their analytical capabilities and complicate the identification of the best solutions. Within this intricate field, Multi-Criteria Decision Analysis (MCDA) serves as an important decision support tool. The complex nature of these problems introduces numerous variables that influence the final choice. This complexity requires sensitivity analysis as an indispensable part of the assessment process. It allows for an examination of how changes in input data can affect the outcomes, providing valuable insights into the stability and reliability of the decision-making process. Based on the state-of-the-art, this study identifies a gap in sensitivity analysis, particularly in assessing the impact of modifications to the decision matrix. Although one-at-a-time (OAT) modification is efficient, simultaneously changing multiple elements provides nuanced insights into decision-matrix interdependencies. Therefore, this research introduces a novel sensitivity analysis method, the COMprehensive Sensitivity Analysis Method (COMSAM), which systematically modifies multiple values within the decision matrix. The COMSAM allows for a detailed problem space exploration, providing insights into alterations across criteria values. Furthermore, the method represents the preferences obtained from the evaluations as interval numbers, offering decision makers additional knowledge about the uncertainty of the analyzed problem. This study advances the field of sensitivity analysis, providing a new perspective on changes in multiple values&#39; simultaneous influence on the robustness of the MCDA result.},
  archive      = {J_ISCI},
  author       = {Jakub Więckowski and Wojciech Sałabun},
  doi          = {10.1016/j.ins.2024.120902},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120902},
  shortjournal = {Inf. Sci.},
  title        = {A new sensitivity analysis method for decision-making with multiple parameters modification},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BAP: Bilateral asymptotic pruning for optimizing CNNs on
image tasks. <em>ISCI</em>, <em>678</em>, 120898. (<a
href="https://doi.org/10.1016/j.ins.2024.120898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pruning facilitates the acquisition of efficient convolutional neural networks (CNNs) tailored for resource-limited environments. General pruning strategies for CNNs are typically based on the characteristics of filters or their generated feature maps. These strategies assume that the similarity between these elements remains highly consistent. Nevertheless, our analysis has shown that this assumption does not always hold, potentially causing pruning methods to misjudge parameter redundancy. It may erroneously remove crucial network parameters, leading to severe performance loss after network compression. This paper proposes a novel method termed Bilateral Asymptotic Pruning (BAP) for channel optimization. BAP conducts density-based clustering on filters and corresponding feature maps separately to identify redundancy. The resulting sets of channel numbers are then fused for bilateral collaborative pruning. Additionally, we present an exponential moving average method with a logarithmic reduction to mitigate the effects of pruning errors on performance. Finally, the compressing rate of networks gradually increases during the asymptotic process, thereby allowing for the precise generation of pruned networks of different sizes in a single experiment. Extensive experiments demonstrate that our BAP outperforms many state-of-the-art methods. For instance, BAP reduces 51.56% parameters and 59.90% FLOPs 1 of ResNet-50 with only 0.5% TOP-5 accuracy loss on ImageNet.},
  archive      = {J_ISCI},
  author       = {Jingfei Chang and Liping Tao and Bo Lyu and Xiangming Zhu and Shanyun Liu and Qiaosha Zou and Hongyang Chen},
  doi          = {10.1016/j.ins.2024.120898},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120898},
  shortjournal = {Inf. Sci.},
  title        = {BAP: Bilateral asymptotic pruning for optimizing CNNs on image tasks},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Defending against similarity shift attack for EaaS via
adaptive multi-target watermarking. <em>ISCI</em>, <em>678</em>, 120893.
(<a href="https://doi.org/10.1016/j.ins.2024.120893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models have revolutionized natural language processing, leading to the emergence of Embedding as a Service (EaaS). While EaaS facilitates access to advanced embedding models, it also presents challenges in copyright protection. Current research primarily relies on single-target watermarking frameworks, where a predefined vector is integrated as a watermark into text embeddings. However, these approaches are vulnerable to watermark information leakage. To investigate this issue, we introduce the Embedding Similarity Shift Attack (ESSA), an innovative attack algorithm designed to detect trigger instances in single-target watermarking systems by analyzing similarity shifts among constructed reference sentence pairs. Additionally, to defend against such an attack, we propose Adaptive Multi-Target Watermarking (AMT-WM). AMT-WM stands as the pioneering multi-target watermarking method aimed at safeguarding the copyright of EaaS. Specifically, AMT-WM constructs multiple watermarks through the utilization of orthogonal vectors to mitigate selection bias towards a particular vector. Furthermore, it incorporates a randomly selected sentence embedding as the base embedding to enhance the confidentiality of backdoored embeddings. For multi-target watermarking, we implement adaptive watermark injection and validation based on similarity. Comprehensive experiments conducted on various datasets validate the effectiveness of ESSA in trigger detection performance and the efficacy of AMT-WM in copyright protection. Our code will be available soon.},
  archive      = {J_ISCI},
  author       = {Zuopeng Yang and Pengyu Chen and Tao Li and Kangjun Liu and Yuan Huang and Xin Lin},
  doi          = {10.1016/j.ins.2024.120893},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120893},
  shortjournal = {Inf. Sci.},
  title        = {Defending against similarity shift attack for EaaS via adaptive multi-target watermarking},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Worthiness benchmark: A novel concept for analyzing binary
classification evaluation metrics. <em>ISCI</em>, <em>678</em>, 120882.
(<a href="https://doi.org/10.1016/j.ins.2024.120882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary classification deals with identifying whether elements belong to one of two possible categories. Various metrics exist to evaluate the performance of such classification systems. It is important to study and contrast these metrics to find the best one for assessing a particular system. Despite extensive research in this field, a particular systematic comparison of these evaluation metrics remains an unaddressed area. The performance of a classifier is usually evaluated through the confusion matrix, a table including the count of accurate and inaccurate predictions for each category. To judge if one classifier is better than another, examining variations in the confusion matrix is necessary. However, no agreed-upon method exists for this analysis. This is crucial because different metrics may interpret and rate two confusion matrices differently. We introduce the Worthiness Benchmark ( γ ), a new concept useful to characterize the principles by which performance metrics rank classifiers. In particular, the Worthiness Benchmark is useful to assess how a metric evaluates the superiority among two classifiers by analyzing differences in their confusion matrices. Through this new concept, we are able to deal with the main challenge of selecting the best metric to evaluate a classifier. We then perform a γ -analysis on several binary classification metrics to outline the specific benchmarks these metrics follow when comparing different classifiers.},
  archive      = {J_ISCI},
  author       = {Mohammad Shirdel and Mario Di Mauro and Antonio Liotta},
  doi          = {10.1016/j.ins.2024.120882},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120882},
  shortjournal = {Inf. Sci.},
  title        = {Worthiness benchmark: A novel concept for analyzing binary classification evaluation metrics},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DEDC-IMAE: A deep evolutionary document clustering model
with inherited mixed autoencoder. <em>ISCI</em>, <em>678</em>, 120880.
(<a href="https://doi.org/10.1016/j.ins.2024.120880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep document clustering has been increasingly attracting interest. However, the design of existing deep document clustering methods is limited to processing only static document datasets because applying these methods to dynamic text documents is challenging as the underlying topics of document datasets are not static but evolve. Deep models must learn the cluster-level representations that are inherited. Thus, methods must be explored to implement the inheritance of cluster-level representations. In this study, we overcome the aforementioned challenges and propose a deep evolutionary document clustering model with an inherited mixed autoencoder (DEDC-IMAE), to discover evolutionary document structures with evolutionary topics in dynamic document datasets. An inherited mixed autoencoder (IMAE) is designed to learn an evolutionary semantic representation of each document considering both the inherited historical topic semantics and the document&#39;s own characteristics, to reflect the evolved topic semantics. Using the document evolutionary semantics, a deep evolutionary document clustering (DEDC) module is then investigated to learn a clustering partition that reflects the characteristics of document datasets. Experimental results on a real evolutionary text document dataset showed that DEDC-IMAE achieves better evolutionary clustering results than a variety of baseline models.},
  archive      = {J_ISCI},
  author       = {Hui Lu and Ziyang Cheng and Ruizhang Huang and Yongbin Qin and Yanping Chen and Chuan Lin and Jingjing Xue},
  doi          = {10.1016/j.ins.2024.120880},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120880},
  shortjournal = {Inf. Sci.},
  title        = {DEDC-IMAE: A deep evolutionary document clustering model with inherited mixed autoencoder},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal fuzzy event-triggered fault-tolerant control of
fractional-order nonlinear stochastic systems. <em>ISCI</em>,
<em>678</em>, 120877. (<a
href="https://doi.org/10.1016/j.ins.2024.120877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the optimal fuzzy fault-tolerant control issue for fractional-order nonlinear stochastic systems (FONSS) using event-triggered mechanisms with fractional-order derivative α ∈ ( 0 , 1 ) α∈(0,1) . First, in order to weaken the impacts of actuator and sensor faults, a fuzzy observer and augmented system are developed. Since stochastic disturbance can adversely affect stability, based on fractional Barbalat lemmas and Lyapunov theory, an adaptive fault-tolerant controller and the corresponding adaptive update law are designed to ensure the stability of FONSS. Then, the architecture of identifier-critic-actor NN, which is more concise than the traditional one, is described. This NN architecture recognizes unknown dynamics and completes control actions after evaluating the control performance, driving control toward optimization. Furthermore, the event-triggered mechanism is devised to save control resources and avoid Zeno behavior. Finally, simulation results demonstrate that under equivalent conditions, the proposed optimal event-triggered control reduces the number of information transmissions compared to traditional time-triggered control, saving communication resources and enhancing the overall control performance.},
  archive      = {J_ISCI},
  author       = {Yuqing Yan and Huaguang Zhang and Jiayue Sun and Zhongyang Ming},
  doi          = {10.1016/j.ins.2024.120877},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120877},
  shortjournal = {Inf. Sci.},
  title        = {Optimal fuzzy event-triggered fault-tolerant control of fractional-order nonlinear stochastic systems},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A reinforcement learning assisted evolutionary algorithm
for constrained multi-task optimization. <em>ISCI</em>, <em>678</em>,
120863. (<a href="https://doi.org/10.1016/j.ins.2024.120863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task optimization problems in the real world often contain constraints. When dealing with these problems, it is necessary to consider multiple tasks and their respective constraints simultaneously. However, most of existing research on multi-task optimization neglects the influence of constraints, which leads to slow convergence speed and susceptibility to local optima. To address the aforementioned issues, this paper proposes a reinforcement learning assisted constrained multi-task evolutionary algorithm. First, to meet the different requirements of different tasks and constraints, an adaptive operator selection strategy based on reinforcement learning is proposed. Second, to enhance population diversity, a multi-population method with different constraint handling techniques is introduced. This method assigns two independent populations to each task. The main population aims to find feasible solutions, while the auxiliary population focuses on exploring the entire search space. Finally, considering the individual differences between tasks, a dimension-based knowledge transfer is employed to facilitate positive information exchange. Compared with other state-of-the-art constrained evolutionary algorithms, the experimental results on constrained multi-task benchmark suite demonstrate the superiority of the proposed algorithm. The source code can be obtained from https://github.com/yufeiyng/RL-CMTEA .},
  archive      = {J_ISCI},
  author       = {Yufei Yang and Changsheng Zhang and Bin Zhang and Jiaxu Ning},
  doi          = {10.1016/j.ins.2024.120863},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120863},
  shortjournal = {Inf. Sci.},
  title        = {A reinforcement learning assisted evolutionary algorithm for constrained multi-task optimization},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive three-way KNN classifier using density-based
granular balls. <em>ISCI</em>, <em>678</em>, 120858. (<a
href="https://doi.org/10.1016/j.ins.2024.120858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The granular ball k-nearest neighbors (GBKNN) algorithm improves the efficiency and robustness of traditional k-nearest neighbors (KNN) by replacing point input with granular ball. However, in the generation process of granular balls by GBKNN, there may be unbalanced distribution of data points existed in some granular balls, which will cause more classification errors. In addition, the fixed value of k in GBKNN may also reduce the accuracy of classification. In order to address these issues, an adaptive three-way KNN classifier using density-based granular balls is proposed. Firstly, an improved density-based granular ball computing using density peak clustering is presented. This method introduces a refined threshold to subdivide the granular balls. Secondly, a data-driven neighborhood is defined to search the optimal k value and a density-based granular ball KNN (DBGBKNN) algorithm is proposed. Thirdly, by considering the fuzziness of the testing set in the classification process, the density-based granular ball KNN with three-way decision (DBGBKNN-3WD) is constructed. Finally, experimental results verify that DBGBKNN-3WD achieves high comprehensive score and low time complexity while maintaining less fuzziness loss than other algorithms.},
  archive      = {J_ISCI},
  author       = {Jie Yang and Juncheng Kuang and Guoyin Wang and Qinghua Zhang and Yanmin Liu and Qun Liu and Deyou Xia and Shuai Li and Xiaoqi Wang and Di Wu},
  doi          = {10.1016/j.ins.2024.120858},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120858},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive three-way KNN classifier using density-based granular balls},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Coping with AI errors with provable guarantees.
<em>ISCI</em>, <em>678</em>, 120856. (<a
href="https://doi.org/10.1016/j.ins.2024.120856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI errors pose a significant challenge, hindering real-world applications. This work introduces a novel approach to cope with AI errors using weakly supervised error correctors that guarantee a specific level of error reduction. Our correctors have low computational cost and can be used to decide whether to abstain from making an unsafe classification. We provide new upper and lower bounds on the probability of errors in the corrected system. In contrast to existing works, these bounds are distribution agnostic, non-asymptotic, and can be efficiently computed just using the corrector training data. They also can be used in settings with concept drifts when the observed frequencies of separate classes vary. The correctors can easily be updated, removed, or replaced in response to changes in distributions within each class without retraining the underlying classifier. The application of the approach is illustrated with two relevant challenging tasks: (i) an image classification problem with scarce training data, and (ii) moderating responses of large language models without retraining or otherwise fine-tuning.},
  archive      = {J_ISCI},
  author       = {Ivan Y. Tyukin and Tatiana Tyukina and Daniël P. van Helden and Zedong Zheng and Evgeny M. Mirkes and Oliver J. Sutton and Qinghua Zhou and Alexander N. Gorban and Penelope Allison},
  doi          = {10.1016/j.ins.2024.120856},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120856},
  shortjournal = {Inf. Sci.},
  title        = {Coping with AI errors with provable guarantees},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Practical fixed-time multi-group time-varying formation for
second-order multi-agent systems with actuator attacks and collision
avoidance. <em>ISCI</em>, <em>678</em>, 120821. (<a
href="https://doi.org/10.1016/j.ins.2024.120821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the fixed-time multi-group time-varying formation problem for second-order nonlinear multi-agent systems (MASs) is studied. It takes into account some factors such as actuator attacks, collision avoidance and Markov switching topology. Based on the presence of actuator attacks and other unknown nonlinearities, radial basis function neural network (RBFNN) is used to approximate these unknown functions. Following this, a distributed fixed-time RBF sliding manifold is proposed to enable the system to reach the desired state in a fixed time. Additionally, a collision-avoiding repulsive potential function is introduced to prevent agents from colliding with each other during the formation process. By combining these factors, a control strategy is proposed that can cope with switching topologies and enable all agents to achieve practical fixed-time multi-group formations. Finally, two examples are provided to demonstrate the feasibility of the control protocol.},
  archive      = {J_ISCI},
  author       = {Xisheng Zhan and Rongxiang Lu and Jie Wu and Huaicheng Yan},
  doi          = {10.1016/j.ins.2024.120821},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {120821},
  shortjournal = {Inf. Sci.},
  title        = {Practical fixed-time multi-group time-varying formation for second-order multi-agent systems with actuator attacks and collision avoidance},
  volume       = {678},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GGT-SNN: Graph learning and gaussian prior integrated
spiking graph neural network for event-driven tactile object
recognition. <em>ISCI</em>, <em>677</em>, 120998. (<a
href="https://doi.org/10.1016/j.ins.2024.120998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks possess asynchronous, discrete, and sparse characteristics that enable direct processing of event-based tactile sensor data and more efficient transmission of information. These networks have been widely applied in the tactile perception field. However, due to the sparsity of tactile data, these models are prone to generalization issues. Additionally, existing methods for tactile graph construction are constrained when spatially connecting high-dimensional tactile data, making it challenging for the model to fuse and process such information effectively. To address these challenges, we propose the GGT-SNN, which introduces a parameter estimation method with Gaussian priors to alleviate generalization problems caused by sparse tactile data. Furthermore, we design M-tree and Z-tree tactile graph construction methods to compensate for deficiencies of other approaches when handling high-dimensional tactile spatial connections. This approach enhances the model’s ability to efficiently process high-dimensional event-driven tactile information. We introduce an approximate LIF neuron activation function to enable backpropagation within the model and comprehensively compare and evaluate its performance against different approximate functions. The experimental results demonstrate that our proposed method performs significantly better than SOTA methods, exhibiting a 10.83 % improvement over TactileSGNet on the EvTouch-Containers dataset and a 2.92 % improvement over TactileSGNet on the EvTouch-Objects dataset.},
  archive      = {J_ISCI},
  author       = {Jing Yang and Zukun Yu and Shaobo Li and Yang Cao and JianJun Hu and Ji Xu},
  doi          = {10.1016/j.ins.2024.120998},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120998},
  shortjournal = {Inf. Sci.},
  title        = {GGT-SNN: Graph learning and gaussian prior integrated spiking graph neural network for event-driven tactile object recognition},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cournot policy model: Rethinking centralized training in
multi-agent reinforcement learning. <em>ISCI</em>, <em>677</em>, 120983.
(<a href="https://doi.org/10.1016/j.ins.2024.120983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work studies Centralized Training and Decentralized Execution (CTDE), which is a powerful mechanism to ease multi-agent reinforcement learning. Although the centralized evaluation ensures unbiased estimates of Q-value, peers with unknown policies make the decentralized policy far from the expectation. To make progress in more stabilized and effective joint policy, we develop a novel game framework, termed Cournot Policy Model, to enhance the CTDE-based multi-agent learning. Combining the game theory and reinforcement learning, we regard the joint decision-making in a single time step as a Cournot duopoly model, and then design a Hetero Variational Auto-Encoder to model the policies of peers in the decentralized execution. With a conditional policy, each agent is guided to a stable mixed-strategy equilibrium even though the joint policy evolves over time. We further demonstrate that such an equilibrium must exist in the case of centralized evaluation. We investigate the improvement of our method on existing centralized learning methods. The experimental results on a comprehensive collection of benchmarks indicate our approach consistently outperforms baseline methods.},
  archive      = {J_ISCI},
  author       = {Jingchen Li and Yusen Yang and Ziming He and Huarui Wu and Haobin Shi and Wenbai Chen},
  doi          = {10.1016/j.ins.2024.120983},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120983},
  shortjournal = {Inf. Sci.},
  title        = {Cournot policy model: Rethinking centralized training in multi-agent reinforcement learning},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). A dynamic broad TSK fuzzy classifier based on iterative
learning on progressively rebalanced data. <em>ISCI</em>, <em>677</em>,
120976. (<a href="https://doi.org/10.1016/j.ins.2024.120976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the existing class imbalanced classification methods are weak in interpretability, which is necessary for models to be convincing in some specific scenarios. In this study, we propose a dynamic broad Takagi-Sugeno-Kang (TSK) fuzzy classifier based on iterative learning on progressively expanded imbalanced dataset (DB-TSK-IL) to enhance interpretability. This method begins with a zero-order TSK fuzzy sub-classifier and constructs a TSK fuzzy classifier with a broad ensemble structure through an iterative and progressive process that repeatedly integrates the misclassified instance set of the previous broad model with the training set to train the next zero-order TSK fuzzy sub-classifier. Despite its simple structure, the proposed DB-TSK-IL provides advantageous over the comparative class-imbalanced classification methods with mostly static structures in three aspects: (1) generalization performance, (2) dynamic method with different fuzzy rules activated for different instances, and (3) significantly fewer fuzzy rules, which provide DB-TSK-IL with superior interpretability. Both the theoretical analysis and experimental results validate the efficiency of this method.},
  archive      = {J_ISCI},
  author       = {Jinghong Zhang and Yingying Li and Bowen Liu and Hao Chen and Jie Zhou and Hualong Yu and Bin Qin},
  doi          = {10.1016/j.ins.2024.120976},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120976},
  shortjournal = {Inf. Sci.},
  title        = {A dynamic broad TSK fuzzy classifier based on iterative learning on progressively rebalanced data},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Low-resolution few-shot learning via multi-space knowledge
distillation. <em>ISCI</em>, <em>677</em>, 120968. (<a
href="https://doi.org/10.1016/j.ins.2024.120968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing few-shot classification models usually rely on limited known support images to form class centers, and classify query images based on the distance between their embedding and the class centers. However, these models assume that the query image is high-resolution (HR), and thus suffer from significant performance degradation when applied to low-resolution (LR) images. Due to the lack of discriminative information in LR images, there is a noticeable discrepancy between the embeddings of LR query images and the class centers formed by HR support images. To address this issue, we first formulate the problem of Low-Resolution Few-Shot Learning (LRFSL), where the support images are HR while the query images are only available in LR. Then, we propose an end-to-end pipeline that leverages mutual learning between a super-resolution (SR) network and a few-shot classification network. To further reduce the domain discrepancy between the embeddings of the SR images and HR class centers, we introduce a multi-space knowledge distillation strategy that aims to transfer pixel-level, feature-level, and logit-level knowledge of the HR domain to the SR domain. We conduct extensive experiments on classic few-shot datasets: miniImageNet, tieredImageNet, and the fine-grained few-shot dataset CUB. Experimental results show that our method can handle few-shot classification with LR input, and achieve performance that is almost comparable to using HR images as input. Specifically, our method achieves an average accuracy improvement of 26.47% with the Meta-Baseline Model and 7.44% with the Meta DeepBDC Model across all datasets compared to LR Query.},
  archive      = {J_ISCI},
  author       = {Ke Liu and Xinchen Ye and Baoli Sun and Hairui Yang and Haojie Li and Rui Xu and Zhihui Wang},
  doi          = {10.1016/j.ins.2024.120968},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120968},
  shortjournal = {Inf. Sci.},
  title        = {Low-resolution few-shot learning via multi-space knowledge distillation},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A common feature-driven prediction model for multivariate
time series data. <em>ISCI</em>, <em>677</em>, 120967. (<a
href="https://doi.org/10.1016/j.ins.2024.120967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series data contain a variety of common features that are difficult to extract, among which the sudden irregular fluctuation trend, the trend feature of large fluctuation amplitude, and the long-term dependency relationship in the time series have an important impact on the accuracy of the prediction model. To predict non-stationary trends in large-scale data accurately using the common characteristics of multivariate time series. A novel generalised forecasting model NeA3L based on common features of time series is developed. The NeA3L model utilizes multiple independent parallel feature extraction modules to obtain the common features of multivariate time series. It utilizes the three-layer iterative structure to deal with sudden irregular fluctuation patterns. NeA3L optimizes the network structure to realize the heterogeneous codec structure. It applies the attention mechanism between the encoder and the decoder to accomplish the multivariate prediction of the multivariate time series, which has good stability for predicting various types of multivariate data. A comparison of the NeA3L model with nine current time series prediction methods on four publicly available datasets shows that the NeA3L model outperforms the current methods in various evaluation metrics. The RMSE is improved by 2.3 %, 26.5 %, 28.9 %, and 20.84 % on average, respectively. The NeA3L model can be universally applicable to the field of multivariate time series prediction, which is important for optimizing the intelligent management and decision-making.},
  archive      = {J_ISCI},
  author       = {Xinning Yu and Haifeng Wang and Jiuru Wang and Xing Wang},
  doi          = {10.1016/j.ins.2024.120967},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120967},
  shortjournal = {Inf. Sci.},
  title        = {A common feature-driven prediction model for multivariate time series data},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A soft prototype-based autonomous fuzzy inference system for
network intrusion detection. <em>ISCI</em>, <em>677</em>, 120964. (<a
href="https://doi.org/10.1016/j.ins.2024.120964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, cyber-attacks have become a common and persistent issue affecting various human activities in modern societies. Due to the continuously evolving landscape of cyber-attacks and the growing concerns around “black box” models, there has been a strong demand for novel explainable and interpretable intrusion detection systems with online learning abilities. In this paper, a novel soft prototype-based autonomous fuzzy inference system (SPAFIS) is proposed for network intrusion detection. SPAFIS learns from network traffic data streams online on a chunk-by-chunk basis and autonomously identifies a set of meaningful, human-interpretable soft prototypes to build an IF-THEN fuzzy rule base for classification. Thanks to the utilization of soft prototypes, SPAFIS can precisely capture the underlying data structure and local patterns, and perform internal reasoning and decision-making in a human-interpretable manner based on the ensemble properties and mutual distances of data. To maintain a healthy and compact knowledge base, a pruning scheme is further introduced to SPAFIS, allowing itself to periodically examine the learned solution and remove redundant soft prototypes from its knowledge base. Numerical examples on public network intrusion detection datasets demonstrated the efficacy of the proposed SPAFIS in both offline and online application scenarios, outperforming the state-of-the-art alternatives.},
  archive      = {J_ISCI},
  author       = {Xiaowei Gu and Gareth Howells and Haiyue Yuan},
  doi          = {10.1016/j.ins.2024.120964},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120964},
  shortjournal = {Inf. Sci.},
  title        = {A soft prototype-based autonomous fuzzy inference system for network intrusion detection},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 3WAUS: A novel three-way adaptive uncertainty-suppressing
model for facial expression recognition. <em>ISCI</em>, <em>677</em>,
120962. (<a href="https://doi.org/10.1016/j.ins.2024.120962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Expression Recognition (FER) remains a challenging task due to the uncertainty caused by the noisy labels, interrater disagreement, and the inter-class similarity of facial expressions. However, the majority of existing FER methods are deterministic, resulting in limited generalization performance in dealing with uncertainty. By adding a non-deterministic option, three-way decision (3WD) enhances the ability to handle uncertainty, which is widely used in different domains to reduce decision risk. Therefore, we introduce 3WD model into FER, and propose a novel three-way adaptive uncertainty-suppressing model (3WAUS). The model divides the sample space into three regions: high-importance, medium-importance, and low-importance, with different action strategies to effectively suppress the uncertainty in FER. Specifically, 3WAUS utilizes a weighted learning strategy to reinforce learning in the high-importance (low-uncertainty) region, thus acquiring high-quality sample features. For medium-importance samples, a dynamic adaptive re-labeling strategy is proposed to modify noisy labels, enabling the model to learn more accurate representations and avoid overfitting noise. Additionally, 3WAUS also attenuates the learning for low-importance (high-uncertainty) samples, effectively reducing the misguidance of noise on the model. Finally, extensive experiments on three public datasets and synthetic noisy datasets indicate that the proposed 3WAUS outperforms state-of-the-art methods in dealing with uncertainty.},
  archive      = {J_ISCI},
  author       = {Dong Li and Weiming Xiong and Tao Luo and Libo Zhang},
  doi          = {10.1016/j.ins.2024.120962},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120962},
  shortjournal = {Inf. Sci.},
  title        = {3WAUS: A novel three-way adaptive uncertainty-suppressing model for facial expression recognition},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conditional plausibility entropy of belief functions based
on dempster conditioning. <em>ISCI</em>, <em>677</em>, 120959. (<a
href="https://doi.org/10.1016/j.ins.2024.120959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty quantification of belief functions is an unsolved issue in belief function theory that is used widely to tackle epistemic uncertainty. This study provides a new definition of conditional entropy of belief functions, called conditional plausibility entropy, in terms of Dempster conditioning and plausibility entropy of mass functions. The proposed conditional plausibility entropy mainly meets two aspects of good properties, one is the semantics of independence property, the other is the compatibility with Shannon&#39;s conditional entropy for probability distributions, which are not simultaneously satisfied by existing definitions of conditional entropy of belief functions. The effectiveness of conditional plausibility entropy is validated further through comparison and analysis on the basis of different conditioning methods.},
  archive      = {J_ISCI},
  author       = {Xinyang Deng and Wen Jiang and Xiaoge Zhang},
  doi          = {10.1016/j.ins.2024.120959},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120959},
  shortjournal = {Inf. Sci.},
  title        = {Conditional plausibility entropy of belief functions based on dempster conditioning},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling methods for deep fuzzy inference systems based on
feature selection. <em>ISCI</em>, <em>677</em>, 120958. (<a
href="https://doi.org/10.1016/j.ins.2024.120958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A bottom-up, layer-by-layer feature selection modeling method is proposed for deep fuzzy inference systems. By selecting features in the input space, redundant and interfering features in each layer&#39;s input space can be removed. The selected features have been appropriately ordered to avoid the randomness of features within the feature sliding window. Based on fuzzy rough set theory, the matching degree between the fuzzy granules associated with the conditional feature set and those associated with the decision feature is used as a likelihood function. The λ - AIC criterion with a penalty term have been redefined as an evaluation index for features. The obtained model is compared to four baseline models and an existing deep fuzzy rule classification system. The results show that the feature selection-based deep fuzzy inference system effectively improves data classification performance and efficiency. Compared to four rough set-based feature selection methods based on different measures, the method proposed is more convincing in terms of accuracy and the number of features selected. Compared to the modeling method where input space features are randomly shuffled, the feature sorting modeling method performs better and avoids the instability in model accuracy caused by randomness.},
  archive      = {J_ISCI},
  author       = {Xiao-Hui Wang and Da-Qing Zhang},
  doi          = {10.1016/j.ins.2024.120958},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120958},
  shortjournal = {Inf. Sci.},
  title        = {Modeling methods for deep fuzzy inference systems based on feature selection},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predefined-time bipartite containment control of multi-agent
systems with novel super-twisting extended state observer.
<em>ISCI</em>, <em>677</em>, 120952. (<a
href="https://doi.org/10.1016/j.ins.2024.120952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the bipartite containment control of multi-agent systems with predefined-time convergence. First, a predefined-time distributed observer (PTDO) is constructed to calculate leaders&#39; spanned convex hulls of symmetric states with the same modulus but different in sign for each follower. In other words, PTDO provides a reference signal for each follower to track with. Besides, a predefined-time super twisting extended state observer (PTSTESO) is put forward to observe the disturbance of each follower. Furthermore, a predefined-time bipartite containment control protocol (PTBCCP) is constructed to achieve bipartite containment. The availability of the method is verified through simulation results.},
  archive      = {J_ISCI},
  author       = {Shaoping Chang and Canfeng Wang and Xiaoyuan Luo},
  doi          = {10.1016/j.ins.2024.120952},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120952},
  shortjournal = {Inf. Sci.},
  title        = {Predefined-time bipartite containment control of multi-agent systems with novel super-twisting extended state observer},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Double set-function choquet integral with applications.
<em>ISCI</em>, <em>677</em>, 120948. (<a
href="https://doi.org/10.1016/j.ins.2024.120948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Related to many applications in different fields, such as game theory, information fusion, data mining, and decision making, we have introduced in one our previous paper so called generalized Choquet-type integral for a real-valued function concerning a set-function and a σ -additive measure. The present study further generalizes the generalized Choquet-type integral in terms of a double set-function Choquet integral for a real-valued function based on a set-function and fuzzy measure. Several of its properties and convergence theorems are obtained, and a novel type of Jensen&#39;s inequality is proved. The stability of the proposed system formed by a double set-function Choquet integral concerning multiple inputs and one output is indicated. An effective application in decision making is shown through numerical examples.},
  archive      = {J_ISCI},
  author       = {Deli Zhang and Radko Mesiar and Endre Pap},
  doi          = {10.1016/j.ins.2024.120948},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120948},
  shortjournal = {Inf. Sci.},
  title        = {Double set-function choquet integral with applications},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive protocol-based control for reaction-diffusion
memristive neural networks with semi-markov switching parameters.
<em>ISCI</em>, <em>677</em>, 120947. (<a
href="https://doi.org/10.1016/j.ins.2024.120947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the asynchronous control of reaction-diffusion memristive neural networks (RDMNNs) using an innovative adaptive event-triggered protocol. The unique characteristic of RDMNNs is captured through a semi-Markov process model, wherein the probability density function of the duration time is contingent on two consecutive modes. A novel adaptive event-triggered strategy, specifically designed for the semi-Markov switching signal, is introduced to effectively reduce the network&#39;s bandwidth usage. The determination of thresholds in the adaptive triggering criterion is intricately associated with the system state residuals. Due to the mismatch between the controller and the RDMNNs, the protocol-based controller operates asynchronously. This asynchronous operation is characterized by a hidden semi-Markovian model. Utilizing stochastic Lyapunov functions that correlate with the detected and system modes, several sufficient criteria for designing an effective asynchronous controller are provided, thereby ensuring the stochastic stability of the system. Finally, the feasibility of the proposed scheme is validated through a simulated example.},
  archive      = {J_ISCI},
  author       = {Na Liu and Jun Cheng and Yonghong Chen and Huaicheng Yan and Dan Zhang and Wenhai Qi},
  doi          = {10.1016/j.ins.2024.120947},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120947},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive protocol-based control for reaction-diffusion memristive neural networks with semi-markov switching parameters},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identifying influential nodes on directed networks.
<em>ISCI</em>, <em>677</em>, 120945. (<a
href="https://doi.org/10.1016/j.ins.2024.120945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying influential nodes on directed networks is a challenging and widely studied task that keeps drawing extensive attention from both academia and industry. The simultaneous consideration of both local and global structural information has demonstrated its effectiveness in identifying influential nodes on un-directed networks. Nevertheless, how to better utilize these two types of information on directed networks remains a challenge. In this paper, we address the influential nodes identification problem for directed networks where a node can directly affect its in-neighbors, like the social network of Twitter. We present a general iterative framework that integrates both local structural information and global influence. The global influence exerted by the target node is determined as the cumulative sum of the global influences originating from its in-neighbors, achieved through an iterative procedure. Meanwhile, the in-degree of the target node is leveraged to capture local structural information, which is consistently reinforced throughout the iterative process to prevent the attenuation of its significance over successive iterations. Our algorithm demonstrates significant performance improvement, averaging 21.61% in Kendall&#39;s τ and 23.43% in precision@0.05 over the 8 benchmarks across 15 real networks. Moreover, it outperforms the benchmarks on artificial networks, and can effectively identify fast influencers.},
  archive      = {J_ISCI},
  author       = {Yan-Li Lee and Yi-Fei Wen and Wen-Bo Xie and Liming Pan and Yajun Du and Tao Zhou},
  doi          = {10.1016/j.ins.2024.120945},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120945},
  shortjournal = {Inf. Sci.},
  title        = {Identifying influential nodes on directed networks},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Honest-GE: 2-step heuristic optimization and node-level
embedding empower spatial-temporal graph model for ECG. <em>ISCI</em>,
<em>677</em>, 120941. (<a
href="https://doi.org/10.1016/j.ins.2024.120941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based models for Electrocardiogram (ECG) incorporate physiological spatial information among ECG leads in elegant manners. It is unachievable for convolution-based models. Nevertheless, existing ECG graph models heavily rely on manually pre-designed structures. Such structures may not be optimal for all ECGs. Moreover, these models lag behind larger representative models, despite their superiority in lightweight cases. In this study, a novel graph structure learning method is proposed. It can learn optimal structures and enhance model representations simultaneously. Typically, ECGs belong to limb/chest lead systems. To explore inter-system and intra-system connections, heuristic optimization including genetic algorithm and particle swarm optimization is employed. Specifically, candidate nodes/edges are encoded as individuals. Thereby graph structure learning is transformed into population iterations. In this scenario, graph-level embedding becomes non-applicable because models require retraining once structures change. Instead, node-level embedding continuously enhances models during structure learning. Consequently, Honest-GE further exploits graph methods&#39; superiority in lightweight cases. It outperforms state-of-the-art models 11.53% and 10.03% in F 1 F1 on two databases. Additionally, it demonstrates comparable performance with larger models. In general, graph learning results corroborate medical knowledge and offer insights for lead selection. Honest-GE provides a promising avenue for high-performing lightweight models and portable deployments with fewer leads.},
  archive      = {J_ISCI},
  author       = {Huaicheng Zhang and Wenhan Liu and Deyu Luo and Jiguang Shi and Qianxi Guo and Yue Ge and Sheng Chang and Hao Wang and Jin He and Qijun Huang},
  doi          = {10.1016/j.ins.2024.120941},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120941},
  shortjournal = {Inf. Sci.},
  title        = {Honest-GE: 2-step heuristic optimization and node-level embedding empower spatial-temporal graph model for ECG},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel clustering-based evolutionary algorithm with
objective space decomposition for multi/many-objective optimization.
<em>ISCI</em>, <em>677</em>, 120940. (<a
href="https://doi.org/10.1016/j.ins.2024.120940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The framework of decomposing a multi-objective optimization problem (MOP) into some MOPs holds considerable promise. However, its advancement is constrained by numerous elements, including the incorrect segmentation of the subspaces and the challenges in balancing convergence and diversity. To address these issues, an objective space Decomposition and Clustering-based Evolutionary Algorithm (DCEA) is proposed in this paper. Specifically, DCEA employs K-means clustering to create an appropriate mating pool for each individual without the necessity to predetermine the number of clusters. Within each mating pool, the proposed adaptive evolutionary operator is applied to produce offspring for balancing the convergence and diversity. To enhance the accuracy of partitioning, a refined environmental selection approach utilizing supplementary weight vectors is developed. Additionally, by utilizing historical clustering data, a straightforward approach to periodically adjust reference vectors for the allocation of computational resources is proposed. In experiments, both MOPs and many-objective optimization problems (MaOPs) are used to test DCEA. A total of 27 MOPs and 30 MaOPs are involved and 16 state-of-the-art algorithms are employed to compare with DCEA. Comprehensive experiments show that DCEA is an effective algorithm for solving both MOPs and MaOPs.},
  archive      = {J_ISCI},
  author       = {Wei Zheng and Yanyan Tan and Zeyuan Yan and Mingming Yang},
  doi          = {10.1016/j.ins.2024.120940},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120940},
  shortjournal = {Inf. Sci.},
  title        = {A novel clustering-based evolutionary algorithm with objective space decomposition for multi/many-objective optimization},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Interactive dynamic diffusion graph convolutional network
for traffic flow prediction. <em>ISCI</em>, <em>677</em>, 120938. (<a
href="https://doi.org/10.1016/j.ins.2024.120938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capturing the temporal and spatial features, and the spatiotemporal correlations in traffic networks is the essential task for accurate traffic flow prediction. Although most existing models have explored the temporal features deeply, the periodicity and dynamics of diffusion signals in spatial features are neglected. Besides, most previous methods cannot capture the heterogeneous spatiotemporal correlations of traffic sequences. In order to tackle the above two issues, a novel deep learning-based model called interactive dynamic diffusion graph convolutional network is proposed to realize accurate traffic flow prediction. Firstly, a new periodic and dynamic diffusion graph convolutional network is proposed to extract the periodicity and dynamics of diffusion signals in spatial features. Secondly, a new spatiotemporal interactive dynamic graph generator is proposed to generate a spatiotemporal dynamic graph through a spatiotemporal interactive operation, and it can comprehensively capture the heterogeneous spatiotemporal correlations of traffic sequences. Finally, the proposed model attains an accurate traffic flow prediction through extensive experiments on two real-world traffic flow datasets, which confirm the superiority of the proposed model compared with twelve baseline models.},
  archive      = {J_ISCI},
  author       = {Shuai Zhang and Wangzhi Yu and Wenyu Zhang},
  doi          = {10.1016/j.ins.2024.120938},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120938},
  shortjournal = {Inf. Sci.},
  title        = {Interactive dynamic diffusion graph convolutional network for traffic flow prediction},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge complexity based on coupled equations within the
bipartite network. <em>ISCI</em>, <em>677</em>, 120937. (<a
href="https://doi.org/10.1016/j.ins.2024.120937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of competing for core competence, the increasing inputs of knowledge factors have brought the issue of “efficiency-enhancing and quality-improving” into focus; and concerns about the “quality” perspective of knowledge require mining information related to complex knowledge hidden in the economic system. In order to quantify knowledge complexity at both the national (or regional) and technological levels, this article combines the Fitness and Complexity algorithm with matrix-estimation exercises based on the framework of the bipartite network. On the basis of these measurements, this article analyzes and discusses the economic implications and evolutionary features while considering the “expiration” of patents; additionally, community detection is conducted to discuss the evolution of the “location” of complex knowledge. The results show that knowledge complexity depends on the structural similarity and specialization of patents; furthermore, the timeliness of patents may affect knowledge complexity conspicuously; moreover, the significance of the “location” of complex knowledge in the past has been downplayed over the past few decades.},
  archive      = {J_ISCI},
  author       = {Shenshen Sergio Zhang},
  doi          = {10.1016/j.ins.2024.120937},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120937},
  shortjournal = {Inf. Sci.},
  title        = {Knowledge complexity based on coupled equations within the bipartite network},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A controlled data envelopment analysis clustering approach
based on individual perspective. <em>ISCI</em>, <em>677</em>, 120932.
(<a href="https://doi.org/10.1016/j.ins.2024.120932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlike most existing clustering methods, data envelopment analysis (DEA) clusters decision-making units (DMUs) based on production characteristics rather than distance. The clustering results obtained using the DEA clustering approach reflect the production relationship between the inputs and outputs of the DMUs to better identify the inherent production correlation between them. However, existing DEA-based clustering approaches struggle to rationally assign unique clusters to DMUs that exhibit multiple production characteristics and lack the further processing of clustering results. Therefore, this study proposes a new DEA clustering approach based on the individual perspective of DMUs that incorporates prospect theory to reflect the individual preferences of DMUs to assign each DMU to a relatively unique cluster. Furthermore, a clustering adjustment method and a clustering reduction method are proposed to further improve the clustering quality. The former can handle some special clusters according to the decision-maker’s preference, and the latter permits the realization of an arbitrary number of clusters. The new DEA clustering approach is more reliable and flexible, and more valuable information can be provided for decision-makers. Finally, the validity of the new approach is verified through a comparison with existing approaches in two numerical cases, and an empirical example is used to illustrate its practicability.},
  archive      = {J_ISCI},
  author       = {Lei Chen and Minghuan Fan and Junchao Wang},
  doi          = {10.1016/j.ins.2024.120932},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120932},
  shortjournal = {Inf. Sci.},
  title        = {A controlled data envelopment analysis clustering approach based on individual perspective},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CCC-TM: Cross-chain consensus committee method using a trust
model. <em>ISCI</em>, <em>677</em>, 120930. (<a
href="https://doi.org/10.1016/j.ins.2024.120930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The presence of malicious nodes poses significant challenges to the robustness and security of blockchain cross-chain systems. This study investigates the interaction mechanism of blockchain cross-chain systems by integrating relay committee and trust models, aiming to mitigate the detrimental effects caused by malicious nodes on the overall system. Firstly, introducing a relay committee is proposed to facilitate the establishment of reliable relay nodes that serve as intermediaries connecting diverse blockchain networks. Secondly, the study devises a trust model, leveraging nodes’ past behaviors to evaluate their trustworthiness and identify and isolate potentially malicious nodes. Lastly, a mutual verification decentralized identifier (MVDID) enforces access control for inter-blockchain objects. In the experimental phase, the proportion of trusted nodes to the total number of nodes ranges from 0.1 to 0.3, yielding a consistently high transaction success rate between 97% and 100%. The findings indicate that implementing a relay committee enhances cross-chain operations’ efficiency and security. Additionally, the trust model aids in accurately identifying malicious nodes while promoting system transparency and collaboration. Consequently, this mechanism offers a comprehensive enhancement in performance and security for blockchain cross-chain systems.},
  archive      = {J_ISCI},
  author       = {Wenlong Yi and Qiliang Xie and Sergey Kuzmin and Igor Gerasimov and Xiangping Cheng},
  doi          = {10.1016/j.ins.2024.120930},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120930},
  shortjournal = {Inf. Sci.},
  title        = {CCC-TM: Cross-chain consensus committee method using a trust model},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy-preserving boolean range query with verifiability
and forward security over spatio-textual data. <em>ISCI</em>,
<em>677</em>, 120929. (<a
href="https://doi.org/10.1016/j.ins.2024.120929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Boolean range query, as one typical spatial keyword query, has received more and more attention and been widely deployed in many applications. To release the storage and computation burden of client, the spatio-textual data is usually outsourced to the cloud. Some existing schemes have been proposed to realize privacy-preserving boolean range query over spatio-textual data. Nevertheless, these schemes do not support the verifiability and the forward security of spatio-textual data simultaneously. In this paper, we aim at exploring this issue and design a privacy-preserving boolean range query scheme with verifiability and forward security over spatio-textual data. In order to realize forward security, we build a secure binary tree index and a secure keyword index for the spatio-textual data. In each update, we generate new tokens for all leaf nodes using different keys, and assign new states for updated keywords. The cloud cannot learn the keyword of previous query token because the update token is not matched with the previous query token. As a result, the proposed scheme realizes forward security. To realize result verification, we design a novel forward secure verification tag. Benefiting from the accumulation of this tag and the newly state assigned for keyword, we can conveniently perform update operation and prevent the cloud from returning the object not updated. According to the newly state stored locally and the returned objects by the cloud, we can generate the tag and check whether it is the same as the returned tag for verifying the result validity. We leverage the additive symmetric homomorphic encryption algorithm to securely realize the accumulation of ciphertexts. Formal security analysis presents that our proposed scheme satisfies forward security and verifiability. Extend experiment is conducted to show its efficiency.},
  archive      = {J_ISCI},
  author       = {Xinrui Ge and Jia Yu and Fanyu Kong},
  doi          = {10.1016/j.ins.2024.120929},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120929},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-preserving boolean range query with verifiability and forward security over spatio-textual data},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature selection based on contradictory state sequence for
multi-scale interval valued decision table. <em>ISCI</em>, <em>677</em>,
120926. (<a href="https://doi.org/10.1016/j.ins.2024.120926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of selecting features for multi-scale interval valued decision table ( M I V D T MIVDT ), conventional research approaches encounter difficulties including elevated data complexity, diminished computational efficiency, and limited model generalization capacity. To overcome these difficulties, feature selection methods based on contradictory state sequence ( CSS ) and fuzzy contradictory state sequence ( F C S S FCSS ) are proposed in this paper. Initially, M I V D T MIVDT is established. According to the characteristics of interval value, a more thorough and impartial metric for assessing the inclusion degree is suggested, along with similarity relation based on the metric. Subsequently, the introduction of the first contradictory object allows for the delineation of contradictory state and fuzzy contradictory state, which serve to characterize the consistency of M I V D T MIVDT . These two concepts are proposed to enhance the accuracy and efficiency of capturing key information in intricate data. Additionally, rapid feature selection algorithms are suggested, which rely on CSS and F C S S FCSS . In contrast to conventional feature selection approaches, the algorithms introduced in this study demonstrate superior computational efficiency and enhanced generalization capabilities when confronted with intricate datasets. In twelve open source datasets, the upper limit for the quantity of objects is 110341, and the average accuracy values of experiments under two parameter combinations are 99.54% and 97.08% respectively. The results of experiments demonstrate that the algorithms introduced are capable of efficiently identifying a novel feature subset from intricate datasets within a shorter timeframe.},
  archive      = {J_ISCI},
  author       = {Xiaoyan Zhang and Zihan Feng},
  doi          = {10.1016/j.ins.2024.120926},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120926},
  shortjournal = {Inf. Sci.},
  title        = {Feature selection based on contradictory state sequence for multi-scale interval valued decision table},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerate rotation invariant sliced gromov-wasserstein
distance by an alternative optimization method. <em>ISCI</em>,
<em>677</em>, 120925. (<a
href="https://doi.org/10.1016/j.ins.2024.120925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional Wasserstein distance is inadequate for comparing two distributions in different metric spaces. The Gromov-Wasserstein distance (GWD), which evolves from the Gromov-Hausdorff distance, constructs intraspace pairs to ensure comparability. However, solving the GWD requires tackling a complex nonconvex quadratic problem, a process that typically demands significant time and space complexity. The sliced Gromov-Wasserstein distance (SGW) addresses the efficiency issues of GWD by employing a projection-slice method. Unfortunately, slicing destroys the crucial rotation invariance property of GWD. The rotation invariant sliced Gromov-Wasserstein distance (RISGW) restores it by enumerating the alignments of the distributions. Inspired by our observations, we introduce BRISGW, a novel batch rotation invariant sliced Gromov-Wasserstein distance that alternately iterates and approximates the underlying best alignment both effectively and efficiently. We theoretically prove the feasibility the proposed our approach. Moreover, significant experimental results show that the proposed method outperforms the state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Jinming Luo and Yuhao Bian and Xianjie Gao and Jian Liu and Xiuping Liu},
  doi          = {10.1016/j.ins.2024.120925},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120925},
  shortjournal = {Inf. Sci.},
  title        = {Accelerate rotation invariant sliced gromov-wasserstein distance by an alternative optimization method},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-strategy driven reinforced hierarchical operator in
the grey wolf optimizer for feature selection. <em>ISCI</em>,
<em>677</em>, 120924. (<a
href="https://doi.org/10.1016/j.ins.2024.120924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a multi-strategy driven reinforced hierarchical operator for a grey wolf optimizer (RHGWO) is proposed to solve the feature selection (FS) problem, whereby tedious data are converted into information and often modeled as a combinatorial optimization problem. First, a multi-strategy mechanism is proposed to provide the GWO algorithm with exploration capabilities, including memory-based diversity and Lévy flight-based extension search. Next, a hierarchical segmentation technique is proposed to allocate exploration and exploitation, thereby providing exploration capability for superior wolves to search diverse regions and exploitation capability for inferior wolves to converge to the promising area. Subsequently, a chaotic elite learning strategy is designed for leaders to prevent misdirection. Finally, a more rational nonlinear parameter transformation is designed. Multiple experiments validate the adaptability and versatility of the proposed RHGWO algorithm.},
  archive      = {J_ISCI},
  author       = {Xiaobing Yu and Zhengpeng Hu},
  doi          = {10.1016/j.ins.2024.120924},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120924},
  shortjournal = {Inf. Sci.},
  title        = {A multi-strategy driven reinforced hierarchical operator in the grey wolf optimizer for feature selection},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lift and generalized ordinal sum of negations on bounded
posets. <em>ISCI</em>, <em>677</em>, 120920. (<a
href="https://doi.org/10.1016/j.ins.2024.120920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, two construction methods for fuzzy negations on bounded structures are presented. The first method focuses on lifting a fuzzy negation from a more general subposet to the complete lattice, extending the existing research. It provides an effective approach to lift fuzzy negations, even when the top and bottom elements of the subposet differ from those of the complete lattice. The second method explores the generalized ordinal sum of negations on an abelian partially ordered group, achieved by complementing a given fuzzy negation. A sufficient and necessary condition for the generalized ordinal sum, with a familiar fuzzy negation as the complement, to be a fuzzy negation is given. Building upon this, the paper introduces a supplementary fuzzy negation based on the provided family of subintervals, which guarantees that the generalized ordinal sum is still a fuzzy negation.},
  archive      = {J_ISCI},
  author       = {Haiwei Wang and Bin Zhao},
  doi          = {10.1016/j.ins.2024.120920},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120920},
  shortjournal = {Inf. Sci.},
  title        = {Lift and generalized ordinal sum of negations on bounded posets},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-type data fusion via transfer learning surrogate
modeling and its engineering application. <em>ISCI</em>, <em>677</em>,
120918. (<a href="https://doi.org/10.1016/j.ins.2024.120918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In engineering problem, there exists many mixed datasets composed of multi-type data, including data without noise, data with homoscedastic noise (known noise variance), and data with heteroscedastic noise (unknown noise variance). To construct accurate predictive models, it is essential to fully utilize the information provided by the diverse dataset, particularly when confronted with limitations in training samples. Motivated by this, this paper introduces a novel transfer learning surrogate modeling approach to fuse multi-type data for prediction purpose. Numerical cases and two engineering applications validate the accuracy and robustness of the proposed model. Comparative analyses reveal superior predictive accuracy and robustness compared to other models. Additionally, by varying the levels of homoscedastic and heteroscedastic noise, the impact of noise on the proposed model is studied. Results indicate that this model has superior applicability and stability compared to other models. The proposed approach is capable of fusing multi-type data and adapting to different levels of noise, making it a promising approach for engineering application.},
  archive      = {J_ISCI},
  author       = {Shuai Zhang and Yong Pang and Qingye Li and Kunpeng Li and Xueguan Song},
  doi          = {10.1016/j.ins.2024.120918},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120918},
  shortjournal = {Inf. Sci.},
  title        = {Multi-type data fusion via transfer learning surrogate modeling and its engineering application},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimum observability of probabilistic boolean networks.
<em>ISCI</em>, <em>677</em>, 120917. (<a
href="https://doi.org/10.1016/j.ins.2024.120917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the minimum observability of probabilistic Boolean networks (PBNs), the main objective of which is to add the fewest measurements such that an unobservable PBN becomes observable. First of all, the algebraic form of a PBN is established with the help of semi-tensor product (STP) of matrices. By combining the algebraic forms of two identical PBNs into a parallel system, a method to search the states that need to be H -distinguishable is proposed based on the robust set reachability technique. Secondly, a necessary and sufficient condition is given to find the minimum measurements such that a given set can be H -distinguishable. Moreover, by comparing the numbers of measurements for all the feasible H -distinguishable state sets, the least measurements that make the system observable are gained. Finally, an example is given to verify the validity of the obtained results.},
  archive      = {J_ISCI},
  author       = {Jiayi Xu and Shihua Fu and Liyuan Xia and Jianjun Wang},
  doi          = {10.1016/j.ins.2024.120917},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120917},
  shortjournal = {Inf. Sci.},
  title        = {Minimum observability of probabilistic boolean networks},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CAT: A causal graph attention network for trimming
heterophilic graphs. <em>ISCI</em>, <em>677</em>, 120916. (<a
href="https://doi.org/10.1016/j.ins.2024.120916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The local attention-guided message passing mechanism (LAMP) adopted in graph attention networks (GATs) can adaptively learn the importance of neighboring nodes and perform local aggregation better, thus demonstrating a stronger discrimination ability. However, existing GATs suffer from significant discrimination ability degradations in heterophilic graphs. The reason is that a high proportion of dissimilar neighbors can weaken the self-attention of the central node, resulting in the central node deviating from its similar nodes in the representation space. This type of influence caused by neighboring nodes is referred to as Distraction Effect (DE) in this paper. To estimate and weaken the DE induced by neighboring nodes, we propose a Causal graph Attention network for Trimming heterophilic graphs (CAT). To estimate the DE, since DE is generated through two paths, we adopt the total effect as the metric for estimating DE; To weaken the DE, we identify the neighbors with the highest DE (we call them Distraction Neighbors) and remove them. We adopt three representative GATs as the base model within the proposed CAT framework and conduct experiments on seven heterophilic datasets of three different sizes. Comparative experiments show that CAT can improve the node classification accuracies of all base GAT models. Ablation experiments and visualization further validate the enhanced discrimination ability of CATs. In addition, CAT is a plug-and-play framework and can be introduced to any LAMP-driven GAT because it learns a trimmed graph in the attention-learning stage, instead of modifying the model architecture or globally searching for new neighbors.},
  archive      = {J_ISCI},
  author       = {Silu He and Qinyao Luo and Xinsha Fu and Ling Zhao and Ronghua Du and Haifeng Li},
  doi          = {10.1016/j.ins.2024.120916},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120916},
  shortjournal = {Inf. Sci.},
  title        = {CAT: A causal graph attention network for trimming heterophilic graphs},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). TodyNet: Temporal dynamic graph neural network for
multivariate time series classification. <em>ISCI</em>, <em>677</em>,
120914. (<a href="https://doi.org/10.1016/j.ins.2024.120914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series classification (MTSC) is a crucial data mining task that can be effectively tackled using prevalent deep learning technology. However, current methods often overlook hidden dependencies across dimensions and struggle to capture dynamic time series features adequately, leading to poor accuracy. To tackle this challenge, we propose TodyNet, a novel dynamic temporal graph neural network. TodyNet extracts latent spatio-temporal dependencies without predefined graph structures, facilitating information flow among isolated but implicitly interdependent variables. It captures associations between time slots through dynamic graphs, boosting classification performance. Furthermore, to address the limitation that the hierarchical representations of graphs are challenging to learn with graph neural networks (GNNs), we introduce a temporal graph pooling layer for obtaining a global graph-level representation. The dynamic graph, graph information propagation, and temporal convolution are jointly learned within an end-to-end framework. Experimental results on 26 UEA benchmark datasets indicate that compared to current state-of-the-art deep learning methods in the MTSC task, the proposed Todynet achieved a performance improvement of 5.5%.},
  archive      = {J_ISCI},
  author       = {Huaiyuan Liu and Donghua Yang and Xianzhang Liu and Xinglei Chen and Zhiyu Liang and Hongzhi Wang and Yong Cui and Jun Gu},
  doi          = {10.1016/j.ins.2024.120914},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120914},
  shortjournal = {Inf. Sci.},
  title        = {TodyNet: Temporal dynamic graph neural network for multivariate time series classification},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Di-GraphGAN: An enhanced adversarial learning framework for
accurate spatial-temporal traffic forecasting under data missing
scenarios. <em>ISCI</em>, <em>677</em>, 120911. (<a
href="https://doi.org/10.1016/j.ins.2024.120911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, various disturbances in urban transportation data acquisition/processing/storage lead to the inevitable data missing problem, which undermines the valuable traffic information and greatly threats the reliability of existing benchmark traffic prediction models. Inspired from the powerful generative learning ability of GANs, we propose an integrated spatiotemporal Data imputation Graph Attention Generative Adversarial Networks (Di-GraphGAN) for accurate and efficient spatial-temporal traffic forecasting under data missing scenarios. Specifically, we first propose a traffic data imputation module named DI-LSTM, which adopts the architecture of LSTM Network with an extra Time Damping unit to accurately estimating the missing values. Then, we facilitate Di-GraphGAN with an original developed Task-Efficient Graph Attention Networks (TE-GAT) for better graph representation learning and a Temporal Contextual Attention (TCA) mechanism to capture the dynamic spatiotemporal traffic patterns. Finally, extensive evaluations are conducted on two real-world traffic speed datasets from China, demonstrating that Di-GraphGAN achieves state-of-the-art performance in both traffic forecasting and spatiotemporal data imputation tasks.},
  archive      = {J_ISCI},
  author       = {Lincan Li and Jichao Bi and Kaixiang Yang and Fengji Luo},
  doi          = {10.1016/j.ins.2024.120911},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120911},
  shortjournal = {Inf. Sci.},
  title        = {Di-GraphGAN: An enhanced adversarial learning framework for accurate spatial-temporal traffic forecasting under data missing scenarios},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Imbalanced and missing multi-label data learning with global
and local structure. <em>ISCI</em>, <em>677</em>, 120910. (<a
href="https://doi.org/10.1016/j.ins.2024.120910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label missing and class imbalance problems are two hot research topics in machine learning, and they have been impeding the improvement of model performance, especially in the multi-label learning. Although some existing methods have proven to be effective, they are suitable for only one case. How to effectively address above two issues simultaneously is a challenging problem. In this paper, we propose a novel model named Imbalanced and Missing multi-Label data learning with Global and Local structure (IMLGL) to address the aforementioned challenge. There are following three advantages. At the empirical risk level, we introduce the label correlation matrix C into the loss function and devise a dynamic weighting method to address the aforementioned challenge. At the data level, we analyze the structural characteristics of the data, and introduce local low-rank and global high-rank term to enhance the generalization performance of the model. At the label level, a smoothing term is also introduced for learning the constraint classifier coefficient matrix W . Our method utilizes alternative optimization technique and alternating minimization method for solving. Extensive experiments on six datasets demonstrate the competitiveness of our approach.},
  archive      = {J_ISCI},
  author       = {Xinpei Su and Yitian Xu},
  doi          = {10.1016/j.ins.2024.120910},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120910},
  shortjournal = {Inf. Sci.},
  title        = {Imbalanced and missing multi-label data learning with global and local structure},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Supervisor synthesis for asynchronous diagnosability
enforcement in labeled petri nets. <em>ISCI</em>, <em>677</em>, 120907.
(<a href="https://doi.org/10.1016/j.ins.2024.120907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The asynchronous fault diagnosis problem involves detecting the occurred faults in a system in the scenario that one asynchronously initiates a diagnosis agent with the system. This research investigates the asynchronous fault diagnosis problem of a system represented by labeled Petri nets (LPNs). An important property named asynchronous diagnosability of an LPN plant is formulated and studied which indicates that the detection of a fault can be achieved within a finite number of observations in the context of asynchronous diagnosis. This paper first introduces a structure named an asynchronous basis diagnoser , based on which the asynchronous diagnosis problem of an LPN plant can be addressed. Moreover, an approach is presented which leverages the asynchronous basis diagnoser to identify the asynchronous diagnosability. If an LPN plant is not asynchronously diagnosable, a supervisor is then designed which constraints the plant&#39;s behavior such that the controlled system satisfies the requirement of asynchronous diagnosability.},
  archive      = {J_ISCI},
  author       = {Yihui Hu and Shaopeng Hu and Xiaoyan Li and Shengli Cao and Huanchao Du and Dan Li},
  doi          = {10.1016/j.ins.2024.120907},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120907},
  shortjournal = {Inf. Sci.},
  title        = {Supervisor synthesis for asynchronous diagnosability enforcement in labeled petri nets},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stacked co-training for semi-supervised multi-label
learning. <em>ISCI</em>, <em>677</em>, 120906. (<a
href="https://doi.org/10.1016/j.ins.2024.120906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the difficulty of annotation, multi-label learning sometimes obtains a small amount of labeled data and a large amount of unlabeled data as supplements. To make up this issue, many algorithms extended the existing semi-supervised strategies in single-label patterns to multi-label applications, but failed to effectively consider the characteristics of semi-supervised multi-label learning. In this paper, a novel method named SCTML (Stacked Co-Training for Multi-Label learning) is proposed for semi-supervised multi-label learning. Through a two-layer stacking framework, SCTML learns label correlation in both base learners and meta learner, and effectively incorporates the semi-supervised assumptions of co-training, clustering and manifold. Extensive experiments demonstrate that the combination of multiple semi-supervised learning strategies effectively solves the semi-supervised multi-label learning problem.},
  archive      = {J_ISCI},
  author       = {Jiaxuan Li and Xiaoyan Zhu and Hongrui Wang and Yu Zhang and Jiayin Wang},
  doi          = {10.1016/j.ins.2024.120906},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120906},
  shortjournal = {Inf. Sci.},
  title        = {Stacked co-training for semi-supervised multi-label learning},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic event-triggered asynchronous control for switched
t-s fuzzy systems. <em>ISCI</em>, <em>677</em>, 120905. (<a
href="https://doi.org/10.1016/j.ins.2024.120905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The H ∞ H∞ control problem for a class of continuous-time switched Takagi-Sugeno (T-S) fuzzy systems with mode-dependent average dwell time (MDADT) switching rules is the main topic of this article. Firstly, the transmission burden is relieved by efficiently reducing the number of signal transmissions by the application of a revolutionary dynamic event-triggered mechanism (ETM). Secondly, there is a thorough understanding of the dynamic event-triggered, asynchronous control behaviors that exist between the controllers and subsystems. To ensure H ∞ H∞ performance of the asynchronous switched T-S fuzzy systems, certain appropriate adequate circumstances are derived by using the merged switching signal approach and Lyapunov-like functional (LKF) method. Lastly, a practical and an numerical example demonstrate the viability and implementation of the conclusions gained.},
  archive      = {J_ISCI},
  author       = {Zhuoying Li and Yuechao Ma},
  doi          = {10.1016/j.ins.2024.120905},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120905},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic event-triggered asynchronous control for switched T-S fuzzy systems},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Information gain-based multi-objective evolutionary
algorithm for feature selection. <em>ISCI</em>, <em>677</em>, 120901.
(<a href="https://doi.org/10.1016/j.ins.2024.120901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) has garnered significant attention because of its pivotal role in enhancing the efficiency and effectiveness of various machine learning and data mining algorithms. Concurrently, multiobjective feature selection (MOFS) algorithms strive to balance the complexity of multiple optimization objectives during the FS process. These include minimizing the number of selected features while maximizing classification performance. Nonetheless, managing the complexity of feature combinations presents a formidable challenge, particularly in high-dimensional datasets. Evolutionary algorithms (EAs) are increasingly adopted in MOFS owing to their exceptional global search capabilities and robustness. Despite their strengths, EAs face difficulties in navigating expansive solution spaces and achieving a balance between exploration and exploitation. To address these challenges, this study introduces a novel information gain-based EA for MOFS, designated as IGEA. This approach utilizes a clustering method for selecting a diverse parent population, thereby enhancing individual variability and maintaining a high-quality population. Considerably, IGEA employs information gain as a metric to evaluate the contribution of features to classification tasks. This metric informs crucial operations such as crossover and mutation. Moreover, the study extensively examines the actual solutions derived from IGEA, focusing on feature correlation and redundancy. This analysis illuminates IGEA&#39;s adept handling of these aspects to refine MOFS. Experimental results on 23 widely used classification datasets confirm IGEA&#39;s superiority over five other state-of-the-art algorithms, demonstrating its enhanced effectiveness and efficiency in complex MOFS scenarios.},
  archive      = {J_ISCI},
  author       = {Baohang Zhang and Ziqian Wang and Haotian Li and Zhenyu Lei and Jiujun Cheng and Shangce Gao},
  doi          = {10.1016/j.ins.2024.120901},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120901},
  shortjournal = {Inf. Sci.},
  title        = {Information gain-based multi-objective evolutionary algorithm for feature selection},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attribute reduction for hierarchical classification based on
improved fuzzy rough set. <em>ISCI</em>, <em>677</em>, 120900. (<a
href="https://doi.org/10.1016/j.ins.2024.120900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction plays a critical role in extracting valuable information from high-dimensional datasets. Compared to Pawlak rough set, fuzzy rough set can preserve more data information, making it a prominent focus in the research of attribute reduction. However, current fuzzy rough set-based attribute reduction focuses on flat classification, neglecting distinguishable stability information in hierarchical classification, which leads to insufficient data utilization and reduces the accuracy of attribute reduction. To address these issues, this paper presents two types of fuzzy rough set, named IFRS-I and IFRS-II. Especially, IFRS-I is an improved fuzzy rough set for flat classification, while IFRS-II is constructed based on IFRS-I for hierarchical classification. Unlike traditional fuzzy rough set, IFRS-II has the following two advantages: (1) a stability factor is designed to measure the stability difference among decision classes, (2) a tolerance index is designed to represent the tolerance distance between decision classes based on the approximate information of different decision classes in hierarchical classification. Finally, a stable and effective attribute reduction based on IFRS-II (ARIFRS-II) is designed for hierarchical classification. Experiments demonstrate that compared with the existing related algorithms, ARIFRS-II obtains a higher classification accuracy and stability, while maintaining a suitable number of subsets after reduction.},
  archive      = {J_ISCI},
  author       = {Jie Yang and Xiaodan Qin and Guoyin Wang and Qinghua Zhang and Shuai Li and Di Wu},
  doi          = {10.1016/j.ins.2024.120900},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120900},
  shortjournal = {Inf. Sci.},
  title        = {Attribute reduction for hierarchical classification based on improved fuzzy rough set},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Binary spectral clustering for multi-view data.
<em>ISCI</em>, <em>677</em>, 120899. (<a
href="https://doi.org/10.1016/j.ins.2024.120899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the majority of multi-view spectral clustering approaches fuse complementary information by performing consistent spectral embedding learning based on pre-constructed similarity graphs and achieve clustering results using a single-view clustering method. Therefore, the whole clustering strategy involves three independent steps, including similarity matrix learning, relaxing a binary cluster indicator matrix (BCIM) into a continuous spectral embedding matrix (CSEM), and discretizing the CSEM back into a BCIM. Consequently, the final clustering results are not optimal since these three independent learning processes only achieve their optimality without considering the coupling between them. To tackle this concern, this study presents an innovative discrete strategy for spectral clustering, leading to the development of a joint learning model referred to as Binary Multi-view Spectral Clustering (BMSC). The suggested BMSC effectively integrates BCIM, CSEM, and consistent graph learning. Precisely, the learning of the consistent similarity graph is dynamically adjusted according to the BCIM feedback to explore complementary information in different views. In turn, the dynamic consistent similarity graph will also facilitate learning the BCIM with view-specific CSEM and obtain the joint optimal clustering results. The suggested BMSC has been shown to be superior to other state-of-the-art methods via experimental findings conducted on several benchmark multi-view datasets.},
  archive      = {J_ISCI},
  author       = {Xueming Yan and Guo Zhong and Yaochu Jin and Xiaohua Ke and Fenfang Xie and Guoheng Huang},
  doi          = {10.1016/j.ins.2024.120899},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120899},
  shortjournal = {Inf. Sci.},
  title        = {Binary spectral clustering for multi-view data},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable graph clustering via expanders in the massively
parallel computation model. <em>ISCI</em>, <em>677</em>, 120897. (<a
href="https://doi.org/10.1016/j.ins.2024.120897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable clustering provides human-understandable reasons for decisions in black-box learning models. In a previous work, a decision tree built on the set of dimensions was used to define ranges of values for k -means clusters. For explainable graph clustering, we use expander graphs instead of dense subgraphs since powering an expander graph is guaranteed to result in a clique after at most a logarithmic number of steps. Consider a set of multi-dimensional points labeled with k labels. We introduce the heat map sorting problem as reordering the rows and columns of an input matrix (each point is a column and each row is a dimension) such that the labels of the entries of the matrix form connected components (clusters). A cluster is preserved if it remains connected, i.e., if it is not split into several clusters and no two clusters are merged. In the massively parallel computation model (MPC), each machine has a sublinear memory and the total memory of the machines is linear. We prove the problem is NP-hard. We give a fixed-parameter algorithm in MPC and an approximation algorithm based on expander decomposition. We empirically compare our algorithm with explainable k-means on several graphs of email and computer networks.},
  archive      = {J_ISCI},
  author       = {Sepideh Aghamolaei and Mohammad Ghodsi},
  doi          = {10.1016/j.ins.2024.120897},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120897},
  shortjournal = {Inf. Sci.},
  title        = {Explainable graph clustering via expanders in the massively parallel computation model},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Regret-based three-way decisions with set pair analysis in
incomplete information systems. <em>ISCI</em>, <em>677</em>, 120896. (<a
href="https://doi.org/10.1016/j.ins.2024.120896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Set pair analysis is a valuable tool for managing uncertain systems and can effectively handle missing information in the decision-making process. In addition, regret theory can objectively describe the impact of decision-maker psychology on decision-making. However, traditional decision-making methods rarely combine set pair analysis and regret theory to discuss decision problems. Thus, this article aims to integrate regret theory into the three-way decision theory based on set pair analysis, presenting a novel approach to address multi-attribute decision-making problems in real life. Specifically, we first propose a data-driven approach based on set pair analysis to determine attribute weights. Then, a similarity relationship is established based on the weighted distance to calculate conditional probability. Meanwhile, the average value of regret and joy under each attribute is selected as a reference point to determine the relative utility function using regret theory. Subsequently, we develop a new three-way decision method in incomplete information systems and apply it to solve practical problems. Finally, the effectiveness and superiority of our method are demonstrated by case analysis and comparison. We also conduct sensitivity analysis to examine the stability of the new method.},
  archive      = {J_ISCI},
  author       = {Haidong Zhang and Jiaxin Song and Chao Zhang and Yanping He},
  doi          = {10.1016/j.ins.2024.120896},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120896},
  shortjournal = {Inf. Sci.},
  title        = {Regret-based three-way decisions with set pair analysis in incomplete information systems},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven attack policy design for cyber-physical systems
under channel constraints. <em>ISCI</em>, <em>677</em>, 120894. (<a
href="https://doi.org/10.1016/j.ins.2024.120894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the design of data-driven sensor injection attack for cyber-physical systems (CPSs) under channel constraints, where the attacker can only access a part of the sensor channels and the accessible channels switch over time. To enhance the attack&#39;s effectiveness while maintaining its stealthiness, the design problem is formulated as a constraint-type L 2 L2 -gain optimization problem. Then, by optimizing the attack-direction matrix using the data-driven parametrization method, an attack policy with channel constraints is proposed. Specifically, the necessary and sufficient design conditions are established in terms of the attack stealthiness. Furthermore, the optimized attack stealthiness index and attack effectiveness index under channel constrains are obtained, and it is theoretically proven that the attack performance is reduced due to the passive channel switching. The effectiveness of the data-driven attack policy is illustrated by the IEEE 6 bus power system.},
  archive      = {J_ISCI},
  author       = {He Liu and Xiao-Jian Li},
  doi          = {10.1016/j.ins.2024.120894},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120894},
  shortjournal = {Inf. Sci.},
  title        = {Data-driven attack policy design for cyber-physical systems under channel constraints},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mg-SubAgg: Multi-granularity subgraph aggregation with
topology for GNN. <em>ISCI</em>, <em>677</em>, 120892. (<a
href="https://doi.org/10.1016/j.ins.2024.120892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although graph neural networks (GNNs) work well on graph data, they are black-box models that lack of reliable explanations for their predictions. We propose a multi-granularity subgraph aggregation method based on graph topology to explain GNNs. Specifically, given a trained GNN model and an input graph, our method constructs a subgraph by heuristics from fine-grained to coarse-grained and sorts the subgraph nodes to obtain subgraph and node-level explain. Furthermore, we propose an improved Shapley value as a heuristic function for the search algorithm, which strikes a balance between the time complexity and accuracy. Finally, experimental results on both synthetic and real datasets demonstrate that our method achieves best performance on seven datasets, quantifying the influence of individual nodes on prediction results and providing more reliable explanations.},
  archive      = {J_ISCI},
  author       = {Xiaoxia Zhang and Mengsheng Ye and Yun Zhang and Qun Liu and Guoyin Wang and Kesheng Wu},
  doi          = {10.1016/j.ins.2024.120892},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120892},
  shortjournal = {Inf. Sci.},
  title        = {Mg-SubAgg: Multi-granularity subgraph aggregation with topology for GNN},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label generation with consistency on the graph for
multi-label feature selection. <em>ISCI</em>, <em>677</em>, 120890. (<a
href="https://doi.org/10.1016/j.ins.2024.120890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection involves the selection of informative features in high-dimensional data sets based on the relationships among different variables. However, large-scale data sets often contain unknown labels that hold latent information, posing a challenge for discovery. Explicitly uncovering latent information among labels not only helps establish robust mappings between features and labels but also expands the applicable knowledge. This paper introduces a novel feature selection method called Label Generation with Consistency on the Graph for Multi-label Feature Selection (LGCM) to effectively integrate label generation and feature selection processes. The proposed method incorporates a two-way flipping mechanism that leverages the consistency on the global graph to guide label generation for each instance. Additionally, the feature selection model utilizes a shared low-rank feature space to minimize deviation from the label generation, providing feedback to the label generation process. Extensive experiments validate the effectiveness of LGCM in improving state-of-the-art feature selection methods in multi-label learning.},
  archive      = {J_ISCI},
  author       = {Pingting Hao and Ping Zhang and Qi Feng and Wanfu Gao},
  doi          = {10.1016/j.ins.2024.120890},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120890},
  shortjournal = {Inf. Sci.},
  title        = {Label generation with consistency on the graph for multi-label feature selection},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Hierarchical fuzzy inference based on bandler-kohout
subproduct. <em>ISCI</em>, <em>677</em>, 120889. (<a
href="https://doi.org/10.1016/j.ins.2024.120889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy inference with the Bandler-Kohout subproduct (BKS) has been successfully applied in many fields such as fuzzy control, artificial intelligence, image processing, data mining, decision-making, prediction, classification and so on. However, one has to face with the rule explosion in these applications. To deal with this problem, hierarchical fuzzy systems with the compositional rule of inference (CRI) method have been constructed by a series of low-dimensional sub fuzzy systems. And it has been proved that hierarchical fuzzy inference method can efficiently restrain the explosion of fuzzy rules. Therefore, in order to increase the computational efficiency of the fuzzy inference based on the BKS when multi-input-single-output (MISO) fuzzy rules are involved, this paper mainly constructs two hierarchical fuzzy inference methods based on the BKS in which the if-then rules are respectively interpreted by fuzzy implications and ML -implications. Moreover, the validity of the two BKS hierarchical fuzzy inferences is studied with the GMP rules. Finally, two examples are employed to illustrate the computational efficiency of our proposed BKS hierarchical inference methods.},
  archive      = {J_ISCI},
  author       = {Dechao Li and Zhisong Liu and Qiannan Guo},
  doi          = {10.1016/j.ins.2024.120889},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120889},
  shortjournal = {Inf. Sci.},
  title        = {Hierarchical fuzzy inference based on bandler-kohout subproduct},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sigmoid distance metric-based spline adaptive filters for
nonlinear adaptive noise cancellation. <em>ISCI</em>, <em>677</em>,
120888. (<a href="https://doi.org/10.1016/j.ins.2024.120888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article devises a spline adaptive filter (SAF) algorithm with robustness for nonlinear adaptive noise cancellation (NANC), called the SAF-SDM, which is built on a distance-based metric with a sigmoid kernel. The presented SAF-SDM delivers insignificant coefficient updates when the system is subjected to remarkable outliers, which leads to low steady-state errors. Additionally, we thoroughly analyze the mean behaviour and mean-square performance of the SAF-SDM at the theoretical level and validate the analysis results using nonlinear system identification (NSI) simulations. To fulfill the higher computational efficiency when a longer linear filter order is selected in the SAF, an improved SAF-SDM is developed through a frequency domain (FD) filtering program, called the FDSAF-SDM. Then, we provide an analysis of the calculation complexity of the two presented algorithms and compare them with those of several similar algorithms. Finally, simulation and experiment results demonstrate the excellence of the presented algorithms in NSI and NANC.},
  archive      = {J_ISCI},
  author       = {Wenqi Li and Zongtan Zhou and Hongxin Li and Ming Xu and Jingsheng Tang},
  doi          = {10.1016/j.ins.2024.120888},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120888},
  shortjournal = {Inf. Sci.},
  title        = {Sigmoid distance metric-based spline adaptive filters for nonlinear adaptive noise cancellation},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-subswarm cooperative particle swarm optimization
algorithm and its application. <em>ISCI</em>, <em>677</em>, 120887. (<a
href="https://doi.org/10.1016/j.ins.2024.120887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimization (PSO) is a classical evolutionary algorithm and has been widely used to solve continuous optimization problems. However, the performance of the PSO algorithm is highly sensitive to its control parameters and learning strategies. To address this problem, a multi-subswarm cooperative particle swarm optimization algorithm (MSC-PSO) is proposed in this paper. In MSC-PSO, firstly, a population muti-subswarm division method is designed to enhance the global exploration capability. Secondly, a level-based particle adaptive inertia weight strategy is introduced to adjust control parameters. Finally, a level-based update learning mechanism is used for particles adaptive selection learning strategy. The performance of the MSC-PSO is evaluated by the CEC2020 test suite, and five heuristic algorithms are compared with the MSC-PSO in the experiments. The experimental results demonstrate that the proposed MSC-PSO algorithm has significant advantages in terms of convergence speed and solving optimal solutions. Furthermore, the proposed MSC-PSO algorithm is used to solve the plant protection unmanned aerial vehicles (UAV) path planning problem. The experimental results proved that the proposed MSC-PSO algorithm effectively solves the real-world UAV path planning problem, and achieves at most a 34 % reduction in round-trip distance and a 24.1 % reduction in total non-spraying time compared to classical PSO.},
  archive      = {J_ISCI},
  author       = {Yu Tang and Kaicheng Huang and Zhiping Tan and Mingwei Fang and Huasheng Huang},
  doi          = {10.1016/j.ins.2024.120887},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120887},
  shortjournal = {Inf. Sci.},
  title        = {Multi-subswarm cooperative particle swarm optimization algorithm and its application},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DeGAN - decomposition-based unified anomaly detection in
static networks. <em>ISCI</em>, <em>677</em>, 120886. (<a
href="https://doi.org/10.1016/j.ins.2024.120886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection aims to identify anomalous occurrences in networks. However, this is more challenging than the traditional anomaly detection problem because anomalies in graphs can manifest in three different forms: anomalous nodes, anomalous edges, and anomalous sub-graphs. It is crucial to detect all these anomaly types within a single framework to provide a unified solution to the graph anomaly detection task. The main objective of this study is to propose a model that is capable of detecting all static graph anomalies in a single architecture across various domains. In this paper, we introduce DeGAN (Decomposition-based unified Graph ANomaly detection), a novel framework for unified graph anomaly detection in static networks. DeGAN combines two deep learning concepts with graph decomposition to identify anomalous graph objects: a graph neural network and an adversarial autoencoder. DeGAN is featured with its capability to detect anomalies in a single process, and adopting graph decomposition has improved performance compared to the traditional adversarial learning approach. DeGAN is evaluated with six real-world datasets to demonstrate that our framework can work in multiple domains. Experimental results demonstrate that DeGAN is capable of detecting anomalous nodes, edges, and sub-graphs within a single model. Additionally, the effectiveness of the sub-components of DeGAN has been demonstrated through experimentation. Even though DeGAN is proposed for plain graphs, it can be extended to attributed and dynamic graphs.},
  archive      = {J_ISCI},
  author       = {Ahmet Tüzen and Yusuf Yaslan},
  doi          = {10.1016/j.ins.2024.120886},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120886},
  shortjournal = {Inf. Sci.},
  title        = {DeGAN - Decomposition-based unified anomaly detection in static networks},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic configuration networks with improved supervisory
mechanism. <em>ISCI</em>, <em>677</em>, 120885. (<a
href="https://doi.org/10.1016/j.ins.2024.120885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stochastic configuration networks (SCNs) have been shown to have great potential for developing fast learning models, making them especially suitable for industrial devices. To achieve low consumption during the SCNs training process, this paper proposes an improved version of SCNs (ISCN-III). First, guided by the function dictionary set and the objective function space, a dynamic hyperparameter is proposed to replace the nonnegative sequence of the supervisory mechanism. Second, based on the dynamic hyperparameters and function dictionary set, an improved supervisory mechanism is proposed to further reduce computational consumption. Finally, the improved supervisory mechanism with the dynamic hyperparameter proves the universal approximation property of ISCN-III. ISCN-III is compared with SCNs and its improved versions using six benchmark datasets and subsequently applied to a grinding process and a continuous stirred tank reactor. The experimental results prove that ISCN-III has the advantages of low computational cost and fast convergence speed.},
  archive      = {J_ISCI},
  author       = {Jing Nan and Wei Dai and Dianhui Wang},
  doi          = {10.1016/j.ins.2024.120885},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120885},
  shortjournal = {Inf. Sci.},
  title        = {Stochastic configuration networks with improved supervisory mechanism},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lightweight multi-scale dynamic selection network for
medical image segmentation. <em>ISCI</em>, <em>677</em>, 120884. (<a
href="https://doi.org/10.1016/j.ins.2024.120884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation technology can assist doctors in accurately diagnosing and treating diseases. However, the diversity of segmented targets in scale and shape, as well as the complexity of the background environment, pose challenges for existing segmentation methods. In this context, we propose two effective deep neural networks, the multi-scale dynamic selection network (MDSNet) and its lightweight version MDSNet-Light for medical image segmentation. In MDSNet, we design a multi-scale dynamic selection module to capture multi-scale contextual information and dynamically adjust the acceptance domain of the feature map to achieve feature fusion at the optimal scale. We introduce PixelShuffle and PixelUnshuffle as sampling methods to effectively alleviate information loss issues for small-scale objects caused by pooling. Experimental results show that MDSNet outperforms eight existing superior neural networks in the test data of the publicly available dataset LIDC-IDRI on four evaluation indicators. And MDSNet-Light achieves a good balance between network performance and computational complexity, providing an option for applications in limited computing resource scenarios.},
  archive      = {J_ISCI},
  author       = {Xue-Mei Dong and Yu Sun and Lili Wang},
  doi          = {10.1016/j.ins.2024.120884},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120884},
  shortjournal = {Inf. Sci.},
  title        = {Lightweight multi-scale dynamic selection network for medical image segmentation},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). A new distance measure between two basic probability
assignments based on penalty coefficient. <em>ISCI</em>, <em>677</em>,
120883. (<a href="https://doi.org/10.1016/j.ins.2024.120883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty information processing is a challenging topic in information science. Dempster-Shafer evidence theory shows excellent performance when dealing with uncertainty in information representation, fusion, and processing. The measurement of the distance between the basic probability assignments (BPA) in Dempster-Shafer evidence theory is a powerful tool that deals with uncertainty in evidential information processing. Most of the existing methods are based on the difference in the assessment of evidential degree for different hypotheses, with a notable example Belief-Jensen-Shannon (BJS) divergence. However, these methods ignore the information that is carried by different units in the power sets that represent the hypotheses, i.e., the difference on the hypotheses themselves that include in the evidential degree assessment of different BPA should be considered in the distance measurement. Therefore, in this paper, a novel method grounded in BJS divergence and incorporating a penalty coefficient to rectify the distance between basic probability assignments is proposed. This methodology showcases commendable properties, including symmetry, boundedness, and adherence to the triangle inequality. To demonstrate the efficiency of the proposed distance measurement method between BPAs, we apply it to two common-used machine learning data sets: Iris data set and Dry Beans data set. Compared to the represented existing evidence distance measurement approaches, the proposed method yields superior performance in both data sets with respect to classification accuracy.},
  archive      = {J_ISCI},
  author       = {Meizhu Li and Linshan Li and Qi Zhang},
  doi          = {10.1016/j.ins.2024.120883},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120883},
  shortjournal = {Inf. Sci.},
  title        = {A new distance measure between two basic probability assignments based on penalty coefficient},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive threshold-based semi-supervised learning method
for cardiovascular disease detection. <em>ISCI</em>, <em>677</em>,
120881. (<a href="https://doi.org/10.1016/j.ins.2024.120881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep cardiovascular disease (CVD) detection usually achieves good performance with large-scale labeled electrocardiograms (ECGs), but manual labeling of ECGs is tedious. Semi-supervised learning (SSL) aims to improve model performance through unlabeled data. In this study, an adaptive threshold-based semi-supervised learning model (ATSS-LGP) is proposed. It introduces the multibranch network (MBN) to generate local and global predictions for 12-lead ECG. The labeled ECGs are used to train the model in supervised manner and produce adaptive thresholds through the proposed prediction voting decision mechanism. The unlabeled ECGs are divided into high-confidence and low-confidence parts by the adaptive thresholds. The pseudo-labeling technique and consistency regularization are used to jointly guide the unsupervised learning, which can fully utilize all unlabeled ECGs. To the best of our knowledge, this is the first SSL algorithm that explores adaptive threshold in ECG. ATSS-LGP shows impressive performance in CVD detection. Using the same number of labeled ECGs, it achieves at least a 5.15% increase in accuracy over pure supervised learning. Moreover, ATSS-LGP achieves comparable performance to fully supervised method using only 10% of labeled ECGs. In summary, ATSS-LGP is a suitable SSL algorithm for 12-lead ECGs, which can greatly reduce the burden of ECG labeling in deep learning.},
  archive      = {J_ISCI},
  author       = {Jiguang Shi and Zhoutong Li and Wenhan Liu and Huaicheng Zhang and Deyu Luo and Yue Ge and Sheng Chang and Hao Wang and Jin He and Qijun Huang},
  doi          = {10.1016/j.ins.2024.120881},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120881},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive threshold-based semi-supervised learning method for cardiovascular disease detection},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dynamic-speciation-based differential evolution with ring
topology for constrained multimodal multi-objective optimization.
<em>ISCI</em>, <em>677</em>, 120879. (<a
href="https://doi.org/10.1016/j.ins.2024.120879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multimodal multi-objective optimization problems (CMMOPs) consist of multiple equivalent constrained Pareto sets (CPSs) that have the identical constrained Pareto front (CPF). It is challenging for primary multimodal multi-objective evolutionary algorithms (MMEAs) to solve CMMOPs since they do not consider constraints. To tackle this challenge, a dynamic speciation-based differential evolution with ring topology, termed DSRDE, for solving CMMOPs is developed in this paper. To search for multiple equivalent CPSs in CMMOPs, the dynamic speciation-based niche strategy is developed. The dynamic speciation-based niche strategy divides the population into multiple species, each of which searches for diverse and equivalent CPSs in different regions. Particularly, the species number is dynamically decreased to explore the equivalent CPSs with good convergence. Then, a ring topology is constructed among multiple species and their neighbors to balance the diversity, convergence, and feasibility of solutions. Continuously, each species interacts information with its neighbors and searches for equivalent CPSs. DSRDE adopts the popular constrained dominance principle to handle constraints and uses the differential evolutionary algorithm to locate diverse CPSs in the ring topology. It is compared with several state-of-the-art algorithms in two CMMOPs test suites for evaluating the performance of the proposed DSRDE. The experimental results confirm that DSRDE is competitive and has the ability to find multiple CPSs when tackling CMMOPs. DSRDE is also implemented in a real-world CMMOP and obtains superior performance.},
  archive      = {J_ISCI},
  author       = {Guoqing Li and Weiwei Zhang and Caitong Yue and Yirui Wang and Jun Tang and Shangce Gao},
  doi          = {10.1016/j.ins.2024.120879},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120879},
  shortjournal = {Inf. Sci.},
  title        = {A dynamic-speciation-based differential evolution with ring topology for constrained multimodal multi-objective optimization},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Secure consensus for multiagent systems with hybrid cyber
attacks: A multi-round-robin protocol-based approach. <em>ISCI</em>,
<em>677</em>, 120878. (<a
href="https://doi.org/10.1016/j.ins.2024.120878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses secure consensus of discrete multiagent systems (DMASs) with information exchange under Multi-Round Robin Protocol (MRRP). Since the information exchange among agents is via the constrained networked transmission channel, it implies that the communication resources should be fully utilized. To overcome this issue, MRRP is employed to adjust the data packet transmissions and conserve the limited network resources. Considering that the transmitted signals may be tampered by malicious attacks during transmission process, an new control strategy is presented taking the negative effects of the deception and injection attacks into account. Based on the augmented system model, a sufficient condition is attained. Moreover, the distributed controller gain is obtained such that the DMASs reach consensus with definite bound in mean-square sense. One simulation example is exploited to demonstrate the validity of the acquired consensus control strategy.},
  archive      = {J_ISCI},
  author       = {Jinliang Liu and Hao Zheng and Lijuan Zha and Engang Tian and Chen Peng},
  doi          = {10.1016/j.ins.2024.120878},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120878},
  shortjournal = {Inf. Sci.},
  title        = {Secure consensus for multiagent systems with hybrid cyber attacks: A multi-round-robin protocol-based approach},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized sparse and outlier-robust broad learning systems
for multi-dimensional output problems. <em>ISCI</em>, <em>677</em>,
120876. (<a href="https://doi.org/10.1016/j.ins.2024.120876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broad learning systems (BLSs) are becoming increasingly popular due to their fast and superior learning capabilities. However, their performances are susceptible to outliers and dense networks. The Elastic-net robust BLS (ER-BLS), which employs an ℓ 1 ℓ1 -norm loss function along with Elastic-net regularization, attempts to mitigate these issues by promoting network sparsity. Nevertheless, even ER-BLS fails to achieve satisfactory robustness and sparsity in multi-dimensional output tasks because the ℓ 1 ℓ1 -norm ignores the correlations between the output dimensions and output weights. Therefore, we propose a generalized Elastic-net robust BLS (GER-BLS) by generalizing the ℓ 1 ℓ1 -norm to the L 2 , 1 L2,1 -norm. The L 2 , 1 L2,1 -norm enhances robustness by treating the residuals across all output dimensions as a whole and induces node-level sparsity by penalizing all output weights connected to a single hidden node. The alternating direction method of multipliers (ADMM) algorithm was employed to solve GER-BLS efficiently, circumventing the non-differentiable issue of the objective function. Moreover, we developed DGER-BLS, a distributed variant of GER-BLS, tailored to handle data with distributed storage. The convergence analysis of our proposed algorithms and a large number of numerical experiments on multi-dimensional output datasets demonstrated the effectiveness of GER-BLS and DGER-BLS in dealing with outliers, distributed stored data, and sparsity.},
  archive      = {J_ISCI},
  author       = {Yuao Zhang and Yunwei Dai and Shuya Ke and Qingbiao Wu and Jing Li},
  doi          = {10.1016/j.ins.2024.120876},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120876},
  shortjournal = {Inf. Sci.},
  title        = {Generalized sparse and outlier-robust broad learning systems for multi-dimensional output problems},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A generic approach for network defense strategies generation
based on evolutionary game theory. <em>ISCI</em>, <em>677</em>, 120875.
(<a href="https://doi.org/10.1016/j.ins.2024.120875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generation of optimal defense strategies in dynamic adversarial environments is crucial for cybersecurity. Recently, defense approaches based on evolutionary game theory have gained significant achievements. However, they would fail when facing complex networks and sophisticated attack strategies, due to the fatal drawbacks of defense strategy generation considering atomic attacks only. To relieve this issue, a generic approach for generating defense strategies using evolutionary game theory is proposed in this paper. Initially, a novel payoff quantification method for network attack-defense games based on attack graphs is designed. Innovatively, two factors concerning the decision-maker&#39;s degree of irrationality (DI) and the level of environmental security (LES) are introduced into the replicator dynamics equation to model the impacts on equilibrium solutions. Noting that Active Directory (AD) domain service is one of the most used and representative information security management system in Windows domains, from which attack graphs and paths can be plainly extracted and analyzed. Therefore, it is necessary and imperative to anchor AD to unfold the theoretical analyses and experiments validation based on a real environment. Case studies on a real-world AD network demonstrate that the proposed approach is effective and can generate stable and efficient defense strategies.},
  archive      = {J_ISCI},
  author       = {Liang Liu and Chuhao Tang and Lei Zhang and Shan Liao},
  doi          = {10.1016/j.ins.2024.120875},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120875},
  shortjournal = {Inf. Sci.},
  title        = {A generic approach for network defense strategies generation based on evolutionary game theory},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring the vulnerability of self-supervised monocular
depth estimation models. <em>ISCI</em>, <em>677</em>, 120874. (<a
href="https://doi.org/10.1016/j.ins.2024.120874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in deep learning have substantially boosted the performance of monocular depth estimation (MDE), an essential component in fully-vision-based autonomous driving systems (e.g., Tesla and Toyota). These advancements, however, have been primarily directed towards optimizing performance, with limited consideration for security vulnerabilities. This study introduces the first backdoor attack against self-supervised MDE models. By conceptualizing backdoor attacks as a multi-task challenge, we propose a novel attack framework that employs multi-task learning to iteratively optimize the standard MDE subtask and the backdoor learning subtask. Within this framework, we design two types of backdoor attacks: Target Disappearing Backdoor Attack (TDBA) and Depth Increasing Backdoor Attack (DIBA). TDBA renders specific objects invisible to the compromised model, while DIBA dramatically inflates the depth of trigger-associated objects. Extensive evaluations on three mainstream MDE models show that TDBA can make the target model directly ignore the specific objects, with a mean depth error under 0.06 meters, while DIBA significantly increases the depth for trigger-associated objects, resulting in a mean depth error exceeding 94.2 meters. These findings highlight the urgent need for advanced security measures in the development of MDE models, to mitigate such vulnerabilities.},
  archive      = {J_ISCI},
  author       = {Ruitao Hou and Kanghua Mo and Yucheng Long and Ning Li and Yuan Rao},
  doi          = {10.1016/j.ins.2024.120874},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120874},
  shortjournal = {Inf. Sci.},
  title        = {Exploring the vulnerability of self-supervised monocular depth estimation models},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IRDA: Implicit data augmentation for deep imbalanced
regression. <em>ISCI</em>, <em>677</em>, 120873. (<a
href="https://doi.org/10.1016/j.ins.2024.120873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data distributions are prevalent in real-world classification and regression tasks. Data augmentation is a commonly employed technique to mitigate this issue, with implicit methods gaining attention for their effectiveness and efficiency. However, implicit data augmentation methods have not been extensively explored in the context of regression tasks. To address this gap, we introduce IRDA, a novel learning method for regression that incorporates implicit data augmentation. Our approach includes developing a new augmentation strategy specifically tailored for deep imbalanced regression tasks, and a regression loss function that is suitable for real-world data with imbalanced label distributions and non-uniformly distributed features. We derive an easily computable surrogate loss and propose two implicit data augmentation algorithms, one incorporating meta-learning and one without. Additionally, we provide a regularization perspective to offer a deeper understanding of IRDA. We evaluate IRDA on five datasets, including a large-scale dataset, demonstrating its effectiveness in mitigating the adverse effects of imbalanced data distribution and its adaptability to various regression tasks.},
  archive      = {J_ISCI},
  author       = {Weiyao Zhu and Ou Wu and Nan Yang},
  doi          = {10.1016/j.ins.2024.120873},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120873},
  shortjournal = {Inf. Sci.},
  title        = {IRDA: Implicit data augmentation for deep imbalanced regression},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural causal graph collaborative filtering. <em>ISCI</em>,
<em>677</em>, 120872. (<a
href="https://doi.org/10.1016/j.ins.2024.120872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph collaborative filtering (GCF) has emerged as a prominent method in recommendation systems, leveraging the power of graph learning to enhance traditional collaborative filtering (CF). One common approach in GCF involves employing Graph Convolutional Networks (GCN) to learn user and item embeddings and utilize these embeddings to optimize CF models. However, existing GCN-based methods often fall short of generating satisfactory embeddings, mainly due to their limitations in capturing node dependencies and variable dependencies within the graph. Consequently, the learned embeddings are fragile in uncovering the root causes of user preferences, leading to sub-optimal performance of GCF models. In this work, we propose integrating causal modeling with the learning process of GCN-based GCF models, leveraging causality-aware graph embeddings to capture complex dependencies in recommendations. Our methodology encompasses three key designs: 1) Causal Graph conceptualization, 2) Neural Causal Model parameterization, and 3) Variational inference for the Neural Causal Model. We define a Causal Graph to model genuine dependencies in GCF models and utilize this Causal Graph to parameterize a Neural Causal Model. The proposed framework, termed Neural Causal Graph Collaborative Filtering (NCGCF) , uses variational inference to approximate neural networks under the Neural Causal Model. As a result, NCGCF is able to leverage the expressive causal effects from the Causal Graph to enhance graph representation learning. Extensive experimentation on four datasets demonstrates NCGCF&#39;s ability to deliver precise recommendations consistent with user preferences.},
  archive      = {J_ISCI},
  author       = {Xiangmeng Wang and Qian Li and Dianer Yu and Wei Huang and Qing Li and Guandong Xu},
  doi          = {10.1016/j.ins.2024.120872},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120872},
  shortjournal = {Inf. Sci.},
  title        = {Neural causal graph collaborative filtering},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A novel multi-label feature selection method based on
knowledge consistency-independence index. <em>ISCI</em>, <em>677</em>,
120870. (<a href="https://doi.org/10.1016/j.ins.2024.120870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification encounters the challenge of dealing with high dimensional data. In response to this challenge, numerous researchers have proposed various multi-label feature selection methods from different perspectives. However, existing methods overlook the consistency and independence of knowledge granules, and thus fail to extract valuable and distinctive information from the knowledge granules that is relevant to the label space. To address this issue, we propose a novel multi-label feature selection method based on the knowledge consistency-independence index (CIMLFS). Firstly, we introduce the concepts of knowledge consistency granularity and knowledge independence granularity to explore valuable and distinctive information from the knowledge granule families. Secondly, based upon these concepts, we define the consistency coefficient, independence coefficient, and consistency gain for features, ultimately considering the three perspectives to achieve the knowledge consistency-independence index. Furthermore, we present a multi-label feature selection method utilizing the index. Finally, to assess the effectiveness of CIMLFS, we conduct comparative experiments with eight representative multi-label feature selection methods on twelve benchmark multi-label data sets and using four evaluation metrics. The final experimental results indicate that CIMLFS ranks the first on three metrics and the second on one metric.},
  archive      = {J_ISCI},
  author       = {Xiangbin Liu and Heming Zheng and Wenxiang Chen and Liyun Xia and Jianhua Dai},
  doi          = {10.1016/j.ins.2024.120870},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120870},
  shortjournal = {Inf. Sci.},
  title        = {A novel multi-label feature selection method based on knowledge consistency-independence index},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic configuration networks with particle swarm
optimisation search. <em>ISCI</em>, <em>677</em>, 120868. (<a
href="https://doi.org/10.1016/j.ins.2024.120868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While building stochastic configuration networks (SCNs), there is no guarantee that the randomly generated weights will satisfy the supervisory mechanism and that the adopted weights will significantly reduce the training error. This paper extends SCN by applying the particle swarm optimisation (PSO) technique for one-step optimising of the set of random weights generated. These optimised weights provide a higher likelihood of satisfying the supervisory mechanism and improving the learning rate. Simulations are carried out over five regression and three classification datasets. Results demonstrate that an improved training rate and generalisation can be achieved.},
  archive      = {J_ISCI},
  author       = {Matthew J. Felicetti and Dianhui Wang},
  doi          = {10.1016/j.ins.2024.120868},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120868},
  shortjournal = {Inf. Sci.},
  title        = {Stochastic configuration networks with particle swarm optimisation search},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-stage clonal selection algorithm for local feature
selection on high-dimensional data. <em>ISCI</em>, <em>677</em>, 120867.
(<a href="https://doi.org/10.1016/j.ins.2024.120867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various evolutionary computation algorithms have shown their excellent performance for high-dimensional feature selection (FS). However, most of current FS methods choose a global feature subset and ignore the correlations between feature subsets and sample subspaces, which limits the performance of methods in the sample space with different probability distributions. To solve the issue, we propose a two-stage clonal selection algorithm for filter-based local feature selection (TSCSA-LFS) that integrates symmetric uncertainty and a discrete clonal selection algorithm with three contributions. First, unlike conventional feature selection methods, TSCSA-LFS introduces local sample behaviors and assigns subsets of features for different sample regions. Second, an improved discrete clonal selection algorithm is developed for searching relevant features, which contains mutual information-based individual initialization, a differential evolution-based mutation strategy pool and a local search technique. Third, a two-part antibody representation is employed for automatical adjustment of the weight-related parameter. Our method shows the promising experimental results compared with well-known global FS and clonal selection-based local FS methods on fourteen high-dimensional datasets. For instance, our method can obviously outperform local FS, filter-based and hybrid methods on at least nine datasets},
  archive      = {J_ISCI},
  author       = {Yi Wang and Hao Tian and Tao Li and Xiaojie Liu},
  doi          = {10.1016/j.ins.2024.120867},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120867},
  shortjournal = {Inf. Sci.},
  title        = {A two-stage clonal selection algorithm for local feature selection on high-dimensional data},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fisher discrimination multiple kernel dictionary learning
for robust identification of nonlinear features in machinery health
monitoring. <em>ISCI</em>, <em>677</em>, 120862. (<a
href="https://doi.org/10.1016/j.ins.2024.120862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In sparse representation-based classification, Fisher discrimination dictionary learning (FDDL) has attracted widespread attention due to its advantages such as fewer parameters and good dictionary discriminability. However, due to its linear nature, it is difficult to handle nonlinear features. Kernel-based nonlinear transformation enables dictionary learning to capture nonlinear features embedded in samples, but traditional single-kernel methods have limited performance. In this paper, a Fisher discrimination multiple kernel dictionary learning (FDMKDL) method is proposed, in which Fisher discriminative criterion is imposed on both high-dimensional samples and coding coefficients. Specifically, we derive the kernel version of FDDL, i.e., Fisher discrimination kernel dictionary learning (FDKDL) to learn nonlinear features and promote dictionary discriminability. Meanwhile, to avoid the problem of poor adaptability and possible manual selection caused by single-kernel methods, we further derive a flexible multiple kernel learning (MKL) framework, which utilizes the complementary information of multiple kernel functions to adaptively obtain the optimal weights and synthesize a discriminative kernel space. Finally, FDMKDL combines FDKDL with this MKL framework to obtain a more discriminative dictionary. Experimental evaluations conducted on two datasets demonstrate the effectiveness and robustness of the proposed FDMKDL method in learning nonlinear features for machinery health monitoring when compared to several state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Xin Zhang and Tao Yang and Hao Long and Haiyang Shi and Jiaxu Wang and Laihao Yang},
  doi          = {10.1016/j.ins.2024.120862},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120862},
  shortjournal = {Inf. Sci.},
  title        = {Fisher discrimination multiple kernel dictionary learning for robust identification of nonlinear features in machinery health monitoring},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DSCAPS: A decentralized smart contract auditing platform
based on sidechain. <em>ISCI</em>, <em>677</em>, 120861. (<a
href="https://doi.org/10.1016/j.ins.2024.120861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Successful attacks on smart contracts can result in loss of digital assets with potential financial and reputation implications. This reinforces the importance of auditing smart contracts prior to deployment. However, existing auditing approaches are generally non transparent, inefficient, limited to known bugs, and imprecise due to lack of real-world information in the blockchain. Therefore, we design a D ecentralized S mart C ontract A uditing P latform based on S idechain (DSCAPS) in this paper. DSCAPS leverages the two-way peg sidechain technology to implement the interactions between the main chain and the sidechain which is used as the audit chain platform. Unlike conventional centralized audits, blockchain users can evaluate the security of contracts in a real-world smart contract execution environment by designing an appropriate incentive mechanism. Thus, detection results will be more comprehensive and precise. Moreover, to prevent multi-party collusion from manipulating the blockchain or audit process, we introduce a margin mechanism. Findings from our security analysis demonstrate that DSCAPS can mitigate potential threats. Evaluation findings based on the system implementation also show that DSCAPS is efficient in auditing a contract with performance overheads of less than 10%.},
  archive      = {J_ISCI},
  author       = {Wenchao Jiang and Weiqi Dai and Jiamin Zheng and Zhipeng Liang and Quankeng Huang and Fanlong Zhang and Tao Wu},
  doi          = {10.1016/j.ins.2024.120861},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120861},
  shortjournal = {Inf. Sci.},
  title        = {DSCAPS: A decentralized smart contract auditing platform based on sidechain},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Stochastic configuration networks with group lasso
regularization. <em>ISCI</em>, <em>677</em>, 120860. (<a
href="https://doi.org/10.1016/j.ins.2024.120860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic configuration networks (SCNs) construct randomized learner models incrementally in a node-by-node format under the guidance of its supervisory mechanism. Block-incremental SCNs (BSCN) extend the original SCNs with block increments to effectively reduce the number of iterations required during model building. Yet, two new issues emerge: the computationally expensive Moore-Penrose generalized inverse in inequality constraints, and some potential redundant hidden nodes. To address these limitations, this study presents efficient block-incremental SCNs (EBSCN) with group lasso regularization, termed EBSCNGL. The hidden block is treated as a specialized form of hidden node, and the output vector is directly replaced with the output matrix in the weights formula of SC-I (the first algorithmic implementation of SCNs) to evaluate the output weights of the newly added hidden block. Subsequently, a new set of inequalities without matrix generalized inverse is presented to ensure the universal approximation capability of EBSCN. Moreover, group lasso regularization is introduced to prune redundant nodes of the hidden layer. We further transform its regularized least-squares solution into an efficient form with proved convergence based on the Woodbury matrix identity. Empirical results on function approximation, benchmark classification, and a practical industrial application verify the efficiency and sparsity of our proposed method.},
  archive      = {J_ISCI},
  author       = {Yang Wang and Guanci Yang and Chenglong Zhang and Yongming Wu},
  doi          = {10.1016/j.ins.2024.120860},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120860},
  shortjournal = {Inf. Sci.},
  title        = {Stochastic configuration networks with group lasso regularization},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fully distributed adaptive event-triggered bipartite
containment control of linear multiagent systems with actuator faults.
<em>ISCI</em>, <em>677</em>, 120854. (<a
href="https://doi.org/10.1016/j.ins.2024.120854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a new type of fully distributed double event-triggered bipartite containment (DETBC) problem for linear multiagent systems (MASs). Meanwhile, multiple leaders with non-zero inputs and time-varying multiplicative and additive actuator faults (TMAAFs) are considered. First, in contrast to traditional event-triggered mechanisms (ETMs), the proposed novel double ETMs can guarantee that information transfer between agents and controller updates proceeds asynchronously. Some adaptive parameters are introduced in the trigger functions to enhance the dynamic adjustment ability of double ETMs. The trigger threshold depends on the relative state-dependent, which is independent of continuous information from neighbors. Then, a fault-tolerant DETBC protocol is designed to solve actuator fault problems. Moreover, compared with other relevant works, our control protocol is fully distributed, which avoids reliance on global information. Finally, a simulation experiment is conducted to validate the feasibility of the designed protocol.},
  archive      = {J_ISCI},
  author       = {Jing He and Dongsheng Yang and Juan Zhang and Bowen Zhou},
  doi          = {10.1016/j.ins.2024.120854},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120854},
  shortjournal = {Inf. Sci.},
  title        = {Fully distributed adaptive event-triggered bipartite containment control of linear multiagent systems with actuator faults},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). L1-gain control for 2D delayed positive continuous markov
jumping systems. <em>ISCI</em>, <em>677</em>, 120849. (<a
href="https://doi.org/10.1016/j.ins.2024.120849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study is focused on analyzing the L 1 L1 -stochastic internal stability and the design of an L 1 L1 -gain controller for two-dimensional (2D) continuous positive Markov jumping systems (PMJSs) with constraints on the inputs and states. An algorithm is developed to explicitly determine the state feedback control law with the optional L 1 L1 -gain performance. First, by constructing a co-positive stochastic Lyapunov function for the positive system and establishing the equation for the Markov states&#39; mathematical expectation, several sufficient and necessary conditions for L 1 L1 -stochastic internal stability are derived. This analysis indicates that 2D PMJSs with directional delays are influenced by sizes of the system matrices and magnitude of delays, and transition matrix. Second, a method for calculating the L 1 L1 -gain is formulated utilizing linear programming (LP), thus, an L 1 L1 -gain controller is designed to guarantee that the closed-loop system is positive and L 1 L1 -stochastically internally stable, while achieving optimal L 1 L1 -gain performance. Two numerical and practical examples are considered, and the influence of delays and transition probability matrices on the L 1 L1 -gain is specified to validate the preceding theoretical findings.},
  archive      = {J_ISCI},
  author       = {Zhaoxia Duan and Yue Sun and Yuchun Feng and Choon Ki Ahn and Zhengrong Xiang},
  doi          = {10.1016/j.ins.2024.120849},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120849},
  shortjournal = {Inf. Sci.},
  title        = {L1-gain control for 2D delayed positive continuous markov jumping systems},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Disturbance rejection and tracking control design for
nonlinear semi-markovian jump systems. <em>ISCI</em>, <em>677</em>,
120841. (<a href="https://doi.org/10.1016/j.ins.2024.120841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, combined problem of robust output tracking and disturbance rejection for nonlinear semi-Markovian jump systems with time-varying delays and uncertainties is investigated in through improved-equivalent-input-disturbance-estimator (IEIDE)-based modified repetitive control (MRC) law. More precisely, IEIDE is introduced into the channel of control input to estimate and compensate the disturbance signals with high precision with an eye to attain the robust tracking performance. Subsequently, MRC block is internally embedded in the control loop that makes the system output signals to track the given reference signals inside the selected neighborhood of the equilibrium via repetitive learning. Furthermore, to obtain the controller and observer gain matrices, the linear matrix inequality conditions are derived based on the technique of Lyapunov stability. Finally, a switching boost converter circuit and single-link robot arm model are used to demonstrate the control scheme&#39;s efficiency and superiority. In addition to that the comparative study with the existing works are carried out. In this way, the potential benefits from practical perspectives of the developed results are validated.},
  archive      = {J_ISCI},
  author       = {S. Harshavarthini and R. Sakthivel and R. Abinandhitha and O.M. Kwon},
  doi          = {10.1016/j.ins.2024.120841},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120841},
  shortjournal = {Inf. Sci.},
  title        = {Disturbance rejection and tracking control design for nonlinear semi-markovian jump systems},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A game theoretic conflict analysis model with linguistic
assessments and two levels of game play. <em>ISCI</em>, <em>677</em>,
120840. (<a href="https://doi.org/10.1016/j.ins.2024.120840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a conflict scenario, the domestic and international stake holders vye to safeguard their specific vested interests and objectives, like in the Syrian and Afghan conflicts. Knowledge about the position of domestic players can help both domestic and international players determine the root causes of conflict and work in groups to resolve the divergent issues. Due to complex nature of conflicts, it is pertinent to study conflict at domestic and international levels separately. For this purpose, we design a two-level conflict analysis model based on game theory and linguistic assessments of players. The first level deals with local players by playing a game between each of them in view of local issues and taking into account the local grouping. At the second level, game is played between local groups and international players regarding multiple issues. In this way, all the parties calculate the gains or losses of comparable actions of each other. Thus, the proposed model provides a comprehensive study of conflict. This paper studies Syrian conflict to validate the conflict analysis algorithm and explain the computations and results.},
  archive      = {J_ISCI},
  author       = {Zohaib Gillani and Zia Bashir and Saira Aquil},
  doi          = {10.1016/j.ins.2024.120840},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120840},
  shortjournal = {Inf. Sci.},
  title        = {A game theoretic conflict analysis model with linguistic assessments and two levels of game play},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interval threshold-based finite-frequency sensor attack
detection for interconnected cyber-physical systems. <em>ISCI</em>,
<em>677</em>, 120839. (<a
href="https://doi.org/10.1016/j.ins.2024.120839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the problem of observer design and its applications to attack detection for an interconnected cyber-physical system subjected to unknown disturbances and sensor attacks. First, an overall system is constructed using the information on the interconnection of several subsystems, and problems related to the observer design are then solved. Second, to facilitate the residual&#39;s sensitivity to attacks and its robustness against unknown disturbances, an observer is provided. The gain matrix is developed using both the H − H− performance and mixed L 2 − L ∞ / H ∞ L2−L∞/H∞ performance. Third, for the suppression of the effect of unknown disturbances and attack signals on the errors in the state estimation and on attack detection in a finite-frequency domain, the generalized Kalman-Yakubovich-Popov lemma is applied to set the conditions under which the observer can operate effectively. In light of the detection scheme, we suggest a detection logic that prevents false alarms by comparing the evaluation function to the corresponding threshold. Additionally, an interval threshold-based method is introduced to establish the threshold bounds, and numerical simulation results are provided to demonstrate the method&#39;s validity in this paper.},
  archive      = {J_ISCI},
  author       = {Shenghui Guo and Mingzhu Tang and Choon Ki Ahn},
  doi          = {10.1016/j.ins.2024.120839},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120839},
  shortjournal = {Inf. Sci.},
  title        = {Interval threshold-based finite-frequency sensor attack detection for interconnected cyber-physical systems},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient suppression algorithms for preserving trajectory
privacy. <em>ISCI</em>, <em>677</em>, 120837. (<a
href="https://doi.org/10.1016/j.ins.2024.120837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concerns about the security of trajectory data have surfaced amid rising public awareness of privacy protection. In this study, we focus on how to protect personal information effectively when adversaries have access to a portion of users’ trajectory data. To resolve this issue, we design a graph-based index structure to store users’ trajectory data and develop a novel subtrajectory upper bound estimation method and corresponding pruning strategies. Using a graph-based index structure and pruning strategies, we propose a global suppression algorithm and a local suppression algorithm to prevent personal information from being extracted from the original trajectory data. Experimental results show that the maintenance cost of the graph-based index structure is low when performing global and local suppression, and that the pruning strategies effectively eliminate unnecessary computation of non-upper-bound subtrajectories. Therefore, the execution times of the proposed algorithms are far shorter than those of existing algorithms.},
  archive      = {J_ISCI},
  author       = {Chen-Yi Lin},
  doi          = {10.1016/j.ins.2024.120837},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120837},
  shortjournal = {Inf. Sci.},
  title        = {Efficient suppression algorithms for preserving trajectory privacy},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Stream label distribution learning processing via broad
learning system. <em>ISCI</em>, <em>677</em>, 120836. (<a
href="https://doi.org/10.1016/j.ins.2024.120836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label distribution learning (LDL) is designed for label ambiguity problem which widely exists in tasks like image classification and sentiment analysis. Nevertheless, most existing LDL methods adopt a batch-wise processing strategy that is not applicable to stream data issues, like video semantic segmentation and object tracking in auto-driving applications. For these scenarios where dynamic new data is generated continuously, stream LDL processing can be applied to reflect the changes in time and improve the accuracy of online prediction. This paper proposes a novel broad learning system (BLS) based online label distribution learning framework (SLD_BLS). Broad learning system was adopted as the baseline model because its incremental weight updating scheme, excellent efficiency, and outstanding performance can process streaming data in dynamically changing environments. However, there are several challenges to adapt BLS for LDL: 1) BLS&#39;s update rule cannot process LDL data; 2) BLS cannot show the mapping relationship between feature space and label space; 3) BLS neglects the inter-label relationships. To tackle these challenges, 1) a new weight update rule for LDL is designed; 2) a manifold regularization is applied to exploit the feature space manifolds; 3) an explicit label collaborating approach is introduced to positively bootstrapping the model training. Extensive experiments on 13 label distribution datasets indicated the performance of SLD_BLS outperforms 9 state-of-the-art LDL models on most datasets with significant reductions in training time across 6 metrics.},
  archive      = {J_ISCI},
  author       = {Guangtai Wang and Jintao Huang and Chi-Man Vong},
  doi          = {10.1016/j.ins.2024.120836},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120836},
  shortjournal = {Inf. Sci.},
  title        = {Stream label distribution learning processing via broad learning system},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FDCNN-AS: Federated deep convolutional neural network
alzheimer detection schemes for different age groups. <em>ISCI</em>,
<em>677</em>, 120833. (<a
href="https://doi.org/10.1016/j.ins.2024.120833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer&#39;s disease (AD) is a memory-related disease that occurs in the human brain where neurons become degenerative. It is an evolved form of dementia that deteriorates over time. Machine learning, an extended version of deep learning, has appeared as an optimistic strategy for AD detection. Regardless, the existing AD detection approaches have yet to acquire the expected accuracy, mainly due to unreasonable data for training and testing. In this paper, we present the Federated Deep Convolutional Neural Network Alzheimer Detection Schemes (FDCNN-AS), specifically designed for varying age groups. FDCNN-AS is an efficient framework that contains architecture, algorithm flow, and implementation. It manages AD data from various laboratories and processes it in additional clinics. Our method mixes training data models from different types of data such as positron emission tomography, summed tomography, magnetic resonance imaging, blood tests, and questionnaires about synaptic degeneration. Further, we look at some restrictions that have yet to be addressed in AD detection. These include seeing AD at different ages, extrapolating the severity of brain damage, comparing treatment and recovery rates, and finding benign and malignant ranges in AD data that has been collected. To ensure secure and privacy-preserving learning, we execute FDCNN-AS within a federated learning environment that concerns considerable laboratories and clinics. Within this setup, we operate the generic deep convolutional neural network. The experimental results indicate that FDCNN-AS performs optimally, reaching a remarkable 99% accuracy in detecting dementia Alzheimer&#39;s in the human brain.},
  archive      = {J_ISCI},
  author       = {Abdullah Lakhan and Mazin Abed Mohammed and Mohd Khanapi Abd Ghani and Karrar Hameed Abdulkareem and Haydar Abdulameer Marhoon and Jan Nedoma and Radek Martinek and Muhammet Deveci},
  doi          = {10.1016/j.ins.2024.120833},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120833},
  shortjournal = {Inf. Sci.},
  title        = {FDCNN-AS: Federated deep convolutional neural network alzheimer detection schemes for different age groups},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Discriminative embedded multi-view fuzzy c-means clustering
for feature-redundant and incomplete data. <em>ISCI</em>, <em>677</em>,
120830. (<a href="https://doi.org/10.1016/j.ins.2024.120830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering is a widely-used technique that seeks to categorize data obtained from various sources. As a representative method, multi-view fuzzy clustering has attracted growing attention. However, it becomes quite challenging when feature-redundant and incomplete data is presented. Despite the existing studies on dimension reduction and imputation methods, several issues remain unresolved. There is an excessive concern on the imputation, without considering that interpolation methods lead to accuracy degradation. Moreover, most of the methods usually process these two steps separately, resulting in inefficiency. To address these issues, we propose a discriminative embedded incomplete multi-view fuzzy c-means clustering method. We construct the indicator matrix to guide the learning of the common membership function, and design the projection matrix to construct embedding spaces. Subsequently, we develop an iterative optimization algorithm that solves the resultant problem. We demonstrate that the projection matrix can be achieved through the utilization of eigenvalue decomposition. Through extensive experimental studies on various benchmark datasets, the proposed method demonstrates the effectiveness and efficiency compared to the existing state-of-the-art clustering algorithms.},
  archive      = {J_ISCI},
  author       = {Yan Li and Xingchen Hu and Tuanfei Zhu and Jiyuan Liu and Xinwang Liu and Zhong Liu},
  doi          = {10.1016/j.ins.2024.120830},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120830},
  shortjournal = {Inf. Sci.},
  title        = {Discriminative embedded multi-view fuzzy C-means clustering for feature-redundant and incomplete data},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven fault detection for closed-loop t-s fuzzy
systems with unknown system dynamics and its application to
aero-engines. <em>ISCI</em>, <em>677</em>, 120829. (<a
href="https://doi.org/10.1016/j.ins.2024.120829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the fault detection problem of closed-loop Takagi-Sugeno (T-S) fuzzy systems with unknown system dynamics. However, the unknown dynamics make the model-based detection methods being infeasible. To tackle this problem, a detection scheme is designed directly by using input/state data, and disturbance attenuation as well as fault sensitivity performance are then introduced within data-driven framework such that a multiobjective optimization problem is formulated to compute the parameters of detector. Moreover, to remove the existing limitation that sensor faults must occur, corresponding design conditions of detector are developed by considering the characteristics of fault frequency. In particular, a linearization approach via searching the minimum singular value of unknown matrix is further developed to handle the nonconvex problem caused by introducing the fault sensitivity performance. Finally, an aero-engine system is used to show the effectiveness and advantages of the developed method.},
  archive      = {J_ISCI},
  author       = {Fu-Qiang Nian and Guang-Hong Yang},
  doi          = {10.1016/j.ins.2024.120829},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120829},
  shortjournal = {Inf. Sci.},
  title        = {Data-driven fault detection for closed-loop T-S fuzzy systems with unknown system dynamics and its application to aero-engines},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantized output-feedback control of piecewise-affine
systems with reachable regions of quantized measurements. <em>ISCI</em>,
<em>677</em>, 120828. (<a
href="https://doi.org/10.1016/j.ins.2024.120828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article explores the asymptotic stability and output-feedback control issues of discrete-time piecewise-affine (PWA) systems under multi-input–multi-output (MIMO) quantization. Our work features more general and practical than those previous works focusing on single-input–single-output quantization for output-feedback control of PWA systems. We choose a PWA output-feedback controller adapting to the located region of the quantized measurement. Since the measurement outputs generally contain partial state information, the determination of the located region of the quantized measurement depends on the region where the system state dwells. Thus, the controller can operate within a reduced number of regions compared to the PWA system. The leveraged Lyapunov function incorporates the region information for both the state and the quantized measurement, as well as the MIMO quantization uncertainties. We propose a method for determining the reachable regions of the quantized measurement, based on which we conduct the stability analysis and output-feedback controller implementation subsequently. In consequence, both the conservativeness and the computational burden can be alleviated compared with the previous results that incorporated all the operating regions for output-feedback controller design. Finally, our proposed control methodology is tested via a water-tank control problem to validate its competence and strengths.},
  archive      = {J_ISCI},
  author       = {Bo Cai and Zepeng Ning and Wenqiang Ji and Yanzheng Zhu and Minghao Han},
  doi          = {10.1016/j.ins.2024.120828},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120828},
  shortjournal = {Inf. Sci.},
  title        = {Quantized output-feedback control of piecewise-affine systems with reachable regions of quantized measurements},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective evolutionary search of variable-length
composite semantic perturbations. <em>ISCI</em>, <em>677</em>, 120827.
(<a href="https://doi.org/10.1016/j.ins.2024.120827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have proven to be vulnerable to adversarial attacks in the form of adding specific perturbations on images to make wrong outputs. Among that, semantic perturbations attract increasing attention due to their naturalness and physical realizability. However, existing works about semantic perturbations have two limitations. On the one hand, the type of devised semantic perturbations is single, which easily causes poor attack performance, especially on the corresponding defensed models. On the other hand, composite semantic perturbations (CSP) improve the attack performance by integrating multiple semantic perturbations but lacks the role of automatic optimization, such as the attack order, which also leads to relatively low generalizability. To address these problems, we propose a novel method called multi-objective evolutionary search of variable-length composite semantic perturbations (MES-VCSP). Specifically, we construct the mathematical model of variable-length CSP, which allows the same type of attacks to be performed multiple times, realizing a more efficient attack. Besides, we introduce the multi-objective evolutionary search consisting of NSGA-II and neighborhood search to find near-optimal variable-length attack sequences. Experimental results on multiple image classification datasets show that compared with CSP, MES-VCSP can obtain adversarial examples with a higher attack success rate, more naturalness, and less time cost.},
  archive      = {J_ISCI},
  author       = {Jialiang Sun and Wen Yao and Tingsong Jiang and Xiaoqian Chen},
  doi          = {10.1016/j.ins.2024.120827},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120827},
  shortjournal = {Inf. Sci.},
  title        = {Multi-objective evolutionary search of variable-length composite semantic perturbations},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A self-organization reconstruction method of ESN reservoir
structure based on reinforcement learning. <em>ISCI</em>, <em>677</em>,
120826. (<a href="https://doi.org/10.1016/j.ins.2024.120826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic reservoir of the randomly generated Echo State Network (ESN) contains numerous redundant neurons, resulting in collinearity in the high-dimensional state space matrix. This collinearity impacts the prediction performance of the network. In order to address this issue, this paper introduces a self-organizing ESN structure optimization model that is based on reinforcement learning, called SR-ESN. The SR-ESN model employs pruning methods to reconstruct the reservoir using contribution and decision mechanisms. To mitigate potential instability caused by high coupling among neurons in a single reservoir, the concept of ensemble learning is applied to create multiple initial reservoir pools, thereby enhancing screening diversity. Simultaneously, the model utilizes reinforcement learning&#39;s decision mechanism to identify effective neurons. Neurons with low contribution are pruned, while those with high contribution are retained for self-organizing reconstruction. This optimization of the network structure enhances its prediction performance. Based on both artificial and real datasets, the proposed SR-ESN model demonstrates superior prediction performance with minimal structural complexity compared to other prediction models.},
  archive      = {J_ISCI},
  author       = {Wei Guo and Huan Yao and YingQin Zhu and ZhaoZhao Zhang},
  doi          = {10.1016/j.ins.2024.120826},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120826},
  shortjournal = {Inf. Sci.},
  title        = {A self-organization reconstruction method of ESN reservoir structure based on reinforcement learning},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated learning via reweighting information bottleneck
with domain generalization. <em>ISCI</em>, <em>677</em>, 120825. (<a
href="https://doi.org/10.1016/j.ins.2024.120825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) plays an important role in collaborative distributed modeling. However, most studies cannot address poor generalization of out-of-distribution (OoD) data. Efforts have been exerted to address data heterogeneity among participants, but yielding limited success. Here, we propose an information bottleneck based FL method (FedIB), which aims to build a model with better OoD generalization. We extract the domain-invariance of different source domains to mitigate the domain heterogeneity under the cross-silo scenarios. Next, given the scale imbalance, we balance the representation importance of different domains with reweighting a better invariance across multiple domains. In addition, the convergence of FedIB is analyzed. As opposed to aligning distributions or eliminating redundancy by previous methods, FedIB achieves better domain generalization explicitly by eliminating the pseudo-invariant features. Finally, we conduct extensive experiments on various datasets revealing that FedIB has superior performances facing OoD and scale imbalance scenarios in distributed modeling.},
  archive      = {J_ISCI},
  author       = {Fangyu Li and Xuqiang Chen and Zhu Han and Yongping Du and Honggui Han},
  doi          = {10.1016/j.ins.2024.120825},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120825},
  shortjournal = {Inf. Sci.},
  title        = {Federated learning via reweighting information bottleneck with domain generalization},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A quasi-reflected and gaussian mutated arithmetic
optimisation algorithm for global optimisation. <em>ISCI</em>,
<em>677</em>, 120823. (<a
href="https://doi.org/10.1016/j.ins.2024.120823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arithmetic optimisation algorithms (AOAs) rely heavily on a structured framework that is inadequate for all the complexity levels; therefore, they cannot explore the full search space effectively. In this study, these shortcomings of AOAs were addressed by incorporating quasi-reflection-based learning and a Gaussian mutation strategy into the basic AOA. Gaussian mutation enhances the searchability of the basic AOA, whereas quasi-reflection-based learning enables the AOA to jump from the local optima to the global optimum in each iteration, and it is adaptively updated based on the knowledge gained from the offspring. The efficacy of the proposed method was tested using basic benchmark functions, CEC2018 test functions, and real-world applications. The effect of quasi-reflection-based learning on the AOA and the combined effect of quasi-reflection-based learning and Gaussian mutation on the AOA were investigated and compared with other cutting-edge optimisation algorithms. The results of the comparison revealed that the proposed optimisation algorithm outperformed the other algorithms.},
  archive      = {J_ISCI},
  author       = {Sumika Chauhan and Govind Vashishtha and Rajesh Kumar and Radoslaw Zimroz and Munish Kumar Gupta and Anil Kumar},
  doi          = {10.1016/j.ins.2024.120823},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120823},
  shortjournal = {Inf. Sci.},
  title        = {A quasi-reflected and gaussian mutated arithmetic optimisation algorithm for global optimisation},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spiking neural networks with consistent mapping relations
allow high-accuracy inference. <em>ISCI</em>, <em>677</em>, 120822. (<a
href="https://doi.org/10.1016/j.ins.2024.120822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spike-based neuromorphic hardware has demonstrated substantial potential in low energy consumption and efficient inference. However, the direct training of deep spiking neural networks is challenging, and conversion-based methods still require substantial time delay owing to unresolved conversion errors. We determine that the primary source of the conversion errors stems from the inconsistency between the mapping relationship of traditional activation functions and the input-output dynamics of spike neurons. To counter this, we introduce the Consistent ANN-SNN Conversion (CASC) framework. It includes the Consistent IF (CIF) neuron model, specifically contrived to minimize the influence of the stable point&#39;s upper bound, and the wake-sleep conversion (WSC) method, synergistically ensuring the uniformity of neuron behavior. This method theoretically achieves a loss-free conversion, markedly diminishing time delays and improving inference performance in extensive classification and object detection tasks. Our approach offers a viable pathway toward more efficient and effective neuromorphic systems.},
  archive      = {J_ISCI},
  author       = {Yang Li and Xiang He and Qingqun Kong and Yi Zeng},
  doi          = {10.1016/j.ins.2024.120822},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120822},
  shortjournal = {Inf. Sci.},
  title        = {Spiking neural networks with consistent mapping relations allow high-accuracy inference},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive PI event-triggered control for MIMO nonlinear
systems with input delay. <em>ISCI</em>, <em>677</em>, 120817. (<a
href="https://doi.org/10.1016/j.ins.2024.120817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An adaptive PI event-triggered control method for a class of multi-input and multi-output (MIMO) nonlinear systems with uncertain input delay is proposed. First, a new variable is designed to eliminate the impact of uncertain input delay based on the Pade approximation and Laplace transform. Then, a nonlinear controller with PI structure is developed, it has a linear structure and the ability to deal with uncertainties. Meanwhile, only one parameter is required to be updated online through RBFNN in the system. Moreover, an event-triggered control strategy is established to dynamically allocate the communication resources based on the PI nonlinear controller. With the proposed method, MIMO nonlinear systems are able to handle input delay of different duration dynamically and still maintain superior tracking performance. Finally, the effectiveness of the proposed method is demonstrated through two sets of simulation experiments.},
  archive      = {J_ISCI},
  author       = {Jianhui Wang and Yushen Wu and C.L.Philip Chen and Zhi Liu and Wenqiang Wu},
  doi          = {10.1016/j.ins.2024.120817},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120817},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive PI event-triggered control for MIMO nonlinear systems with input delay},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Complete inference via knowledge petri nets and resolution
rules. <em>ISCI</em>, <em>677</em>, 120816. (<a
href="https://doi.org/10.1016/j.ins.2024.120816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel inference approach is presented based on knowledge Petri nets and resolution rules. First, a knowledge base is modeled as a knowledge Petri net, where logical clauses are represented by monitor places, called semantic places. Second, a resolution pair is defined to identify a pair of semantic places, which, corresponding to two clauses that can be resolved, can be used to generate a new place in the knowledge Petri net. Such a new place represents an unknown clause implied by the knowledge base. Third, a method is proposed to decide whether a resolution inference is redundant based on the resolution pair. The size of a knowledge Petri net can be reduced, and the inference computation is saved in this way. Fourth, an inference algorithm is proposed employing the resolution pair and knowledge Petri net, proven to be sound and complete. Its computational complexity is polynomial with respect to the number of logical variables and clauses. In addition, another inference algorithm is developed for a given complete knowledge base and a set of newfound clauses. The algorithm is proven to be sound and complete, which offers significantly reduced computational complexity and specifically is linear concerning the number of new clauses. Finally, the wumpus world problem is taken as an example to illustrate and verify the proposed inference algorithms.},
  archive      = {J_ISCI},
  author       = {Kaicheng Tan and Jiliang Luo and Zepei Li and Jiazhong Zhou and Zhiwu Li},
  doi          = {10.1016/j.ins.2024.120816},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120816},
  shortjournal = {Inf. Sci.},
  title        = {Complete inference via knowledge petri nets and resolution rules},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive opinion evolution process with opinion dynamics for
large-scale group decision making: A novel approach based on overlapping
community detection in social networks. <em>ISCI</em>, <em>677</em>,
120809. (<a href="https://doi.org/10.1016/j.ins.2024.120809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of Web2.0 technologies and social media platforms has developed a new paradigm that allows many individuals to participate in decision-making processes within online social networks, leading to the rise of social network group decision making (SNGDM). Existing research in SNGDM primarily focus on small-scale DMs, which may not be suitable for large-scale SNGDM problems due to the high costs and time constraints of adjustments. Moreover, the non-overlapping community structure in social network encounter several limitations, further complicating the resolution of large-scale SNGDM problems. In this study, we propose an adaptive opinion evolution process with opinion dynamics for large-scale SNGDM. The proposed approach comprises four stages: classification of decision makers (DMs), determination of community weights, consensus reaching process, and alternative selection. A real-world application is utilized to demonstrate the effectiveness of the proposed method, and a comparison with existing related works highlights the advantages and innovation of the proposed model.},
  archive      = {J_ISCI},
  author       = {You Peng and Yuheng Wu},
  doi          = {10.1016/j.ins.2024.120809},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120809},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive opinion evolution process with opinion dynamics for large-scale group decision making: A novel approach based on overlapping community detection in social networks},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel distributed event/self-triggered sliding-mode control:
Application to practical fixed-time consensus of second-order
multi-agent systems. <em>ISCI</em>, <em>677</em>, 120808. (<a
href="https://doi.org/10.1016/j.ins.2024.120808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel terminal sliding-mode control (SMC) protocol to accomplish the practical fixed-time (PFXT) consensus of second-order multi-agent systems (MASs) through event-triggered scheme (ETS). The main challenge is the digitization of SMC which prevents the controlled system from reaching an ideal sliding phase and the singularity problem in terminal sliding-mode controllers. Firstly, a novel method of PFXT stability is proposed, which guarantees the non-singularity for the controller. Secondly, based on the proposed PFXT control method, a practical non-singular terminal SMC strategy is designed to accomplish the PFXT consensus of MASs through ETS. Besides, a strictly positive minimal triggering interval of each follower is given to exclude the Zeno phenomenon. Different with conventional terminal SMC, maintaining the sliding trajectory constrained on the sliding manifold is not a premise to guarantee the system stability. Then, to eliminate the requirement of continuous monitoring for ETS, the SMC strategy is generalized to the self-triggered approach. At last, a numerical example is presented to validate the developed methods.},
  archive      = {J_ISCI},
  author       = {Feida Song and Leimin Wang and Xiaofang Hu and Xiaofeng Zong and Shiping Wen},
  doi          = {10.1016/j.ins.2024.120808},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120808},
  shortjournal = {Inf. Sci.},
  title        = {Novel distributed event/self-triggered sliding-mode control: Application to practical fixed-time consensus of second-order multi-agent systems},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling brain information flow dynamics with
multidimensional fuzzy inference systems. <em>ISCI</em>, <em>677</em>,
120807. (<a href="https://doi.org/10.1016/j.ins.2024.120807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a pioneering approach to analyzing brain information flow dynamics through the development of a novel hybrid system. The key innovation of our system lies in the integration of n-cell fuzzy functions into a multidimensional fuzzy inference system (MFIS). Fuzzy n-cell numbers, representing a significant advancement in fuzzy mathematics, are central to our methodology, showcasing their capability to handle intricate uncertainties and imprecise data within multidimensional scenarios. Our proposed system aligns seamlessly with neuroscience principles, providing a robust framework to unravel the complexities of brain information flow dynamics. We leverage Transfer Entropy and Granger Causality measures for a quantitative assessment of influence strengths, enabling a systematic exploration of temporal information flow within the brain. Furthermore, the utilization of fuzzy n-cell numbers enhances the system&#39;s adaptability to the intricacies of neural processes. The outcomes of our study are presented through a series of visualizations, offering a comprehensive demonstration of the effectiveness and adaptability of the proposed hybrid system. This article aims to contribute to the understanding of brain dynamics by presenting a versatile and complex methodology that combines fuzzy mathematics, neuroscience principles, and advanced analytical techniques.},
  archive      = {J_ISCI},
  author       = {Ugur Kadak},
  doi          = {10.1016/j.ins.2024.120807},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120807},
  shortjournal = {Inf. Sci.},
  title        = {Modeling brain information flow dynamics with multidimensional fuzzy inference systems},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent medical diagnosis and treatment for diabetes
with deep convolutional fuzzy neural networks. <em>ISCI</em>,
<em>677</em>, 120802. (<a
href="https://doi.org/10.1016/j.ins.2024.120802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of smart healthcare has significantly heightened the importance of computer technologies in supporting medical diagnosis and treatment. Nevertheless, the challenges of mining latent knowledge within diagnostic data and explaining results to healthcare professionals have limited the application of many algorithms like neural network in clinical practice. To address these issues, our study introduces an Interpretable Predictor with Deep Convolutional Fuzzy Neural Network (IP-DCFNN). The proposed model is capable of assessing disease risks based on individual data and providing interpretable justifications aiding medical diagnosis and treatment decisions. By deconstructing the fuzzy inference process and incorporating convolutional neural network, our approach enhances the ability to discover underlying information while maintaining transparency and interpretability. Furthermore, we introduce a grid partition-based method for initializing the antecedent parameters and a hybrid approach that combines gradient descent with least squares estimation for training. Compared with Adaptive Neuro-Fuzzy Inference System (ANFIS) and Deep Neural Networks (DNN), Our model has an average improvement of 7.4% on prediction accuracy. More importantly, it can extract interpretable insights from membership functions, rule bases, and fuzzy contributions, offering valuable knowledge for medical research on type 2 diabetes, supporting intelligent diagnostic processes and providing personalized healthcare recommendations. The model can also be applied on the diagnosis and treatment of various other diseases.},
  archive      = {J_ISCI},
  author       = {Wenhui Zhou and Xiaomin Liu and Hongtao Bai and Lili He},
  doi          = {10.1016/j.ins.2024.120802},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120802},
  shortjournal = {Inf. Sci.},
  title        = {Intelligent medical diagnosis and treatment for diabetes with deep convolutional fuzzy neural networks},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A change severity degree-based dynamic multi-objective
optimization algorithm with adaptive response strategy. <em>ISCI</em>,
<em>677</em>, 120794. (<a
href="https://doi.org/10.1016/j.ins.2024.120794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world optimization problems are dynamic by nature, exhibiting temporal variations in objective functions, constraints, and parameters. These problems present significant challenges for algorithm convergence and diversity, as they require the ability to adapt appropriately to new environments. To address these challenges, a Dynamic Multi-objective Particle Swarm Optimization algorithm with an Adaptive Response Strategy (DMOPSO-ARS) is proposed in this paper. The DMOPSO-ARS possesses the capability to detect the degree of change and apply a suitable response strategy accordingly. Specifically, the change response strategy encompasses initialization-based prediction and elite-based learning methods, designed to speed up convergence speed and enhance algorithm diversity in the face of high/low severity environmental changes. To assess the effectiveness of the DMOPSO-ARS, we select the standard CEC 2018 benchmark, noisy test functions, and the recently released OL-DOP 2022 benchmark. Empirical studies indicate the robustness of the DMOPSO-ARS in tracking evolving solutions over time, showcasing its significant superiority compared to state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Najwa Kouka and Rahma Fourati and Raja Fdhila and Amir Hussain and Adel M. Alimi},
  doi          = {10.1016/j.ins.2024.120794},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120794},
  shortjournal = {Inf. Sci.},
  title        = {A change severity degree-based dynamic multi-objective optimization algorithm with adaptive response strategy},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cooperative control of multiple magnetically controlled soft
robots. <em>ISCI</em>, <em>677</em>, 120790. (<a
href="https://doi.org/10.1016/j.ins.2024.120790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple magnetically controlled soft robots are more efficient in terms of task execution. However, how to realize such multiple robots moving along the respective different paths is still a challenge since they are in one driving magnetic field. In order to deal with this problem, this paper proposes a cooperative control method by fusing their parallel cooperative motion (multiple robots moving simultaneously) and their independent cooperative motion (single robot moving). Yet, there are two strong couplings in the fusion of such two cooperative motions, which makes the control more difficult. Thus, an enumeration-based decoupling algorithm is developed for the first combined mode coupling, and the speed of each robot is planned for the second motion speed coupling. Then, a neural network-based controller is developed to achieve the respective speed control simultaneously of multiple robots, and the deviation limiting controller is constructed to compensate the deviation angle. Finally, through the actual experiments, it is verified that the proposed method realizes effectively the motion of two robots along different paths and the mean absolute error of speed is about 0.1091 mm/s and 0.2118 mm/s, while the mean absolute error of tracking is about 0.3369 mm and 0.4454 mm, respectively.},
  archive      = {J_ISCI},
  author       = {Pan Zhang and Wenjie Qing and Xuzhi Lai and Yawu Wang and Min Wu},
  doi          = {10.1016/j.ins.2024.120790},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120790},
  shortjournal = {Inf. Sci.},
  title        = {Cooperative control of multiple magnetically controlled soft robots},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid MADM method considering expert consensus for
emergency recovery plan selection: Dynamic grey relation analysis and
partial ordinal priority approach. <em>ISCI</em>, <em>677</em>, 120784.
(<a href="https://doi.org/10.1016/j.ins.2024.120784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency recovery plan selection (ERPS) is critical for managing post-disaster recovery and ensuring long-term societal stability. However, current multi-attribute decision-making (MADM) research on ERPS is limited and lacks consideration of Pareto-optimal solutions and expert consensus resulting from multi-stakeholder involvement. Therefore, this study proposes a hybrid Dynamic Grey Relation Analysis and Partial Ordinal Priority Approach (DGRA-POPA) model for ERPS. The proposed approach employs stable and easily accessible ranking data as inputs. DGRA is first utilized to extract consistency in attribute preferences among experts and serves as the basis for determining expert rankings. Considering expert consensus and information distribution, preference modification coefficients are derived and embedded into POPA. Through decision-weight optimization, partial-order cumulative transformation, and dominance structure generation, the weights for experts, attributes, and alternatives are determined along with a Hasse diagram. This diagram offers Pareto-optimal and suboptimal alternatives and alternative clustering information. The proposed approach is demonstrated using the ERPS after the Manchester Stadium attack. Sensitivity and comparative analyses with ten different MADM methods validate the effectiveness. Overall, the proposed approach enhances ERPS transparency, stability, and robustness by identifying Pareto-optimal alternatives while considering expert consensus and information distribution.},
  archive      = {J_ISCI},
  author       = {Renlong Wang},
  doi          = {10.1016/j.ins.2024.120784},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120784},
  shortjournal = {Inf. Sci.},
  title        = {A hybrid MADM method considering expert consensus for emergency recovery plan selection: Dynamic grey relation analysis and partial ordinal priority approach},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Geometric localized graph convolutional network for
multi-view semi-supervised classification. <em>ISCI</em>, <em>677</em>,
120769. (<a href="https://doi.org/10.1016/j.ins.2024.120769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning has received increasing attention in recent years due to its ability to leverage valuable patterns hidden in heterogeneous data sources. While existing studies have achieved encouraging results, especially those based on graph convolutional networks, they are still limited in their ability to fully exploit the connectivity relationships between samples and are susceptible to noise. To address the aforementioned limitations, we propose a framework called geometric localized graph convolutional network for multi-view semi-supervised classification. This framework utilizes a diffusion map to obtain the geometric structure of the feature space of multiple views and constructs a stable distance matrix that considers the local connectivity of nodes on the geometric structure. Additionally, we propose a truncated diffusion correlation function that maps the distance matrix of each view into correlations between samples to obtain a reliable sparse graph. To fuse the features, we use learnable weights to concatenate the coordinates of the geometric structure. Finally, we obtain a graph embedding of the fused feature and topology by using graph convolutional networks. Comprehensive experiments demonstrate the superiority of the proposed method over other state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Aiping Huang and Jielong Lu and Zhihao Wu and Zhaoliang Chen and Yuhong Chen and Shiping Wang and Hehong Zhang},
  doi          = {10.1016/j.ins.2024.120769},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120769},
  shortjournal = {Inf. Sci.},
  title        = {Geometric localized graph convolutional network for multi-view semi-supervised classification},
  volume       = {677},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assessing construction workforce diversity of skills and
education with the probabilistic linguistic fuzzy petri net.
<em>ISCI</em>, <em>676</em>, 120869. (<a
href="https://doi.org/10.1016/j.ins.2024.120869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workforce diversity has impacts on the performance and productivity of construction projects. While the attributes of workforce diversity have been researched, few existing studies evaluate the negative workforce diversity factors, particularly concerning the diversity of ‘skills and education’ in uncertain circumstances. In this study, the failure mode and effect analysis, with the independent relationship of RPN factors (I-FMEA), has been developed to assess the negative diversity factors of ‘skills and education’. In the I-FMEA model, the probability of occurrence ( P O PO ), the negative impact level ( N I NI ), and the degree of risk manageability ( M D MD ) are considered independent for analyzing ‘skills and education’. Secondly, the evaluation information is analyzed with probabilistic linguistic fuzzy Petri nets (PL-FPN). The reasoning rules of the PL-FPN are related to linguistic scales. Finally, a case study of negative diversity factors related to ‘skills and education’ is analyzed with PL-FPN in the I-FMEA model. The apparent advantages of the proposed analytical approach are validated through various comparative analyses, including methods involving reasoning rules, distance-based methods, and the traditional FMEA method.},
  archive      = {J_ISCI},
  author       = {Lina Wang and Daniel W.M. Chan and Zeshui Xu and Nehal Elshaboury},
  doi          = {10.1016/j.ins.2024.120869},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120869},
  shortjournal = {Inf. Sci.},
  title        = {Assessing construction workforce diversity of skills and education with the probabilistic linguistic fuzzy petri net},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy protection and utility trade-off for social graph
embedding. <em>ISCI</em>, <em>676</em>, 120866. (<a
href="https://doi.org/10.1016/j.ins.2024.120866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In graph embedding protection, deleting the embedding vector of a node does not completely disrupt its structural relationships. The embedding model must be retrained over the network without sensitive nodes, which incurs a waste of computation and offers no protection for ordinary users. Meanwhile, the edge perturbations do not guarantee good utility. This work proposed a new privacy protection and utility trade-off method without retraining. Firstly, since embedding distance reflects the closeness of nodes, we label and group user nodes into sensitive, near-sensitive, and ordinary regions to perform different strengths of privacy protection. The near-sensitive region can reduce the leaking risk of neighboring nodes connecting to sensitive nodes without sacrificing all of their utility. Secondly, we use mutual information to measure privacy and utility while adapting a single model-based mutual information neural estimator to vector pairs to reduce modeling and computational complexity. Thirdly, by keeping adding different noise to the divided regions and reestimating the mutual information between the original and noise-perturbed embeddings, our framework achieves a good trade-off between privacy and utility. Simulation results show that the proposed framework is superior to state-of-the-art baselines like LPPGE and DPNE.},
  archive      = {J_ISCI},
  author       = {Lin Cai and Jinchuan Tang and Shuping Dang and Gaojie Chen},
  doi          = {10.1016/j.ins.2024.120866},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120866},
  shortjournal = {Inf. Sci.},
  title        = {Privacy protection and utility trade-off for social graph embedding},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A YOLO-based deep learning model for real-time face mask
detection via drone surveillance in public spaces. <em>ISCI</em>,
<em>676</em>, 120865. (<a
href="https://doi.org/10.1016/j.ins.2024.120865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automating face mask detection in public areas is paramount to maintaining public health, especially in the context of the COVID-19 pandemic. Utilization of technologies such as deep learning and computer vision systems enables effective monitoring of mask compliance, thereby minimizing the risk of virus spread. Real-time detection helps in prompt intervention for and enforcement of the use of masks, thereby preventing potential outbreaks and ensuring compliance with public health guidelines. This method helps save human resources and makes the reinforcement of wearing masks in public areas consistent and objective. Automatic detection of face masks serves as a key tool for preventing the spread of contagious diseases, protecting public health, and creating a safer environment for every person. This study addresses the challenges of real-time face mask detection via drone surveillance in public spaces, with reference to three categories: wearing of mask, incorrect wearing of mask, and no mask. Addressing these challenges entails an efficient and robust object detection and recognition algorithm. This algorithm can deal with a crowd of multiple faces via a mobile camera carried by a mini drone, and performs real-time video processing. Accordingly, this study proposes a You Only Look Once (YOLO) based deep learning C-Mask model for real-time face mask detection and recognition via drone surveillance in public spaces. The C-Mask model aims to operate within a mini drone surveillance system and provide efficient and robust face mask detection. The C-Mask model performs preprocessing, feature extraction, feature generation, feature enhancement, feature selection, and multivariate classification tasks for each face mask detection cycle. The preprocessing task prepares the training and testing data in the form of images for further processing. The feature extraction task is performed using a Convolutional Neural Network (CNN). Moreover, Cross-Stage Partial (CSP) DarkNet53 is used to improve the feature extraction and to facilitate the model’s object detection ability. A data augmentation algorithm is used for feature generation to enhance the model’s training robustness. The feature enhancement task is performed by applying the Path Aggregation Network (PANet) and Spatial Pyramid Pooling Network (SPPNet) algorithms, which are deployed to enhance the extracted and generated features. The classification task is performed through multi-label classification, wherein each object in an image can belong to multiple classes simultaneously, and the network generates a grid of bounding boxes and corresponding confidence scores for each class. The YOLO-based C-Mask model testing is performed by experimenting with various face mask detection scenarios and with varying mask colors and types, to ensure the efficiency and robustness of the proposed model. The C-Mask model test results show that this model can correctly and effectively detect face masks in real-time video streams under various conditions with an overall accuracy of 92.20%, precision of 92.04, recall of 90.83%, and F1-score of 89.95%, for all the three classes. These high scores have been obtained despite mini drone mobility and camera orientation adjustment substantially affecting face mask detection performance.},
  archive      = {J_ISCI},
  author       = {Salama A. Mostafa and Sharran Ravi and Dilovan Asaad Zebari and Nechirvan Asaad Zebari and Mazin Abed Mohammed and Jan Nedoma and Radek Martinek and Muhammet Deveci and Weiping Ding},
  doi          = {10.1016/j.ins.2024.120865},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120865},
  shortjournal = {Inf. Sci.},
  title        = {A YOLO-based deep learning model for real-time face mask detection via drone surveillance in public spaces},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MCNet: Multivariate long-term time series forecasting with
local and global context modeling. <em>ISCI</em>, <em>676</em>, 120864.
(<a href="https://doi.org/10.1016/j.ins.2024.120864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data typically exhibit various intra-sequence and inter-sequence correlations, resulting in intricate, intertwined dependencies, which pose challenges for accurately predicting future long-term trends. Previous studies have not fully considered the two correlations, and they also still face challenges of excessive time and memory complexity when dealing with long-term predictions. To address these challenges and establish high-precision prediction models, we propose MCNet that consists of a local branch and a global branch. The local branch aims at capturing short-term variations of intra-sequences, as well as capturing inter-sequence correlations. The global branch models long-term dependencies within sequences. Specifically, the local branch consists only of MLP module, which effectively captures short-term variations of intra-sequences by independently modeling the temporal information within and between patches of the most recent time series. Subsequently, inter-sequence dependencies are captured through the channel interaction module, which further explores more key information to improve the performance of MCNet. Meanwhile, global branch models long-term dependencies within the time series through structured global convolution. Experimental results on multiple popular long-term time series forecasting benchmarks demonstrate that MCNet outperforms state-of-the-art methods, yielding a relative improvement of 12% for multivariate time series while also being more efficient.},
  archive      = {J_ISCI},
  author       = {Jiaqi Sun and Junhai Zhai},
  doi          = {10.1016/j.ins.2024.120864},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120864},
  shortjournal = {Inf. Sci.},
  title        = {MCNet: Multivariate long-term time series forecasting with local and global context modeling},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal design and allocation of stealthy attacks against
remote state estimation for cyber-physical systems. <em>ISCI</em>,
<em>676</em>, 120859. (<a
href="https://doi.org/10.1016/j.ins.2024.120859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the design and allocation problem for stealthy attacks against remote state estimation for cyber-physical systems, where the data are transmitted through multiple wireless communication channels. With limited budget for the available energy at each step and total energy over the finite-time horizon, the aim of the stealthy attacker is to maximize the estimation error based on the collaboration between the attack matrices and schedule, which is formulated as the optimization problem with multi-variable coupling. Under the presented framework of stepwise optimization, the optimization problem is separated into two subproblems with the guarantee of optimality. First, for the optimal design of attack matrices, the analytical expression is derived by employing the proposed data isolation technique instead of the assumption utilized in the existing results that the output matrix is of full row rank. And then, for the optimal allocation of energy constrained attacks, the scheduling sequence is obtained by solving the transformed linear 0-1 programming. Finally, simulation results sustain the performance of the presented attack strategy.},
  archive      = {J_ISCI},
  author       = {Xuan Liu and Guang-Hong Yang},
  doi          = {10.1016/j.ins.2024.120859},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120859},
  shortjournal = {Inf. Sci.},
  title        = {Optimal design and allocation of stealthy attacks against remote state estimation for cyber-physical systems},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stabilization analysis for nonlinear interconnected system
with memory based coupled sampled data control via quantum-inspired
genetic algorithm. <em>ISCI</em>, <em>676</em>, 120857. (<a
href="https://doi.org/10.1016/j.ins.2024.120857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of modern interconnected systems, achieving stability represents a pivotal challenge due to the complex dynamics among various components. This paper presents a new approach to stability analysis, leveraging linear matrix inequalities and Lyapunov-Krasovskii functionals. The framework of memory-based coupling sampled data control is enhanced by a quantum genetic algorithm. By incorporating linear matrix inequality approach, this study establishes a robust mathematical foundation for characterizing stability conditions and synthesizing control gains. This innovative integration provides a powerful toolset to optimize control parameters while mitigating the impact of disturbances. The simulation findings are explicitly based on experimental values of two-area interconnected power systems with doubly fed induction generator based wind farm, which guarantees the asymptotic stability of the proposed controller.},
  archive      = {J_ISCI},
  author       = {K. Sanjay and R. Vijay Aravind and P. Balasubramaniam},
  doi          = {10.1016/j.ins.2024.120857},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120857},
  shortjournal = {Inf. Sci.},
  title        = {Stabilization analysis for nonlinear interconnected system with memory based coupled sampled data control via quantum-inspired genetic algorithm},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive evolutionary search-based method for efficiently
tackling the set-union knapsack problem. <em>ISCI</em>, <em>676</em>,
120855. (<a href="https://doi.org/10.1016/j.ins.2024.120855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper tackles the NP-hard set-union knapsack problem using a novel adaptive evolutionary algorithm. Such a problem has applications in database query optimization, network design, and project portfolio management. The method starts by creating an archive set with elite and diversified solutions, employing a customized procedure based on item scores and Hamming max-min distance for diversity. Various operators are added to enhance solution quality in the elite set and refine the search process. To counteract premature convergence, combination and subset reference update methods are used. The fusion strategy serves as an exploration mechanism, generating new solutions and preventing premature convergence. Finally, the effectiveness and performance of the proposed method is evaluated on a set of benchmark instances taken from existing literature and by conducting a thorough statistical analysis of all achieved results. All obtained results are systematically compared against those achieved by state-of-the-art methods, indicating a substantial improvement of 50% for the large-sized instances, outperforming those published in the literature.},
  archive      = {J_ISCI},
  author       = {Juntao Zhao and Mhand Hifi},
  doi          = {10.1016/j.ins.2024.120855},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120855},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive evolutionary search-based method for efficiently tackling the set-union knapsack problem},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On multiplicative generators of the unified form of
0-overlap and 1-grouping functions. <em>ISCI</em>, <em>676</em>, 120853.
(<a href="https://doi.org/10.1016/j.ins.2024.120853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Qiao introduced a unified form for 0-overlap and 1-grouping functions, called Θ − Ξ Θ−Ξ functions. With more relaxed boundary conditions, Θ − Ξ Θ−Ξ functions can be served as a generalization of overlap and grouping functions. As a result, the flexibility and generality of Θ − Ξ Θ−Ξ functions allow for a wider range of applications, with a potential for application that exceeds that of overlap and grouping functions. This paper focuses on the study of the multiplicative generator pairs (MGPs) of Θ − Ξ Θ−Ξ functions. Firstly, we propose two concepts of an MGP for a Θ − Ξ Θ−Ξ function, which are based on the correlation between the value of boundary elements ℓ and ℘, specifically, ℓ ℘ ℓ&amp;gt;℘ . And then, for each of the two cases in turn, we provide the conditions for deriving a Θ − Ξ Θ−Ξ function from the MGP and determine its block structures. Moreover, we discuss such multiplicatively generated Θ − Ξ Θ−Ξ functions with neutral elements and examine the actions of ( ℓ , ℘ ) (ℓ,℘) -pseudo-automorphisms on them. Finally, we establish two equivalent relationships between MGPs of Θ − Ξ Θ−Ξ functions with ℓ ℘ ℓ&amp;gt;℘ .},
  archive      = {J_ISCI},
  author       = {Meng Cao and Junsheng Qiao},
  doi          = {10.1016/j.ins.2024.120853},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120853},
  shortjournal = {Inf. Sci.},
  title        = {On multiplicative generators of the unified form of 0-overlap and 1-grouping functions},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VAEAT: Variational AutoeEncoder with adversarial training
for multivariate time series anomaly detection. <em>ISCI</em>,
<em>676</em>, 120852. (<a
href="https://doi.org/10.1016/j.ins.2024.120852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High labor costs and the requirement for significant domain expertise often result in a lack of anomaly labels in most time series. Consequently, employing unsupervised methods becomes critical for practical industrial applications. However, prevailing reconstruction-based anomaly detection algorithms encounter challenges in capturing intricate underlying correlations and temporal dependencies in time series. This study introduces an unsupervised anomaly detection model called Variational AutoeEncoder with Adversarial Training for Multivariate Time Series Anomaly Detection (VAEAT). Its fundamental concept involves adopting a two-phase training strategy to improve anomaly detection precision through adversarial reconstruction of raw data. In the first phase, the model reconstructs raw data to extract its basic features by training two enhanced variational autoencoders (VAEs) that incorporate both the long short-term memory (LSTM) network and the attention mechanism in their common encoder. In the second phase, the model refines reconstructed data to optimize the reconstruction quality. In this manner, this two-phase VAE model effectively captures intricate underlying correlation and temporal dependencies. A large number of experiments are conducted to evaluate the performance on five publicly available datasets, and experimental results illustrate that VAEAT exhibits robust performance and effective anomaly detection capabilities. The source code of the proposed VAEAT can be available at https://github.com/Du-Team/VAEAT .},
  archive      = {J_ISCI},
  author       = {Sheng He and Mingjing Du and Xiang Jiang and Wenbin Zhang and Congyu Wang},
  doi          = {10.1016/j.ins.2024.120852},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120852},
  shortjournal = {Inf. Sci.},
  title        = {VAEAT: Variational AutoeEncoder with adversarial training for multivariate time series anomaly detection},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attribute reduction based on intuitionistic fuzzy dominance
mutual information in intuitionistic fuzzy information systems.
<em>ISCI</em>, <em>676</em>, 120851. (<a
href="https://doi.org/10.1016/j.ins.2024.120851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy information system (IFIS) is an extension of fuzzy information system that can represent more uncertain information and more accurately describe the essence of fuzziness. Attribute reduction is an important problem in processing and analyzing IFISs. The article tries to propose an attribute reduction method in view of intuitionistic fuzzy dominance mutual information in IFISs, whose information values are intuitionistic fuzzy numbers. First, an intuitionistic fuzzy dominance relation is established in IFISs according to intuitionistic fuzzy dominance degrees, and the intuitionistic fuzzy information structure generated by the intuitionistic fuzzy dominance relation is constructed. Then, the intuitionistic fuzzy dominance entropy and its variations are researched, and some of their properties are discussed. Subsequently, an attribute reduction method and its algorithm based on intuitionistic fuzzy dominance mutual information are given. Furthermore, numerical studies and statistical tests are presented to evaluate the performance of the proposed method. Theoretical research and experiments show that the raised attribute reduction method is applicable to IFISs.},
  archive      = {J_ISCI},
  author       = {Xiaofeng Liu and Hong Mo and Jianhua Dai},
  doi          = {10.1016/j.ins.2024.120851},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120851},
  shortjournal = {Inf. Sci.},
  title        = {Attribute reduction based on intuitionistic fuzzy dominance mutual information in intuitionistic fuzzy information systems},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Functional analysis on hypergraphs: Density and zeta
functions – applications to molecular graphs and image analysis.
<em>ISCI</em>, <em>676</em>, 120850. (<a
href="https://doi.org/10.1016/j.ins.2024.120850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces new descriptors and invariants for hypergraphs. We develop a new type of Zeta functions and density functions, that are proved to have useful invariance and monotony properties. Links with hypergraph entropies are established as well. New matrices linked with hypergraphs are also proposed, from which a new type of Laplacian associated with hypergraphs is derived. Two applications are then suggested, molecular graphs in chemistry and image analysis, where the proposed functions and invariants are useful characterizations.},
  archive      = {J_ISCI},
  author       = {Isabelle Bloch and Alain Bretto},
  doi          = {10.1016/j.ins.2024.120850},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120850},
  shortjournal = {Inf. Sci.},
  title        = {Functional analysis on hypergraphs: Density and zeta functions – applications to molecular graphs and image analysis},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LSTEG: An evolutionary game model leveraging deep
reinforcement learning for privacy behavior analysis on social networks.
<em>ISCI</em>, <em>676</em>, 120842. (<a
href="https://doi.org/10.1016/j.ins.2024.120842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the investment of third-party companies, various accurate recommendation services have emerged on social network platforms, making convenience and privacy concerns coexist for users. Platforms, users, and third-party companies have conflicts of interest around privacy issues, and privacy protection is not the only goal for them. For the analysis of multi-party behaviors related to privacy, a long short-term evolutionary game model (LSTEG) is proposed, where the long-term and short-term evolutionary processes describe the dynamics between three parties and between users, respectively. Their dynamic evolutionary processes are described by mean dynamic equations and all possible stationary-state conditions are analyzed theoretically. Deep reinforcement learning is adopted to solve these evolutionary stationary states and to reveal the rules of interdependence between long-term evolution and short-term evolution. Experiments conducted on real-world datasets show that this work can help platforms, users, and third-party companies to get a better sense of what is occurring in dynamic network environments.},
  archive      = {J_ISCI},
  author       = {Yu Wu and Li Pan},
  doi          = {10.1016/j.ins.2024.120842},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120842},
  shortjournal = {Inf. Sci.},
  title        = {LSTEG: An evolutionary game model leveraging deep reinforcement learning for privacy behavior analysis on social networks},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). CTITF: A tensor factorization model with constrained
bidirectional user trust and implicit feedback for context-aware
recommender systems. <em>ISCI</em>, <em>676</em>, 120838. (<a
href="https://doi.org/10.1016/j.ins.2024.120838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems offer an efficient solution to the problem of information overload, which is exacerbated by the rapid expansion of data. Context-aware recommender systems (CARS) have become prominent, incorporating contextual information to provide more desirable recommendations. While the dimension of contextual information rises, the complexity of algorithms increases as well, highlighting the data sparsity problem. In this paper, we propose CTITF, a novel tensor factorization model that incorporates constrained user bidirectional trust and implicit feedback. First, CTITF distinguishes the roles of trust networks in terms of the directionality of trust relationships: the trustor and the trustee. CTITF then constructs trust influences and biases for both roles to linearly represent user preferences. Furthermore, CTITF improves the rating prediction function and recommendation objective function based on CP factorization. Finally, CTITF filters out trust relationships where users do not have the same history items. It also uses contextual information to limit the amount of implicit feedback, addressing the issue of high time complexity. Experiments on two real-world datasets illustrate that the proposed model outperforms previous TF-based models and social recommender systems in terms of rating prediction accuracy. In addition, the CTITF model reduces the training time by 50.28% compared to the trustTF model, which also uses trust.},
  archive      = {J_ISCI},
  author       = {Hao Li and Jianjian Chen and Jianli Zhao and Lutong Yao and Rumeng Zhang and Lu Yang and Xiaoping Lu},
  doi          = {10.1016/j.ins.2024.120838},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120838},
  shortjournal = {Inf. Sci.},
  title        = {CTITF: A tensor factorization model with constrained bidirectional user trust and implicit feedback for context-aware recommender systems},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CPS-3WS: A critical pattern supported three-way sampling
method for classifying class-overlapped imbalanced data. <em>ISCI</em>,
<em>676</em>, 120835. (<a
href="https://doi.org/10.1016/j.ins.2024.120835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class-imbalance problem widely exists in real applications ranging from medial diagnosis to economic fraud detection, etc. As one of the mainstream techniques in dealing with imbalanced data, SMOTE (Synthetic Minority Over-sampling TEchnique) and its extensions mainly rebalance the datasets via generation of observations in specific regions with various adapted strategies. Many of them do not consider the cost of role assignment of samples, and the intractable data complexity (overlap, small disjuncts, etc.) poses additional challenges to them. This paper proposes a critical pattern supported three-way sampling method (CPS-3WS) for classifying class-overlapped imbalanced data, introducing the philosophy of thinking in threes to effective classification in imbalanced learning. Specifically, CPS-3WS uses a three-way sample partition strategy with the Bayes posterior probability by dividing majority and minority classes into three disjoint subsets: risky, critical and safe patterns. CPS-3WS conducts a three-way hybrid sampling through (i) evaluating the risky majority pattern to be eliminated and (ii) selecting critical minority pattern to synthesize new samples under local information constraint. Extensive experiments on 42 UCI benchmark datasets demonstrate the superiority of the proposed CPS-3WS compared with 11 data-level methods. The source code of CPS-3WS is available at https://github.com/ytyancp/CPS-3WS .},
  archive      = {J_ISCI},
  author       = {Yuanting Yan and Zhong Zheng and Yiwen Zhang and Yanping Zhang and Yiyu Yao},
  doi          = {10.1016/j.ins.2024.120835},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120835},
  shortjournal = {Inf. Sci.},
  title        = {CPS-3WS: A critical pattern supported three-way sampling method for classifying class-overlapped imbalanced data},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling item exposure and user satisfaction for debiased
recommendation with causal inference. <em>ISCI</em>, <em>676</em>,
120834. (<a href="https://doi.org/10.1016/j.ins.2024.120834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems (RSs) aim to provide suggestions for items that are most pertinent to a particular user. Typically, RSs are trained and evaluated directly on the observed items, raising concerns about exposure bias - many missing items are false negatives, which were not consumed due to lack of exposure rather than lack of affinity. In addition, user satisfaction is often ignored in previous RSs, where consumer behaviors may be influenced by advertisement or promotion instead of actual user interests. In this paper, we propose a novel model-agnostic causal inference method for debiased recommendation, which models item E xposure and user S atisfaction simultaneously with C ausal I nference (ESCI). Specifically, we formulate a causal graph to describe the recommendation process, where the ranking score is influenced by item exposure, user satisfaction, and user-item matching. We investigate the change in the ranking score when item exposure is discarded. In addition, we propose an adversarial training strategy to improve the generalization and robustness of recommender systems. During testing, we perform causal inference to remove the effect of item exposure. The comprehensive experimental study on four benchmark datasets demonstrates that the proposed ESCI enhances recommendation performance for users with non-high interaction frequencies, thereby outperforming state-of-the-art baselines.},
  archive      = {J_ISCI},
  author       = {Jie Liao and Min Yang and Wei Zhou and Hongyu Zhang and Junhao Wen},
  doi          = {10.1016/j.ins.2024.120834},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120834},
  shortjournal = {Inf. Sci.},
  title        = {Modeling item exposure and user satisfaction for debiased recommendation with causal inference},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel multimodal multi-objective differential evolution
algorithm based on nearest neighbor-repulsion strategy. <em>ISCI</em>,
<em>676</em>, 120832. (<a
href="https://doi.org/10.1016/j.ins.2024.120832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multi-objective optimization problem (MMOP) is a variant of the multi-objective problem (MOP), which has multiple optimal Pareto sets (PSs) mapping to the same or similar Pareto front (PF) from the decision space to the objective space. As algorithms must obtain multiple Pareto Sets, addressing MMOPs presents greater challenges for algorithms. To address the issue, the paper proposes a novel multimodal multi-objective differential evolution algorithm named MMODE_SDNR. Firstly, the algorithm sorts the population using the fast non-dominated sorting method and the Shortest Distance (SD) values. SD represents the shortest Euclidean distance between an individual and its nearest neighboring individual, calculated jointly in the decision space and the objective space. Secondly, a definition of the similarity between an individual and its neighbors in both spaces is provided, based on which a novel environmental selection strategy for the algorithm, called the nearest Neighbor-Repulsion (nNR) is devised. The strategy removes the individuals that have similarity with one another to maximize the retention of different individuals. Moreover, it keeps the diversity of PSs in the decision space and retains more solutions that exhibit a similar or same PF in the objective space. Finally, the proposed MMODE_SDNR has undergone several tests on the benchmark functions from CEC 2019 and CEC 2020 to assess its performance. The experimental results indicate that MMODE_SDNR excels in three metrics, outperforming other several state-of-the-art MMO algorithms. Its strong convergence and focus on decision space quality ensure competitiveness.},
  archive      = {J_ISCI},
  author       = {Yingjuan Jia and Liangdong Qu and Xiaoqin Li},
  doi          = {10.1016/j.ins.2024.120832},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120832},
  shortjournal = {Inf. Sci.},
  title        = {A novel multimodal multi-objective differential evolution algorithm based on nearest neighbor-repulsion strategy},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing graph convolutional networks with progressive
granular ball sampling fusion: A novel approach to efficient and
accurate GCN training. <em>ISCI</em>, <em>676</em>, 120831. (<a
href="https://doi.org/10.1016/j.ins.2024.120831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional network (GCN) has gained considerable attention and has been widely utilized in graph data analytics. However, training large GCNs presents considerable challenges owing to the inherent complexity of graph-structured data. Previous training algorithms frequently struggle with slow convergence speed caused by full-batch gradient descent on entire graphs and reduced model performance due to inappropriate node sampling methods. To address these issues, we propose a novel framework called Progressive Granular Ball Sampling Fusion (PGBSF). PGBSF leverages granular ball sampling to partition the original graph into a collection of subgraphs, thereby enhancing both training efficiency and detail capture. Then, it applies a progressive approach accompanied by a parameter-sharing strategy for incremental GCN model training, which results in robust performance and rapid convergence speed. This simple yet effective strategy considerably enhances classification accuracy and memory efficiency. The experiment results show that our proposed architecture consistently outperforms other baseline models in terms of accuracy across almost all datasets with different label rates. In addition, PGBSF improves GCN performance significantly on large and complex datasets. Moreover, GCN+PGBSF reduces time complexity by training on subgraphs and achieves the fastest convergence speed among all models, with a relatively small variance in loss during training.},
  archive      = {J_ISCI},
  author       = {Hui Cong and Qiguo Sun and Xibei Yang and Keyu Liu and Yuhua Qian},
  doi          = {10.1016/j.ins.2024.120831},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120831},
  shortjournal = {Inf. Sci.},
  title        = {Enhancing graph convolutional networks with progressive granular ball sampling fusion: A novel approach to efficient and accurate GCN training},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incomplete data evidential classification with inconsistent
distribution. <em>ISCI</em>, <em>676</em>, 120824. (<a
href="https://doi.org/10.1016/j.ins.2024.120824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification analysis of incomplete data is an important and challenging topic in machine learning. Many approaches have been devised to cope with incomplete data. They usually consider that the training and test sets are independent and identically distributed, but the distribution of training and test sets may be inconsistent caused by missing values in applications. In this paper, we propose a novel evidential classification approach to address such a problem based on the Dempster-Shafer theory. First, attributes with missing values are combined with other high correlation attributes to generate different subsets, and they are imputed by K nearest neighbors (KNNs) in subsets. Basic classifiers trained by edited subsets are employed to classify the test sample. Second, the mixed discounting factor composed of the importance and reliability factors is designed to calibrate classification results of the test sample. The importance is evaluated by the difference of distribution between training and test subsets, and the reliability is quantified by minimizing the deviation between classification results of training samples and the truth. Different classification results are combined with mixed discounting factors by the Dempster-Shafer (DS) fusion rule thereby making the final decision. We conduct extensive experiments with several real incomplete data, and the results show that the proposed approach yields more promising and stable performance with respect to other typical approaches.},
  archive      = {J_ISCI},
  author       = {Hongpeng Tian and Xiaole Wang and Yongguang Tan},
  doi          = {10.1016/j.ins.2024.120824},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120824},
  shortjournal = {Inf. Sci.},
  title        = {Incomplete data evidential classification with inconsistent distribution},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Asynchronous h∞ consensus control for singular markov jump
multi-agent systems under a sample-data-based distributed dynamic
event-triggered scheme. <em>ISCI</em>, <em>676</em>, 120820. (<a
href="https://doi.org/10.1016/j.ins.2024.120820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel approach leveraging a sample-data-based, distributed, dynamic event-triggered framework to develop an H ∞ H∞ asynchronous consensus controller tailored for singular Markov jump multi-agent systems (MJMASs). This approach primarily focuses on mitigating the communication load inherent in singular multi-agent systems. We employ a hidden Markov model (HMM) to adeptly manage the mode synchronization discrepancies between the controller and the system. We establish the stochastic admissibility with H ∞ H∞ consensus performance of the singular consensus error system by deriving linear matrix inequalities (LMIs). Furthermore, we introduce a co-design methodology for optimizing controller gains, which simultaneously addresses the requirements of H ∞ H∞ consensus and the dynamic event-triggered framework. The effectiveness of our proposed method are demonstrated through three numerical examples, each employing a different triggering mechanism.},
  archive      = {J_ISCI},
  author       = {Haotian Wang and Fei Chen and Yanqian Wang and Shao Shao},
  doi          = {10.1016/j.ins.2024.120820},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120820},
  shortjournal = {Inf. Sci.},
  title        = {Asynchronous h∞ consensus control for singular markov jump multi-agent systems under a sample-data-based distributed dynamic event-triggered scheme},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assessment of environment-conscious propulsion technologies
for road freight distribution based on t-spherical fuzzy schweizer-sklar
power operators. <em>ISCI</em>, <em>676</em>, 120819. (<a
href="https://doi.org/10.1016/j.ins.2024.120819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the viability of environmentally conscious propulsion technologies for road freight distribution, specifically using T-spherical fuzzy information. With the increasing need for sustainable transportation, the study investigates the potential of various propulsion technologies, including electric, hybrid, solar, and diesel vehicles, and evaluates their environmental impact in terms of emissions reduction and energy efficiency. The T-spherical fuzzy information is utilized to analyze and compare the performance of these technologies in different scenarios. In this paper, we proposed hybrid aggregation operators (AOs) namely T-spherical fuzzy Schweizer-Sklar power AOs for the aggregation of T-spherical fuzzy information. Moreover, the T-spherical fuzzy aggregation method provides a comprehensive and effective tool for evaluating the viability of different propulsion technologies. This article exhibits some characteristics of the proposed AOs. Using suggested AOs with numerous evaluations by decision-makers and partial weight information under T-spherical fuzzy information, a method for multi-criteria decision-making is constructed. The results show that the adoption of environmentally conscious propulsion technologies can significantly reduce carbon emissions and improve energy efficiency in road freight distribution. In addition, the research includes a sensitivity analysis and a comparison between the proposed strategy and current methods.},
  archive      = {J_ISCI},
  author       = {Hafiz Muhammad Athar Farid and Muhammad Riaz and Rukhsana Kausar and Vladimir Simic},
  doi          = {10.1016/j.ins.2024.120819},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120819},
  shortjournal = {Inf. Sci.},
  title        = {Assessment of environment-conscious propulsion technologies for road freight distribution based on T-spherical fuzzy schweizer-sklar power operators},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable feature selection and ensemble classification
via feature polarity. <em>ISCI</em>, <em>676</em>, 120818. (<a
href="https://doi.org/10.1016/j.ins.2024.120818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection aims to choose the most relevant features from the dataset that can enhance the performance and efficiency of machine learning models. Although feature selection has been studied for many years, most existing methods focus on accuracy and efficiency while neglecting the interpretability of selected features. Therefore, inspired by the “Yin-Yang” philosophy, we introduce the concept of feature polarity for the first time and divide the features into positive and negative features. For example, by analyzing a patient&#39;s symptoms (features), we can obtain two sets of features to explain whether the patient has the flu. Positive features help us determine if the patient has the flu, while negative features can help us rule out the possibility of the flu. We introduce the PN (Positive and Negative) coefficient to measure the polarity of candidate features and develop a novel and explainable feature selection method based on feature polarity. Furthermore, we propose an ensemble classification framework that leverages both positive and negative features for each class to improve classification performance. Extensive experiments demonstrate the effectiveness of the PN coefficient compared to other information measurements. Moreover, our proposed classification framework performs excellently compared to some state-of-the-art feature selection methods.},
  archive      = {J_ISCI},
  author       = {Peng Zhou and Ji Liang and Yuanting Yan and Shu Zhao and Xindong Wu},
  doi          = {10.1016/j.ins.2024.120818},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120818},
  shortjournal = {Inf. Sci.},
  title        = {Explainable feature selection and ensemble classification via feature polarity},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cooperative performance assessment for multiagent systems
based on the belief rule base with continuous inputs. <em>ISCI</em>,
<em>676</em>, 120815. (<a
href="https://doi.org/10.1016/j.ins.2024.120815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By dint of the advantage of deeply integrating empirical knowledge and monitoring data, the belief rule base (BRB) is widely used to assess the performance of complex systems, including multiagent systems. However, the existing paradigms for designing the inputs of BRB systems necessitate sampling discretization when faced with continuous signal inputs, which poses the risk of information loss and reduces the effectiveness of performance assessment. As such, the BRB with continuous inputs (BRB-CI) is constructed based on the continuous wavelet transform, a typical joint time-frequency analysis technique, enabling BRB systems to handle continuous signal inputs directly. The stability of the BRB-CI is proven through output error analysis. A new structure optimization strategy aimed at simplifying the BRB-CI by removing redundant belief rules is developed. Moreover, a new parameter optimization approach based on the improved gray wolf optimizer with interpretability reinforcement is devised, contributing to the interdisciplinary research on BRB systems and metaheuristic algorithms. Several experiments are conducted, demonstrating the novelty, superiority, and engineering practicability of the proposal.},
  archive      = {J_ISCI},
  author       = {Haoran Zhang and Ruohan Yang and Wei He and Zhichao Feng},
  doi          = {10.1016/j.ins.2024.120815},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120815},
  shortjournal = {Inf. Sci.},
  title        = {Cooperative performance assessment for multiagent systems based on the belief rule base with continuous inputs},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design, performance analysis and applications of pneumatic
bellows actuator for building block soft robots. <em>ISCI</em>,
<em>676</em>, 120814. (<a
href="https://doi.org/10.1016/j.ins.2024.120814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, there are some new challenges for pneumatic soft robots brought by complex application environments and variable task objectives. To address these challenges, inspired by the building blocks, we develop a novel pneumatic soft actuator named pneumatic bellows actuator (PBA) that can generate bidirectional deformation, and propose a building block design concept for the soft robots based on the developed PBA. The PBA consists of three parts: a soft rubber layer (SRL), a fiber-reinforced layer (FRL) and some rigid joints. We design the SRL as a bellows-like shape so the PBA can generate bidirectional deformation, and weave an FRL as the coating of the SRL to prevent the significant radial expansion of the SRL that may affect the application of the PBA. The rigid joints include sealing glands and connectors. The sealing glands are used to seal the SRL, while the connectors having interfaces on their five surfaces are used to connect the PBAs through the customized plugs corresponding to these interfaces. Moreover, the experimental results indicate that the PBA can generate large deformation and driving force, while it has the advantages of good repeatability and approximate rate-independent under low frequency. Based on the building block design concept for the soft robots, we construct three PBA-based soft robots: a soft crawling robot, a soft gripper, and a soft manipulator, to demonstrate that we can easily use the PBAs to construct various soft robots.},
  archive      = {J_ISCI},
  author       = {Huai Xiao and Qingxin Meng and Xuzhi Lai and Yawu Wang and Jinhua She and Edwardo F. Fukushima and Min Wu},
  doi          = {10.1016/j.ins.2024.120814},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120814},
  shortjournal = {Inf. Sci.},
  title        = {Design, performance analysis and applications of pneumatic bellows actuator for building block soft robots},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-domain continual learning via CLAMP. <em>ISCI</em>,
<em>676</em>, 120813. (<a
href="https://doi.org/10.1016/j.ins.2024.120813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks, celebrated for their human-like cognitive learning abilities, often encounter the well-known catastrophic forgetting (CF) problem, where the neural networks lose the proficiency in previously acquired knowledge. Despite numerous efforts to mitigate CF, it remains the significant challenge particularly in complex changing environments. This challenge is even more pronounced in cross-domain adaptation following the continual learning (CL) setting, which is a more challenging and realistic scenario that is under-explored. To this end, this article proposes a cross-domain CL approach making possible to deploy a single model in such environments without additional labelling costs. Our approach, namely continual learning approach for many processes (CLAMP), integrates a class-aware adversarial domain adaptation strategy to align a source domain and a target domain. An assessor-guided learning process is put forward to navigate the learning process of a base model assigning a set of weights to every sample controlling the influence of every sample and the interactions of each loss function in such a way to balance the stability and plasticity dilemma thus preventing the CF problem. The first assessor focuses on the negative transfer problem rejecting irrelevant samples of the source domain while the second assessor prevents noisy pseudo labels of the target domain. Both assessors are trained in the meta-learning approach using random transformation techniques and similar samples of the source domain. Theoretical analysis and extensive numerical validations demonstrate that CLAMP significantly outperforms established baseline algorithms across all experiments by at least 10% margin.},
  archive      = {J_ISCI},
  author       = {Weiwei Weng and Mahardhika Pratama and Jie Zhang and Chen Chen and Edward Yapp Kien Yie and Ramasamy Savitha},
  doi          = {10.1016/j.ins.2024.120813},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120813},
  shortjournal = {Inf. Sci.},
  title        = {Cross-domain continual learning via CLAMP},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). M3KGR: A momentum contrastive multi-modal knowledge graph
learning framework for recommendation. <em>ISCI</em>, <em>676</em>,
120812. (<a href="https://doi.org/10.1016/j.ins.2024.120812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a discernible upswing in the utilization of knowledge graphs within recommender systems. This heightened interest in knowledge graphs stems from their ability to vividly illustrate relationships between items through augmented attribute representations. Scholars have endeavored to incorporate multi-modal data, encompassing texts and images, into knowledge graphs, albeit with restricted success. These efforts primarily hinge on image models for extracting visual representations and text models for extracting textual representations, prompting apprehensions regarding potential disparities between the two modalities. Moreover, the current approaches for computing node similarities using multi-modal information have not witnessed noteworthy progress or enhancements. M omentum Contrastive M ulti- M odal K nowledge G raph Learning Framework for R ecommendation ( M 3 KGR ) proposed in this paper aims to enhance the utilization of multi-modal data. Specifically, we leverage the existing CLIP model to simultaneously extract textual and visual representations of an entity, thus overcoming the challenge of integrating multi-modal information. Additionally, we introduce a multi-modal enhanced attention technique to further enhance the performance of the graph attention network. Furthermore, we introduce Momentum Contrast to mitigate the common issues of data sparsity and noise in recommender systems. Our comprehensive experiments conducted on three real datasets demonstrate that our model enhances the efficacy of multi-modal knowledge graphs in recommender systems by fully leveraging the potential of multi-modal data. The implementation of our model will be available at https://github.com/KlaineWei/M3KGR .},
  archive      = {J_ISCI},
  author       = {Zihan Wei and Ke Wang and Fengxia Li and Yina Ma},
  doi          = {10.1016/j.ins.2024.120812},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120812},
  shortjournal = {Inf. Sci.},
  title        = {M3KGR: A momentum contrastive multi-modal knowledge graph learning framework for recommendation},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cost-effective hierarchical clustering with local density
peak detection. <em>ISCI</em>, <em>676</em>, 120811. (<a
href="https://doi.org/10.1016/j.ins.2024.120811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical clustering plays a crucial role in real-world knowledge discovery and data mining applications. This powerful technique provides tree-shaped results that are typically considered data summaries. However, achieving well-organized outputs requires a challenging trade-off between computational complexity (both in time and space) and clustering accuracy, especially in big data scenarios. To address this challenge, we propose a novel agglomerative algorithm for hierarchical clustering. Our algorithm constructs tree-shaped subclusters using a nearest-neighbour chain search. Next, the proxy (root) for each subcluster is identified using a local density peak detection mechanism, which guides the subsequent aggregation. Additionally, we propose a non-parametric variant to facilitate the easy implementation of the algorithm in real-world applications. Comprehensive experimental studies on fourteen real-world and synthetic datasets demonstrate that our algorithm surpasses other benchmarks in terms of clustering accuracy, response time, and memory footprint in most cases. Notably, our proposed algorithm can handle up to two million data points on a personal computer, further verifying its cost-effectiveness.},
  archive      = {J_ISCI},
  author       = {Wen-Bo Xie and Bin Chen and Xun Fu and Jun-Hao Shi and Yan-Li Lee and Xin Wang},
  doi          = {10.1016/j.ins.2024.120811},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120811},
  shortjournal = {Inf. Sci.},
  title        = {Cost-effective hierarchical clustering with local density peak detection},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fusing multiple interval-valued fuzzy monotonic decision
trees. <em>ISCI</em>, <em>676</em>, 120810. (<a
href="https://doi.org/10.1016/j.ins.2024.120810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a powerful knowledge mining technique for ordinal classification tasks, dominance-based rough set theory has many advantages but also some issues. Sensitivity to noisy information means that even a single mislabeled sample can lead to substantial fluctuations in the approximation calculations. Another issue is that most monotonic classifiers can only handle real-valued data and cannot directly deal with interval-valued data, which is common in practical applications. To address these issues, a tree-based fusion learning method for monotonic classification of interval-valued attributes, named FM-IFMDT, has been proposed. Its functional structure comprises three components: (i) The proposed robust β -precision interval-valued fuzzy dominance neighborhood rough set model ( β -IFDNRS) can adaptively identify and filter noise samples. (ii) The interval dominance discernibility matrix based on β -IFDNRS is developed for feature selection and can generate a set of complete and diverse feature subsets. (iii) The novel interval-valued fuzzy monotonic decision tree (IFMDT) based on the probability distribution is trained on each feature subset and is used as the base classifier of the weighted voting fusion model. Extensive experiments show the proposed fusion learning method has significant advantages.},
  archive      = {J_ISCI},
  author       = {Jiankai Chen and Zhongyan Li and Xin Wang and Han Su and Junhai Zhai},
  doi          = {10.1016/j.ins.2024.120810},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120810},
  shortjournal = {Inf. Sci.},
  title        = {Fusing multiple interval-valued fuzzy monotonic decision trees},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global robust exponential synchronization of neutral-type
interval cohen–grossberg neural networks with mixed time delays.
<em>ISCI</em>, <em>676</em>, 120806. (<a
href="https://doi.org/10.1016/j.ins.2024.120806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global robust exponential synchronization of neutral-type interval Cohen–Grossberg neural networks (NTICGNNs) with mixed time delays is analyzed in this paper. The system model, in which unrepresentable using vector-matrices, renders certain methods unsuitable for addressing issues within the vector-matrix framework. To address this limitation, a direct method based on system solutions is proposed, and sufficient conditions are provided to achieve global robust exponential synchronization of the considered NTICGNNs. This approach results in a global robust exponential synchronization criterion without the need to establish any Lyapunov-Krasovskii functionals. The applicability of the obtained synchronization conditions is validated using two numerical examples. Additionally, the obtained theoretical results have been applied to solve a quadratic programming problem and to encrypt and decrypt color images, demonstrating the practical application value of our research results. Notably, this study presents the first global robust exponential synchronization analysis for the considered NTICGNNs and proposes a novel approach grounded in system solutions.},
  archive      = {J_ISCI},
  author       = {Xin Wang and Jinbao Lan and Xiaona Yang and Xian Zhang},
  doi          = {10.1016/j.ins.2024.120806},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120806},
  shortjournal = {Inf. Sci.},
  title        = {Global robust exponential synchronization of neutral-type interval Cohen–Grossberg neural networks with mixed time delays},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary reinforcement learning with action sequence
search for imperfect information games. <em>ISCI</em>, <em>676</em>,
120804. (<a href="https://doi.org/10.1016/j.ins.2024.120804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Reinforcement Learning (DRL) has achieved remarkable success in perfect information games. However, when applied to imperfect information games like Contract Bridge, DRL faces challenges not only from unobservable partial information but also from the lack of efficient exploration. Although several Evolutionary Reinforcement Learning algorithms (ERLs) have harnessed Evolutionary Algorithms (EAs) to enhance exploration capabilities, the practical performance of EAs is limited either by the high-dimensional parameter space or possibly inaccurate guidance from value networks. In this paper, we introduce a novel ERL algorithm that employs the Particle Swarm Optimization (PSO) algorithm to search for superior action sequences, thereby aiding agents in exploring uncharted territory. We conduct the search in action space and evaluate action sequences through interactions with the environment to avoid the limitations of parameter space and value networks, respectively. The diverse experiences collected in the search and evaluation can boost the learning of the DRL agent. In addition, the action sequence search is executed only when the agent converges to local optima, which can reduce the overall cost of action evaluation and avoid influencing the optimization process of DRL. Through experimental comparisons conducted on Contract Bridge, our method demonstrates superior performance when compared with several state-of-the-art DRL and ERL algorithms. Furthermore, we utilize our method in the Bridge Competition of AAMAS 2023 Imperfect Information Card Games Competition and rank the first.},
  archive      = {J_ISCI},
  author       = {Xiaoqiang Wu and Qingling Zhu and Wei-Neng Chen and Qiuzhen Lin and Jianqiang Li and Carlos A. Coello Coello},
  doi          = {10.1016/j.ins.2024.120804},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120804},
  shortjournal = {Inf. Sci.},
  title        = {Evolutionary reinforcement learning with action sequence search for imperfect information games},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Observer-based sampled-data event-triggered tracking for
nonlinear multi-agent systems with semi-markovian switching topologies.
<em>ISCI</em>, <em>676</em>, 120803. (<a
href="https://doi.org/10.1016/j.ins.2024.120803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The observer-based and sampled-data event-triggered consensus problem of multi-agent systems (MASs) is studied under time-varying interaction topologies governed by a semi-Markovian process. In particular, a nonlinear observer is designed for estimating the unknown state of every agent such that its evolution trajectory is available asymptotically. Based on the sampled data of observed state, an exponential decay term depending on a given convergence rate as a dynamic threshold is introduced into the event-triggered condition to establish an economical and efficient controller. We consider two cases: fully known and partially unknown transition rate matrices (TRMs), respectively. A novel mode-dependent multiple Lyapunov functional is constructed to obtain lower dimensional and less conservative consensus criteria. By using linear matrix inequalities (LMIs), convex combination technique and free slack matrix, the design approach of control parameter matrices is proposed. At last, two numerical simulations are given to verify the theoretical results.},
  archive      = {J_ISCI},
  author       = {Jian Yang and JinRong Wang and Dong Shen},
  doi          = {10.1016/j.ins.2024.120803},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120803},
  shortjournal = {Inf. Sci.},
  title        = {Observer-based sampled-data event-triggered tracking for nonlinear multi-agent systems with semi-markovian switching topologies},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning and large group consensus based cruise
satisfaction evaluation model with online reviews. <em>ISCI</em>,
<em>676</em>, 120801. (<a
href="https://doi.org/10.1016/j.ins.2024.120801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cruise satisfaction assessment is pivotal for both passenger experiences and the enterprise&#39;s industry competitiveness. To do that, this research proposes a deep learning based cruise satisfaction evaluation model by integrating cruise online reviews and a large group consensus model. In order to acquire the dimensions influencing cruise passenger satisfaction, attribute extraction is employed. Unlike traditional methods that rely on word-based attribute representation, this method employs sentence-level information to comprehensively capture attributes that are of genuine concern to users, including implicit ones. Additionally, it utilizes the pre-trained language model, BART, to accurately predict sentiment polarity by treating sentiment analysis as a generation task based on online reviews from the CruiseCritic website. Subsequently, the proposed consensus model is implemented to determine the final satisfaction level, taking into consideration subgroup weights and an ideal solution-based feedback mechanism. This mechanism facilitates the provision of reasonable adjustment recommendations tailored to the context of online evaluations. Ultimately, the research findings contribute valuable insights to enhance service quality within the Royal Caribbean International cruise line.},
  archive      = {J_ISCI},
  author       = {Wenjie Ma and Feixia Ji and Changyong Liang and Qi Sun and Jian Wu},
  doi          = {10.1016/j.ins.2024.120801},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120801},
  shortjournal = {Inf. Sci.},
  title        = {A deep learning and large group consensus based cruise satisfaction evaluation model with online reviews},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maximum likelihood weight estimation for partial domain
adaptation. <em>ISCI</em>, <em>676</em>, 120800. (<a
href="https://doi.org/10.1016/j.ins.2024.120800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial Domain Adaptation (PDA) aims to generalize a classification model from a labeled source domain to an unlabeled target domain, where the source label space contains the target label space. There are two main challenges in PDA that weaken the model&#39;s classification performance in the target domain: (i) the joint distribution of the source domain is related but different from that of the target domain, and (ii) the source outlier data, whose labels do not belong to the target label space, have a negative impact on learning the target classification model. To tackle these challenges, we propose a Maximum Likelihood Weight Estimation (MLWE) approach to estimate a weight function for the source domain. The weight function matches the joint source distribution of the relevant part to the joint target distribution, and reduces the negative impact of the source outlier data. To be specific, our approach estimates the weight function by maximizing a likelihood function, and the estimation leads to a nice convex optimization problem that has a global optimal solution. In the experiments, our approach demonstrates superior performance on popular benchmark datasets. Intro video and PyTorch code are available at https://github.com/sentaochen/Maximum-Likelihood-Weight-Estimation .},
  archive      = {J_ISCI},
  author       = {Lisheng Wen and Sentao Chen and Zijie Hong and Lin Zheng},
  doi          = {10.1016/j.ins.2024.120800},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120800},
  shortjournal = {Inf. Sci.},
  title        = {Maximum likelihood weight estimation for partial domain adaptation},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Elastic online deep learning for dynamic streaming data.
<em>ISCI</em>, <em>676</em>, 120799. (<a
href="https://doi.org/10.1016/j.ins.2024.120799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic streaming data is widespread in various real-world scenarios, and the distribution may change under unforeseen disturbances. The decrease in predicted performance caused by distribution change is known as concept drift. Many online learning algorithms utilize an ensemble of multiple classifiers to mitigate the impact but the generalization is constrained by the fitting capability of base classifiers. Deep neural networks have strong fitting ability and work well in static and offline learning environments while they may struggle in both dynamic adaptation and real-time learning. An Elastic Online Deep Learning (EODL) is proposed for dynamic streaming data with concept drift, which merges the fast adaptability of online ensemble methods and the fitting ability of deep neural networks. In the EODL model, each hidden layer is attached to a classifier, also called the intermediate classifier. These intermediate classifiers are regarded as base classifiers to obtain the ensemble prediction result. Then a depth adaption strategy is proposed to select different depth subnetworks for adapting the different distribution of new coming data through intermediate classifiers. With more in-distribution data arrived, deeper depth subnetworks will be selected through weights adjustment, and their training is based on the trained shallower subnetworks. When the data distribution changes, EODL will timely select shallower depth subnetworks to rapidly relearn the new data distribution. Moreover, a parameter adaption strategy is proposed for mitigating the optimization conflict, which might occur in the backpropagation of hidden layers shared by intermediate classifiers when they have different predictions. The strategy works by setting an adaptive learning rate for each subnetwork located at different depths. Experimental results demonstrate that the EODL model can efficiently adapt to changes in dynamic streaming data and outperforms recent online learning models.},
  archive      = {J_ISCI},
  author       = {Rui Su and Husheng Guo and Wenjian Wang},
  doi          = {10.1016/j.ins.2024.120799},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120799},
  shortjournal = {Inf. Sci.},
  title        = {Elastic online deep learning for dynamic streaming data},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discrimination-aware safe semi-supervised clustering.
<em>ISCI</em>, <em>676</em>, 120798. (<a
href="https://doi.org/10.1016/j.ins.2024.120798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safe semi-supervised clustering (S3C) has recently made remarkable progress in the machine learning field and numerous S3C methods have been proposed to estimate safe degrees of labeled instances. However, these methods often overlook the discriminative information within the data. For this reason, a discrimination-aware safe semi-supervised fuzzy c -means (DaS3FCM) method is presented in this paper. To mine the discriminative information, DaS3FCM introduces cluster and instance confidence. Cluster confidence is estimated using the silhouette coefficient, and instance confidence is assessed based on the internal dissimilarity of membership degree obtained by fuzzy c -means (FCM). High cluster and instance confidence can significantly enhance larger safe degrees while reducing smaller ones. For the instances with very low safe degrees, they can be extremely mislabeled and it is beneficial to correct their labels. Therefore, their labels are corrected using those estimated by FCM. Finally, an optimization problem is formulated and solved using an iterative optimization strategy. Experimental results on synthetic and UCI datasets demonstrate that DaS3FCM respectively achieves a maximum improvement of 21%, 19%, and 3% over unsupervised, semi-supervised, and S3C methods. This indicates that DaS3FCM excels in estimating the safe degrees of labeled instances while effectively correcting mislabeled labels.},
  archive      = {J_ISCI},
  author       = {Haitao Gan and Weiyan Gan and Zhi Yang and Ran Zhou},
  doi          = {10.1016/j.ins.2024.120798},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120798},
  shortjournal = {Inf. Sci.},
  title        = {Discrimination-aware safe semi-supervised clustering},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scaled consensus of heterogeneous multi-agent systems under
asynchronous DoS attacks. <em>ISCI</em>, <em>676</em>, 120797. (<a
href="https://doi.org/10.1016/j.ins.2024.120797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the issue of scaled consensus in heterogeneous multi-agent systems (HMASs) under asynchronous Denial-of-Service (DoS) attacks. In the system structure, our exploration centers on the challenge of achieving scaled consensus in HMASs. The aim is to guarantee that the states of both first-order and second-order agents within the system reach predetermined scalar values, aligning with diverse real-world scenarios. Subsequently, the security of the system in directed communication topology under asynchronous DoS attack is also taken into account. To achieve above research objectives, an impulsive control scheme based on topology switching is proposed and a corresponding algorithm for determining the pulse moments based on the Floyd algorithm is devised. This scheme utilizes the topology switching caused by asynchronous DoS attacks as the driving force for impulsive control. Furthermore, leveraging the correlation property of random matrices, we derive the sufficient conditions for the system to achieve secure control. Finally, a numerical simulation is provided to validate the effectiveness of the protocol and the accuracy of conclusions.},
  archive      = {J_ISCI},
  author       = {Hongyun Dai and Lianghao Ji and Xing Guo and Yan Xie and Huaqing Li},
  doi          = {10.1016/j.ins.2024.120797},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120797},
  shortjournal = {Inf. Sci.},
  title        = {Scaled consensus of heterogeneous multi-agent systems under asynchronous DoS attacks},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online learning for data streams with bi-dynamic
distributions. <em>ISCI</em>, <em>676</em>, 120796. (<a
href="https://doi.org/10.1016/j.ins.2024.120796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data streams, as an important pattern of big data, require online real-time processing because instances arrive one by one and are fleeting. Existing online learning methods make distinctive assumptions, such as a fixed feature space, a varying feature space that follows specific patterns, and a fixed data distribution. However, data streams generated from real-world scenarios typically have both randomly changing feature spaces and data distributions, making existing methods inappropriate for practical applications. To fill this gap, this study proposes a novel O nline L earning for Data Streams with B i-dynamic D istributions (OLBD) algorithm. OLBD has a two-fold main idea: 1) it overcomes random changes in the feature space by building a mapping matrix to space transform and projects the original instances onto the global feature space; 2) it handles dynamic data distributions by constraining prior knowledge and transferring established mapping relationships to new distributions. To evaluate OLBD, we compared it with related state-of-the-art algorithms. First, we use 13 datasets to simulate three scenarios of dynamic feature space, namely trapezoidal, feature evolvable, and capricious data streams. Second, we simulated the data streams with dynamic data distributions using eight real and four generated datasets. We then conducted ablation studies on the parameter α . Finally, we analyzed data streams with bi-dynamic data distributions under different feature missing ratios and verified the generalization. The results show that OLBD significantly outperforms its rivals. Additionally, a practical case study on movie review classification was conducted to illustrate the effectiveness of OLBD in real-world scenarios.},
  archive      = {J_ISCI},
  author       = {Huigui Yan and Jiale Liu and Jiawei Xiao and Shina Niu and Siqi Dong and Dianlong You and Limin Shen},
  doi          = {10.1016/j.ins.2024.120796},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120796},
  shortjournal = {Inf. Sci.},
  title        = {Online learning for data streams with bi-dynamic distributions},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Voronoi tessellations based simple optimizer. <em>ISCI</em>,
<em>676</em>, 120795. (<a
href="https://doi.org/10.1016/j.ins.2024.120795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population diversity holds significant importance in determining the success of any evolutionary algorithm. It helps the algorithm in efficiently exploring the search space and identifying the promising region(s) containing global optimal solution(s). However, during the optimization procedure the population may lose its diversity, causing premature convergence in the algorithm and resulting in approximations to the sub-optimal solution(s). This paper proposes a Voronoi Tessellations based Simple Optimizer (VTSO) algorithm that utilizes a niche concept of Voronoi Tessellations (VTs) from the field of computational geometry to ensure a well-distributed population throughout the optimization procedure. It proposed an elite sampling mechanism that utilizes Lévy flights to aggressively explore the search space for locating potential optimal region(s), and the Differential Evolution (DE) algorithm to exploit these regions in order to approximate the global optimal solution(s). In addition, a population diameter-based switch is devised which activates itself when the algorithm detects premature convergence in the algorithm. Experiments are conducted on CEC14 and CEC17 benchmark test suit, and the proposed algorithm is compared with the existing state-of-the-art evolutionary algorithms. The results are competitive to recommend the VTSO algorithm as a new efficient and accurate optimizer for handling complex optimization problems.},
  archive      = {J_ISCI},
  author       = {Prathu Bajpai and Jagdish Chand Bansal},
  doi          = {10.1016/j.ins.2024.120795},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120795},
  shortjournal = {Inf. Sci.},
  title        = {Voronoi tessellations based simple optimizer},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Security concern and fuzzy output sliding mode load
frequency control of power systems. <em>ISCI</em>, <em>676</em>, 120793.
(<a href="https://doi.org/10.1016/j.ins.2024.120793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research investigates the concern of security in multi-area load frequency control (LFC) power systems using fuzzy logic output sliding mode control approach. A motion-trends-based deception attack model is proposed to represent malicious threats from communication networks. The motion-trends-based deception attack model enhances the destructive effect of deception attacks by monitoring changes in system state. In terms of the security concerns, a fuzzy-based output sliding mode control (OSMC) is applied to protect the power system from potential cyber-attacks. We provide sufficient conditions for the power systems stability under motion-trends-based deception attack. An initial controller gain that will bring the power system to stability is calculated by linear matrix inequalities (LMIs). The obtained controller gain provides a design method for fuzzy logic member functions. Fuzzy logic is then used to adjust the resulting controller gain to improve power system performance. The simulation results validate the usefulness of the proposed strategy, and indicate the viability of fuzzy logic in fine-tuning controllers.},
  archive      = {J_ISCI},
  author       = {Siwei Qiao and Xinghua Liu and Dianhui Wang and Shuzhi Sam Ge},
  doi          = {10.1016/j.ins.2024.120793},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120793},
  shortjournal = {Inf. Sci.},
  title        = {Security concern and fuzzy output sliding mode load frequency control of power systems},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Co-augmentation of structure and feature for boosting graph
contrastive learning. <em>ISCI</em>, <em>676</em>, 120792. (<a
href="https://doi.org/10.1016/j.ins.2024.120792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Contrastive Learning (GCL) learns invariant representation by maximizing the consistency between different augmented graphs that share the same semantics. However, the performance of existing GCL methods is inseparable from varied manually designed augmentation techniques that randomly perturb edges/nodes/features, which unexpectedly change the semantic similarity and lead to biased structure and feature augmentation. In this paper, we propose a co-augmentation strategy for STR ucture and FE ature ( STRFE ) to eliminate augmentation bias. Specifically, we construct a relatively unbiased augmented graph by amplifying or suppressing graph frequency in the spectral domain, which promises structural consistency and feature diversity between the augmented and original graph. Moreover, we investigate external and internal contrastive loss to balance the consistency and diversity between the original and augmented graph, which facilitates preserving semantic similarity and encourages relatively unbiased structure and feature augmentation to enhance the performance of GCL. Theoretical analysis proves why our proposed structure and feature co-augmentation strategy can perform well. Extensive experiments show that STRFE achieves competitive results in three real-world datasets on different downstream tasks compared with more than ten benchmarks.},
  archive      = {J_ISCI},
  author       = {Peng Bao and Rong Yan and Shirui Pan},
  doi          = {10.1016/j.ins.2024.120792},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120792},
  shortjournal = {Inf. Sci.},
  title        = {Co-augmentation of structure and feature for boosting graph contrastive learning},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning solid dynamics with graph neural network.
<em>ISCI</em>, <em>676</em>, 120791. (<a
href="https://doi.org/10.1016/j.ins.2024.120791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has shown great promise in solid physic dynamic simulation. By incorporating physical laws, recent works have further improved performance. However, existing methods rarely conform to macrophysics and incur computational costs. Furthermore, the velocity direction features of the current model have not been decomposed, forcing the model to learn vector operations. To address the aforementioned problems, we propose a S olid- G raph N etwork (Solid-GN), designed for more accurate and efficient learning of solid dynamics. Firstly, we design a novel and cost-effective symmetric direction encoding system that achieves macroscopic equivariance in 2D space by representing same relative directional relationships among particle pairs and their flipping version. Secondly, we propose a message-passing mechanism incorporated with the contact process, facilitating an accurate description of interactions through the decomposition of normal and tangential effects. Lastly, four novel datasets for solid dynamics with non-uniform radius particles are released, thereby enabling more complex and realistic physical simulations. Experimental evaluations conducted on five datasets demonstrate our model&#39;s performance concerning predictive accuracy, macroscopic equivariance, and computational cost over the state-of-the-art ones.},
  archive      = {J_ISCI},
  author       = {Bohao Li and Bowen Du and Junchen Ye and Jiajing Huang and Leilei Sun and Jinyan Feng},
  doi          = {10.1016/j.ins.2024.120791},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120791},
  shortjournal = {Inf. Sci.},
  title        = {Learning solid dynamics with graph neural network},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multigranulation variable-scale fuzzy neighborhood measures
and corresponding choquet-like integrals for feature selection.
<em>ISCI</em>, <em>676</em>, 120789. (<a
href="https://doi.org/10.1016/j.ins.2024.120789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Choquet-like integrals, a nonlinear fuzzy aggregation function, are diffusely applied in several real problems. However, the corresponding fuzzy measures in them are provided by human intervention and not by data-driven methods. As an effective knowledge representation tool, rough set models in different approximation spaces are established for data processing. Particularly, the multigranulation fuzzy β -covering approximation space has been concerned with only a single scale β ∈ ( 0 , 1 ] β∈(0,1] . However, different granulation structures should have different scales. Therefore, establishing a multigranulation approximation space with a variable scale by inducing fuzzy measures through data-driven methods and using corresponding Choquet-like integrals in practical problems is a significant challenge. To address this challenge, the notion of multigranulation variable-scale fuzzy Θ-covering group approximation space is presented here, as well as multigranulation variable-scale fuzzy neighborhood measures in it. Furthermore, Choquet-like integrals with the presented measures are constructed to solve the issue of feature selection (i.e., attribute reduction) under the new approximation spaces. Firstly, the concept of multigranulation variable-scale fuzzy Θ-covering group approximation space is presented, where different fuzzy β -coverings have different scales β ∈ Θ β∈Θ . Moreover, multigranulation variable-scale fuzzy neighborhood measures in it, as fuzzy measures, are presented. Subsequently, Choquet-like integrals with multigranulation variable-scale fuzzy neighborhood measures are constructed. A novel attribute reduction method under Choquet-like integrals with multigranulation variable-scale fuzzy neighborhood measures is proposed for any decision information table. Finally, the presented method is selected for solving problems of classification and diagnosis of rolling bearing faults. Several public data sets are used to demonstrate the effectiveness and feasibility of the presented methods mentioned above.},
  archive      = {J_ISCI},
  author       = {Jingqian Wang and Songtao Shao and Xiaohong Zhang},
  doi          = {10.1016/j.ins.2024.120789},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120789},
  shortjournal = {Inf. Sci.},
  title        = {Multigranulation variable-scale fuzzy neighborhood measures and corresponding choquet-like integrals for feature selection},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantum differential evolutionary algorithm with
quantum-adaptive mutation strategy and population state evaluation
framework for high-dimensional problems. <em>ISCI</em>, <em>676</em>,
120787. (<a href="https://doi.org/10.1016/j.ins.2024.120787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential Evolution (DE) has been found to be inefficient and inaccurate in addressing high-dimensional complex problems. The Quantum-inspired Differential Evolution algorithm (QDE), endowed with quantum computing characteristics, efficiently manages high-dimensional problems but suffers from excessive mutation and poor convergence performance. Therefore, a new quantum differential evolutionary algorithm with quantum-adaptive mutation strategy and population state evaluation framework, namely PSEQADE is proposed. In PSEQADE, the quantum adaptive mutation strategy is employed to address the issue of excessive mutation in QDE, which adaptively reduces the degree of mutation, taking full advantage of the exceptional performance of quantum computing to enhance convergence accuracy. The quantum adaptive PSE framework is introduced to monitor the unstable mutation trends within the population, evaluate the population’s state, and intervene accordingly, thereby significantly improving the convergence performance and stability of the quantum differential evolution algorithm. 20 well-known functions from CEC2017 were selected for comparison with EPSDE, SADE, SHADE, JADE, CODE algorithms in dimensions of 500, 1000 and 3000. Additionally, comparisons were conducted with MLSHADE-SPA, SHADE-ILS, CCPSO2, NFDDE, DBO, and RIME algorithms in the dimension of 3000. Experimental results demonstrate that PSEQADE exhibits excellent convergence performance, high convergence accuracy, and exceptional stability in solving high-dimensional complex problems.},
  archive      = {J_ISCI},
  author       = {Wu Deng and Jiarui Wang and Aibin Guo and Huimin Zhao},
  doi          = {10.1016/j.ins.2024.120787},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120787},
  shortjournal = {Inf. Sci.},
  title        = {Quantum differential evolutionary algorithm with quantum-adaptive mutation strategy and population state evaluation framework for high-dimensional problems},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-efficient software defect prediction: A comparative
analysis of active learning-enhanced models and voting ensembles.
<em>ISCI</em>, <em>676</em>, 120786. (<a
href="https://doi.org/10.1016/j.ins.2024.120786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As software systems undergo escalating complexity, the identification of bugs and defects becomes pivotal for ensuring seamless user experiences and averting potentially costly post-release issues. This study addresses this critical need by concentrating on the application of active learning methods in code defect prediction. The investigation focuses on the efficacy of active learning combined with ensemble methods, leveraging the dynamic selection and labeling of training instances to increase model performance, reduce the demand for exhaustive labeling efforts, and enhance the effectiveness of code defect prediction systems. Various traditional and ensemble methods are deployed, employing diverse query strategies (uncertainty, margin, and entropy sampling) to assess if active variants can rival original approaches while significantly downsizing the training set. Evaluation encompasses classical classification metrics (AUC, Kappa, and MCC), supplemented by a proposed easy-to-interpret performance index that takes into consideration not only the traditional metric outcomes but also the percentage of the initial dataset utilized, aligned with the dual nature of the problem. The results, elucidated through graphical representations and statistical tests, unveil the advantage of active methods, showcasing reductions of the initial training set by at least 75% in approximately 64% of cases.},
  archive      = {J_ISCI},
  author       = {Charalampos M. Liapis and Aikaterini Karanikola and Sotiris Kotsiantis},
  doi          = {10.1016/j.ins.2024.120786},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120786},
  shortjournal = {Inf. Sci.},
  title        = {Data-efficient software defect prediction: A comparative analysis of active learning-enhanced models and voting ensembles},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finding mixed memberships in categorical data.
<em>ISCI</em>, <em>676</em>, 120785. (<a
href="https://doi.org/10.1016/j.ins.2024.120785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Latent class analysis, a fundamental problem in categorical data analysis, often encounters overlapping latent classes that introduce further challenges. This paper presents a solution to this problem by focusing on finding latent mixed memberships of subjects in categorical data with polytomous responses. We employ the Grade of Membership (GoM) model, which assigns each subject a membership score in each latent class. To address this, we propose two efficient spectral algorithms for estimating these mixed memberships and other GoM parameters. Our algorithms are based on the singular value decomposition of a regularized Laplacian matrix. We establish their convergence rates under a mild condition on data sparsity. Additionally, we introduce a metric to evaluate the quality of estimated mixed memberships for real-world categorical data and determine the optimal number of latent classes based on this metric. Finally, we demonstrate the practicality of our methods through experiments on both computer-generated and real-world categorical datasets.},
  archive      = {J_ISCI},
  author       = {Huan Qing},
  doi          = {10.1016/j.ins.2024.120785},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120785},
  shortjournal = {Inf. Sci.},
  title        = {Finding mixed memberships in categorical data},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fine-grained complexity-driven latency predictor in
hardware-aware neural architecture search using composite loss.
<em>ISCI</em>, <em>676</em>, 120783. (<a
href="https://doi.org/10.1016/j.ins.2024.120783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient hardware-aware neural architecture search is crucial for automating the creation of network architectures that are optimized for resource-limited platforms. However, challenges arise owing to inaccuracies in key hardware performance metrics, notably in latency estimation. This study introduces a composite loss-based complexity-driven latency predictor, which is an innovative approach that achieves remarkable evaluation accuracy with limited training data. This reveals a robust correlation between the layer-based complexity features and network inference latency. This groundbreaking insight leverages these complex features as network architecture encodings for latency predictors, substantially enhancing the precision of latency assessments. In addition, a composite loss function is proposed that seamlessly integrates ranking and absolute performance losses. This novel approach addresses the limitations of rank-based loss methods, which often lack broader context. Incorporating a global perspective through absolute performance metrics significantly improves the generalization capabilities of the predictor across various benchmarks. Experimental results on the NAS-Bench-201, NAS-Bench-101, and MobileNetV3 benchmarks underscore the effectiveness of the predictor. For instance, in the NAS-Bench-201 evaluation, the predictor demonstrates a notable increase in Kendall&#39;s tau correlation, from 0.738 to 0.9733. These findings highlight the enhanced accuracy of the proposed approach with far-reaching implications for optimizing network structures on resource-limited platforms.},
  archive      = {J_ISCI},
  author       = {Chengmin Lin and Pengfei Yang and Chengcheng Li and Fei Cheng and Wenkai Lv and Zhenyi Wang and Quan Wang},
  doi          = {10.1016/j.ins.2024.120783},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120783},
  shortjournal = {Inf. Sci.},
  title        = {Fine-grained complexity-driven latency predictor in hardware-aware neural architecture search using composite loss},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dismantling complex networks with graph contrastive learning
and multi-hop aggregation. <em>ISCI</em>, <em>676</em>, 120780. (<a
href="https://doi.org/10.1016/j.ins.2024.120780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network dismantling is a process of identifying influential nodes that can decompose a network into disconnected sub-networks. This provides a novel approach to understanding and analyzing complex networks abstracted from the real world. State-of-the-art solutions for this task exploit graph encoders to capture the structural features of the network, which are then sent to the multi-layer perceptron for predicting the node importance. This process, however, fails to exploit the interactions among the graph representations learned from different views and neglects the neighboring information when evaluating node importance. In this work, we address these issues with a graph contrastive learning framework with multi-hop aggregation, resulting in the identification of influential nodes. Firstly, we construct role graphs to provide a holistic view of the original graphs. Secondly, graph representations are obtained in the individual views, and enhanced expressiveness is achieved through contrastive learning. Finally, based on the representations, the multi-hop neighbor information of the nodes is aggregated to rank the node importance, and thus aid in the identification of important nodes. We evaluate our proposal on real and synthetic networks, and the results show that our method outperforms the baseline with fewer nodes required to disassemble a network.},
  archive      = {J_ISCI},
  author       = {Siqi Ma and Weixin Zeng and Weidong Xiao and Xiang Zhao},
  doi          = {10.1016/j.ins.2024.120780},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120780},
  shortjournal = {Inf. Sci.},
  title        = {Dismantling complex networks with graph contrastive learning and multi-hop aggregation},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic analysis and control measures of rumor propagation
model considering true individuals and public opinion individuals.
<em>ISCI</em>, <em>676</em>, 120779. (<a
href="https://doi.org/10.1016/j.ins.2024.120779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to better describe the mechanism of rumor propagation, suppress rumor propagation. This paper examines the influence of true information disseminators on individuals and rumor spreaders who are affected by the public opinion environment. It is found by comparing those who have true information and those who do not have true information in the population. When there are true information disseminators in the crowd, it can effectively control the turn of individuals affected by the public opinion environment to the spread of rumors, and increase the turn of individuals affected by the public opinion environment to the true information disseminators. In addition, this paper analyzes the problems related to the optimal control of the rumor propagation model, and proposes some policies to increase the number of true information disseminators and reduce the number of rumor propagators, so as to better control the spread of rumors. Finally, numerical simulations verify the inhibitory effect of true information disseminators on the spread of rumors. It can be seen from the figure that the earlier the true information disseminator appears, the greater the number of true information disseminators, and the more obvious the inhibitory effect on the spread of rumors.},
  archive      = {J_ISCI},
  author       = {Meng Wang and Yuhan Hu},
  doi          = {10.1016/j.ins.2024.120779},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120779},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic analysis and control measures of rumor propagation model considering true individuals and public opinion individuals},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extremal values of degree-based entropies of bipartite
graphs. <em>ISCI</em>, <em>676</em>, 120737. (<a
href="https://doi.org/10.1016/j.ins.2024.120737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We characterize the bipartite graphs that minimize the (first degree-based) entropy among all bipartite graphs of given size. For bipartite graphs given size and (upper bound on the) order, we give a lower bound for this entropy. The extremal graphs turn out to be complete bipartite graphs, or nearly complete bipartite. Here we make use of an equivalent representation of bipartite graphs by means of Young diagrams, which make it easier to compare the entropy of related graphs. We conclude that the general characterization of the extremal graphs is a difficult problem, due to its connections with number theory. However, it is easier to identify them for particular values of the order n and size m because we have narrowed down the possible extremal graphs. We indicate that some of our ideas extend to other degree-based topological indices as well.},
  archive      = {J_ISCI},
  author       = {Stijn Cambie and Yanni Dong and Matteo Mazzamurro},
  doi          = {10.1016/j.ins.2024.120737},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120737},
  shortjournal = {Inf. Sci.},
  title        = {Extremal values of degree-based entropies of bipartite graphs},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Causality-aware social recommender system with network
homophily informed multi-treatment confounders. <em>ISCI</em>,
<em>676</em>, 120729. (<a
href="https://doi.org/10.1016/j.ins.2024.120729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Typical recommender systems utilize observed ratings of users as inputs to learn their preferences and aim to output recommendations of new items that users will like by predicting their potential ratings. The real world is driven by causality given that whether or not a user is made exposed to the item may significantly affect the rating. While some recent methods have taken a causal view to mitigate the confounding bias in observed rating data, few have recognized recommendation as a multiple causal inference problem that concerns numerous items simultaneously in practice. By framing the recommendation as a multiple causal inference problem, this paper develops a causality-aware social recommender that incorporates underlying social network structures with matrix factorization methods for deconfounding in networked observational data to enhance social recommendations. Leveraging social network information, which inherently confounds with the preferences of users, is particularly crucial but not trivial for inferring unobserved confounders in social recommender systems. Considering that connected users in a social network share similar attributes, we propose to incorporate the network homophily into the matrix factorization models through regularization to better learn the latent variables. The extracted latent variables then capture the network informed multi-treatment confounders to mitigate the confounding bias and improve the rating prediction accuracy. The models are estimated through a proximal gradient-based optimization framework, which not only eases the incorporation of the network structure constraints but also improves the computational efficiency of the proposed method. Simulation and case studies are conducted to validate the proposed method.},
  archive      = {J_ISCI},
  author       = {Xin Zan and Alexander Semenov and Chao Wang and Xiaochen Xian and Wondi Geremew},
  doi          = {10.1016/j.ins.2024.120729},
  journal      = {Information Sciences},
  month        = {8},
  pages        = {120729},
  shortjournal = {Inf. Sci.},
  title        = {Causality-aware social recommender system with network homophily informed multi-treatment confounders},
  volume       = {676},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A principled framework for explainable multimodal
disentanglement. <em>ISCI</em>, <em>675</em>, 120768. (<a
href="https://doi.org/10.1016/j.ins.2024.120768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning effective representations for data from multiple modalities is crucial in machine learning. Recent efforts focus on learning latent representations that integrate information from various modalities. These approaches generally assume simple or implicit relationships between different modalities and as a result are not able to accurately and explicitly depict the correlations among these modalities and lack explainability. To address this, we propose definitions and conditions for unsupervised multimodal disentanglement, offering guidelines for explicit disentanglement between modalities to enhance explainability. Furthermore, we have derived a novel objective function to explicitly separate multimodal data into components shared across modalities and components exclusive to each modality. The explicit guaranteed disentanglement is of great potential for downstream tasks. Benefiting from a cleverly designed network structure, we can visualize these disentangled representations, providing intuitive explainability. Experiments on a variety of multimodal datasets demonstrate that our objective can effectively disentangle information from different modalities while satisfying the disentangling conditions.},
  archive      = {J_ISCI},
  author       = {Zongbo Han and Tao Luo and Huazhu Fu and Qinghua Hu and Joey Tianyi Zhou and Changqing Zhang},
  doi          = {10.1016/j.ins.2024.120768},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120768},
  shortjournal = {Inf. Sci.},
  title        = {A principled framework for explainable multimodal disentanglement},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An axiomatic framework for three-way clustering.
<em>ISCI</em>, <em>675</em>, 120761. (<a
href="https://doi.org/10.1016/j.ins.2024.120761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way clustering provides a variety of models with richer structural features than traditional two-way clustering. However, the structural properties of three-way clustering have not been systematically studied. In this paper, we propose an axiomatic framework to study three-way clustering based on the structural properties of three-way clusters. We categorize three-way clustering models into 16 types organized in five levels according to six axioms. We propose three strategies for three-way clustering approaches: the 2to3WC Strategy, the I3WC Strategy, and the E3WC Strategy. These strategies comprehensively cover existing three-way clustering models. We examine each of the existing methods and incorporate almost all of them into these three strategies. The framework not only summarizes the structural properties and methods of existing studies but also provides inspiration for future research. There are six types of three-way clustering models that have not yet been proposed and require further study. Strategies that have not been applied to each type also suggest possible future research directions.},
  archive      = {J_ISCI},
  author       = {Yingxiao Chen and Ping Zhu and Yiyu Yao},
  doi          = {10.1016/j.ins.2024.120761},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120761},
  shortjournal = {Inf. Sci.},
  title        = {An axiomatic framework for three-way clustering},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CosPer: An adaptive personalized approach for enhancing
fairness and robustness of federated learning. <em>ISCI</em>,
<em>675</em>, 120760. (<a
href="https://doi.org/10.1016/j.ins.2024.120760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) enables clients to collaboratively train a global model while safeguarding the privacy of their respective data. In practical applications, the data heterogeneity across clients introduces competing constraints on the accuracy, fairness and robustness of FL models. However, existing methods that attempt to address all three of these issues perform poorly in scenarios with severe data heterogeneity. To address this limitation, this paper proposes an innovative personalized federated learning (PFL) framework named CosPer. This framework employs an adaptive local aggregation mechanism, where the aggregation weight is determined by the cosine similarity between the global gradient and the local gradient of each client. This mechanism can construct a personalized model for each client, suited to different degrees of the data heterogeneity. In addition, we conduct extensive experiments to evaluate the performance of CosPer on four datasets. The results demonstrate that CosPer outperforms other state-of-the-art PFL methods in terms of accuracy, fairness and robustness.},
  archive      = {J_ISCI},
  author       = {Pengcheng Ren and Kaiyue Qi and Jialin Li and Tongjiang Yan and Qiang Dai},
  doi          = {10.1016/j.ins.2024.120760},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120760},
  shortjournal = {Inf. Sci.},
  title        = {CosPer: An adaptive personalized approach for enhancing fairness and robustness of federated learning},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VIRTSI: A novel trust dynamics model enhancing artificial
intelligence collaboration with human users – insights from a ChatGPT
evaluation study. <em>ISCI</em>, <em>675</em>, 120759. (<a
href="https://doi.org/10.1016/j.ins.2024.120759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid integration of intelligent processes and methods into information systems in the Artificial Intelligence (AI) era has led to a substantial shift towards autonomous software decision-making. This evolution necessitates robust human oversight, especially in critical domains like Healthcare, Education, and Energy. Human trust in AI plays a vital role in influencing decision-making processes of users interacting with AI. This paper presents VIRTSI ( V ariability and I mpact of R eciprocal T rust S tates towards I ntelligent systems), a novel rigorous computational model for human-AI Interaction. VIRTSI simulates human trust states, spanning from overtrust to distrust, through user modelling. It comprises: 1. A trust dynamics representational model based on Deterministic Finite State Automata (DFAs), illustrating transitions among cognitive trust states in response to AI-generated replies. 2. A trust evaluation model based on Confusion Matrices, originating from machine learning and Accuracy Metrics, providing a quantitative framework for analysing human trust dynamics. As a result, this is the first time that trust dynamics have been thoroughly traced in a representational model and a method has been developed to assess the impact of possibly harmful states like overtrust and distrust. An empirical study on the recently launched Large Language Model of generative AI, ChatGPT (version 3.5), provides a radical underexplored AI-generated platform for evaluating the human-AI interaction through VIRTSI. The study involved 1200 interactions of real users as well as AI experts together with experts in two very different domains of evaluation, namely software engineering and poetry. This study traces trust dynamics and the emerging human-AI interaction, in concrete examples of real user synergies with generative AI. The research reveals the vital role of maintaining normal trust states for optimal human-AI interaction and that both AI and human users need further steps towards this goal. The real-world implications of this research can guide the creation and evaluation of user interfaces with AI and the incorporation of functionalities in the development of generative AI chatbots in terms of trust by providing a new rigorous DFA representational method of trust dynamics and a corresponding new perspective of confusion matrix evaluation method of the dynamics’ impact in the efficiency of human-AI dialogues.},
  archive      = {J_ISCI},
  author       = {Maria Virvou and George A. Tsihrintzis and Evangelia-Aikaterini Tsichrintzi},
  doi          = {10.1016/j.ins.2024.120759},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120759},
  shortjournal = {Inf. Sci.},
  title        = {VIRTSI: A novel trust dynamics model enhancing artificial intelligence collaboration with human users – insights from a ChatGPT evaluation study},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-independent event-based consensus of multiple
euler-lagrange systems with input disturbances. <em>ISCI</em>,
<em>675</em>, 120758. (<a
href="https://doi.org/10.1016/j.ins.2024.120758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates leaderless consensus (LLC) and leader-follower consensus (LFC) issues of multiple Euler-Lagrange systems (MELSs) with uncertain system parameters and input disturbances. Firstly, by utilizing event-based control strategy, event-based consensus protocols are proposed to achieve LLC and LFC, respectively. Then, to confirm that no Euler-Lagrange (EL) system will exhibit Zeno behavior under the above event-based consensus protocols, we show that the low bound of event-triggering interval is strictly positive for any time instants. Distinct with the existing related works, the proposed event-triggered consensus protocols only rely on local sampled state, and are irrelevant to the system parameters. Finally, some simulation examples are presented to illustrate the feasibility of the proposed event-based consensus algorithms.},
  archive      = {J_ISCI},
  author       = {Mingkang Long and Qing An and Housheng Su},
  doi          = {10.1016/j.ins.2024.120758},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120758},
  shortjournal = {Inf. Sci.},
  title        = {Model-independent event-based consensus of multiple euler-lagrange systems with input disturbances},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel cooperative swarm intelligence feature selection
method for hybrid data based on fuzzy β covering and fuzzy
self-information. <em>ISCI</em>, <em>675</em>, 120757. (<a
href="https://doi.org/10.1016/j.ins.2024.120757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the generalization of fuzzy covering, fuzzy β covering can effectively deal with uncertain information in hybrid data. Swarm intelligence algorithm has unique advantages in feature selection. This paper proposes a novel cooperative swarm intelligence feature selection method for hybrid data based on fuzzy β covering and fuzzy self-information. First, the parameterized fuzzy β neighborhood and fuzzy decision in a fuzzy β covering decision information system are defined, and the lower and upper fuzzy approximations are further studied. Fuzzy rough set model exclusively focuses on the information derived from the lower fuzzy approximation within a decision. In actual circumstances, the uncertainty of fuzzy information is linked to not only the lower fuzzy approximation but also the upper fuzzy approximation. Then, by incorporating the lower and upper fuzzy approximations of a decision, fuzzy self-information and relative fuzzy self-information are introduced as two evaluation indicators of feature selection. Next, a forward feature selection algorithm based on heuristic search strategy is designed by means of these two evaluation indicators. Moreover, in order to effectively explore feature subsets to a greater extent, a cooperative swarm intelligent feature selection algorithm based on random search strategy is also designed by combining particle swarm optimization algorithm and cuckoo search algorithm. Finally, an array of experiments is executed to compare two designed algorithms with five other existing feature selection algorithms. Experimental results show that these two designed algorithms achieve a high feature selection rate while improving the classification accuracy of the raw data.},
  archive      = {J_ISCI},
  author       = {Zhaowen Li and Xiaopeng Cai and Qin Huang and Yonghua Lin},
  doi          = {10.1016/j.ins.2024.120757},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120757},
  shortjournal = {Inf. Sci.},
  title        = {A novel cooperative swarm intelligence feature selection method for hybrid data based on fuzzy β covering and fuzzy self-information},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural network-based adaptive critic control for saturated
nonlinear systems with full state constraints via a novel
event-triggered mechanism. <em>ISCI</em>, <em>675</em>, 120756. (<a
href="https://doi.org/10.1016/j.ins.2024.120756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the issue of event-triggered optimal control for saturated nonlinear systems with full state constraints. A smooth function is defined to map the constrained states, then the considered system can be transformed into a state unconstrained system with unknown approximate errors. In addition, a novel event-triggered mechanism is proposed via an adaptive dynamic programming algorithm, which can obtain the optimal control law without constructing the so-called event-triggered HJB equation. Moreover, in order to conquer the difficulty caused by the persistence of excitation conditions, the experience replay technique is utilized to design the critic update law. Meanwhile, it is demonstrated that all signals are uniformly ultimately bounded. Finally, two simulation examples are given to demonstrate the effectiveness of the control strategy.},
  archive      = {J_ISCI},
  author       = {Heng Zhao and Huanqing Wang and Xiaoheng Chang and Adil M. Ahmad and Xudong Zhao},
  doi          = {10.1016/j.ins.2024.120756},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120756},
  shortjournal = {Inf. Sci.},
  title        = {Neural network-based adaptive critic control for saturated nonlinear systems with full state constraints via a novel event-triggered mechanism},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A study on fuzzy sphere and fuzzy cone. <em>ISCI</em>,
<em>675</em>, 120755. (<a
href="https://doi.org/10.1016/j.ins.2024.120755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate three different methods to construct a fuzzy sphere . These methods depend on the entities available to form a fuzzy sphere. In the first method, we formulate a fuzzy sphere when the position of the center and the value of the radius are given imprecisely. In the second method, a fuzzy sphere is constructed when the diameter of a fuzzy sphere is known. In the last method, we construct a fuzzy sphere that passes through four given S -type space fuzzy points whose core points are not co-planar. Also, a rotation invariance property of a fuzzy sphere is investigated. In addition, we show that the intersection of a fuzzy sphere with a crisp plane is a fuzzy circle . In a sequel, the idea of a fuzzy cone is developed. The properties concerned with the intersection of a fuzzy cone with a crisp plane are studied sequentially. All the studies are supported with geometrical interpretations and numerical examples. Moreover, we also develop the algorithms to get the membership grade of a number},
  archive      = {J_ISCI},
  author       = {Diksha Gupta and Debdas Ghosh and Tanmoy Som},
  doi          = {10.1016/j.ins.2024.120755},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120755},
  shortjournal = {Inf. Sci.},
  title        = {A study on fuzzy sphere and fuzzy cone},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy control for networked systems with mixed data missing
under quantization based event-triggered scheme. <em>ISCI</em>,
<em>675</em>, 120754. (<a
href="https://doi.org/10.1016/j.ins.2024.120754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an innovative event-triggered fuzzy control approach for networked systems operating over unreliable network channels. Traditional complicated modeling and analysis process of network induced issues is replaced by a bran-new logarithmic quantization based event-triggered scheme method. The joint characterization of mixed data missing, arising from the event-triggered mechanism and unreliable network channels, becomes a challenging issue due to disrupted data sequences and variable relations. Consequently, this paper contributes a formulated auxiliary stochastic sequence approach to overcome the difficulty of dynamics modeling. With an formulated event driven controller, the modeling and implementation of the closed-loop systems are constructed and further simplified. Considering the difference and relation between the membership functions of plant and controller, we present a new fuzzy output feedback controller design method to obtain feasible result via uncertainty based method. Finally, we verify the validity of the designed control policy via a simulation example.},
  archive      = {J_ISCI},
  author       = {Ziran Chen and Cheng Tan and Zhengqiang Zhang},
  doi          = {10.1016/j.ins.2024.120754},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120754},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy control for networked systems with mixed data missing under quantization based event-triggered scheme},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A density clustering-based differential evolution algorithm
for solving nonlinear equation systems. <em>ISCI</em>, <em>675</em>,
120753. (<a href="https://doi.org/10.1016/j.ins.2024.120753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving nonlinear equation systems (NESs) is one of the most important tasks in numerical computing. The NESs usually have multiple roots, and quickly locating their roots in a single algorithm run with a limited number of iterations has always been the algorithm improvement direction. In order to further enhance the efficiency of the existing methods, a density clustering-based differential evolution algorithm (DCDE) for the NESs problem solving is proposed in this paper. Firstly, density-based spatial clustering of applications with noise (DBSCAN) is used to divide the population into clusters and noises, which provides a better direction for population evolution. Secondly, a cluster evaluation factor is proposed, which not only divides the clusters into excellent clusters and non-excellent clusters, but also prevents the migration of excellent clusters and maintain the diversity of populations. Then, a migration strategy and individual generation mechanism are proposed to guide non-excellent clusters to migrate to promising regions. Finally, combined with an archive technique, the individuals which satisfy the solution requirements are archived and randomly initialized to further improve population diversity. To verify the effectiveness of the proposed algorithm, comparative experimental results of the propsoed DCDE with other state-of-the-art algorithms for thirty NESs problems solving show that the proposed DCDE is the most effective algorithm to locate more roots in a single run.},
  archive      = {J_ISCI},
  author       = {Yan Guo and Mu Li and Jie Jin and Xianke He},
  doi          = {10.1016/j.ins.2024.120753},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120753},
  shortjournal = {Inf. Sci.},
  title        = {A density clustering-based differential evolution algorithm for solving nonlinear equation systems},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generative adversarial networks for overlapped and
imbalanced problems in impact damage classification. <em>ISCI</em>,
<em>675</em>, 120752. (<a
href="https://doi.org/10.1016/j.ins.2024.120752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops an oversampling method designed for rebalancing datasets in impact damage classification of reinforced concrete walls. The proposed method addresses class imbalance and overlap issues using the Wasserstein Generative Adversarial Network with Gradient Penalty (WGANGP) approach, aiming to enhance classification accuracy. Initially, sample weights are calculated for overlapped and non-overlapped samples based on their proximity to the decision boundary via an initial classification process using the Support Vector Machine algorithm. Then, these weighted samples are combined with the original dataset to form a training dataset for the WGANGP model. To effectively learn from limited data samples and stabilize the training process, the Model Agnostic Meta-learning (MAML) method is incorporated into the WGANGP algorithm. New samples are generated to balance the impact damage dataset using the generator network of the WGANGP model. The proposed method is compared to advanced oversampling methods handling overlapping, noisy, near-borderline samples between the classes. Four well-known classifiers are trained on the impact damage dataset, including Multilayer Perceptron (MLP), Random Forest (RF), Extreme Gradient Boosting (XGB), and Support Vector Machine (SVM). Implementation results demonstrate the efficacy of the proposed oversampling technique on the impact damage dataset, outperforming others in terms of F1 score.},
  archive      = {J_ISCI},
  author       = {Quoc Hoan Doan and Behrooz Keshtegar and Seung-Eock Kim and Duc-Kien Thai},
  doi          = {10.1016/j.ins.2024.120752},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120752},
  shortjournal = {Inf. Sci.},
  title        = {Generative adversarial networks for overlapped and imbalanced problems in impact damage classification},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot class incremental learning via robust transformer
approach. <em>ISCI</em>, <em>675</em>, 120751. (<a
href="https://doi.org/10.1016/j.ins.2024.120751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-Shot Class-Incremental Learning (FSCIL)presents an extension of the Class Incremental Learning (CIL)problem where a model is faced with the problem of data scarcity while addressing the Catastrophic Forgetting (CF)problem. This problem remains an open problem because all recent works are built upon the Convolutional Neural Networks (CNNs)performing sub-optimally compared to the transformer approaches. Our paper presents Robust Transformer Approach (ROBUSTA)built upon the Compact Convolutional Transformer (CCT). The issue of overfitting due to few samples is overcome with the notion of the stochastic classifier, where the classifier&#39;s weights are sampled from a distribution with mean and variance vectors, thus increasing the likelihood of correct classifications, and the batch-norm layer to stabilize the training process. The issue of CFis dealt with the idea of delta parameters, small task-specific trainable parameters while keeping the backbone networks frozen. A non-parametric approach is developed to infer the delta parameters for the model&#39;s predictions. The prototype rectification approach is applied to avoid biased prototype calculations due to the issue of data scarcity. The advantage of ROBUSTAis demonstrated through a series of experiments in the benchmark problems where it is capable of outperforming prior arts with big margins without any data augmentation protocols.},
  archive      = {J_ISCI},
  author       = {Naeem Paeedeh and Mahardhika Pratama and Sunu Wibirama and Wolfgang Mayer and Zehong Cao and Ryszard Kowalczyk},
  doi          = {10.1016/j.ins.2024.120751},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120751},
  shortjournal = {Inf. Sci.},
  title        = {Few-shot class incremental learning via robust transformer approach},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HUSM: High utility subgraph mining in single graph
databases. <em>ISCI</em>, <em>675</em>, 120743. (<a
href="https://doi.org/10.1016/j.ins.2024.120743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent subgraph mining (FSM) is a crucial research area with diverse applications. However, traditional FSM treats all subgraphs as equally important. In practical applications, some subgraphs may be frequent but not very valuable, while others may be infrequent but highly valuable. To address this issue, we introduce utility pattern mining into single graph mining, enabling the discovery of meaningful patterns based on user&#39;s interest rather than relying solely on support. We define a utility function in single graph databases and formally define the problem of high utility subgraph mining (HUSM). In the face of several challenges posed by this new problem, such as the absence of downward closure property and a large number of candidates, we design several utility upper bounds that satisfy the downward closure property . We then develop a HUSM algorithm to efficiently mine all high utility subgraphs in single graph databases. Additionally, we design a lossless concise representation for high utility subgraphs, which has fewer instances than the total number of high utility subgraphs and can derive all of them, making the mining results more representative. The experimental results demonstrate that our method exhibits excellent performance, and the concise representation plays a significant role in simplifying the mining results.},
  archive      = {J_ISCI},
  author       = {Zhaoming Chen and Cheng He and Guoting Chen and Wensheng Gan and Philippe Fournier-Viger},
  doi          = {10.1016/j.ins.2024.120743},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120743},
  shortjournal = {Inf. Sci.},
  title        = {HUSM: High utility subgraph mining in single graph databases},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diff-MGR: Dynamic causal graph attention and pattern
reproduction guided diffusion model for multivariate time series
probabilistic forecasting. <em>ISCI</em>, <em>675</em>, 120742. (<a
href="https://doi.org/10.1016/j.ins.2024.120742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series probability forecasting provides insight into future evolution and its inherent uncertainty from past data. In order to obtain more accurate forecasting as the reliable basis for future decision-making and planning, a new probabilistic prediction model of multivariate time series Diff-MGR is proposed in this study. Diff-MGR innovatively proposes dynamic causal graph attention blocks and pattern reproduction guided prediction blocks to predict the future patterns. Compared with the existing methods, the former captures dynamic unidirectional information flow by using causal graph structure at different periods to provide a real representation of variable relationships. The latter completes a reliable mapping of historical patterns to the future based on the prior knowledge of pattern reproduction. Furthermore, Diff-MGR proposes a novel noise prediction network that can effectively capture dependencies in predicted future patterns and generate probability distributions of future sequences using a conditional diffusion model. Extensive experiments on several real datasets verify the effectiveness of Diff-MGR&#39;s components, and show it outperforms existing models in probabilistic forecasting performance.},
  archive      = {J_ISCI},
  author       = {Tianlong Zhao and Guangle Song and Xuemei Li and Lizhen Cui and Caiming Zhang},
  doi          = {10.1016/j.ins.2024.120742},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120742},
  shortjournal = {Inf. Sci.},
  title        = {Diff-MGR: Dynamic causal graph attention and pattern reproduction guided diffusion model for multivariate time series probabilistic forecasting},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy-driven image enhancement via ABR-fractal-fractional
differentiation. <em>ISCI</em>, <em>675</em>, 120741. (<a
href="https://doi.org/10.1016/j.ins.2024.120741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-light images often suffer from low sharpness and low contrast, hindering their visual quality and the performance of computer vision systems. To address this issue, we propose a novel image enhancement algorithm that combines local detail enhancement and global contrast enhancement. Our algorithm first transforms the crisp image into an intuitionistic fuzzy image. Next, we construct a global adaptive brightness transformation membership function to generate the first enhanced image. The second enhanced image is obtained using a newly proposed fractal-fractional differential operator. Finally, an image fusion technique is employed to effectively extract image features and integrate the locally and globally enhanced images. Our proposed technique effectively enhances the quality of low-light images while preserving their unique characteristics. Experimental results demonstrate that our method achieves comparable or even superior performance compared to state-of-the-art approaches, both qualitatively and quantitatively.},
  archive      = {J_ISCI},
  author       = {N. Ramesh Babu and A. Sam Joshua and P. Balasubramaniam and Ankita Tiwari},
  doi          = {10.1016/j.ins.2024.120741},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120741},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy-driven image enhancement via ABR-fractal-fractional differentiation},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Direct integration bias-compensated maximum correntropy
criterion algorithm independent of measurement noise samples.
<em>ISCI</em>, <em>675</em>, 120740. (<a
href="https://doi.org/10.1016/j.ins.2024.120740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In system identification, if the filter input and the desired signal are both interfered by noise, traditional adaptive filtering algorithms will not work effectively. The recently presented bias-compensated normalized maximum correntropy criterion (BC-NMCC) algorithm, which was developed based on the information theory learning (ITL) and Taylor expansion, can deal with this case. However, it needs to use measurement noise samples to update the adaptive filter weight vector, whose values are usually unavailable. To solve this problem, we propose a direct integration bias-compensated maximum correntropy criterion (DI-BC-MCC) algorithm under an unbiasedness criterion (UC). Specifically, we utilize a direct integral approach to calculate the expected values instead of using Taylor expansion. With this idea, the update equation of DI-BC-MCC does not involve measurement noise samples, unlike BC-NMCC. The derived compensation term can reduce the impact of input noise significantly, and DI-BC-MCC can perform well in impulsive noise environments. In addition, the steady-state performance of DI-BC-MCC is analyzed under some frequently used assumptions. Finally, simulations are provided to demonstrate the good performance of DI-BC-MCC and to verify the accuracy of the theoretical analysis.},
  archive      = {J_ISCI},
  author       = {Qin Song and Jingen Ni},
  doi          = {10.1016/j.ins.2024.120740},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120740},
  shortjournal = {Inf. Sci.},
  title        = {Direct integration bias-compensated maximum correntropy criterion algorithm independent of measurement noise samples},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024e). Controlling estimation error in reinforcement learning via
reinforced operation. <em>ISCI</em>, <em>675</em>, 120736. (<a
href="https://doi.org/10.1016/j.ins.2024.120736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Value-based and Actor-Critic reinforcement learning (RL) methods, both inaccuracy and instability of value estimation will detrimentally affect their performance. Some typical RL methods, such as Maxmin Q-learning and QMD3, are plagued by the underestimation problem while failing to trade off the estimation bias and variance jointly. We propose the Reinforced Operation (RO) to address these shortcomings, which selects the closest median among multiple Q-function. RO is applicable to any model-free RL method. Theoretically, we introduce the Mean Square Error (MSE) to jointly analyze the estimation bias and variance of value estimation methods. We also demonstrate the superiority of RO in MSE reduction and give an upper bound for the estimation bias of value estimation methods with arbitrary distribution to guide the calculation of the estimation bias of value estimation methods. Based on RO, we propose the variants of Q-learning and TD3, Reinforced Q-learning (RQ) and Reinforced Delayed Deep Deterministic policy gradient (RD3), respectively, to tackle different tasks. We empirically demonstrate that our method can reduce estimation error and achieve superior performance on discrete and continuous benchmark tasks.},
  archive      = {J_ISCI},
  author       = {Yujia Zhang and Lin Li and Wei Wei and Xiu You and Jiye Liang},
  doi          = {10.1016/j.ins.2024.120736},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120736},
  shortjournal = {Inf. Sci.},
  title        = {Controlling estimation error in reinforcement learning via reinforced operation},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rough set theory-based group incremental approach to feature
selection. <em>ISCI</em>, <em>675</em>, 120733. (<a
href="https://doi.org/10.1016/j.ins.2024.120733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection in a dynamic learning system often encounters challenges from sample variation. Incremental selection techniques using rough set theory (RST) address this challenge, to a certain degree, but two issues remain: (1) high redundancy and (2) low efficiency in processing high-dimensional datasets. To address these issues and further improve feature selection, we develop triple nested equivalence class (TNEC) RST for a group incremental approach to feature selection. In particular, we construct a group TNEC to enable universe-reduction learning to help consistently filter out inconsequential samples and incrementally update dependencies. Furthermore, with TNEC-based incremental partitioning, we develop a novel dependency computing technique to reduce redundant features and avoid repeated learning. We conducted experimental verification using 18 dynamic datasets, including ultra-high-dimensional datasets. Tests on five incremental datasets from each of the 18 original datasets validated that the group TNEC approach significantly outperformed the state-of-the-art methods in terms of classification efficiency, selection accuracy, feature significance, and suitability for ultra-high-dimensional data. In both incremental and static feature selection cases, the TNEC approach extended the ability of evolutionary and other types of heuristic learning algorithms in handling sample variations.},
  archive      = {J_ISCI},
  author       = {Jie Zhao and Dai-yang Wu and Yong-xin Zhou and Jia-ming Liang and WenHong Wei and Yun Li},
  doi          = {10.1016/j.ins.2024.120733},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120733},
  shortjournal = {Inf. Sci.},
  title        = {Rough set theory-based group incremental approach to feature selection},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). End-to-end multi-perspective multimodal posts relevance
score reasoning prediction. <em>ISCI</em>, <em>675</em>, 120727. (<a
href="https://doi.org/10.1016/j.ins.2024.120727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the surge in students sharing insights on online platforms, evaluating discussion forum posts has emerged as a significant research focus. This assessment is crucial for both students and educators, as it enables teachers to efficiently gauge student comprehension and helps students tailor their learning approaches to suit their individual needs, thereby fostering personalized growth. However, existing research on post-quality assessment faces challenges: 1) They overlook multimodal information interaction between post and topic, leading to inaccurate evaluations. 2) They are usually classification tasks that fail to provide feedback on the minor and relative differences between posts on the same topic. 3) They are usually evaluated using a single perspective, which is insufficient for capturing the complexity of the relationship between post and topic. Based on the above challenges, we propose a new assessment task, Multimodal Topic-Post Relevance Score Prediction (MTRSP), which analyzes whether a student&#39;s post comprehensively answers the question of the discussion topic by combining text and images to predict topic-post relevance scores, i.e., the degree of correctness of the answer. We develop an end-to-end Multi-perspective Topic-Post Relevance Score Reasoning (MTRSR) Method to solve the MTRSP Task, which leverages images and text from both the post and topic to infer topic-post relevance scores based on semantic similarity and logical coherence. Specifically, the topic-post content relevance reasoning module uses multimodal fusion to learn the semantic similarity of posts and topics. The logical coherence inference module examines the logical connections between posts and topics. Finally, we use three newly collected multimodal topic-post datasets and the public dataset Lazada-Home as an evaluation benchmark for the MTRSP task. Experimental results show that our MTRSR method can bring up to 9.02% in the NDCG@3 (Normalized Discounted Cumulative Gain) metric compared to the best-performing text-only model. The source code and dataset will be made public.},
  archive      = {J_ISCI},
  author       = {Xiaoxu Guo and Han Cao and Siyan Liang},
  doi          = {10.1016/j.ins.2024.120727},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120727},
  shortjournal = {Inf. Sci.},
  title        = {End-to-end multi-perspective multimodal posts relevance score reasoning prediction},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Important-data-based attack design and resilient remote
estimation for recurrent neural networks. <em>ISCI</em>, <em>675</em>,
120723. (<a href="https://doi.org/10.1016/j.ins.2024.120723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an attack-defense framework is proposed for the remote H ∞ H∞ state estimation of delayed recurrent neural networks (RNNs). Firstly, an important-data-based (IDB) attack strategy is constructed, which can identify the important packets that play essential roles in the estimation and selectively attack them based on their importance degree from the perspective of the attackers. By targeting the important packets, larger attack damages can be achieved. Then, a resilient state estimator that can resist IDB attacks is developed from the defenders&#39; point of view. Notably, some unrealistic assumptions (e.g., the attacker knowing the system structure and full parameters, the defender knowing the attack rate/parameters) are removed, which makes the proposed method easy to implement. At last, simulation results are presented to show the larger destructive effect of the constructed IDB attack and the efficiency of the proposed resilient H ∞ H∞ state estimator.},
  archive      = {J_ISCI},
  author       = {Xia Zhao and Xun Wang and Jiancun Wu and Hongtian Chen and Engang Tian},
  doi          = {10.1016/j.ins.2024.120723},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120723},
  shortjournal = {Inf. Sci.},
  title        = {Important-data-based attack design and resilient remote estimation for recurrent neural networks},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DPGazeSynth: Enhancing eye-tracking virtual reality privacy
with differentially private data synthesis. <em>ISCI</em>, <em>675</em>,
120720. (<a href="https://doi.org/10.1016/j.ins.2024.120720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As spatial computing devices increasingly integrate eye-tracking technology to enhance virtual reality (VR) experiences, the imperative to protect sensitive eye-tracking data against privacy risks, such as user re-identification, has become more pressing. Existing privacy-preserving mechanisms face challenges in balancing the dual demands of privacy and utility in the context of VR applications. This paper presents DPGazeSynth , a novel framework designed to fortify privacy protections while ensuring the utility of eye-tracking data. DPGazeSynth addresses the unique requirements of gaze path synthesis, especially the differentiation between fixations and saccades. Our approach introduces a semi-synthetic method based on the Markov Chain model to accurately maintain data correlations for analytical tasks. We demonstrate that DPGazeSynth provides robust differential privacy guarantees, and our comprehensive experiments on two real-world datasets validate its effectiveness in safeguarding against re-identification attacks. The results showcase DPGazeSynth &#39;s better performance over existing solutions like Kal ε ido and establish its potential as a reliable foundation for future research aimed at reconciling privacy concerns with the demands of complex trajectory data analysis in eye-tracking applications.},
  archive      = {J_ISCI},
  author       = {Xiaojun Ren and Jiluan Fan and Ning Xu and Shaowei Wang and Changyu Dong and Zikai Wen},
  doi          = {10.1016/j.ins.2024.120720},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120720},
  shortjournal = {Inf. Sci.},
  title        = {DPGazeSynth: Enhancing eye-tracking virtual reality privacy with differentially private data synthesis},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Hierarchical classification with exponential weighting of
multi-granularity paths. <em>ISCI</em>, <em>675</em>, 120715. (<a
href="https://doi.org/10.1016/j.ins.2024.120715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For hierarchical classification tasks, label relationships can be represented as a hierarchical structure ranging from coarse-grained to fine-grained. Existing hierarchical classifications typically employ a top-down classification approach, which leads to significant inter-level error propagation. Moreover, none of the existing approaches consider the impact of the path weights of different classes on the classification. In this paper, we propose a Hierarchical Classification method with Exponential Weighting of Multi-granularity Paths (HCEWMP), which combines path weights and hierarchical structure to propose a new hierarchical classification framework. Firstly, HCEWMP decomposes the datasets from coarse-grained to fine-grained based on the hierarchical structure and assigns weights to paths by the data distribution. Secondly, two different weighting strategies, probability weighting, and exponential weighting, are considered to calculate the probability of each class. Thirdly, the fine-grained top k classes are selected based on the probability descending order. Finally, HCEWMP obtains the best-predicted class using a random forest classifier. Compared with eight different algorithms on seven datasets, our experimental results demonstrate that the proposed method is effective in addressing the inter-level error propagation problem. The exponential weighting strategy has superior results among the two strategies, further indicating the significance of path weighting in hierarchical classification.},
  archive      = {J_ISCI},
  author       = {Yibin Wang and Qing Zhu and Yusheng Cheng},
  doi          = {10.1016/j.ins.2024.120715},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120715},
  shortjournal = {Inf. Sci.},
  title        = {Hierarchical classification with exponential weighting of multi-granularity paths},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerating page loads via streamlining JavaScript engine
for distributed learning. <em>ISCI</em>, <em>675</em>, 120713. (<a
href="https://doi.org/10.1016/j.ins.2024.120713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed learning based on JavaScript-based frontends is typically implemented at the endpoint to maximize performance. Yet, JavaScript-based frontends often experience suboptimal performance. To reconcile these disparities in performance between EDGE and endpoint deployments, strategic optimization is essential, particularly for preserving privacy in distributed learning. Real-time streaming optimizations are imperative to align the performance of disparate components for smooth integration. The reliance on JavaScript for various web functionalities can lead to increased resource consumption and slower page loads. Thus, we introduce a streamlined JavaScript engine designed to optimize structural patterns in JavaScript code, with three key enhancements. Firstly, we reduce the computational burden of the JavaScript engine necessary for setting up the browser&#39;s runtime environment. Secondly, we refine the parsing process for specific code patterns, boosting the efficiency of our lightweight engine. Thirdly, we streamline the Inter-Process Communication (IPC) to maintain high performance, even with limited memory resources. Our evaluations demonstrate that our approach reduces the median Total Computation Time (TCT) by 45.2%, and surpasses existing leading solutions, Siploader and Prepack, with improvements ranging from 1.13× to 1.39×.},
  archive      = {J_ISCI},
  author       = {Chen Liang and Guoyu Wang and Ning Li and Zuo Wang and Weihong Zeng and Fu-an Xiao and Yu-an Tan and Yuanzhang Li},
  doi          = {10.1016/j.ins.2024.120713},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120713},
  shortjournal = {Inf. Sci.},
  title        = {Accelerating page loads via streamlining JavaScript engine for distributed learning},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distillation enhanced time series forecasting network with
momentum contrastive learning. <em>ISCI</em>, <em>675</em>, 120712. (<a
href="https://doi.org/10.1016/j.ins.2024.120712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive representation learning is crucial in time series analysis as it alleviates the issue of data noise and incompleteness as well as sparsity of supervision signal. However, existing contrastive learning frameworks usually focus on intra-temporal features, which fail to fully exploit the intricate nature of time series data. To address this issue, we propose DE-TSMCL, an innovative distillation enhanced framework for long sequence time series forecasting. Specifically, we design a learnable data augmentation mechanism which adaptively learns whether to mask a timestamp to obtain optimized sub-sequences. Then, we propose a contrastive learning task with momentum update to explore inter-sample and intra-temporal correlations of time series to learn the underlying structure feature on the unlabeled time series. Meanwhile, we design a supervised task to learn more robust representations and facilitate the contrastive learning process. Finally, we jointly optimize the above two tasks. By developing model loss from multiple tasks, we can learn effective representations for downstream forecasting task. Extensive experiments, in comparison with state-of-the-arts, well demonstrate the effectiveness of DE-TSMCL, where the maximum improvement can reach to 27.3%. Source code for the algorithm is available at https://github.com/gaohaozhi/DE-TSMCL .},
  archive      = {J_ISCI},
  author       = {Haozhi Gao and Qianqian Ren and Jinbao Li},
  doi          = {10.1016/j.ins.2024.120712},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120712},
  shortjournal = {Inf. Sci.},
  title        = {Distillation enhanced time series forecasting network with momentum contrastive learning},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel intervention effect-based quadratic time-varying
nonlinear discrete grey model for forecasting carbon emissions
intensity. <em>ISCI</em>, <em>675</em>, 120711. (<a
href="https://doi.org/10.1016/j.ins.2024.120711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of severe global warming, accurately exploring the trend of carbon emissions intensity (CEI) changes is of great significance for mitigating climate change issues. The implementation of China&#39;s Carbon Emissions Trading Scheme (ETS) in 2013 is a policy intervention aimed at influencing CEI. The impact of intervention events makes forecasting a complex problem, which poses significant challenges to the construction of forecasting models. We first develop a quadratic time-varying nonlinear discrete grey model (QDNDGM(1,1)) to assess the intervention effect of the ETS policy. Then, a novel intervention effect-based quadratic time-varying nonlinear discrete grey model (IE-QDNDGM(1,1)) is developed to conduct the prediction under intervention effect, including an intervention term. The Whale Optimization Algorithm (WOA) is used to calculate a nonlinear parameter. We assess the intervention effect of the ETS policy in China and find that it can indeed reduce CEI. We verify the IE-QDNDGM(1,1) model’s superiority by comparing its predictive performance with that of three grey models, one statistical technique, and one artificial intelligence model. The comparative study shows the proposed model’s excellent fitting and prediction performance. An ablation experiment is conducted to validate the design of the IE-QDNDGM(1,1) model. Policy implications of the ETS intervention effect are discussed.},
  archive      = {J_ISCI},
  author       = {Li Ye and Liping Fang and Yaoguo Dang and Junjie Wang},
  doi          = {10.1016/j.ins.2024.120711},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120711},
  shortjournal = {Inf. Sci.},
  title        = {A novel intervention effect-based quadratic time-varying nonlinear discrete grey model for forecasting carbon emissions intensity},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Secure state estimation with disturbance rejection against
switched sparse sensor attacks. <em>ISCI</em>, <em>675</em>, 120709. (<a
href="https://doi.org/10.1016/j.ins.2024.120709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the issue of secure state estimation for cyber-physical systems vulnerable to sparse sensor attacks, where attackers might change their attack targets at any time to deteriorate the estimation performance. To address this issue, a Luenberger-like observer is designed to estimate the system state under the attack interference, which employs an improved projection operator and the least square method to handle the switched attacks and introduces a disturbance estimator to enhance the anti-disturbance capability. It is proven that the observation error system can achieve asymptotic stability and dissipative performance, even under the influence of switched sensor attacks and disturbances. Different from the existing results, this method can not only defend against more erratic attacks but also effectively reject disturbances. The conclusion presented is validated through simulation experiments.},
  archive      = {J_ISCI},
  author       = {Qingdong Sun and Guang-Hong Yang and Georgi Marko Dimirovski},
  doi          = {10.1016/j.ins.2024.120709},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120709},
  shortjournal = {Inf. Sci.},
  title        = {Secure state estimation with disturbance rejection against switched sparse sensor attacks},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the limitations of adversarial training for robust image
classification with convolutional neural networks. <em>ISCI</em>,
<em>675</em>, 120703. (<a
href="https://doi.org/10.1016/j.ins.2024.120703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial Training has proved to be an effective training paradigm to enforce robustness against adversarial examples in modern neural network architectures. Despite many efforts, explanations of the foundational principles underpinning the effectiveness of Adversarial Training are limited and far from being widely accepted by the Deep Learning community. Moreover, very few research works investigated the limitations of robust Convolutional Neural Networks beyond the well-known accuracy drop on natural images. In this paper, we describe surprising properties of these models, shedding light on mechanisms through which robustness against adversarial attacks is implemented. We also highlight limitations and failure modes that were not discussed in prior works. Through extensive analyses on a wide range of architectures and datasets, we empirically demonstrate that adversarially-trained Convolutional Neural Networks do not exploit efficiently the model capacity and that the simplicity biases induced by Adversarial Training may lead to undesired behaviors.},
  archive      = {J_ISCI},
  author       = {Mattia Carletti and Alberto Sinigaglia and Matteo Terzi and Gian Antonio Susto},
  doi          = {10.1016/j.ins.2024.120703},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120703},
  shortjournal = {Inf. Sci.},
  title        = {On the limitations of adversarial training for robust image classification with convolutional neural networks},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An information entropy-based fuzzy stochastic configuration
network for robust data modeling. <em>ISCI</em>, <em>675</em>, 120689.
(<a href="https://doi.org/10.1016/j.ins.2024.120689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data-driven modeling, the generalization performance of a neural network based on the minimum mean square error criterion may be affected when the samples contain noise. To handle uncertain data modeling problems, this study contributes a novel robust data modeling method called information entropy-based fuzzy stochastic configuration networks (IEFSCNs), which incorporates the maximum correntropy criterion (MCC) to reflect the squared error of the training sample set and uses the quantized minimum error entropy (QMEE) criterion to mine the distribution structure of the modeling data and suppress outlier data. Fuzzy systems are designed to generate nodes in the fuzzy transformation layer. A nonlinear enhancement layer is established as a hidden layer to enhance the representational capacity of the target system. The fuzzy transformation and nonlinear enhancement layers are fully connected to determine the outputs of the IEFSCNs. In addition, an incremental parameter learning algorithm is developed based on a supervision mechanism for optimizing the cost function, and its convergence property is demonstrated. Owing to the superiorities of the cost function by synthesizing MCC and QMEE, IEFSCNs can improve the modeling accuracy and reduce noise suppression. The performances are evaluated using various regression and classification tasks. Compared with existing methods, including SCNs, RVFL, F-SCNs, RSC-KDE, RSC-MCC, and SM-RSC, the proposed method demonstrates an effective robust modeling performance by reducing network structure redundancy while enhancing its ability to suppress noisy data.},
  archive      = {J_ISCI},
  author       = {Degang Wang and Fei Teng and Jie Li and Wenyan Song and Hongxing Li},
  doi          = {10.1016/j.ins.2024.120689},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120689},
  shortjournal = {Inf. Sci.},
  title        = {An information entropy-based fuzzy stochastic configuration network for robust data modeling},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An autoencoder-based self-supervised learning for multimodal
sentiment analysis. <em>ISCI</em>, <em>675</em>, 120682. (<a
href="https://doi.org/10.1016/j.ins.2024.120682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning is a crucial and challenging task within multimodal sentiment analysis. Effective multimodal sentiment representations contain two key aspects: consistency and difference. However, the state-of-the-art multimodal sentiment analysis approaches failed to capture the difference and consistency of sentiment information across diverse modalities. To address the multimodal sentiment representation problem, we propose an autoencoder-based self-supervised learning framework. In the pre-training stage, an autoencoder is designed for each modality, leveraging unlabeled data to learn richer sentiment representations for each modality through sample reconstruction and modality consistency detection tasks. In the fine-tuning stage, the pre-trained autoencoder is injected into MulT (AE-MT) and enhance the model&#39;s ability to extract deep sentiment information by incorporating a contrastive learning auxiliary task. Our experiments on the popular Chinese sentiment analysis benchmark (CH-SIMS v2.0) and English sentiment analysis benchmark (MOSEI) demonstrate significant gains over baseline models.},
  archive      = {J_ISCI},
  author       = {Wenjun Feng and Xin Wang and Donglin Cao and Dazhen Lin},
  doi          = {10.1016/j.ins.2024.120682},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120682},
  shortjournal = {Inf. Sci.},
  title        = {An autoencoder-based self-supervised learning for multimodal sentiment analysis},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent event-based lip reading word classification with
spiking neural networks using spatio-temporal attention features and
triplet loss. <em>ISCI</em>, <em>675</em>, 120660. (<a
href="https://doi.org/10.1016/j.ins.2024.120660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lip reading is a visual alternative to enhance the intelligence of traditional speech recognition, which can benefit from retina-like event cameras that focus on dynamic movements. Spiking Neural Networks (SNNs) are inherently well-suited to cooperate with event cameras. However, employing SNN for event-based lip reading presents significant challenges, particularly in effectively extracting spatio-temporal features from input events and distinguishing between phonetically similar elements. To address these challenges, this paper proposes a novel event-based lip-reading model that leverages the SNN framework, enriched by a designed Spatial-Temporal Attention Block (STAB) and a triplet loss. Specifically, STAB comprises both spatial and temporal attention branches, dynamically emphasizing those spatial and temporal characteristics most reflective of lip movements. STAB also includes a fusion mechanism to integrate these spatial and temporal insights, providing a comprehensive and focused representation of lip movements. In addition, we enhance the model by incorporating triplet loss into the SNN training process, further improving the model&#39;s ability to distinguish between visually similar words. Experimental results show the superior performance of our SNN and validate the effect of STAB and triplet loss. We also conduct the energy consumption analysis to affirm the model&#39;s energy efficiency.},
  archive      = {J_ISCI},
  author       = {Qianhui Liu and Meng Ge and Haizhou Li},
  doi          = {10.1016/j.ins.2024.120660},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120660},
  shortjournal = {Inf. Sci.},
  title        = {Intelligent event-based lip reading word classification with spiking neural networks using spatio-temporal attention features and triplet loss},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MVQS: Robust multi-view instance-level cost-sensitive
learning method for imbalanced data classification. <em>ISCI</em>,
<em>675</em>, 120467. (<a
href="https://doi.org/10.1016/j.ins.2024.120467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view imbalanced learning is to handle the datasets with multi-view representations and imbalanced classes. Existing multi-view imbalanced learning methods can be divided into two main categories: multi-view ensemble learning and multi-view cost-sensitive learning. However, these methods suffer from the following problems: 1) neglecting either consensus or complementary information, 2) complex preprocessing and information fusion in multi-view ensemble learning and manual assignment of misclassification costs in multi-view cost-sensitive learning, and 3) limited ability to handle noisy samples. Therefore, we aim to design a concise and unified framework to grapple with the multi-view representations, imbalanced classes and noisy samples simultaneously. Inspired by the merits of support vector machine (SVM) and quadratic type squared error (QTSE) loss function, we propose a robust multi-view instance-level cost-sensitive SVM with QTSE loss (MVQS) for imbalanced data classification. The consensus regularization term and combination weight strategy are employed to fully exploit multi-view information. The QTSE loss can adaptively impose instance-level penalties to the misclassification of samples, and make MVQS be robust to noisy samples. We solve MVQS with the alternating direction method of multipliers (ADMM) and the gradient descent (GD) algorithm. Comprehensive experiments validate that MVQS is more competitive and robust than other benchmark approaches.},
  archive      = {J_ISCI},
  author       = {Zhaojie Hou and Jingjing Tang and Yan Li and Saiji Fu and Yingjie Tian},
  doi          = {10.1016/j.ins.2024.120467},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120467},
  shortjournal = {Inf. Sci.},
  title        = {MVQS: Robust multi-view instance-level cost-sensitive learning method for imbalanced data classification},
  volume       = {675},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A dynamic dual-trust network-based consensus model for
individual non-cooperative behaviour management in group
decision-making. <em>ISCI</em>, <em>674</em>, 120750. (<a
href="https://doi.org/10.1016/j.ins.2024.120750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In group decision-making, trust relationships are the basis of interactions among decision makers (DMs) and play an important role in maintaining cooperation. However, DMs from different backgrounds may use the trust relationship to influence the opinion adjustment of other individuals and adopt non-cooperative behaviours, which will also consume trust among DMs, both of which are ignored by extant consensus models. To explore the mutual influence of trust relationships, consensus processes, and non-cooperative behaviour, a consensus model for individual non-cooperative behaviour management in group decision-making under a dynamic dual-trust network is proposed. First, to represent the trust relationship among DMs in a more realistic way, a dynamic dual-trust network based on familiarity-based trust and similarity-based trust is developed. This approach can comprehensively model the interpersonal relationship and opinion similarity among DMs, while dynamically updating according to their interactions. Second, a minimum adjustment consensus model based on a dual-trust relationship is proposed. This model can provide adjustment suggestions to DMs to retain initial opinions as much as possible while considering the impact of trust relationships on opinion adjustments. Subsequently, a non-cooperative behaviour management method based on non-cooperative willingness and trust risk is designed to classify the behaviour of DMs and then adjust their trust relationship and weight accordingly. Subsequently, an illustrative example is provided to demonstrate the effectiveness of the proposed method. Finally, the validity of the model is verified through a simulation and comparative analysis.},
  archive      = {J_ISCI},
  author       = {Zhengmin Liu and Wenxin Wang and Xiaohan Zhang and Peide Liu},
  doi          = {10.1016/j.ins.2024.120750},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120750},
  shortjournal = {Inf. Sci.},
  title        = {A dynamic dual-trust network-based consensus model for individual non-cooperative behaviour management in group decision-making},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view fair-augmentation contrastive graph clustering
with reliable pseudo-labels. <em>ISCI</em>, <em>674</em>, 120739. (<a
href="https://doi.org/10.1016/j.ins.2024.120739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive clustering (GCC) has achieved numerous advantageous results due to the information mining capability of self-supervised learning. Multi-view attribute graph clustering, as a means of addressing complex attribute graph data with multi-view relations or features, has gained significant attention in recent years. However, only a few GCC methods are applicable to multi-view graph data, limiting the full utilization of the rich information contained in such data. Furthermore, most GCC methods rely on random augmentation strategies, leading to structural unfairness in the augmentation process across views. To address these issues, we propose multi-view fair-augmentation contrastive graph clustering with reliable pseudo-labels (MFCGC), which combines contrastive learning and fully utilizes the node-level and cluster-level information within each view of the multi-view data, ensuring the consistency of information across different views. Moreover, we designed a carefully crafted node-degree-based augmentation method called fair augmentation, which preserves the partial topology structure of multi-view data. Finally, we propose a reliable pseudo-label selection mechanism that integrates reliable pseudo-labels from multi-view graph to improve the quality of sample pairs. Our proposed MFCGC has been extensively evaluated on real-world datasets, demonstrating its superiority over state-of-the-art algorithms in two categories of multi-view graph data and attesting to its significant effectiveness.},
  archive      = {J_ISCI},
  author       = {Shaochen Yang and Zhaorun Liao and Runyu Chen and Yuren Lai and Wei Xu},
  doi          = {10.1016/j.ins.2024.120739},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120739},
  shortjournal = {Inf. Sci.},
  title        = {Multi-view fair-augmentation contrastive graph clustering with reliable pseudo-labels},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An industrial IoT-based deformation resistance prediction
and thickness control method of cold-rolled strip in steel production
systems. <em>ISCI</em>, <em>674</em>, 120735. (<a
href="https://doi.org/10.1016/j.ins.2024.120735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different from traditional analytical and numerical simulation methods, data-driven methods can more effectively describe the effects of nonlinear and coupling factors. Although the fluctuations of deformation resistance and thickness for hot-rolled strips significantly influence the thickness accuracy in strip cold rolling, the traditional deformation resistance prediction model and thickness control mode don&#39;t involve that. Thus, based on the Industrial Internet of Things (IIOT) platform and data-driven technology, this work proposed a new method for deformation resistance prediction and a new mode of feed-forward control for strip thickness. IIOT platform can collect production data from the various levels to provide a complete data set. The deformation resistance prediction model is established by adopting the differential evolutionary algorithm to optimize the bi-directional long and short-term memory network. In addition, the feed-forward control (DFFC) strategy for strip thickness is proposed based on deformation resistance prediction. An application results of a 1420 mm production line of CR indicated that the established prediction model could provide a high accuracy prediction for deformation resistance, and compared to traditional thickness gauges-based automatic gauge control methods, the DDFC can capture the effect of the fluctuations of deformation resistance and thickness for the hot-rolled strip to improve thickness accuracy effectively.},
  archive      = {J_ISCI},
  author       = {Jingdong Li and Jianwei Zhao and Xiaochen Wang and Haotang Qie and Quan Yang and Zhonghui Wang and Zedong Wu},
  doi          = {10.1016/j.ins.2024.120735},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120735},
  shortjournal = {Inf. Sci.},
  title        = {An industrial IoT-based deformation resistance prediction and thickness control method of cold-rolled strip in steel production systems},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Classic distance join queries using compact data structures.
<em>ISCI</em>, <em>674</em>, 120732. (<a
href="https://doi.org/10.1016/j.ins.2024.120732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance-based Join Queries ( DJQ s) have multiple applications in spatial databases, Geographic Information Systems, and other areas. The K Closest Pairs Query ( K CPQ) and the ε Distance Join Query ( ε DJQ) are well-known DJQs that have been widely studied and can be solved using plane-sweep techniques, which are efficient but must keep the whole datasets in main memory. In this work, we propose DJQ algorithms that work with data represented using a k 2 k2 -tree, a compact data structure for binary grids. Our algorithms solve K CPQ and ε DJQ queries, as well as several window-constrained variants, taking advantage of the indexing capabilities of k 2 k2 -trees to efficiently answer queries without the need to decompress the data. Our experimental evaluation with large datasets shows that k 2 k2 -tree algorithms are up to 5 times faster than plane-sweep algorithms in K CPQ, and 5–30 times faster in ε DJQ. In variants that are window-constrained, our algorithms are competitive in most scenarios and faster for large windows. Additionally, our algorithms are not very affected by the distribution of the data and yield much more predictable query times, showing up to 30 times smaller variance in query times than plane sweep, depending on the location of the query window.},
  archive      = {J_ISCI},
  author       = {Guillermo de Bernardo and Miguel R. Penabad and Antonio Corral and Nieves R. Brisaboa},
  doi          = {10.1016/j.ins.2024.120732},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120732},
  shortjournal = {Inf. Sci.},
  title        = {Classic distance join queries using compact data structures},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GB-DBSCAN: A fast granular-ball based DBSCAN clustering
algorithm. <em>ISCI</em>, <em>674</em>, 120731. (<a
href="https://doi.org/10.1016/j.ins.2024.120731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density-Based Spatial Clustering of Applications with Noise (DBSCAN) identifies high-density connected areas as clusters, so that it has advantages in discovering arbitrary-shaped clusters. However, it has difficulty in adjusting parameters and since it needs to scan all data points in turn, its time complexity is O ( n 2 ) O(n2) . Granular-ball (GB) is a coarse grained representation of data. It is on the basis of the assumption that an object and its local neighbors have similar distribution and they have high possibility of belonging to the same class. It has been introduced into supervised learning by Xia et al. to improve the efficiency of supervised learning. Inspired by the idea of granular-ball, we introduce it into unsupervised learning and use it to improve the efficiency of DBSCAN, called GB-DBSCAN. The main idea of the proposed algorithm GB-DBSCAN is to employ granular-ball to represent a set of data points and then clustering on granular-balls, instead of the data points. Firstly, we use k-nearest neighbors (KNN) to generate granular-balls, which is a bottom-up strategy, and describe granular-balls according to their centers and radius. Then, the granular-balls are divided into Core-GBs and Non-Core-GBs according to their density. After that, the Core-GBs are merged into clusters according to the idea of DBSCAN and the Non-Core-GBs are assigned to the appropriate clusters. Since the granular-balls&#39; number is much smaller than the size of the objects in a dataset, the running time of DBSCAN is greatly reduced. By comparing with KNN-BLOCK DBSCAN, RNN-DBSCAN, DBSCAN, K-means, DP and SNN-DPC algorithms, the proposed algorithm can get similar or even better clustering result in much less running time.},
  archive      = {J_ISCI},
  author       = {Dongdong Cheng and Cheng Zhang and Ya Li and Shuyin Xia and Guoyin Wang and Jinlong Huang and Sulan Zhang and Jiang Xie},
  doi          = {10.1016/j.ins.2024.120731},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120731},
  shortjournal = {Inf. Sci.},
  title        = {GB-DBSCAN: A fast granular-ball based DBSCAN clustering algorithm},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SCSQ: A sample cooperation optimization method with sample
quality for recurrent neural networks. <em>ISCI</em>, <em>674</em>,
120730. (<a href="https://doi.org/10.1016/j.ins.2024.120730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting holds significant value across various application scenarios. However, practical implementations often encounter challenges related to low-quality time series data resulting from system failures or external interference. Unfortunately, existing forecasting methods primarily focus on optimizing model architecture for accurate predictions and overlook the importance of addressing data quality issues. In this paper, we propose optimizing data utilization to enhance model performance based on data quality and introduce the Sample Cooperation with Sample Quality (SCSQ) method to facilitate recurrent neural networks training. Firstly, we define sample quality as the matching degree between samples and model, and suggest using the attention entropy to calculate the sample quality through an attention mechanism. Secondly, we optimize the model&#39;s gradient vector based on sample quality. To address optimization training involving samples of different qualities effectively, we propose a more reasonable objective function within our proposed sample gradient conflict optimization module and devise a novel algorithm leveraging approximation techniques along with ADMM algorithm implementation. Through experiments conducted on six datasets, the results demonstrate that SCSQ significantly improves LSTM&#39;s performance. In certain cases, it even surpasses the state-of-the-art models. Additionally, SCSQ enhances the anti-interference ability of LSTM against low-quality samples.},
  archive      = {J_ISCI},
  author       = {Feihu Huang and Jince Wang and Peiyu Yi and Jian Peng and Xi Xiong and Yun Liu},
  doi          = {10.1016/j.ins.2024.120730},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120730},
  shortjournal = {Inf. Sci.},
  title        = {SCSQ: A sample cooperation optimization method with sample quality for recurrent neural networks},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Green, resilient, and inclusive supplier selection using
enhanced BWM-TOPSIS with scenario-varying z-numbers and reversed
PageRank. <em>ISCI</em>, <em>674</em>, 120728. (<a
href="https://doi.org/10.1016/j.ins.2024.120728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Firms need a reliable decision-making framework to select suppliers who are Green, Resilient, and embrace Inclusive Development (GRID). However, GRID supplier selection is challenged by events that are uncertain and often dependent. Such events affect supplier rankings in a fuzzy decision environment. This paper builds a GRID-based criteria system and applies an enhanced Best Worst Method (BWM) and Technique for Order Preferencing using the Similarity to the Ideal Solution (TOPSIS), with Scenario-Varying Z-numbers (SVZs) and reversed PageRank. The decision criteria are extracted from the literature and confirmed by expert judgement. The SVZs and SVZ Preference Relations (SVZPRs) are developed by combining the Concept of Stratification Theory (CST) with Z-numbers, to reflect the impact of Dependent Uncertain Events (DUEs). Reverse PageRank is then used to find the occurrence probability of the scenarios due to DUEs. BWM is applied in an SVZPR environment to obtain the weights of the decision criteria. TOPSIS, incorporating SVZs, is used to rank the suppliers. An example is used to highlight the enhanced BWM-TOPSIS, to find the priority ranking of the GRID weights. Comparative and sensitivity analyses are conducted to validate the proposed method.},
  archive      = {J_ISCI},
  author       = {Xu Zhang and Mark Goh and Sijun Bai and Qun Wang},
  doi          = {10.1016/j.ins.2024.120728},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120728},
  shortjournal = {Inf. Sci.},
  title        = {Green, resilient, and inclusive supplier selection using enhanced BWM-TOPSIS with scenario-varying Z-numbers and reversed PageRank},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel cost-sensitive three-way intuitionistic fuzzy large
margin classifier. <em>ISCI</em>, <em>674</em>, 120726. (<a
href="https://doi.org/10.1016/j.ins.2024.120726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision (3WD) has been widely applied in diverse fields in tackling uncertainty, particularly in classification domain. As a discriminative learning algorithm, Large Margin Distribution Machine (LDM) aims to maximize the inter-class margin by leveraging the marginal distribution of samples, which captures the underlying structure and achieves superior classification performance. However, existing LDMs still suffer from some inherent flaws, including: i) the neglect of fuzzy decision items, leading to the inadequate handling of uncertainty; ii) the utilization of a cost-insensitive mechanism, resulting in high misclassification costs; and iii) the disregard of sample credibility, contributing to the noise susceptibility. To address these limitations, we introduce the intuitionistic fuzzy (IF) and cost-sensitive 3WD (CS3WD), presenting an innovative model known as the CS3W-IFLMC model. The IF theory is employed to quantify sample confidence levels, augmenting noise suppression in our proposed model. Moreover, the integration of the CS3WD method effectively reduces the overall decision cost and further improves the handling of uncertainty in datasets. Consequently, the CS3W-IFLMC model demonstrates superior noise resilience and generalization performance. Our comparative experiments validate the efficacy of the proposed CS3W-IFLMC model in achieving robustness to noise while upholding a competitive classification performance.},
  archive      = {J_ISCI},
  author       = {Shuangyi Fan and Heng Li and Cong Guo and Dun Liu and Libo Zhang},
  doi          = {10.1016/j.ins.2024.120726},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120726},
  shortjournal = {Inf. Sci.},
  title        = {A novel cost-sensitive three-way intuitionistic fuzzy large margin classifier},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unifying credal partitions and fuzzy orthopartitions.
<em>ISCI</em>, <em>674</em>, 120725. (<a
href="https://doi.org/10.1016/j.ins.2024.120725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on fuzzy orthopartitions and credal partitions, which are distinct mathematical models representing partitions where the membership of elements to classes is only partially known. Firstly, we show that fuzzy orthopartitions and credal partitions are special cases of generalized fuzzy orthopartitions, which we introduce in this article as a new structure for modelling partitions with uncertainty. Next, we examine the connections between credal partitions and fuzzy orthopartitions, considering that both can be seen as types of fuzzy partitions (in particular, we deal with fuzzy probabilistic and Ruspini partitions). Moreover, we find that each generalized fuzzy orthopartition corresponds to a collection of zero, one, or infinitely many credal partitions; conversely, a credal partition maps to at most one generalized fuzzy orthopartition. Finally, we identify the class of all credal partitions that coincide with fuzzy orthopartitions.},
  archive      = {J_ISCI},
  author       = {Stefania Boffa and Davide Ciucci},
  doi          = {10.1016/j.ins.2024.120725},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120725},
  shortjournal = {Inf. Sci.},
  title        = {Unifying credal partitions and fuzzy orthopartitions},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A clustering-based resampling technique with cluster
StructureAnalysis for software defect detection in imbalanced datasets.
<em>ISCI</em>, <em>674</em>, 120724. (<a
href="https://doi.org/10.1016/j.ins.2024.120724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software defect detection focuses on the automatic identification of flaws in software modules. Given the great importance of the problem, numerous researchers have introduced a rich collection of deep learning approaches to confront it. However, the datasets that are used to train the proposed classifiers are in most cases highly imbalanced, leading to models that cannot learn the minority classes effectively, while being biased towards the majority class. The state-of-the-art solutions either overlook the issue of data imbalance, or they confront it insufficiently by ignoring the existence of outliers and the local properties of the classes&#39; distributions. In this work we introduce CBR, a Clustering-Based Resampling technique for mitigating the problem of class imbalance in software defect detection tasks. The proposed method initially employs a quite simple heuristic to determine the maximum distance threshold between two clusters. Then, it uses this threshold to apply hierarchical clustering with the aim of grouping together similar samples. CBR considers the singleton clusters as outliers, and discards the ones originating from the majority class. The algorithm subsequently organizes the clusters into sub-clusters than contain samples from the same class and determines which sub-clusters should participate in the oversampling process. In this way, CBR produces samples of improved quality and variance. We evaluated the performance of CBR against 9 baseline and state-of-the-art techniques by using 27 datasets and a Multilayer Perceptron classifier. The results demonstrate the superiority of CBR in terms of Balanced Accuracy and Precision scores.},
  archive      = {J_ISCI},
  author       = {Leonidas Akritidis and Panayiotis Bozanis},
  doi          = {10.1016/j.ins.2024.120724},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120724},
  shortjournal = {Inf. Sci.},
  title        = {A clustering-based resampling technique with cluster StructureAnalysis for software defect detection in imbalanced datasets},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A method of predicting and managing public opinion on social
media: An agent-based simulation. <em>ISCI</em>, <em>674</em>, 120722.
(<a href="https://doi.org/10.1016/j.ins.2024.120722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In current opinion dynamics models for predicting public opinion, the spread of events within social media has been inadequately considered, resulting in suboptimal prediction performance and inefficient strategies for public opinion management. This deficiency is particularly consequential for governments and enterprises, as adverse public opinions associated with them can inflict significant harm. This study develops a link prediction-based opinion dynamics (LPOD) model to address this gap in predicting and managing public opinion. The proposed model integrates insights from epidemiology, specifically the susceptible-infected-recovered model, to characterize the spread of events. The LPOD model enhances the updating process of relationships and opinions by redesigning the link and opinion prediction methods. Subsequently, a link-recommendation-based management approach is formulated to manage public opinion effectively. Experimental results reveal that, compared to existing models, the proposed model elevates opinion prediction accuracy from 0.81 to 0.92 and link prediction accuracy from 0.60 to 0.70. In terms of public opinion management efficacy, when compared to conventional methods such as managing opinion leaders and introducing particular nodes in social networks, the developed approach demonstrates a 20% and 18% increase in success rates, respectively. Furthermore, validation through simulations and real-world scenarios robustly confirms the model&#39;s versatile applicability and effectiveness.},
  archive      = {J_ISCI},
  author       = {Guo-Rui Yang and Xueqing Wang and Ru-Xi Ding and Jin-Tao Cai and Jingjun (David) Xu and Enrique Herrera-Viedma},
  doi          = {10.1016/j.ins.2024.120722},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120722},
  shortjournal = {Inf. Sci.},
  title        = {A method of predicting and managing public opinion on social media: An agent-based simulation},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weighted three-way conflict analysis in multi-attribute
decision-making perspective. <em>ISCI</em>, <em>674</em>, 120721. (<a
href="https://doi.org/10.1016/j.ins.2024.120721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real life, multiple issues may have different weights in leading to conflicts. Some of the existing conflict analysis literature related to weight does not involve an explicit weight method, and some use common methods such as entropy weight method. This paper aims to design a reasonable weighting method for the inherent characteristics of conflict analysis. The main motivation is that the issues getting vast majority of support (or opposition) are assumed to be more likely to cause intense conflicts. Firstly, a novel weighting method using N -bounded symmetric concave reciprocal function is brought in. Some properties of the method such as duality, objectivity and symmetry are discussed. Then, by embedding the weights into the existing distance function a weighted three-way conflict analysis model is proposed. Next the thresholds of conflict, alliance and neutrality relations are given by decision-theoretic rough set theory. In addition, as a main characteristic of the model, the conflict distance between any two agents is determined by the overall conflict table rather than their own. Finally, the model of this paper is compared with the existing conflict analysis weight model. At the same time, a comparative simulation experiment was carried out on the weight change and the number of maximal coalitions. The new weighted conflict model proposed in this paper can effectively compensate for the limitations of existing weighted models, especially in three-valued information systems and multi-valued information systems. It can also theoretically expand the field of three-way conflict analysis.},
  archive      = {J_ISCI},
  author       = {Jia Luo and Banghe Han and Biao Huang and Shengling Geng},
  doi          = {10.1016/j.ins.2024.120721},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120721},
  shortjournal = {Inf. Sci.},
  title        = {Weighted three-way conflict analysis in multi-attribute decision-making perspective},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-stage direction-guided evolutionary algorithm for
large-scale multiobjective optimization. <em>ISCI</em>, <em>674</em>,
120719. (<a href="https://doi.org/10.1016/j.ins.2024.120719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale multiobjective optimization problems (LSMOPs) have exponential growth in the search space as the decision variables increase, and the vast search space poses a challenge to the performance of multiobjective evolutionary algorithms (MOEAs). Many current large-scale MOEAs need to consume a large amount of computational resources to get good performance. This paper proposes a two-stage direction-guided evolutionary algorithm for large-scale multiobjective optimization (LMOEA-S2D) to balance the performance and computational resource overhead. The algorithm exploits the Pareto-optimality property of domination and the diversity-preserving property of decomposition to optimize the performance in the two stages, respectively, and designs a corresponding direction-guided mechanism to improve search efficiency. LMOEA-S2D designs global direction search and local direction search in the domination-based stage for efficient exploitation to accelerate population convergence. To promote greater population diversity, a hybrid direction search was devised to aid diversity exploration in the decomposition-based stage, and this facilitates even distribution of candidate solutions across the Pareto optimal frontier. LMOEA-S2D is compared with five state-of-the-art large-scale MOEAs on some large-scale multiobjective test suites with 100 to 5,000 decision variables. The experimental results show that LMOEA-S2D significantly outperformed all compared algorithms under limited computational resources.},
  archive      = {J_ISCI},
  author       = {Juan Zou and Li Tang and Yuan Liu and Shengxiang Yang and Shiting Wang},
  doi          = {10.1016/j.ins.2024.120719},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120719},
  shortjournal = {Inf. Sci.},
  title        = {A two-stage direction-guided evolutionary algorithm for large-scale multiobjective optimization},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Dynamic event-triggered-based adaptive fuzzy optimized
control for slowly switched nonlinear system with intermittent state
constrains. <em>ISCI</em>, <em>674</em>, 120717. (<a
href="https://doi.org/10.1016/j.ins.2024.120717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel fuzzy event-triggered optimized strategy for slowly switched nonlinear system using reinforcement learning technique. For addressing intermittent state constraints problem, some improved shifting functions and barrier functions are designed in the adaptive backstepping process. Subsequently, by designing global performance functions with the discount term, the corresponding Hamilton-Jacobi-Bellman equation is derived and the optimal solution can be obtained under critic-actor structure. Different from the existing event-triggered methods, a novel dynamic event-triggered scheme for subsystem is developed, which not only saves communication resources, but also solves the mismatch behaviour between controller and subsystem without restriction on maximum asynchronous intervals and the number of switch within a triggering interval. Furthermore, by using modified average cycle dwell time method and Lyapunov stability theorem, all signals of system are proved to be bounded. Eventually, numerical simulation results validate the superiority of the proposed approach, and this new scheme is applied to single-link robotic manipulator.},
  archive      = {J_ISCI},
  author       = {Jing Zhang and Chengyuan Yan and Jianwei Xia and Hao Shen and Xiangpeng Xie},
  doi          = {10.1016/j.ins.2024.120717},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120717},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic event-triggered-based adaptive fuzzy optimized control for slowly switched nonlinear system with intermittent state constrains},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bridging pre-trained models to continual learning: A
hypernetwork based framework with parameter-efficient fine-tuning
techniques. <em>ISCI</em>, <em>674</em>, 120710. (<a
href="https://doi.org/10.1016/j.ins.2024.120710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern techniques of pre-training and fine-tuning have significantly improved the performance of models on downstream tasks. However, this improvement faces challenges when pre-trained models encounter the necessity to adapt sequentially to multiple downstream tasks within the context of continuously shifting training data. In this study, we aim to leverage the general capabilities of pre-trained models for knowledge sharing across different tasks while endow them with the capability for continuous learning. To this end, we propose a Hypernetwork-based Parameter Efficient Fine-Tuning (HyperPEFT) framework. Utilizing a pre-trained Vision Transformer (ViT) as the backbone, HyperPEFT is capable of incorporating various PEFT techniques, enabling the pre-trained ViT to adapt to diverse downstream tasks. The core of our method lies in the application of hypernetworks, which efficiently encapsulate task-specific information, significantly reducing task interference and fortifying the model against catastrophic forgetting. The adoption PEFT techniques allows for precise adjustments to the pre-trained models, enhancing their performance for each specific task. Moreover, this strategy employs a shared hypernetwork to make task-specific adjustments, thereby facilitating knowledge sharing across different tasks for pre-trained models. The extensive experiments reveal that our method effectively mitigates catastrophic forgetting, outperforms comparison methods, and uncovers latent associations among tasks. Overall, this study introduces a unified strategy that synergistically blends the general capabilities of pre-trained models with the necessary adaptability for continual learning scenarios.},
  archive      = {J_ISCI},
  author       = {Fengqian Ding and Chen Xu and Han Liu and Bin Zhou and Hongchao Zhou},
  doi          = {10.1016/j.ins.2024.120710},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120710},
  shortjournal = {Inf. Sci.},
  title        = {Bridging pre-trained models to continual learning: A hypernetwork based framework with parameter-efficient fine-tuning techniques},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Observer-based fuzzy tracking control of nonlinear systems
with intermittent output constraints. <em>ISCI</em>, <em>674</em>,
120708. (<a href="https://doi.org/10.1016/j.ins.2024.120708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper pays attention to the output tracking control problem of nonlinear systems where the output is uniquely measurable and subject to an intermittent constraint. A multiplicative transformation based on the shifting-replaying function is introduced together with barrier Lyapunov function to solve the intermittent output constraint. A state observer independent of the matching condition of control gains is designed via the non-uniform state transformation to relax the assumption of full-state measurability. By virtue of the estimated states, we propose an output feedback controller that only involves one fuzzy adaptive parameter to restrain the effect of unknown system nonlinearities. Through Lyapunov stability analysis, it is proved that the proposed controller can make all signals in the closed-loop system remain semi-globally uniformly ultimately bounded. Two simulation examples are provided to verify the effectiveness of the proposed method, and also the superiority over the existing ones.},
  archive      = {J_ISCI},
  author       = {Chen-Liang Zhang and Ge Guo},
  doi          = {10.1016/j.ins.2024.120708},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120708},
  shortjournal = {Inf. Sci.},
  title        = {Observer-based fuzzy tracking control of nonlinear systems with intermittent output constraints},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A quantum group decision model for meteorological disaster
emergency response based on d-s evidence theory and choquet integral.
<em>ISCI</em>, <em>674</em>, 120707. (<a
href="https://doi.org/10.1016/j.ins.2024.120707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In addressing complex and dynamic meteorological disaster decision-making environment, the traditional multi-attribute group decision-making domain model is often unable to effectively deal with the correlation between attributes and the mutual influence of group opinions. To overcome this challenge, this paper proposes a novel quantum framework for group decision-making, which is used to deal with the emergency situation of meteorological disaster. The model initially characterizes attribute correlations using 2-additive Choquet integrals and employs Dempster-Shafer evidence theory to both integrate information and ascertain attribute weights, and decision makers&#39; weights are calculated based on grey relative correlation. On this basis, a quantum-like Bayesian network is developed to capture the interference among decision-makers&#39; opinions. The alternatives are ranked by quantum probabilities computed based on Bayesian principle. Finally, a case study on meteorological disaster emergency scenario assessment is conducted to validate the proposed model&#39;s effectiveness and superiority. Additionally, its stability and practicality are confirmed through sensitivity analysis and comparative analysis.},
  archive      = {J_ISCI},
  author       = {Shuli Yan and Yizhao Xu and Zaiwu Gong and Enrique Herrera-Viedma},
  doi          = {10.1016/j.ins.2024.120707},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120707},
  shortjournal = {Inf. Sci.},
  title        = {A quantum group decision model for meteorological disaster emergency response based on D-S evidence theory and choquet integral},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A multi-view representation learning framework for
commonsense knowledge bases. <em>ISCI</em>, <em>674</em>, 120704. (<a
href="https://doi.org/10.1016/j.ins.2024.120704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Commonsense knowledge bases play an essential role in a wide range of natural language processing tasks. This paper studies the problem of representation learning for commonsense knowledge bases to effectively incorporate their knowledge into numerical models. Most existing knowledge base representation learning methods are difficult to apply to commonsense knowledge bases since they are much sparser than general knowledge bases. Hence, in this paper, we propose a novel method for commonsense knowledge base representation learning. Specifically, we first model the nodes from multiple views, including word/phase information, context information, and graph information. Then, we design a scoring function to measure whether the commonsense triplets are established through relation representation learning. We conduct extensive experiments on two tasks and the results show that our proposed model outperforms other knowledge base representation learning methods.},
  archive      = {J_ISCI},
  author       = {Weiyan Zhang and Chuang Chen and Tao Chen and Jingping Liu and Qi Ye and Tong Ruan},
  doi          = {10.1016/j.ins.2024.120704},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120704},
  shortjournal = {Inf. Sci.},
  title        = {A multi-view representation learning framework for commonsense knowledge bases},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Instance redistribution-based label integration for
crowdsourcing. <em>ISCI</em>, <em>674</em>, 120702. (<a
href="https://doi.org/10.1016/j.ins.2024.120702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing provides an inexpensive solution to employ crowd workers labeling instances, and hence each instance is labeled with a multiple noisy label set instead of its true label. Label integration aims to infer a true label from its multiple noisy label set. However, existing fine-tuned methods increase the model complexity while enhancing the performance of label integration. Therefore, it is a challenge to search for a simple but efficient label integration method. Meeting this challenge, this paper proposes instance redistribution-based label integration (IRLI), a novel method for label integration. Firstly, from the label view, we estimate the probability of an instance belonging to each class based on its multiple noisy label set and obtain a multiple noisy label distribution vector. Secondly, from the attribute view, we reestimate the probability of an instance belonging to each class based on its attribute set and obtain an instance redistribution vector. Finally, we combine the multiple noisy label distribution vector and the instance redistribution vector of each instance to infer its integrated label. Comprehensive experimental results on both simulated and real-world crowdsourced datasets validate the superiority of IRLI.},
  archive      = {J_ISCI},
  author       = {Yao Zhang and Liangxiao Jiang and Chaoqun Li},
  doi          = {10.1016/j.ins.2024.120702},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120702},
  shortjournal = {Inf. Sci.},
  title        = {Instance redistribution-based label integration for crowdsourcing},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time asynchronous control for semi-markov jump
systems with random uncertainties and actuator faults. <em>ISCI</em>,
<em>674</em>, 120701. (<a
href="https://doi.org/10.1016/j.ins.2024.120701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is aimed at studying the finite-time reliable asynchronous control issue for continuous semi-Markov jump systems (S-MJSs) with actuator failures and randomly occurring uncertainties (ROUs). To characterize the asynchronous phenomenon between the system mode and the controller mode, the mode detector approach via a hidden semi-Markov model (HSM) is adopted. The transition probability (TP) matrix of the HSM is nonhomogeneous, which can be provided by a polytopic structure. By resorting the mode-dependent Lyapunov function, sufficient conditions are attained to guarantee the stochastic finite-time boundedness (SFTB) and H ∞ H∞ performance of the closed-loop system. Then, according to a skillful matrix inequality transforming method, the reliable asynchronous control law is constructed. Finally, a tunnel diode circuit system and a mass-spring-damper mechanical system are proposed to demonstrate the superiority, effectiveness and practicality of the developed design method.},
  archive      = {J_ISCI},
  author       = {Meng-Jie Hu and Ju H. Park and Jun Cheng},
  doi          = {10.1016/j.ins.2024.120701},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120701},
  shortjournal = {Inf. Sci.},
  title        = {Finite-time asynchronous control for semi-markov jump systems with random uncertainties and actuator faults},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging cascading information for community detection in
social networks. <em>ISCI</em>, <em>674</em>, 120696. (<a
href="https://doi.org/10.1016/j.ins.2024.120696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information exchange among individuals is one of the key factors leading to formation of modular structures in social networks, often referred as communities. In this paper, we devise a novel information diffusion based approach to leverage the latent information exchange among the individuals for identifying communities. Designed an algorithm called PraSar, which has mainly two phases namely seeding and unification. In seeding phase, closely connected groups of nodes called seed communities are identified by analyzing the cascades obtained during information diffusion. In unification phase, the external connections of seed communities are reduced by unifying two or more seed communities. Involvement of cascade that are formed during the diffusion process enables PraSar to operate locally and giving an overall complexity of O ( n 2 ) . The theoretical foundation of the proposed approach is established by various theorems. Empirical results on diverse real world datasets are evident for the effectiveness and competitiveness of the PraSar algorithm over state-of-the-art community detection algorithms.},
  archive      = {J_ISCI},
  author       = {Soumita Das and Ravi Kishore Devarapalli and Anupam Biswas},
  doi          = {10.1016/j.ins.2024.120696},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120696},
  shortjournal = {Inf. Sci.},
  title        = {Leveraging cascading information for community detection in social networks},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient privacy-preserving outsourced k-means clustering
on distributed data. <em>ISCI</em>, <em>674</em>, 120687. (<a
href="https://doi.org/10.1016/j.ins.2024.120687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, more and more data is collected and stored by different organizations. When the data is distributed among multiple users who wish to perform data mining on the joint data, outsourcing the task to cloud servers becomes an attractive solution for users who lack professional skills. However, privacy concerns make users reluctant to adopt such solutions. In this paper, we propose a privacy-preserving outsourced k -means clustering (PPOKC) algorithm on distributed data. Our system consists of multiple users and two non-colluding servers. Each user submits their data to the servers, which perform k -means clustering over the joint data without compromising data privacy. Unlike existing solutions, which typically include a cryptographic server and a computing server, each server in our system provides both services. Based on this architecture, we first design several important sub-protocols, including secure comparison, secure minimum and secure division. We then use these protocols to construct an efficient and highly secure PPOKC algorithm. The implementation of our algorithm relies heavily on secret sharing techniques, complemented by homomorphic encryption. We also conduct theoretical analysis and experiments. Security analysis shows that our scheme guarantees the security of the input/output data, the intermediate results and the data access pattern under the semi-honest model. Complexity analysis and numerical experiments show that our algorithm has good efficiency and is suitable for practical applications.},
  archive      = {J_ISCI},
  author       = {Guowei Qiu and Yingliang Zhao and Xiaolin Gui},
  doi          = {10.1016/j.ins.2024.120687},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120687},
  shortjournal = {Inf. Sci.},
  title        = {Efficient privacy-preserving outsourced k-means clustering on distributed data},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Customizing graph neural networks using path reweighting.
<em>ISCI</em>, <em>674</em>, 120681. (<a
href="https://doi.org/10.1016/j.ins.2024.120681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have been extensively used for mining graph-structured data with impressive performance. However, because these traditional GNNs do not distinguish among various downstream tasks, embeddings embedded by them are not always effective. Intuitively, paths in a graph imply different semantics for different downstream tasks. Inspired by this, we design a novel GNN solution, namely Customized Graph Neural Network with Path Reweighting (CustomGNN for short). Specifically, the proposed CustomGNN can automatically learn the high-level semantics for specific downstream tasks to highlight semantically relevant paths as well to filter out task-irrelevant noises in a graph. Furthermore, we empirically analyze the semantics learned by CustomGNN and demonstrate its ability to avoid the three inherent problems in traditional GNNs, i.e., over-smoothing, poor robustness, and overfitting. In experiments with the node classification task, CustomGNN achieves state-of-the-art accuracies on three standard graph datasets and four large graph datasets. The source code of the proposed CustomGNN is available at https://github.com/cjpcool/CustomGNN .},
  archive      = {J_ISCI},
  author       = {Jianpeng Chen and Yujing Wang and Ming Zeng and Zongyi Xiang and Bitan Hou and Yunhai Tong and Ole J. Mengshoel and Yazhou Ren},
  doi          = {10.1016/j.ins.2024.120681},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120681},
  shortjournal = {Inf. Sci.},
  title        = {Customizing graph neural networks using path reweighting},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-association evidential feature selection and its
application to identifying schizophrenia. <em>ISCI</em>, <em>674</em>,
120647. (<a href="https://doi.org/10.1016/j.ins.2024.120647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Granular Computing (GrC)-based feature selection can remove redundant features from a massive amount of data and improve the efficiency of information processing. However, the existing method of neighborhood-based information granule only considers the distance between samples, ignoring other significant relationships existing between them. To fill this gap, this paper proposes a novel feature selection approach based on two-step multi-association neighborhood evidence entropy. This approach is constructed in three phases. Firstly, adaptive k value corresponding to each sample in sparse representation method is determined. Sparse correlation and distance measure are fused to form a multi-association information granule. Then, the samples in the multi-association information granule are estimated and weak-related information is removed to constitute a two-step multi-association information granule. Secondly, sparse correlation information is processed using Dempster-Shafer evidence theory, and a new credibility-based function is developed. In addition, the credibility is used to construct a novel neighborhood evidence entropy, which can effectively reflect the uncertainty of data. Thirdly, the proposed neighborhood evidence entropy is applied to assess the importance of features. As a result, several vital features are selected. The experimental results on twelve datasets demonstrate that the effectiveness of the proposed method is superior to other algorithms in construction of information granules and classification accuracy, respectively. Finally, the proposed method is applied to the selection of brain regions in schizophrenia. It can effectively analyze the lesions of schizophrenia and improve the prediction of the disorder. The code is available at https://github.com/fxx-Aurora/TMAE-FS/tree/main.},
  archive      = {J_ISCI},
  author       = {Hengrong Ju and Xiaoxue Fan and Weiping Ding and Jiashuang Huang and Witold Pedrycz and Xibei Yang},
  doi          = {10.1016/j.ins.2024.120647},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120647},
  shortjournal = {Inf. Sci.},
  title        = {Multi-association evidential feature selection and its application to identifying schizophrenia},
  volume       = {674},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cascaded maximum median-margin discriminant projection with
its application to face recognition. <em>ISCI</em>, <em>673</em>,
120734. (<a href="https://doi.org/10.1016/j.ins.2024.120734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel method called cascaded maximum median-margin discriminant projection (CMMDP) for robust face recognition. Initially, we introduce the maximum median-margin discriminant projection (MMDP) method, which aims to maximize the distances between class medians and their inter-class neighbors, while simultaneously minimizing the distances between class medians and their intra-class samples. To extract features at multiple levels, we extend the MMDP method to its deep version, known as CMMDP. The CMMDP algorithm incorporates the MMDP technique to learn multistage filter banks specifically designed for facial images. Afterward, we utilize straightforward binary hashing techniques for efficient indexing, along with block histograms for effective feature pooling. The CMMDP model is simple and easy to train, while taking full account of the global and local structure of the samples by maximizing the distances between samples that are dissimilar and minimizing the distances between samples that are similar after projection. This results in a low-dimensional data representation with better discriminative performance. We evaluate the performance of CMMDP on face datasets including AR, ORL, ExtYaleB and CMU PIE databases. The results indicate that CMMDP achieves superior performance than most advanced methods.},
  archive      = {J_ISCI},
  author       = {Pu Huang and Cheng Tong and Xuran Du and Zhangjing Yang},
  doi          = {10.1016/j.ins.2024.120734},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120734},
  shortjournal = {Inf. Sci.},
  title        = {Cascaded maximum median-margin discriminant projection with its application to face recognition},
  volume       = {673},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Three-way conflict analysis model under agent-agent mutual
selection environment. <em>ISCI</em>, <em>673</em>, 120718. (<a
href="https://doi.org/10.1016/j.ins.2024.120718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conflict analysis is an effective methodology for comprehensively analyzing conflicts. Utilizing Pawlak&#39;s rough set theory, the traditional conflict analysis model investigates the origins of conflict by evaluating agents&#39; positions on various issues and provides feasible solutions to resolve conflicts. However, it predominantly centers on the conflicts within a single agent set and fails to address the case of conflicts between two agent sets under mutual selection environment (called agent-agent mutual selection), which also frequently appears in the real world. Different from the traditional conflict analysis model, in agent-agent mutual selection, conflicts not only originate between two agents within a set due to their common preference but also originate between two agent sets due to their attitudes on a pairing strategy. Therefore, the issue of agent-agent mutual selection requires simultaneously considering the preference of two agent sets. To study this problem, we propose a three-way conflict analysis model to analyze agent-agent mutual selection. The model not only reveals the internal causes of conflicts between two agents in a set but also explores the degree of conflict between two sets of agents. A method to minimize the conflict between two sets of agents is also designed by maximizing the satisfaction degree (SD) of the valid pairing. Experiments indicate that the satisfaction degree (SD) derived from the agent-agent conflict analysis model exceeds that of the agent-issue conflict analysis model.},
  archive      = {J_ISCI},
  author       = {Hongxia Dou and Shen Li and Jinhai Li},
  doi          = {10.1016/j.ins.2024.120718},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120718},
  shortjournal = {Inf. Sci.},
  title        = {Three-way conflict analysis model under agent-agent mutual selection environment},
  volume       = {673},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bridging knowledge distillation gap for few-sample
unsupervised semantic segmentation. <em>ISCI</em>, <em>673</em>, 120714.
(<a href="https://doi.org/10.1016/j.ins.2024.120714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to privacy, security, and costly labeling of images, unsupervised semantic segmentation with very few samples has become a promising direction, but still remains unexplored. This inspires us to introduce the few-sample unsupervised semantic segmentation task, which is very challenging because generalizing the segmentation model from only a few unlabeled images is far from sufficient. We address this problem in the knowledge distillation perspective, by proposing a medium-sized auxiliary network as the bridge, which narrows down the semantic knowledge gap between teacher network (large) and student network (small). To this end, we develop the Knowledge Distillation Bridge (KDB) framework for few-sample unsupervised semantic segmentation. In particular, it consists of the teacher-auxiliary-student architecture, which adopts the block-wise distillation that encourages the auxiliary to imitate the teacher and the student to imitate the auxiliary. In this way, the knowledge gap between the source feature distribution and the target one is reduced, allowing the student with the smaller network to be readily deployed in highly-demanding environment. Meanwhile, each channel characterizes different semantics in feature map, which motivates us to distill the features of decoder in a channel-wise manner. Extensive experiments on two benchmarks including Pascal VOC2012 and Cityscapes demonstrate the promising performance of the proposed method, which strikes a good balance between precision and speed, e.g., it achieves the inference speed of 230 fps for a 512 × 512 512×512 image.},
  archive      = {J_ISCI},
  author       = {Ping Li and Junjie Chen and Chen Tang},
  doi          = {10.1016/j.ins.2024.120714},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120714},
  shortjournal = {Inf. Sci.},
  title        = {Bridging knowledge distillation gap for few-sample unsupervised semantic segmentation},
  volume       = {673},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A linguistic z-number-based sorting method for three-way
multi-criterion decision-making in ecological function zoning.
<em>ISCI</em>, <em>673</em>, 120706. (<a
href="https://doi.org/10.1016/j.ins.2024.120706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional multi-criterion decision-making methods can help decision-makers decide whether to accept or reject an alternative, but they cannot ensure these results fully meet decision-makers’ requirements. Three-way decision methods overcome this limitation by dividing alternatives into three regions. However, traditional three-way decision methods rarely considered the reliability of evaluation information and individual regrets under some criteria. Moreover, most weighting methods in three-way decisions ignored the influence of abnormal values. To fill the above gaps, this paper develops a linguistic Z-number-based sorting method combining the three-way decision with the gain and lost dominance score (GLDS) method that reflects individual regrets under some criteria. Firstly, to avoid individual regrets, we introduce the linguistic Z-number-based GLDS sorting (LZ-GLDS-Sort) method, which obtains two states of alternatives that will be used in the three-way decision. Linguistic Z-numbers can express linguistic evaluation and credibility. Two parameters are introduced in the LZ-GLDS-Sorting method to reflect the relative importance of evaluation information and credibility. Then, a three-way decision method is introduced to divide alternatives into three regions, in which the variation-coefficient weighting method is introduced to avoid the effect of abnormal values. Finally, the ecological function zoning as an example is provided to validate the applicability of this model.},
  archive      = {J_ISCI},
  author       = {Yue Xiao and Huchang Liao and Xiaowan Jin and Jianming Zhan},
  doi          = {10.1016/j.ins.2024.120706},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120706},
  shortjournal = {Inf. Sci.},
  title        = {A linguistic Z-number-based sorting method for three-way multi-criterion decision-making in ecological function zoning},
  volume       = {673},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A prior knowledge-guided distributionally robust
optimization-based adversarial training strategy for medical image
classification. <em>ISCI</em>, <em>673</em>, 120705. (<a
href="https://doi.org/10.1016/j.ins.2024.120705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image classification plays a vital role in computer vision applications within the field of healthcare and medicine, and deep neural network-based classifiers are continuously achieving new breakthroughs and demonstrating tremendous potential in medical imaging analysis. However, the lack of robustness in deep learning techniques makes it risky to apply these classifiers to the domain of healthcare. In addition, the existing adversarial training strategies and domain generation methods are difficult to generalize into the medical imaging field challenged by complex medical texture features. To address this issue, we propose a medical morphological knowledge-guided adversarial training strategy, by jointly considering the robustness against medical data distribution shifts and adversarial attacks from the view of distributionally robust optimization. First, we train a surrogate model with the augmented dataset by guided filtering for capturing model attention on medical morphological information. Next, we design a gradient normalization-based prior knowledge injection module to transfer the attention information learned by surrogate model to the main classifier. Finally, we design a distributionally robust a optimization-based training strategy to induce the main classifier to learn key diagnostic clues as well as enhance the robustness against adversarial attacks. To evaluate the effectiveness of the proposed methods, we perform experiments on two types of in-domain and out-of-domain medical image sets, which contain lung CT scan datasets and dermatoscopic image datasets. Comparative results show that the proposed training strategy achieves higher adversarial attack accuracy than all involved state-of-the-art adversarial training methods and domain generation methods. The code is available at https://github.com/sysu19351146/MMK-DRO.},
  archive      = {J_ISCI},
  author       = {Shancheng Jiang and Zehui Wu and Haiqiong Yang and Kun Xiang and Weiping Ding and Zhen-Song Chen},
  doi          = {10.1016/j.ins.2024.120705},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120705},
  shortjournal = {Inf. Sci.},
  title        = {A prior knowledge-guided distributionally robust optimization-based adversarial training strategy for medical image classification},
  volume       = {673},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decoupled differentiable graph neural architecture search.
<em>ISCI</em>, <em>673</em>, 120700. (<a
href="https://doi.org/10.1016/j.ins.2024.120700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The differentiable graph neural architecture search (GNAS) effectively designs graph neural networks (GNNs) efficiently and automatically with excellent performance based on different graph data distributions. Given a GNN search space containing multiple GNN component operation candidates, the differentiable GNAS method builds a mixed supernet using learnable architecture parameters multiplied by the GNN component operation candidates. When the mixed supernet completes optimization, the mixed supernet is pruned based on the best architecture parameters to efficiently identify the optimal GNN architecture in the GNN search space. However, the multiplicative relationship between the architecture parameters and the GNN component operation candidates introduces a coupled optimization bias into the weight optimization process of the mixed supernet GNN component operation candidates. This bias results in differentiable GNAS performance degradation. To solve the problem of coupled optimization bias in the previous differentiable GNAS method, we propose the D ecoupled D ifferentiable G raph N eural A rchitecture S earch (D 2 GNAS). It utilizes the Gumbel distribution as a bridge to decouple the weights optimization of supernet GNN component candidate operation and architecture parameters for constructing the decoupled differentiable GNN architecture sampler. The sampler is capable of selecting promising GNN architectures based on architecture parameters treated as sampling probabilities, and it is further optimized through the validation gradients derived from the sampled GNN architectures. Simultaneously, D 2 GNAS builds a single-path supernet with a pruning strategy to compress the supernet progressively to improve search efficiency further. We conduct extensive experiments on multiple benchmark graphs. The experimental findings demonstrate that D 2 GNAS outperforms all established baseline methods, both manual GNN and GNAS methods, in terms of performance. Additionally, D 2 GNAS has a lower time complexity than previous differentiable GNAS methods. Based on the fair GNN search space, it achieves an average 5x efficiency improvement. Codes are available at https://github.com/AutoMachine0/D2GNAS .},
  archive      = {J_ISCI},
  author       = {Jiamin Chen and Jianliang Gao and Zhenpeng Wu and Raeed Al-Sabri and Babatounde Moctard Oloulade},
  doi          = {10.1016/j.ins.2024.120700},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120700},
  shortjournal = {Inf. Sci.},
  title        = {Decoupled differentiable graph neural architecture search},
  volume       = {673},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aircraft type selection using fuzzy trigonometric based OPA
and RAFSI model. <em>ISCI</em>, <em>673</em>, 120688. (<a
href="https://doi.org/10.1016/j.ins.2024.120688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of numerous types of aircraft and their technical capabilities are offering a wide range of alternatives. As customers have different expectations, aircraft type selection is a business strategy for the airline companies. The choice on carriers should be made in accordance with disparate dimensions such as customers&#39; expectations, profit of the company, capacity limitations and market conditions. This study formulates aircraft type selection as a Multi Criteria Decision Making (MCDM) problem and proposes a novel model that incorporates fuzzy trigonometric norms to solve. Being differentiated from the existing models in the literature, a two-stage model is identified. In the first stage, a fuzzy trigonometric-based Ordinal Priority Approach (OPA) determines the criteria weights. In the second stage, RAFSI (Ranking of Alternatives through Functional Mapping of Criteria Subintervals into Single Intervals) is integrated to determine the optimal aircraft type. The model simulated for a case of Turkish Airline company. Sensitivity tests justify robustness of the model. Results show that among the four options, medium-scale high-qualified but not luxury aircraft is the best option.},
  archive      = {J_ISCI},
  author       = {Muhammet Deveci and Muharrem Enis Çiftçi and Mehtap Isik and Dragan Pamucar and Xin Wen and Tachia Chin and Seifedine Kadry},
  doi          = {10.1016/j.ins.2024.120688},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120688},
  shortjournal = {Inf. Sci.},
  title        = {Aircraft type selection using fuzzy trigonometric based OPA and RAFSI model},
  volume       = {673},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Multi-AUV underwater static target search method based on
consensus-based bundle algorithm and improved glasius bio-inspired
neural network. <em>ISCI</em>, <em>673</em>, 120684. (<a
href="https://doi.org/10.1016/j.ins.2024.120684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research introduces a hierarchical strategy for static target searches with multi-autonomous underwater vehicles (AUVs) to optimize cumulative search rewards. The approach comprises two primary elements: task allocation and path planning. A Voronoi diagram segments regions based on peak detection via a maximum filter in the task allocation stage. Then, a consensus-based bundling algorithm ensures the load-balanced distribution of peak sub-regions across AUVs, while a dynamic cooperation mechanism allows for dynamic adjustment of task allocation, thereby increasing the system&#39;s operational flexibility. Path planning employs an improved Glasius bio-inspired neural network, leveraging analogies to convolution processes and incorporating mean pooling, multiple convolutions, and resampling. This method enhances global information propagation and optimizes path point selection through a discounted reward function evaluating adjacent nodes, thus boosting the search efficiency of individual AUVs. Simulation experiments validate the method&#39;s effectiveness and robustness in multi-AUV static target searches, demonstrating its potential to improve search efficiency.},
  archive      = {J_ISCI},
  author       = {Yibing Li and Yujie Huang and Zili Zou and Qiang Yu and Zitang Zhang and Qian Sun},
  doi          = {10.1016/j.ins.2024.120684},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120684},
  shortjournal = {Inf. Sci.},
  title        = {Multi-AUV underwater static target search method based on consensus-based bundle algorithm and improved glasius bio-inspired neural network},
  volume       = {673},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prescribed-time fault-tolerant tracking control for markov
jump nonlinear systems based on saturation dynamics filters.
<em>ISCI</em>, <em>673</em>, 120683. (<a
href="https://doi.org/10.1016/j.ins.2024.120683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of prescribed-time fault-tolerant tracking control for a class of Markov jump nonlinear systems affected by actuator faults and input saturation. First, a new time-varying constraint function and an error transformation are invoked to transform the original prescribed-time tracking control problem into a tracking control problem with deferred constraint for tracking error. Furthermore, the parameter correction terms are designed, on which a novel Markov jump saturation dynamic filter is constructed to handle the unfavorable effect of input saturation. Meanwhile, the projection operator technique and the norm estimation methodology are integrated to devise adaptive laws to estimate the unknown actuator faults evolving in accordance with the Markov chain. A new prescribed-time fault-tolerant tracking control scheme is put forward that realizes the deferred constraint on the tracking error, which in turn ensures that the tracking error of the system converges to a prescribed accuracy within a prescribed-time. Finally, two simulation examples, one of which implements a prescribed-time fault-tolerant tracking control for rotary steerable drilling tool system, are presented to illustrate the effectiveness and practicality of the developed scheme.},
  archive      = {J_ISCI},
  author       = {Yongli Wei and Ming Gao and Li Sheng},
  doi          = {10.1016/j.ins.2024.120683},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120683},
  shortjournal = {Inf. Sci.},
  title        = {Prescribed-time fault-tolerant tracking control for markov jump nonlinear systems based on saturation dynamics filters},
  volume       = {673},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decentralized and performance-constrained state-estimated
fuzzy control for nonlinear differential-algebraic interconnected
systems. <em>ISCI</em>, <em>673</em>, 120666. (<a
href="https://doi.org/10.1016/j.ins.2024.120666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a decentralized and mixed performance-constrained state-estimated fuzzy control strategy designed for nonlinear differential-algebraic interconnected systems. Initially, the approach employs a Takagi-Sugeno (T-S) fuzzy model to approximate these complex systems. To address potential limitations within the interconnected systems, a Proportional-plus-Derivative (PD) state control method is integrated into the proposed control scheme. Additionally, an observer is constructed to estimate system states, enhancing the feasibility of the control method. System stability analysis is conducted using the free-weighing Lyapunov function approach, allowing designers to customize the weight matrix for desired control performance and facilitate controller design. Subsequently, a fuzzy controller is developed to ensure stability and meet both Passive- H ∞ H∞ Performance (PHP) and H 2 H2 Control Performance (HCP) criteria. Finally, the effectiveness of the proposed design approach is validated through simulation results.},
  archive      = {J_ISCI},
  author       = {Yi-Chen Lee and Che-Lun Su and Wen-Jer Chang},
  doi          = {10.1016/j.ins.2024.120666},
  journal      = {Information Sciences},
  month        = {7},
  pages        = {120666},
  shortjournal = {Inf. Sci.},
  title        = {Decentralized and performance-constrained state-estimated fuzzy control for nonlinear differential-algebraic interconnected systems},
  volume       = {673},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Information orientation-based modular type-2 fuzzy neural
network. <em>ISCI</em>, <em>672</em>, 120716. (<a
href="https://doi.org/10.1016/j.ins.2024.120716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Type-2 fuzzy neural networks (T2FNNs) have gained popularity due to their processing ability for high uncertainty. However, concerned with the high-dimensional problems of nonlinear systems, the interpretability of individual T2FNNs is weak due to the exponential growth of fuzzy rules. To deal with this problem, an information orientation-based modular T2FNN (IO-MT2FNN) is developed to improve its interpretability in this paper. First, an information entropy-based decomposition method is designed to divide the original input space into three sub-spaces, namely edge, local and global regions. Then, the information with different attributes is separated to provide an unambiguous interpretation. Second, the independent module describing these regions with type-2 fuzzy sets is embedded in the membership function layer of IO-MT2FNN to represent the coupling relationship between regional information in an interpretable way. Third, an information mapping strategy is introduced with low-order Gaussian kernel matrices, instead of a high-order mapping matrix, to extract the features from the allocated information in each module, which enables IO-MT2FNN to achieve a compact topology through dimensionality reduction. Finally, the simulations demonstrate that the proposed IO-MT2FNN can compete with the advanced approaches in terms of interpretability for the prediction of high-dimensional and complex systems.},
  archive      = {J_ISCI},
  author       = {Chenxuan Sun and Zheng Liu and Xiaolong Wu and Hongyan Yang and Honggui Han},
  doi          = {10.1016/j.ins.2024.120716},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120716},
  shortjournal = {Inf. Sci.},
  title        = {Information orientation-based modular type-2 fuzzy neural network},
  volume       = {672},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A MeanShift-guided oversampling with self-adaptive sizes for
imbalanced data classification. <em>ISCI</em>, <em>672</em>, 120699. (<a
href="https://doi.org/10.1016/j.ins.2024.120699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The imbalanced data classification has gained popularity in machine learning research domain due to its prevalence in numerous applications and its difficulty. However, the majority of contemporary work primarily focuses on addressing between-class imbalance issues. Previous researches have shown that combined with other elements, such as within-class imbalance, small sample size and the presence of small disjuncts, the imbalanced data significantly increase the difficulties for the traditional classifiers to learn. Therefore, we propose a novel MeanShift-guided oversampling with self-adaptive sizes for imbalanced data classification. The proposed MeanShift-guided oversampling technique can simultaneously consider the distribution of minority class and majority class within the sphere with the current minority instance as its center, which can favor addressing small sample size and avoiding overlapping issues often caused by the nearest neighbor (NN)-based oversampling techniques. The incorporation of random vector and flexible cut-off mechanism for vector length can enhance the diversity among the generated synthetic minority instances and avoid overlapping, which makes it suitable for small sample size and small disjuncts problems. To address between-class and within-class imbalance issues, we also introduce a self-adaptive sizes assignment strategy for each minority instance to be oversampled, where the assigned size is inversely proportional to its density and its distance from the majority class. In addition to eliminating within-class imbalance, the strategy can ensure that the informative border minority instances have more opportunities to be oversampled, thus improving classification performance. Extensive experimental results on some datasets with different distributions and imbalance ratios show the proposed algorithm outperforms other compared ones with significant difference.},
  archive      = {J_ISCI},
  author       = {Xinmin Tao and Xiaohan Zhang and Yujia Zheng and Lin Qi and Zhiting Fan and Shan Huang},
  doi          = {10.1016/j.ins.2024.120699},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120699},
  shortjournal = {Inf. Sci.},
  title        = {A MeanShift-guided oversampling with self-adaptive sizes for imbalanced data classification},
  volume       = {672},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024e). A general neural membrane computing model. <em>ISCI</em>,
<em>672</em>, 120686. (<a
href="https://doi.org/10.1016/j.ins.2024.120686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural P systems are a class of distributed parallel computing models inspired by the way neurons cooperate in biological neural networks. Artificial neural networks integrate biological neural networks with mathematical models, which have powerful information processing capabilities. This work adopts the structure and data processing method of neural networks and integrates them with membrane computing to improve the neural P systems in data processing. A general neural membrane computing (GNMC) model is developed to realize the flow and manipulation of data in the form of objects and rules in the neuron. Glial cells are introduced into the GNMC model at the cellular level to modulate the states of the connected neurons. The trigger conditions, the activation mechanisms and the dissolve-reconnect rules make the GNMC model more efficient in handling objects. The multiple objects and multiple topological structures enable the GNMC model to handle different practical problems. The Turing universality of the GNMC model is proved as number generating and accepting devices. Furthermore, a small universal GNMC model with 71 neurons, fewer than that of the existing state-of-the-art neural P systems, is constructed for computing functions.},
  archive      = {J_ISCI},
  author       = {Xiaoling Zhang and Xiyu Liu and Qianqian Ren and Minghe Sun and Yuzhen Zhao},
  doi          = {10.1016/j.ins.2024.120686},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120686},
  shortjournal = {Inf. Sci.},
  title        = {A general neural membrane computing model},
  volume       = {672},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Density peaks clustering based on superior nodes and fuzzy
correlation. <em>ISCI</em>, <em>672</em>, 120685. (<a
href="https://doi.org/10.1016/j.ins.2024.120685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Density Peaks Clustering (DPC) algorithm is simple and efficient, but still has a few limitations. For example, DPC needs manual selection of clustering centers and may miss the correct cluster when searching for denser nearest neighbors, which may cause incorrect allocation of data points. To address these limitations, this work proposes a novel density peaks clustering algorithm based on superior nodes and fuzzy correlation (DPC-SNFC). Reverse nearest neighbors are used first to find the nearest point with a higher density as the superior node. Fuzzy correlation is then applied to construct connectivity subgraphs without using clustering centers. The connectivity subgraphs can identify the different clusters. Extensive experiments are conducted using 12 synthetic datasets and 10 real datasets and using 6 state-of-the-art baseline algorithms. The experimental results show that the proposed DPC-SNFC algorithm outperforms the baseline algorithms, which validates its efficiency.},
  archive      = {J_ISCI},
  author       = {Wenke Zang and Xincheng Liu and Linlin Ma and Jing Che and Minghe Sun and Yuzhen Zhao and Xiyu Liu and Hui Li},
  doi          = {10.1016/j.ins.2024.120685},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120685},
  shortjournal = {Inf. Sci.},
  title        = {Density peaks clustering based on superior nodes and fuzzy correlation},
  volume       = {672},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An end-to-end knowledge graph solution to the frequent
itemset hiding problem. <em>ISCI</em>, <em>672</em>, 120680. (<a
href="https://doi.org/10.1016/j.ins.2024.120680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Frequent Itemset Hiding Problem (FIHP) constitutes a critical aspect of Privacy-Preserving Data Mining, aiming to protect sensitive information while extracting valuable patterns. Despite the ubiquity of Knowledge Graphs (KGs) in many domains, their integration with FIHP remains an underexplored research area. In this paper, we present a new solution to FIHP, leveraging graph-based algorithms and Community Detection. Our method employs the efficiency and structure of KGs to quickly locate what needs to be hidden in order to strategically conceal sensitive knowledge within the data, while ensuring the preservation of KG structure and utility. Through comprehensive evaluations on established FIHP datasets, we showcase the efficacy of our approach in terms of processing time and increased data privacy. The results imply that our proposed method holds promise for facilitating privacy-preserving KG analytics in real-world applications, particularly in scenarios involving substantial streaming data, where existing approaches encounter limitations.},
  archive      = {J_ISCI},
  author       = {Panteleimon Krasadakis and Giuseppe Futia and Vassilios S. Verykios and Evangelos Sakkopoulos},
  doi          = {10.1016/j.ins.2024.120680},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120680},
  shortjournal = {Inf. Sci.},
  title        = {An end-to-end knowledge graph solution to the frequent itemset hiding problem},
  volume       = {672},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reasoning on property graphs with graph generating
dependencies. <em>ISCI</em>, <em>672</em>, 120675. (<a
href="https://doi.org/10.1016/j.ins.2024.120675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data dependencies are a key concept in data management and have been researched in data integration, data quality and query optimization. With the increasing use of graph-structured data in diverse applications, there is also an increasing interest in the study of graph data dependencies. In this scenario, different classes of graph data dependencies have been proposed in the literature. In this work, we study the class of Graph Generating Dependencies (GGDs). Graph Generating Dependencies (GGDs) informally express constraints between two (possibly different) graph patterns which enforce relationships on both graph&#39;s data (via property value constraints) and its structure (via topological constraints). While most of previously proposed classes of graph data dependencies focus on generalizing equality-generating dependencies for graph data, Graph Generating Dependencies (GGDs) can express tuple- and equality-generating dependencies on property graphs, both of which find broad application in graph data management. Given this new class of dependency, in this paper, we discuss the reasoning behind GGDs on Property Graphs. We propose algorithms to solve three main reasoning problems: the satisfiability , implication , and validation problems for GGDs and analyze their complexity. By studying these problems, we can understand the expressiveness and the limitations of GGDs in practical applications. To demonstrate the practical use of GGDs, we propose an algorithm that finds inconsistencies in data through validation of GGDs. Our experiments show that even though the validation of GGDs has high computational complexity, GGDs can be used to find data inconsistencies in a feasible execution time on both synthetic and real-world data.},
  archive      = {J_ISCI},
  author       = {Larissa C. Shimomura and Nikolay Yakovets and George Fletcher},
  doi          = {10.1016/j.ins.2024.120675},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120675},
  shortjournal = {Inf. Sci.},
  title        = {Reasoning on property graphs with graph generating dependencies},
  volume       = {672},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable deep learning for sEMG-based similar gesture
recognition: A shapley-value-based solution. <em>ISCI</em>,
<em>672</em>, 120667. (<a
href="https://doi.org/10.1016/j.ins.2024.120667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface electromyography (sEMG) based gesture recognition shows promise in enhancing human-robot interaction. However, accurately recognizing similar gestures is a challenging task, and the underlying mechanisms of gesture recognition are not well understood. To address these issues, we developed a new solution called the Shapley-value-based similar gesture recognition (SV-SGR) method. Our solution combines deep learning and game theory to achieve high recognition accuracy and interpretability. First, we devised a data preprocessing method that converts sEMG signals into sEMG color images, which can be more effectively utilized by deep learning techniques. Next, we established a deep-neural-network-based model for gesture recognition using the processed sEMG color images. Then, we designed a global explanation approach based on Shapley values to quantify the contribution of each channel to recognizing similar gestures. Finally, we carried out an explanation analysis, which provides feedback on the recognition model to enhance the precision of gesture recognition. Extensive comparisons and interpretable analyses have been conducted on real-world datasets, and the results demonstrate that the SV-SGR method outperforms other baselines under various experimental conditions. The interpretable analysis method based on Shapley values effectively enhances the performance of recognizing similar gestures and provides valuable insights into the decision-making process of recognition models.},
  archive      = {J_ISCI},
  author       = {Feng Wang and Xiaohu Ao and Min Wu and Seiichi Kawata and Jinhua She},
  doi          = {10.1016/j.ins.2024.120667},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120667},
  shortjournal = {Inf. Sci.},
  title        = {Explainable deep learning for sEMG-based similar gesture recognition: A shapley-value-based solution},
  volume       = {672},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Community hiding: Completely escape from community
detection. <em>ISCI</em>, <em>672</em>, 120665. (<a
href="https://doi.org/10.1016/j.ins.2024.120665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection algorithms play an important role in revealing and analyzing complex network structures. However, when these algorithms are put into practice, privacy concerns often arise, especially when community nodes wish to safeguard their identities from exposure. This interaction between network analysis and privacy issues leads to what we refer to as the “community hiding problem.” In the context of concealing specific target communities, popular methods primarily focus on preventing community detection algorithms from accurately identifying the entire original community, resulting in partial concealment. This study formally addresses the challenge of achieving complete concealment of target communities. We introduce key metrics such as escape scores, dispersion scores, and hiding scores to precisely define the problem. Additionally, we design a metric, denoted as M-value, to evaluate the effectiveness of concealing target communities from multiple perspectives. To tackle this challenge, we employ a genetic algorithm that leverages previous knowledge to maximize the concealment of the target community while minimizing changes to link connections. We validate our approach through extensive experiments with various real-world datasets, demonstrating that our algorithm outperforms several state-of-the-art baseline algorithms across multiple metrics. Visual representations of our method confirm its ability to effectively hide target communities while minimally affecting the broader network&#39;s community structure, strengthening the inherent effectiveness of our community hiding approach. Furthermore, we assess the adaptability of our modified network with different community detection algorithms, consistently demonstrating effective concealment even when these algorithms are extended. This emphasizes the robustness and generality of our proposed approach in various algorithmic scenarios.},
  archive      = {J_ISCI},
  author       = {Zhengchao Chang and Jing Liang and Shaohui Ma and Dong Liu},
  doi          = {10.1016/j.ins.2024.120665},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120665},
  shortjournal = {Inf. Sci.},
  title        = {Community hiding: Completely escape from community detection},
  volume       = {672},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Experimental analysis and evaluation of cohesive subgraph
discovery. <em>ISCI</em>, <em>672</em>, 120664. (<a
href="https://doi.org/10.1016/j.ins.2024.120664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieving cohesive subgraphs in networks is a fundamental problem in social network analysis and graph data management. These subgraphs can be used for marketing strategies or recommendation systems. Despite the introduction of numerous models over the years, a systematic comparison of their performance, especially across varied network configurations, remains unexplored. In this study, we evaluated various cohesive subgraph models using task-based evaluations and conducted extensive experimental studies on both synthetic and real-world networks. Thus, we unveil the characteristics of cohesive subgraph models, highlighting their efficiency and applicability. Our findings not only provide a detailed evaluation of current models but also lay the groundwork for future research by shedding light on the balance between the interpretability and cohesion of the subgraphs. This research guides the selection of suitable models for specific analytical needs and applications, providing valuable insights.},
  archive      = {J_ISCI},
  author       = {Dahee Kim and Song Kim and Jeongseon Kim and Junghoon Kim and Kaiyu Feng and Sungsu Lim and Jungeun Kim},
  doi          = {10.1016/j.ins.2024.120664},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120664},
  shortjournal = {Inf. Sci.},
  title        = {Experimental analysis and evaluation of cohesive subgraph discovery},
  volume       = {672},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-parameter clustering algorithm based on chain
propagation and natural neighbor. <em>ISCI</em>, <em>672</em>, 120663.
(<a href="https://doi.org/10.1016/j.ins.2024.120663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering analysis is a powerful tool for discovering potential knowledge in datasets. However, numerous existing clustering algorithms suffer from heavy reliance on parameter settings and cannot cluster complex manifold data very well. Moreover, although non-parameter clustering algorithms aim to lower the usage threshold, their actual performance in clustering is often unsatisfactory. Addressing how to achieve similar clustering effects for numerous data points with only a few core data points during clustering is a valuable consideration. To alleviate these challenges, a non-parameter clustering algorithm is proposed and named N on- p arameter C lustering Algorithm based on C hain P ropagation and N atural Neighbor (NPCCPN) in this paper, by jointly using chain propagation and natural neighbor. Specifically, NPCCPN identifies core points through chain propagation and clusters them using the saturated neighborhood graph. This makes the core data extraction and clustering process efficient and non-parameter. Finally, the performance of the method is validated on 15 complex synthetic datasets and 10 real datasets from public UCI database. The experimental results show that the effectiveness and superiority of the proposed algorithm. Purity scores first. ACC scores second without parameters, but the score first algorithm needs to set the parameters.},
  archive      = {J_ISCI},
  author       = {Tianshuo Li and Lijun Yang and Juntao Yang and Rui Pu and Jinghui Zhang and Dongming Tang and Tao Liu},
  doi          = {10.1016/j.ins.2024.120663},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120663},
  shortjournal = {Inf. Sci.},
  title        = {Non-parameter clustering algorithm based on chain propagation and natural neighbor},
  volume       = {672},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). AHA-3WKM: The optimization of k-means with three-way
clustering and artificial hummingbird algorithm. <em>ISCI</em>,
<em>672</em>, 120661. (<a
href="https://doi.org/10.1016/j.ins.2024.120661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering, as an essential technique in unsupervised learning, plays a pivotal role in the fields of data mining and machine learning. However, the classic K -means clustering algorithm has intrinsic drawbacks such as sensitivity to initial cluster centers, susceptibility to a local optimal solution, and challenges in handling data uncertainty. To address these problems, this paper proposes an artificial hummingbird algorithm (AHA)-based three-way K -means clustering algorithm, called AHA-3WKM. First, AHA is introduced to address the problems of sensitivity to initial cluster centers and local optima. Second, a fitness function of AHA is specifically constructed to find the best initial clustering centers so that the hummingbirds can search for high-quality food sources, i.e., the global optimum cluster centers. Third, a three-way clustering approach is utilized to capture information about data uncertainty. In this way, the results of clustering are divided into three distinct regions based on the relationship between objects and clusters. The experimental results demonstrate that AHA-3WKM has good performance, and enhances the stability and the accuracy of clustering results.},
  archive      = {J_ISCI},
  author       = {Xiying Chen and Caihui Liu and Bowen Lin and Jianying Lai and Duoqian Miao},
  doi          = {10.1016/j.ins.2024.120661},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120661},
  shortjournal = {Inf. Sci.},
  title        = {AHA-3WKM: The optimization of K-means with three-way clustering and artificial hummingbird algorithm},
  volume       = {672},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A patent retrieval method and system based on double
classification. <em>ISCI</em>, <em>672</em>, 120659. (<a
href="https://doi.org/10.1016/j.ins.2024.120659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most prominent carriers of knowledge, patents can provide masses of cross-domain knowledge to support the innovative design process of products. However, there is a major problem faced by most patent-aided innovation design systems, that is, identifying and providing patents related to design requirements from a multitude of cross-domain patents. To address this problem, a patent retrieval method based on double classification is proposed in this study, and a corresponding patent-aided innovative design prototype system is also developed. Firstly, the functional attributes are extracted from design requirements and expanded to different fields based on functional bases, by which the primary patent sets are constructed via classifying cross-domain patents. Secondly, technical features are mined from the primary patent sets with the topic model, which is used to classify the primary patent sets in turn and construct the secondary patent sets, hence, corresponding patents can be obtained to solve the design problems. Finally, a patent-aided prototype system is developed based on the proposed method. On the basis of the system, the hole plug of irradiated samples of nuclear reactor pressure vessel has undergone innovative design, which verifies the feasibility and practicability of both the method and system.},
  archive      = {J_ISCI},
  author       = {Chuanxiao Li and Wenqiang Li and Yida Hong and Hai Xiang},
  doi          = {10.1016/j.ins.2024.120659},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120659},
  shortjournal = {Inf. Sci.},
  title        = {A patent retrieval method and system based on double classification},
  volume       = {672},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised multiview fuzzy broad learning.
<em>ISCI</em>, <em>672</em>, 120625. (<a
href="https://doi.org/10.1016/j.ins.2024.120625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning models often rely on restricted assumptions, and can easily suffer from covariate shift or noise. Few studies have investigated the use of fuzzy rule-based methods in the semi-supervised discipline. To improve model accuracy against covariate shift and to introduce fuzzy methods for interpretability, we first build a semi-supervised fuzzy broad learning model named SSFBLS, which employs a Mean-Teacher framework. Then, a trusted multiview semi-supervised classification method, termed TMSSC, is proposed by integrating the SSFBLS with a multiview fusion network to enhance the robustness of the model. Under the Mean-Teacher framework, SSFBLS involves the Takagi-Sugeno-Kang fuzzy model which can effectively deal with imprecision and uncertainty, and broad learning system which has strong learning ability and high computational efficiency. TMSSC utilizes a trusted mechanism to blend multiple views, so as to enhance its learning ability in semi-supervised scenarios. Experiments on the benchmark datasets demonstrate that the proposed methods have better anti-noise ability, competitive classification accuracy, as well as fast running speed.},
  archive      = {J_ISCI},
  author       = {Chao Xi and Zizhu Fan and Cheng Peng and Qiang Liu and Hui Wang},
  doi          = {10.1016/j.ins.2024.120625},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120625},
  shortjournal = {Inf. Sci.},
  title        = {Semi-supervised multiview fuzzy broad learning},
  volume       = {672},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stealthy attacks against distributed state estimation of
stochastic multi-agent systems under composite attack detection
mechanisms. <em>ISCI</em>, <em>672</em>, 120584. (<a
href="https://doi.org/10.1016/j.ins.2024.120584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the security problem of distributed state estimation for stochastic multi-agent systems (MASs) under directed topology. First, in the absence of attacks, an optimal distributed filter is proposed to reconstruct the states of MASs by minimizing the mean square error, which makes full use of the measurable local output information and relative state estimates of agents. Moreover, instead of using a single detection mechanism to measure the stealthiness of attacks, based on the structure of the derived filter, a composite attack detection mechanism capable of simultaneously detecting anomalies in the sensor channels of the agents themselves and the network topologies between different agents is utilized in this paper. Then, from the perspective of potential adversaries, two stealthy attack strategies are established through a joint design of sensor and topology attacks, enabling attackers to fulfill diverse attack objectives while evading the given composite detection mechanisms. Finally, simulation results are provided to verify the availability of the designed filter and attack generation schemes.},
  archive      = {J_ISCI},
  author       = {Dong-Yu Zhang and Xiao-Jian Li},
  doi          = {10.1016/j.ins.2024.120584},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120584},
  shortjournal = {Inf. Sci.},
  title        = {Stealthy attacks against distributed state estimation of stochastic multi-agent systems under composite attack detection mechanisms},
  volume       = {672},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meta generative flow networks with personalization for
task-specific adaptation. <em>ISCI</em>, <em>672</em>, 120569. (<a
href="https://doi.org/10.1016/j.ins.2024.120569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task reinforcement learning and meta-reinforcement learning have been developed to enhance the learning capabilities on new tasks, but they tend to focus on maximizing rewards, leading to poor performance in exploration. To address this issue, we propose Meta Generative Flow Networks (GFlowMeta): an integration of Generative Flow Networks (GFlowNets) into meta-learning algorithms. By leveraging the unique capabilities of GFlowNets to generate diverse candidate solutions, GFlowMeta exhibits enhanced exploration of tasks. However, GFlowMeta&#39;s performance deteriorates when confronted with heterogeneous transitions from distinct tasks, leading to a decrease in its effectiveness. Therefore, we subsequently introduce a personalization approach called personalized Meta Generative Flow Networks (pGFlowMeta), which combines task-specific personalized policies with a meta policy. Each personalized policy balances the loss on its personalized task and the difference from the meta policy, while the meta policy aims to minimize the average loss of all tasks. The theoretical analysis shows that the proposed pGFlowMeta converges at a sublinear rate. Furthermore, extensive experiments demonstrate the superiority of pGFlowMeta over state-of-the-art reinforcement learning algorithms.},
  archive      = {J_ISCI},
  author       = {Xinyuan Ji and Xu Zhang and Wei Xi and Haozhi Wang and Olga Gadyatskaya and Yinchuan Li},
  doi          = {10.1016/j.ins.2024.120569},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120569},
  shortjournal = {Inf. Sci.},
  title        = {Meta generative flow networks with personalization for task-specific adaptation},
  volume       = {672},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label relaxation and shared information for multi-label
feature selection. <em>ISCI</em>, <em>671</em>, 120662. (<a
href="https://doi.org/10.1016/j.ins.2024.120662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rapid growth of labels and high-dimensional data, multi-label feature selection has attracted increasing attention. However, two common issues are ignored by existing multi-label feature selection methods: 1) The pseudo-label matrix is constructed by using logical label matrix directly. 2) There is an imbalance of label density in multi-label data. To tackle the mentioned issues, we innovatively propose a new method named Label relaxation and Shared information for Multi-label Feature Selection (LSMFS). Specifically, LSMFS combines a logical label matrix with a non-negative label relaxation matrix to fit a pseudo-label matrix, which is used for learning the correlations of class labels. LSMFS uses the feature weight matrix to capture a shared information of different related labels, which mitigates the influence of low-density labels on feature selection. The above principles are transformed into the objective function of LSMFS, and an alternate iterative optimization algorithm is developed to solve the objective function. Experiments on multi-label datasets from different domains have demonstrated the effectiveness of the proposed method LSMFS. Code is released at https://github.com/HQUF/LSMFS .},
  archive      = {J_ISCI},
  author       = {Yuling Fan and Xu Chen and Shimu Luo and Peizhong Liu and Jinghua Liu and Baihua Chen and Jianeng Tang},
  doi          = {10.1016/j.ins.2024.120662},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120662},
  shortjournal = {Inf. Sci.},
  title        = {Label relaxation and shared information for multi-label feature selection},
  volume       = {671},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A note on “a new method for intuitionistic fuzzy
multi-objective linear fractional optimization problem and its
application in agricultural land allocation problem.” <em>ISCI</em>,
<em>671</em>, 120658. (<a
href="https://doi.org/10.1016/j.ins.2024.120658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moges et al. (Inf. Sci. 625 (2023) 457–475) proposed a method to find a Pareto-optimal solution (POS) of intuitionistic fuzzy multi-objective linear fractional optimization problem (MOLFOP). In this method, firstly, an intuitionistic fuzzy MOLFOP is transformed into a crisp MOLFOP with the help of a ranking function. Then, using the existing method (Fuzzy Sets Syst. 125 (2002) 335–342), the transformed crisp MOLFOP is transformed into a crisp multi-objective linear optimization problem (MOLOP). Finally, it is assumed that to find a POS of the considered intuitionistic fuzzy MOLFOP is equivalent to find a POS of the transformed crisp MOLOP. It is pertinent to mention that this assumption is valid only if the transformed crisp MOLFOP is equivalent to the considered intuitionistic fuzzy MOLFOP as well as the transformed crisp MOLOP is equivalent to the transformed crisp MOLFOP. In this note, a numerical example is considered to show that the transformed crisp MOLFOP is not equivalent to the considered intuitionistic fuzzy MOLFOP. Also, on the basis of the existing results (Fuzzy Sets Syst. 246 (2014) 156–159), it is pointed out that the transformed crisp MOLOP is not equivalent to the transformed crisp MOLFOP. Therefore, Moges et al.’s method is not valid and hence, the results of agricultural planning problem of Ethopia for cultivation of different crops, obtained by Moges et al. with their proposed method, are not correct.},
  archive      = {J_ISCI},
  author       = {Parul Tomar and Amit Kumar},
  doi          = {10.1016/j.ins.2024.120658},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120658},
  shortjournal = {Inf. Sci.},
  title        = {A note on “A new method for intuitionistic fuzzy multi-objective linear fractional optimization problem and its application in agricultural land allocation problem”},
  volume       = {671},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive event-triggered based path following output
feedback control for networked autonomous vehicles. <em>ISCI</em>,
<em>671</em>, 120657. (<a
href="https://doi.org/10.1016/j.ins.2024.120657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the adaptive event-triggered (AET)-based path following controller design problem for a networked autonomous vehicle, where the limited networked bandwidth, system nonlinearities and uncertainties are considered. The polytopic model is proposed to construct a linear parameter varying (LPV) system for the nonlinear vehicle system. Taking into account the effects of event trigger on the path following performance, an improved AET mechanism is designed to achieve a balance between efficient communication and accurate path following requirements. Sufficient conditions are developed to guarantee that the closed-loop system is exponentially stable with an H ∞ H∞ performance index being satisfied. In addition, a co-design method with less conservatism is derived to obtain the event-triggered weight matrix and output feedback controller gain matrix simultaneously. Finally, simulation results verify the effectiveness of the proposed control strategy.},
  archive      = {J_ISCI},
  author       = {Tengfei Zhang and Heng Wang and Qing Li and Weiwei Che},
  doi          = {10.1016/j.ins.2024.120657},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120657},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive event-triggered based path following output feedback control for networked autonomous vehicles},
  volume       = {671},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A joint learning framework for optimal feature extraction
and multi-class SVM. <em>ISCI</em>, <em>671</em>, 120656. (<a
href="https://doi.org/10.1016/j.ins.2024.120656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high-dimensional data classification, effectively extracting discriminative features while eliminating redundancy is crucial for enhancing the performances of classifiers, such as Support Vector Machine (SVM). However, previous studies have decoupled the process of feature extraction from the development of SVM, leading to suboptimal classification accuracy. To address this problem, we propose a novel joint learning framework that combines optimal feature extraction and multi-class SVM, incorporating a generalized regression form to learn a discriminative latent subspace. The projected data in this subspace are more likely to have a larger margin between different classes and align with the properties of the SVM classification mechanism, enhancing the overall classification performance. Three iterative algorithms were presented to obtain optimal solutions with guaranteed convergence, and theoretical analyses were also conducted to reveal their fundamental nature. The optimal linear projection subspace is equivalent to that obtained from Linear Discriminant Analysis (LDA) in some special cases. We conducted extensive experiments using diverse datasets to evaluate the performances of the proposed algorithms. Our algorithms achieved an accuracy improvement of up to 7.55% compared to other conventional methods.},
  archive      = {J_ISCI},
  author       = {Zhihui Lai and Guangfei Liang and Jie Zhou and Heng Kong and Yuwu Lu},
  doi          = {10.1016/j.ins.2024.120656},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120656},
  shortjournal = {Inf. Sci.},
  title        = {A joint learning framework for optimal feature extraction and multi-class SVM},
  volume       = {671},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Aspect-level item recommendation based on user reviews with
variational autoencoders. <em>ISCI</em>, <em>671</em>, 120655. (<a
href="https://doi.org/10.1016/j.ins.2024.120655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose an aspect-based recommendation model based on variational autoencoders, that provides not only coarse predictions about what items users may like, but also finer-grained predictions of specific aspects users may be interested in of the recommended items. The proposed model first employs convolution operations to learn probability distributions of aspect-level embeddings for users and items from user aspect-level sentiments on seen items. Then it samples from these distributions and feeds the samples into transpose convolution operations to ‘reconstruct’ missing aspect-level sentiments for unseen items, thereby serving as signals for generating recommendations. To prevent overfitting, we impose a prior on the representation distributions and penalize the model if the learned distributions diverge from the prior. Based on the output of the proposed model, we propose a two-stage ranking scheme that combines aspect-level and overall sentiment signals to rank items. Experiment results show that the proposed model outperforms state-of-the-art aspect-based recommendation models, and the two-stage ranking scheme improves the traditional ranking by overall sentiment predictions.},
  archive      = {J_ISCI},
  author       = {Wei Ou and Van-Nam Huynh},
  doi          = {10.1016/j.ins.2024.120655},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120655},
  shortjournal = {Inf. Sci.},
  title        = {Aspect-level item recommendation based on user reviews with variational autoencoders},
  volume       = {671},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-task self-supervised time-series representation
learning. <em>ISCI</em>, <em>671</em>, 120654. (<a
href="https://doi.org/10.1016/j.ins.2024.120654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series representation learning is crucial for extracting meaningful representations from time-series data with temporal dynamics and sparse labels. Contrastive learning, a powerful technique for exploiting the inherent data patterns, has been applied to explore the diverse consistencies in time-series data, achieved through careful selection of contrastive pairs and design of appropriate loss. Encouraging such consistency is essential for acquiring comprehensive representations of time-series data. In this paper, we propose a new framework for time-series representation learning that combines the advantages of contextual, temporal, and transformation consistencies. This framework enables the network to learn general representations suitable for different tasks and domains. First, positive and negative pairs are generated to establish a multi-task learning setup. Then, contrastive losses are formulated to explore contextual, temporal, and transformation consistencies, which are jointly optimized to learn general time-series representations. In addition, we investigate an uncertainty weighting approach to enhance the effectiveness of multi-task learning. To evaluate the performance of our framework, we conduct experiments on three downstream tasks: time-series classification, forecasting, and anomaly detection. The experimental results demonstrate the superior performance of our framework compared to benchmark models across different tasks. Furthermore, our framework shows efficiency in cross-domain transfer learning scenarios.},
  archive      = {J_ISCI},
  author       = {Heejeong Choi and Pilsung Kang},
  doi          = {10.1016/j.ins.2024.120654},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120654},
  shortjournal = {Inf. Sci.},
  title        = {Multi-task self-supervised time-series representation learning},
  volume       = {671},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TimeSQL: Improving multivariate time series forecasting with
multi-scale patching and smooth quadratic loss. <em>ISCI</em>,
<em>671</em>, 120652. (<a
href="https://doi.org/10.1016/j.ins.2024.120652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series are usually sequences of real-valued variables recorded at regular intervals. Forecasting them poses significant challenges due to their inherent noise and complex temporal dynamics. To effectively address these challenges, we introduce TimeSQL, a novel approach specifically designed for multivariate time series. TimeSQL employs multi-scale patching and a smooth quadratic loss (SQL) function. This enables it to adeptly capture both local and long-term patterns in complex, noisy data environments. The multi-scale patching approach provides a comprehensive view of temporal correlations, while the SQL, rooted in the rational quadratic kernel, strategically adjusts gradients to avoid overfitting. Through both theoretical and empirical analysis, we have demonstrated that TimeSQL exhibits superior noise resilience compared with models based on Mean Squared Error (MSE). Evaluated across eight diverse benchmark datasets, TimeSQL consistently delivers exceptional performance in multivariate time series forecasting. Furthermore, ablation studies underscore the adaptability of TimeSQL&#39;s components, enhancing the performance of various other forecasting models and proving their utility as plug-and-play modules.},
  archive      = {J_ISCI},
  author       = {Site Mo and Haoxin Wang and Bixiong Li and Songhai Fan and Yuankai Wu and Xianggen Liu},
  doi          = {10.1016/j.ins.2024.120652},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120652},
  shortjournal = {Inf. Sci.},
  title        = {TimeSQL: Improving multivariate time series forecasting with multi-scale patching and smooth quadratic loss},
  volume       = {671},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A large-scale graph clustering method for cell conditions
spatio-temporal localization in aluminum electrolysis. <em>ISCI</em>,
<em>671</em>, 120651. (<a
href="https://doi.org/10.1016/j.ins.2024.120651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensor nodes (industrial nodes) clustering is an efficacious method for gaining local working conditions real-timely in the production process. The existing deep graph neural networks-based industrial nodes clustering studies construct static graphs to describe the potential spatial correlation among industrial nodes, but the temporal correlation among industrial nodes is ignored, resulting in inferior real-time performance. Meanwhile, these deep learning models fail to obtain good clustering results due to the large-scale and noise-containing characteristics of industrial nodes. In this paper, a large-scale graph clustering method (LsGCM) is proposed for cell conditions spatio-temporal localization in aluminum electrolysis to address the above issues. Specifically, a spatio-temporal graph construction method based on industrial process mechanism knowledge and local working condition boundary types statistical feature fusion is proposed for capturing effective spatio-temporal correlations between industrial nodes. Then, hysteresis knowledge of industrial production system is used to guide the nodes merging, thereby avoiding the incorrect merging of time-asynchronous nodes when performing the spatio-temporal region detection of local working conditions. Finally, combined with the actual spatio-temporal location information of industrial nodes, a novel spatio-temporal information expansion method (StIEM) of the sub-spatio-temporal graph describing local working condition is proposed for obtaining spatio-temporal feature information of the neighborhood, which is beneficial to improve the performance of industrial node clustering. Validation studies on a numerical simulation example and multiple real aluminum electrolysis industrial datasets certificate the effectiveness and superiority of the proposed method. In particular, compared with existing graph clustering methods, our method improves the clustering accuracy by 7.79%.},
  archive      = {J_ISCI},
  author       = {Yubo Sun and Weihua Gui and Xiaofang Chen and Lihui Cen and Chunhua Yang and Zhong Zou},
  doi          = {10.1016/j.ins.2024.120651},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120651},
  shortjournal = {Inf. Sci.},
  title        = {A large-scale graph clustering method for cell conditions spatio-temporal localization in aluminum electrolysis},
  volume       = {671},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-channel spatial-temporal transformer model for
traffic flow forecasting. <em>ISCI</em>, <em>671</em>, 120648. (<a
href="https://doi.org/10.1016/j.ins.2024.120648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow forecasting is a crucial task in transportation management and planning. The main challenges for traffic flow forecasting are that (1) as the length of prediction time increases, the accuracy of prediction will decrease; (2) the predicted results greatly rely on the extraction of temporal and spatial dependencies from the road networks. To overcome the challenges mentioned above, we propose a multi-channel spatial-temporal transformer model for traffic flow forecasting, which improves the accuracy of the prediction by fusing results from different channels of traffic data. Our approach leverages graph convolutional network to extract spatial features from each channel while using a transformer-based architecture to capture temporal dependencies across channels. We introduce an adaptive adjacency matrix to overcome limitations in feature extraction from fixed topological structures. Experimental results on six real-world datasets demonstrate that introducing a multi-channel mechanism into the temporal model enhances performance and our proposed model outperforms state-of-the-art models in terms of accuracy.},
  archive      = {J_ISCI},
  author       = {Jianli Xiao and Baichao Long},
  doi          = {10.1016/j.ins.2024.120648},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120648},
  shortjournal = {Inf. Sci.},
  title        = {A multi-channel spatial-temporal transformer model for traffic flow forecasting},
  volume       = {671},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graphs with minimum degree-entropy. <em>ISCI</em>,
<em>671</em>, 120629. (<a
href="https://doi.org/10.1016/j.ins.2024.120629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We continue studying extremal values of the degree-entropy, which is an information-theoretic measure defined as the Shannon entropy based on the information functional involving vertex degrees. For a graph with a given number of vertices and edges achieving the minimum entropy value, we show its unique structure. Also, a tight lower bound for the entropy in bipartite graphs with a given number of vertices and edges is proved. Our result directly derives the result of Cao et al. (2014) that for a tree with a given number of vertices, the minimum value of the entropy is attained if and only if the tree is the star.},
  archive      = {J_ISCI},
  author       = {Yanni Dong and Maximilien Gadouleau and Pengfei Wan and Shenggui Zhang},
  doi          = {10.1016/j.ins.2024.120629},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120629},
  shortjournal = {Inf. Sci.},
  title        = {Graphs with minimum degree-entropy},
  volume       = {671},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel quantum dempster’s rule of combination for pattern
classification. <em>ISCI</em>, <em>671</em>, 120617. (<a
href="https://doi.org/10.1016/j.ins.2024.120617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster&#39;s rule of combination (DRC) is widely used for uncertainty reasoning in intelligent information system, which is generalized to complex domain recently. However, as the increase of identification framework elements, the computational complexity of Dempster&#39;s rule of combination increases exponentially. To address this issue, we propose a novel quantum Dempster&#39;s rule of combination (QDRC) by means of Toffoli gate. The QDRC combination process is completely implemented using quantum circuits. To validate the efficiency of the proposed QDRC, we conduct simulation experiments on IBM and IonQ quantum cloud platforms. Besides, we implement the QDRC algorithm to the real quantum computer of IonQ Harmony. The experiment results show that the result of QDRC is getting more and more accurate as the number of measurements increases. In addition, we propose a quantum multisource information fusion method on the basis of QDRC. Finally, we demonstrate its effectiveness to solve pattern classification problem under several diverse real UCI datasets.},
  archive      = {J_ISCI},
  author       = {Huaping He and Fuyuan Xiao},
  doi          = {10.1016/j.ins.2024.120617},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120617},
  shortjournal = {Inf. Sci.},
  title        = {A novel quantum dempster&#39;s rule of combination for pattern classification},
  volume       = {671},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Z-number based neural network structured inference system.
<em>ISCI</em>, <em>671</em>, 120341. (<a
href="https://doi.org/10.1016/j.ins.2024.120341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Z-number based Neural Network structured Inference System (ZNIS) with rule-base consisting of linguistic Z-terms trainable with Differential Evolution with Constraints (DEC) optimization algorithm is suggested. The inference mechanism of the multi-layered ZNIS consists of a fuzzifier, fuzzy rule base, inference engine, and output processor. Due to the use of extended fuzzy terms, each processing layer implements appropriate extended fuzzy operations, including computation of fuzzy valued rule firing strengths, fuzzy Level-2 aggregate outputs, and two consecutive Center of Gravity (COG) defuzzification procedures. The experiments with different versions of ZNIS have demonstrated that it is a universal modeling tool suitable for dealing with both approximate reasoning and functional mapping tasks. Random experiments on benchmark examples (among which are simple functional mapping, Parkinson disease, and non-linear system identification) have shown that ZNIS performance is equivalent to or better than FLS Type 2 and far superior to FLS Type 1, showing on average 2–3 times lower MSE. Along with this, the main advantages of ZNIS over other inference systems are better semantic expressing power, higher degree of perception and interpretability of the linguistic rules by humans, and a higher confidence in the reliability of achieved decision due to the transparency of the underlying decision-making mechanism.},
  archive      = {J_ISCI},
  author       = {Rafik A. Aliev and M.B. Babanli and Babek G. Guirimov},
  doi          = {10.1016/j.ins.2024.120341},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120341},
  shortjournal = {Inf. Sci.},
  title        = {Z-number based neural network structured inference system},
  volume       = {671},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). When grey model meets deep learning: A new hazard
classification model. <em>ISCI</em>, <em>670</em>, 120653. (<a
href="https://doi.org/10.1016/j.ins.2024.120653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of hazard is critical in industrial informatics, as it enhances early safety alerts, supports decision-making, and facilitates policy assessment. However, previous studies have generally neglected the temporal attributes of hazards, thereby constraining the effectiveness of models. This paper introduces a new model for hazard classification termed DLGM. DLGM represents a deep learning framework, with the structural parameters of grey models to encapsulate the hazard temporal attributes. To better accommodate the fluctuations of hazard series, a new grey model termed FSGM(1,1) equipped with Fourier series is proposed. Moreover, DLGM leverages a novel hierarchical feature fusion neural network (HFFNN) to optimize feature processing. Extensive experiments across three hazard themes involving 18 large-scale industrial processes have demonstrated the competitiveness of DLGM (e.g., it surpasses benchmark models such as Random Forest and BERT by approximately 2% in both accuracy and F1), the suitability of FSGM(1,1) (e.g., its mean absolute percentage error is less than 10% and mean squared error is below 0.02) and the effectiveness of HFFNN (e.g., it enhances the accuracy and F1 of DLGM by about 1%).},
  archive      = {J_ISCI},
  author       = {Fuqian Zhang and Bin Wang and Dong Gao and Chengxi Yan and Zhenhua Wang},
  doi          = {10.1016/j.ins.2024.120653},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120653},
  shortjournal = {Inf. Sci.},
  title        = {When grey model meets deep learning: A new hazard classification model},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A learned cost model for big data query processing.
<em>ISCI</em>, <em>670</em>, 120650. (<a
href="https://doi.org/10.1016/j.ins.2024.120650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficiency of query processing in the Spark SQL big data processing engine is significantly affected by execution plans and allocated resources. However, existing cost models for Spark SQL rely on hand-crafted rules. While learning-based cost models have been proposed for relational databases, they do not consider available resources. To address this issue, we propose a resource-aware deep learning model capable of automatically predicting query plan execution times based on historical data. To train our model, we embed query execution plans within a query plan tree and extracted features from allocated resources. An adaptive attention mechanism is integrated into the deep learning model to enhance prediction accuracy. Additionally, we extract sufficient features to represent data information and learn the effect of the data on query execution. This approach reduces the need for model retraining owing to data changes. The experimental results demonstrate that our deep cost model outperforms traditional rule-based methods and relational database learning-based optimizers in predicting query plan execution times.},
  archive      = {J_ISCI},
  author       = {Yan Li and Liwei Wang and Sheng Wang and Yuan Sun and Bolong Zheng and Zhiyong Peng},
  doi          = {10.1016/j.ins.2024.120650},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120650},
  shortjournal = {Inf. Sci.},
  title        = {A learned cost model for big data query processing},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Concept drift adaptation with continuous kernel learning.
<em>ISCI</em>, <em>670</em>, 120649. (<a
href="https://doi.org/10.1016/j.ins.2024.120649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept drift poses significant challenges in the fields of machine learning and data mining. At present, many existing algorithms struggle to maintain low error rates or require excessive computational resources to achieve satisfactory classification results when addressing concept drift. To address these issues, a novel mathematical model is first introduced to mitigate the degradation of classification performance caused by concept drift. Then, based on the proposed objective function, a continuous kernel learning method is employed to adapt to potential changes in data distribution as new samples continuously arrive. Furthermore, we propose an ensemble learning approach leveraging the majority voting strategy to enhance classification performance in non-stationary environments. Finally, a theoretical analysis of the proposed algorithm is conducted. Experimental results demonstrate that the proposed algorithm not only achieves lower error rates and reduced memory consumption but also operates more efficiently than most of the state-of-the-art algorithms when processing different types of data streams.},
  archive      = {J_ISCI},
  author       = {Yingying Chen and Hong-Liang Dai},
  doi          = {10.1016/j.ins.2024.120649},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120649},
  shortjournal = {Inf. Sci.},
  title        = {Concept drift adaptation with continuous kernel learning},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). A convolutional neural network based on an evolutionary
algorithm and its application. <em>ISCI</em>, <em>670</em>, 120644. (<a
href="https://doi.org/10.1016/j.ins.2024.120644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PM 2.5 concentration predictions can provide air pollution control, management, and early warning. However, the PM 2.5 data with high-dimensionality, complexity, and dynamics pose a great challenge to achieve optimal prediction results. Convolutional Neural Networks (CNNs) has unique advantages in processing complex data and contributes to state-of-the-art performances. However, designing the architecture and selecting the learning rate for CNN are time-consuming and requires prior knowledge. Evolutionary algorithms, with the advantages of global convergence, ergodicity, robustness and adaptability, are the most commonly used methods to design the optimal framework for CNNs. Therefore, to improve the predictive performance of CNNs, this paper proposes an improved CNN method (EBRO-ICNN) which employs the enhanced battle royale optimization (EBRO) algorithm and proportional-derivative (PD) control. Firstly, the EBRO algorithm with multistrategy collaborative optimization is introduced, and validated by CEC2017 benchmark functions, which demonstrates EBRO strong global exploration capability, fast convergence speed, and low time complexity. Next, PD control is applied to adjust the learning rate of CNN (ICNN) dynamically, which improves the efficiency and stability of the network training process. At the same time, the ICNN model is optimized using the EBRO algorithm, which can reduce the human interference, generate the optimal framework automatically and enhance the prediction accuracy effectively. Finally, a private air quality dataset and two public datasets are utilized to evaluate the performance of the EBRO-ICNN model, considering 3 error evaluation metrics and 7 prediction comparison models. The experimental results demonstrate that the EBRO-ICNN model exhibits great accuracy and stability.},
  archive      = {J_ISCI},
  author       = {Yufei Zhang and Limin Wang and Jianping Zhao and Xuming Han and Honggang Wu and Mingyang Li and Muhammet Deveci},
  doi          = {10.1016/j.ins.2024.120644},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120644},
  shortjournal = {Inf. Sci.},
  title        = {A convolutional neural network based on an evolutionary algorithm and its application},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Defending against membership inference attacks: RM learning
is all you need. <em>ISCI</em>, <em>670</em>, 120636. (<a
href="https://doi.org/10.1016/j.ins.2024.120636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-capacity machine learning models are vulnerable to membership inference attacks that disclose the privacy of the training dataset. The privacy concerns posed by membership inference attacks have inspired many defense strategies. Unfortunately, they have various limitations: 1) failing to achieve a high-quality tradeoff between membership privacy and model utility. 2) Providing little flexibility to users. This paper proposes Repair-Membership Learning (RM Learning), a simple but effective defense mechanism. RM Learning mitigates membership inference attacks by giving each sample of the training dataset an appropriate soft label to reduce the loss gap between the training and testing datasets of the model. Meanwhile, RM Learning controls the distinguishability between the training and testing datasets by limiting the model&#39;s loss gap over them with an adjustable parameter λ to give users flexibility. We evaluated the RM Learning algorithm on four datasets with seven models and compared it with three state-of-the-art methods. For instance, we reduce the effectiveness of black-box and white-box membership inference attacks to about 50.0%, with a loss of less than 1.3% of testing accuracy, for the CIFAR10 dataset with the ResNet18 model.},
  archive      = {J_ISCI},
  author       = {Zheng Zhang and Jianfeng Ma and Xindi Ma and Ruikang Yang and Xiangyu Wang and Junying Zhang},
  doi          = {10.1016/j.ins.2024.120636},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120636},
  shortjournal = {Inf. Sci.},
  title        = {Defending against membership inference attacks: RM learning is all you need},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dirichlet probability navigated fault detection via
key-group memory auto-encoder under non-stationary working conditions.
<em>ISCI</em>, <em>670</em>, 120635. (<a
href="https://doi.org/10.1016/j.ins.2024.120635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time condition monitoring is the foundation of prognostics and health management (PHM) for mechanical systems. Constraint by extravagant cost and insurmountable obstacles to simulate real faults in actual working conditions, establishing fault detection models with historical normal data is the most promising way. Meanwhile, non-stationary fault detection is rarely studied in the literature but fits most in real working conditions. Thus, an innovative method named KGMem-DirAE is proposed to conduct real-time fault detection under non-stationary working conditions using normal data only. In the training stage, normal patterns with different semantics are recorded in the developed key-group memory module (KGMem) combined with auto-encoder. Considering the matching probabilities of encoded latent features and recorded memory units (normal patterns), a statistical anomaly score defined by aggregated negative log-likelihood of Dirichlet distributions is proposed to detect incipient failures. In order to deal with time-varying working conditions and capture fault degradation trends concurrently, normalized time-frequency maps containing fault-evolving information are obtained from vibration data. Both widely studied non-stationary and stationary run-to-failure data sets are deeply researched using the proposed KGMem-DirAE and the experimental results proved its superiority against other comparative anomaly detection methods.},
  archive      = {J_ISCI},
  author       = {De-Yu Weng and Jun-Wei Zhu and Qi Xuan},
  doi          = {10.1016/j.ins.2024.120635},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120635},
  shortjournal = {Inf. Sci.},
  title        = {Dirichlet probability navigated fault detection via key-group memory auto-encoder under non-stationary working conditions},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Image-based fire detection using an attention mechanism and
pruned dense network transfer learning. <em>ISCI</em>, <em>670</em>,
120633. (<a href="https://doi.org/10.1016/j.ins.2024.120633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire accidents continually threaten lives and property, posing a great risk to public safety. Therefore, timely, accurate fire smoke and flame detection technology provides a technical foundation for ensuring personnel and property safety. This paper proposes a deep transfer learning model that integrates attention mechanisms and pruning techniques into the DenseNet network (P-DenseNet-A-TL) for detecting fire smoke and flame targets. To reduce the computational complexity of the fire detection model, we simplified the DenseNet network structure. To improve the recognition accuracy of the fire detection model, we incorporated attention mechanisms including a channel attention module (CAM) and spatial attention module (SAM) into the pruned dense network structure. To expedite the model training process, we also introduced a transfer learning model. Furthermore, to enhance the generalization ability and robustness of the model, we created a large-scale fire smoke and flame dataset. The experimental results show that our model (P-DenseNet-A-TL) achieved a test accuracy of 99.06%, F1 score of 99.09%, area under the curve (AUC) of 0.97, and a detection speed of 756 frames per second (FPS). The comparison experimental results and ablation experimental results indicate that our method achieves high detection accuracy and efficiency. Additionally, it possesses strong generalization capability and robustness.},
  archive      = {J_ISCI},
  author       = {Hai Li and Zheng Ma and Sheng-Hua Xiong and Qiang Sun and Zhen-Song Chen},
  doi          = {10.1016/j.ins.2024.120633},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120633},
  shortjournal = {Inf. Sci.},
  title        = {Image-based fire detection using an attention mechanism and pruned dense network transfer learning},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). State estimation with unknown measurement losses: A
detector-based approach. <em>ISCI</em>, <em>670</em>, 120632. (<a
href="https://doi.org/10.1016/j.ins.2024.120632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we are devoted to solving the problems of designing an estimator, and determining its estimator stability and estimation performance for a system with unknown measurement losses (UML). The solutions to these problems include three steps: first, we design two measurement-loss detectors to detect the measurement losses; Then, we design a detector-based estimator for UML systems. Finally, by analyzing the upper and lower bounds of the covariances of the proposed estimator, we establish a stability condition and determine the estimation performance. Detailed findings and main contributions of this paper are summarized as follows: (i) from the estimator stability perspective, we obtain a necessary and sufficient stability condition. Specifically, the estimator is stable almost surely if and only if the measurement-loss rate is less than a critical value. (ii) From the estimation performance perspective, we prove that under some conditions, the performance of the proposed estimator is almost surely the same as that of the optimal estimator for the system with known measurement losses.},
  archive      = {J_ISCI},
  author       = {Hong Lin and Chenxiao Cai and Shan Lu and Xiaochen Xie and Peng Shi},
  doi          = {10.1016/j.ins.2024.120632},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120632},
  shortjournal = {Inf. Sci.},
  title        = {State estimation with unknown measurement losses: A detector-based approach},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An enhanced discrete particle swarm optimization for
structural k-anonymity in social networks. <em>ISCI</em>, <em>670</em>,
120631. (<a href="https://doi.org/10.1016/j.ins.2024.120631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, social network usage has exhibited explosive growth, leading to a huge amount of users’ private data available. The main challenge in releasing social network data publicly is the protection of the users’ privacy while preserving its utility for third parties. Accordingly, several social network privacy-preserving methods have been introduced, where anonymization is the most common approach. Structural k-anonymity is a widely used anonymization model to mask the structure of social networks by clustering the edges and nodes into super-edges and super-nodes. However, it comes at the cost of losing structural information, which is measured by a criterion called structural information loss (SIL). This study introduces an enhanced discrete particle swarm optimization (EDPSO) algorithm, which effectively minimizes the SIL within the clustering process of the structural k-anonymity model, leading to a high-utility anonymized network. In this regard, we propose a vector-based solution representation that can be efficiently exploited by the EDPSO. Moreover, a novel position updating heuristic is suggested for the EDPSO, which adaptively tunes the operators’ selection probabilities. This happens based on each operator’s performance both in the current iteration and their history regarding the number and the average amount of fitness improvements in the previous iterations. We also propose two fortified versions of the EDPSO algorithm (EDPSOVNS and EDPSOSA) by employing two new network-specific local search strategies to enhance the exploration, exploitation, and convergence rate of the process. Simulation results on the nine real-world networks demonstrate the superiority of the suggested algorithms in terms of the fitness value, reliability, and convergence rate over other analyzed approaches found in the literature.},
  archive      = {J_ISCI},
  author       = {Navid Yazdanjue and Hossein Yazdanjouei and Ramin Karimianghadim and Amir H. Gandomi},
  doi          = {10.1016/j.ins.2024.120631},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120631},
  shortjournal = {Inf. Sci.},
  title        = {An enhanced discrete particle swarm optimization for structural k-anonymity in social networks},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mixed norm regularized models for low-rank tensor
completion. <em>ISCI</em>, <em>670</em>, 120630. (<a
href="https://doi.org/10.1016/j.ins.2024.120630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances on low-rank representation have achieved promising performances for tensor completion in the area of information sciences. However, current low-rank tensor completion (LRTC) models merely model global low-rankness and lose sight of capturing the local subspace low-rank structures of underlying tensor objects. As such, they may fall short for the low sampling rates cases. To this end, we develop a novel tensor completion scheme that bridges global low-rankness and local subspace low-rankness priors into a unified framework. More specifically, we propose two mixed norm tensor penalties to describe local subspace low-rank structures for tensor completion through theoretical analysis. Besides, we point out that mixed norm on the factor subspaces can ensure the non-convex global low-rankness of tensor objects. We design a block coordinate descent algorithm with proximal technique to solve the models, which is guaranteed to converge to the coordinate-wise minimizers. Notably, our methods are much more tractable than existing tensor rank minimization methods with lower computational complexities. Finally, extensive experiments on three types of tensor datasets validate the superiority of the proposed methods, especially in extremely low sampling rates cases.},
  archive      = {J_ISCI},
  author       = {Yuanyang Bu and Yongqiang Zhao and Jonathan Cheung-Wai Chan},
  doi          = {10.1016/j.ins.2024.120630},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120630},
  shortjournal = {Inf. Sci.},
  title        = {Mixed norm regularized models for low-rank tensor completion},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accurate parameters extraction of photovoltaic models with
multi-strategy gaining-sharing knowledge-based algorithm. <em>ISCI</em>,
<em>670</em>, 120627. (<a
href="https://doi.org/10.1016/j.ins.2024.120627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The determination of photovoltaic (PV) model parameters has essential theoretical and practical significance for the performance evaluation, power monitoring, and power generation efficiency calculation of PV systems. In this paper, a multi-strategy gaining-sharing knowledge-based algorithm (MSGSK) is developed to determine these parameters. In our previous work, it has been demonstrated that gaining-sharing knowledge-based algorithm (GSK) is well suited for solving the concerned problem. To enhance its performance, a parameter adjustment strategy is developed to adjust the knowledge rate and knowledge ratio of GSK. Besides, a backtracking differential mutation strategy by combining the mutation scheme of differential evolution and the updating scheme of backtracking search optimization algorithm is developed to enrich the population diversity. Furthermore, a strategy selection mechanism is introduced to integrate the former two strategies to balance exploration and exploitation in different stages of the evolutionary process. The suggested MSGSK algorithm is applied to five PV cases (SDM, DDM, Photowatt-PW201, STM6-40/36, and STP6-120/36). From the experimental data, it can be observed that MSGSK extracts the PV model parameters more precisely than the basic GSK. Furthermore, it exhibits faster convergence speed and higher accuracy compared to other advanced algorithms found in the literature.},
  archive      = {J_ISCI},
  author       = {Guojiang Xiong and Zaiyu Gu and Ali Wagdy Mohamed and Houssem R.E.H. Bouchekara and Ponnuthurai Nagaratnam Suganthan},
  doi          = {10.1016/j.ins.2024.120627},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120627},
  shortjournal = {Inf. Sci.},
  title        = {Accurate parameters extraction of photovoltaic models with multi-strategy gaining-sharing knowledge-based algorithm},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HFN: Heterogeneous feature network for multivariate time
series anomaly detection. <em>ISCI</em>, <em>670</em>, 120626. (<a
href="https://doi.org/10.1016/j.ins.2024.120626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the key step of anomaly detection for multivariate time-series (MTS) data, learning the relations among different variables has been explored by many approaches. However, most existing approaches overlook the heterogeneity among variables, that is, different types of variables (continuous numerical variables, discrete categorical variables or hybrid variables) may have different edge distributions. In this paper, we propose a novel semi-supervised anomaly detection framework based on a heterogeneous feature network (HFN) for MTS. Specifically, we first combine the embedding similarity subgraph generated by sensor embedding and the feature value similarity subgraph generated by sensor values to construct a time-series heterogeneous graph, which fully utilizes the rich heterogeneous mutual information among variables. Then, a prediction model containing nodes and channel attentions is jointly optimized to obtain better time-series representations. This approach fuses the state-of-the-art technologies of heterogeneous graph structure learning (HGSL) and representation learning. Experimental results on four sensor datasets from real-world applications demonstrate that our approach achieves more accurate anomaly detection compared to baseline methods, laying a foundation for the rapid positioning of anomalies.},
  archive      = {J_ISCI},
  author       = {Jun Zhan and Chengkun Wu and Canqun Yang and Qiucheng Miao and Xiandong Ma},
  doi          = {10.1016/j.ins.2024.120626},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120626},
  shortjournal = {Inf. Sci.},
  title        = {HFN: Heterogeneous feature network for multivariate time series anomaly detection},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantifying intragroup and intergroup connections in
non-disjoint groups in social networks: A comprehensive analysis
incorporating edges’ and nodes’ weights. <em>ISCI</em>, <em>670</em>,
120624. (<a href="https://doi.org/10.1016/j.ins.2024.120624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose generalizations of the EI index to quantify the distinction between intragroup and intergroup connections in social networks. These generalizations enable the analysis of interactions between non-disjoint groups, as large-scale disjoint groups are rarely found in many empirical networks. By expanding social network analysis, these measures facilitate the identification of actors with greater similarities or differences, generating previously untapped knowledge. Furthermore, we propose incorporating both edges&#39; and nodes&#39; weights in assessing the EI index. Intuitively, our approach classifies each network edge as internal or external, depending on the attribute groups that each node linked by the given edge belongs to. Since nodes can belong to more than one attribute group, three methods of classifying a network edge are proposed which depend on the number of shared groups by the pair of nodes. We evaluate the new measures in two distinct network contexts. The first context involves a co-authorship network, where researchers, acting as network actors, are categorized based on their respective areas of expertise in management engineering. The second network consists of trade relations among countries in the Americas, with countries grouped according to their participation in trade agreements. The analysis showed which area of management engineering is more independent by having more internal connections and made it possible to investigate the role of trade agreements in the actual trades made by countries. These proposals provide a more comprehensive and nuanced understanding of network dynamics, allowing for a more precise comprehension of interactions and patterns present in social systems.},
  archive      = {J_ISCI},
  author       = {Ricardo Lopes de Andrade and Leandro Chaves Rêgo},
  doi          = {10.1016/j.ins.2024.120624},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120624},
  shortjournal = {Inf. Sci.},
  title        = {Quantifying intragroup and intergroup connections in non-disjoint groups in social networks: A comprehensive analysis incorporating edges&#39; and nodes&#39; weights},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Group-aware graph neural networks for sequential
recommendation. <em>ISCI</em>, <em>670</em>, 120623. (<a
href="https://doi.org/10.1016/j.ins.2024.120623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendations play a crucial role in recommender systems. Existing methods commonly focus on extracting sequential patterns within individual item sequences to make personalized recommendations. However, this paper argues that such a closure strategy has limitations. Firstly, the inherent uncertainty and sparsity within these sequences pose considerable challenges in accurately capturing sequential patterns. Secondly, ignoring group behaviors beyond the sequence hinders the modeling of user similarities, which are essential for recommendations. To address these limitations, this paper proposes a novel collaborative sequential recommendation approach, called G roup- a ware G raph N eural N etworks (GaGNN). GaGNN seeks to incorporate group behaviors within sequential recommendations, thereby enhancing the modeling of user preferences through the assimilation of collective wisdom. GaGNN constructs two transition graphs, each offering a distinct behavioral perspective. The group transition graph is designed to capture the collaborative effects and learn collaborative information, whereas the individual transition graph aims to articulate individual behaviors, thereby extracting sequential information. Additionally, a multi-source information fusion module is designed to bridge semantic gaps between the two types of information and yield a holistic understanding of user preferences. Through rigorous experimental comparisons and ablation studies, the superiority of GaGNN and the beneficial integration of collaborative information are emphatically validated.},
  archive      = {J_ISCI},
  author       = {Zhen Huang and Zhongchuan Sun and Jiaming Liu and Yangdong Ye},
  doi          = {10.1016/j.ins.2024.120623},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120623},
  shortjournal = {Inf. Sci.},
  title        = {Group-aware graph neural networks for sequential recommendation},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interconnected takagi-sugeno system and fractional SIRS
malware propagation model for stabilization of wireless sensor networks.
<em>ISCI</em>, <em>670</em>, 120620. (<a
href="https://doi.org/10.1016/j.ins.2024.120620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to investigate the dynamical behaviors of malware attack on a familiar kind of complex heterogeneous networks, namely Wireless Sensor Network, and discuss an effective immunization treatment based on fractional interconnected Takagi-Sugeno (T-S) fuzzy systems. Our approach is based on the mathematical modeling to establish a controlled fractional network-based SIRS malware propagation model that better describes the attacking behavior of malicious objects on Wireless Sensor Network. After that, we point out some qualitative properties of the proposed network-based SIRS malware propagation model such as the existence of positively invariant set, backward bifurcation and asymptotic behavior. Especially, in order to study the model&#39;s stability, we evaluate an epidemiological threshold value R 0 R0 , namely basic reproductive ratio, which ensures the existence of at least one endemic equilibrium ⁎ P ⁎ P⁎ and the local asymptotic stability of malware-free equilibrium P 0 P0 . As a consequence of theoretical result, the malware-free equilibrium P 0 P0 is unstable when R 0 &gt; 1 R0&amp;gt;1 and hence, the rest of this paper is to address a stabilization problem for the proposed controlled network-based model and establish some sufficient conditions related to linear matrix inequalities and positive definite matrices. Finally, we illustrate the obtained theoretical results by a computational example.},
  archive      = {J_ISCI},
  author       = {Nguyen Phuong Dong and Nguyen Long Giang and Hoang Viet Long},
  doi          = {10.1016/j.ins.2024.120620},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120620},
  shortjournal = {Inf. Sci.},
  title        = {Interconnected takagi-sugeno system and fractional SIRS malware propagation model for stabilization of wireless sensor networks},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). The realistic tolerance solution to a system of linear
fuzzy and interval equations using the shifted membership function
method. <em>ISCI</em>, <em>670</em>, 120619. (<a
href="https://doi.org/10.1016/j.ins.2024.120619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite many years of research on fuzzy and interval equation systems, there are still great difficulties in solving them. The reason for this is the high degree of complexity of the problem. The article presents the Shifted Membership Function (SMF) method. It is characterized by several novelties. In contrast to the most commonly used methods based on α -cuts, the SMF-method uses a completely different approach. After determining with use of the multidimensional interval arithmetic the set of possible crisp solutions, the method determines one optimal crisp solution vector of the system. The search for this vector is done with use of shifted membership functions of left-hand sides of equations. Their positions and spans can be changed by changing values of elements of the control (decision) vector ( x 1 , x 2 ) T (x1,x2)T . The SMF-method solves tolerance problems that could not be solved before by the α -cuts method.},
  archive      = {J_ISCI},
  author       = {Andrzej Piegat and Marcin Pluciński},
  doi          = {10.1016/j.ins.2024.120619},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120619},
  shortjournal = {Inf. Sci.},
  title        = {The realistic tolerance solution to a system of linear fuzzy and interval equations using the shifted membership function method},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An attack-agnostic defense method against adversarial
attacks on speaker verification by fusing downsampling and upsampling of
speech signals. <em>ISCI</em>, <em>670</em>, 120618. (<a
href="https://doi.org/10.1016/j.ins.2024.120618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advance of deep learning, adversarial attack and defense has becoming a hot research topic. However, existing defense methods rely on the prior knowledge of the adversarial attacks, and are also vulnerable to adaptive attacks. In this paper, towards a secure automatic speaker verification system, a novel attack-agnostic defense method is proposed, named by SampleShield , which consists of a pairwise random downsampling (PRD) module and an upsampling module achieved by speech super-resolution (SSR). The PRD module can destroy the adversarial perturbations by downsampling, which also introduces randomness and non-differentiability, leading to its resistance to adaptive attacks. PRD does not use any adversarial example as training data, which makes it an attack-agnostic defense method with good generalization ability. Furthermore, the upsampling module achieved by a neural network can recover the downsampled speech to its original quality. In summary, given the experimental results and analysis on the benchmark public datasets, by fusing the downsampling and upsampling modules, SampleShield achieves excellent performance. On adversarial defense, SampleShield obtains an error rate about 5.2% which is quite close to the idea lower bound value 3.2%. On speech quality, SampleShield gets a 5 dB signal-to-noise ratio improvement with respect to the best existing method.},
  archive      = {J_ISCI},
  author       = {Yihao Li and Xiongwei Zhang and Meng Sun and Weiwei Chen and Yinan Li},
  doi          = {10.1016/j.ins.2024.120618},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120618},
  shortjournal = {Inf. Sci.},
  title        = {An attack-agnostic defense method against adversarial attacks on speaker verification by fusing downsampling and upsampling of speech signals},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). COCOA: Cost-optimized COunterfactuAl explanation method.
<em>ISCI</em>, <em>670</em>, 120616. (<a
href="https://doi.org/10.1016/j.ins.2024.120616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of artificial intelligence for decision support and automation has shown tremendous potential in many areas. The ability to explain the decisions made by a machine learning algorithm is fundamental to facilitating the widespread use of this type of tool. There are many important real-world problems where the cost of the decisions depends on the characteristics of each example: these are called example-dependent cost (EDC) problems. For this type of classification problem, an appropriate formulation that takes into account the decision costs is fundamental both for the design of the classifier and for the explanation of its decisions. In this paper, we propose COCOA, an explanation method designed for EDC problems based on a Bayesian discriminant. The proposed method can provide counterfactual samples generated by considering decision costs. The COCOA method provides valid and plausible counterfactuals with a high success rate, which can be actionable, diverse, and sparse, achieving a remarkable improvement in terms of cost over five state-of-the-art methods on six real-world datasets.},
  archive      = {J_ISCI},
  author       = {Javier Mediavilla-Relaño and Marcelino Lázaro},
  doi          = {10.1016/j.ins.2024.120616},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120616},
  shortjournal = {Inf. Sci.},
  title        = {COCOA: Cost-optimized COunterfactuAl explanation method},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Homotopic ADP based h∞ integral sliding mode secure control
for markov jumping cyber-physical systems. <em>ISCI</em>, <em>670</em>,
120615. (<a href="https://doi.org/10.1016/j.ins.2024.120615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the sliding mode secure control problem for continuous-time cyber-physical systems (CPSs) subject to unmatched disturbances and actuator deception attacks. To capture different operating conditions and account for random component failures in CPSs, a Markov jumping model is introduced to characterize the system&#39;s component matrices. Next, a novel model-free integral sliding mode function and a corresponding sliding mode controller are presented to mitigate the impact of external disturbances and deception attacks on Markov jumping cyber-physical systems. An algorithm based on adaptive dynamic programming (ADP) and homotopic policy iteration (PI) is applied to develop the sliding mode controller, called the online homotopic ADP algorithm, which avoids the requirement for an initial stabilizing matrix compared to existing PI algorithms. Lastly, the mode-independent integral sliding mode control scheme is studied to a two-mode Markov jumping vertical take-off and landing helicopter system, providing guaranteed reachability of sliding variables and stability of sliding mode dynamics. Importantly, this is achieved without any reliance on knowledge of system dynamics.},
  archive      = {J_ISCI},
  author       = {Hai Wang and Gang Qin and Jun Cheng and Shengda Tang},
  doi          = {10.1016/j.ins.2024.120615},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120615},
  shortjournal = {Inf. Sci.},
  title        = {Homotopic ADP based h∞ integral sliding mode secure control for markov jumping cyber-physical systems},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient computation of top-k g-skyline groups on
large-scale database. <em>ISCI</em>, <em>670</em>, 120614. (<a
href="https://doi.org/10.1016/j.ins.2024.120614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The G-Skyline query aims to return the best groups that are not g-dominated by any other group of equal size; this approach plays an important role in many fields, such as multiobjective decision-making. The top- k G-Skyline query has important implications since the output size of the G-Skyline query is often too large to make decisions. Due to the massive number of candidate groups and the high index construction consumption, the existing top- k G-Skyline algorithms cannot handle large-scale databases well. In this paper, an efficient algorithm is proposed called the TGPE ( T op- k G -Skyline algorithm based on P resorting and E numeration) to rapidly compute the top- k G-Skyline groups for large-scale databases. TGPE proposes an efficient scanning method based on a presorted table to obtain tuples making up G-Skyline groups and their dominant relationships. TGPE does not need to repeatedly reconstruct the index for different skyline criteria. Three computational lemmas are presented based on sorting information and monotonicity, and they are utilized to reduce the number of candidate groups to obtain results rapidly. Finally, extensive experiments on synthetic and real datasets verify that TGPE has significant performance advantages over those of the existing algorithms.},
  archive      = {J_ISCI},
  author       = {Kangao Wang and Xixian Han and Xiaolong Wan and Jinbao Wang},
  doi          = {10.1016/j.ins.2024.120614},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120614},
  shortjournal = {Inf. Sci.},
  title        = {Efficient computation of top-k G-skyline groups on large-scale database},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Enhancing relation extraction using multi-task learning
with SDP evidence. <em>ISCI</em>, <em>670</em>, 120610. (<a
href="https://doi.org/10.1016/j.ins.2024.120610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation extraction (RE) is a crucial subtask of information extraction, which involves recognizing the relation between entity pairs in a sentence. Previous studies have extensively employed syntactic information, notably the shortest dependency path (SDP), to collect word evidence, termed SDP evidence, which gives clues about the given entity pair, thus improving RE. Nevertheless, prevalent transformer-based techniques lack syntactic information and cannot effectively model essential syntactic clues to support relations. This study exerts multi-task learning to address these issues by imbibing an SDP token position prediction task into the RE task. To this end, we introduce SGA, an SDP evidence guiding approach that transfers the SDP evidence into two novel supervisory signal labels: SDP tokens label and SDP matrix label. The former guides the attention modules to assign high attention weights to SDP token positions, emphasizing relational clues. In the meantime, the latter supervises SGA to predict a parameterized asymmetric product matrix among the SDP tokens for RE. Experimental outcomes demonstrate the model&#39;s enhanced ability to leverage SDP information, thereby directing attention modules and predicted matrix labels to focus on SDP evidence. Consequently, our proposed approach surpasses existing publicly available optimal baselines across four RE datasets: SemEval2010-Task8, KBP37, NYT, and WebNLG. 1},
  archive      = {J_ISCI},
  author       = {Hailin Wang and Dan Zhang and Guisong Liu and Li Huang and Ke Qin},
  doi          = {10.1016/j.ins.2024.120610},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120610},
  shortjournal = {Inf. Sci.},
  title        = {Enhancing relation extraction using multi-task learning with SDP evidence},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wasserstein distance regularized graph neural networks.
<em>ISCI</em>, <em>670</em>, 120608. (<a
href="https://doi.org/10.1016/j.ins.2024.120608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distribution shift widely exists in graph representation learning and often reduces model performance. This work investigates how to improve the performance of a graph neural network (GNN) in a single graph by controlling distribution shift between embedding spaces. Specifically, we provide an upper error-bound estimation, which quantitatively analyzes how distribution shift affects GNNs&#39; performance in a single graph. Considering that there is no natural domain division in a single graph, we propose PW-GNN to simultaneously learn discriminative embedding and reduce distribution shift. PW-GNN measures distribution discrepancy using the distance between test embeddings and prototypes, and transfers minimizing distribution shift to minimizing the power of Wasserstein distance, which is introduced into GNNs as a regularizer. A series of theoretical analyses are carried out to demonstrate the effectiveness of PW-GNN. Besides, a low-complexity training algorithm is designed by exploring entropy-regularized strategy and block coordinate descent method. Extensive numerical experiments are conducted on different datasets with both biased and unbiased splits. We empirically test our model equipped with four backbone models. Results show that PW-GNN outperforms state-of-the-art baselines and mitigates up to 8% of negative effects off distribution shift on backbones.},
  archive      = {J_ISCI},
  author       = {Yong Shi and Lei Zheng and Pei Quan and Lingfeng Niu},
  doi          = {10.1016/j.ins.2024.120608},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120608},
  shortjournal = {Inf. Sci.},
  title        = {Wasserstein distance regularized graph neural networks},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boosting scalability for large-scale multiobjective
optimization via transfer weights. <em>ISCI</em>, <em>670</em>, 120607.
(<a href="https://doi.org/10.1016/j.ins.2024.120607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale multiobjective optimization problems (LSMOPs), which optimize multiple conflicting objectives with hundreds or even thousands of decision variables, demand increasing computational resources to assure satisfactory performance as the decision variables increase. Multiobjective evolutionary algorithms are naturally scalable, but as the dimension increases, the conflict between analyzing enough solutions and the limited number of function evaluations has hindered further improvements in scalability. In this paper, we first define the scalability of multiobjective evolutionary algorithms and design an indicator to quantitatively measure the scalability. Second, to boost scalability when solving LSMOPs, we propose a scalable multiobjective optimization algorithm by transferring weights between solutions to reduce dependency on ever-increasing computational resources as the problem dimension increases. The proposed framework entails constructing a latent decision space to determine evolutionary weights for chosen representative solutions. These computed weights are then transferred to the remaining solutions, enabling evolutionary optimization to proceed without requiring additional evaluations, even as the dimensionality increases. By utilizing the knowledge gained from the source solutions, each solution is customized with an evolutionary weight scheme that not only preserves computational resources but also enhances optimization performance, thereby boosting scalability. We have conducted experiments on LSMOPs to verify the effectiveness and scalability of the proposed algorithm. The proposed method outperforms selected state-of-the-art algorithms and gains scalability boosts in situations where the dimensions increase while the function evaluation remains constant.},
  archive      = {J_ISCI},
  author       = {Haokai Hong and Min Jiang and Gary G. Yen},
  doi          = {10.1016/j.ins.2024.120607},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120607},
  shortjournal = {Inf. Sci.},
  title        = {Boosting scalability for large-scale multiobjective optimization via transfer weights},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A maximum satisfaction consensus-based large-scale group
decision-making in social network considering limited compromise
behavior. <em>ISCI</em>, <em>670</em>, 120606. (<a
href="https://doi.org/10.1016/j.ins.2024.120606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the enrichment of social platforms, large-scale group decision-making (LSGDM) in social networks has gradually taken shape. In practice, experts may show limited compromise behavior during consensus reaching process (CRP), which may lead to bias or even failure in decision-making results. To tackle this issue, considering limited compromise behavior, this paper proposes a maximum satisfaction consensus (MSC) model, and focusing on LSGDM with fuzzy preference relation in social networks. Firstly, an expert weight determination algorithm integrating the interactive weights and individual weights is constructed. The interactive weights are determined by social influence strength, while the individual weights are measured by the compromise degree of limited compromise behavior and the consistency level of preferences. Subsequently, a grey clustering method is developed to classify experts into subgroups, considering both opinions similarity and limited compromise behavior similarity. In CRP, considering the limited compromise behavior, an MSC model under the limited budget determined by the minimum cost consensus (MCC) model is proposed. Based on MSC and MCC models, satisfaction-cost ratio is defined to measure the efficiency of CRP. Finally, a case study of selecting of shared bicycle operators and further discussion are conducted to verify the feasibility and superiority of the study.},
  archive      = {J_ISCI},
  author       = {Yuan Xu and Haiyan Xu},
  doi          = {10.1016/j.ins.2024.120606},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120606},
  shortjournal = {Inf. Sci.},
  title        = {A maximum satisfaction consensus-based large-scale group decision-making in social network considering limited compromise behavior},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-level feature assessment for unsupervised multi-view
feature selection with latent space learning. <em>ISCI</em>,
<em>670</em>, 120604. (<a
href="https://doi.org/10.1016/j.ins.2024.120604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, numerous unsupervised multi-view feature selection methods have been presented. However, these methods assess the significance of data features in each view individually or jointly evaluate the significance of data features across multiple views by concatenating data features from all data views. So, they disregard either inter-view or intra-view feature connections of data. Moreover, they ignore the complementary information from multiple insufficient views, each of which only captures partial information of multi-view data and is insufficient to characterize data distribution. To address these problems, this paper proposes a model named Dual-level Feature Assessment for Unsupervised Multi-view Feature Selection with Latent Space Learning (DFA-LSL). It first investigates the underlying complementary information from multiple views in a latent space while simultaneously learning latent representations for data. Compared with the original data representations, the latent representations contain the entire information of multi-view data. Then, it explores connections and distinguishing ability of features at two levels, namely the inter-view and intra-view levels, by jointly assessing the significance of features in the latent space and individually assessing the significance of features in each view concurrently. Following that, an effective optimization algorithm is presented. Extensive experiments demonstrate that the proposed work surpasses several state-of-the-art models.},
  archive      = {J_ISCI},
  author       = {Jian-Sheng Wu and Jun-Xiao Gong and Jing-Xin Liu and Wei Huang and Wei-Shi Zheng},
  doi          = {10.1016/j.ins.2024.120604},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120604},
  shortjournal = {Inf. Sci.},
  title        = {Dual-level feature assessment for unsupervised multi-view feature selection with latent space learning},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Secure adaptive event-triggered anti-synchronization for BAM
neural networks with energy-limited DoS attacks. <em>ISCI</em>,
<em>670</em>, 120594. (<a
href="https://doi.org/10.1016/j.ins.2024.120594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on the problem of adaptive event-triggered anti-synchronization control for bidirectional associative memory neural networks subject to energy-limited denial of service attacks. First, a novel adaptive event-triggered scheme is developed by resorting to the acknowledgment character technique, which can help conserve valuable communication resources and has better performance in resisting malicious cyber attacks compared to traditional schemes. Second, a more general attack strategy for denial of service attacks is proposed with the consideration of energy constraints, and an anti-synchronization error system is established to analyze the anti-synchronization behavior. Then, sufficient conditions are provided to guarantee the anti-synchronization of drive and response bidirectional associative memory neural networks in H ∞ H∞ sense. Next, a design approach is obtained based on the above conditions for the controller gains. Finally, a numerical example is employed to demonstrate the effectiveness of the proposed method and its superiority over the traditional event-triggered scheme.},
  archive      = {J_ISCI},
  author       = {Hekai Feng and Zhenyu Wu and Xuexi Zhang and Zehui Xiao and Meng Zhang and Jie Tao},
  doi          = {10.1016/j.ins.2024.120594},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120594},
  shortjournal = {Inf. Sci.},
  title        = {Secure adaptive event-triggered anti-synchronization for BAM neural networks with energy-limited DoS attacks},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time filtering design with past output measurements
for interval type-2 fuzzy systems: A descriptor approach. <em>ISCI</em>,
<em>670</em>, 120593. (<a
href="https://doi.org/10.1016/j.ins.2024.120593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is interested in the design of full-order H ∞ H∞ memory filters for discrete-time nonlinear systems within finite-time domain. First, the investigated nonlinear systems are modeled by a Takagi–Sugeno fuzzy technique for the interval type-2 case. And to reduce the size of the model, only the past measurements of systems are involved during the memory filters construction. Then, novel design processes with less conservatism are proposed through executing a decoupling transformation for the filtering error dynamics. Based on Lyapunov methods together with several strategies that apply convex optimization techniques and slack variables, some sufficient conditions are presented and certified to solve the memory filter parameters, such that the augmented error dynamics are singular finite-time bounded with prescribed H ∞ H∞ performance. Finally, an example is introduced to illustrate the effectiveness of the proposed strategy in contrast to existent works.},
  archive      = {J_ISCI},
  author       = {Zehui Xiao and Jie Tao and Meng Zhang and Renquan Lu},
  doi          = {10.1016/j.ins.2024.120593},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120593},
  shortjournal = {Inf. Sci.},
  title        = {Finite-time filtering design with past output measurements for interval type-2 fuzzy systems: A descriptor approach},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enabling privacy-preserving non-interactive computation for
hamming distance. <em>ISCI</em>, <em>670</em>, 120592. (<a
href="https://doi.org/10.1016/j.ins.2024.120592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hamming distance is a measure of the similarity between two strings of the same length. Privacy-preserving Hamming distance computation allows data users to obtain the Hamming distance between their data without disclosing their respective private data. The existing privacy-preserving protocols for Hamming distance computation require multiple rounds of online interactive computation between two data users. To address this issue, we propose a new Privacy-preserving non-interactive Hamming Distance Computation (PHDC) protocol. Different from previous works, we adopt the strategy of secure outsourcing to avoid the online interactive computation between data users. We move the Hamming distance computation from the user side to the cloud side. The cloud server is responsible for the Hamming distance computation under privacy protection. To preserve data privacy, we propose a novel blinding technique for user data. Data users initially blind their data using homomorphic encryption and randomization techniques. The edge server is responsible for data aggregation and further data blindness. In this way, data users only need to outsource their encrypted data to the edge server, and there is no online interactive computation between data users. With the assistance of the edge server and the cloud server, the privacy-preserving Hamming distance computation is achieved. The security analysis demonstrates that the protocol guarantees the data privacy under the semi-honest adversarial model. The theoretical analysis and experimental results illustrate the efficiency of the proposed protocol.},
  archive      = {J_ISCI},
  author       = {Wenjing Gao and Wei Liang and Rong Hao and Jia Yu},
  doi          = {10.1016/j.ins.2024.120592},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120592},
  shortjournal = {Inf. Sci.},
  title        = {Enabling privacy-preserving non-interactive computation for hamming distance},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse l0-norm least squares support vector machine with
feature selection. <em>ISCI</em>, <em>670</em>, 120591. (<a
href="https://doi.org/10.1016/j.ins.2024.120591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Least squares support vector machine (LSSVM) is a powerful classification tool based on hyperplanes. But the classical LSSVM does not perform well on small sample size data sets (SSS) because it lacks feature selection capability. To address this issue, we introduce an L 0 L0 -norm regularization term into the objective function of LSSVM, and propose a new sparse LSSVM model called L 0 L0 -LSSVM. However, the introduction of the L 0 L0 -norm makes the resulting optimization problem nonconvex and nonsmooth. To overcome these challenges, instead of using the traditional convex or non-convex approximation of the L 0 L0 -norm, we design an efficient algorithm for L 0 L0 -LSSVM based on alternating direction method of multipliers (ADMM) where the L 0 L0 -norm is handled by employing the proximity operator. Numerical results demonstrate that L 0 L0 -LSSVM not only exhibits excellent generalization performance and feature selection capability but also offers a substantial improvement in computational speed.},
  archive      = {J_ISCI},
  author       = {Qingqing Tang and Guoquan Li},
  doi          = {10.1016/j.ins.2024.120591},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120591},
  shortjournal = {Inf. Sci.},
  title        = {Sparse l0-norm least squares support vector machine with feature selection},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A prediction model for rumor user propagation behavior based
on sparse representation and transfer learning. <em>ISCI</em>,
<em>670</em>, 120590. (<a
href="https://doi.org/10.1016/j.ins.2024.120590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a prediction model rooted in sparse representation and transfer learning, with the primary objective of predicting user behavior during rumor propagation. Users&#39; behavior is dynamic, and rumor, rumor-refuting, and rumor-promoting messages interact dynamically, according to the model. Firstly, this paper proposes to compensate for the low performance of propagation prediction models due to data sparsity at the beginning of rumor topics&#39; lifes. Transfer learning is used to compensate for the data sparsity problem at the beginning of the topic. To map the rumor topic space effectively, a low-rank dense vectorization algorithm based on sparse representation is proposed. Finally, to mine the potential impact of multiple types of information on users, a model based on three-party game theory is constructed. It considers the complex interaction between rumor, rumor-refuting, and rumor-promoting information in the propagation of rumor. Additionally, this paper develops a model of dynamic user behavior prediction using Rumor-Attention-Mechanism-Graph-Attention (RAM-GAT) to predict rumor propagation. Experiments demonstrate that our model can effectively mine the interaction influence between multiple types of information. It can accurately predict user behavior when initial data is insufficient. In addition, rumor propagation patterns and trends are revealed.},
  archive      = {J_ISCI},
  author       = {Yunpeng Xiao and Yu Zhang and Cong Zeng and Tun Li and Rong Wang and Qian Li and Chaolong Jia},
  doi          = {10.1016/j.ins.2024.120590},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120590},
  shortjournal = {Inf. Sci.},
  title        = {A prediction model for rumor user propagation behavior based on sparse representation and transfer learning},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized multiplicative fuzzy possibilistic product
partition c-means clustering. <em>ISCI</em>, <em>670</em>, 120588. (<a
href="https://doi.org/10.1016/j.ins.2024.120588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regarding the defects of Ruspini partition-based clustering in revealing the intrinsic correlation between classes, this paper proposes a series of generalized multiplicative fuzzy possibilistic product partition clustering algorithms. First, based on the existing concept of generalized multiplicative intuitionistic fuzzy sets, this paper introduces a new concept of generalized multiplicative fuzzy sets and further defines the corresponding multiplicative fuzzy partition. Then, based on the concept of multiplicative fuzzy partition, a novel generalized multiplicative fuzzy possibilistic product partition C-means (GMFPCM) clustering algorithm is presented, and its local convergence is strictly proved using Zangwill’s theorem. Meanwhile, a robust Gaussian-base radial kernel based on the M-estimator is introduced into the GMFPCM algorithm to improve its robustness against noise and outliers in numerical data. Additionally, a multiplicative fuzzy possibilistic local information factor is constructed and embedded into the GMFPCM algorithm to strengthen its ability to suppress noise in images. Finally, the comparison with existing fuzzy possibilistic clustering algorithms in the literature confirms the competitiveness of the proposed algorithms.},
  archive      = {J_ISCI},
  author       = {Chengmao Wu and Meng Li},
  doi          = {10.1016/j.ins.2024.120588},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120588},
  shortjournal = {Inf. Sci.},
  title        = {Generalized multiplicative fuzzy possibilistic product partition C-means clustering},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel consensus model considering individual and social
behaviors under the social trust network. <em>ISCI</em>, <em>670</em>,
120587. (<a href="https://doi.org/10.1016/j.ins.2024.120587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical decision-making scenarios, the challenges lie in obtaining the collective opinion that the majority of decision makers are willing to accept, thereby arriving at the final decision result. Among them, both the inherent uncertainty and reliability embedded in the information may lead to a deviation from the fact in the final decision result. Moreover, individual and social behaviors have the potential to influence the acquisition of effective decision result. Based on this, this paper constructs a novel social network-based consensus model under discrete Z -number environment, taking into account the individual and social behaviors of experts. First, novel trust propagation and trust aggregation operators with discrete Z -numbers are developed, which aim to form a complete social trust network. Then, unit consensus cost function and compromise boundary function based on social trust network are given to objectively determine the unit adjustment costs and compromise boundaries of each decision maker. In addition, a minimum cost consensus model considering the coexistence and interaction between individual and social behaviors is explored. Last, the feasibility and superiority of the model are proved through a case of the agricultural supply chain. Through simulation and comparative analysis, the results show the effectiveness of novel trust propagation and aggregation operators. And the necessity of considering individual and social behaviors for consensus reaching process is presented.},
  archive      = {J_ISCI},
  author       = {Fei Teng and Xinran Liu and Xin Dong and Peide Liu},
  doi          = {10.1016/j.ins.2024.120587},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120587},
  shortjournal = {Inf. Sci.},
  title        = {A novel consensus model considering individual and social behaviors under the social trust network},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cluster structure augmented deep nonnegative matrix
factorization with low-rank tensor learning. <em>ISCI</em>,
<em>670</em>, 120585. (<a
href="https://doi.org/10.1016/j.ins.2024.120585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering approaches based on deep nonnegative matrix factorization have received significant attention because it can learn hierarchical semantics from data in a layer-wise manner. However, latent representation learning and clustering are two separate processes in these models, leading to information loss and sub-optimal clusterings. Furthermore, if data contain complex structure or noise, the pre-defined graph in data space will not be precise enough for graph-regularized deep nonnegative matrix factorization models. Moreover, most of them maintain the similarity graph at the top layer, neglecting the information covered by other layers. In this paper, Cluster Structure Augmented Deep Nonnegative Matrix Factorization with Low-rank Tensor Learning is proposed. First, as representations at different layers cover different data abstractions, a learning mechanism is leveraged to generate multiple local similarity graphs based on representations from different layers, thus maintaining diversity across layers. Then, a low-rank third-order tensor is constructed by stacking these graphs to capture the high-order consistency across layers, thus capturing the intrinsic property of data. Third, clustering is integrated into the framework, allowing the cluster structure to facilitate multi-layer matrix factorization and graph structure learning, thereby generating discriminative representations. Experimental results on several datasets demonstrate that the proposed model outperforms several state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Bo Zhong and Jian-Sheng Wu and Wei Huang and Wei-Shi Zheng},
  doi          = {10.1016/j.ins.2024.120585},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120585},
  shortjournal = {Inf. Sci.},
  title        = {Cluster structure augmented deep nonnegative matrix factorization with low-rank tensor learning},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analytical solution to partial least squares. <em>ISCI</em>,
<em>670</em>, 120583. (<a
href="https://doi.org/10.1016/j.ins.2024.120583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial least squares (PLS) is a widely used multivariate statistical technique, which can be used in neuroimaging, process monitoring, economics, etc. Because the standard PLS is trained by nonlinear iterative partial least squares (NIPALS) algorithm, which can only obtain the numerical solution rather than the analytical solution. Therefore, it is hard for the subsequent theoretical analysis in PLS and the iterative optimization process is computationally intensive. This paper proposes an analytical solution to take the place of NIPALS. This determination meaningfully contributes to future theoretical analysis of PLS. In addition, the analytical solution demonstrates that the selection of initial vector in NIPALS does not affect the PLS training results. Moreover, the analytical solution avoids the multiple iterative calculations, so the divergence of the calculation process will be avoided and the computation burden will be reduced significantly.},
  archive      = {J_ISCI},
  author       = {Zhijiang Lou and Shan Lu and Youqing Wang and Xin Ma},
  doi          = {10.1016/j.ins.2024.120583},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120583},
  shortjournal = {Inf. Sci.},
  title        = {Analytical solution to partial least squares},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DeFTA: A plug-and-play peer-to-peer decentralized federated
learning framework. <em>ISCI</em>, <em>670</em>, 120582. (<a
href="https://doi.org/10.1016/j.ins.2024.120582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a pivotal catalyst for enabling large-scale privacy-preserving distributed machine learning (ML). By eliminating the need for local raw dataset sharing, FL substantially reduces privacy concerns and alleviates the isolated data problem. However, in reality, the success of FL is predominantly attributed to a centralized framework called FedAvg [1] , in which workers are responsible for model training, and servers are in control of model aggregation. Nevertheless, FedAvg&#39;s centralized worker-server architecture has raised new concerns, including low scalability of the cluster, risk of data leakage, and central server failure or even defection. To overcome these challenges, we propose De centralized F ederated T rusted A veraging (DeFTA), a decentralized FL framework that serves as a plug-and-play replacement for FedAvg , bringing instant improvements to security, scalability, and fault-tolerance in the federated learning process. In essence, it primarily consists of a novel model aggregating formula with theoretical performance analysis, and a decentralized trust system (DTS) to significantly enhance system robustness. Extensive experiments conducted on six datasets and six basic models suggest that DeFTA not only exhibits comparable performance with FedAvg in a more realistic setting, but also achieves remarkable resilience even when 67% of workers are malicious.},
  archive      = {J_ISCI},
  author       = {Yuhao Zhou and Minjia Shi and Yuxin Tian and Qing Ye and Jiancheng Lv},
  doi          = {10.1016/j.ins.2024.120582},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120582},
  shortjournal = {Inf. Sci.},
  title        = {DeFTA: A plug-and-play peer-to-peer decentralized federated learning framework},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CAT-unet: An enhanced u-net architecture with coordinate
attention and skip-neighborhood attention transformer for medical image
segmentation. <em>ISCI</em>, <em>670</em>, 120578. (<a
href="https://doi.org/10.1016/j.ins.2024.120578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of deep learning, the U-Net network, based on a U-shaped architecture and skip connections, has found widespread application in various medical image segmentation tasks. However, the receptive field of the standard convolution operation is limited, because it is difficult to achieve global and long-distance semantic information interaction. Inspired by the advantages of ConvNext and Neighborhood Attention (NA), we propose CAT-Unet in this study to address the aforementioned challenges. We effectively reduce the number of parameters by utilizing large kernels and depthwise separable convolutions. Meanwhile, we introduce a Coordinate Attention (CA) module, which enables the model to learn more comprehensive and contextual information from surrounding regions. Furthermore, we introduce Skip-NAT (Neighborhood Attention Transformer) as the main algorithmic framework, replacing U-Net&#39;s original skip-connection layers, to lessen the impact of shallow features on network efficiency. Experimental results show that CAT-Unet achieves better segmentation results. On the ISIC2018 dataset, the best results for Dice (Dice Coefficient), IoU (Intersection over Union), and HD (Hausdorff Distance) are 90.26%, 83.58%, and 4.259, respectively. For the PH2 dataset, the best Dice, IoU, and HD results are 96.49%, 91.81%, and 3.971, respectively. Finally, on the DSB2018 dataset, the best Dice, IoU, and HD results are 94.58%, 88.78%, and 3.749, respectively.},
  archive      = {J_ISCI},
  author       = {Zhiquan Ding and Yuejin Zhang and Chenxin Zhu and Guolong Zhang and Xiong Li and Nan Jiang and Yue Que and Yuanyuan Peng and Xiaohui Guan},
  doi          = {10.1016/j.ins.2024.120578},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120578},
  shortjournal = {Inf. Sci.},
  title        = {CAT-unet: An enhanced U-net architecture with coordinate attention and skip-neighborhood attention transformer for medical image segmentation},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AKA-SafeMed: A safe medication recommendation based on
attention mechanism and knowledge augmentation. <em>ISCI</em>,
<em>670</em>, 120577. (<a
href="https://doi.org/10.1016/j.ins.2024.120577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medication recommendation (MR) focuses on generating a medication combination without adverse drug-drug interactions (DDIs) based on electronic health records (EHRs) in making prescriptions. However, how to capture the temporality in historical visits and concurrence in clinical events are two challenges that determine the outcomes of an MR model. To achieve effective and safe MR with imbalanced EHR data, we propose a medication recommendation model based on the attention mechanism and knowledge augmentation strategy (AKA-SafeMed). Specifically, in the patient representation module, bidirectional long short-term memory (BiLSTM) models are deployed to encode the patient&#39;s sequential visits, and a self-attention mechanism is employed to learn the weights of diagnosis and procedure vectors from a patient&#39;s historical visits; in the medication generation module, the EHR and DDI graphs are leveraged to fully explore the relationships between pairwise drugs as a knowledge augmentation strategy. Finally, extensive experiments are conducted to evaluate the performance of AKA-SafeMed on public EHR datasets. The experimental results demonstrate that the AKA-SafeMed model achieves superior performance in MR tasks compared with the state-of-the-art baseline models.},
  archive      = {J_ISCI},
  author       = {Xiaomei Yu and Xue Li and Fangcao Zhao and Xiaoyan Yan and Xiangwei Zheng and Tao Li},
  doi          = {10.1016/j.ins.2024.120577},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120577},
  shortjournal = {Inf. Sci.},
  title        = {AKA-SafeMed: A safe medication recommendation based on attention mechanism and knowledge augmentation},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PIAENet: Pyramid integration and attention enhanced network
for object detection. <em>ISCI</em>, <em>670</em>, 120576. (<a
href="https://doi.org/10.1016/j.ins.2024.120576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is a challenging task that requires a trade-off between accuracy and efficiency. Previous approaches have focused mainly on optimizing one aspect at the expense of the other, making them unsuitable for resource-constrained devices. To address this issue, we propose a new object detection network architecture, the Pyramid Integration and Attention Enhanced Network (PIAENet). PIAENet is a lightweight architecture that can achieve high accuracy and efficiency. We utilize a lightweight EfficientNet-B2 backbone for feature extraction to maintain accuracy while reducing computational overhead. The core components of PIAENet, the Pyramid Integration Module (PIM) and the Attention Enhanced Module (AEM), work together to improve the performance of object detection. PIM fuses multi-scale features using multiple branches to enhance the receptive field of the model, while AEM strengthens the fusion of features using two attention mechanisms to suppress the influence of irrelevant information. Our proposed method has been evaluated on the PASCAL VOC and KITTI datasets. The results have shown our method outperforms most of the existing state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Xiangyan Tang and Wenhang Xu and Keqiu Li and Mengxue Han and Zhizhong Ma and Ruili Wang},
  doi          = {10.1016/j.ins.2024.120576},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120576},
  shortjournal = {Inf. Sci.},
  title        = {PIAENet: Pyramid integration and attention enhanced network for object detection},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximation of functions from korobov spaces by shallow
neural networks. <em>ISCI</em>, <em>670</em>, 120573. (<a
href="https://doi.org/10.1016/j.ins.2024.120573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the problem of approximating functions from a Korobov space on [ − 1 , 1 ] d [−1,1]d by ReLU shallow neural networks and present a rate O ( m − 2 5 ( 1 + 2 d ) log ⁡ m ) O(m−25(1+2d)log⁡m) of uniform approximation by networks of m hidden neurons. This is achieved by combining a novel Fourier analysis approach and a probability argument. We apply our approximation theory to a learning algorithm for regression based on ReLU shallow neural networks and derive learning rates of order O ( N − 4 ( d + 2 ) 9 d + 8 log ⁡ N ) O(N−4(d+2)9d+8log⁡N) for the excess generalization error with the sample size N when the regression function lies in the Korobov space.},
  archive      = {J_ISCI},
  author       = {Yuqing Liu and Tong Mao and Ding-Xuan Zhou},
  doi          = {10.1016/j.ins.2024.120573},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120573},
  shortjournal = {Inf. Sci.},
  title        = {Approximation of functions from korobov spaces by shallow neural networks},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Consistency-guided pseudo labeling for transductive
zero-shot learning. <em>ISCI</em>, <em>670</em>, 120572. (<a
href="https://doi.org/10.1016/j.ins.2024.120572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning (ZSL) aims to recognize unseen classes during training. Transductive methods have advanced in ZSL, however, often rely on pseudo labels based on confidence scores, leading to semantic misalignment between unseen-class image features and corresponding class semantic descriptions due to noisy pseudo labels. In this paper, we introduce a novel Consistency-Guided Pseudo-Labeling (CGPL) to generate high-quality pseudo labels, achieving robust mapping from visual to semantic space for unseen classes. CGPL incorporates a large-scale vision-language model as a collaborator with the ZSL model to generate high-quality pseudo-labels. Then, pseudo-labeled samples with consistent prediction of two models are added to the training set, to learn the visual-to-semantic mapping for unseen classes. Furthermore, we design a quasi-classification loss based on reconstructed unseen prototypes to learn accurate visual-semantic mapping. Consequently, CGPL is further encouraged to obtain higher-quality pseudo labels, and progressively learn the precise visual-semantic mapping for unseen classes throughout the iterative process. Our extensive experimental results across four benchmark datasets highlight the superior performance of CGPL in both CZSL and GZSL settings.},
  archive      = {J_ISCI},
  author       = {Hairui Yang and Ning Wang and Zhihui Wang and Lei Wang and Haojie Li},
  doi          = {10.1016/j.ins.2024.120572},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120572},
  shortjournal = {Inf. Sci.},
  title        = {Consistency-guided pseudo labeling for transductive zero-shot learning},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved stochastic configuration networks with vision patch
fusion method for industrial image classification. <em>ISCI</em>,
<em>670</em>, 120570. (<a
href="https://doi.org/10.1016/j.ins.2024.120570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper contributes to the advancement of stochastic configuration neural networks (SCN) in the field of visual applications. The proposed image classification randomized algorithm is an extension of deep stochastic configuration networks (DeepSCN), known as an improved SCN with vision patch fusion (Vi-SCN). Compared to existing two dimensional stochastic configuration networks (2DSCN) and DeepSCN, we have developed an incremental modeling method that employs a stochastic configuration patch fusion method. This method extracts randomly fused image features from three-channel high-resolution image data, improving the network&#39;s ability to extract features. Moreover, we have introduced a strategy for dynamically determining the depth structure of the network, enabling flexible adjustments to the network structure and the number of nodes in each layer based on the complexity of image recognition tasks. Through a series of comparisons on four image classification benchmark datasets, we assess the superior learning performance of our design compared to 2DSCN and DeepSCN. Furthermore, to evaluate the performance of Vi-SCN in practical visual application scenarios, we collect three industrial datasets with distinct characteristics. Vi-SCN demonstrate outstanding performance in all three tasks, showing its significant potential in image recognition.},
  archive      = {J_ISCI},
  author       = {Ruilin Li and Wenhua Jiao and Yongjun Zhu},
  doi          = {10.1016/j.ins.2024.120570},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120570},
  shortjournal = {Inf. Sci.},
  title        = {Improved stochastic configuration networks with vision patch fusion method for industrial image classification},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accurate multiclassification and segmentation of gastric
cancer based on a hybrid cascaded deep learning model with a vision
transformer from endoscopic images. <em>ISCI</em>, <em>670</em>, 120568.
(<a href="https://doi.org/10.1016/j.ins.2024.120568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with other forms of cancer, gastric cancer has high mortality and incidence rates, making it a major cause of death worldwide. Accurate diagnosis is crucial in the treatment of stomach cancer. Researchers have used deep learning techniques facilitated by developments in artificial intelligence to classify and segment endoscopic images of stomach cancer. Most recent research examining endoscopic images of stomach cancer has used a binary classification system, which is insufficient for practical use. False-positives and computational costs become problematic when segmentation is applied to all the images of healthy patients obtained throughout the evaluation. Hence, the expected level of performance has not been attained in the real-time multiclassification and segmentation of stomach cancer. In this study, we present a deep learning-based technique for multiclassification of endoscopic images by combining modified GoogLeNet and vision transformer (ViT) models and identifying invasive areas based on Faster R-CNN. The classification of endoscopic images into three categories, namely, normal, early gastric cancer, and advanced gastric cancer, is accomplished by using a hybrid approach including modified GoogLeNet and vision transformer (ViT) models. Gastric cancer regions are then identified and segmented in the endoscopic images using the Faster R-CNN method. The Faster R-CNN algorithm is used with an endoscopic image as input, resulting in the generation of a bounding box and label image that accurately represents the gastric cancerous area. The proposed model achieved an accuracy, sensitivity and F1-score of 97.4%, 97.5% and 95.9%, respectively, for the classification of noncancerous, early gastric cancer and advanced gastric cancer. Furthermore, the performance of the segmentation method was also validated based on evaluation metrics and achieved 96.7%, 96.6% and 95.5% accuracy, sensitivity and F1-score, respectively, for the segmentation of noncancerous, early gastric cancer and advanced gastric cancer tissues. In conclusion, the method proposed in this study demonstrates enhanced global classification and detection performance compared to existing state-of-the-art algorithms. This finding underscores the significant potential of the proposed method in the domain of gastric endoscopic image classification and segmentation.},
  archive      = {J_ISCI},
  author       = {Ejaz Ul Haq and Qin Yong and Zhou Yuan and Huang Jianjun and Rizwan Ul Haq and Xuwen Qin},
  doi          = {10.1016/j.ins.2024.120568},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120568},
  shortjournal = {Inf. Sci.},
  title        = {Accurate multiclassification and segmentation of gastric cancer based on a hybrid cascaded deep learning model with a vision transformer from endoscopic images},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024f). Data-driven replay attack detection for unknown
cyber-physical systems. <em>ISCI</em>, <em>670</em>, 120562. (<a
href="https://doi.org/10.1016/j.ins.2024.120562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a data-driven method to detect stealthy replay attacks on cyber-physical systems (CPSs) whose models are unknown. Most existing attack detection methods assume the system dynamic is known. However, due to the large scale and complexity of the system, it is difficult to get an accurate model of a CPS. This paper uses a moving window subspace identification method to construct a linear discrete time-varying model of CPS. The controllability and observability of the obtained model are proved. On this basis, the replay attack is transformed into a detectable additive attack using the output coding strategy. Then, considering modeling errors, a time-varying H ∞ filter is designed, and a detection function based on the output residual is constructed. When the system works without any attacks, the detection function approaches a limited threshold. On the contrary, that function will increase extremely larger than the threshold when the replay attack occurs. The detectability of our scheme for attacks is also mathematically proven. Finally, to verify the effectiveness of the proposed scheme, we provide simulation results on a linear motor system and a nonlinear robotic system.},
  archive      = {J_ISCI},
  author       = {Zhengdao Zhang and Mingdong Li and Linbo Xie},
  doi          = {10.1016/j.ins.2024.120562},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120562},
  shortjournal = {Inf. Sci.},
  title        = {Data-driven replay attack detection for unknown cyber-physical systems},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable artificial hydrocarbon networks classifier
applied to preeclampsia. <em>ISCI</em>, <em>670</em>, 120556. (<a
href="https://doi.org/10.1016/j.ins.2024.120556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainability is crucial in domains where system decisions have significant implications for human trust in black-box models. Lack of understanding regarding how these decisions are made hinders the adoption of so-called clinical decision support systems. While neural networks and deep learning methods exhibit impressive performance, they remain less explainable than white-box approaches. Artificial Hydrocarbon Networks (AHN) is an effective black-box model that can be used to support critical clinical decisions if accompanied by explainability mechanisms to instill confidence among clinicians. In this paper, we present a use case involving global and local explanations for AHN models, provided with an automatic procedure so-called eXplainable Artificial Hydrocarbon Networks (XAHN). We apply XAHN to preeclampsia prognosis, enabling interpretability within an accurate black-box model. Our approach involves training a suitable AHN model using the cross-validation with ten repetitions, followed by a comparative analysis against four well-known machine learning techniques. Notably, the AHN model outperformed the others, achieving an F1-score of 74.91%. Additionally, we assess the efficacy of our XAHN explainer through a survey applied to clinicians, evaluating the goodness and satisfaction of the provided explanations. To the best of our knowledge, this work represents one of the earliest attempts to address the explainability challenge in preeclampsia prediction.},
  archive      = {J_ISCI},
  author       = {Hiram Ponce and Lourdes Martínez-Villaseñor and Antonieta Martínez-Velasco},
  doi          = {10.1016/j.ins.2024.120556},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120556},
  shortjournal = {Inf. Sci.},
  title        = {Explainable artificial hydrocarbon networks classifier applied to preeclampsia},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic classification ensembles for handling imbalanced
multiclass drifted data streams. <em>ISCI</em>, <em>670</em>, 120555.
(<a href="https://doi.org/10.1016/j.ins.2024.120555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models often encounter significant difficulties when dealing with multiclass imbalanced data streams in nonstationary environments. These challenges can lead to biased and unreliable predictions, which ultimately impact the overall performance of the models. To address these issues, we propose an innovative approach that integrates dynamic ensemble selection, an adaptive technique for managing imbalanced multiclass data streams, with a concept drift detector for recognizing stream changes and the K-nearest neighbor (KNN) algorithm to tackle issues related to class overlap. The primary objective was to improve the classification of imbalanced multiclass drifted data streams. The adaptive oversampling method generates synthetic samples to mitigate the issues associated with imbalanced data streams. This method utilizes KNN to ensure that the generated samples do not overlap. To handle incoming data streams, a drift detector assists in deciding whether to retain the existing classifiers or create a new one. Dynamic Ensemble Selection (DES) was utilized to select the most appropriate classifier for incoming data, aiming to optimize the performance of the classification task. The proposed method offers an effective solution for achieving an accurate and resilient classification in the context of imbalanced multiclass drifted data streams. To evaluate the effectiveness of our proposal, we conducted experiments on a variety of datasets, including benchmark datasets, real application stream datasets, and synthetic data streams. The experimental results demonstrate the superiority of our contribution in addressing the challenges posed by imbalanced multiclass drifted data streams.},
  archive      = {J_ISCI},
  author       = {Ahmed H. Madkour and Hatem M. Abdelkader and Amgad M. Mohammed},
  doi          = {10.1016/j.ins.2024.120555},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120555},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic classification ensembles for handling imbalanced multiclass drifted data streams},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A novel attribute reduction method with constraints on
empirical risk and decision rule length. <em>ISCI</em>, <em>670</em>,
120552. (<a href="https://doi.org/10.1016/j.ins.2024.120552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction is a crucial issue of rough set theory and has been applied to various fields. It aims to remove useless or redundant features from data and extract precise rules. Traditional attribute reduction methods have obvious limitations, that is, it can not guarantee the generalization ability of reduced decision rules to classification but can only guarantee the classification performance to visible objects. To overcome this issue and enhance the model classification generalization ability without increasing rules&#39; complexity based attribute reduction, we propose a novel attribute method by employing the Structural Risk Minimization principle, which is a classic method in machine learning to balance model complexity and performance. The improved attribute reduction method with rough set tries to get a trade-off between the number of features and empirical error, wherein the former is defined by rule confidence, and the latter is explored by the mutual information between the condition attribute subset and the decision attribute. In other words, model accuracy can be regarded as an empirical error term to measure the model&#39;s classification or prediction performance, and the model complexity as a penalty term to characterize the size of the reduction subset. To implement this approach, genetic algorithm is employed as a heuristic search technique, to obtain the optimal reduction subset. Several comparative experiments are performed on ten UCI datasets to evaluate the model&#39;s classification accuracy and the size of the reduction subset. The experimental results indicate the method proposed in this paper with better generalization ability compared to other traditional algorithms under the condition of equal reducted set length.},
  archive      = {J_ISCI},
  author       = {Xiaoxia Zhang and Penghao Zhang and Yanjun Liu and Guoyin Wang},
  doi          = {10.1016/j.ins.2024.120552},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120552},
  shortjournal = {Inf. Sci.},
  title        = {A novel attribute reduction method with constraints on empirical risk and decision rule length},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Developing a hybrid system for stock selection and portfolio
optimization with many-objective optimization based on deep learning and
improved NSGA-III. <em>ISCI</em>, <em>670</em>, 120549. (<a
href="https://doi.org/10.1016/j.ins.2024.120549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portfolio management is a critical aspect of investment strategies, with the goal to balance the low-risk and high-return investments. Despite this, existing portfolios frequently overlook the integration of stock selection outcomes and underutilize data from listed companies, leading to suboptimal portfolio performance. Addressing these shortcomings, this paper introduces a hybrid system involving stock selection and portfolio optimization. In stock selection, the system employs a combination of convolutional neural network and bi-directional recurrent neural network to predict stock trends. This approach enables the identification of stocks likely to appreciate in value, setting the stage for their inclusion in the subsequent optimization process. For portfolio optimization, the study formulates a five-objective optimization problem that incorporates mean, variance, skewness, kurtosis, and distance-to-default as key considerations. To solve the many-objective constrained optimization problem, an advanced strategy employing a static penalty function and an improved Non-dominated Sorting Genetic Algorithm III (NSGA-III) based on tent chaotic mapping is utilized. The efficacy of the proposed hybrid system is rigorously tested through three sets of ablation experiments alongside two discussions focused on its robustness and computational efficiency. The findings from these investigations reveal that the hybrid system outperforms traditional approaches, reducing risks and improving returns for investors.},
  archive      = {J_ISCI},
  author       = {Mengzheng Lv and Jianzhou Wang and Shuai Wang and Jialu Gao and Honggang Guo},
  doi          = {10.1016/j.ins.2024.120549},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120549},
  shortjournal = {Inf. Sci.},
  title        = {Developing a hybrid system for stock selection and portfolio optimization with many-objective optimization based on deep learning and improved NSGA-III},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Group decision making based on linguistic interval-valued
atanassov intuitionistic fuzzy yager weighted arithmetic aggregation
operator of linguistic interval-valued atanassov intuitionistic fuzzy
numbers. <em>ISCI</em>, <em>670</em>, 120517. (<a
href="https://doi.org/10.1016/j.ins.2024.120517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a noval addition operation (AOP) and a novel scalar multiplication operation (SMOP) of linguistic interval-valued Atanassov intuitionistic fuzzy numbers (LIVAIFNs) based on Yager’s t -conorm and t -norm. The proposed AOP and the proposed SMOP of LIVAIFNs can conquer the shortcomings of the existing AOP and the existing SMOP of LIVAIFNs. Based on the proposed AOP and the proposed SMOP of LIVAIFNs, we propose the linguistic interval-valued Atanassov intuitionistic fuzzy Yager weighted arithmetic (LIVAIYFWA) aggregation operator (AO) of LIVAIFNs. We also prove some properties of the proposed LIVAIFYWA AO of LIVAIFNs. Moreover, by using the proposed LIVAIFYWA AO of LIVAIFNs, we propose a noval group decision making (GDM) method. The proposed GDM method can conquer the drawbacks of the existing GDM methods in the context of LIVAIFNs.},
  archive      = {J_ISCI},
  author       = {Kamal Kumar and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2024.120517},
  journal      = {Information Sciences},
  month        = {6},
  pages        = {120517},
  shortjournal = {Inf. Sci.},
  title        = {Group decision making based on linguistic interval-valued atanassov intuitionistic fuzzy yager weighted arithmetic aggregation operator of linguistic interval-valued atanassov intuitionistic fuzzy numbers},
  volume       = {670},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy-tolerant-strategy for constrained nonlinear system via
adaptive observer. <em>ISCI</em>, <em>669</em>, 120628. (<a
href="https://doi.org/10.1016/j.ins.2024.120628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers the tracking control of nonlinear system with state constraints and faults. A fuzzy tolerant control approach on adaptive sliding-mode observer is proposed to accomplish good tracking performance. Firstly, for the purpose of getting the unknown state, a state estimator based on the fuzzy logic systems (FLSs) is designed. Secondly, a fuzzy observer by variable structure method is posed to approximate the faults, and the finite time convergence of observation error is proven. Furthermore, a two-layer nested adaptive law is constructed to improve the observer. Thirdly, a fuzzy backstepping tolerant controller based on super-twisting differentiator is proposed. In which, the barrier Lyapunov function is designed to counter the state constraints, and the super-twisting estimator is employed to estimate the derivative of virtual control input. Finally, two simulation results are analyzed to demonstrate the potential of the developed schemes.},
  archive      = {J_ISCI},
  author       = {Meng Li and Yong Chen and Yuezhi Liu and Ikram Ali},
  doi          = {10.1016/j.ins.2024.120628},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120628},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy-tolerant-strategy for constrained nonlinear system via adaptive observer},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive fuzzy filtering for multi-area power systems
subject to nonhomogeneous sojourn probabilities. <em>ISCI</em>,
<em>669</em>, 120613. (<a
href="https://doi.org/10.1016/j.ins.2024.120613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the design of an adaptive fuzzy filter for discrete-time multi-area power systems, considering the presence of sojourn probabilities and deception attacks. To capture the dynamic behavior of multi-area power systems more accurately, an innovative switching law is introduced, incorporating nonhomogeneous sojourn probability information. The feedback sojourn probability information is determined by a deterministic switched signal, enhancing the system&#39;s stability and performance. With the aim of addressing the potential impact of measurement outlier, a robust filter is developed, incorporating a dynamic saturation constraint and fuzzy logic systems. The filter effectively mitigates the influence of outliers by adaptively adjusting the saturation level based on estimation errors. The stability analysis is carried out using Lyapunov theory and average dwell-time information, demonstrating the mean square exponentially ultimately bounded of the augmented system. To validate the proposed algorithm, a simulation example is presented, showcasing its effectiveness and practical applicability in real-world scenarios.},
  archive      = {J_ISCI},
  author       = {Lidan Liang and Jun Cheng and Yonghong Chen and Huaicheng Yan and Dan Zhang},
  doi          = {10.1016/j.ins.2024.120613},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120613},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fuzzy filtering for multi-area power systems subject to nonhomogeneous sojourn probabilities},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised enhanced denoising diffusion for anomaly
detection. <em>ISCI</em>, <em>669</em>, 120612. (<a
href="https://doi.org/10.1016/j.ins.2024.120612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models have significantly enhanced anomaly detection through their powerful ability to model data. However, many existing generative model-based anomaly detection methods prioritize refining the generative process while overlooking the importance of acquiring discriminative data representations, which is suboptimal. Furthermore, the intricate architectures of these methods contribute to poor model convergence, resulting in coarse data reconstructions and diminished performance. To address the above problems, we propose self-supervised enhanced denoising diffusion for anomaly detection (SDAD) to detect anomalies effectively. Specifically, SDAD acquires discriminative data representations through an auxiliary learning module with two pretext tasks, facilitating the distinction between normal data and abnormal data. Subsequently, a denoising diffusion module is used to accurately learn the normal data distribution, serving as a benchmark for anomaly detection. Extensive experiments on ten real-world datasets demonstrate the remarkable advantages of SDAD over nine state-of-the-art anomaly detection methods, as evidenced by significant improvements across various evaluation metrics.},
  archive      = {J_ISCI},
  author       = {Shu Li and Jiong Yu and Yi Lu and Guangqi Yang and Xusheng Du and Su Liu},
  doi          = {10.1016/j.ins.2024.120612},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120612},
  shortjournal = {Inf. Sci.},
  title        = {Self-supervised enhanced denoising diffusion for anomaly detection},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Information control in networked discrete event systems.
<em>ISCI</em>, <em>669</em>, 120611. (<a
href="https://doi.org/10.1016/j.ins.2024.120611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to control information exchange among different users is an important problem in networked systems with many users/agents. Generally speaking, there are several considerations in control of information exchange in a networked system, including (1) to ensure a friend user has sufficient information to perform its tasks, (2) to deprive an adversary user its information to perform its tasks, (3) to minimize information exchange among friend users so that the risk of information leaking is minimized, and (4) to maximize information broadcasted to all users to achieve maximum transparency. In this paper, we investigate the information control problems in the framework of discrete event systems. Based on the problem at hand, we divide users in a networked system into two or more groups. Users in the same group are consider as friends and users in a different group are consider as adversaries. Several information control problems are investigated and solved using a systematic and rigorous approach. Methods are developed to design controllers that send minimum information to its friends to help them to perform their tasks and broadcast maximum information without helping its adversaries.},
  archive      = {J_ISCI},
  author       = {Fei Wang and Feng Lin},
  doi          = {10.1016/j.ins.2024.120611},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120611},
  shortjournal = {Inf. Sci.},
  title        = {Information control in networked discrete event systems},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fed-mRMR: A lossless federated feature selection method.
<em>ISCI</em>, <em>669</em>, 120609. (<a
href="https://doi.org/10.1016/j.ins.2024.120609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection has become a mandatory task in data mining, due to the overwhelming amount of features in Big Data problems. To handle this high-dimensional data and avoid the well-known curse of dimensionality, we need to pre-select an optimal subset of features to reduce redundant computations. Federated learning is a machine learning technique based on training an algorithm over many decentralized edge devices holding local rather than global data on a centralized server. Application of this technique is extending to fields such as self-driving cars, medicine and health, and Industry 4.0, where data privacy is compulsory. Feature selection through federated learning is a complicated task since suboptimal features calculated by feature selection methods may be different in heterogeneous datasets from different nodes. In this paper, we propose a lossless federated version of the classic minimum redundancy maximum relevance (mRMR) feature selection algorithm, called federated mRMR (fed-mRMR), which, without losing any effectiveness of the original mRMR method, is applicable to federated learning approaches and capable of dealing with data that are not independent and identically distributed (non-IID data). Implementation can be found at: https://github.com/jorgehermo9/fed-mrmr},
  archive      = {J_ISCI},
  author       = {Jorge Hermo and Verónica Bolón-Canedo and Susana Ladra},
  doi          = {10.1016/j.ins.2024.120609},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120609},
  shortjournal = {Inf. Sci.},
  title        = {Fed-mRMR: A lossless federated feature selection method},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MEAformer: An all-MLP transformer with temporal external
attention for long-term time series forecasting. <em>ISCI</em>,
<em>669</em>, 120605. (<a
href="https://doi.org/10.1016/j.ins.2024.120605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based models have significantly improved performance in Long-term Time Series Forecasting (LTSF). These models employ various self-attention mechanisms to discover long-term dependencies. However, the computational efficiency is hampered by the inherent permutation invariance of self-attention, and they primarily focus on relationships within the sequence while neglecting potential relationships between different sample sequences. This limits the ability and flexibility of self-attention in LTSF. In addition, the Transformer&#39;s decoder outputs sequences in an autoregressive manner, leading to slow inference speed and error accumulation effects, especially for LTSF. Regarding the issues with Transformer-based models for LTSF, we propose a model better suited for LTSF, named MEAformer. MEAformer adopts a fully connected Multi-Layer Perceptron (MLP) architecture consisting of two types of layers: encoder layers and MLP layers. Unlike most encoder layers in Transformer-based models, the MEAformer replaces self-attention with temporal external attention. Temporal external attention explores potential relationships between different sample sequences in the training dataset. Compared to the quadratic complexity of self-attention mechanisms, temporal external attention has efficient linear complexity. Encoder layers can be stacked multiple times to capture time-dependent relationships at different scales. Furthermore, the MEAformer replaces the intricate decoder layers of the original model with more straightforward MLP layers. This modification aims to enhance inference speed and facilitate single-pass sequence generation, effectively mitigating the problem of error accumulation effects. Regarding long-term forecasting, MEAformer achieves state-of-the-art performance on six benchmark datasets, covering five real-world domains: energy, transportation, economy, weather, and disease. Code is available at: https://github.com/huangsiyuan924/MEAformer .},
  archive      = {J_ISCI},
  author       = {Siyuan Huang and Yepeng Liu and Haoyi Cui and Fan Zhang and Jinjiang Li and Xiaofeng Zhang and Mingli Zhang and Caiming Zhang},
  doi          = {10.1016/j.ins.2024.120605},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120605},
  shortjournal = {Inf. Sci.},
  title        = {MEAformer: An all-MLP transformer with temporal external attention for long-term time series forecasting},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural quadratic sliding mode control of interconnected
markov jump systems through dynamic event-triggered observer.
<em>ISCI</em>, <em>669</em>, 120603. (<a
href="https://doi.org/10.1016/j.ins.2024.120603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an observer-based neural quadratic sliding mode control strategy for interconnected Markov jump systems faced with unknown interconnections, regardless of the high dimensionality of the systems. Firstly, a dynamic event-triggered scheme is constructed in the communication channel to the Lebesgue state observer, with which an integral quadratic sliding mode hyperplane is put forward; Secondly, a neural-based control method is put forward to make sure that predefined sliding hyperplane is attractive; In addition, the occurrence of Zeno phenomenon is also verified to be avoided with the implementation of the controller; Thirdly, linear matrix inequality technique and Lyapunov stochastic stability theory are proposed to check the stochastic stability of closed-loop systems, including sliding mode dynamics and error dynamics; Finally, simulation results on single-link robot arms are given to reveal the validity of the obtained results.},
  archive      = {J_ISCI},
  author       = {Baoping Jiang and Hamid Reza Karimi and Zhengtian Wu and Xin Zhang},
  doi          = {10.1016/j.ins.2024.120603},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120603},
  shortjournal = {Inf. Sci.},
  title        = {Neural quadratic sliding mode control of interconnected markov jump systems through dynamic event-triggered observer},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). WSBCV: A data-driven cross-version defect model via
multi-objective optimization and incremental representation learning.
<em>ISCI</em>, <em>669</em>, 120595. (<a
href="https://doi.org/10.1016/j.ins.2024.120595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-version defect prediction (CVDP) refers to training an excellent model on tagged defect data in a previously released project version, and then performing defect prediction on an unlabeled instance module in the current version. Nevertheless, the complicated internal intrinsic construction hidden behind the code defects makes it difficult for the previous cross-version defect models to capture more discriminative software features, and seriously restrains the CVDP performance. In this study, we propose an intelligent data-driven CVDP model named WSBCV based on multi-objective optimization and incremental representation learning. We firstly leverage an advanced deep generation adversarial network – WGAN-GP (Wasserstein GAN with Gradient Penalty) to perform data augmentation, including balancing defect classes and synthesizing abundant training instances. Secondly, a multi-objective SPEA/R (Strength Pareto-based Evolutionary Algorithm / Reference) feature selection optimization method is built to effectively search the fewest representative feature subsets while achieving the minimum error. Finally, a powerful defect predictor for CVDP based on the BLS (Broad Learning System) with incremental learning is built to learn excellent feature representations and achieve incremental online model update quickly. Experimental results across 32 cross-version pairs from 45 version demonstrate that the proposed SPEA/R, BLS and WSBCV all have statistically significant difference advantages compared to ten multi-objective feature selection approaches, six defect predictors and two CVDP models, respectively.},
  archive      = {J_ISCI},
  author       = {Nana Zhang and Kun Zhu and Weiping Ding and Dandan Zhu},
  doi          = {10.1016/j.ins.2024.120595},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120595},
  shortjournal = {Inf. Sci.},
  title        = {WSBCV: A data-driven cross-version defect model via multi-objective optimization and incremental representation learning},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attribute reduction with fuzzy kernel-induced relations.
<em>ISCI</em>, <em>669</em>, 120589. (<a
href="https://doi.org/10.1016/j.ins.2024.120589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy rough sets have strong ability in dealing with data uncertainty, which have been widely applied in attribute reduction problems. Fuzzy relations are the cornerstones of fuzzy rough sets, and kernel-induced relations can simultaneously reflect the similarities of objects in both original space and high-dimensional Hilbert space. However, existing distance-based fuzzy relations (even kernel-induced) cannot truly reflect the correlations of objects under complex data distributions. To obtain better expressing ability for data, we propose a general optimization framework to get the memberships of objects with respect to categories. Considering various complex data distributions, the concepts of intra-class aggregation degree based on membership and inter-class dispersion degree based on nonmembership are proposed, and a separability measure is constructed to evaluate the importance of attributes to decisions. Correspondingly, a new attribute reduction algorithm is proposed, with a forward evaluation L -step strategy to skip local fluctuations in classification accuracy. Finally, we conduct a series of experiments to verify the effectiveness of the proposed algorithm. From the experiments on UCI, ELVIRA and face recognition datasets, it can be seen that the attribute subset obtained by the proposed algorithm not only has high classification accuracy and computational efficiency, but also has fewer attributes.},
  archive      = {J_ISCI},
  author       = {Meng Hu and Yanting Guo and Ran Wang and Xizhao Wang},
  doi          = {10.1016/j.ins.2024.120589},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120589},
  shortjournal = {Inf. Sci.},
  title        = {Attribute reduction with fuzzy kernel-induced relations},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Many-objective evolutionary self-knowledge distillation with
adaptive branch fusion method. <em>ISCI</em>, <em>669</em>, 120586. (<a
href="https://doi.org/10.1016/j.ins.2024.120586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a new technology for model compression, self-knowledge distillation (SKD) avoids the large computational overhead of training the teacher model seen with traditional knowledge distillation. However, existing SKD methods pay attention to the knowledge transfer between deep and shallow layers of the network but ignore the mutual learning between shallow branches. This paper proposes a many-objective evolutionary self-knowledge distillation framework (MaOESKD) to guide the knowledge fusion between branches in the SKD neural network. This framework embeds an optimization module and a temporary branch into the multi-branch SKD network. The optimization module includes a many-objective adaptive weight optimization model (MaAWOM) and an many evolutionary optimization algorithm based on multi-strategy consensus mechanism (MaOEA-MCM); meanwhile, the temporary branch performs linear weighted fusion. In the MOBWOM, the weight of different branches in knowledge fusion is taken as the decision variable, and the mutual information, covariance, KL divergence between branch output features, and the total information of each branch are taken as the optimization objective. The MSCMEA integrates several state-of-the-art individual selection strategies in the field of evolutionary algorithms. It includes shift density estimation (SDE), penalized boundary intersection (PBI), balanced fitness estimation (BFE), and adaptive position transformation (APT). The accuracy of MOESKD achieves 99.70, 95.74 and 78.21 in MNIST, CIFAR-10 and CIFAR-100.},
  archive      = {J_ISCI},
  author       = {Jiayuan Bai and Yi Zhang},
  doi          = {10.1016/j.ins.2024.120586},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120586},
  shortjournal = {Inf. Sci.},
  title        = {Many-objective evolutionary self-knowledge distillation with adaptive branch fusion method},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-criteria constrained interval type-2 fuzzy
decision-making: A space analysis perspective. <em>ISCI</em>,
<em>669</em>, 120581. (<a
href="https://doi.org/10.1016/j.ins.2024.120581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Practical decision-making problems invariably involve inherent uncertainty in information, making it challenging to obtain precise evaluations. In this research, the utilization of constrained interval type-2 fuzzy sets (CIT2 FSs) enables the representation of complex uncertainty in decision information, and a space analysis approach, called CIT2 fuzzy multi-criteria acceptability analysis (CIT2FMAA), is proposed for conducting reliable decision-making. The CIT2FMAA introduces a novel paradigm for type-2 fuzzy decision-making, wherein CIT2 fuzzy evaluations are acknowledged as spaces of type-1 fuzzy evaluations and processed using type-1 fuzzy operations and methodologies. First, from a space analysis perspective, the type-2 fuzzy measures of logical rank expressions are formalized as CIT2 fuzzy rank acceptability indexes, and the CIT2 fuzzy rank acceptability analysis is developed to rank CIT2 fuzzy numbers. Second, the weighted average of the CIT2 fuzzy numbers is defined, and the CIT2FMAA is proposed to support uncertain multi-criteria decision-making. Subsequently, a sampling algorithm is designed for implementing CIT2 fuzzy rank acceptability analysis and CIT2FMAA. Finally, a linguistic disease diagnosis is performed to demonstrate the efficiency of CIT2FMAA. Compared to traditional type-2 fuzzy decision-making methods, CIT2FMAA is more efficient because it not only derives ranks of alternatives but also provides confidence degrees for those ranks.},
  archive      = {J_ISCI},
  author       = {Hao Li and Xianchao Dai and Ligang Zhou and Wenming Yang},
  doi          = {10.1016/j.ins.2024.120581},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120581},
  shortjournal = {Inf. Sci.},
  title        = {Multi-criteria constrained interval type-2 fuzzy decision-making: A space analysis perspective},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A GNN-based fraud detector with dual resistance to graph
disassortativity and imbalance. <em>ISCI</em>, <em>669</em>, 120580. (<a
href="https://doi.org/10.1016/j.ins.2024.120580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the prosperity of Internet services, various fraudulent activities have emerged, and some graph neural network-based methods have been proposed for fraud detection. These methods have achieved significant performances based on the assortativity assumption where the connected nodes tend to have the same labels. However, the fraud graphs are not always assortative but more likely disassortative as fraudsters usually disguise themselves by deliberately making extensive connections to benign users. Furthermore, some studies have noticed node imbalance issues as the fraudsters are far fewer than normal users. But for another one, the edge imbalance issue is unexplored, and they also failed to make full use of these rare but valuable edges. Therefore, we propose an imbalanced disassortative graph learning framework for fraud detection. Specifically, a learnable dual-channel graph convolution filter is introduced to adaptively aggregate low- and high-frequency signals from its neighbors to assimilate/discriminate nodes with assortative/disassortative edges. Then, the label-aware node and edge samplers are designed to remedy graph imbalance problems. Furthermore, the sampled edges are treated as the auxiliary supervision signal to explicitly facilitate the training of graph filters. Extensive experiments on real-world datasets verify the superiority of our method.},
  archive      = {J_ISCI},
  author       = {Junhang Wu and Ruimin Hu and Dengshi Li and Lingfei Ren and Wenyi Hu and Yilong Zang},
  doi          = {10.1016/j.ins.2024.120580},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120580},
  shortjournal = {Inf. Sci.},
  title        = {A GNN-based fraud detector with dual resistance to graph disassortativity and imbalance},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MaskArmor: Confidence masking-based defense mechanism for
GNN against MIA. <em>ISCI</em>, <em>669</em>, 120579. (<a
href="https://doi.org/10.1016/j.ins.2024.120579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have demonstrated remarkable performance in diverse graph-related tasks, including node classification, graph classification, link prediction, etc. Previous research has indicated that GNNs are vulnerable to membership inference attacks (MIA). These attacks enable malevolent parties to deduce whether the data points are part of the training set by identifying the output distribution, giving rise to noteworthy privacy apprehensions, especially when the graph contains sensitive data. There have been some studies to defend against graph MIA so far, but they have issues like high computational cost and decreased model accuracy. In this paper, we introduce a novel defense framework called MaskArmor , designed to bolster the privacy and security of GNNs against MIA. The MaskArmor framework encompasses four distinct masking strategies: AdjMask, DTMask, ATMask, and SigMask. These strategies leverage message-passing mechanisms, distillation temperature, hybrid masking, and the Sigmoid function, respectively. The MaskArmor framework effectively obscures the distribution of the model on both the training and non-training samples, rendering it challenging for attackers to ascertain whether particular samples have undergone training. Additionally, MaskArmor sustains the model&#39;s precision with negligible computational overhead. Our experiments are implemented across seven benchmark datasets and four GNN networks against shadow-based and threshold-based MIAs, showcasing that MaskArmor substantially heightens GNNs&#39; resilience against MIA while simultaneously preserving accuracy on the initial tasks. It also demonstrates adeptness in countering threshold-based MIA through strategies like AdjMask and ATMask. Exhaustive experimental results substantiate that MaskArmor outperforms alternative existing approaches, maintaining effectiveness and applicability across diverse datasets and attack scenarios.},
  archive      = {J_ISCI},
  author       = {Chenyang Chen and Xiaoyu Zhang and Hongyi Qiu and Jian Lou and Zhengyang Liu and Xiaofeng Chen},
  doi          = {10.1016/j.ins.2024.120579},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120579},
  shortjournal = {Inf. Sci.},
  title        = {MaskArmor: Confidence masking-based defense mechanism for GNN against MIA},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerating deep neural network learning using data stream
methodology. <em>ISCI</em>, <em>669</em>, 120575. (<a
href="https://doi.org/10.1016/j.ins.2024.120575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel machine learning approach, called BBATDD (Boosting-Based Algorithm Trained with Drift Detector), that departs from traditional epoch-based methods by adopting a data stream generation strategy from the original dataset. The proposed method is versatile, applicable to a broad range of deep structures and other machine learning architectures. The key to its effectiveness is the conversion of original data into a streaming sequence, which is then fed into the neural network structure. To monitor the learning process and prevent overfitting, a drift detector, commonly used in stream data mining, is employed. Additionally, two methods, ELB and ENT, are introduced to prioritize problematic data elements during the learning process, enhancing overall model performance. Extensive simulations on benchmark datasets (MNIST and CIFAR) validate that BBATDD achieves higher accuracy with significantly fewer batches, without sacrificing generalization capability. For instance, when applied to the MNIST dataset and processing 10 000 batches while comparing loss function values, our approach demonstrates a remarkable 45.6% improvement.},
  archive      = {J_ISCI},
  author       = {Piotr Duda and Mateusz Wojtulewicz and Leszek Rutkowski},
  doi          = {10.1016/j.ins.2024.120575},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120575},
  shortjournal = {Inf. Sci.},
  title        = {Accelerating deep neural network learning using data stream methodology},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weighted probability kernel multi-granularity three-way
decision integrating GRA and its application in medical diagnosis.
<em>ISCI</em>, <em>669</em>, 120574. (<a
href="https://doi.org/10.1016/j.ins.2024.120574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision, an outstanding method to handle decision-making uncertainties, relies on essentially the loss functions derived from the Bayesian risk decision process. Actually, there are plentiful loss functions that depend on the subjective judgment of decision-makers under different decision scenarios, lacking uniform and objective measurement frameworks. This study pays attention to the real clinical diagnosis, and constructs a weighted probability kernel multi-granularity three-way decision method (WKMG-TWD) integrating gray relation analysis (GRA) over a multi-source heterogeneous decision information system (MHDIS). The method establishes a standardized data-driven calculation framework of loss functions. Foremost, the multi-kernel probabilistic similarity is defined and granularity&#39;s weights with knowledge consistency are explored. Subsequently, a weighted probability kernel multi-granularity rough set (WKMGRS) is constructed in this paper. Secondly, to introduce the three-way decision, this study proposes the cost-sensitive individual loss functions considering the correlation determined by GRA between decision objects and different decision classes. Ultimately, this study establishes and applies a three-way iterative classification model to hypertension diagnosis. The experimental results confirm the effectiveness and superiority of the model. The main contribution of this paper is twofold. One is to offer a uniform calculation framework for loss functions and granularity&#39;s weights. The other is to furnish invaluable guidance for solving complex medical decision-making problems.},
  archive      = {J_ISCI},
  author       = {Xiaoyan Qin and Bingzhen Sun and Simin Wu and Juncheng Bai and Xiaoli Chu},
  doi          = {10.1016/j.ins.2024.120574},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120574},
  shortjournal = {Inf. Sci.},
  title        = {Weighted probability kernel multi-granularity three-way decision integrating GRA and its application in medical diagnosis},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimization design of a new variable type hierarchical
fuzzy system with interpretability improvement. <em>ISCI</em>,
<em>669</em>, 120571. (<a
href="https://doi.org/10.1016/j.ins.2024.120571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a variable-type hierarchical fuzzy system (VTHFS) with high accuracy and strong interpretability. An improved rear-part direct-connected structure is used in the VTHFS, which eliminates the intermediate variables of the hierarchical fuzzy system (HFS). A new feature sorting method is proposed to find suitable input variables for each layer of subsystems of VTHFS. Under the proposed topology structure, layer by layer training of VTHFS can be achieved by changing the expected output of each layer, thereby reducing residual errors layer by layer and improving the prediction accuracy of VTHFS. Three fuzzy set distribution constraints are used in parameter optimization of VTHFS to improve the interpretability, including integrity, distinguishability, and footprint of uncertainty. The type of fuzzy set is automatically adjusted according to the uncertainty characteristics of input data measured by fuzziness, which further enhances the semantic interpretability of the VTHFS and solves the problem of requiring prior knowledge to define the fuzzy set type in existing research. Finally, the proposed VTHFS is tested on the regression data sets in the real world. Experimental results demonstrate the effectiveness of the feature sorting method and the fuzzy set type adjustment method. Through a large number of quantitative indicators, it can be confirmed that VTHFS has stronger interpretability and higher prediction accuracy compared to other fuzzy systems.},
  archive      = {J_ISCI},
  author       = {Tao Zhao and Tao Tan and Xiangpeng Xie},
  doi          = {10.1016/j.ins.2024.120571},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120571},
  shortjournal = {Inf. Sci.},
  title        = {Optimization design of a new variable type hierarchical fuzzy system with interpretability improvement},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). OnceNAS: Discovering efficient on-device inference neural
networks for edge devices. <em>ISCI</em>, <em>669</em>, 120567. (<a
href="https://doi.org/10.1016/j.ins.2024.120567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge Intelligence (EI) offers an attractive approach for local AI processing at the network edge for privacy protection and reduced transmission, but deploying resource-intensive neural networks on edge devices remains a challenge. The neural architecture search (NAS) technique, known for its automation and minimal manual intervention, serves as a pivotal tool for EI. However, existing methods typically concentrate on optimizing resource consumption for specific hardware, leading to hardware-specific neural architectures with limited generalizability. In response, we propose OnceNAS, a novel method that designs and optimizes on-device inference neural networks for resource-constrained edge devices. OnceNAS simultaneously optimizes for parameter count and inference latency in addition to inference accuracy, producing lightweight neural networks while maintaining their inference performance. Meanwhile, we introduce an efficient evaluation strategy that can simultaneously assess multiple metrics. Experimental results demonstrate the effectiveness of OnceNAS, achieving high-performing architectures with substantial size reduction (10.49x) and speedup (5.45x). As a result, OnceNAS offers practical value by generating efficient on-device inference neural architectures for resource-constrained edge devices, facilitating real-world applications like autonomous driving and smart healthcare. Furthermore, we contribute DARTS-Bench, an open-source dataset providing candidate architectures with hardware-related information and a user-friendly API, facilitating future research in lightweight NAS.},
  archive      = {J_ISCI},
  author       = {Yusen Zhang and Yunchuan Qin and Yufeng Zhang and Xu Zhou and Songlei Jian and Yusong Tan and Kenli Li},
  doi          = {10.1016/j.ins.2024.120567},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120567},
  shortjournal = {Inf. Sci.},
  title        = {OnceNAS: Discovering efficient on-device inference neural networks for edge devices},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). GA-FCFNN: A new forecasting method combining feature
selection methods and feedforward neural networks using genetic
algorithms. <em>ISCI</em>, <em>669</em>, 120566. (<a
href="https://doi.org/10.1016/j.ins.2024.120566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modern landscape, the fusion of forecasting and computational intelligence empowers organizations to extract invaluable insights from vast datasets, facilitating informed decision-making, swift adaptation to market dynamics, and the enhancement of competitiveness, ultimately fostering innovation. Notably, forecasting has recently garnered significant attention, particularly within the realm of big data. This modern terrain presents a dual challenge: effectively distilling essential insights from complex data and optimizing data utilization. To address this challenge, we introduce a pioneering forecasting model (FM) engineered to excel in both information extraction and data utilization. Our approach commences with a formula designed to compute feature similarity, leveraging trend change data. These similarity metrics, applied to features and their relationships with labels, inform our feature selection process. This method integrates spatial and temporal correlations among features, fostering robust interconnections within the selected subset. Subsequently, we employ a feedforward neural network (FNN) to optimize feature subsets based on test error. While the FM trained with the optimal feature subset exhibits enhanced performance, it still shows some deviation from actual values in initial forecasting results (FORs). To mitigate these discrepancies, we implement a data utilization strategy. We refine the initial FORs by considering the contribution of each feature subset to them, thereby reducing disparities between forecasts and actual values. Model parameters are fine-tuned using a genetic algorithm (GA). Finally, we conduct an experimental analysis, comparing our FM to seven similar models using publicly available datasets. Our experimental results consistently demonstrate that our FM achieves high forecasting performance (FOP).},
  archive      = {J_ISCI},
  author       = {Rongtao Zhang and Xueling Ma and Chao Zhang and Weiping Ding and Jianming Zhan},
  doi          = {10.1016/j.ins.2024.120566},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120566},
  shortjournal = {Inf. Sci.},
  title        = {GA-FCFNN: A new forecasting method combining feature selection methods and feedforward neural networks using genetic algorithms},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guided prediction strategy based on regional
multi-directional information fusion for dynamic multi-objective
optimization. <em>ISCI</em>, <em>669</em>, 120565. (<a
href="https://doi.org/10.1016/j.ins.2024.120565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Region partitioning is effective for solving dynamic multi-objective optimization problems (DMOPs). However, most region partitioning approaches use only specific individual information to predict directions within each region. Their efficiency degrades when the distribution of individuals is irregular, and the use of several methods to obtain high-quality areas incurs high computational costs. To address these problems, this study develops a guided prediction strategy based on regional multi-directional information fusion for dynamic multi-objective optimization (RMDIF). Firstly, quantiles are used in the subregional segmentation, whose computational cost is small. Secondly, to increase the prediction accuracy and adaptability of the algorithm for individuals with irregular distributions, information from the center and boundary points of each subregion is fused to construct a new direction for generating initial individuals in new environments. Similar to the quantile-guided dual-prediction strategy, a dual-space prediction strategy is used to generate individuals in new environments to increase the population diversity. Finally, a “maintain-decline-maintain” strategy is used to determine the proportion of new individuals from two prediction spaces. Compared with the fixed proportion method, the proposed method better balances convergence and diversity. RMDIF and six other algorithms are tested on 27 DMOPs, the proposed algorithm outperformed the others in most cases.},
  archive      = {J_ISCI},
  author       = {Jinyu Feng and Debao Chen and Feng Zou and Fangzhen Ge and Xiaotong Bian and Xuenan Zhang},
  doi          = {10.1016/j.ins.2024.120565},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120565},
  shortjournal = {Inf. Sci.},
  title        = {Guided prediction strategy based on regional multi-directional information fusion for dynamic multi-objective optimization},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collaborative knowledge amalgamation: Preserving
discriminability and transferability in unsupervised learning.
<em>ISCI</em>, <em>669</em>, 120564. (<a
href="https://doi.org/10.1016/j.ins.2024.120564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Knowledge Amalgamation (UKA) trains a versatile student model with an unlabeled dataset to handle joint objectives of multiple off-the-shelf teacher models, each specialized for distinct tasks. Existing research primarily focuses on facilitating the learning of discriminative knowledge by student models from their teacher models within a latent feature space, but often overlooks the transferability of such knowledge to downstream tasks. In this paper, we propose a novel Collaborative Knowledge Amalgamation (Co-KA) framework, which aims to preserve both the discriminability and transferability of knowledge in the UKA task. Specifically, within the latent feature space, we introduce the concept of “inherent semantic relationships” between mini-batch samples to maintain knowledge transferability through a distance-based contrastive objective. Additionally, we employ alignment loss to ensure knowledge discrimination between the target student and teachers. In the logit space, we design a decoupled soft-target distillation to enable the student model to acquire both discriminative and transferable knowledge from the aggregate teachers. Extensive experiments on various benchmarks and challenging cross-dataset tasks empirically demonstrate the efficacy and adaptability of our approach for unsupervised knowledge amalgamation.},
  archive      = {J_ISCI},
  author       = {Shangde Gao and Yichao Fu and Ke Liu and Wei Gao and Hongxia Xu and Jian Wu and Yuqiang Han},
  doi          = {10.1016/j.ins.2024.120564},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120564},
  shortjournal = {Inf. Sci.},
  title        = {Collaborative knowledge amalgamation: Preserving discriminability and transferability in unsupervised learning},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiple GRAphs-oriented random wAlk (MulGRA2) for social
link prediction. <em>ISCI</em>, <em>669</em>, 120563. (<a
href="https://doi.org/10.1016/j.ins.2024.120563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current link prediction methods in Location-Based Social Networks (LBSNs) fuse graphs derived from users&#39; check-in data and their social links to form a single graph or network. Then, they learn node representations and link probabilities from a fused graph that undermines the distinctive characteristics of each user&#39;s spatiotemporal mobility and social links. Consequently, the input datasets are heavily contaminated with noise, which makes it challenging for these algorithms to make accurate predictions. Our study employs the proposed Multiple GRAphs-oriented Random wAlk (MulGRA2) to model graphs while maintaining the distinctive characteristics of the data to address the issue of noisy data in the learning process. Specifically, we use three graphs: a social graph constructed from social links data, a user co-occurrence graph derived from users&#39; check-in data to capture spatiotemporal co-occurrence, and a user-location bipartite graph that links users to specific locations based on the same check-in data. After traversing all three graphs, it learns node representation and infers links effectively. Extensive experiments on both Foursquare and synthetic datasets demonstrate that our algorithm significantly improves link prediction performance. Furthermore, sensitivity analysis on various datasets confirms the robustness of our algorithm.},
  archive      = {J_ISCI},
  author       = {Tianliang Qi and Yujie Li and Weihua Ji and Kuo-Ming Chao and Yan Chen and Haiping Zhu and Caixia Yan and Jun Liu and Mo Xu and Zhihai Suo and Qinghua Zheng and Feng Tian},
  doi          = {10.1016/j.ins.2024.120563},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120563},
  shortjournal = {Inf. Sci.},
  title        = {Multiple GRAphs-oriented random wAlk (MulGRA2) for social link prediction},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). Efficient approach to cyclic scheduling of high throughput
screening systems for bioengineering. <em>ISCI</em>, <em>669</em>,
120561. (<a href="https://doi.org/10.1016/j.ins.2024.120561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a standard technology, high throughput screening (HTS) is widely applied for the analysis and detection of new biological substances and drugs in pharmaceutical industries and life science research. Efficient scheduling of HTS systems is a crucial issue for reducing the cost of their operations. As a typical application of high throughput screening, this work studies the scheduling problem of the enzyme-linked immunoassay (ELISA) processes in HTS systems. For this process, it requires a one-microplate cyclic schedule and a microplate visits some processing resources multiple times, making the process deadlock-prone such that its scheduling problem is very challenging. To tackle this problem, the process is modeled by a kind of Petri nets. Based on this model, by analyzing the dynamic properties of the process, it is able to directly deduce an activity sequence to form an optimal cyclic schedule. In this way, it not only efficiently solves the challenging scheduling problem without building a mathematical programming model, but also the obtained schedule is very easy to understand and implement.},
  archive      = {J_ISCI},
  author       = {SiWei Zhang and Tan Li and NaiQi Wu and Yan Qiao and Weiwen Guo},
  doi          = {10.1016/j.ins.2024.120561},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120561},
  shortjournal = {Inf. Sci.},
  title        = {Efficient approach to cyclic scheduling of high throughput screening systems for bioengineering},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive mean field multi-agent reinforcement learning.
<em>ISCI</em>, <em>669</em>, 120560. (<a
href="https://doi.org/10.1016/j.ins.2024.120560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale Multi-Agent Reinforcement Learning (MARL) is fundamentally a challenge due to the curse of dimensionality. In a homogeneous multi-agent setting, mean field theory gives an effective way of scalable MARL by abstracting other agents to a virtual mean agent, assuming that the influence between agents is equal and infinitesimal. However, in some real scenarios, only several neighboring agents, rather than all agents, affect the decision-making of an agent, and different neighboring agents may have varying degrees of influence on the agent&#39;s decision-making. In this paper, not restricted to a homogeneous setting, we propose adaptive mean field MARL, which is based on the attention mechanism and can be used to deal with many-agent scenarios where there may be different influence relationships among agents. Specifically, we first derive the mean field approximation with adaptive weight and give the error bound of the approximation. Then, we propose adaptive mean field Q-Learning and describe how to obtain the adaptive weight. In addition, we discuss the differences between the proposed approach and existing mean-field MARL methods. Finally, we conduct experiments on simulation platforms, and the results show that the performance of the proposed approach outperforms that of the state-of-the-art method.},
  archive      = {J_ISCI},
  author       = {Xiaoqiang Wang and Liangjun Ke and Gewei Zhang and Dapeng Zhu},
  doi          = {10.1016/j.ins.2024.120560},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120560},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive mean field multi-agent reinforcement learning},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stacking multi-view broad learning system with residual
structures for classification. <em>ISCI</em>, <em>669</em>, 120559. (<a
href="https://doi.org/10.1016/j.ins.2024.120559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broad learning system (BLS) is an effective and efficient discriminative learning algorithm, particularly adept at rapid implementation for incremental learning without necessitating substantial computational resources. However, BLS exhibits excellent performance exclusively in low-complexity scenarios, with its classification performance on RGB images being somewhat underwhelming. In this article, a novel BLS model named the stacking multi-view broad learning system with residual structures (RSM-BLS) is proposed. This model integrates the strengths of residual structures, multi-view learning, and transfer learning. Furthermore, the specific architecture of this model and the process of implementing incremental learning are provided. Finally, we evaluate the classification performance of the proposed RSM-BLS on the NOBR dataset, Fashion-MNIST dataset, cifar10 dataset, SVHN dataset, and cifar100 dataset, and conduct ablation studies and incremental structure tests. The experimental results indicate that, in comparison to relevant BLS algorithms and state-of-the-art methods, RSM-BLS exhibits superior performance and generalization capabilities.},
  archive      = {J_ISCI},
  author       = {Tao Huang and Hua Li and Gui Zhou and Shaobo Li},
  doi          = {10.1016/j.ins.2024.120559},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120559},
  shortjournal = {Inf. Sci.},
  title        = {Stacking multi-view broad learning system with residual structures for classification},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Considering user dynamic preferences for mitigating negative
effects of long-tail in recommender systems. <em>ISCI</em>,
<em>669</em>, 120558. (<a
href="https://doi.org/10.1016/j.ins.2024.120558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems focusing solely on accuracy, defined as the similarity of items to users&#39; interests, often encounter the long-tail problem. This issue arises because short-head items, having received more ratings, dominate users&#39; recommendation lists, while long-tail items, which are less popular, are underrepresented to maintain recommendation list precision. Unlike other approaches that treat users&#39; preferences as fixed, this work advocates for considering dynamic user preferences to address the long-tail problem effectively. Specifically, we demonstrate two key observations: 1) users register varying proportions of ratings for long-tail and short-head items over time, and 2) item popularity is dynamic and undergoes changes over time. Consequently, recommendation lists can be dynamically adjusted to include different proportions of popular and unpopular items. We propose adapting the recommendation lists based on users&#39; tenure in the system and their accrued ratings, allowing for higher inclusion of long-tail items for users with longer membership and more registered ratings. Additionally, we maintain an updated list of popular items as their popularity can fluctuate over time. In this study, modifications are made to the memetic algorithm to leverage users&#39; dynamic preferences, demonstrating notable improvements. The proposed method achieves a precision of 90%, surpassing related works by 7% in addressing the long-tail problem, leading to increased participation of unpopular items in recommendation lists.},
  archive      = {J_ISCI},
  author       = {Reza Shafiloo and Marjan Kaedi and Ali Pourmiri},
  doi          = {10.1016/j.ins.2024.120558},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120558},
  shortjournal = {Inf. Sci.},
  title        = {Considering user dynamic preferences for mitigating negative effects of long-tail in recommender systems},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time event-triggered output-feedback adaptive
decentralized echo-state network fault-tolerant control for
interconnected pure-feedback nonlinear systems with input saturation and
external disturbances: A fuzzy control-error approach. <em>ISCI</em>,
<em>669</em>, 120557. (<a
href="https://doi.org/10.1016/j.ins.2024.120557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a decentralized Event-Triggered fault-tolerant echo-state network (ESN) direct adaptive controller for uncertain interconnected nonlinear systems in pure-feedback form. The proposed controller addresses input saturation, actuator faults, external disturbances, and unavailable states for measurement. Unlike the existing works in the literature that adapts the ESN weights using the tracking error, our method employs the control error that is estimated using a fuzzy inference system, to derive the adaptation laws. The complexity explosion typically seen with recursive back-stepping and Dynamic Surface Control (DSC) designs is completely avoided. Our control scheme addresses four types of state-dependent actuator faults: bias, drift, loss of accuracy, as well as loss of effectiveness. The ESNs approximate unknown ideal control laws, while robust terms are added to enhance the stability of the closed-loop system. Stability analysis ensures that tracking errors converge, in finite time, to a small compact set near the origin due to the strictly positive real (SPR) property. Simulation results of a quadrotor UAV and a mathematical system are presented. A comparative analysis is performed with another approach to emphasize the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Oussama Bey and Mohamed Chemachema},
  doi          = {10.1016/j.ins.2024.120557},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120557},
  shortjournal = {Inf. Sci.},
  title        = {Finite-time event-triggered output-feedback adaptive decentralized echo-state network fault-tolerant control for interconnected pure-feedback nonlinear systems with input saturation and external disturbances: A fuzzy control-error approach},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MAB-RP: A multi-armed bandit based workers selection scheme
for accurate data collection in crowdsensing. <em>ISCI</em>,
<em>669</em>, 120554. (<a
href="https://doi.org/10.1016/j.ins.2024.120554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate data collection from workers is crucial for the success of Mobile Crowd Sensing (MCS) applications. However, Current studies exhibit several drawbacks. Firstly, the workers&#39; sensing qualities remain unknown even after the platform acquires the data submitted by the workers, known as the Post Unknown Worker Selection (PUWS) problem. Secondly, systematic deviations between worker data and the Ground Truth Data (GTD) reduce the quality of MCS applications. Thirdly, the data collected by workers for different tasks may vary in accuracy, resulting in low-quality data collection. To address these challenges, we propose a novel Multi-armit-based worker selection scheme with reputation and preference (MAB-RP). The proposed scheme aims to select credible workers for high-quality data collection through trust identification, thus addressing the PUWS issue after worker recruitment. Additionally, the scheme employs a learning-based approach to identify and correct the gaps between the sensed data and the GTD, ultimately improving the accuracy of data collection. Lastly, a matching-based approach is used to identify workers&#39; sensing qualities for different tasks, further enhancing the accuracy of data collection in MCS. Extensive simulations on real-world datasets demonstrate that the proposed MAB-RP scheme outperforms previous strategies in terms of both data quality and cost.},
  archive      = {J_ISCI},
  author       = {Yuwei Lou and Jianheng Tang and Feijiang Han and Anfeng Liu and Neal N. Xiong and Shaobo Zhang and Tian Wang and Mianxiong Dong},
  doi          = {10.1016/j.ins.2024.120554},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120554},
  shortjournal = {Inf. Sci.},
  title        = {MAB-RP: A multi-armed bandit based workers selection scheme for accurate data collection in crowdsensing},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Biometric identification on the cloud: A more secure and
faster construction. <em>ISCI</em>, <em>669</em>, 120553. (<a
href="https://doi.org/10.1016/j.ins.2024.120553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud-assisted biometric identification can benefit data owners with limited resources by offloading their storage and identification tasks to cloud servers with abundant resources. However, the adoption of this computing paradigm is hindered by security and privacy concerns. To solve the dilemma, several privacy-preserving cloud-assisted biometric identification protocols have been proposed. Nevertheless, the existing designs suffer from one or more of the following restrictions: (1) support only for data owner-online query, (2) low security level, and (3) inefficiency. Motivated by these challenges, this paper aims to explore a more secure and efficient construction. Concretely, we initialize the error weighted hashing (EWH)-based data packing technique to replace the time-consuming linear scan search during the identification process. Additionally, to ensure compatibility with the EWH-based search algorithm, we formulate an identity ( id )-based scoring strategy and introduce a random split-based data encryption algorithm, which circumvents the costly homomorphic encryption scheme. Within the framework of the two non-colluding servers model, the random split-based one-time pad encryption guarantees provably indistinguishable security against chosen-plaintext attacks. Finally, since only simple hash and xor operations are involved, our novel construction exhibits significantly improved performance compared to prior designs, both in theory and in practice. This superiority is validated through rigorous theoretical analysis and extensive experimental evaluation.},
  archive      = {J_ISCI},
  author       = {Duo Wu and Leibo Li and Weizhong Tian and Hequn Xian and Chengliang Tian},
  doi          = {10.1016/j.ins.2024.120553},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120553},
  shortjournal = {Inf. Sci.},
  title        = {Biometric identification on the cloud: A more secure and faster construction},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective evolutionary algorithm with
evolutionary-status-driven environmental selection. <em>ISCI</em>,
<em>669</em>, 120551. (<a
href="https://doi.org/10.1016/j.ins.2024.120551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hardly dominated boundary (HDB) is a common feature of multi-objective optimization problems (MOPs). Previous studies have proposed several multi-objective evolutionary algorithms (MOEAs) to deal with the problem characterized by HDBs. Nevertheless, these methods lack consideration of the evolutionary status, potentially resulting in low efficiency when addressing problems that entail a confluence of HDB and other intricate characteristics. This paper proposes an MOEA with evolutionary-status-driven environmental selection (MOEA-ESD) to address such an issue. Specifically, in each generation, the current and historical information are used to evaluate the evolutionary status. Based on the estimated evolutionary status, the proposed MOEA-ESD algorithm adaptively uses three types of environmental selection: the traditional environmental selection ( TES ) based on Pareto-dominance and crowding distance, a convergence-first environmental selection ( CFES ) based on Gaussian mixture model clustering, and a diversity-first environmental selection ( DFES ) based on outlier detection and extreme solutions. In this way, inferior solutions situated on the HDB can be effectively eliminated, thereby facilitating the convergence of the population while concurrently preserving a commendable degree of diversity. Moreover, a set of new benchmark problems with different objective magnitudes and complicated Pareto sets is developed to enrich the features of HDB-MOPs and to verify the algorithm&#39;s performance. Our experimental results on 22 HDB-MOPs show the promising performance of the proposed algorithm. The source code of MOEA-ESD is available at https://github.com/CIAM-Group/EvolutionaryAlgorithm_Codes/tree/main/MOEA-ESD .},
  archive      = {J_ISCI},
  author       = {Kangnian Lin and Genghui Li and Qingyan Li and Zhenkun Wang and Hisao Ishibuchi and Hu Zhang},
  doi          = {10.1016/j.ins.2024.120551},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120551},
  shortjournal = {Inf. Sci.},
  title        = {Multi-objective evolutionary algorithm with evolutionary-status-driven environmental selection},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transfer learning in cross-domain sequential recommendation.
<em>ISCI</em>, <em>669</em>, 120550. (<a
href="https://doi.org/10.1016/j.ins.2024.120550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation captures users&#39; dynamic preferences by modeling the sequential information of their behaviors. However, most existing works only focus on users&#39; behavior sequences in a single domain, and when there is insufficient data in the target domain, the recommendation performance may not be satisfactory. We notice that a user&#39;s interests are usually diverse, for which the items he/her interacts with in a period of time may be from multiple domains. Moreover, there are also item transition patterns across sequences from different domains, which means that a user&#39;s interaction in one domain may affect his/her interaction in the other domains next time. In this paper, we aim to improve the performance of sequential recommendation in the target domain by introducing users&#39; behavior sequences from multiple source domains, and propose a novel solution named transfer via joint attentive preference learning (TJAPL). Specifically, we tackle the studied problem from the perspective of transfer learning and attentive preference learning (APL). For target-domain APL, we adopt the self-attention mechanism to capture the users&#39; dynamic preferences in the target domain. Furthermore, to address the scarcity challenge posed by limited target-domain data, we introduce users&#39; behavioral sequences in the source domain, and devise cross-domain user APL to transfer and share the users&#39; overall preferences from multiple source domains to the target domain. We also design cross-domain local APL that specializes in capturing the item transition patterns across different domains for knowledge transfer. These modules are all based on the attention mechanism and thus can accelerate the training by parallel computation. Notice that our TJAPL can be applied to scenarios with multiple source domains, while transferring knowledge from multiple domains is potentially helpful in practical applications. Extensive empirical studies indicate that our TJAPL significantly outperforms thirteen recent and competitive baselines.},
  archive      = {J_ISCI},
  author       = {Zitao Xu and Weike Pan and Zhong Ming},
  doi          = {10.1016/j.ins.2024.120550},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120550},
  shortjournal = {Inf. Sci.},
  title        = {Transfer learning in cross-domain sequential recommendation},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved multi-operator differential evolution with
two-phase migration strategy for numerical optimization. <em>ISCI</em>,
<em>669</em>, 120548. (<a
href="https://doi.org/10.1016/j.ins.2024.120548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last decade, the multi-operator differential evolution (MODE) has become one of the most popular research areas in the differential evolution (DE) family. Among these MODEs, an improved multi-operator differential evolution (IMODE) has achieved success as the winner in CEC2020. Despite its good performance, the random information sharing strategy may not efficiently handle the balance between exploration and exploitation for the complex numerical optimization. To address this limitation, we propose a two-phase migration strategy (TMS) to improve the performance of IMODE, called IMODE-TMS. In the first phase, the top-ranked individuals in each sub-population are retained for exploitation, and all the bottom-ranked individuals are assigned to three sub-populations to maintain diversity. Furthermore, the second phase plays a crucial role in eliminating stagnation. When a sub-population is identified as stagnant by the stagnation indicator, the optimal individual will migrate to that sub-population following the uni-directional ring structure. This process is mainly used to increase the off-trap capability on some problems with complex fitness landscapes. IMODE-TMS is tested on the CEC2020, CEC2021 and CEC2022 benchmark functions, and seven well-known complex global trajectory optimization problems (GTOP). The experimental results show that IMODE-TMS significantly outperforms not only IMODE but also other state-of-the-art comparison algorithms.},
  archive      = {J_ISCI},
  author       = {Zhuoming Yuan and Lei Peng and Guangming Dai and Maocai Wang and Jian Li and Wanbing Zhang and Qianqian Yu},
  doi          = {10.1016/j.ins.2024.120548},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120548},
  shortjournal = {Inf. Sci.},
  title        = {An improved multi-operator differential evolution with two-phase migration strategy for numerical optimization},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VMMP: Verifiable privacy-preserving multi-modal multi-task
prediction. <em>ISCI</em>, <em>669</em>, 120547. (<a
href="https://doi.org/10.1016/j.ins.2024.120547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer is emerging as a promising model with intrinsic traits in various multi-modal applications. Edge computing has provided an efficient platform for computationally-weak clients, but this entails risks to confidential data and proprietary models. Prior works on the privacy-preserving transformer-based inference only process a single modal data and protect confidential data or model parameters, or approximate non-linear functions with utility degradation. To mitigate the aforementioned issues, we propose the first verifiable outsourcing framework for multi-modal multi-task prediction (VMMP) via the additive secret sharing technique in an edge computing paradigm, which not only ensures the confidentiality of local data and model parameters but also guarantees the verifiability of prediction results. The security analysis and computational consumption reveal that VMMP can save the time costs of clients by 87%, 30%, and 40% compared to the original model on three types of cross-modal tasks and achieves significant time cost savings on the client side compared to the previous works in a secure manner. To evaluate the effective utility, VMMP is examined on three public datasets across visual and language modalities. Extensive evaluations indicate that VMMP outperforms the related works without utility degradation.},
  archive      = {J_ISCI},
  author       = {Mingyun Bian and Yanli Ren and Gang He and Guorui Feng and Xinpeng Zhang},
  doi          = {10.1016/j.ins.2024.120547},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120547},
  shortjournal = {Inf. Sci.},
  title        = {VMMP: Verifiable privacy-preserving multi-modal multi-task prediction},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FLEX: A fast and light-weight learned index for kNN search
in high-dimensional space. <em>ISCI</em>, <em>669</em>, 120546. (<a
href="https://doi.org/10.1016/j.ins.2024.120546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k Nearest Neighbors ( k NN) search in high-dimensional space is a fundamental problem with various applications. In this paper, we try to solve this problem by using deep neural networks (DNNs). We apply DNNs to represent complex correlations between high-dimensional objects, enabling us to project similar objects into the same class, thus reducing the search cost. Based on DNNs, we propose two novel techniques to improve query efficiency while keeping accuracy. First, traditional DNNs typically demand extensive training data for achieving high accuracy. To decrease the training size, we design a multi-module DNN framework comprising several small modules. Each module learns to capture part of knowledge for the given query. The collective output of these sub-modules is then seamlessly integrated to form the final result. Second, with machine learning models, the size of candidates are unbounded. Thus, we design a linear-time data layout refinement algorithm, aiming to limit the number of candidates to a small constant. Empirically we find that our approach significantly outperforms the state-of-the-art methods in terms of both time efficiency and space efficiency while still attaining comparable or better accuracy.},
  archive      = {J_ISCI},
  author       = {Lingli Li and Ao Han and Xiaotong Cui and Baohua Wu},
  doi          = {10.1016/j.ins.2024.120546},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120546},
  shortjournal = {Inf. Sci.},
  title        = {FLEX: A fast and light-weight learned index for kNN search in high-dimensional space},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Homotopic quantum fuzzy adaptive simulated annealing [HQF
ASA]. <em>ISCI</em>, <em>669</em>, 120529. (<a
href="https://doi.org/10.1016/j.ins.2024.120529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The work proposes a new approach for evolutionary global optimization which, in simple terms, may be described as a fusion of quantum and simulated annealing. This becomes possible by using basic concepts from Homotopy Theory, conjugated to the already existing Fuzzy Adaptive Simulated Annealing paradigm and other components. In this fashion, it occurs a temporal and nonlinear superposition of the two types of annealing, provoking interesting effects in runtime, including the so-called quantum tunneling, when there is a sudden transition between attraction basins of different minima without “climbing” potential barriers. In addition, the proposal includes a generalization of the “deformation” of Hamiltonians used in quantum annealing by suggesting the use of general homotopies between the surface corresponding to the cost function under processing and another specific landscape, being this possible because of the ability of Fuzzy ASA of handling time-varying objective functions. The proposed paradigm shows that it is possible and beneficial to superpose the two types of annealing, displaying amazing numerical results and suggesting a kind of interlacing or synergic behavior - perhaps we could call it an “annealing entanglement”. Finally, given the fast advances in commercial quantum annealing processors, it seems sensible to expect that an implementation of the proposed approach using such devices may occur very soon. In order to demonstrate the efficacy of the proposed algorithm, some significant and detailed examples are included in the text, so as to illustrate and clarify the presented ideas.},
  archive      = {J_ISCI},
  author       = {Hime A. e Oliveira Jr.},
  doi          = {10.1016/j.ins.2024.120529},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120529},
  shortjournal = {Inf. Sci.},
  title        = {Homotopic quantum fuzzy adaptive simulated annealing [HQF ASA]},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PT-ADP: A personalized privacy-preserving federated learning
scheme based on transaction mechanism. <em>ISCI</em>, <em>669</em>,
120519. (<a href="https://doi.org/10.1016/j.ins.2024.120519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy (DP) is a widely used technique for enhancing privacy in federated learning (FL) frameworks, whereby noise is added to the datasets or learning parameters to prevent attackers from discovering which client (i.e., the data owner) the sensitive information originated from. More noise implies higher privacy protection but also leads to a decrease in model accuracy. The privacy budget is a key parameter that controls the amount of noise. Most existing methods focus on the same privacy budget, ignoring the various privacy protection requirements of the clients. In this study, we propose PT-ADP, which is a personalized privacy-preserving federated learning scheme. First, a privacy transaction mechanism (PT) is proposed to realize personalized allocation of privacy budget for clients through “quotation-allocation.” Subsequently, an adaptive transmission data perturbation mechanism (ADP) is proposed to save a large amount of privacy budget and improve accuracy under the premise of providing sufficient privacy protection. The security, convergence, efficiency, and specific parameters of the proposed scheme were theoretically analyzed and verified through extensive experiments. PT-ADP can improve model availability while providing the same level of privacy protection compared to other schemes, without increasing complexity and communication overhead.},
  archive      = {J_ISCI},
  author       = {Jiaqi Xia and Pengyong Li and Yiming Mao and Meng Wu},
  doi          = {10.1016/j.ins.2024.120519},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120519},
  shortjournal = {Inf. Sci.},
  title        = {PT-ADP: A personalized privacy-preserving federated learning scheme based on transaction mechanism},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SYEnet: Simple yet effective network for palmprint
recognition. <em>ISCI</em>, <em>669</em>, 120518. (<a
href="https://doi.org/10.1016/j.ins.2024.120518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Palmprint recognition techniques have been widely applied in security authentication. As a typical image processing method, convolutional neural network (CNN) has been applied to extract features from palmprint images. However, most existing CNN methods cannot meet the demand in recognition speed due to their high computational complexity. This paper proposes a simple yet effective network (SYEnet) for palmprint recognition, which is a lightweight neural network. SYEnet is composed of four learnable feature extraction networks, which can extract discriminative information from 9 patches. In addition, a dedicated network for palmprint ROI extraction (PREnet) is designed. PREnet extracts ROI from the original image, generating ROI images of consistent dimensions, which can be adapted to complex environments without limitations of lighting, gesture, image quality, and resolution. Moreover, a new contactless palmprint database is collected to validate our method. The database contains 12,800 images from 400 palms and provides data supplementation for current research on palmprint recognition. The proposed SYEnet is evaluated on eight real-world palmprint databases, in comparison to other related methods. Experimental results prove that our method is more efficient and has higher recognition accuracy.},
  archive      = {J_ISCI},
  author       = {Siyuan Ma and Qintai Hu and Shuping Zhao and Siyuan Chen and Lin Jiang},
  doi          = {10.1016/j.ins.2024.120518},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120518},
  shortjournal = {Inf. Sci.},
  title        = {SYEnet: Simple yet effective network for palmprint recognition},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The strategy of consensus and consistency improving
considering bounded confidence for group interval-valued intuitionistic
multiplicative best-worst method. <em>ISCI</em>, <em>669</em>, 120489.
(<a href="https://doi.org/10.1016/j.ins.2024.120489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To significantly and reasonably enhance the individual consistency and group consensus in group best-worst method (GBWM) under interval-valued intuitionistic multiplicative environment, this study proposes a strategy of consensus and consistency improving considering bounded confidence. Firstly, based on the consistency definition of interval-valued intuitionistic multiplicative preference relations (IVIMPRs), the consistency definition for interval-valued intuitionistic multiplicative reference comparison relations (IVIMRCRs) is proposed. Subsequently, a two-stage consistency improving optimization model is constructed. Then, an interactively iterative consistency improving algorithm considering bounded confidence is designed. For GBWM with IVIMRCRs, the concept of consensus measure is first defined to assess the consensus level among individual IVIMRCRs, and then a two-stage consensus improving optimization model considering bounded confidence is constructed. Additionally, based on the above theories and models, an interactively iterative consensus improving algorithm considering bounded confidence and consistency management is designed for GBWM with IVIMRCRs. Finally, the practicality and effectiveness of the proposed GBWM are verified through an actual application case and simulation analyses. Meanwhile, the advantages of this method are explained through comparative analyses with the existing BWMs and group decision making (GDM) with IVIMPRs.},
  archive      = {J_ISCI},
  author       = {Xiao-Yun Lu and Jiu-Ying Dong and Shu-Ping Wan and He-Cheng Li},
  doi          = {10.1016/j.ins.2024.120489},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120489},
  shortjournal = {Inf. Sci.},
  title        = {The strategy of consensus and consistency improving considering bounded confidence for group interval-valued intuitionistic multiplicative best-worst method},
  volume       = {669},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mining negative samples on contrastive learning via
curricular weighting strategy. <em>ISCI</em>, <em>668</em>, 120534. (<a
href="https://doi.org/10.1016/j.ins.2024.120534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning, which pulls positive pairs closer and pushes away negative pairs, has remarkably propelled the development of self-supervised representation learning. Previous studies either neglected negative sample selection, resulting in suboptimal performance, or emphasized hard negative samples from the beginning of training, potentially leading to convergence issues. Drawing inspiration from curriculum learning, we find that learning with negative samples ranging from easy to hard improves both model performance and convergence rate. Therefore, we propose a dynamic negative sample weighting strategy for contrastive learning. Specifically, we design a loss function that adaptively adjusts the weights assigned to negative samples based on the model&#39;s performance. Initially, the loss prioritizes easy samples, but as training advances, it shifts focus to hard samples, enabling the model to learn more discriminative representations. Furthermore, to prevent an undue emphasis on false negative samples during later stages, which probably results in trivial solutions, we apply L 2 L2 regularization on the weights of hard negative samples. Extensive qualitative and quantitative experiments demonstrate the effectiveness of the proposed weighting strategy. The ablation study confirms both the reasonableness of the curriculum and the effectiveness of the regularization.},
  archive      = {J_ISCI},
  author       = {Jin Zhuang and Xiao-Yuan Jing and Xiaodong Jia},
  doi          = {10.1016/j.ins.2024.120534},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120534},
  shortjournal = {Inf. Sci.},
  title        = {Mining negative samples on contrastive learning via curricular weighting strategy},
  volume       = {668},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Fair large kernel embedding with relation-specific features
extraction for link prediction. <em>ISCI</em>, <em>668</em>, 120533. (<a
href="https://doi.org/10.1016/j.ins.2024.120533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding is a crucial technique for addressing the challenge of incomplete knowledge graphs, and convolutional neural networks are widely applied in this domain. However, convolutional neural networks face limitations in effectively capturing long-range dependencies between entities and relations in feature maps. Moreover, existing knowledge graph embedding models often adopt a uniform perspective on all relations within a knowledge graph, thereby overlooking the relation-specific features. To address the two issues, two novel knowledge graph embedding models, L arge K ernel E mbedding (LKE) and L arge K ernel E mbedding with R elation-specific Features Extraction (LKER), are proposed. The effectiveness of knowledge graph embedding is improved by integrating fair large kernel attention and introducing a parallel branch for relation-specific feature extraction in these models. Specifically, fair large kernel attention is incorporated into LKE, capturing long-range dependencies within the model. Based on LKE, LKER adds a parallel relationship-specific feature extraction branch to obtain more comprehensive relationship-specific feature information. The proposed models are extensively evaluated on five benchmark datasets, and the results show that the proposed models yield significant performance improvements in link prediction compared to classical and latest knowledge graph embedding models.},
  archive      = {J_ISCI},
  author       = {Qinghua Zhang and Shuaishuai Huang and Qin Xie and Fan Zhao and Guoyin Wang},
  doi          = {10.1016/j.ins.2024.120533},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120533},
  shortjournal = {Inf. Sci.},
  title        = {Fair large kernel embedding with relation-specific features extraction for link prediction},
  volume       = {668},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Integrating confidence calibration and adversarial
robustness via adversarial calibration entropy. <em>ISCI</em>,
<em>668</em>, 120532. (<a
href="https://doi.org/10.1016/j.ins.2024.120532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vulnerability of deep neural networks to adversarial samples poses significant security concerns. Previous empirical analyses have shown that increasing adversarial robustness through adversarial training leads to models making unconfident decisions, undermining trust in model confidence scores as an accurate indication of their reliability. This raises the question: are adversarial robustness and confidence calibration mutually exclusive? In this work, we find empirically that adversarial examples mislead undefended models to make more confident mistakes during an attack and that adversarial training causes models to become more risk-averse. Further, we investigate the phenomenon of adversarial degradation from an uncertainty perspective and demonstrate that confidence and adversarial robustness can exhibit a uniform trend. To simultaneously improve the model&#39;s adversarial robustness and confidence calibration performance, we propose a novel adversarial calibration entropy to regularize the cross-entropy. Extensive experiments show that our approach increases the confidence that the model makes correct decisions and achieves adversarial robustness comparable to current state-of-the-art models.},
  archive      = {J_ISCI},
  author       = {Yong Chen and Peng Hu and Zhong Yuan and Dezhong Peng and Xu Wang},
  doi          = {10.1016/j.ins.2024.120532},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120532},
  shortjournal = {Inf. Sci.},
  title        = {Integrating confidence calibration and adversarial robustness via adversarial calibration entropy},
  volume       = {668},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DRGAT: Dual-relational graph attention networks for
aspect-based sentiment classification. <em>ISCI</em>, <em>668</em>,
120531. (<a href="https://doi.org/10.1016/j.ins.2024.120531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment classification has become a popular topic in natural language processing. Exploiting dependency syntactic information with graph neural networks has recently become a popular trend. Despite their success, methods that rely heavily on a dependency tree face major challenges. This concerns the alignment of aspects and their word sentiments due to the richness of the language and the fact that a dependency tree might produce noisy signals from unrelated associations. This paper introduces a Dual-Relational Graph Attention Network (DRGAT) that fully exploits syntactic structural information and then the sentiment-aware context (e.g., phrase segmentation and hierarchical structure) of the constituent tree of a sentence. Additional constituency and dependency attention mechanisms provide comprehensive syntactic information across words, thereby enabling an accurate connection between aspect words and corresponding sentiment words. Considering that the original parsed constituency tree may have a large depth, this could lead to words being far apart increasing the computational overhead. The constituency tree of each sentence is dynamically reconstructed by determining the importance of each relational node. Extensive experimental results on six English datasets demonstrated that fully exploiting syntactic information can achieve excellent sentiment classification results.},
  archive      = {J_ISCI},
  author       = {Lan You and Jiaheng Peng and Hong Jin and Christophe Claramunt and Haoqiu Zeng and Zhen Zhang},
  doi          = {10.1016/j.ins.2024.120531},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120531},
  shortjournal = {Inf. Sci.},
  title        = {DRGAT: Dual-relational graph attention networks for aspect-based sentiment classification},
  volume       = {668},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blockchain-based reliable task offloading framework for
edge-cloud cooperative workflows in IoMT. <em>ISCI</em>, <em>668</em>,
120530. (<a href="https://doi.org/10.1016/j.ins.2024.120530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the evolution of I nternet o f M edical T hings (IoMT), the number of terminal devices has grown exponentially. This has led to a substantial influx of health-related data, which is transmitted among various distributed terminal devices and edge-cloud servers. This data is subsequently processed to provide real-time medical services and assistance. Nevertheless, within this context, challenges such as user mobility, stringent requirements, heterogeneous nature of resources, and data security concerns pose substantial obstacles for the task offloading problem. To address these challenges, we introduce a B lockchain-based R eliable T ask O ffloading (BRTO) framework for edge-cloud cooperative workflows in IoMT system. Specifically, we establish a three-layer edge-cloud cooperative framework that leverages blockchain and S oftware D efined N etwork (SDN) to enhance task offloading efficiency and security. Subsequently, we formulate and model the task offloading problem as an optimization model that takes into account latency, energy efficiency, and security. Then, we propose a two-phase offloading algorithm based on blockchain smart contracts to solve the problem. It involves the use of an enhanced Ant-based algorithm for optimal task offloading decisions and the creation of an SDN-based smart contract to guarantee data security. Comprehensive experimental results illustrate that BRTO outperforms other strategies in terms of scalability, robustness, efficiency, and reliability.},
  archive      = {J_ISCI},
  author       = {Juan Li and Mengyuan Zhu and Jin Liu and Wei Liu and Bo Huang and Ruhong Liu},
  doi          = {10.1016/j.ins.2024.120530},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120530},
  shortjournal = {Inf. Sci.},
  title        = {Blockchain-based reliable task offloading framework for edge-cloud cooperative workflows in IoMT},
  volume       = {668},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blockchain service platform evaluation with probabilistic
linguistic preference information based on choquet integral and
ExpTODIM. <em>ISCI</em>, <em>668</em>, 120528. (<a
href="https://doi.org/10.1016/j.ins.2024.120528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of Internet of Medical Things (IoMT) can improve the treatment efficiency of medical institutions, but it still has hidden dangers in security and privacy. The introduction of blockchain technology into IoMT is expected to prevent these hidden dangers. This study proposes a multiple criteria decision aiding model to select a suitable blockchain service platform for IoMT to enhance its safety and reliability. The proposed model combines the probabilistic linguistic term set (PLTS), multiple criteria hierarchy process (MCHP), 2-additive Choquet integral and ExpTODIM method to assist decision-makers (DMs) to obtain a reliable and low-risk decision result. The MCHP is employed to analyze decision-making problems by hierarchical criteria. The 2-additive Choquet integral is adopted to reflect interactions between criteria, and parameter values in the 2-additive Choquet integral are indirectly determined based on the preference information of DMs. PLTSs are used to represent the evaluation information of experts and the preference information of DMs. The ExpTODIM (Exponential TODIM) method is adopted to rank alternatives considering the psychological characteristics of DMs. An illustrative example demonstrates the applicability and merits of the proposed model with comparative analysis.},
  archive      = {J_ISCI},
  author       = {Zhi Wen and Huchang Liao},
  doi          = {10.1016/j.ins.2024.120528},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120528},
  shortjournal = {Inf. Sci.},
  title        = {Blockchain service platform evaluation with probabilistic linguistic preference information based on choquet integral and ExpTODIM},
  volume       = {668},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rethinking the defense against free-rider attack from the
perspective of model weight evolving frequency. <em>ISCI</em>,
<em>668</em>, 120527. (<a
href="https://doi.org/10.1016/j.ins.2024.120527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a distributed machine learning approach where multiple clients collaboratively train a joint model without exchanging their own data. Despite FL&#39;s unprecedented success in data privacy-preserving, its vulnerability towards free-rider attacks. Numerous defense methods have been proposed, however, they fail to resist highly camouflaged free-riders. To address these challenges, we reconsider the defense from a novel perspective, i.e., model weight evolving frequency. Empirically, we gain a novel insight that during the FL&#39;s training, the model weight evolving frequency of free-riders and that of benign clients are significantly different. Inspired by this insight, we propose a novel defense method based on the model W eight E volving F requency , referred to as WEF-Defense. Specifically, we first collect the weight evolving frequency (defined as WEF-Matrix) during local training. Each client uploads the WEF-Matrix of the local model as well as the model weights to the server. The server then separates free-riders from benign clients based on the difference in the WEF-Matrix. At last, the server provides different global models for the corresponding clients using a personalization algorithm, which prevents free-riders from gaining high-quality models. Comprehensive experiments conducted on five datasets and five models demonstrate that WEF-Defense achieves better defense effectiveness (∼×1.4) than the state-of-the-art baselines and identifies free-riders at an earlier stage of training. Besides, we verify the effectiveness of WEF-Defense against an adaptive attack and visualize the WEF-Matrix during the training to interpret its effectiveness. The data and code of WEF-Defense are available at: https://github.com/research-limingjun/WEF-Defense.git .},
  archive      = {J_ISCI},
  author       = {Jinyin Chen and Mingjun Li and Tao Liu and Haibin Zheng and Hang Du and Yao Cheng},
  doi          = {10.1016/j.ins.2024.120527},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120527},
  shortjournal = {Inf. Sci.},
  title        = {Rethinking the defense against free-rider attack from the perspective of model weight evolving frequency},
  volume       = {668},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-stage consensus reaching process in social network large
group decision-making with application to battery supplier selection.
<em>ISCI</em>, <em>668</em>, 120526. (<a
href="https://doi.org/10.1016/j.ins.2024.120526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust relationships play an important role in social network large group decision making (SN-LGDM). Extant studies overlook the self-adjustment stage of decision makers (DMs) and the binding force of subgroup on preference adjustment in consensus reaching process (CRP). This article proposes a new two-stage CRP for SN-LGDM considering self-adjustment and binding force of subgroup. A new trust propagation approach is presented based on individual trust level. An improved grey clustering algorithm is devised based on the fusion of preference similarity and trust relationship. The preference stability and the awareness of big picture are defined to determine the weights of DMs. The subgroup size, cohesion and influence are integrated to determine the weights of subgroups comprehensively. For the new two-stage CRP, the first stage is self-adjustment stage. DMs may proactively choose to adjust the preference or update the trust relationship according to the degree of matching between the trust relationship and preference difference. In the second stage, four scenarios are identified and the corresponding adjustment strategies are given considering the intention of DM to modify and the binding force of subgroup, which makes the consensus more consistent with reality. A battery supplier selection case is offered to illustrate the proposed method.},
  archive      = {J_ISCI},
  author       = {Shu-Ping Wan and Jiu-Ying Dong and Zhi-Hao Zhang},
  doi          = {10.1016/j.ins.2024.120526},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120526},
  shortjournal = {Inf. Sci.},
  title        = {Two-stage consensus reaching process in social network large group decision-making with application to battery supplier selection},
  volume       = {668},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive histogram equalization with visual perception
consistency. <em>ISCI</em>, <em>668</em>, 120525. (<a
href="https://doi.org/10.1016/j.ins.2024.120525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Histogram equalization (HE) is a well-established method for image contrast enhancement due to its simplicity and effectiveness. However, it suffers from three main shortcomings, i.e., over-enhancement, under-enhancement and mean shift. To address these issues, this paper proposes a systematic scheme, that is, adaptive histogram equalization with visual perception consistency (AHEVPC). Firstly, a novel histogram correction model is designed to get the optimal controlling parameters, which specifically address the aforementioned issues of HE. Besides, considering the subjective perception of the initial output of the model, two strategies are proposed to make the enhanced image more natural and comfortable. Finally, histogram equalization is applied to the modified histogram. Extensive experimental results demonstrate that the proposed scheme is reasonable and effective, and outperforms several state-of-the-art methods in terms of subjective and objective metrics.},
  archive      = {J_ISCI},
  author       = {Qi Yuan and Shengkui Dai},
  doi          = {10.1016/j.ins.2024.120525},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120525},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive histogram equalization with visual perception consistency},
  volume       = {668},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive differential evolution algorithm based on
archive reuse. <em>ISCI</em>, <em>668</em>, 120524. (<a
href="https://doi.org/10.1016/j.ins.2024.120524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, differential evolution algorithms based on archives have achieved significant success because archives can increase population diversity and balance the exploration and exploitation of algorithms. However, insufficient utilisation of archives has led to an imbalance between exploration and exploitation. Herein, a new archive-reuse-based adaptive differential evolution (AR-aDE) algorithm framework is proposed that can be applied to (L)SHADE and its variants. It comprises three main strategies. First, a new external archive update method based on a cache mechanism is proposed, in which the archive size is the same as the population size, eliminating the need to adjust its size. Second, influenced by knowledge transfer in multitasking optimisation, we designed a new method of reusing the archive to better utilise the information in it. Finally, the classic parameter adaptation method was improved. The experimental results for the CEC2020 and CEC2021 competition problem sets show that the KR-aDE has a strong competitive advantage.},
  archive      = {J_ISCI},
  author       = {Zhihua Cui and Ben Zhao and Tianhao Zhao and Xingjuan Cai and Jinjun Chen},
  doi          = {10.1016/j.ins.2024.120524},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120524},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive differential evolution algorithm based on archive reuse},
  volume       = {668},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). More communication-efficient distributed sparse learning.
<em>ISCI</em>, <em>668</em>, 120523. (<a
href="https://doi.org/10.1016/j.ins.2024.120523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a modern distributed learning framework, the speeds of intra-worker calculation and inter-worker communication may differ by 1,000 times. It is advisable to perform expensive calculations on worker machines and communicate as few rounds as possible. In this paper, we propose three novel distributed sparse learning algorithms (EDSL-ET, EDSL-IBCD, and EDSL-IBCD-ET) in high dimensions, which are efficient in both computation and communication. Algorithm EDSL-ET utilizes the Top k sparse technique to reduce communication costs and adopts error feedback to guarantee convergence. Algorithm EDSL-IBCD greatly reduces communication costs by introducing an independent block coordinate descent method. Algorithm EDSL-IBCD-ET takes advantage of EDSL-ET and EDSL-IBCD algorithms for extra-high dimensional feature learning, which is the best one whether in communication, computation, and stability. We give theoretical guarantees of the three algorithms under mild conditions, which match the performance of the centralized algorithm. Extensive experiments on simulated and real data validate our theoretical analysis and demonstrate that the proposed algorithms perform well with just a few rounds of communications.},
  archive      = {J_ISCI},
  author       = {Xingcai Zhou and Guang Yang},
  doi          = {10.1016/j.ins.2024.120523},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120523},
  shortjournal = {Inf. Sci.},
  title        = {More communication-efficient distributed sparse learning},
  volume       = {668},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differential evolution algorithm with a complementary
mutation strategy and data fusion-based parameter adaptation.
<em>ISCI</em>, <em>668</em>, 120522. (<a
href="https://doi.org/10.1016/j.ins.2024.120522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an excellent optimization algorithm widely used to solve various practical problems, differential evolution (DE) algorithm has few parameters, yet its performance is significantly affected by these parameters. To address this issue, this paper presents a novel variant of DE called DACDE, which utilizes data fusion-based parameter adaptation and a complementary mutation strategy. Most parameter adaptation methods based on successful history only analyze the mean of parameters and ignore their degree of dispersion. In DACDE, the successful parameter distribution is recorded and described by both the mean and variance. Data fusion is then used to combine records and generate an estimated distribution, which is applied to a Gaussian distribution to generate new parameters. Inspired by opposition-based learning, we introduce a complementary mutation strategy. This strategy employs a symmetric selection mechanism to adapt to the varying search abilities required by the algorithm at different stages. The new variant is verified on 32 single-objective functions from CEC 2011 and 2014 benchmark suites, and the results show that DACDE is competitive compared to other 29 evolutionary algorithms.},
  archive      = {J_ISCI},
  author       = {Bozhen Chen and Haibin Ouyang and Steven Li and Dexuan Zou},
  doi          = {10.1016/j.ins.2024.120522},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120522},
  shortjournal = {Inf. Sci.},
  title        = {Differential evolution algorithm with a complementary mutation strategy and data fusion-based parameter adaptation},
  volume       = {668},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A distributed attribute reduction based on neighborhood
evidential conflict with apache spark. <em>ISCI</em>, <em>668</em>,
120521. (<a href="https://doi.org/10.1016/j.ins.2024.120521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction is widely employed to improve the efficiency and accuracy of data analysis by eliminating redundant and irrelevant attributes from datasets. However, with the emergence of growing big data, the sequential execution of such algorithms becomes time-consuming and requires distributed computing capabilities to achieve scalable parallelization. This study proposes a novel attribute reduction algorithm for neighborhood decision systems. We introduce two novel metrics—the neighborhood evidential conflict degree (NECD) and neighborhood evidential conflict rate (NECR)—to compute heterogeneity between samples in the neighborhood and assess the significance of attributes in the feature space, respectively. These metrics assess the quality and selection of attribute subsets in attribute reduction, improving classification accuracy and computational efficiency. We also develop a sequentially forward selection attribute reduction method to select a feature subset through the defined NECR. Finally, we develop a distributed attribute reduction algorithm implemented in Apache Spark. Our approach involves a two-phase Map-Reduce process for K -Nearest Neighbors search, evidence combination, and NECR computation. NECR, as a measure of feature subset quality, enhances the feature subset&#39;s decision approximation capability of the data. Experimental results on small and large datasets demonstrate that the proposed algorithm outperforms benchmarking algorithms regarding classification accuracy and computational efficiency.},
  archive      = {J_ISCI},
  author       = {Yuepeng Chen and Weiping Ding and Hengrong Ju and Jiashuang Huang and Tao Yin},
  doi          = {10.1016/j.ins.2024.120521},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120521},
  shortjournal = {Inf. Sci.},
  title        = {A distributed attribute reduction based on neighborhood evidential conflict with apache spark},
  volume       = {668},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DualGAD: Dual-bootstrapped self-supervised learning for
graph anomaly detection. <em>ISCI</em>, <em>668</em>, 120520. (<a
href="https://doi.org/10.1016/j.ins.2024.120520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection (GAD) is an emerging and essential research field for discovering anomalous individuals (e.g., nodes or edges) that deviate significantly from the normal majority in an attributed graph. Unlike other anomaly types (e.g., image, text) with independence, it is not trivial to capture inherent and distinctive anomaly patterns as graph anomalies usually exist more complex relational interaction with a overwhelming amount of normal majority, which induces the inconsistency in feature and structure space. Recently, some studies have applied graph self-supervised learning on the GAD task and surge a new climax. Despite their success, the sub-optimal performance is only achieved because the imbalance nature of anomaly problem significantly dilutes anomalous information and causes the shortage of effective supervision signals. To address these challenges, we propose a dual-bootstrapped self-supervised approach, namely DualGAD, that consists of one generative module and one contrastive module. Specifically, we first sample a local subgraph for each target node and employ two mask strategies on subgraphs to break the short-range connection and reduce redundancy spread from majority neighbors. The generative module is equipped with the reconstruction objective to model the surrounding context of masked subgraphs, which learn discriminative representations by capturing the inconsistency patterns at both feature and structure space. Considering the local information is easily been over-emphasized, we elaborately tailor a novel cluster-guided contrastive learning module without relying on positive/negative pairs to learn the intrinsic anomaly property by aligning the perturbation distributions across views. Finally, the two self-supervised modules are seamlessly integrated and bootstrap each other for learning the discriminative representations to distinguish anomalies and normal majority. Extensive experiments demonstrate the superiority of DualGAD on the node-level anomaly detection task.},
  archive      = {J_ISCI},
  author       = {Hui Tang and Xun Liang and Jun Wang and Sensen Zhang},
  doi          = {10.1016/j.ins.2024.120520},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120520},
  shortjournal = {Inf. Sci.},
  title        = {DualGAD: Dual-bootstrapped self-supervised learning for graph anomaly detection},
  volume       = {668},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Exploring trajectory embedding via spatial-temporal
propagation for dynamic region representations. <em>ISCI</em>,
<em>668</em>, 120516. (<a
href="https://doi.org/10.1016/j.ins.2024.120516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In smart cities, the development of urban regions stands as a fundamental pillar in the planning process, significantly influencing the overall urban living experience. Effective representations of regions are essential for providing fundamental insights and enabling various applications in urban computing. While research on regional embeddings, especially in dynamic urban representations, has gained considerable attention, there is often a lack of in-depth investigation into the reciprocal impact of mobility trajectories and spatiotemporal interactions. To address this challenge, we present a novel Spatial-Temporal Dynamic Representation framework for urban regions (STDR) to uncover the dynamic functions and variation patterns. Our model leverages interaction information between human mobility and regional features based on motion trajectories, enabling time and geographic encoding for each region. It then combines temporal propagation and spatial proximity to aggregate dynamic function representations. Moreover, it implements a spatiotemporal gating mechanism addressing the imbalance issue in global spatiotemporal transmission. Compared with state-of-the-art research methods, our method can achieve more accurate performance in two downstream tasks.},
  archive      = {J_ISCI},
  author       = {Chunyu Liu and Hongli Zhang and Guopu Zhu and Haotian Guan and Sam Kwong},
  doi          = {10.1016/j.ins.2024.120516},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120516},
  shortjournal = {Inf. Sci.},
  title        = {Exploring trajectory embedding via spatial-temporal propagation for dynamic region representations},
  volume       = {668},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast multi-type resource allocation in local-edge-cloud
computing for energy-efficient service provision. <em>ISCI</em>,
<em>668</em>, 120502. (<a
href="https://doi.org/10.1016/j.ins.2024.120502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of information technology, the concept of local-edge-cloud computing has gained prominence. Operating on a collaborative model, heterogeneous computing nodes converge to deliver a spectrum of multi-type services, including calculation-intensive, latency-sensitive, and privacy-requiring services. This collaborative approach fosters high-quality development in power economy. However, the proliferation of heterogeneous computing nodes, while beneficial, introduces challenges. The intricate connections and limited energy supply may lead to interruptions in the service processes of nodes. In this study, we present an energy-efficient resource allocation scheme designed for low-latency multi-type service provision within a local-edge-cloud collaboration. Our methodology focuses on optimizing the performance of multi-type service provision in a local-edge-cloud network, taking into account considerations such as latency, resource allocation, and energy consumption. To accomplish this, we employ the Alopex-based Differential Evolution algorithm. Initially, we construct three sub-models to analyze latency and energy aspects across various computing modes. Subsequently, we formulate a constrained optimization problem aimed at minimizing both latency and energy consumption in multi-type service provisioning. These models seek to derive optimal resource allocation decisions for the given scenario. To address this optimization problem, we introduce the hybrid differential evolution algorithm, Alopex-DE. A formal analysis is conducted to showcase its near-optimal performance in comparison to three state-of-the-art algorithms. Additionally, extensive simulations are carried out to validate the superior effectiveness of our proposed approach.},
  archive      = {J_ISCI},
  author       = {Yishan Chen and Shumei Ye and Jianqing Wu and Bi Wang and Hui Wang and Wei Li},
  doi          = {10.1016/j.ins.2024.120502},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120502},
  shortjournal = {Inf. Sci.},
  title        = {Fast multi-type resource allocation in local-edge-cloud computing for energy-efficient service provision},
  volume       = {668},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A sentiment analysis and dual trust relationship-based
approach to large-scale group decision-making for online reviews: A case
study of china eastern airlines. <em>ISCI</em>, <em>667</em>, 120515.
(<a href="https://doi.org/10.1016/j.ins.2024.120515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of e-commerce, more and more people are willing to post their reviews and opinions about the products they buy online. Therefore, the use of online review data for decision-making appears to be more practical and universal, and how to effectively use this kind of data to support large-scale group decision-making (LSGDM) is a worthy research direction. In this paper, we firstly use sentiment analysis to analyze online review data to derive the decision maker&#39;s (DM&#39;s) sentiment value, and apply the sentiment value to construct a social network based on a dual trust relationship, which considers both familiarity-based trust and similarity-based trust. Secondly, a directed Louvain clustering algorithm in light of dual trust relationships and a method for solving the DM&#39;s intra-group weights and the group&#39;s weights are proposed based on this network. A two-stage clustering based consensus model in light of dual trust relationships is then proposed, in which the DMs in the agreement cluster can communicate with other DMs outside of such a cluster and dynamically update the grouping using the clustering algorithm. Finally, the practicality and effectiveness of the LSGDM method proposed in this paper are verified through a real case.},
  archive      = {J_ISCI},
  author       = {Lun Guo and Jianming Zhan and Gang Kou and Luis Martínez},
  doi          = {10.1016/j.ins.2024.120515},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120515},
  shortjournal = {Inf. Sci.},
  title        = {A sentiment analysis and dual trust relationship-based approach to large-scale group decision-making for online reviews: A case study of china eastern airlines},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An integrated QFD and FMEA method under the co-opetitional
relationship for product upgrading. <em>ISCI</em>, <em>667</em>, 120505.
(<a href="https://doi.org/10.1016/j.ins.2024.120505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving customer satisfaction is as important as reducing risk associated with product upgrades. The quality function deployment (QFD), as a customer-centric tool, is widely used for product improvement. The failure mode and effect analysis (FMEA) method is recognized as a reliability management tool. Considering the need to eliminate risks and meet customer expectations, building an integrated QFD-FMEA framework is useful for product upgrading. To enhance the performance, the QFD and FMEA methods are improved. First, the base criterion method (BCM) is used to derive the CR weights in the QFD method and RFs in the FMEA method. Second, the combined compromise solution (CoCoSo) method and interactive multi-criteria decision making (TODIM- Portuguese acronym) methods are utilized to derive the priority of TCs and FMs, respectively. Third, the interval-valued intuitionistic fuzzy set (IVIFS) is used to express the expert evaluation. Moreover, given that co-opetitional relationship exist in firms and lead to opinion interactions, the improved Hegselmann-Krause (HK) model is utilized in our improved method to stimulate opinion interaction under different competitive states in different phases. Finally, a case study is presented to validate the improved method, and its superiority is demonstrated through sensitivity and comparative analysis.},
  archive      = {J_ISCI},
  author       = {Yifan Wu and Peide Liu and Ying Li},
  doi          = {10.1016/j.ins.2024.120505},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120505},
  shortjournal = {Inf. Sci.},
  title        = {An integrated QFD and FMEA method under the co-opetitional relationship for product upgrading},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse k-means clustering algorithm with anchor graph
regularization. <em>ISCI</em>, <em>667</em>, 120504. (<a
href="https://doi.org/10.1016/j.ins.2024.120504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a classical unsupervised learning method, the K-means algorithm selects the cluster centers randomly and calculates the mean values of the cluster&#39;s data points to generate clusters. However, its performance is susceptible to the initial cluster centers and the sparsity of the membership matrix. To overcome these limitations, in this paper, we propose a sparse K-means clustering algorithm with anchor graph regularization (SKM-AGR) for optimizing initial cluster center sensitivity and improving membership matrix sparsity. The main idea is to use the anchor graph regularization (AGR) constrained K-means models, which effectively learn the membership matrix of data points and the membership matrix of anchors. In particular, by constructing an anchor graph, the AGR term not only discovers the internal structure information of data, but also covers the data distribution. Furthermore, an alternating optimization algorithm with fast-converging is adopted to solve the optimization problems of SKM-AGR, and the computational complexity is analyzed. Extensive clustering experiments on several synthetic and benchmark datasets show that the proposed SKM-AGR method performs better than several previous methods in most cases.},
  archive      = {J_ISCI},
  author       = {Xiaojun Yang and Weihao Zhao and Yuxiong Xu and Chang-Dong Wang and Bin Li and Feiping Nie},
  doi          = {10.1016/j.ins.2024.120504},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120504},
  shortjournal = {Inf. Sci.},
  title        = {Sparse K-means clustering algorithm with anchor graph regularization},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New distance measure-driven flexible linguistic consensus
model with application to urban flooding risk assessment. <em>ISCI</em>,
<em>667</em>, 120503. (<a
href="https://doi.org/10.1016/j.ins.2024.120503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a novel linguistic representation tool, flexible linguistic expression (FLE) has substantial flexibility in expressing ambiguous and uncertain information from experts. However, FLEs pose the following challenges to developing information measurement and consensus mechanisms for FLEs-based multi-attribute group decision-making (MAGDM). (1) The current studies primarily use linguistic distribution approximation or triangular fuzzy numbers to measure the difference between FLEs indirectly without proposing an exact distance measure. (2) Few studies have been conducted on direct accurate consensus models incorporating adaptive consensus feedback mechanisms. To deal with these issues, the flexible linguistic ordinal Deng entropy (FLODE) is firstly proposed to measure the uncertainty of FLEs, and by combining it with linguistic scale functions, a new distance measure for FLEs is constructed, which can accurately measure the level of group consensus and the difference in pairwise FLEs. Subsequently, by integrating the defined FLODE with the classical entropy weight method, a new method for determining the experts’ personalized attribute weights is constructed, fully considering the impact of experts’ personalized attribute weights on decision-making results. Also, a new consensus model incorporating a minimum adjustment feedback mechanism and dynamic personalized attribute weights is developed, in which the feedback adjustment coefficients and personalized attribute weights are dynamically updated during the consensus reaching process (CRP). Lastly, an urban flooding risk assessment is applied to confirm the effectiveness of the proposed consensus model.},
  archive      = {J_ISCI},
  author       = {Hao Tian and Shitao Zhang and Muhammet Deveci and Xiaodi Liu and Hao Xu},
  doi          = {10.1016/j.ins.2024.120503},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120503},
  shortjournal = {Inf. Sci.},
  title        = {New distance measure-driven flexible linguistic consensus model with application to urban flooding risk assessment},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LSFSR: Local label correlation-based sparse multilabel
feature selection with feature redundancy. <em>ISCI</em>, <em>667</em>,
120501. (<a href="https://doi.org/10.1016/j.ins.2024.120501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent studies, existing multilabel feature selection models have focused on either considering the relationship between labels or the redundancy between features. Furthermore, they only use simple sparsity constraints to process high-dimensional data without the intrinsic relationships between features and labels. These issues can have a great impact on the classification effectiveness of feature selection. To address these limitations, this article describes a new local label correlation-based sparse multilabel feature selection approach with feature redundancy. First, a new loss function is established among the matrices of samples, label coefficients, and labels. Then, the Frobenius norm is imposed to investigate the potential relationships between features and labels. The weight matrix is sparsified by the l 2,1 norm to ensure that the new loss function has high interpretability. Second, a manifold constraint is employed to capture the local geometric structure between labels and to delve deeper into the latent information among the local labels. Then manifold constraints and Laplacian scores are combined for embedding feature selection to guide the exploration of hidden latent label. Finally, by considering the differences between the feature scores and the redundancy between the samples, feature redundancy is analyzed via the modified cosine similarity, and a candidate feature subset with low redundancy is generated. The l 2 norm is used to select features with low redundancy while preserving sparsity, and a novel objective function is developed to optimize this solution. Thus, a sparse feature selection algorithm via local label correlation and feature redundancy is designed, and has demonstrated remarkable classification effectiveness in comparative experiments conducted on 21 multilabel datasets.},
  archive      = {J_ISCI},
  author       = {Lin Sun and Yuxuan Ma and Weiping Ding and Zhihao Lu and Jiucheng Xu},
  doi          = {10.1016/j.ins.2024.120501},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120501},
  shortjournal = {Inf. Sci.},
  title        = {LSFSR: Local label correlation-based sparse multilabel feature selection with feature redundancy},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rolling the dice for better deep learning performance: A
study of randomness techniques in deep neural networks. <em>ISCI</em>,
<em>667</em>, 120500. (<a
href="https://doi.org/10.1016/j.ins.2024.120500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a comprehensive empirical investigation into the interactions between various randomization techniques in Deep Neural Networks (DNNs) and their impact on learning performance. It is well-established that injecting randomness into the training process of DNNs, through various approaches, at different stages, is often beneficial for reducing overfitting and improving generalization. Nonetheless, the interactions between randomness techniques such as weight noise, dropout, and many others remain poorly understood. Consequently, it is challenging to determine which methods can be effectively combined to optimize DNN performance. To address this issue, we categorize the existing randomness techniques into four key types: injection of noise/randomness at the data, model structure, optimization or learning stage. We use this classification to identify gaps in the current coverage of potential mechanisms for the introduction of randomness, leading to proposing two new techniques: adding noise to the loss function and random masking of the gradient updates. In our empirical study, we employ a Particle Swarm Optimizer (PSO) for hyperparameter optimization (HPO) to explore the space of possible configurations to determine where and how much randomness should be injected to maximize DNN performance. We assess the impact of various types and levels of randomness for DNN architectures across standard computer vision benchmarks: MNIST, FASHION-MNIST, CIFAR10, and CIFAR100. Across more than 30 000 evaluated configurations, we perform a detailed examination of the interactions between randomness techniques and their combined impact on DNN performance. Our findings reveal that randomness through data augmentation and in weight initialization are the main contributors to performance improvement. Additionally, correlation analysis demonstrates that different optimizers, such as Adam and Gradient Descent with Momentum, prefer distinct types of randomization during the training process. A GitHub repository with the complete implementation and generated dataset is available. 2},
  archive      = {J_ISCI},
  author       = {Mohammed Ghaith Altarabichi and Sławomir Nowaczyk and Sepideh Pashami and Peyman Sheikholharam Mashhadi and Julia Handl},
  doi          = {10.1016/j.ins.2024.120500},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120500},
  shortjournal = {Inf. Sci.},
  title        = {Rolling the dice for better deep learning performance: A study of randomness techniques in deep neural networks},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep contrastive framework for unsupervised temporal link
prediction in dynamic networks. <em>ISCI</em>, <em>667</em>, 120499. (<a
href="https://doi.org/10.1016/j.ins.2024.120499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dynamic networks, temporal link prediction aims to predict the appearance and disappearance of links in future snapshots based on the network structure we have observed. It also plays a crucial role in network analysis and predicting the behavior of the dynamic system. However, most existing studies only focus on supervised temporal link prediction problems, i.e., taking part of the links in future snapshots as supervised information. The ones that can solve the unsupervised temporal link prediction problem are mainly based on matrix decomposition, which lack the capability to automatically extract nonlinear spatial and temporal features from dynamic networks. The most challenging part of this problem is to extract the inherent evolution of the patterns hidden in dynamic networks in unsupervised ways. Inspired by the application and achievement of contrastive learning in network representation learning, we propose a novel deep Contrastive framework for unsupervised Temporal Link Prediction (CTLP). Our framework is based on a deep encoder-decoder architecture, which can capture the nonlinear structure and temporal features automatically and can predict future links of subsequent snapshots of dynamic networks in an unsupervised manner. Besides, CTLP could handle the multi-step temporal link prediction problem of dynamic networks through attenuation modeling across the snapshots. Extensive experiments on temporal link prediction show that our CTLP framework significantly outperforms state-of-the-art unsupervised methods, and even outperforms the supervised methods in some cases.},
  archive      = {J_ISCI},
  author       = {Pengfei Jiao and Xinxun Zhang and Zehao Liu and Long Zhang and Huaming Wu and Mengzhou Gao and Tianpeng Li and Jian Wu},
  doi          = {10.1016/j.ins.2024.120499},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120499},
  shortjournal = {Inf. Sci.},
  title        = {A deep contrastive framework for unsupervised temporal link prediction in dynamic networks},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Random clustering-based outlier detector. <em>ISCI</em>,
<em>667</em>, 120498. (<a
href="https://doi.org/10.1016/j.ins.2024.120498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection is one of the most important issues in contemporary data analysis. At present, many methods are employed for anomaly and outlier detection, but there is still no universal tool that delivers a high degree of efficiency. In this study, we present a novel approach for outlier detection based on the skillful use of the law of large numbers. The main idea of the proposed solution consists of the random clustering of the elements of the analyzed set. Then, those elements that are sufficiently distant from the random cluster centers are marked as outliers. The proposed approach, besides being highly effective, is also very intuitive. The results of the conducted numerical experiments confirm the high degree of effectiveness of the proposed method, with the measures of accuracy and precision reaching a value of 1. The indisputable advantages of this novel approach for outlier detection are the simplicity of interpretation and the possibility of its modification by people who may lack an extensive experience in data analysis. The effectiveness of the proposed method was compared with other recognized techniques in detecting outliers within both artificially generated and empirical data sets.},
  archive      = {J_ISCI},
  author       = {Adam Kiersztyn and Dorota Pylak and Michał Horodelski and Krystyna Kiersztyn and Pavel Urbanovich},
  doi          = {10.1016/j.ins.2024.120498},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120498},
  shortjournal = {Inf. Sci.},
  title        = {Random clustering-based outlier detector},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic configuration networks with CPU-GPU
implementation for large-scale data analytics. <em>ISCI</em>,
<em>667</em>, 120497. (<a
href="https://doi.org/10.1016/j.ins.2024.120497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic configuration networks (SCNs) are a class of randomized learner models that have garnered increasing attention in data analytics. In the original implementation of SCN, the pseudo-inverse of the hidden layer output matrix is used to evaluate output weights. However, it is quite challenging to compute the pseudo-inverse of the hidden layer output matrices for large-scale datasets with high complexity, which occurs in many real-world applications. This paper aims to accelerate the learning process of SCNs by employing the well-known alternating direction method of multipliers (ADMM) solver and CPU-GPU heterogeneous computing technique. Empirical results on two benchmark datasets demonstrate the efficiency and effectiveness of the proposed method for large-scale data analytics.},
  archive      = {J_ISCI},
  author       = {Junqi Li and Dianhui Wang},
  doi          = {10.1016/j.ins.2024.120497},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120497},
  shortjournal = {Inf. Sci.},
  title        = {Stochastic configuration networks with CPU-GPU implementation for large-scale data analytics},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identification of labeled petri nets from finite automata.
<em>ISCI</em>, <em>667</em>, 120488. (<a
href="https://doi.org/10.1016/j.ins.2024.120488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automata and Petri nets are two typical models of discrete event systems. The paper studies the problem of converting a finite automaton into a Petri net that satisfies the specified structural features. More specifically, we identify a labeled Petri net from a nondeterminstic finite automaton such that the reachability graph of the identified net is isomorphic to the given automaton, meaning that the Petri net models exactly the same dynamic system as the automaton. The identified net necessarily satisfies the specified structural requirements, such as the numbers of places and transitions, absence of self-loops, the exact structure of a part of the net, and so on. Since label Petri nets and nondeterminstic finite automata are generalizations of Petri nets and deterministic finite automata, respectively, the proposed approach can identify a larger spectrum of Petri nets and effectively handle the nondeterminstic cases in the given automaton. Four kinds of conditions are first extracted from the given automaton, namely deterministic enabling conditions, nondeterministic enabling conditions (i.e., multiple transitions with the same label are enabled simultaneously at a marking), transition disabling conditions, and marking inequality conditions. Then, an integer linear programming problem is formulated by characterizing these four kinds of conditions using integer linear constraints. A labeled Petri net satisfying the structural requirements is obtained by solving the integer linear programming problem. We also present two examples to show the possible applications of the proposed identification approach.},
  archive      = {J_ISCI},
  author       = {Guanghui Zhu and Li Yin and Yaohui Li and Zhiwu Li and Naiqi Wu},
  doi          = {10.1016/j.ins.2024.120488},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120488},
  shortjournal = {Inf. Sci.},
  title        = {Identification of labeled petri nets from finite automata},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). E3WD: A three-way decision model based on ensemble learning.
<em>ISCI</em>, <em>667</em>, 120487. (<a
href="https://doi.org/10.1016/j.ins.2024.120487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision model is an effective way to deal with complex decision problems. However, since the three-way decision models now proposed are all based on a single decision criterion, the decision results typically reflect only one preference of decision-makers. Thus, these models may also not effectively deal with complex decision-making problems. To solve the above problems, this paper proposes a new three-way decision model based on ensemble learning. Specifically, we first obtain different three-way decision results by employing different decision criteria. Then, we can acquire the core and candidate sets of the positive and negative regions through set operations. Next, we use the K-means algorithm to divide the candidate sets into three disjoint subsets based on similarities. After that, we adopt a hierarchical filtering method to select suitable objects from the candidate sets and add them to the core sets. Finally, we employ four three-way decision models with different decision criteria as examples to conduct experiments on eight datasets. Experimental results show that our proposed model can obtain higher classification accuracy and lower deferment rate than other traditional three-way decision models under most experimental conditions.},
  archive      = {J_ISCI},
  author       = {Jin Qian and Di Wang and Ying Yu and XiBei Yang and Shang Gao},
  doi          = {10.1016/j.ins.2024.120487},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120487},
  shortjournal = {Inf. Sci.},
  title        = {E3WD: A three-way decision model based on ensemble learning},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Emergency scheduling based on event triggering and
multi-hierarchical planning for space surveillance network.
<em>ISCI</em>, <em>667</em>, 120486. (<a
href="https://doi.org/10.1016/j.ins.2024.120486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space Surveillance Network (SSN) task scheduling plays a crucial role in maintaining the catalog of Resident Space Objects (RSO). However, various emergencies, such as RSO maneuvering, collisions, or rocket launch, may disrupt the original scheduled scheme. Therefore, it is essential to rapidly regenerating emergency schemes while minimizing disturbance to the initial scheduling scheme. This paper introduces an Emergency Task Scheduling model, referred to as MM-ETS, which aims to Maximize observation profits and Minimize disturbance. This model incorporates constraints related to observability, tasks, and resources, which are derived from practical applications. Additionally, a Hierarchical Distributed Dynamic Emergency Scheduling algorithm, encompassing Task assignment, Conflict resolution, Resource negotiation, and Center collaboration (HD-TCRC-DES), is proposed. The presented algorithm is activated by emergencies and a Rolling Horizon Strategy (RHS) is employed to break down long-term, large-scale problems into short-term, small-scale problems, thus improving feasibility and emergency response capabilities. At each layer of the proposed algorithm, heuristic rules are utilized to solve the new scheme, which helps allocate the computational load to resource nodes, and quickly adjust the initial scheduling scheme. Experimental scenarios involving 15 ground observation resources and 1000 emergency tasks are constructed, and the simulation results demonstrate that the proposed method can enhance Comprehensive Benefits Indicators (CBI) by approximately 24.65%, 24.7%, 24.91%, and 30.5% compared to the baselines. Consequently, it is suitable for SSN emergency task scheduling.},
  archive      = {J_ISCI},
  author       = {Xi Long and Leping Yang and Chenyuan Qiao},
  doi          = {10.1016/j.ins.2024.120486},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120486},
  shortjournal = {Inf. Sci.},
  title        = {Emergency scheduling based on event triggering and multi-hierarchical planning for space surveillance network},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Active domain adaptation with mining diverse knowledge: An
updated class consensus dictionary approach. <em>ISCI</em>,
<em>667</em>, 120485. (<a
href="https://doi.org/10.1016/j.ins.2024.120485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation (DA) has recently emerged as an effective paradigm for training the target model with labeled source knowledge. When knowledge transfer in DA encounters the bottleneck, one effective crack way is to introduce the labeled data to guide the DA process. Along this line, many active learning-based DA approaches are emerging to improve the quality of samples selection at the decision border. However, these methods have not preserved and exploited cross-domain common knowledge. In this work, we propose active domain adaptation with mining diverse knowledge: an updated class consensus dictionary approach (UCCDA). Specifically, we firstly initialize the class consensus dictionary by the source prior knowledge. Then, we choose high-confident target pseudo samples through self-training, while assigning labels to those low-confident via oracle annotation. In addition, we design the class consensus dictionary to guide the alignment between the source and target domains, instead of traditional direct cross-domain data alignment. Remarkably, to prevent error accumulation during the consensus dictionary learning, we specially design the anti-forgetting mask matrix to randomly restore the original knowledge. Finally, abundant experiments demonstrate that UCCDA outperforms the related state-of-the-art approaches.},
  archive      = {J_ISCI},
  author       = {Qing Tian and Liangyu Zhou and Yanan Zhu and Lulu Kang},
  doi          = {10.1016/j.ins.2024.120485},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120485},
  shortjournal = {Inf. Sci.},
  title        = {Active domain adaptation with mining diverse knowledge: An updated class consensus dictionary approach},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive fuzzy prescribed-time control of high-order
nonlinear systems with actuator faults. <em>ISCI</em>, <em>667</em>,
120484. (<a href="https://doi.org/10.1016/j.ins.2024.120484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study concentrates on the adaptive prescribed-time control of high-order nonlinear systems with actuator faults. Since the actual control signal of high-order nonlinear systems has a non-affine form, the existing results require that the bounds of time-varying actuator fault parameters be known. To break through the above limitation, the non-affine form of the actual control signal is solved in a linear manner, and novel adaptive estimations are designed. Moreover, fuzzy logic systems are adopted to approximate uncertain terms in control design. It is proved theoretically that the system states converge to zero within the prescribed time which can be set in advance, and all signals in the closed-loop system are bounded. Finally, the effectiveness of the proposed control scheme is certificated by a numerical simulation and a practical simulation of the electromechanical system.},
  archive      = {J_ISCI},
  author       = {Yu Gao and Wei Sun and Xiangpeng Xie},
  doi          = {10.1016/j.ins.2024.120484},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120484},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fuzzy prescribed-time control of high-order nonlinear systems with actuator faults},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MOFS-REPLS: A large-scale multi-objective feature selection
algorithm based on real-valued encoding and preference leadership
strategy. <em>ISCI</em>, <em>667</em>, 120483. (<a
href="https://doi.org/10.1016/j.ins.2024.120483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective feature selection (MOFS) has emerged as a crucial step in constructing efficient machine-learning models. While multi-objective evolutionary algorithms often yield satisfactory sub-optimal solutions, enhancing these algorithms&#39; global optimization capacity remains a central challenge in the field of engineering optimization. To improve the quality of solutions to problems, there is an imperative need for an algorithm with superior optimization capability. This study introduces a large-scale MOFS algorithm based on real-valued encoding and a preference leadership strategy, named MOFS-REPLS, which aims to address the challenge of large-scale sparse feature selection (FS). First, we propose a novel encoding scheme to facilitate broader population exploration. During the population initialization phase, we integrate a ReliefF-guided approach with roulette wheel selection to create the initial population. Second, we introduce a preference leadership strategy that directs individuals toward their respective areas in the Pareto front. Finally, we devise an adaptive learning strategy incorporating ReliefF-guided methods to steer the evolution of the population, thereby mitigating performance deficiencies due to the algorithm&#39;s lack of prior knowledge. MOFS-REPLS employs a dual-archive mechanism to maintain diversity within the algorithm and to preserve non-dominated solutions for further exploration. Through experimental assessment using 20 UCI datasets and 10 state-of-the-art algorithms, we demonstrate the effectiveness of MOFS-REPLS. The results show that our proposed algorithm not only maintains high accuracy but also selects a smaller, more relevant set of features, significantly outperforming other FS algorithms in comparison.},
  archive      = {J_ISCI},
  author       = {Qiyong Fu and Qi Li and Xiaobo Li and Hui Wang and Jiapin Xie and Qian Wang},
  doi          = {10.1016/j.ins.2024.120483},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120483},
  shortjournal = {Inf. Sci.},
  title        = {MOFS-REPLS: A large-scale multi-objective feature selection algorithm based on real-valued encoding and preference leadership strategy},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FedAGAT: Real-time traffic flow prediction based on
federated community and adaptive graph attention network. <em>ISCI</em>,
<em>667</em>, 120482. (<a
href="https://doi.org/10.1016/j.ins.2024.120482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting traffic flow is vital for optimizing intelligent transportation systems (ITS) and reducing congestion by forecasting traffic patterns accurately. However, current centralized TFP systems have limitations, e.g., slow training, high communication costs, and privacy concerns. To address these challenges, this study proposes FedAGAT, a system for short-term traffic flow prediction (TFP) based on federated community and adaptive spatial-temporal graph attention networks (AGAT). The FedAGAT system allows for local data processing and sharing only model updates with the server. This enables real-time, scalable, and secure TFP - essential capabilities for efficient ITS. AGAT is employed to capture intricate spatial-temporal dependencies in traffic flow, while federated learning facilitates decentralized learning, enhancing privacy. The FedAGAT prediction process involves four steps: dividing the local subnetwork using spectral community detection, locally training based on global parameters, uploading updated parameters, and creating a global model prediction based on the aggregated parameters. To evaluate the performance of FedAGAT, two real-world traffic datasets were utilized for benchmarking against seven statistical and deep learning models. Results demonstrate that FedAGAT provides relatively higher accuracy for short- and mid-term forecasting horizons. Moreover, FedAGAT predictions closely match real traffic flow values, and the overall performance is comparable to a global model, while requiring less time.},
  archive      = {J_ISCI},
  author       = {Rasha Al-Huthaifi and Tianrui Li and Zaid Al-Huda and Chongshou Li},
  doi          = {10.1016/j.ins.2024.120482},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120482},
  shortjournal = {Inf. Sci.},
  title        = {FedAGAT: Real-time traffic flow prediction based on federated community and adaptive graph attention network},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Secure and efficient federated learning via novel
multi-party computation and compressed sensing. <em>ISCI</em>,
<em>667</em>, 120481. (<a
href="https://doi.org/10.1016/j.ins.2024.120481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) enables the full utilization of decentralized training without raw data. However, various attacks still threaten the training process of FL. To address these concerns, differential privacy (DP) and secure multi-party computation (SMC) are applied, but these methods may result in low accuracy and heavy training load. Moreover, the high communication consumption of FL in resource-constrained devices is also a challenging problem. In this paper, we propose a novel SMC algorithm for the FL (FL-IPFE) to protect the local gradients. It does not require a trusted third party (TTP) and is more suitable for FL. Furthermore, we propose a secure and efficient FL algorithm (SEFL), which applies compressed sensing (CS) and all-or-nothing transform (AONT) to minimize the number of transmitted and encrypted model updates. Additionally, our FL-IPFE is used to encrypt the last element of the preprocessed parameters for guaranteeing the security of the entire local model updates. Meanwhile, the issue of participant dropouts is also taken into account. Theoretical analyses demonstrate that our proposed algorithms can aggregate model updates with high security. Finally, experimental evaluation reveals that our SEFL possesses higher efficiency compared to other state-of-the-art works, while providing comparable model accuracy and strong privacy guarantees.},
  archive      = {J_ISCI},
  author       = {Lvjun Chen and Di Xiao and Zhuyang Yu and Maolan Zhang},
  doi          = {10.1016/j.ins.2024.120481},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120481},
  shortjournal = {Inf. Sci.},
  title        = {Secure and efficient federated learning via novel multi-party computation and compressed sensing},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Landmark-based k-factorization multi-view subspace
clustering. <em>ISCI</em>, <em>667</em>, 120480. (<a
href="https://doi.org/10.1016/j.ins.2024.120480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering (MSC) has gained significant popularity due to its ability to overcome noise and bias present in single views by fusing information from multiple views. MSC enhances the accuracy and robustness of clustering. However, many existing MSC methods suffer from high computational costs and sub-optimal performance on large-scale datasets, since they often construct a fused graph directly from high-dimensional data and then apply spectral clustering. To address these challenges, we propose a framework called Landmark-based k -Factorization Multi-view Subspace Clustering (LKMSC). Our framework tackles these issues by generating a small number of landmarks p ≪ n p≪n for each view, which form a landmark graph. We represent each entire view as a linear combination of these landmarks, where n is the number of data points. To address inconsistencies that naturally occur in landmark graphs due to multiple views, we utilize Landmark Graphs Alignment. This technique incorporates both feature and structural information to capture the correspondence between landmarks. The aligned graphs are then factorized into consensus k groups, emphasizing structural sparsity. LKMSC efficiently extracts features and reduces dimensionality of the input dataset. It eliminates the need for learning large-scale affinity matrix and feature decomposition. Our approach exhibits linear computational complexity and has demonstrated promising results in numerous experimental evaluations across a range of datasets. The source codes and datasets are available at https://github.com/FY0109/LKMSC .},
  archive      = {J_ISCI},
  author       = {Yuan Fang and Geping Yang and Xiang Chen and Zhiguo Gong and Yiyang Yang and Can Chen and Zhifeng Hao},
  doi          = {10.1016/j.ins.2024.120480},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120480},
  shortjournal = {Inf. Sci.},
  title        = {Landmark-based k-factorization multi-view subspace clustering},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incremental information fusion in the presence of object
variations for incomplete interval-valued data based on information
entropy. <em>ISCI</em>, <em>667</em>, 120479. (<a
href="https://doi.org/10.1016/j.ins.2024.120479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information fusion technology plays a crucial role in integrating data from multiple sources or sensors to generate comprehensive representation, which can eliminate uncertainty in multi-source information systems (Ms-IS). Incomplete interval-valued data, a generalized form of single-valued data, is commonly encountered in real-world scenarios and effectively represents uncertain information. This paper introduces a novel information entropy specifically designed to quantify the uncertainty in incomplete interval-valued data. Based on the proposed entropy, a new unsupervised fusion approach is developed. Additionally, two dynamic update mechanisms are established to obtain fusion results efficiently when collecting new objects and removing obsolete ones. The relevant static and dynamic fusion algorithms are provided, and a detailed analysis and comparison of their time complexities are conducted. Finally, the effectiveness analysis reveals that the proposed method achieves higher average classification accuracy (5% to 8.7% improvement) compared to three common fusion methods (MAXF, MEANF, and MINF), as well as the state-of-the-art entropy-based supervised fusion method (ESF). The efficiency analysis demonstrates that the average running time of dynamic fusion algorithms is significantly lower (66.9% to 85.6% reduction) compared to the static fusion algorithm, and this difference is statistically significant.},
  archive      = {J_ISCI},
  author       = {Xiuwei Chen and Maokang Luo},
  doi          = {10.1016/j.ins.2024.120479},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120479},
  shortjournal = {Inf. Sci.},
  title        = {Incremental information fusion in the presence of object variations for incomplete interval-valued data based on information entropy},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Random subsequence forests. <em>ISCI</em>, <em>667</em>,
120478. (<a href="https://doi.org/10.1016/j.ins.2024.120478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The random forest classifier is widely used in different fields due to its accuracy and robustness. Since its invention, the random forest algorithm is naturally developed for multi-dimensional vectorial data since features can be directly sampled during the decision tree construction procedure. In the context of discrete sequence classification, an explicit feature set is not readily available and we need to employ a feature extraction algorithm before building the random forest. However, such a predefined feature subset may limit the diversity of decision trees since the set of candidate features is composed of all subsequences. As a result, the predictive accuracy of constructed random forest classifier may be reduced. To address this, we propose a new algorithm that is able to directly build a random forest by choosing features from the set of all subsequences adaptively. To improve the running efficiency of our algorithm, the count-suffix tree is utilized to facilitate the fast frequency counting of subsequences so as to accelerate the generation of each randomized decision tree. The experimental results on 15 real datasets show that our method can outperform those state-of-the-art classification algorithms in terms of the predictive accuracy. The source code of our method can be found at: https://github.com/JiaqiWang-dlut/RSForest .},
  archive      = {J_ISCI},
  author       = {Zengyou He and Jiaqi Wang and Mudi Jiang and Lianyu Hu and Quan Zou},
  doi          = {10.1016/j.ins.2024.120478},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120478},
  shortjournal = {Inf. Sci.},
  title        = {Random subsequence forests},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatiotemporal knowledge graph completion via diachronic and
transregional word embedding. <em>ISCI</em>, <em>667</em>, 120477. (<a
href="https://doi.org/10.1016/j.ins.2024.120477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph Completion (KGC) is an essential application in the field of knowledge graphs (KGs) that attempts to fill in the missing information in the process of KG modelling. With the popularity of temporal knowledge graphs (TKGs), a wide range of techniques based on temporal knowledge graph completion (TKGC) have appeared, solving the issue of real-world knowledge with temporal properties. However, there is little study on KGC with spatiotemporal attributes, some real-world data include both spatial and temporal attributes. Effectively handling the completion of missing entities or predicates in spatiotemporal knowledge graphs (STKGs) is an important challenge. Our study fills the gap in knowledge completion techniques in the field of STKG. We present a model for completion based on the well-known tensor factorization canonical polyadic (CP) decomposition. It introduces temporal and spatial attributes into the decomposition vector to achieve entity and link predictions. We name it diachronic and transregional word embedding (DT-WE), which includes two different modules: the embedding framework and the scoring module. Firstly, send the vectors to the embedding framework to get the new vector representation, then, we send it to the scoring module to compute, and finally, the resulting values are added together to compute the prediction probability. We conducted extensive experiments on three real-world STKGs: YAGO10K, Wikidata40K and Opensky. The results indicate that the newly introduced spatiotemporal attributes not only improve accuracy in predicting entities and predicates compared to temporal models but also achieve state-of-the-art performance with lower spatial complexity.},
  archive      = {J_ISCI},
  author       = {Xiaobei Xu and Wei Jia and Li Yan and Xiaoping Lu and Chao Wang and Zongmin Ma},
  doi          = {10.1016/j.ins.2024.120477},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120477},
  shortjournal = {Inf. Sci.},
  title        = {Spatiotemporal knowledge graph completion via diachronic and transregional word embedding},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel grade assessment method for cybersecurity situation
of online retailing with decision makers’ bounded rationality.
<em>ISCI</em>, <em>667</em>, 120476. (<a
href="https://doi.org/10.1016/j.ins.2024.120476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The online retailing cybersecurity situations grade assessment (GS) is a key issue in cybersecurity management, which can be regarded as a type of multi-attributes GS problems. However, traditional GS methods rarely discuss the boundary fuzziness and hesitation in the grade classification of attributes, as well as the monotony relation and interrelation between entropy fuzziness and intuitionism. A novel GS method with respect to decision makers’ bounded rationality is proposed. To get the method, the membership functions (MFs) and non-membership functions (NMFs) of attributes’ eigenvalue grade considering decision maker s’ bounded rationality and hesitation are proposed. An axiomatic definition of IF entropy on the basis of isentropic arcs is proposed, providing the formula of the monotony relation and interrelation between fuzziness and intuitionism. We, considering the reliability and the IF grade assessment method, propose the similarity of IF grade eigenvalue, which identifies grades reasonably and distinguishes the ranking of the same grade, and overcomes the defect that the maximum membership degree principle ignores the position differences of each grade assessment level.},
  archive      = {J_ISCI},
  author       = {Gao-Feng Yu and Wen-Jin Zuo},
  doi          = {10.1016/j.ins.2024.120476},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120476},
  shortjournal = {Inf. Sci.},
  title        = {A novel grade assessment method for cybersecurity situation of online retailing with decision makers’ bounded rationality},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contribution-wise byzantine-robust aggregation for
class-balanced federated learning. <em>ISCI</em>, <em>667</em>, 120475.
(<a href="https://doi.org/10.1016/j.ins.2024.120475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a promising approach that allows many clients to jointly train a model without sharing the raw data. Due to the clients&#39; different preferences, the class imbalance issue frequently occurs in real-world FL problems and poses threats for poisoning attacks to the existing FL methods. In this work, we first propose a new attack called Class Imbalance Attack that can degrade the testing accuracy of a particular class(es) to even 0 under the state-of-the-art robust FL methods. To defend against such attacks, we further propose a Class-Balanced FL method with a novel contribution-wise Byzantine-robust aggregation rule. In the designed rule, an honest score and a contribution score will be assigned to each client dynamically according to the server model. The server itself will be initiated with a small dataset, and a model (called server model) will be maintained. These two scores will be subsequently used to calculate the weighted average of the client gradients for each training iteration. The experiments are conducted on five datasets against state-of-the-art poisoning attacks, including the Class Imbalance Attack. The empirical results demonstrate the effectiveness of the proposed Class-Balanced FL method.},
  archive      = {J_ISCI},
  author       = {Yanli Li and Weiping Ding and Huaming Chen and Wei Bao and Dong Yuan},
  doi          = {10.1016/j.ins.2024.120475},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120475},
  shortjournal = {Inf. Sci.},
  title        = {Contribution-wise byzantine-robust aggregation for class-balanced federated learning},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trainable and explainable simplicial map neural networks.
<em>ISCI</em>, <em>667</em>, 120474. (<a
href="https://doi.org/10.1016/j.ins.2024.120474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simplicial map neural networks (SMNNs) are topology-based neural networks with interesting properties such as universal approximation ability and robustness to adversarial examples under appropriate conditions. However, SMNNs present some bottlenecks for their possible application in high-dimensional datasets. First, SMNNs have precomputed fixed weight and no SMNN training process has been defined so far, so they lack generalization ability. Second, SMNNs require the construction of a convex polytope surrounding the input dataset. In this paper, we overcome these issues by proposing an SMNN training procedure based on a support subset of the given dataset and replacing the construction of the convex polytope by a method based on projections to a hypersphere. In addition, the explainability capacity of SMNNs and effective implementation are also newly introduced in this paper.},
  archive      = {J_ISCI},
  author       = {Eduardo Paluzo-Hidalgo and Rocio Gonzalez-Diaz and Miguel A. Gutiérrez-Naranjo},
  doi          = {10.1016/j.ins.2024.120474},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120474},
  shortjournal = {Inf. Sci.},
  title        = {Trainable and explainable simplicial map neural networks},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A large-scale graph partition algorithm with redundant
multi-order neighbor vertex storage. <em>ISCI</em>, <em>667</em>,
120473. (<a href="https://doi.org/10.1016/j.ins.2024.120473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, graph data become increasingly important and larger in many fields, and many distributed graph computing systems have been proposed to deal with large-scale graphs. The graph partition algorithm is the basis of these systems. In many graph applications, a vertex updates its feature by aggregating information of its multi-order neighboring vertices, and the existing graph partition algorithms often lead to heavy communication cost. This paper proposes a graph partition algorithm to store the multi-order neighbor vertices redundantly to avoid the communication requirement. It first formulates the problem of graph partitioning with redundant multi-order neighbor vertices storage as an optimization problem, and then proposes PARN (partition algorithm with redundant multi-order neighbor) algorithm to tackle it. The PARN algorithm consists of initial partition and vertex migration based on genetic algorithm, and it classifies the vertices of a partition into primary and auxiliary vertices. The auxiliary vertices required for the primary vertices in a partition are stored in the same partition, so the primary vertices don&#39;t need to fetch the information from the other partitions. The experiment results show that the proposed algorithm is comparable to Hash, GAP, GNP, and QCLP algorithms in terms of load balance and produces fewer auxiliary vertices than these algorithms.},
  archive      = {J_ISCI},
  author       = {Huanqing Cui and Di Yang and Chuanai Zhou},
  doi          = {10.1016/j.ins.2024.120473},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120473},
  shortjournal = {Inf. Sci.},
  title        = {A large-scale graph partition algorithm with redundant multi-order neighbor vertex storage},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MGL2Rank: Learning to rank the importance of nodes in road
networks based on multi-graph fusion. <em>ISCI</em>, <em>667</em>,
120472. (<a href="https://doi.org/10.1016/j.ins.2024.120472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of important nodes with strong propagation capabilities in road networks is a vital topic in urban planning. Existing methods for evaluating the importance of nodes in traffic networks only consider topological information and traffic volumes, the diversity of the traffic characteristics in road networks, such as the number of lanes and average speed of road segments, is ignored, thus limiting their performance. To solve this problem, we propose a graph learning-based framework (MGL2Rank) that integrates the rich characteristics of road networks to rank the importance of nodes. This framework comprises an embedding module containing a sampling algorithm (MGWalk) and an encoder network to learn the latent representations for each road segment. MGWalk utilizes multi-graph fusion to capture the topology of road networks and establish associations between road segments based on their attributes. The obtained node representation is then used to learn the importance ranking of the road segments. Finally, a synthetic dataset is constructed for ranking tasks based on the regional road network of Shenyang City, and the ranking results on this dataset demonstrate the effectiveness of our method. The data and source code for MGL2Rank are available at https://github.com/ZJ726 .},
  archive      = {J_ISCI},
  author       = {Ming Xu and Jing Zhang},
  doi          = {10.1016/j.ins.2024.120472},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120472},
  shortjournal = {Inf. Sci.},
  title        = {MGL2Rank: Learning to rank the importance of nodes in road networks based on multi-graph fusion},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Learning to walk with logical embedding for knowledge
reasoning. <em>ISCI</em>, <em>667</em>, 120471. (<a
href="https://doi.org/10.1016/j.ins.2024.120471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The path-based model has remarkably succeeded in the knowledge graph (KG) multi-hop reasoning task. It employs all available resources to accomplish various complex path reasoning tasks and continuously explores new graph paths. However, existing multi-hop reasoning methods rely heavily on the high reward, which is fed back to the model when the agent searches for the target. In contrast, most previous methods focused on efficiently querying the correct answer while disregarding the logic and validity of the entire reasoning chain. It contradicts the intention of various complex reasoning tasks in real-world scenarios. Unreasonable paths will cause the selection to deviate from normal cognition, resulting in invalid path resource information. Therefore, we must be able to complete specific tasks via these reliable paths. In order to address these issues, we proposed a R einforcement Learning-Based K nowledge Reasoning Model with L ogical E mbedding (RKLE) to enhance the interpretability of the reasoning chain. RKLE assembles the logical structure (query structure) with additional nodes in the current step and develops the logical reward shaping to assist the agent in selecting a more reasonable path. Finally, experimental results on several benchmarks demonstrate that our approach can search for the correct answers more efficiently than existing path-based methods and that the corresponding reasoning chain is interpretable.},
  archive      = {J_ISCI},
  author       = {Ruinan Liu and Guisheng Yin and Zechao Liu},
  doi          = {10.1016/j.ins.2024.120471},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120471},
  shortjournal = {Inf. Sci.},
  title        = {Learning to walk with logical embedding for knowledge reasoning},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A log-based non-convex relaxation regularized regression for
robust face recognition. <em>ISCI</em>, <em>667</em>, 120470. (<a
href="https://doi.org/10.1016/j.ins.2024.120470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regression methods are widely employed in face recognition applications. The vector-based norm regression model only represents the pixel by pixel correlation and exhibits poor performance with contiguous occlusion. In contrast, methods based on the nuclear norm describe the low-rank structural information, but it is difficult to achieve satisfactory performance when dealing with complex noise. To address this, a log-based non-convex relaxation regularized regression (log-NCRR) model for robust face recognition is proposed in this paper. We adopt the log-based matrix loss without additional parameters to characterize the low-rank part of error image. Considering sparsity, we design a log-based vector loss to describe the sparse part of the error matrix, which achieves a balance between the l 0 l0 -norm and l 1 l1 -norm. Additionally, a weighted non-convex relaxation of l 2 , 1 l2,1 -norm is proposed to ensure the group sparsity of the regression coefficient. The optimization problem is optimized by ADMM, with the corresponding sub-problems easily solved by the generalized singular value shrinkage operator. Finally, experimental results on four public databases for various types of noise validate the effectiveness and robustness of log-NCRR in face recognition.},
  archive      = {J_ISCI},
  author       = {Ruonan Liu and Yitian Xu},
  doi          = {10.1016/j.ins.2024.120470},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120470},
  shortjournal = {Inf. Sci.},
  title        = {A log-based non-convex relaxation regularized regression for robust face recognition},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural collapse inspired semi-supervised learning with fixed
classifier. <em>ISCI</em>, <em>667</em>, 120469. (<a
href="https://doi.org/10.1016/j.ins.2024.120469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pseudo-labeling-based approaches are gaining prominence in Semi-Supervised Learning (SSL). Recent studies have identified that the key bottleneck in this methodology is addressing insufficient, incorrect, and imbalanced pseudo-labels. In this paper, we argue that the intrinsic problem behind this bottleneck is classifier bias, i.e., the classifier&#39;s prototypes suffer from poor uniformity. Further, inspired by neural collapse that reveals an optimal structure under supervised training scenarios, we address this classifier bias by utilizing an offline simplex Equiangular Tight Frame (ETF) classifier with maximally and equally separated prototypes. During the training phase, we maintain the prototypes of the classifier as fixed and concentrate on refining the feature encoder. Specifically, we integrate a straightforward clustering-based pseudo-labeling strategy with information maximization for feature learning. In practice, the fixed ETF classifier prevents the model from falling into a detrimental cycle, where a biased classifier exacerbates misaligned features, further perpetuating this bias. Furthermore, the clustering-based pseudo-labeling strategy reduces the dependency on complex threshold-adjusting mechanisms and effectively navigates the quantity-quality trade-off that plagues existing SSL methods. Leveraging these methodologies, we develop a simple yet powerful approach, termed ETF-SSL. Extensive experiments across Image, Text, and Audio datasets demonstrate that ETF-SSL can achieve competitive or superior performance compared to existing approaches. This success highlights the benefits of using a fixed ETF classifier in SSL and points to promising directions for future research in this area. The code is available at: https://github.com/yichenwang231/ETFSSL .},
  archive      = {J_ISCI},
  author       = {Zhanxuan Hu and Yichen Wang and Hailong Ning and Yonghang Tai and Feiping Nie},
  doi          = {10.1016/j.ins.2024.120469},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120469},
  shortjournal = {Inf. Sci.},
  title        = {Neural collapse inspired semi-supervised learning with fixed classifier},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Topological numbers of fuzzy soft graphs and their
application. <em>ISCI</em>, <em>667</em>, 120468. (<a
href="https://doi.org/10.1016/j.ins.2024.120468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diagram kind of a graph is used to show accumulated data. Graphs can be utilized for a variety of purposes because this data can be either quantitative or qualitative. Graphs can be used to model different relationships and processes in physical, biological, and social media marketing systems, and in finding directions on a map. A graph with properties attached to its nodes and edges that emphasize its applicability to real-world systems is sometimes called a network. The idea of fuzzy sets has developed in numerous ways and across many areas since its establishment in 1965. Applications of this theory can be found in numerous fields for instance in recognition of patterns, management science, AI, computer science, medicine, also in control engineering. The progress of mathematics has reached a very high level and continues now. While classical graph theory is widely applied in several domains, there are instances where its outcomes can be subject to uncertainty. In order to address this challenge, the utilization of the fuzzy theory of graphs is adopted, as it offers more accurate outcomes. There is a lack of a parameterization tool in fuzzy graph theory, as a consequence Molodtsov introduced soft set theory, which is a rather recent way to talk about ambiguity and vagueness. It is becoming more and more popular among scholars and is a novel approach to uncertainty and ambiguity simulation. The concept of soft graphs offers a parameterized perspective on graphs. In this article, we defined some familiar graph families in a fuzzy soft (FS) environment and by calculating their degrees, derived important results for two versions of Sombor numbers. In the end, we discussed an application of calculated results and by comparison, checked the efficiency of Sombor numbers in a FS framework.},
  archive      = {J_ISCI},
  author       = {Muhammad Azeem and Shabana Anwar and Muhammad Kamran Jamil and Muhammad Saeed and Muhammet Deveci},
  doi          = {10.1016/j.ins.2024.120468},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120468},
  shortjournal = {Inf. Sci.},
  title        = {Topological numbers of fuzzy soft graphs and their application},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An evolutionary neural architecture search method based on
performance prediction and weight inheritance. <em>ISCI</em>,
<em>667</em>, 120466. (<a
href="https://doi.org/10.1016/j.ins.2024.120466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary Neural Architecture Search (ENAS) algorithms attract great attention since they can automatically search for appropriate network architectures for a given task. However, most ENAS algorithms suffer from a prohibitive computational burden. Moreover, some of these approaches directly use performance predictors for evaluations, which may introduce inaccurate assessments and harm the evolution. To overcome these shortcomings, we propose an efficient ENAS algorithm named EPPGA. EPPGA employs a predictor to pre-select potentially high-performing offspring, enhancing the performance and accelerating the evolution. As the offspring will be further accurately evaluated, even potentially inaccurate predictions will not adversely affect the evolution. Furthermore, a weight inheritance method is suggested to accelerate the evaluation, and new genetic operations are developed to produce offspring that share a substantial proportion of beneficial genetic materials with one parent, improving the performance predictor&#39;s effectiveness and promoting weight inheritance. Finally, a new efficient backbone block structure is designed to facilitate the search for lightweight networks. The experimental results demonstrate that EPPGA is a highly competitive algorithm on three benchmarks in terms of accuracy, model size, and computational cost, reveal the superiority of the proposed block structure, and confirm the effectiveness of the proposed performance predictor and weight inheritance method.},
  archive      = {J_ISCI},
  author       = {Gonglin Yuan and Bing Xue and Mengjie Zhang},
  doi          = {10.1016/j.ins.2024.120466},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120466},
  shortjournal = {Inf. Sci.},
  title        = {An evolutionary neural architecture search method based on performance prediction and weight inheritance},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid learning based on fisher linear discriminant.
<em>ISCI</em>, <em>667</em>, 120465. (<a
href="https://doi.org/10.1016/j.ins.2024.120465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid learning is an excellent method that combines the global information of data with the local information of data. Different from the known hybrid learning algorithms, in this paper we propose a new hybrid learning strategy for Fisher Linear Discriminant (FLD) and introduce novel hybrid learning based on FLD (HL-FLD). The main idea of HL-FLD is to obtain the global structural information by FLD firstly, and then use the obtained global information to divide the given data locally in a more detailed way. To study systematically the proposed HL-FLD, we not only establish the generalization bound of HL-FLD and prove that the proposed HL-FLD algorithm is consistent, but also present some discussions on HL-FLD. Since splitting the blocks of a given data is a hyperparameter, we also improve HL-FLD and introduce another new self-adaptive hybrid learning based on FLD (SHL-FLD). The experimental researches for benchmark repository confirm that the proposed two algorithms have better performance in terms of misclassification rates and total time.},
  archive      = {J_ISCI},
  author       = {Jiawen Gong and Bin Zou and Chen Xu and Jie Xu and Xinge You},
  doi          = {10.1016/j.ins.2024.120465},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120465},
  shortjournal = {Inf. Sci.},
  title        = {Hybrid learning based on fisher linear discriminant},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Continuous monitoring of reverse approximate nearest
neighbour queries on road network. <em>ISCI</em>, <em>667</em>, 120464.
(<a href="https://doi.org/10.1016/j.ins.2024.120464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reverse Approximate Nearest Neighbour (RANN) query relaxes the R k NN definition of influence, where a user u can be influenced by not only its closest facility but also by every other facility that is almost as close to u as its closest facility is. In this paper, we study the continuous monitoring of RANN queries on road network. Existing continuous RANN algorithms on Euclidean space cannot be extended to continuously monitor RANN queries on road network. We propose two different methods to efficiently monitor RANN queries. We conduct an extensive experiment on different real data sets and demonstrate that our both proposed algorithms are significantly better than the competitor},
  archive      = {J_ISCI},
  author       = {Xinyu Li and Arif Hidayat and David Taniar and Muhammad Aamir Cheema},
  doi          = {10.1016/j.ins.2024.120464},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120464},
  shortjournal = {Inf. Sci.},
  title        = {Continuous monitoring of reverse approximate nearest neighbour queries on road network},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). StreamliNet: Cost-aware layer-wise neural network
linearization for fast and accurate private inference. <em>ISCI</em>,
<em>667</em>, 120463. (<a
href="https://doi.org/10.1016/j.ins.2024.120463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Private inference (PI) allows a client and a server to perform cryptographically-secure deep neural network inference without disclosing their sensitive data to each other. Despite the strong security guarantee, existing models are ill-suited for PI since their overused non-linear operations such as ReLUs are computationally expensive in the regime of ciphertext and therefore dominate the PI latency. Previous solutions on ReLU optimization either ignore the intrinsic importance of ReLU or suffer from significant accuracy loss. In this work, we propose StreamliNet , an importance-driven gradient-based framework to speed up PI latency and retain inference accuracy. Specifically, we first present a novel notion of ReLU negativity as a proxy for the ReLU importance in a multivariate metric to precisely identify layer-wise budgets. Then, our StreamliNet automates the selection of performance-insensitive ReLUs for linearization and learns the non-linearity sparse model where ReLUs are present in each layer with appropriate counts and locations. Moreover, in order to reduce the activation map discrepancy, we develop a cost-aware post-activation consistency constraint to prioritize the linearization of ReLUs with low cost while further mitigating the model performance degradation. Extensive experiments on various models and datasets demonstrate that StreamliNet outperforms the state-of-the-arts such as SNL (ICML 22) and SENet (ICLR 23) by boosting 3.09% more accuracy with iso-ReLU budget or requiring 2× fewer ReLUs with iso-accuracy, on CIFAR-100.},
  archive      = {J_ISCI},
  author       = {Zhi Pang and Lina Wang and Fangchao Yu and Kai Zhao and Bo Zeng},
  doi          = {10.1016/j.ins.2024.120463},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120463},
  shortjournal = {Inf. Sci.},
  title        = {StreamliNet: Cost-aware layer-wise neural network linearization for fast and accurate private inference},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A belief rule-based classification system using fuzzy
unordered rule induction algorithm. <em>ISCI</em>, <em>667</em>, 120462.
(<a href="https://doi.org/10.1016/j.ins.2024.120462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A rule-based system is a widely used artificial intelligence system that employs a set of rules to make decisions. The belief rule-based (BRB) classification system is an extension of fuzzy rule-based (FRB) system that handles uncertainty and imprecision in classification tasks by incorporating Dempster-Shafer evidence theory and fuzzy set theory. However, the BRB classification system suffers from the combinatorial explosion and high time complexity problems. To solve these issues, the fuzzy unordered rule induction algorithm (FURIA) is introduced into the BRB classification systems to design a novel BRB classification system in this paper. FURIA is computationally less complex and has superior classification performance. The proposed system outperforms BRB classification systems in terms of classification performance and significantly reduces the number of rules and conditions. Furthermore, the proposed system offers a more effective solution than FURIA. To evaluate the validity and superiority of the proposed system, we conduct two classification experiments, comparing it with five traditional classifiers and seven rule-based systems, respectively, in terms of classification performance and interpretability.},
  archive      = {J_ISCI},
  author       = {Yangxue Li and Ignacio Javier Pérez and Francisco Javier Cabrerizo and Harish Garg and Juan Antonio Morente-Molinera},
  doi          = {10.1016/j.ins.2024.120462},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120462},
  shortjournal = {Inf. Sci.},
  title        = {A belief rule-based classification system using fuzzy unordered rule induction algorithm},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel regularization method for decorrelation learning of
non-parallel hyperplanes. <em>ISCI</em>, <em>667</em>, 120461. (<a
href="https://doi.org/10.1016/j.ins.2024.120461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-parallel hyperplane classifiers have attracted many attention due to their wider applicability than parallel hyperplane classifiers, and it accelerates the training speed through separately training of each hyperplane. However, it does not consider the correlation relationship among the non-parallel hyperplanes. In addition, since these non-parallel hyperplanes are built on the same training data, there may exist correlation among them due to redundancy of the data. In this paper, we investigate the decorrelation problem of non-parallel hyperplane classifiers. We integrate non-parallel hyperplanes into a unified model and explore this relationship through a joint classifier learning approach. Taking the twin support vector machine as an example, a novel decorrelation regularization term is added into the joint problem. Additionally, an effective alternating optimization algorithm has been introduced to address this nonconvex problem. To evaluate the proposed method, a series of experiments are conducted on binary and multi-class classification datasets from the benchmark database repository. Experimental results compared to several parallel and non-parallel hyperplane based classifiers demonstrate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Wen-Zhe Shao and Yuan-Hai Shao and Chun-Na Li},
  doi          = {10.1016/j.ins.2024.120461},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120461},
  shortjournal = {Inf. Sci.},
  title        = {A novel regularization method for decorrelation learning of non-parallel hyperplanes},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive supervisory control for automated manufacturing
systems using borrowed-buffer slots. <em>ISCI</em>, <em>667</em>,
120460. (<a href="https://doi.org/10.1016/j.ins.2024.120460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust deadlock supervisory control techniques for automated manufacturing systems under resource failures that need additional central buffers may lead to supererogatory cost in control implementation. To mitigate this issue, this paper reports a Petri net-based low-cost adaptive supervisory control policy that does not require extra buffers. If an unreliable resource fails, three classes of buffer spaces can be temporarily used to store parts that require the failed resource in their impending processing routes. The proposed adaptive supervisory control comprises of control places and switch controllers. If an unreliable resource fails, the switch controllers are activated to move the part types that require the failed resource in their subsequent processing stages into borrowed buffer spaces. After the failed resource is recovered, the system returns to its normal operating mode. The part types in the borrowed buffer spaces will be returned to their last processing stages before the occurrence of the failure and continued along their processing route. We propose criteria for selecting buffer space borrowers and buffer space lenders. Furthermore, redundant control places are removed by a new technique proposed in the paper in order to reduce the complexity of the supervisory control structure. We demonstrate the proposed method using examples.},
  archive      = {J_ISCI},
  author       = {Umar Suleiman Abubakar and Gaiyun Liu},
  doi          = {10.1016/j.ins.2024.120460},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120460},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive supervisory control for automated manufacturing systems using borrowed-buffer slots},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A nondominated sorting genetic model for co-clustering.
<em>ISCI</em>, <em>667</em>, 120459. (<a
href="https://doi.org/10.1016/j.ins.2024.120459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-clustering aims to cluster the rows and columns of data simultaneously and can be often formulated as a two-objective optimization problem (one objective for rows and the other for columns) and the solution is a Pareto-optimal solution set in principle. Existing methods usually convert the co-clustering problem into a single-objective optimization problem by setting a hyper-parameter λ between the two objectives. However, finding a good value of λ is not easy because of its large parameter space; also, there may exist many equally good λ s. In this paper, a nondominated sorting genetic model (NSGC) is proposed to tackle the co-clustering problem, totally bypassing the trade-off parameter λ and returning to the original two-objective problem. The core of our model is to group a row objective function and a column objective function and integrate them into a genetic algorithm as the fitness functions. After this reformulation, we follow a standard genetic algorithm procedure to iteratively find the Pareto-optimal solutions. Finally, to fish out a single best solution we further design a sorting criterion according to which the Pareto-optimal solution set can be totally ordered. Extensive experiments with 16 public datasets are conducted, and the results demonstrate the superiority of our approach.},
  archive      = {J_ISCI},
  author       = {Wuchun Yang and Hongjun Wang and Yinghui Zhang and Zhipeng Luo and Tanrui Li},
  doi          = {10.1016/j.ins.2024.120459},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120459},
  shortjournal = {Inf. Sci.},
  title        = {A nondominated sorting genetic model for co-clustering},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual auto-weighted multi-view clustering via
autoencoder-like nonnegative matrix factorization. <em>ISCI</em>,
<em>667</em>, 120458. (<a
href="https://doi.org/10.1016/j.ins.2024.120458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering (MVC) can exploit the complementary information among multi-view data to achieve the satisfactory performance, thus having extensive potentials for practical applications. Although Nonnegative Matrix Factorization (NMF) has emerged as an effective technique for MVC, the existing NMF-based methods still have two main limitations: 1) They solely focus on the reconstruction of original data, which can be regarded as the decoder of an autoencoder, while neglecting the low-dimensional representation learning. 2) They lack the ability to effectively capture both linear and nonlinear structures of data. To solve these problems, in this paper, we propose a D ual A uto-weighted multi-view clustering model based on A utoencoder-like NMF (DA 2 NMF), which enables a comprehensive exploration of both linear and nonlinear structures. Specifically, we establish an autoencoder-like NMF model that learns linear low-dimensional representations by integrating data reconstruction and representation learning within a unified framework. Moreover, the adaptive graph learning is introduced to explore the nonlinear structures in data. We further design a dual auto-weighted strategy to adaptively compute weights for different views and low-dimensional representations, thereby obtaining an enhanced consistent graph. An effective algorithm based on Multiplicative Update Rule (MUR) is developed to solve the DA 2 NMF with the theoretical convergence guarantee. Experimental results show that the proposed DA 2 NMF can effectively improve the clustering performance compared with the state-of-the-art MVC algorithms.},
  archive      = {J_ISCI},
  author       = {Si-Jia Xiang and Heng-Chao Li and Jing-Hua Yang and Xin-Ru Feng},
  doi          = {10.1016/j.ins.2024.120458},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120458},
  shortjournal = {Inf. Sci.},
  title        = {Dual auto-weighted multi-view clustering via autoencoder-like nonnegative matrix factorization},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Practical finite-time synchronization of delayed fuzzy
cellular neural networks with fractional-order. <em>ISCI</em>,
<em>667</em>, 120457. (<a
href="https://doi.org/10.1016/j.ins.2024.120457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The practical finite-time (PFT) synchronization of fractional-order delayed fuzzy cellular neural networks (FODFCNNs) is presented in this article. Initially, a useful practical finite time (FT) stable lemma is developed, serving as an efficient instrument for the PFT synchronization of fractional-order systems. Subsequently, a new PFT synchronization criterion for FODFCNNs is derived using the designed controller and the aforementioned lemma. Simultaneously, the settling time for PFT synchronization is determined, relying on specific controller parameters and the initial conditions of the considered systems. Ultimately, the accuracy of the derived outcomes is confirmed through a numerical simulation.},
  archive      = {J_ISCI},
  author       = {Feifei Du and Jun-Guo Lu and Qing-Hao Zhang},
  doi          = {10.1016/j.ins.2024.120457},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120457},
  shortjournal = {Inf. Sci.},
  title        = {Practical finite-time synchronization of delayed fuzzy cellular neural networks with fractional-order},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive integral sliding-mode finite-time control with
integrated extended state observer for uncertain nonlinear systems.
<em>ISCI</em>, <em>667</em>, 120456. (<a
href="https://doi.org/10.1016/j.ins.2024.120456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the typical uncertain nonlinear systems subjected to controller gain variation and disturbances, an integrated adaptive robust controller, called integral sliding-mode finite-time controller with an integrated extended state observer (ISFC-IESO), is proposed. The designed controller mainly consists of an integrated ESO (IESO) unit and an integral sliding-mode control (ISMC) unit. The IESO unit is composed of improved linear and nonlinear ESOs which are designed to automatically switch each other, with the aim of enhancing disturbance estimation capability. Moreover, the ISMC unit produces an integral sliding-mode control law (SMCL) based on the newly designed integral sliding-mode surface function (SMSF) and sliding-mode reaching law (SMRL). The integral SMSF is developed based on the n -th estimated state and a designed convergence function of tracking error to suppress the influence of the disturbance estimation error. On this basis, SMRL is further presented by combining integral SMSF with a specially designed variable boundary layer thickness saturation function, for the purpose of eliminating chattering and enhancing robustness. Finally, fourteen control methods are compared to illustrate the effectiveness and superiority of the proposed ISFC-IESO.},
  archive      = {J_ISCI},
  author       = {Zhen Zhang and Yinan Guo and Song Zhu and Jianxing Liu and Dunwei Gong},
  doi          = {10.1016/j.ins.2024.120456},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120456},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive integral sliding-mode finite-time control with integrated extended state observer for uncertain nonlinear systems},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meta-path and hypergraph fused distillation framework for
heterogeneous information networks embedding. <em>ISCI</em>,
<em>667</em>, 120453. (<a
href="https://doi.org/10.1016/j.ins.2024.120453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Information Networks (HINs) are crucial in various intelligent systems. The latest advancements in HIN learning aim to combine meta-paths and hypergraphs, capitalizing on their strengths for further success. However, existing methods typically transform meta-paths into hypergraphs by simply removing the original edges from the meta-paths to integrate two semantics. This will inevitably encounter semantic ambiguity, a so-called semantic-shift problem, during the “meta-path → hyperedges” transforming, causing limited improvements. To address this, we introduce a novel fusion framework that distills knowledge from meta-paths into hypergraphs, mitigating such a problem. Specifically, we propose a unique hyperedge extraction method for incorporating various meta-paths instead of relying solely on one type of meta-path. Subsequently, we introduce a shallow student model to capture high-order information from the hypergraph, complementing a teacher model that focuses on encoding low-order information from meta-paths. Then, a distillation framework is employed to integrate explicitly multi-order information into the student. Experimental results across diverse datasets demonstrate a substantial improvement in node classification tasks, with an average accuracy increase of 2.1% over existing state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Beibei Yu and Cheng Xie and Hongming Cai and Haoran Duan and Peng Tang},
  doi          = {10.1016/j.ins.2024.120453},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120453},
  shortjournal = {Inf. Sci.},
  title        = {Meta-path and hypergraph fused distillation framework for heterogeneous information networks embedding},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real estate price estimation through a fuzzy
partition-driven genetic algorithm. <em>ISCI</em>, <em>667</em>, 120442.
(<a href="https://doi.org/10.1016/j.ins.2024.120442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating the actual price of a residential property is a critical issue in the real estate market. Real estate market practitioners gauge a property&#39;s price by considering features such as property type and residential area. Subsequently, they evaluate the property&#39;s intrinsic features, such as condition, sun exposure, scenic views, and ancillary amenities. Finally, extrinsic features such as the proximity of services and infrastructure are assessed. This paper proposes a new genetic approach for selecting residential properties that meet the purchase offer and the intrinsic and extrinsic characteristics desired by the client. Since the real estate market&#39;s changes can influence extrinsic features, the method introduces price fluctuations of properties. Extrinsic features are modelled as fuzzy partitions: each fuzzy set describes a qualitative aspect of the corresponding feature that, expressed in a linguistic term, has a human-like interpretation. Then, a deviation value (fluctuation) from the average price of the property is considered for each fuzzy set in the partition. All the property features, extrinsic and intrinsic, are encoded in the chromosome genes of the genetic algorithm. The fitness function calculates the distance between the unit price of the property and the purchase offer. Some case studies were conducted in various Italian municipalities, using the average price per square meter of residential properties the Osservatorio del Mercato Immobiliare (OMI) assigned. Depending on customer requirements and preferences, different OMI zones were selected using additional characteristics such as type, location, conservation, and proximity to various urban services. The results demonstrated the effectiveness of the proposed approach for all the case studies, showing how the optimal solution represents a good compromise between customer preferences and market offerings.},
  archive      = {J_ISCI},
  author       = {Barbara Cardone and Ferdinando Di Martino and Sabrina Senatore},
  doi          = {10.1016/j.ins.2024.120442},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120442},
  shortjournal = {Inf. Sci.},
  title        = {Real estate price estimation through a fuzzy partition-driven genetic algorithm},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A robust one-stage detector for SAR ship detection with
sequential three-way decisions and multi-granularity. <em>ISCI</em>,
<em>667</em>, 120436. (<a
href="https://doi.org/10.1016/j.ins.2024.120436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic Aperture Radar (SAR) images are widely used in ship detection because of their all-weather and all-day imaging characteristics. However, there are two challenges for SAR ship detection. One is coherent speckle noise, causing ship confusion with similar objects and raising false alarms. The other is multi-scale ship detection, particularly in small ships, which suffers from insufficient accuracy. To address these challenges, this paper proposes a robust one-stage detector, S3MDet, for SAR ship detection with sequential three-way decisions (S3WDs) and multi-granularity. First, to effectively eliminate the interference of coherent speckle noise, a noise classification and denoising module (NCDM) S3WD-based is designed. This module can accurately classify the noise level of the image and only perform denoising on the images identified as noisy, avoiding unnecessary operations on noise-free images. Then, to solve the problem of multi-scale ship detection, a multi-granularity group attention module (MGAM) is designed to obtain a richer representation of multi-granularity features. This module adopts a multi-granularity group convolution structure and channel-wise attention weights to efficiently extract ship features of different scales from SAR images. Extensive experiments on four SAR ship datasets, including SAR-Ship-Dataset, HRSID, SSDD, and LS-SSDD-v1.0, validate the robustness of S3MDet, demonstrating that it achieves state-of-the-art performance.},
  archive      = {J_ISCI},
  author       = {Li Ying and Duoqian Miao and Zhifei Zhang},
  doi          = {10.1016/j.ins.2024.120436},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120436},
  shortjournal = {Inf. Sci.},
  title        = {A robust one-stage detector for SAR ship detection with sequential three-way decisions and multi-granularity},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SANe: Space adaptation network for temporal knowledge graph
completion. <em>ISCI</em>, <em>667</em>, 120430. (<a
href="https://doi.org/10.1016/j.ins.2024.120430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Knowledge Graphs (TKGs) model time-dependent facts as relations between entities at specific timestamps, making them well-suited for real-world scenarios. However, TKGs are susceptible to incompleteness, necessitating Temporal Knowledge Graph Completion (TKGC) to predict missing facts. Prior methods often struggle to effectively handle two critical properties of TKGs, time-variability and time-stability, simultaneously, which hinders their performance. In this paper, we propose Space Adaptation Network (SANe), a novel approach for TKGC. SANe adapts facts at different timestamps to distinct latent spaces, effectively addressing time-variability. Our model introduces Parameter Generation Network to produce separate neural networks for each snapshot, which are then encoded into different latent spaces. A dynamic convolutional neural network processes entities and relations, utilizing different learned parameters generated by parameter generation network with respect to timestamps. By handling different temporal snapshots separately, TKGC is transformed into static KGC, enabling the modeling of time-variability. Dynamic convolutional neural network efficiently learns collective knowledge over large periods and supplements more specific knowledge gradually in smaller periods, facilitating time-stability. To strike a balance between learning time-variability and time-stability, we introduce a time-aware parameter generator to produce parameters hierarchically based on year, month, and day timestamps. Long-term knowledge is effectively shared across adjacent snapshots within the same year or month, while short-term knowledge within a day is preserved in specific parameters. However, in unbalanced TKGs, where many facts occur in small intervals, the large number of parameters generated by time-aware parameter generator may remain underutilized. To address this, we propose Adaptive Parameter Generation with a partition tree, ensuring parameter load balancing while maintaining time-stability. We conduct extensive experiments on five benchmark datasets, demonstrating the superiority of SANe over existing methods for TKGC, achieving state-of-the-art performance. Our contributions include pioneering TKGC from the perspective of space adaptation, achieving a balance between time-variability and time-stability through latent space overlap constraints, and substantiating the effectiveness of our model through comprehensive experiments on rich temporal datasets.},
  archive      = {J_ISCI},
  author       = {Yancong Li and Xiaoming Zhang and Bo Zhang and Feiran Huang and Xiaopeng Chen and Ming Lu and Shuai Ma},
  doi          = {10.1016/j.ins.2024.120430},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120430},
  shortjournal = {Inf. Sci.},
  title        = {SANe: Space adaptation network for temporal knowledge graph completion},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SecureTLM: Private inference for transformer-based large
model with MPC. <em>ISCI</em>, <em>667</em>, 120429. (<a
href="https://doi.org/10.1016/j.ins.2024.120429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based Large Models (TLM), such as generative pre-trained models (GPT), have become increasingly popular for practical applications through Deep Learning as a Service (DLaaS). They have been extensively used in natural language processing and computer vision. However, concerns regarding potential private data leakage arise with this type of inference service. While some private inference techniques can protect privacy, they often introduce high latency and approximate replacements in the design protocols, resulting in changes to the model structure and decreased accuracy. In this research, we present SecureTLM, a private inference method based on secure multi-party computation (MPC) that does not require modifications to the underlying model structure. SecureTLM offers protocols for crucial computations in TLM, such as Multiplication, Softmax, GeLU, and LayerNorm, without altering the model structure. Experimental results demonstrate that SecureTLM ensures data privacy, maintains correctness, and achieves efficiency in private inference tasks.},
  archive      = {J_ISCI},
  author       = {Yuntian Chen and Xianjia Meng and Zhiying Shi and Zhiyuan Ning and Jingzhi Lin},
  doi          = {10.1016/j.ins.2024.120429},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120429},
  shortjournal = {Inf. Sci.},
  title        = {SecureTLM: Private inference for transformer-based large model with MPC},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical bottleneck for heterogeneous graph
representation. <em>ISCI</em>, <em>667</em>, 120422. (<a
href="https://doi.org/10.1016/j.ins.2024.120422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graphs (HGs) contain many nodes and their interaction relationships, which can model complex systems and provide rich semantic and structural information for task execution. Among these, HG representation stands as the fundamental and pivotal component. Existing HG representation methods primarily employ graph neural networks to acquire the semantics of nodes along various meta-paths and fuse them to represent the nodes. The most prevalent HG representation methods encompass two steps: semantic information extraction within meta-paths and semantic fusion between meta-paths. However, these methods overlooked the consideration of node heterogeneity within meta-paths and the simultaneous semantic correlation between meta-paths. Specifically, node heterogeneity within meta-paths signifies that the meta-path-based neighbors do not consistently contain information that positively influences the target node, and the semantic correlation between meta-paths indicates that different meta-path spaces are not entirely independent. Disregarding either of these issues leads to the propagation of irrelevant or redundant information and potential disruption of HG embedding. Consequently, in this study, we propose the HBHG, which is a hierarchical bottleneck for heterogeneous graph representation. HBHG primarily employs the information bottleneck (IB) as a guiding principle, constraining the propagation of irrelevant information within and between meta-paths while preserving relevant information. The central concept of the IB revolves around viewing model learning as the preservation of relevant information and compression of irrelevant information, accomplished by minimizing the dependency between input and hidden features through mutual information (MI) and maximizing the dependency between hidden features and ground-truth. Considering the complexity associated with MI estimation, this paper introduces a novel dependency index, namely the Hilbert-Schmidt independence criterion (HSIC), which offers ease of calculation. Specifically, HBHG comprises two primary components: a semantic bottleneck within meta-paths and a semantic bottleneck between meta-paths. The semantic bottleneck within meta-paths relies primarily on the HSIC-based limitations of dependencies at different layers of the graph neural network on various meta-paths, thereby maximizing the extraction of information relevant to the target node from neighboring nodes. The semantic bottleneck between meta-paths enables flexible extraction and fusion of semantic information based on downstream tasks, achieved by managing the trade-off of dependencies with HSIC between different meta-path semantic spaces. In summary, the proposed HBHG integrates hierarchical bottleneck constraints within and between meta-paths. This integration serves to maximize the aggregation of relevant information while effectively compressing irrelevant information, thereby enhancing the quality of heterogeneous graph embedding. The effectiveness of HBHG was validated through performance and ablation experiments conducted on multiple datasets.},
  archive      = {J_ISCI},
  author       = {Yunfei He and Li Meng and Jian Ma and Yiwen Zhang and Qun Wu and Weiping Ding and Fei Yang},
  doi          = {10.1016/j.ins.2024.120422},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120422},
  shortjournal = {Inf. Sci.},
  title        = {Hierarchical bottleneck for heterogeneous graph representation},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Turing instability analysis of a rumor propagation model
with time delay on non-network and complex networks. <em>ISCI</em>,
<em>667</em>, 120402. (<a
href="https://doi.org/10.1016/j.ins.2024.120402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the Internet and social media, rumors can spread not only through word-of-mouth but also rapidly through the network. In this paper, a dynamic model of rumor propagation with time delay is proposed separately for non-network and network scenarios. Additionally, we analyze the equilibrium points and their existence conditions for rumor propagation. After the linear approximation of the model, the necessary conditions for Turing instability are derived. Furthermore, the amplitude equation corresponding to the model in this paper is derived. Finally, through numerical simulations in the non-network model, we validate the aforementioned theories and find that changing the removed coefficient and cross-diffusion coefficient have a significant impact on Turing patterns, while time delay and periodic diffusion have a smaller impact. In the network model, we compare the effects of two network structures, the WS network and the BA network, through numerical simulations, verifying the feasibility of the Monte Carlo simulation method.},
  archive      = {J_ISCI},
  author       = {Yi Ding and Linhe Zhu},
  doi          = {10.1016/j.ins.2024.120402},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120402},
  shortjournal = {Inf. Sci.},
  title        = {Turing instability analysis of a rumor propagation model with time delay on non-network and complex networks},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Balancing pareto front exploration of non-dominated
tournament genetic algorithm (b-NTGA) in solving multi-objective NP-hard
problems with constraints. <em>ISCI</em>, <em>667</em>, 120400. (<a
href="https://doi.org/10.1016/j.ins.2024.120400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents a new balanced selection operator applied to the proposed Balanced Non-dominated Tournament Genetic Algorithm (B-NTGA) that actively uses archive to solve multi- and many-objective NP-hard combinatorial optimization problems with constraints. The primary motivation is to make B-NTGA more efficient in exploring Pareto Front Approximation (PFa), focusing on “gaps” and reducing some PFa regions&#39; sampling too frequently. Such a balancing mechanism allows B-NTGA to be more adaptive and focus on less explored PFa regions. The proposed B-NTGA is investigated on two benchmark multi- and many-objective optimization real-world problems, like Thief Traveling Problem and Multi-Skill Resource-Constrained Project Scheduling Problem. The results of experiments show that B-NTGA has a higher efficiency and better performance than state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Michał Antkiewicz and Paweł B. Myszkowski},
  doi          = {10.1016/j.ins.2024.120400},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120400},
  shortjournal = {Inf. Sci.},
  title        = {Balancing pareto front exploration of non-dominated tournament genetic algorithm (B-NTGA) in solving multi-objective NP-hard problems with constraints},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge-guided communication preference learning model for
multi-agent cooperation. <em>ISCI</em>, <em>667</em>, 120395. (<a
href="https://doi.org/10.1016/j.ins.2024.120395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In partially observable scenarios such as distributed multi-agent systems with limited perceptual ranges, information sharing among agents is particularly crucial. Existing research, however, mostly focuses on broadcast communication, which not only depends heavily on bandwidth efficiency, it also causes information redundancy that may have a detrimental impact on collaboration. To solve these problems, we present a novel communication model, named Preference-oriented Multi-agent Communication (PoMaC) which enables agents to learn a communication preference to choose valuable agents with whom to share information. Specifically, communication preference is defined as the communication probability, which represents the degree of influence between agents&#39; policies. It is jointly generated by the preference network and prior knowledge, which constrains the communication selection space and improves the efficiency of network learning. After communication, the cooperative policy is generated by fusing shared messages from selected communication partners. The experimental results demonstrate that the proposed model outperforms the state-of-the-art methods in communication efficiency and results in improvement in team cooperation.},
  archive      = {J_ISCI},
  author       = {Han Zhang and Hang Yu and Xiaoming Wang and Mengke Wang and Zhenyu Zhang and Yang Li and Shaorong Xie and Xiangfeng Luo},
  doi          = {10.1016/j.ins.2024.120395},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120395},
  shortjournal = {Inf. Sci.},
  title        = {Knowledge-guided communication preference learning model for multi-agent cooperation},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collusive spam detection from chinese community question
answering sites: A collective classification framework. <em>ISCI</em>,
<em>667</em>, 120379. (<a
href="https://doi.org/10.1016/j.ins.2024.120379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With Community Question Answering (CQA) sites evolving into quite popular knowledge-sharing platforms on the Internet, they have also become ideal places for various spammers to spread fake or promotional information. Recently, with the rapid development of crowdsourcing systems, numerous malicious users have launched organized spam campaigns, conducting many spam accounts to carry out collusive spamming activities on CQA sites. In these campaigns, the spammers do not act independently but post deceptive questions and answers (Q&amp;As) collaboratively, which makes the Q&amp;As closely related to each other, but the spam clues of them are even less visible. Therefore, most existing spam detection works may fail to detect these carefully organized and posted collusive CQA spam. In this paper, taking Baidu Zhidao, a popular CQA platform in Chinese, as the study object, we propose a C ollective C lassification framework for community Q uestion A nswering spam detection ( CCQA ), which collectively identifies the collusive CQA spam using Q&amp;A features and the correlations among Q&amp;As. First, we define the Deceptive Pattern of Q&amp;As, based on which the real Q&amp;A groups are extracted. Then, we extract several highly discriminative Q&amp;A features from both individual and group levels, and propose several types of correlations, which correlate the Q&amp;As that are more likely to have the same labels. After uniformly modeling the Q&amp;As, features, and correlations in the Attributed Heterogeneous Information Network (AHIN), a semi-supervised collective classification algorithm is proposed to detect the collusive Q&amp;A spam. Experimental results on a real-life dataset demonstrate that CCQA can accurately detect the collusive CQA spam, and outperform a number of competitive baselines.},
  archive      = {J_ISCI},
  author       = {Lu Zhang and Mingming Xu and Zhan Bu and Gaofeng He and Haiting Zhu and Changjian Fang},
  doi          = {10.1016/j.ins.2024.120379},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120379},
  shortjournal = {Inf. Sci.},
  title        = {Collusive spam detection from chinese community question answering sites: A collective classification framework},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view uncertainty deep forest: An innovative deep
forest equipped with uncertainty estimation for drug-induced liver
injury prediction. <em>ISCI</em>, <em>667</em>, 120342. (<a
href="https://doi.org/10.1016/j.ins.2024.120342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug-induced liver injury (DILI) refers to the harmful effects that certain drugs can have on the liver, potentially leading to severe health issues and even life-threatening conditions. Early detection of potential DILI events is crucial in drug development and toxicity assessment to ensure patient safety and the successful market entry of pharmaceuticals. We introduced a novel model, the Multi-view Uncertainty Deep Forest (MVU-DF), for predicting DILI. This model expands the Deep Forest architecture to multiple views and uses two-stage feature construction: intra-view feature interaction for key information within a view, and inter-view feature interaction for sharing information across views. Additionally, we incorporated uncertainty estimation to evaluate the confidence of predictions, using opinion as an alternative to probability. The opinion measures class support and incorporates uncertainty, enabling more precise differentiation of hard and easy samples in each MVU-DF iteration, enhancing the cascading scheme. The model&#39;s high interpretability enhances prediction performance and reliability. Our experiments demonstrate the potential of this research in improving the accuracy and decision-making transparency of hepatotoxicity predictions in drug development.},
  archive      = {J_ISCI},
  author       = {Qiong Tan and Yuqi Wen and Yong Xu and Kunhong Liu and Song He and Xiaochen Bo},
  doi          = {10.1016/j.ins.2024.120342},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120342},
  shortjournal = {Inf. Sci.},
  title        = {Multi-view uncertainty deep forest: An innovative deep forest equipped with uncertainty estimation for drug-induced liver injury prediction},
  volume       = {667},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DSTCNN: Deformable spatial-temporal convolutional neural
network for pedestrian trajectory prediction. <em>ISCI</em>,
<em>666</em>, 120455. (<a
href="https://doi.org/10.1016/j.ins.2024.120455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian trajectory prediction holds significant research value in service robots, autonomous driving, and intelligent monitoring. Currently, most pedestrian trajectory prediction methods focus on data-driven models based on recurrent neural networks, but there is insufficient research on data-driven models based on convolutional neural networks. In this study, we first analyze the two problems in pedestrian trajectory prediction methods based on convolutional neural networks: 1. Previous trajectory prediction methods based on convolutional neural networks have spatial-temporal entanglement problems; 2. These methods are limited by their fixed convolution kernels and cannot accurately model social and temporal interactions. Furthermore, we propose a deformable spatial-temporal convolutional neural network (DSTCNN) to better adapt to the pedestrian trajectory prediction task. The deformable spatial-temporal convolutional neural network models spatial and temporal interactions separately, overcoming the shortcomings of spatial-temporal entanglement. The deformable spatial-temporal convolution also gets rid of the fixed convolution kernel, making the modeling of spatial-temporal interactions more accurate. On the ETH and UCY datasets, the average displacement error and final displacement error of our method are 0.29 and 0.53 meters, respectively. In kernel density estimation, average Mahalanobis distance, and average maximum eigenvalue metrics, our method still achieves better performance compared to baseline methods. Moreover, the deformable spatial-temporal convolutional neural network is a memory-efficient model with only 4.1 K parameters.},
  archive      = {J_ISCI},
  author       = {Wangxing Chen and Haifeng Sang and Jinyu Wang and Zishan Zhao},
  doi          = {10.1016/j.ins.2024.120455},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120455},
  shortjournal = {Inf. Sci.},
  title        = {DSTCNN: Deformable spatial-temporal convolutional neural network for pedestrian trajectory prediction},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse orthogonal supervised feature selection with global
redundancy minimization, label scaling, and robustness. <em>ISCI</em>,
<em>666</em>, 120454. (<a
href="https://doi.org/10.1016/j.ins.2024.120454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting discriminative features to build effective learning models is a significant research work in machine learning. In practical applications, the data distribution characteristics are diverse, and the uncertainties pose challenges for building learning models with robustness and generalization capabilities. Since one-hot encoding is good at representing independent labels, the label matrix of regression-based feature selection (FS) methods is usually encoded with one-hot encoding. However, it&#39;s not well adapted to the different data distributions. This paper proposes a sparse orthogonal supervised FS model with global redundancy minimization, label scaling, and robustness (GRMLSRSOFS) to address the above problems. This model uses the label scaling technique proposed in this paper to better adapt to different data distributions. An iterative optimization method is given, and its convergence is demonstrated theoretically and experimentally. Further, experimental results on 12 public datasets show that 1) The GRMLSRSOFS can achieve higher classification accuracy with fewer features in most cases than several state-of-the-art FS methods. For example, the GRMLSRSOFS achieves 100% classification accuracy using only 20 features on the warpPIE10P dataset and obtains nearly 6% improvement over other methods on the Yale dataset. 2) The convergence speed of the GRMLSRSOFS will be faster after label scaling.},
  archive      = {J_ISCI},
  author       = {Huming Liao and Hongmei Chen and Yong Mi and Chuan Luo and Shi-Jinn Horng and Tianrui Li},
  doi          = {10.1016/j.ins.2024.120454},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120454},
  shortjournal = {Inf. Sci.},
  title        = {Sparse orthogonal supervised feature selection with global redundancy minimization, label scaling, and robustness},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust hyperspectral image classification using generative
adversarial networks. <em>ISCI</em>, <em>666</em>, 120452. (<a
href="https://doi.org/10.1016/j.ins.2024.120452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces Sill-Rgan, a novel Generative Adversarial Network (GAN) designed to improve hyperspectral image (HSI) classification under varying lighting conditions. Sill-Rgan uniquely maps different light condition domains, enhancing sample classification robustness and generating new virtual samples. Addressing challenges like high spectral dimensionality and noise in HSI classification, our approach utilizes a deep proxy-based learning framework. It integrates and improves advanced GAN models and multitask networks for optimal training stability and loss function optimization. The model&#39;s mapping network is adept at generating domain-specific latent codes, enabling the transformation of original hyperspectral data into enhanced versions. Extensive experiments conducted on hyperspectral datasets of agricultural products under diverse indoor and outdoor lighting conditions confirm the effectiveness of Sill-Rgan. The results highlight the model&#39;s adaptability in both supervised and semi-supervised learning scenarios, yielding exceptional classification accuracy and enhanced data quality. The versatile potential of Sill-Rgan extends its applicability to a broad range of spectral data classifications, underlining its significant contribution to hyperspectral imaging. This advancement opens new avenues in machine vision systems, particularly in scenarios with dynamic lighting challenges.},
  archive      = {J_ISCI},
  author       = {Ziru Yu and Wei Cui},
  doi          = {10.1016/j.ins.2024.120452},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120452},
  shortjournal = {Inf. Sci.},
  title        = {Robust hyperspectral image classification using generative adversarial networks},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Variable precision fuzzy rough sets based on overlap
functions with application to tumor classification. <em>ISCI</em>,
<em>666</em>, 120451. (<a
href="https://doi.org/10.1016/j.ins.2024.120451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overlap functions, which can be characterized as a type of non-associative binary aggregation operators, have emerged as one of the most extensively utilized aggregation operators in numerous applications, including image processing, information fusion, and classification problems. At the same time, fuzzy rough sets have also been widely used in these fields due to their excellent ability to handle continuous and uncertain information. However, the variable precision fuzzy rough set model based on overlap functions and its applications have not been fully studied. For instance, some basic properties are invalid and there is a lack of practical applications. In this paper, both overlap functions and precision parameters are introduced into the fuzzy rough sets, namely the overlap function-based variable precision fuzzy rough set (OVPFRS), which is then used in the practical problem of tumor classification. First, considering the existing overlap function-based rough set models, the OVPFRS model is established, and some underlying properties of this model are explored. Second, on the basis of the proposed model, a method for attribute reduction is developed. Finally, the new method is applied to the classification of tumor data from the real world. Through experimentation and comparison with other attribute reduction methods, it has been demonstrated that our model is flexible and the algorithm is viable and effective.},
  archive      = {J_ISCI},
  author       = {Xiaohong Zhang and Qiqi Ou and Jingqian Wang},
  doi          = {10.1016/j.ins.2024.120451},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120451},
  shortjournal = {Inf. Sci.},
  title        = {Variable precision fuzzy rough sets based on overlap functions with application to tumor classification},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A method of data analysis based on division-mining-fusion
strategy. <em>ISCI</em>, <em>666</em>, 120450. (<a
href="https://doi.org/10.1016/j.ins.2024.120450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of data technology and storage services, the scale and complexity of data are rapidly growing. Consequently, promptly analyzing data and deriving precise insights have become urgent. Nevertheless, traditional methods struggle to balance the speed and accuracy of data mining. This paper proposes a data analysis technique called the Division-Mining-Fusion (DMF) strategy to tackle this challenge. Specifically, we divide a large-scale and complex dataset into multiple small-scale and simple sub-datasets. Then, we extract the knowledge embedded within each sub-dataset. Finally, we combine the extracted knowledge from each sub-dataset to accomplish learning tasks. To demonstrate the superior performance of the DMF strategy, we apply it to two fields: rough set theory and feature selection. The DMF strategy can accelerate the speed of data mining, enhance the accuracy of data analysis, and reduce the dimensionality of data. These advantages suggest that the DMF strategy outperforms traditional methods in processing data more efficiently. In addition, the number of sub-datasets is a crucial parameter of the DMF strategy. As the number of sub-datasets increases, the ability of the DMF strategy to analyze data continuously improves.},
  archive      = {J_ISCI},
  author       = {Qingzhao Kong and Wanting Wang and Weihua Xu and Conghao Yan},
  doi          = {10.1016/j.ins.2024.120450},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120450},
  shortjournal = {Inf. Sci.},
  title        = {A method of data analysis based on division-mining-fusion strategy},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An XGBoost-assisted evolutionary algorithm for expensive
multiobjective optimization problems. <em>ISCI</em>, <em>666</em>,
120449. (<a href="https://doi.org/10.1016/j.ins.2024.120449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many expensive optimization problems exist in various real-world applications. However traditional evolutionary algorithms are inadequate for solving these problems directly. Surrogate-assisted evolutionary algorithm (SAEA) can effectively solve expensive optimization problems using computationally inexpensive surrogate models. However, both the Kriging and ensemble models most SAEAs adopted have limited uncertainty of prediction, especially for expensive multiobjective optimization problems (EMOPs). To enhance the optimization performance of SAEA for EMOPs, this paper proposes a new XGBoost-assisted evolutionary algorithm, calling XGBEA. Specifically, XGBoost is used as the surrogate model, and a neighborhood density selection strategy based on a mixed population and archive space (NDS-MPA) is proposed to measure the uncertainties of individuals. XGBoost helps to best fit objective functions with different fitness landscapes. NDS-MPA selects non-dominated individuals with minimal density for re-evaluation, incorporating considerations of convergence, diversity and uncertainty. Experimental results on two well-studied benchmarks demonstrated the superiority of XGBEA over seven state-of-the-art SAEAs.},
  archive      = {J_ISCI},
  author       = {Feiqiao Mao and Ming Chen and Kaihang Zhong and Jiyu Zeng and Zhengping Liang},
  doi          = {10.1016/j.ins.2024.120449},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120449},
  shortjournal = {Inf. Sci.},
  title        = {An XGBoost-assisted evolutionary algorithm for expensive multiobjective optimization problems},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meta-path aware dynamic graph learning for friend
recommendation with user mobility. <em>ISCI</em>, <em>666</em>, 120448.
(<a href="https://doi.org/10.1016/j.ins.2024.120448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, friend recommendation has gained widespread popularity in location-based social networks (LBSNs), which provides more opportunities for users to forge new friendships. Most existing studies exploit user trajectories or check-ins of Point-Of-Interests (POIs) to predict friendships based on geographic homophily. However, the dynamics of social relationships are left insufficiently considered in modeling user preferences. In this paper, we explore how geographical and social preferences influence each other in a dynamic manner. Specifically, we propose a Meta-path aware Dynamic Graph with Subgraph Inference, named MDyGSI, which models the evolution of user preferences with time-phased sequences of POIs and social relationships for friend recommendation in LBSNs. In each time step of the evolution, geographical and social preferences are modeled through behavior-specific meta-paths in a dynamic heterogeneous graph. The formations of different meta-paths are facilitate by each other to explore mutual influences of dual preferences. To keep the dynamics of social relationships aligned with check-in history, reliable User - User connections are sampled from social graphs based on geographical collaborative filtering in each step, which also avoids noisy social interactions. Furthermore, the dual preferences are concatenated with evolutionary weights measured by a Gated Recurrent Unit for final recommendation. Experimental results on two real-world datasets show significant improvements in MDyGSI over the state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Ding Ding and Jing Yi and Jiayi Xie and Zhenzhong Chen},
  doi          = {10.1016/j.ins.2024.120448},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120448},
  shortjournal = {Inf. Sci.},
  title        = {Meta-path aware dynamic graph learning for friend recommendation with user mobility},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised feature extraction based on uncorrelated
approach. <em>ISCI</em>, <em>666</em>, 120447. (<a
href="https://doi.org/10.1016/j.ins.2024.120447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high-dimensional spaces, mathematically driven data processing methods have recently attracted a lot of attention. We consider the situation when information is obtained by sampling a probability distribution with support on or close to a sub-manifold of Euclidean space. In this paper, we provide an innovative unsupervised learning method called Uncorrelated Neighborhood Preserving Embedding (UNPE) which identifies the underlying manifold structure of a data set and preserves the neighborhood structure of the data set. We provide a concrete formulation with UNPE, an iterative technique to demonstrate the usefulness of the framework, which has been confirmed by experimental findings on datasets Coil20, Pie, Tox, and Prostate-GE that uses three different parameters viz., F-score, NMI, and accuracy. It is observed that performance is better than the LPP algorithm by 1%, PCA by 2%, and more than 2% of LLE and LE algorithms.},
  archive      = {J_ISCI},
  author       = {Jayashree and Shiva Prakash T. and Venugopal K.R.},
  doi          = {10.1016/j.ins.2024.120447},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120447},
  shortjournal = {Inf. Sci.},
  title        = {Unsupervised feature extraction based on uncorrelated approach},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Structured collaborative sparse dictionary learning for
monitoring of multimode processes. <em>ISCI</em>, <em>666</em>, 120444.
(<a href="https://doi.org/10.1016/j.ins.2024.120444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel structured collaborative sparse dictionary learning approach is proposed to improve the monitoring performance of discriminative dictionary learning for multimode processes. The mode discriminability and data reconstruction are first balanced by decomposing the dictionary coefficients into between- and within-class parts and introducing a within-class self-expression regularization term. A weight vector of between-class coefficients is subsequently exploited for accurate mode identification of data that falls into the overlapping regions between different class distributions. Moreover, in order to pinpoint the fault variables, a scalable fault isolation method is developed which imposes a constraint of statistical control limit and introduces the ℓ 1 ℓ1 / ℓ 2 , 0 ℓ2,0 -structured sparsity regularization terms. The mode identification capability of the proposed method is proved theoretically by Theorem 1 , Theorem 2 , and a lower-bound magnitude is provided by Theorem 3 for fault isolation. Finally, extensive experiments conducted in the numerical and industrial process demonstrate that our proposed method outperforms some state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Yi Liu and Jiusun Zeng and Bingbing Jiang and Weiguo Sheng and Zidong Wang and Lei Xie and Li Li},
  doi          = {10.1016/j.ins.2024.120444},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120444},
  shortjournal = {Inf. Sci.},
  title        = {Structured collaborative sparse dictionary learning for monitoring of multimode processes},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel three-way classification and ranking approach based
on regret theory and TOPSIS. <em>ISCI</em>, <em>666</em>, 120443. (<a
href="https://doi.org/10.1016/j.ins.2024.120443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-attribute decision-making (MADM) problems, attribute types typically include benefit attributes and cost attributes. In most existing MADM studies, attribute types are converted to the same type to reduce the effect of diverse attribute types on decision results, inevitably leading to the loss of original information. In view of this, this paper presents a novel three-way decision (TWD) approach based on regret theory (RT) and TOPSIS to handle MADM problems in fuzzy environments without converting attribute types. Firstly, RT is employed to analyze the process of acquiring the relative revenue function for benefit attributes and the relative loss function for cost attributes. Then, we combine RT and TOPSIS method to estimate the conditional probability. Based on two attribute types, we develop the corresponding TWD models. One is to establish a TWD model that maximizes expected revenues based on benefit attributes, and the other is to establish a TWD model that minimizes expected losses based on cost attributes. Subsequently, we introduce the notion of integrated decision domains and investigate the ranking methods for alternatives that belong to the same (or different) integrated decision domains. Finally, we validate the effectiveness and performance of our method through case study and experimental analyses.},
  archive      = {J_ISCI},
  author       = {Ke-Ya Yan and Hai-Long Yang and Zhi-Lian Guo},
  doi          = {10.1016/j.ins.2024.120443},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120443},
  shortjournal = {Inf. Sci.},
  title        = {A novel three-way classification and ranking approach based on regret theory and TOPSIS},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A socio-technical approach to trustworthy semantic
biomedical content generation and sharing. <em>ISCI</em>, <em>666</em>,
120441. (<a href="https://doi.org/10.1016/j.ins.2024.120441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of online biomedical content has presented a notable challenge in delivering timely and precise semantic annotations. Semantic annotations play a crucial role in contextually indexing data, thereby enhancing search accuracy. This intricate process involves the utilization of multiple coded ontologies, requiring extensive technical expertise and domain knowledge. While automated ontologies face limitations in balancing accuracy and speed, expert knowledge generation is also scarce and expensive. In response to these conflicting challenges, we propose a socio-technical content generation and sharing approach named ‘Semantically,’ which actively involves biomedical experts and scientists. Additionally, ‘Semantically’ leverages schema.org for incorporating additional semantic tags to enhance search engine performance. The outcome is high-quality, machine-understandable content that not only facilitates fast and accurate searches but also instills trust due to the collaborative nature of the annotation process. ‘Semantically’ generated biomedical content was evaluated in two scenarios: (1) search based solely on initial-level annotations and (2) search incorporating additional expert-recommended annotations. ‘Semantically’ enhances the user search experience when compared to benchmark data. In the first scenario, the unigram to 5-grams strategy efficiently recognizes biomedical terms, resulting in high precision, recall, F1, and accuracy scores, all around 0.9. ‘Semantically’ code is openly accessible at https://github.com/bukharilab/Semantically .},
  archive      = {J_ISCI},
  author       = {Asim Abbas and Tahir Hameed and Fazel Keshtkar and Seifedine Kadry and Syed Ahmad Chan Bukhari},
  doi          = {10.1016/j.ins.2024.120441},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120441},
  shortjournal = {Inf. Sci.},
  title        = {A socio-technical approach to trustworthy semantic biomedical content generation and sharing},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An optimal bayesian intervention policy in response to
unknown dynamic cell stimuli. <em>ISCI</em>, <em>666</em>, 120440. (<a
href="https://doi.org/10.1016/j.ins.2024.120440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interventions in gene regulatory networks (GRNs) aim to restore normal functions of cells experiencing abnormal behavior, such as uncontrolled cell proliferation. The dynamic, uncertain, and complex nature of cellular processes poses significant challenges in determining the best interventions. Most existing intervention methods assume that cells are unresponsive to therapies, resulting in stationary and deterministic intervention solutions. However, cells in unhealthy conditions can dynamically respond to therapies through internal stimuli, leading to the recurrence of undesirable conditions. This paper proposes a Bayesian intervention policy that adaptively responds to cell dynamic responses according to the latest available information. The GRNs are modeled using a Boolean network with perturbation (BNp), and the fight between the cell and intervention is modeled as a two-player zero-sum game. Assuming an incomplete knowledge of cell stimuli, a recursive approach is developed to keep track of the posterior distribution of cell responses. The proposed Bayesian intervention policy takes action according to the posterior distribution and a set of Nash equilibrium policies associated with all possible cell responses. Analytical results demonstrate the superiority of the proposed intervention policy against several existing intervention techniques. Meanwhile, the performance of the proposed policy is investigated through comprehensive numerical experiments using the p53-MDM2 negative feedback loop regulatory network and melanoma network. The results demonstrate the empirical convergence of the proposed policy to the optimal Nash equilibrium policy.},
  archive      = {J_ISCI},
  author       = {Seyed Hamid Hosseini and Mahdi Imani},
  doi          = {10.1016/j.ins.2024.120440},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120440},
  shortjournal = {Inf. Sci.},
  title        = {An optimal bayesian intervention policy in response to unknown dynamic cell stimuli},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Density peak clustering by local centers and improved
connectivity kernel. <em>ISCI</em>, <em>666</em>, 120439. (<a
href="https://doi.org/10.1016/j.ins.2024.120439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similarity calculation is one of the most critical steps of clustering analysis, especially for arbitrarily formed elongated structures. When it comes to Density Peak Clustering (DPC), using Euclidean distance solely to calculate the similarity also makes it suffer arbitrarily formed data clustering. To tackle this deficiency of DPC, an improved Connectivity Kernel (ICK) was presented to accelerate Connectivity Kernel and help DPC identify clusters with arbitrarily formed structures, which mainly consist of two strategies: (i) Because that Connectivity Kernel suffers from outliers between two clusters if their density is as high as the backbone of the clusters, ICK firstly extracts local centers according to local density and relative location of points, which can eliminate most outliers and boundary points without breaking the original distribution of data. Thus, not only the adverse impact of outliers can be avoided, many meaningless calculations time can also be saved; (ii) ICK defines the connection between two local centers as their dissimilarity according to Connectivity Kernel. Differently, instead of traversing the entire dataset, ICK only focus on several specific path between two local centers to evaluate their connectivity, which further reduces the computational complexity of the algorithm to O ( n l o g n ) O(nlogn) . Experiments on synthetic and real-world datasets demonstrate the effectiveness and robustness of the proposed algorithm in practical application.},
  archive      = {J_ISCI},
  author       = {Wenjie Guo and Wei Chen and Xinggao Liu},
  doi          = {10.1016/j.ins.2024.120439},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120439},
  shortjournal = {Inf. Sci.},
  title        = {Density peak clustering by local centers and improved connectivity kernel},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-perspective knowledge graph completion with global and
interaction features. <em>ISCI</em>, <em>666</em>, 120438. (<a
href="https://doi.org/10.1016/j.ins.2024.120438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs are multi-relation heterogeneous graphs. Thus, the existence of numerous multi-relation entities imposes a tough challenge to the modelling of the knowledge graph. Some recent works represent the property of corresponding entities and relations by generating embeddings. They attempted to identify the missing entities by translation operations or semantic matching. However, the expressiveness of these approaches depends on the entity (relations) embedding. The heterogeneity of entities leads to the difficulty of balancing uniform embedding dimension settings on complex and sparse relational entities, as high-dimensional embedding leads to the overfitting of sparse relational entities, and low-dimensional embedding leads to the underfitting of complex relational entities. We introduce a multi-perspective knowledge graph embedding model with global and interaction features (MGIF) to alleviate these issues. This achieved knowledge transfer from complex relational entities to sparse relational entities through the multi-view features. In particular, to overcome the local limitations of convolution neural networks, the global features shared between entities (relations) and entities (relations) are incorporated in the MGIF. The performance of MGIF is experimentally evaluated on several datasets. The experimental effects demonstrate that MGIF can efficiently model complicated entities and accomplish state-of-the-art complex relationship prediction results on most evaluation metrics.},
  archive      = {J_ISCI},
  author       = {Duantengchuan Li and Fobo Shi and Xiaoguang Wang and Chao Zheng and Yuefeng Cai and Bing Li},
  doi          = {10.1016/j.ins.2024.120438},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120438},
  shortjournal = {Inf. Sci.},
  title        = {Multi-perspective knowledge graph completion with global and interaction features},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Supplement data in federated learning with a generator
transparent to clients. <em>ISCI</em>, <em>666</em>, 120437. (<a
href="https://doi.org/10.1016/j.ins.2024.120437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a decentralized learning approach that shows promise for preserving users&#39; privacy by avoiding local data sharing. However, the heterogeneous data in federated learning limits its applications in wider scopes. The data heterogeneity from diverse clients leads to weight divergence between local models and degrades the global performance of federated learning. To mitigate data heterogeneity, supplementing training data in federated learning has been explored and proven effective. However, traditional methods of supplementing data raise privacy concerns and increase learning costs. In this paper, we propose a solution to supplement training data with a generative model that is transparent to local clients. We keep the learning of the generative model on the server side and store the supplementary data from the generative model on the server side as well. This approach avoids collecting auxiliary data directly from local clients, reducing privacy concerns for them and preventing rising costs for local clients. To avoid loose learning on the real and synthetic samples, we constrain the optimization of the global model with a distance between the training global model and the distribution of the aggregated global model. Extensive experiments have verified that the synthetic data from the generative model improve the performance of federated learning, especially in a heterogeneous environment.},
  archive      = {J_ISCI},
  author       = {Xiaoya Wang and Tianqing Zhu and Wanlei Zhou},
  doi          = {10.1016/j.ins.2024.120437},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120437},
  shortjournal = {Inf. Sci.},
  title        = {Supplement data in federated learning with a generator transparent to clients},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-hyperplane twin support vector regression guided with
fuzzy clustering. <em>ISCI</em>, <em>666</em>, 120435. (<a
href="https://doi.org/10.1016/j.ins.2024.120435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, twin support vector regression has become a hot research topic because of its low computing time and excellent performance. It can be observed, however, that either the support vector regression or twin support vector regression have no more than two regression hyperplanes. Many research studies have ignored the potential of multiple hyperplanes regression algorithms. In this paper, a one-versus-all twin support vector regression (OVATWSVR) with multiple regression hyperplanes is proposed, in order to achieve excellent regression performance though multi-hyperplane structure. Suppose that the input data implicitly has p categories, OVATWSVR solves a smaller quadratic programming problem (QPP) and repeats this process p times, resulting in p regression hyperplanes. For the purpose of mining the implicit category information of each point to assist OVATWSVR in training hyperplanes, meanwhile considering the fuzzy characteristics of points (they lack classification labels) in different types of regression datasets, we further propose a fuzzy clustering algorithm, namely fuzzy weighted K-nearest neighbors fuzzy density peak clustering (FKNN-FDPC), to provide OVATWSVR with information regarding the category of each point. A fuzzy membership function, also guided by FKNN-FDPC, is added to OVATWSVR in order to enhance the capability of OVATWSVR to handle possible fuzzy properties in data, thus creating FOVATWSVR. F3OVATWSVR is a reasonable name for the entire multiple phases’ algorithm. Several UCI benchmark datasets, a real-world competition dataset and a state of health (SOH) estimation of lithium-ion batteries dataset are used to verify the superiority and effectiveness of F3OVATWSVR.},
  archive      = {J_ISCI},
  author       = {Zichen Zhang and Wei-Chiang Hong and Yongquan Dong},
  doi          = {10.1016/j.ins.2024.120435},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120435},
  shortjournal = {Inf. Sci.},
  title        = {Multi-hyperplane twin support vector regression guided with fuzzy clustering},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantifying opacity of discrete event systems modeled with
probabilistic petri nets. <em>ISCI</em>, <em>666</em>, 120434. (<a
href="https://doi.org/10.1016/j.ins.2024.120434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The verification and enforcement problem of opacity that falls into the category of security properties of information flows in a cyber-physical system has been extensively studied from the view of discrete event systems. Recent years have witnessed growing interest in the quantitative analysis of opacity. However, documented results on quantifying opacity in the literature are not formulated within the framework of Petri nets. By introducing a new class of Petri net as a modeling vehicle for opacity quantification, we suggest a novel notion of opacity referred to as worthy opacity, which describes the worth associated with the information that a system might leak during its evolution. Depending on how much system information is captured by an intruder, we propose two types of worthy opacity: stepwise and observational worthy opacity. We provide a necessary and sufficient condition for stepwise worthy opacity and prove its decidability. Observational worthy opacity is established by considering both system and observation aspects, with its verification shown to be undecidable. Compared with the existing works on quantifying opacity, we argue that the worthy opacity is of practical concern, as being aware of the information worth that a system may leak during its evolution is a more realistic guide than the probability that it may reveal a system secret.},
  archive      = {J_ISCI},
  author       = {Sian Zhou and Li Yin and Zhiwu Li},
  doi          = {10.1016/j.ins.2024.120434},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120434},
  shortjournal = {Inf. Sci.},
  title        = {Quantifying opacity of discrete event systems modeled with probabilistic petri nets},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Context CVGN: A conditional multimodal trajectory
prediction network based on scene semantic modeling. <em>ISCI</em>,
<em>666</em>, 120433. (<a
href="https://doi.org/10.1016/j.ins.2024.120433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian behavior and trajectory prediction in highly dynamic and interactive scenes have emerged as among the most daunting challenges in the realm of autonomous driving. In addressing the modeling of pedestrian interaction and the generation of multimodal trajectories for pedestrian trajectory prediction, we present a novel approach: a context-based conditional variational generative adversarial network (Context-CVGN). This network is capable of capturing the physical environment, pedestrian interactions, and other scene elements by representing them as a bird&#39;s-eye view (BEV) semantic map. It can then infer various potential pedestrian trajectories in the future. By training and evaluating our model on the ETH&amp;UCY dataset, we demonstrate superior performance compared to several state-of-the-art methods, particularly in terms of the final displacement error (FDE). These results substantiate the efficacy of our model in accurately predicting future pedestrian trajectories.},
  archive      = {J_ISCI},
  author       = {Xin Yang and Shiyu Wang and Yitian Zhu and Dake Zhou and Tao Li},
  doi          = {10.1016/j.ins.2024.120433},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120433},
  shortjournal = {Inf. Sci.},
  title        = {Context CVGN: A conditional multimodal trajectory prediction network based on scene semantic modeling},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive population size based differential evolution by
mining historical population similarity for path planning of unmanned
aerial vehicles. <em>ISCI</em>, <em>666</em>, 120432. (<a
href="https://doi.org/10.1016/j.ins.2024.120432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various variants have been proposed to improve the search ability and efficiency of Differential Evolution (DE). However, the variants ignore the impact caused by the use of accumulated historical information, resulting in unpromising performance of the search. Furthermore, the global exploration and local exploitation ability of population is affected by the population number ( NP ), which commonly adapts with little adaptive control or with linear descendent only. To utilize more historical population information, we propose in this paper a novel adaptive population size-based DE (APSDE) by mining historical population information, to balance global exploration and local exploitation ability. APSDE uses historical population information to mine population distribution and extract information to assign parameters to the current population. Moreover, an archive is utilized to store the historical population information, where historical successful parameter information consists of scaling factor ( F ), crossover rate ( CR ) and NP for better balancing the search ability of population. To evaluate the performance of APSDE, we conduct experiments both on the 28 benchmark functions of CEC2017, the 10 benchmark functions of CEC2020, and a real-world application - the path planning of unmanned aerial vehicles (UAVs). The experimental results have demonstrated that APSDE achieves the promising performance in both convergence accuracy and convergence speed.},
  archive      = {J_ISCI},
  author       = {Zijian Cao and Kai Xu and Zhenyu Wang and Ting Feng and Feng Tian},
  doi          = {10.1016/j.ins.2024.120432},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120432},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive population size based differential evolution by mining historical population similarity for path planning of unmanned aerial vehicles},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed robust scheduling optimization for energy system
of steel industry considering prediction uncertainties. <em>ISCI</em>,
<em>666</em>, 120431. (<a
href="https://doi.org/10.1016/j.ins.2024.120431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive scheduling is commonly deployed for the energy systems in the steel industry, while the uncertainties caused by the predictions can lead to under-optimization or over-adjustment. In order to solve this problem, a novel distributed robust optimization framework is proposed in this study. A Robust Optimization (RO) model is established at first to mathematically address the prediction uncertainties, where the gas, steam, and electricity networks are considered as distributed participants, with their operating costs and CO 2 emissions costs as the objectives for minimization. Then the vanilla 2-block Alternating Direction Multiplier Method (ADMM) is extended to a 3-block structure in this study for solving the established RO model in a distributed manner. Considering the superiority on efficiency, the Column-and-Constraint Generation (C&amp;CG) algorithm is deployed for each block. To ensure convergence considering the extensive interaction between the updated dual and coupling variables in each iteration of the overall ADMM and each C&amp;CG, an adaptive bridging method is developed in this study. Finally, experiments using real data from a steel plant in China demonstrate that the proposed framework has a deviation of less than 1.33 % while with higher efficiency and better robustness compared to other algorithms.},
  archive      = {J_ISCI},
  author       = {Zhiyuan Wang and Zhongyang Han and Jun Zhao and Wei Wang},
  doi          = {10.1016/j.ins.2024.120431},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120431},
  shortjournal = {Inf. Sci.},
  title        = {Distributed robust scheduling optimization for energy system of steel industry considering prediction uncertainties},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-criteria assessment of climate change due to green
house effect based on sugeno weber model under spherical fuzzy
z-numbers. <em>ISCI</em>, <em>666</em>, 120428. (<a
href="https://doi.org/10.1016/j.ins.2024.120428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using the multi-criteria decision-making (MCDM) approach, this research piece addresses the urgent problems of environmental degradation and climate change. The method provides a structured way to examine and compare different criteria and options, which improves the precision of decision-making. In order to make this method even better, we combine Zadeh&#39;s Z ´ Z´ -numbers with limitations and reliability factors in an effort to fill the current knowledge vacuum about their maximum potential. We investigate Z ´ Z´ -numbers, which are unexpected and fuzzy, in an effort to use them to our advantage by combining them with spherical fuzzy sets (SFSs). We present the idea of spherical fuzzy Z ´ Z´ -numbers ( S F Z ´ N s SFZ´Ns ) that allow for flexible and adaptive handling of uncertain data by facilitating fast pairwise comparisons of decision-making options. We develop a full set of operational rules and create aggregation operators (AOs) based on the Sugeno Weber Γ ¯ Γ¯ -norm and Γ ¯ Γ¯ -conorm to formalize this new method. We use the average and geometric AOs, two of these operators, to show how our suggested technique works and how practical it is. In decision-making situations including climate change assessment, our comparison study highlights the importance of the suggested operators and approaches, especially in relation to the greenhouse effect. Our study helps us understand Z ´ Z´ -numbers better and how they might be used to handle uncertain data by tackling the interaction between fuzziness and randomness. By emphasizing clarity and specificity, our research provides a solid basis for better decision-making and handling of ambiguity in several fields.},
  archive      = {J_ISCI},
  author       = {Shahzaib Ashraf and Maria Akram and Chiranjibe Jana and LeSheng Jin and Dragan Pamucar},
  doi          = {10.1016/j.ins.2024.120428},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120428},
  shortjournal = {Inf. Sci.},
  title        = {Multi-criteria assessment of climate change due to green house effect based on sugeno weber model under spherical fuzzy Z-numbers},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DCGNN: Adaptive deep graph convolution for heterophily
graphs. <em>ISCI</em>, <em>666</em>, 120427. (<a
href="https://doi.org/10.1016/j.ins.2024.120427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have demonstrated significant efficacy in addressing graph learning tasks by leveraging both node features and graph topology. Prevalent GNN architectures often implicitly or explicitly rely on the homophily assumption, which presupposes that neighboring nodes tend to share similar features. Despite their efficacy, GNNs may prove inadequate in modeling graphs characterized by heterophily, wherein nodes with disparate labels frequently interconnect. To mitigate this limitation, we propose DCGNN, a novel GNN framework capable of accommodating heterophily while retaining effectiveness in homophily scenarios. Initially, we elucidate that prevailing message-passing neural networks (MPNNs) struggle to discern circular substructures, prevalent in graphs demonstrating heterophily. Consequently, we propose an adaptive deep graph convolution technique, which integrates adaptive aggregation of local high-order neighborhoods, replacing the conventional stacking of single-order convolutional layers in the message-passing paradigm. Theoretical analysis confirms that DCGNN demonstrates significantly enhanced expressive capacity compared to existing MPNNs. Empirical evaluations conducted on real-world datasets validate that DCGNN outperforms several state-of-the-art GNNs tailored for graphs exhibiting heterophily.},
  archive      = {J_ISCI},
  author       = {Yang Wu and Yu Wang and Liang Hu and Juncheng Hu},
  doi          = {10.1016/j.ins.2024.120427},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120427},
  shortjournal = {Inf. Sci.},
  title        = {DCGNN: Adaptive deep graph convolution for heterophily graphs},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Dealing with congestion in the optimization of locating
single-server battery swapping stations. <em>ISCI</em>, <em>666</em>,
120426. (<a href="https://doi.org/10.1016/j.ins.2024.120426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a study on the location problem of single-server battery swap stations, identifying instances of excessively long waiting times at certain stations during their operation in a real-world company scenario. This study innovatively transforms the problem into an extended version of the classic maximal covering location problem, incorporating technology selection and three sets of additional constraints: budget, closest-assignment, and average waiting time constraints. In particular, the closest-assignment constraint is specifically designed to mimic human behavioral patterns. A non-convex integer programming model is proposed and then reformulated thus enabling it to be tackled by some general-purpose solvers. The model is validated considering a test bed of randomly generated instances. The model comprehensiveness added-value is assessed. Finally, real-world data is used which allows discussing the extraction of information in the studied context. That information is used to build an instance that is solved and analyzed to provide valuable managerial insights, emphasizing the importance of technological improvement to the management.},
  archive      = {J_ISCI},
  author       = {Bowen Zhang and Xiang Li and Francisco Saldanha-da-Gama},
  doi          = {10.1016/j.ins.2024.120426},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120426},
  shortjournal = {Inf. Sci.},
  title        = {Dealing with congestion in the optimization of locating single-server battery swapping stations},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluating potential quality of e-commerce order fulfillment
service: A collective intelligence-driven approach. <em>ISCI</em>,
<em>666</em>, 120425. (<a
href="https://doi.org/10.1016/j.ins.2024.120425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce order fulfillment service (E-COFS) plays a pivotal role in shaping consumer behavior in online marketplaces. The strategic outsourcing of the service allows e-commerce sellers to prioritize their core business areas, enhance customer satisfaction, and minimize fulfillment costs. However, a critical challenge lies in appraising the potential quality of E-COFS provided by third parties, especially when lacking historical information. To address this, this paper first designs a generalized framework for guiding the construction of the quantitative model for evaluating the potential quality of E-COFS. The proposed framework unfolds in three stages: (1) evaluating potential effectiveness of an E-COFS through quantifying stakeholders’ potential satisfaction from the E-COFS plan tailored by its provider, (2) evaluating its potential feasibility by quantifying the potential performance of the E-COFS quality management system (E-COFS-QMS) built by the provider on supporting the plan, and (3) integrating the above two parts to gauge the potential quality of the E-COFS. Building upon this framework, this paper then designs a novel quantitative model. Specifically, this model adopts the linguistic subjective judgment representation method and introduces basic uncertain linguistic information to achieve computing with words. Multiple stakeholders within e-commerce sellers are tasked with articulating their requirements, their preferences and expectations, and consensus reaching process is conducted to obtain the acceptable consensus among these stakeholders. Multiple experts from various domains are tasked with giving their subjective judgements on the performances of E-COFS and E-COFS-QMS, and a method of weighting individual judgments, which respects the reliabilities of individual judgements and the overall similarity in knowledge structures among the experts, is adopted to effectively tap into collective intelligence. Finally, a case study is conducted to validate the validity and feasibility of the proposed quantitative model.},
  archive      = {J_ISCI},
  author       = {Jian-Peng Chang and Yan Su and Mirosław J. Skibniewski and Zhen-Song Chen},
  doi          = {10.1016/j.ins.2024.120425},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120425},
  shortjournal = {Inf. Sci.},
  title        = {Evaluating potential quality of e-commerce order fulfillment service: A collective intelligence-driven approach},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive t-s fuzzy synchronization for uncertain
fractional-order chaotic systems with input saturation and disturbance.
<em>ISCI</em>, <em>666</em>, 120423. (<a
href="https://doi.org/10.1016/j.ins.2024.120423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an adaptive Takagi-Sugeno (T-S) fuzzy control scheme to synchronize two uncertain fractional-order (FO) chaotic systems with input saturations and external disturbances. Under the FO Lyapunov criterion, a novel adaptive T-S FO controller with a simple architecture is developed. System constraints are handled by modeling a saturator as a fraction of unknown functions. Due to the presence of system uncertainties, FO adaptive laws are established to adjust controller parameters. The asymptotic convergence of tracking errors and the boundedness of all closed-loop signals can be ensured. Especially, the feedback control is achieved in T-S FO chaotic systems and the posed method avoids solving linear matrix inequalities, which relieves the calculation burden. The feasibility of the presented method is confirmed through numerical simulations.},
  archive      = {J_ISCI},
  author       = {Yilin Hao and Zhiming Fang and Heng Liu},
  doi          = {10.1016/j.ins.2024.120423},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120423},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive T-S fuzzy synchronization for uncertain fractional-order chaotic systems with input saturation and disturbance},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time chaotic video encryption based on multi-threaded
parallel confusion and diffusion. <em>ISCI</em>, <em>666</em>, 120420.
(<a href="https://doi.org/10.1016/j.ins.2024.120420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the strong correlation among adjacent pixels, image encryption schemes typically perform multiple rounds of confusion and diffusion to protect images against various attacks. This is time-consuming and cannot meet the real-time requirements for video encryption. Existing works, therefore, realize video encryption by simplifying encryption process or selectively encrypting specific pixels, resulting in lower security compared to image encryption. This paper proposes a real-time chaotic video encryption strategy based on parallel computing. It splits video frame into sub-frames, creates a dedicated set of threads to concurrently perform confusion and diffusion operations on their respective sub-frames, and efficiently outputs encrypted frames. To assess its performance, two cryptosystems are implemented using different chaotic systems. Encryption speed evaluation demonstrates a significant acceleration in byte generation, confusion, and diffusion phases, enabling real-time encryption and decryption on different X86 platforms. The average encryption time is less than 42 ms, despite performing five rounds of confusion and diffusion operations on each frame. Statistical and security analysis prove that the deployed cryptosystems exhibit exceptional statistical properties and provide resistance to different attacks. Moreover, our method is adopted to implement a multi-user, real-time mobile video secure communication system using embedded systems, validating the feasibility of the proposed strategy for various application scenarios.},
  archive      = {J_ISCI},
  author       = {Dong Jiang and Tao Chen and Zhen Yuan and Wen-xin Li and Hai-tao Wang and Liang-liang Lu},
  doi          = {10.1016/j.ins.2024.120420},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120420},
  shortjournal = {Inf. Sci.},
  title        = {Real-time chaotic video encryption based on multi-threaded parallel confusion and diffusion},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Performance-oriented design and analysis for direct
data-driven control of multi-agent systems. <em>ISCI</em>, <em>666</em>,
120419. (<a href="https://doi.org/10.1016/j.ins.2024.120419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There exists a relationship between the consensus performance and the control protocol in the coordination of multiple agents. This article proposes a novel direct data-driven control (DirDDC) using such a relationship directly by establishing a performance-oriented design and analysis framework without relying on any model information. A consensus error is defined by considering the topology information among the agents to match the consensus objective. Then, a nonlinear data relationship between the consensus-error and control input (NDR-CE&amp;I) is established such that the current consensus error is related to the previous consensus errors and the agent inputs over a moving time window. Next, a linear data relationship of NDR-CE&amp;I, termed as LDR-CE&amp;I, is established by introducing a dynamic linearization method. Subsequently, the novel DirDDC is proposed directly using the LDR-CE&amp;I regardless whether the multi-agent systems (MASs) are nonlinear or linear, affine or non-affine, homogeneous or heterogeneous. The convergence analysis is directly conducted based on the performance function, i.e., the NDR-CE&amp;I, instead of the original MASs, so that the model requirement of the MASs can be completely bypassed. The proposed DirDDC can be applied to the MASs with either fixed or switching communication topologies. The simulation study verifies the results.},
  archive      = {J_ISCI},
  author       = {Ronghu Chi and Na Lin and Biao Huang and Zhongsheng Hou},
  doi          = {10.1016/j.ins.2024.120419},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120419},
  shortjournal = {Inf. Sci.},
  title        = {Performance-oriented design and analysis for direct data-driven control of multi-agent systems},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fast spatial high utility co-location pattern mining
approach based on branch-and-depth-extension. <em>ISCI</em>,
<em>666</em>, 120407. (<a
href="https://doi.org/10.1016/j.ins.2024.120407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining co-location patterns hidden in spatial data is crucial for spatial association discovery, and it has broad prospects in many applications. H igh U tility C o-location P attern M ining (HUCPM) further takes the utility factor of spatial features into consideration, so it is more realistic compared with the traditional co-location pattern mining. However, HUCPM is more difficult, since the Apriori-like pruning technique does not apply. To address this problem, we firstly suggest two novel pruning strategies to trim the pattern search space. Then, a series of optimizing techniques are presented to speed up the pattern utility ratio calculation of each candidate. Based on above techniques, a fast HUCPM algorithm is proposed, which searches for high utility co-locations involved in each pattern branch via a depth-extending manner and equips with a heuristic strategy to enhance the effect of pruning techniques. Moreover, we theoretically prove the completeness and correctness of the proposed algorithm, and discuss its algorithmic complexity. On multiple spatial datasets, we conduct substantial experiments to reveal the superiority of our algorithm in efficiency and scalability, as well as the effectiveness of the proposed technique. Particularly, the proposed algorithm in this paper runs faster than other baselines for several times to several orders of magnitude.},
  archive      = {J_ISCI},
  author       = {Peizhong Yang and Lizhen Wang and Lihua Zhou and Hongmei Chen},
  doi          = {10.1016/j.ins.2024.120407},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120407},
  shortjournal = {Inf. Sci.},
  title        = {A fast spatial high utility co-location pattern mining approach based on branch-and-depth-extension},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Surrogate-assisted PSO with archive-based neighborhood
search for medium-dimensional expensive multi-objective problems.
<em>ISCI</em>, <em>666</em>, 120405. (<a
href="https://doi.org/10.1016/j.ins.2024.120405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thousands of real function evaluations are not burdensome when a surrogate-assisted evolutionary algorithm (SAEA) is used to solve expensive multi-objective optimization problems (MOPs). To reduce the computational overhead, this paper studies a surrogate-assisted multi-objective particle swarm optimization algorithm, named SaMOPSO_NS, in which an external archive-based neighborhood search, as a local search, and a pbest -dominance-based infill criterion are newly developed. The local search works hard to refine exploitation around the current non-dominated individuals once the trigger mechanism is activated, while the pbest -dominance-based infill criterion chooses non-dominated individuals predicted by an ensemble surrogate for actual evaluations. With the collaborative efforts between the local search strategy and the infill criterion, computing resources are more efficiently allocated. Three types of benchmark test instances with different dimensions as well as an engineering expensive MOP are used to examine the proposed algorithm. Experimental results demonstrate that the proposed algorithm significantly outperforms its rivals with fewer real evaluations on most medium-dimensional MOPs. Moreover, the optimized electromagnetic acoustic transducers achieved an amplitude and amplitude ratio of 9.666E-07 mm and 0.1328 respectively, markedly outpacing previously reported results.},
  archive      = {J_ISCI},
  author       = {Mingyuan Yu and Zhou Wu and Jing Liang and Caitong Yue},
  doi          = {10.1016/j.ins.2024.120405},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120405},
  shortjournal = {Inf. Sci.},
  title        = {Surrogate-assisted PSO with archive-based neighborhood search for medium-dimensional expensive multi-objective problems},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel intuitionistic fuzzy best-worst method for group
decision making with intuitionistic fuzzy preference relations.
<em>ISCI</em>, <em>666</em>, 120404. (<a
href="https://doi.org/10.1016/j.ins.2024.120404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new intuitionistic fuzzy best-worst method (IFBWM) for group decision making (GDM) with intuitionistic fuzzy (IF) preference relations (IFPRs). IF values (IFVs) are used to express reference comparisons of criteria. Based on the additive consistency of IFPRs, this paper proposes the definition of additive consistency of IF reference comparisons (IFRCs). Based on the deviation minimization, a linear goal programming model is established to calculate the optimal IF priority weights. By the additive consistency, the consistency index in the closed form is computed by the score function of IFVs. A new approach is devised to enhance the additive consistency of IFRCs. Thus, an IFBWM with the additive consistency of IFRCs is proposed. For GDM with IFPRs, the best criterion and the worst criterion are identified for each decision maker by constructing the score matrix of the IFPR. The individual ranking order of the criteria is obtained by using the proposed IFBWM. Then, the collective ranking order of the criteria is obtained via building a 0–1 integer programming model. Therefore, a GDM method based on the developed IFBWM with IFPRs is proposed. Four examples are analyzed to demonstrate the effectiveness and the advantages of the proposed IFBWM for GDM.},
  archive      = {J_ISCI},
  author       = {Shu-Ping Wan and Jiu-Ying Dong and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2024.120404},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120404},
  shortjournal = {Inf. Sci.},
  title        = {A novel intuitionistic fuzzy best-worst method for group decision making with intuitionistic fuzzy preference relations},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design and comprehensive analysis of improved
proportional-integral-retarded protocol for second-order multi-agent
systems. <em>ISCI</em>, <em>666</em>, 120396. (<a
href="https://doi.org/10.1016/j.ins.2024.120396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The attractive characteristics of an innovative delay-based controller called Proportional-Integral-Retarded (PIR) controller are reported in many fields. However, a detailed investigation of the merits of the PIR controller for multi-agent systems (MASs) is still missing. To bridge this gap, we propose an improved PIR protocol for a general class of second-order MASs. This protocol, using multiple intentional delays and heterogeneous gains as tunable parameters, realizes the optimal spectrum assignment of each subsystem in a completely independent way without affecting the stability of other subsystems. We then present a systematic and flexible parameter tuning strategy for the PIR protocol such that the desired exponential decay rate of the consensus system can be achieved. Specifically, this strategy achieves an arbitrary dominant root assignment in the domain of non-negative real numbers and enables enhanced control flexibility by adjusting an additionally introduced free variable in the analytical parameter formulae. To unveil the superiority of our proposed PIR protocol, we develop a comprehensive comparison of the PIR protocol with the Proportional-Integral-Derivative (PID) scheme and the Proportional-Retarded (PR) protocol. The numerical simulations show that our PIR protocol outperforms the PID scheme regarding the noise attenuation property. Besides, this protocol can attain faster consensus, stronger robustness against parameter uncertainties, and superior disturbance resistance than the PR protocol. Our paper provides a valuable reference for the design of an effective and implementable multi-agent consensus protocol.},
  archive      = {J_ISCI},
  author       = {Xujie Zhang and Qingbin Gao and Jiazhi Cai and Wenfu Xu},
  doi          = {10.1016/j.ins.2024.120396},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120396},
  shortjournal = {Inf. Sci.},
  title        = {Design and comprehensive analysis of improved proportional-integral-retarded protocol for second-order multi-agent systems},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lightweight privacy-preserving authentication mechanism in
5G-enabled industrial cyber physical systems. <em>ISCI</em>,
<em>666</em>, 120391. (<a
href="https://doi.org/10.1016/j.ins.2024.120391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the deep integration of informatization and industrialization, cyber-physical system (CPS), which integrates computing, communication and control technologies, comes into being and has been widely used in industrial applications. A large number of information physical system devices and control systems are based on open internet connections, and security and privacy protection issues are gradually emerging, especially in the process of dynamic and difficult to control information physical system stream data transmission and storage, which will face new security threats. To alleviate these issues, user authentication mechanisms can prevent unauthorized access by adversaries in the CPS environment. For this purpose, we put forth a lightweight privacy-preserving authentication scheme for 5G-enabled ecosystems. This method utilizes edge devices to save online transaction data in network and securely transmits IoT devices data from the sensors to the edge gateway. Then, the edge gateway delivers and stores these data in the cloud. A detailed comparative study based on experimental results indicates that our proposal achieves a better balance between security and functionality features, communication and capitulation costs compared to other existing competitive solutions.},
  archive      = {J_ISCI},
  author       = {Xinyin Xiang and Jin Cao and Weiguo Fan},
  doi          = {10.1016/j.ins.2024.120391},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120391},
  shortjournal = {Inf. Sci.},
  title        = {Lightweight privacy-preserving authentication mechanism in 5G-enabled industrial cyber physical systems},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Asynchronous h∞ control for IT2 fuzzy networked system
subject to hybrid attacks via improved event-triggered scheme.
<em>ISCI</em>, <em>666</em>, 120390. (<a
href="https://doi.org/10.1016/j.ins.2024.120390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This investigation focuses on the asynchronous H ∞ H∞ control of interval type-2 (IT2) fuzzy networked systems under hybrid attacks employing a novel, improved event-triggered scheme. An IT2 fuzzy model is proposed to represent the nonlinear system with external disturbances and parametric uncertainties. A new hybrid attack involving two popular attacks-denial-of-service (DoS) attacks and deception attacks is taken into account simultaneously in communication networks. In order to satisfy the Bernoulli distribution, a hybrid attack was developed as a stochastic random variable. To improve communication, a novel event-triggered scheme is used, which significantly reduces the amount of network data transmission and protects communication resources in the presence of hybrid attacks. In addition, sufficient conditions are derived to ensure that the closed-loop system achieves the specified H ∞ H∞ performance using the Lyapunov stability theory and linear matrix inequality technique. To demonstrate the proposed control technique, an application example of the mass-spring-damper mechanical system is presented.},
  archive      = {J_ISCI},
  author       = {Mourad Kchaou and M. Mubeen Tajudeen and M. Syed Ali and Grienggrai Rajchakit and G. Shanthi and Jinde Cao},
  doi          = {10.1016/j.ins.2024.120390},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120390},
  shortjournal = {Inf. Sci.},
  title        = {Asynchronous h∞ control for IT2 fuzzy networked system subject to hybrid attacks via improved event-triggered scheme},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalisation of a synchronous solution of the parity
problem on cyclic configurations over a non-circulant graph.
<em>ISCI</em>, <em>666</em>, 120387. (<a
href="https://doi.org/10.1016/j.ins.2024.120387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The parity problem is a classical binary benchmark for addressing the computational ability and limitations of automata networks. It refers to conceiving a local rule to allow deciding whether the number of 1-states in the nodes of an arbitrary network is an odd or even number, without global access to the nodes. In its standard formulation, the automata network has an odd number of nodes whose states, arranged as a cyclic configuration, should converge to a fixed point of all 0s, if the initial configuration has an even number of 1s, or to a fixed point of all 1s, otherwise. It has been shown that a local rule alone is able to solve the problem in this formulation, including a synchronous solution we have recently shown, totally based on the local parity rule of the cellular automata elementary space (number 150), with a certain pattern of connection between the nodes. Here, we generalise this solution, showing how to construct many others, combining rule 150 with rules 170 and 240, which are the local shifts of the same space, in such a way that the original solution is just one among countless possibilities. Such solutions may have different convergence times for specific configurations, but are equivalent in the context of all configurations of a given size; also, various solutions form symmetric pairs, in terms of the actual rules they used. The solutions were evaluated computationally and presented here without their formal proofs, but empirical evidences strongly suggest that they can be obtained by the same kind of technique we used in the solution exclusively with rule 150.},
  archive      = {J_ISCI},
  author       = {Fernando Faria and Eurico Ruivo and Pedro Paulo Balbi},
  doi          = {10.1016/j.ins.2024.120387},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120387},
  shortjournal = {Inf. Sci.},
  title        = {Generalisation of a synchronous solution of the parity problem on cyclic configurations over a non-circulant graph},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SVD enclosure of a class of interval matrices.
<em>ISCI</em>, <em>666</em>, 120386. (<a
href="https://doi.org/10.1016/j.ins.2024.120386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops the concept of the singular value decomposition (SVD) of a class of interval matrices. The methodology relies on tighter outer estimations of eigenvalues and their corresponding eigenvectors of an interval matrix. The interval enclosure of every eigenvalue of an interval matrix is determined using an iterative procedure, and an algorithm is proposed for determining the corresponding eigenvector enclosure. Using these concepts, the SVD enclosure of an interval matrix is obtained. Numerical examples are provided to demonstrate the principles of the proposed methodologies at different stages.},
  archive      = {J_ISCI},
  author       = {Sarishti Singh and Geetanjali Panda},
  doi          = {10.1016/j.ins.2024.120386},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120386},
  shortjournal = {Inf. Sci.},
  title        = {SVD enclosure of a class of interval matrices},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A regionally coordinated allocation strategy for medical
resources based on multidimensional uncertain information.
<em>ISCI</em>, <em>666</em>, 120384. (<a
href="https://doi.org/10.1016/j.ins.2024.120384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the face of an emergency, regionally coordinated allocation is an important prerequisite for maintaining the normal order of production and living. Considering the complexity and uncertainty of the emergencies in local governments, this paper establishes a two-stage process for allocating medical resources. In the first stage, cooperative regions with incomplete weights and multidimensional uncertain information ranked via a novel decision-making method. The second stage is an optimal strategy which the optimization model is established to minimize the cost incurred by the local government considering two components of cost. The first stage is the reserve cost for the local government to prepare a certain amount of flexible procurement materials to respond to a public health emergency. The second is the scheduling cost when cooperative regions support medical resources. Theoretically, the optimal allocation of the reserve of different kinds of medical resources is deduced at the lowest cost. Through numerical simulation and sensitivity analysis, we explore the impacts of attribute weights, resource reserve capacity, unit costs, and the number of cooperative regions on the demand for different kinds of medical resources and the total costs incurred by local governments. This study provides a regional coordinated allocation framework and theoretical reference for government departments responding to the emergencies.},
  archive      = {J_ISCI},
  author       = {Xinxin Wang and Yangyi Li and Ke Yang and Zeshui Xu and Jian Zhang},
  doi          = {10.1016/j.ins.2024.120384},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120384},
  shortjournal = {Inf. Sci.},
  title        = {A regionally coordinated allocation strategy for medical resources based on multidimensional uncertain information},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Anchor-based scalable multi-view subspace clustering.
<em>ISCI</em>, <em>666</em>, 120374. (<a
href="https://doi.org/10.1016/j.ins.2024.120374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering is a major topic in pattern recognition and machine learning. Common multi-view clustering algorithms construct similarity graphs from original samples and use them to perform spectral clustering. The time complexity of the singular value decomposition process in graph construction and spectral clustering is high, leading to high computational and memory costs. In addition, subsequent K -means clustering is sensitive to the initial points, yielding unstable clustering results. To address these issues, this study proposes a novel approach to reduce time overhead and memory space from two perspectives. First, a new anchor selection method is proposed to reduce the dimension of the original data by lowering the cost. Second, the self-representation matrix of multi-views is fused into a consistent graph matrix using the post-fusion technique, and the fused graph is directly processed in postprocessing. Furthermore, the proposed method directly obtains clustering results based on the connectivity of the fusion graph, eliminating the need for K -means postprocessing, which avoids the issue of unstable clustering results. Experimental results on artificial and real multi-view datasets indicate that the proposed algorithm is superior to existing algorithms.},
  archive      = {J_ISCI},
  author       = {Shibing Zhou and Mingrui Yang and Xi Wang and Wei Song},
  doi          = {10.1016/j.ins.2024.120374},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120374},
  shortjournal = {Inf. Sci.},
  title        = {Anchor-based scalable multi-view subspace clustering},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Off-policy RL algorithms can be sample-efficient for
continuous control via sample multiple reuse. <em>ISCI</em>,
<em>666</em>, 120371. (<a
href="https://doi.org/10.1016/j.ins.2024.120371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sample efficiency is one of the most critical issues for online reinforcement learning (RL). Existing methods achieve higher sample efficiency by adopting model-based methods, Q-ensemble, or better exploration mechanisms. We, instead, propose to train an off-policy RL agent via updating on a fixed sampled batch multiple times, thus reusing these samples and better exploiting them within a single optimization loop. We name our method sample multiple reuse (SMR). We theoretically show the properties of Q-learning with SMR, e.g., convergence. Furthermore, we incorporate SMR with off-the-shelf off-policy RL algorithms and conduct experiments on a variety of continuous control benchmarks. Empirical results show that SMR significantly boosts the sample efficiency of the base methods across most of the evaluated tasks without any hyperparameter tuning or additional tricks.},
  archive      = {J_ISCI},
  author       = {Jiafei Lyu and Le Wan and Xiu Li and Zongqing Lu},
  doi          = {10.1016/j.ins.2024.120371},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120371},
  shortjournal = {Inf. Sci.},
  title        = {Off-policy RL algorithms can be sample-efficient for continuous control via sample multiple reuse},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An extension framework for creating operators and functions
for intuitionistic fuzzy sets. <em>ISCI</em>, <em>666</em>, 120336. (<a
href="https://doi.org/10.1016/j.ins.2024.120336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy sets, introduced by Atanassov in the mid-1980′s, represent a key extension of Zadeh&#39;s fuzzy sets. Zadeh&#39;s extension principle, a fundamental concept in fuzzy set theory, has been utilized to extend functions from the classical mathematics setting to the fuzzy setting. In this article, we propose an extension framework for intuitionistic fuzzy sets. The proposed approach offers several advantages: (i) Since an intuitionistic fuzzy function so-obtained is constructed from a bottom-up concrete manner, the behavior of the function, when applied to intuitionistic fuzzy sets, can be readily understood in terms of the behavior of its fuzzy counterpart. (ii) Certain mathematical properties fulfilled by the fuzzy counterpart in the fuzzy setting can often be translated into a corresponding statement that the analogous properties in the intuitionistic fuzzy setting are also fulfilled by the intuitionistic fuzzy function. (iii) The application of the extension framework to construct the intuitionistic fuzzy intersection and union operators has led us to the discovery of a natural spectrum of intuitionistic fuzzy intersection and union operators that have not been postulated in the literature before. Due to these advantages, the extension framework has the potential to facilitate greatly the theoretical and application developments of intuitionistic fuzzy sets.},
  archive      = {J_ISCI},
  author       = {Shing-Chung Ngan},
  doi          = {10.1016/j.ins.2024.120336},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120336},
  shortjournal = {Inf. Sci.},
  title        = {An extension framework for creating operators and functions for intuitionistic fuzzy sets},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust stabilization for networked systems with transmission
delay via integral lyapunov functional and congruence transformation
method. <em>ISCI</em>, <em>666</em>, 120190. (<a
href="https://doi.org/10.1016/j.ins.2024.120190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainties and information transmission delay exist in many real-world applications. The control design of such systems is challenging even for existing advanced control theory. Besides, if there is actuator saturation in the system and networked control strategy is considered, the problem will become even more complicated. In order to solve the problem, the stochastic Takagi-Sugeno (T-S) fuzzy delay-dependent static output feedback control is proposed in this paper, and strictly dissipative analysis is addressed for the stochastic T-S fuzzy singular information networked control systems. In the propose control scheme, the T-S fuzzy model and stochastic Bernoulli theory are employed in the controller design. The stability conditions of the closed-loop control system are summarized in the linear matrix inequalities (LMIs), then the closed-loop system is regular impulse free, stochastically admissible and strictly dissipative. Both fuzzy-basis-dependent and delay-dependent stability analysis, with the consideration of strictly dissipative performance index, are conducted to develop stability conditions in terms of LMIs based on Lyapunov stability theory. Via the LMIs optimization constraints, the nonconvex problem caused by fuzzy-basis-dependent can be solved. Finally, the simulation examples are provided to verify the effectiveness of the proposed control strategy.},
  archive      = {J_ISCI},
  author       = {Wei Zheng and Zhiming Zhang and Hak Keung Lam and Fuchun Sun and Shuhuan Wen},
  doi          = {10.1016/j.ins.2024.120190},
  journal      = {Information Sciences},
  month        = {5},
  pages        = {120190},
  shortjournal = {Inf. Sci.},
  title        = {Robust stabilization for networked systems with transmission delay via integral lyapunov functional and congruence transformation method},
  volume       = {666},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A spherical evolution algorithm with two-stage search for
global optimization and real-world problems. <em>ISCI</em>,
<em>665</em>, 120424. (<a
href="https://doi.org/10.1016/j.ins.2024.120424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a spherical evolution algorithm with two-stage search. Spherical search and hypercube search are combined to achieve individuals&#39; evolution. A self-adaptive Gaussian scale factor and a variable scale factor are designed to adaptively control individuals&#39; spherical and hypercube search area according to their search situations. Two search stages frequently switch with four search cases to enhance the balance between exploration and exploitation processes. A directed adjacency matrix is devised to analyze the relationship among individuals from the perspective of graph theory. Experiments compare the proposed algorithm with five algorithms with distinctive search patterns on twenty nine CEC2017 benchmark functions. The diversity analysis and graph theory analysis show the good population diversity and effective information spreading of the proposed algorithm. Twenty two real-world problems evaluate the practicality and optimization ability of the proposed algorithm. Finally, the computational time complexity demonstrates that the proposed algorithm is more efficient than the original spherical evolution algorithm.},
  archive      = {J_ISCI},
  author       = {Yirui Wang and Zonghui Cai and Lijun Guo and Guoqing Li and Yang Yu and Shangce Gao},
  doi          = {10.1016/j.ins.2024.120424},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120424},
  shortjournal = {Inf. Sci.},
  title        = {A spherical evolution algorithm with two-stage search for global optimization and real-world problems},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mining frequent temporal duration-based patterns on time
interval sequential database. <em>ISCI</em>, <em>665</em>, 120421. (<a
href="https://doi.org/10.1016/j.ins.2024.120421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential databases have wide applications, such as market basket analysis, medical prediction, and sign language recognition. Most prior research is based on pointed-based sequential databases, which assume each item/event occurs instantaneously. However, in many real-world scenarios, events persist over intervals of varying durations, such as varying time intervals of a symptom or a gesture of sign language. Assigning the same weight to different times of events and neglecting the duration of events can hinder the recognition of interesting patterns, such as concurrent symptoms preceding a disease. To address these issues, this paper integrates duration with temporal patterns in interval-based sequential databases, introduces the concept of temporal duration-based patterns (TDPs), and designs two algorithms called FTDPMiner-EP (Frequent TDPMiner based on endpoint representation) and FTDPMiner-TM (Frequent TDPMiner based on triangular matrix representation) by using different extension methods to mine frequent TDPs. Due to the complex relationships between events, temporal pattern mining is more challenging than sequential pattern mining. Strategies are used in this paper to accelerate the algorithms&#39; search process. Experiments are conducted on both real and synthetic databases, which show good performance of the two algorithms.},
  archive      = {J_ISCI},
  author       = {Fuyin Lai and Guoting Chen and Wensheng Gan and Mengfeng Sun},
  doi          = {10.1016/j.ins.2024.120421},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120421},
  shortjournal = {Inf. Sci.},
  title        = {Mining frequent temporal duration-based patterns on time interval sequential database},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A framework for constrained large-scale multi-objective
white-box problems based on two-scale optimization through decision
transfer. <em>ISCI</em>, <em>665</em>, 120411. (<a
href="https://doi.org/10.1016/j.ins.2024.120411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing constrained multi-objective evolutionary algorithms (CMOEAs) are not so efficient when handling constrained large-scale multi-objective problems (CLSMOPs). To overcome white-box CLSMOPs with definitive objective functions, a two-scale optimization framework based on decision transfer, which integrates dimensionality reduction of large-scale decision variables and constraint handling technology, is proposed. The Lagrange multiplier is first used to construct the two-scale optimization model, which bridges original large-scale decision space of variables and small-scale (2-scale) decision space of objective-constraint parameter. The decision transfer algorithm is then designed to switch between large-scale original decision space and small-scale parametric decision space, while achieving the maximum dimensionality reduction. Finally, the two-scale evolution strategy is proposed for the alternative optimizations in the two decision spaces, which emphasize objectives and constraints, respectively. In summary, the optimization in the large-scale space pushes the population to unconstrained Pareto front (PF), the optimization in the small-scale space helps the population cross the infeasible areas to approach constrained PF, and the offspring generation by Lagrange multiplier is beneficial to both objectives and constraints. Eight representative and state-of-the-art CMOEAs have been embedded into the CLDTEA framework to demonstrate its effectiveness through comparative experiments on CLSMOPs with equality and inequality constraints and 1000 decision variables. Experimental results show that CLDTEA can significantly improve the performance of these basic CMOEAs.},
  archive      = {J_ISCI},
  author       = {Qingzhu Wang and Tianyang Li and Fanqi Meng and Bin Li},
  doi          = {10.1016/j.ins.2024.120411},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120411},
  shortjournal = {Inf. Sci.},
  title        = {A framework for constrained large-scale multi-objective white-box problems based on two-scale optimization through decision transfer},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Oversampling method via adaptive double weights and gaussian
kernel function for the transformation of unbalanced data in risk
assessment of cardiovascular disease. <em>ISCI</em>, <em>665</em>,
120410. (<a href="https://doi.org/10.1016/j.ins.2024.120410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In risk assessment of cardiovascular disease (CVD), the classification error caused by unbalanced data is a significant challenge, which has sparked widespread concern and research upsurge in the field of data mining. Therefore, in view of the imbalance of CVD data sets, an oversampling method via adaptive double weights and Gaussian kernel function (ADWGKFO) is proposed, which converts the unbalanced data sets into balanced data sets. Firstly, clustering algorithm is utilized to cluster minority samples, boundary samples are identified by Borderline-Synthetic Minority Over-sampling Technique (Borderline-SMOTE), K nearest neighbor and support vector machine algorithms, and the number of samples synthesized in each group is calculated based on the double weights of boundary points and majority distribution. Secondly, in order to clearly define the classification boundary, the mutual class potential of new samples in each cluster is calculated by Gaussian kernel function, and new samples are filtered according to the mutual class potential until the data set is balanced. Finally, taking the data sets from Kaggle platform as the research samples, the proposed method is empirically analyzed. In order to validate the efficacy and universality of the proposed method, this paper selects CatBoost that is a new integrated algorithm to test the effect of the ADWGKFO method, and compares it with different sampling methods and different classifiers using performance evaluation indexes such as accuracy, F1-score and area under the curve (AUC). Compared with the combinations of other methods, the accuracy, F1-score and AUC are significantly improved. It is concluded that the ADWGKFO method described in this paper can successfully improve the data quality, and increases the reliability of CVD risk assessment.},
  archive      = {J_ISCI},
  author       = {Congjun Rao and Xi Wei and Xinping Xiao and Yu Shi and Mark Goh},
  doi          = {10.1016/j.ins.2024.120410},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120410},
  shortjournal = {Inf. Sci.},
  title        = {Oversampling method via adaptive double weights and gaussian kernel function for the transformation of unbalanced data in risk assessment of cardiovascular disease},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving adversarial transferability through frequency
enhanced momentum. <em>ISCI</em>, <em>665</em>, 120409. (<a
href="https://doi.org/10.1016/j.ins.2024.120409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of adversarial examples seriously affects the practical security deployment of convolutional neural networks. The existing attack algorithms perform brilliantly under white-box scenarios, but they show weak transferability when faced with unknown black-box models. Recent studies have revealed that models have different interests in different frequency components of images, and the low-frequency characteristics play a non-negligible role in the decision-making of models. In this article, we present the frequency enhanced momentum iterative attack, called FE-MI-FGSM. Specifically, we use multiple convolution kernels for Gaussian filtering of the image before each gradient update to push the processed image closer to the common decision boundaries of multiple models. Then, the average gradient of the white-box model to these processed images is obtained and used as the perturbation direction to generate adversarial examples with a high success rate of white-box attack and high transferability. The empirical results show that compared with the current mainstream gradient-based methods, our method performs better on both normally trained and adversarially trained models. Besides, our method can combine with gradient-based methods which integrate convergence algorithms or input transformations for the sake of reaching satisfactory improvement of the transferability.},
  archive      = {J_ISCI},
  author       = {Changfei Zhao and Xinyang Deng and Wen Jiang},
  doi          = {10.1016/j.ins.2024.120409},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120409},
  shortjournal = {Inf. Sci.},
  title        = {Improving adversarial transferability through frequency enhanced momentum},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive fuzzy-evidential classification based on
association rule mining. <em>ISCI</em>, <em>665</em>, 120408. (<a
href="https://doi.org/10.1016/j.ins.2024.120408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most promising classification approaches, association classification (AC) integrates data classification and association discovery techniques for generating a compact set of classification association rules. Recently, the fuzzy set and evidence theories are successively applied into AC in order to improve the classification performance in terms of accuracy and interpretability. However, from the perspectives of applicability and universality, there still exists two important issues in the current AC framework. On one hand, several key parameters, such as the number of fused rules in classification and the minimum support threshold in association discovery, are difficult to be accurately predefined in practice. On the other hand, the fixed grid-based fuzzy partition is not benefit to adapt for those datasets with large number of features. In this paper, an association rule-based adaptive fuzzy-evidential classification framework (AR-AFEC) is developed for overcoming the above limitations. To do so, an optimal rule fusion strategy and a dynamic minimum support threshold setting scheme are proposed for adaptively learning the parameters during classification and association mining respectively. In addition, an entropy-based trapezoidal fuzzy partition technique is proposed to adaptively obtain the fuzzy sets defined on each continuous feature domain. Experiments on 26 benchmark datasets and a human activity recognition application demonstrate that the proposal can achieve better accuracy than some state-of-the-art rule-based classification approaches, using less rules with more general structure.},
  archive      = {J_ISCI},
  author       = {Xiaojiao Geng and Qingxue Sun and Zhi-Jie Zhou and Lianmeng Jiao and Zongfang Ma},
  doi          = {10.1016/j.ins.2024.120408},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120408},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fuzzy-evidential classification based on association rule mining},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel joint neural collaborative filtering incorporating
rating reliability. <em>ISCI</em>, <em>665</em>, 120406. (<a
href="https://doi.org/10.1016/j.ins.2024.120406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based recommendations have demonstrated impressive performance in improving recommendation accuracy. However, such approaches mainly utilize implicit feedback to predict user preferences and neglect the adverse impact of explicit preference noise, which affects the robustness and reliability of model training. To consider the reliability of both rating input and output, we propose a novel joint deep neural recommendation framework that incorporates rating reliability derived solely from ratings to provide reliable recommendations for active users. Firstly, we introduce a noise detection method based on intuitionistic fuzzy sets to identify incorrect ratings from the perspective of fuzzy preferences and label them to generate a binary rating reliability matrix. Subsequently, we propose a joint deep neural framework that integrates rating reliability to simultaneously capture the high-order features of users and items, yielding predictions with their corresponding reliability probabilities. Finally, to achieve a balance between accuracy and reliability for recommendations, we design a reliability threshold selection strategy based on K-means clustering to find an appropriate threshold. Experimental results on three widely used datasets show that our model achieves an average improvement of 9.4% and 8.0% in the metrics Recall and NDCG, respectively, compared with the closest competitor. This paper provides new insights for integrating rating reliability into a deep neural network to enhance the performance of recommender systems.},
  archive      = {J_ISCI},
  author       = {Jiangzhou Deng and Qi Wu and Songli Wang and Jianmei Ye and Pengcheng Wang and Maokang Du},
  doi          = {10.1016/j.ins.2024.120406},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120406},
  shortjournal = {Inf. Sci.},
  title        = {A novel joint neural collaborative filtering incorporating rating reliability},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Granular structure evaluation and selection based on
justifiable granularity principle. <em>ISCI</em>, <em>665</em>, 120403.
(<a href="https://doi.org/10.1016/j.ins.2024.120403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Granular structures are fundamental components of human granulation intelligence and different views or scales of granulation result in different granular structures. Therefore, the evaluation and selection of optimal granular structures can lay the foundation for problem-solving. Information granules are basic components of granular structures. The principle of justifiable granularity presents a coherent method for designing information granules. Therefore, this study performs granular structure evaluation and selection based on the justifiable granularity principle. First, it proposes a new evaluation criterion for granular structures that considers the coverage and specificity of all information granules in a granular structure. Thereafter, coverage and specificity are evaluated based on a core sample of the information granule. Subsequently, a detailed formulation is provided to compute the significance of the granular structure according to the proposed evaluation criterion. Finally, a general framework for granular structure selection is presented, and a detailed algorithm for selecting the optimal granular structure with the aid of the justifiable granularity principle is provided. The proposed method is employed to determine the optimal attribute and select the optimal neighborhood size for neighborhood classifiers. Experiments and analyses have demonstrated the necessity, reasonableness, and effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Lei-Jun Li and Mei-Zheng Li and Ju-Sheng Mi},
  doi          = {10.1016/j.ins.2024.120403},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120403},
  shortjournal = {Inf. Sci.},
  title        = {Granular structure evaluation and selection based on justifiable granularity principle},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving adversarial robustness using knowledge
distillation guided by attention information bottleneck. <em>ISCI</em>,
<em>665</em>, 120401. (<a
href="https://doi.org/10.1016/j.ins.2024.120401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have recently been found to be vulnerable to adversarial examples, which raises concerns about their reliability and poses potential security threats. Adversarial training has been extensively studied to counter adversarial attacks. However, the limited attack types incorporated during the training phase will restrict the defense performance of models against unknown attacks and impact their standard accuracies. Furthermore, we discover that adversarial training models tend to overfit redundant noisy features, which hinders their generalization. To alleviate these issues, this paper proposes the attention information bottleneck-guided knowledge distillation (AIB-KD) method to enhance models&#39; adversarial robustness. We integrate adversarial training with attention information bottleneck as the defense framework to achieve an optimal trade-off between information compression and classification performance. Simultaneously, we specifically employ knowledge distillation to guide the adversarial training models in learning both the standard attention information and valuable deep feature distributions to enhance their defense generalization capability. Experimental results demonstrate that AIB-KD can effectively classify adversarial examples in multiple attack settings. The average white-box and black-box classification accuracies for the WideResNet-28-10 model on the CIFAR-10 dataset are 56.59% and 85.49%, respectively, and the average accuracies on the SVHN dataset are 61.71% and 88.96%. When applied to unknown attack scenarios, AIB-KD is more effective and interpretable than state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Yuxin Gong and Shen Wang and Tingyue Yu and Xunzhi Jiang and Fanghui Sun},
  doi          = {10.1016/j.ins.2024.120401},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120401},
  shortjournal = {Inf. Sci.},
  title        = {Improving adversarial robustness using knowledge distillation guided by attention information bottleneck},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive memory event-triggered observer-based pinning
synchronization control for complex dynamical networks under
asynchronous attacks. <em>ISCI</em>, <em>665</em>, 120399. (<a
href="https://doi.org/10.1016/j.ins.2024.120399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the security synchronization issue of complex dynamical networks under asynchronous cyber and physical attacks within the context of cyber-physical systems. An observer is devised to estimate the system&#39;s state using the measured outputs of partial nodes. The integration of a buffer for storing historical information enhances the accuracy of state estimation under asynchronous attacks, enabling the observer-based control scheme to generate more precise control signals during attacks. The robustness against external disturbances is reinforced by introducing disturbance compensation for both the observer and the controller. Additionally, an adaptive memory event-triggered mechanism is designed to conserve network resources. Then, a sufficient condition for the synchronization of complex dynamical networks against asynchronous attacks is obtained, and the gains of the observer and controller are computed based on the linear matrix inequality technique. Finally, a simulated example demonstrates the effectiveness of the suggested strategy.},
  archive      = {J_ISCI},
  author       = {Li Shu and Shengyuan Xu},
  doi          = {10.1016/j.ins.2024.120399},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120399},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive memory event-triggered observer-based pinning synchronization control for complex dynamical networks under asynchronous attacks},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic multiobjective optimization with varying number of
objectives assisted by dynamic principal component analysis.
<em>ISCI</em>, <em>665</em>, 120398. (<a
href="https://doi.org/10.1016/j.ins.2024.120398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multi-objective optimization problems, which are equipped with the increment or decrement number of time-varying objective functions, have been hardly researched in recent decades. Different from other dynamism handling approaches, we propose a new framework incorporated with the dynamic principal component analysis technique, which embeds the acquired knowledge of Pareto optimal set during the evolutionary search process. As the environmental changes occur, the dynamic principal component analysis technique learns the global structure of Pareto optimal set incrementally as newly generated data are collected to depict the manifold contour. In addition, this method constructs high-quality solutions on the basis of obtained knowledge, which in turn captures the main structure of previous solutions. We undertake comprehensive experiments in which the benchmark instances are given with a varying number of objective functions and the computational values are assessed with respect to performance metrics. The obtained statistical findings with 70% improvement fully demonstrate that our proposed algorithm is efficient and effective for solving dynamic multi-objective optimization problems.},
  archive      = {J_ISCI},
  author       = {Fei Zou and Gary G. Yen},
  doi          = {10.1016/j.ins.2024.120398},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120398},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic multiobjective optimization with varying number of objectives assisted by dynamic principal component analysis},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Fuzzy control of singular fractional order multi-agent
systems with actuator saturation. <em>ISCI</em>, <em>665</em>, 120397.
(<a href="https://doi.org/10.1016/j.ins.2024.120397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a T-S fuzzy model is established to describe nonlinear fuzzy singular fractional order multi-agent systems (SFOMASs) exhibiting actuator saturation when the order is between 0 and 2. We focus on the case where the system state is difficult to measure or cannot be directly measured, so it needs to be estimated based on other measurable signals. To this end, a fuzzy observer is designed, which can process fuzzy or imprecise input and output signals through fuzzy processing. Then the observer-based leader-following consensus problem of fuzzy SFOMASs with actuator saturation is addressed. To address input saturation, we use some mathematical tools to represent the saturated linear feedback on the convex hull, which is then transformed into seeking the optimal solution of linear matrix inequalities (LMIs). Finally, the effectiveness of the proposed approach is verified through the adoption of a numerical example.},
  archive      = {J_ISCI},
  author       = {Yuying Wang and Jin-Xi Zhang and Xuefeng Zhang},
  doi          = {10.1016/j.ins.2024.120397},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120397},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy control of singular fractional order multi-agent systems with actuator saturation},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive robust control for fuzzy underactuated mechanical
systems: A stackelberg game-theoretic optimization approach.
<em>ISCI</em>, <em>665</em>, 120394. (<a
href="https://doi.org/10.1016/j.ins.2024.120394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a Stackelberg game-theoretic optimization approach for adaptive robust controller design of fuzzy underactuated mechanical systems (UMSs). As a commonly encountered challenge, several factors render it difficult to further improve the control performance of these UMSs, such as the coupling effects and nonlinearities resulting from the underactuated structure. Meanwhile, various sources of unexpected time-varying uncertainties can further add to the difficulty in the controller design procedure pipeline. To overcome the above-mentioned issues and further enhance the system performance, a dual-parameter optimization framework is presented here for adaptive robust controller design, leveraging fuzzy set theory and Stackelberg game. In this development, the time-varying uncertainty is characterized via suitable membership functions; and thus the appropriate fuzzy UMS is established. Then, an adaptive robust controller with a leakage-type adaptation law is presented to tackle the uncertainty appropriately. To further improve the system performance considering the trade-off among the transient performance; the steady-state performance; and the control cost; a Stackelberg game-based dual-parameter optimization method is proposed to determine the Stackelberg strategy. It is rigorously proved in the developments here that the proposed controller design and parameters optimization method guarantees the desired deterministic system performance, i.e., uniform boundedness (UB) and uniform ultimate boundedness (UUB). Moreover, a series of numerical simulations based on a flywheel inverted pendulum (FIP) are performed, which illustrate the effectiveness and superiority of the proposed method.},
  archive      = {J_ISCI},
  author       = {Yuanjie Xian and Jun Ma and Kang Huang and Xiaolong Chen and Wenxin Wang and Abdullah Al Mamun and Tong Heng Lee},
  doi          = {10.1016/j.ins.2024.120394},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120394},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive robust control for fuzzy underactuated mechanical systems: A stackelberg game-theoretic optimization approach},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wearable-based behaviour interpolation for semi-supervised
human activity recognition. <em>ISCI</em>, <em>665</em>, 120393. (<a
href="https://doi.org/10.1016/j.ins.2024.120393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While traditional feature engineering for Human Activity Recognition (HAR) involves a trial-and-error process, deep learning has emerged as a preferred method for high-level representations of sensor-based human activities. However, most deep learning-based HAR requires a large amount of labelled data and extracting HAR features from unlabelled data for effective deep learning training remains challenging. We, therefore, introduce a deep semi-supervised HAR approach, MixHAR, which concurrently uses labelled and unlabelled activities. Our MixHAR employs a linear interpolation mechanism to blend labelled and unlabelled activities while addressing both inter- and intra-activity variability. A unique challenge identified is the activity-intrusion problem during mixing, for which we propose a mixing calibration mechanism to mitigate it in the feature embedding space. Additionally, we rigorously explored and evaluated the five conventional/popular deep semi-supervised technologies on HAR, acting as the benchmark of deep semi-supervised HAR. Our results demonstrate that MixHAR significantly improves performance, underscoring the potential of deep semi-supervised techniques in HAR.},
  archive      = {J_ISCI},
  author       = {Haoran Duan and Shidong Wang and Varun Ojha and Shizheng Wang and Yawen Huang and Yang Long and Rajiv Ranjan and Yefeng Zheng},
  doi          = {10.1016/j.ins.2024.120393},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120393},
  shortjournal = {Inf. Sci.},
  title        = {Wearable-based behaviour interpolation for semi-supervised human activity recognition},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MRI-CE: Minimal rare itemset discovery using the
cross-entropy method. <em>ISCI</em>, <em>665</em>, 120392. (<a
href="https://doi.org/10.1016/j.ins.2024.120392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rare itemsets have been studied less extensively than frequent itemsets, but have important potential applications in black swan events, like detecting anomalies. Mining rare itemsets poses two challenges: too many results may be obtained, and the process may incur a high computational overhead. To overcome these two challenges, we can attempt to mine minimal rare itemsets (MRIs) and use heuristic methods to mine approximate results instead of exact results. This paper describes a novel algorithm for mining MRIs using cross-entropy (CE). We present the modeling method for MRI-CE and introduce a progressive checking strategy that enables more MRIs to be discovered in each iteration. The discovered MRIs are then used to update a probability vector. We design two optimization strategies to improve the algorithm&#39;s performance. The adaptive sample size strategy narrows the search space as the number of iterations increases, and the crossover-based individual generation strategy improves the diversity of the samples. To evaluate the performance of MRI-CE, we select six competitive algorithms and conduct extensive experiments on publicly available datasets. The results show that the proposed algorithm is not only efficient, but also highly accurate. Furthermore, we verify the effectiveness of the two optimization strategies experimentally.},
  archive      = {J_ISCI},
  author       = {Wei Song and Zhen Sun and Philippe Fournier-Viger and Youxi Wu},
  doi          = {10.1016/j.ins.2024.120392},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120392},
  shortjournal = {Inf. Sci.},
  title        = {MRI-CE: Minimal rare itemset discovery using the cross-entropy method},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spiking autoencoder for nonlinear industrial process fault
detection. <em>ISCI</em>, <em>665</em>, 120389. (<a
href="https://doi.org/10.1016/j.ins.2024.120389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, artificial neural networks have been found successful applications in process monitoring within metallurgy, chemical engineering and mechanical manufacturing owing to their superior ability to construct flexible models with varying degrees of nonlinearity and effectively handle large-scale data. However, the model&#39;s distinctiveness diminishes due to the high cost associated with neural network training and initializations, resulting in a more fluctuating fault detection performance. To alleviate this problem and inspired by the way biological neurons emit spikes to transmit information, the spiking neurons are employed in the construction of a spiking neural network, introducing a shift in parameter optimization from conventional global parameter tuning to two-stage layer-wise process. Based on this, a brain-like discrete model, spiking auto-encoder (SNNAE) is constructed. The SNNAE&#39;s training process is firstly compared with that of artificial neural networks with the same structure through modeling a numerical example, results show the superior efficiency and accuracy of SNNAE in modeling highly nonlinear data. To gauge its effectiveness in fault detection, SNNAE is then compared with the state-of-art methods through the same numerical example and a three-phase flow process, indicating its ability to significantly improve process monitoring performance in nonlinear processes while notably reducing its fluctuation.},
  archive      = {J_ISCI},
  author       = {Bochun Yue and Kai Wang and Hongqiu Zhu and Xiaofeng Yuan and Chunhua Yang},
  doi          = {10.1016/j.ins.2024.120389},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120389},
  shortjournal = {Inf. Sci.},
  title        = {Spiking autoencoder for nonlinear industrial process fault detection},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-view deep interpretable TSK fuzzy classifier under
mutually teachable classification criterion. <em>ISCI</em>,
<em>665</em>, 120388. (<a
href="https://doi.org/10.1016/j.ins.2024.120388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the existing classification techniques generally requires the consistent distribution assumption between training and testing samples. However, recent results theoretically reveal that enhanced classification performance may be achieved by breaking this assumption and meanwhile managing to satisfy a subtle assumption between a prediction function, training and testing samples. Although such a subtle assumption is too hard to be leveraged as a criterion for designing a single-view classifier, this study as the first attempt exhibits its natural yet distinctive value in designing a two-view classifier. In this study, originating from the inconsistent distribution assumption between training and testing samples, a new mutually teachable classification criterion is proposed, and accordingly a two-view deep interpretable Tagaki-Sugeno-Kang fuzzy classifier called Tvd-TFC is developed. In order to keep both promising classification performance and high interpretability of Tvd-TFC, it simply takes our recent work-- deep Tagaki-Sugeno-Kang fuzzy classifier (D-TSK-FC) as a basic component of each deep sub-classifier for each view. The distinctive novelty of Tvd-TFC exists in that its double deep structures along with two respective views are interchangeably learnt in deep learning manner according to the proposed mutually teachable classification criterion. The proposed learning algorithm can not only minimize the testing error along with each view but also ensure the consistency between two views. Experimental results on two-view datasets demonstrate that the proposed classifier Tvd-TFC realizes enhanced or at least comparable classification performance and simultaneously has better interpretability in contrast to the comparative classifiers.},
  archive      = {J_ISCI},
  author       = {Ta Zhou and Guanjin Wang and Kup Sze Choi and Shitong Wang},
  doi          = {10.1016/j.ins.2024.120388},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120388},
  shortjournal = {Inf. Sci.},
  title        = {A two-view deep interpretable TSK fuzzy classifier under mutually teachable classification criterion},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the granular representation of fuzzy quantifier-based
fuzzy rough sets. <em>ISCI</em>, <em>665</em>, 120385. (<a
href="https://doi.org/10.1016/j.ins.2024.120385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set theory is a well-known mathematical framework that can deal with inconsistent data by providing lower and upper approximations of concepts. A prominent property of these approximations is their granular representation: that is, they can be written as unions of simple sets, called granules. The latter can be identified with “if…, then…” rules, which form the backbone of rough set rule induction. Alternatively, this property of granular representability can be defined as being free from inconsistencies, i.e. there are no elements within the set that are indiscernible to elements outside the set. It has been shown previously that this property can be maintained for various fuzzy rough set models, including those based on ordered weighted average (OWA) operators. In this paper, we will focus on some instances of the general class of fuzzy quantifier-based fuzzy rough sets (FQFRS). In these models, the lower and upper approximations are evaluated using binary and unary fuzzy quantifiers, respectively. One of the main targets of this study is to examine the granular representation of different models of FQFRS. The main findings reveal that Choquet-based fuzzy rough sets can be represented granularly under the same conditions as OWA-based fuzzy rough sets, whereas Sugeno-based FRS can always be represented granularly. Additionally, we provide counterexamples for the granular representability of other FQFRS models, and show that despite this, these approaches still demonstrate effectiveness in mitigating inconsistencies in real-life datasets. This observation highlights the potential of these models for resolving data inconsistencies and managing noise.},
  archive      = {J_ISCI},
  author       = {Adnan Theerens and Chris Cornelis},
  doi          = {10.1016/j.ins.2024.120385},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120385},
  shortjournal = {Inf. Sci.},
  title        = {On the granular representation of fuzzy quantifier-based fuzzy rough sets},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application of spatial uncertainty predictor in CNN-BiLSTM
model using coronary artery disease ECG signals. <em>ISCI</em>,
<em>665</em>, 120383. (<a
href="https://doi.org/10.1016/j.ins.2024.120383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to address the need for reliable diagnosis of coronary artery disease (CAD) using artificial intelligence (AI) models. Despite the progress made in mitigating opacity with explainable AI (XAI) and uncertainty quantification (UQ), understanding the real-world predictive reliability of AI methods remains a challenge. In this study, we propose a novel indicator called the Spatial Uncertainty Estimator (SUE) to assess the prediction reliability of classification networks in practical Electrocardiography (ECG) scenarios. SUE quantifies the spatial overlap of critical Grad-CAM (Gradient-weighted Class Activation Mapping) features, offering a confidence score for predictions. To validate SUE, we designed a deep learning network that integrates Convolutional Neural Network (CNN) and Bidirectional Long Short-Term Memory (BiLSTM) mechanisms for precise ECG signal classification of CAD. This network achieved high accuracy, sensitivity, and specificity rates of 99.6%, 99.8%, and 98.2%, respectively. During test time, SUE accurately distinguishes between correctly classified and misclassified ECG segments, demonstrating the superiority of the proposed network over existing methods. The study highlights the potential of combining XAI and UQ techniques to enhance ECG analysis. The evaluation of spatial overlap among discriminative features provides quantitative insights into the network&#39;s robustness, encompassing both current prediction accuracy and the repeatability of predictions.},
  archive      = {J_ISCI},
  author       = {Silvia Seoni and Filippo Molinari and U. Rajendra Acharya and Oh Shu Lih and Prabal Datta Barua and Salvador García and Massimo Salvi},
  doi          = {10.1016/j.ins.2024.120383},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120383},
  shortjournal = {Inf. Sci.},
  title        = {Application of spatial uncertainty predictor in CNN-BiLSTM model using coronary artery disease ECG signals},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differential evolution with proration-based mutation
strategy and multi-segment mixed parameter setting for numerical
optimization. <em>ISCI</em>, <em>665</em>, 120382. (<a
href="https://doi.org/10.1016/j.ins.2024.120382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new differential evolution (DE) algorithm is presented for solving global optimization problems by guiding the individuals adaptively to explore different decision regions and setting the control parameters properly for individuals. To consolidate algorithm efficiency and preserve population diversity, we first introduce a proration-based mutation strategy. This strategy dynamically selects promising individuals from population as guiders and proportionately allocates the individuals following them based on their fitness values and unsuccessful updates. Besides, we design a multi-segment mixed parameter setting to provide suitable parameters for individuals, considering feedback information from the population, individual requirements, and parameters&#39; interaction. Additionally, we devise an adaptive population maintaining mechanism to refresh the population by replacing individuals with higher unsuccessful updates and removing those with poor fitness values. Unlike previous DE versions, our new algorithm dynamically and appropriately explores promising areas, refines parameter suitability, and accelerates convergence by updating and removing unpromising individuals. This enhances the algorithm search efficiency and achieves a good balance between exploration and exploitation. Finally, we evaluate the proposed algorithm&#39;s performance by comparing it with 17 typical or state-of-the-art algorithms on IEEE CEC2014 and CEC2017 test suites. Experimental results indicate that the proposed algorithm is a more promising optimizer.},
  archive      = {J_ISCI},
  author       = {Xueqing Yan and Mengnan Tian and Yongming Li},
  doi          = {10.1016/j.ins.2024.120382},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120382},
  shortjournal = {Inf. Sci.},
  title        = {Differential evolution with proration-based mutation strategy and multi-segment mixed parameter setting for numerical optimization},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Complete multi-view subspace clustering via auto-weighted
combination of visible and latent views. <em>ISCI</em>, <em>665</em>,
120381. (<a href="https://doi.org/10.1016/j.ins.2024.120381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering aims to leverage the consensus and complementary information embedded within the data and effectively fuse the multiple views. However, existing methods have limitations in fully exploring the complementary information. Tensor-based methods tend to overlook the underlying structures, while latent representation-based methods struggle to capture high-order correlations, both of which are important components of complementary information. In this paper, we introduce a novel method called complete multi-view subspace clustering (CMVSC) using visible and latent views. The latent view with the underlying structures is obtained by the latent representation, along with visible views (i.e., original features) constitute the complete multi-view data. Then, the low-rank tensor constraint is imposed on the complete views to comprehensively explore the consensus and complementary information. Besides, to effectively combine the advantages of visible and latent views, we devise an auto-weighted strategy that can automatically assign the ideal weights to each view. Finally, an efficient alternating iterative algorithm using the augmented Lagrange multiplier method is designed to solve the CMVSC model. Experimental results show that our model outperforms the state-of-the-art counterparts while achieving almost perfect clustering performance on several benchmark datasets.},
  archive      = {J_ISCI},
  author       = {Bing Cai and Gui-Fu Lu and Guangyan Ji and Weihong Song},
  doi          = {10.1016/j.ins.2024.120381},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120381},
  shortjournal = {Inf. Sci.},
  title        = {Complete multi-view subspace clustering via auto-weighted combination of visible and latent views},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PaVa: A novel path-based valley-seeking clustering
algorithm. <em>ISCI</em>, <em>665</em>, 120380. (<a
href="https://doi.org/10.1016/j.ins.2024.120380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering methods are being applied to a wider range of scenarios involving more complex datasets, where the shapes of clusters tend to be arbitrary. In this paper, we propose a novel Path-based Valley-seeking clustering algorithm for arbitrarily shaped clusters. This work aims to seek the valleys among clusters and then individually extract clusters. Three vital techniques are used in this algorithm. First, path distance (minmax distance) is employed to transform the irregular boundaries among clusters, that is density valleys, into perfect spherical shells. Second, a suitable density measurement, k -distance, is employed to make adjustment on Minimum Spanning Tree, by which a robust minmax distance is calculated. Third, we seek the transformed density valleys by determining their centers and radii. Based on the vital techniques, the main contributions of the proposed algorithm can be summarized as follows. First, the clusters are wrapped in spherical shells after the distance transformation, making the extraction process efficient even with clusters of arbitrary shape. Second, adjusted Minimum Spanning Tree enhances the robustness of minmax distance under different kinds of noise. Last, the number of clusters does not need to be inputted or decided manually due to the individual extraction process. After applying the proposed algorithm to several commonly used synthetic datasets, the results indicate that the Path-based Valley-seeking algorithm is accurate and efficient. The algorithm is based on the dissimilarity of objects, so it can be applied to a wide range of fields. Its performance on real-world datasets illustrates its versatility.},
  archive      = {J_ISCI},
  author       = {Lin Ma and Conan Liu and Tiefeng Ma and Shuangzhe Liu},
  doi          = {10.1016/j.ins.2024.120380},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120380},
  shortjournal = {Inf. Sci.},
  title        = {PaVa: A novel path-based valley-seeking clustering algorithm},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph contrastive learning with min-max mutual information.
<em>ISCI</em>, <em>665</em>, 120378. (<a
href="https://doi.org/10.1016/j.ins.2024.120378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning has achieved rapid development in learning representations from graph-structured data, which aims to maximize the mutual information between two representations learned from different augmented views of a graph. However, maximizing the mutual information between different views without any constraints may cause encoders to capture information irrelevant to downstream tasks, limiting the efficiency of graph contrastive learning methods. To tackle these issues, we propose a Graph Contrastive Learning method with Min-max mutual Information (GCLMI). Specifically, we conduct theoretical analysis to present our learning objective. It designs a min-max principle to constrain the mutual information among multiple views, including between a graph and each of its augmented views, as well as between different augmented views. Based on the learning objective, we further construct two augmented views by separating the feature and topology information of a graph to preserve different semantic information from the graph. Subsequently, we maximize the mutual information between each augmented view and the graph while minimizing the mutual information between two augmented views, to learn informative and diverse representations. Extensive experiments are conducted on a variety of graph datasets, and experimental results show that GCLMI achieves better or competitive performance compared with state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Yuhua Xu and Junli Wang and Mingjian Guang and Chungang Yan and Changjun Jiang},
  doi          = {10.1016/j.ins.2024.120378},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120378},
  shortjournal = {Inf. Sci.},
  title        = {Graph contrastive learning with min-max mutual information},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BPFL: Blockchain-based privacy-preserving federated learning
against poisoning attack. <em>ISCI</em>, <em>665</em>, 120377. (<a
href="https://doi.org/10.1016/j.ins.2024.120377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In federated learning (FL), multiple clients use local datasets to train models and submit local gradients to the server for aggregation. However, malicious clients may compromise the performance of the model by submitting poisonous gradients. Moreover, the clients do not want to reveal their training models in most application scenarios since their private data may be inferred from them. In addition, most of FL protocols lack an incentive mechanism to supervise participants and cannot punish malicious participants, which is unfair to honest participants. To tackle these problems, we propose a blockchain-based privacy-preserving federated learning against poisoning attack (BPFL). In BPFL, a blockchain-based incentive mechanism is constructed to supervise participants and promptly track malicious behaviors. BPFL can also protect the privacy of aggregated and local model if some participants are malicious, and detect poisonous data by computing cosine similarity between the aggregated gradient and local gradient of the client by using Paillier cryptosystem with threshold decryption. The experiments show that BPFL improves the accuracy of the model from 10% to 75% on CIFAR-10 against poisoning attacks, and therefore BPFL can effectively resist poisoning attacks based on the privacy of local and aggregated models.},
  archive      = {J_ISCI},
  author       = {Yanli Ren and Mingqi Hu and Zhe Yang and Guorui Feng and Xinpeng Zhang},
  doi          = {10.1016/j.ins.2024.120377},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120377},
  shortjournal = {Inf. Sci.},
  title        = {BPFL: Blockchain-based privacy-preserving federated learning against poisoning attack},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction of airport runway settlement using an integrated
SBAS-InSAR and BP-EnKF approach. <em>ISCI</em>, <em>665</em>, 120376.
(<a href="https://doi.org/10.1016/j.ins.2024.120376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of surface settlement occupies a crucial role in achieving effective catastrophe prevention and mitigation, as well as facilitating the maintenance of airport runways. Given the challenges associated with the manual collection of settlement data and the suboptimal timeliness of the Back Propagation (BP) technique in neural networks, this study proposes an integrated prediction method that combines the Ensemble Kalman Filter (EnKF) with BP. This study focuses on the processing of Synthetic Aperture Radar (SAR) pictures obtained from the ascending orbit of the Sentinel-1A satellite. The Small Baseline Subset Interferometric synthetic aperture radar (SBAS-InSAR) technology is employed to derive the settlement time series on the runway of Kangding Airport. Moreover, three sites with high coherence within the primary settlement region are employed to assess the dependability of the model after the expansion of the data by cubic spline interpolation. The findings of the study indicate that both the BP-EnKF and BP models exhibit favorable outcomes in predicting airport runway settlement. However, following the alteration of data caused by external environmental influences, the BP-EnKF model has superior adaptability to variations in data. It has been shown that the BP-EnKF model exhibits a prediction accuracy that surpasses the BP model by 9.25%.},
  archive      = {J_ISCI},
  author       = {Sheng-Hua Xiong and Zhi-Peng Wang and Gang Li and Mirosław J. Skibniewski and Zhen-Song Chen},
  doi          = {10.1016/j.ins.2024.120376},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120376},
  shortjournal = {Inf. Sci.},
  title        = {Prediction of airport runway settlement using an integrated SBAS-InSAR and BP-EnKF approach},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). GD3N: Adaptive clustering-based detection of selective
forwarding attacks in WSNs under variable harsh environments.
<em>ISCI</em>, <em>665</em>, 120375. (<a
href="https://doi.org/10.1016/j.ins.2024.120375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks (WSNs) are susceptible to numerous security threats due to their reliance on open environments and broadcast communication methods. Among these, the selective forwarding attack is notably challenging to detect. This difficulty arises from the ability of malicious nodes to imitate the behavior of normal nodes, and selectively drop data packets, which makes them virtually indistinguishable from normal ones, particularly under conditions of poor channel quality. To address this challenge with harsh environments, we introduce a novel methodology termed GD3N. This approach is underpinned by the design of a unique type of data point that encapsulates both short-term and long-term forwarding behaviors of nodes. It combines a refined version of the Gradient Diffusion Density-based Spatial Clustering of Applications with Noise (GD-DBSCAN) algorithm, with a novel Double-Parameter Neighbor Voting (DP-NV) method based on the data set. These innovations contribute to a significant enhancement in detection accuracy and a reduction in computational complexity when compared to traditional DBSCAN and NV methods. Simulation results show that our GD3N achieves a false detection rate (FDR) of less than 2%, a missed detection rate (MDR) of below 10%, and an overall detection accuracy rate (DAR) of over 95% across various testing scenarios.},
  archive      = {J_ISCI},
  author       = {Haozhen Wang and Xinyu Huang and Yuanming Wu},
  doi          = {10.1016/j.ins.2024.120375},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120375},
  shortjournal = {Inf. Sci.},
  title        = {GD3N: Adaptive clustering-based detection of selective forwarding attacks in WSNs under variable harsh environments},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning disentangled representations in signed directed
graphs without social assumptions. <em>ISCI</em>, <em>665</em>, 120373.
(<a href="https://doi.org/10.1016/j.ins.2024.120373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signed graphs can represent complex systems of positive and negative relationships such as trust or preference in various domains. Learning node representations is indispensable because they serve as pivotal features for downstream tasks on signed graphs. However, most existing methods often oversimplify the modeling of signed relationships by relying on social theories, while real-world relationships can be influenced by multiple latent factors. This hinders those methods from effectively capturing the diverse factors, thereby limiting the expressiveness of node representations. In this paper, we propose DINES , a novel method for learning disentangled node representations in signed directed graphs without social assumptions. We adopt a disentangled framework that separates each embedding into distinct factors, allowing for capturing multiple latent factors, and uses signed directed graph convolutions that focus solely on sign and direction, without depending on social theories. Additionally, we propose a new decoder that effectively classifies an edge&#39;s sign by considering correlations between the factors. To further enhance disentanglement, we jointly train a self-supervised factor discriminator with our encoder and decoder. Throughout extensive experiments on real-world signed directed graphs, we show that DINES effectively learns disentangled node representations, and significantly outperforms its competitors in predicting link signs.},
  archive      = {J_ISCI},
  author       = {Geonwoo Ko and Jinhong Jung},
  doi          = {10.1016/j.ins.2024.120373},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120373},
  shortjournal = {Inf. Sci.},
  title        = {Learning disentangled representations in signed directed graphs without social assumptions},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Carbon emission causal discovery and multi-step forecasting
using spatiotemporal information. <em>ISCI</em>, <em>665</em>, 120372.
(<a href="https://doi.org/10.1016/j.ins.2024.120372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spurred by the urgency to combat climate change, lowering carbon emissions has become a critical global concern. Nevertheless, interregional emission causal discovery and emission forecasting, potent decision tools for reducing emissions, have been insufficiently researched. This study aims to bridge these gaps by unveiling two innovative algorithms. The first, a causal discovery algorithm, adeptly navigates the complexities of emission interactions among regions, utilizing matrix decomposition and diffusion models for nuanced insights. The second, a spatiotemporal forecasting algorithm, leverages hyperbolic graph neural networks and ordinary differential neural networks to refine predictions of regional carbon emissions. The efficacy of the proposed algorithms is verified via meticulous verification, including Taylor statistics, predictive errors, Diebold Mariano tests, and ablation experiments. This study identifies key features of the carbon emission network, including 32 regions in the Chinese mainland, and offers insights into joint reduction policies grounded in algorithm effectiveness. This research catalyzes theoretical progress in carbon emission causality analysis and forecasting within the context of the ongoing climate crisis while also facilitating the decision-making science of artificial intelligence. Furthermore, it offers practical applications in environmental protection strategies, ecological assessments, and advancing global carbon neutrality via information science.},
  archive      = {J_ISCI},
  author       = {Xiaoyan Li and Wenting Zhan and Peng Luo and Xuedong Liang},
  doi          = {10.1016/j.ins.2024.120372},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120372},
  shortjournal = {Inf. Sci.},
  title        = {Carbon emission causal discovery and multi-step forecasting using spatiotemporal information},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards blockchain-enabled decentralized and secure
federated learning. <em>ISCI</em>, <em>665</em>, 120368. (<a
href="https://doi.org/10.1016/j.ins.2024.120368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional machine learning process typically operates under the premise of centralized data aggregation, where all data is collected at a central location for model training. However, this raises substantial privacy concerns when the data contains private information. In this context, federated learning has emerged as a prominent solution for preserving privacy in machine learning. This innovative paradigm allows multiple data owners, or clients, to collaboratively train a machine learning model while keeping their local data unshared. A federated learning task is typically initiated by companies, often referred to as model owners, who do not possess enough training data and are willing to financially remunerate clients who contribute to the development of the federated learning model. This situation demands a trading platform that enables model owners to effectively select clients, while ensuring robustness against malicious clients who execute poisoning attacks for unfair financial gain. To address these issues, we design a contribution-based exploration-exploitation mechanism implemented as a smart contract. This mechanism cherry-picks clients with high data quality based on the Shapley value, which is calculated based on local models to evaluate the contribution of each client. Unlike other state-of-the-art security mechanisms, the proposed mechanism can adapt to various scenarios with heterogeneous data distribution and various attacks, while mitigating the effect of malicious behaviors without compromising training accuracy. To accelerate the time-consuming calculation of the Shapley value, we design a parallel computing algorithm that partitions blockchain nodes into multiple shards and distributes calculation tasks among them. The algorithm improves efficiency and tolerates potential false calculation results from malicious nodes.},
  archive      = {J_ISCI},
  author       = {Xuyang Ma and Du Xu and Katinka Wolter},
  doi          = {10.1016/j.ins.2024.120368},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120368},
  shortjournal = {Inf. Sci.},
  title        = {Towards blockchain-enabled decentralized and secure federated learning},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maximum output discrepancy computation for convolutional
neural network compression. <em>ISCI</em>, <em>665</em>, 120367. (<a
href="https://doi.org/10.1016/j.ins.2024.120367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network compression methods minimize the number of network parameters and computation costs while maintaining desired network performance. However, the safety assurance of many compression methods is based on a large amount of experimental data, whereas unforeseen incidents beyond the experiment data may result in unsafe consequences. In this work, we developed a discrepancy computation method for two convolutional neural networks by giving a concrete value to characterize the maximum output difference between the two networks after compression. Using Imagestar-based reachability analysis, we propose a novel method to merge the two networks to compute the difference. We illustrate reachability computation for each layer in the merged network, such as the convolution, max pooling, fully connected, and ReLU layers. We apply our method to a numerical example to prove its correctness. Furthermore, we implement our developed methods on the VGG16 model with the Quantization Aware Training (QAT) compression method; the results show that our approach can efficiently compute the accurate maximum output discrepancy between the original neural network and the compressed neural network.},
  archive      = {J_ISCI},
  author       = {Zihao Mo and Weiming Xiang},
  doi          = {10.1016/j.ins.2024.120367},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120367},
  shortjournal = {Inf. Sci.},
  title        = {Maximum output discrepancy computation for convolutional neural network compression},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A preliminary study on few-shot knowledge reasoning
mechanism based on three-way partial order structure. <em>ISCI</em>,
<em>665</em>, 120366. (<a
href="https://doi.org/10.1016/j.ins.2024.120366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot knowledge reasoning, as a novel theory that attempts to combine few-shot learning with knowledge reasoning, is a challenging subject. This article intends to explore few-shot knowledge reasoning mechanism based on three-way partial order structure. First, from the perspective of granular computing, some knowledge reasoning operators are defined: granule splitting, granule combination, and granule isomorphism; then, based on the knowledge reasoning operators, the data augmentation operation and knowledge reasoning algorithm are presented; finally, some specific experiments on five datasets are conducted to further illustrate the few-shot knowledge reasoning algorithm. Experiment results show that the method proposed in this article can effectively realize knowledge reasoning based on small sample size data. It can be concluded that the proposed few-shot knowledge reasoning method is effective at some extent, and is expected to bring inspiration to the development of other concept-based knowledge reasoning models.},
  archive      = {J_ISCI},
  author       = {Enliang Yan and Tao Zhang and Jianping Yu and Tianyong Hao and Qiliang Chen},
  doi          = {10.1016/j.ins.2024.120366},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120366},
  shortjournal = {Inf. Sci.},
  title        = {A preliminary study on few-shot knowledge reasoning mechanism based on three-way partial order structure},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonlinear blind source separation exploiting spatial
nonstationarity. <em>ISCI</em>, <em>665</em>, 120365. (<a
href="https://doi.org/10.1016/j.ins.2024.120365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In spatial blind source separation the observed multivariate random fields are assumed to be mixtures of latent spatially dependent random fields. The objective is to recover latent random fields by estimating the unmixing transformation. Currently, the algorithms for spatial blind source separation can only estimate linear unmixing transformations. Nonlinear blind source separation methods for spatial data are scarce. In this paper, we extend an identifiable variational autoencoder that can estimate nonlinear unmixing transformations to spatially dependent data, and demonstrate its performance for both stationary and nonstationary spatial data using simulations. In addition, we introduce scaled mean absolute Shapley additive explanations for interpreting the latent components through nonlinear mixing transformation. The spatial identifiable variational autoencoder is applied to a geochemical dataset to find the latent random fields, which are then interpreted by using the scaled mean absolute Shapley additive explanations. Finally, we illustrate how the proposed method can be used as a pre-processing method when making multivariate predictions.},
  archive      = {J_ISCI},
  author       = {Mika Sipilä and Klaus Nordhausen and Sara Taskinen},
  doi          = {10.1016/j.ins.2024.120365},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120365},
  shortjournal = {Inf. Sci.},
  title        = {Nonlinear blind source separation exploiting spatial nonstationarity},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A knowledge-based iterated local search for the weighted
total domination problem. <em>ISCI</em>, <em>665</em>, 120364. (<a
href="https://doi.org/10.1016/j.ins.2024.120364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a simple undirected weighted graph G = ( V , E , w , c ) G=(V,E,w,c) , the weighted total domination problem is to find a total dominating set S with the minimum weight cost. A total dominating set S is a vertex subset satisfying that for each vertex in V there is at least one neighboring vertex in S . We propose a knowledge-based iterated local search algorithm for this problem that combines a reduction procedure to reduce the input graph, a learning-based initialization to generate high-quality initial solutions and a solution-based iterated local search to conduct intensive solution examination. Experiments on 342 benchmark instances show that the algorithm outperforms state-of-the-art algorithms. In particular, it reports 93 new upper bounds and 249 same results (including 165 known optimal results). The impact of each component of the algorithm is examined.},
  archive      = {J_ISCI},
  author       = {Wen Sun and Chaofan Chen and Jin-Kao Hao and Wenlong Li and Qinghua Wu and Yuning Chen},
  doi          = {10.1016/j.ins.2024.120364},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120364},
  shortjournal = {Inf. Sci.},
  title        = {A knowledge-based iterated local search for the weighted total domination problem},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FCSG-miner: Frequent closed subgraph mining in multi-graphs.
<em>ISCI</em>, <em>665</em>, 120363. (<a
href="https://doi.org/10.1016/j.ins.2024.120363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph data-based mining is vital in various fields, such as business management, chemistry, and social networks. Frequency-based frameworks have limitations regarding large mining output. In many real-world scenarios, not all frequent patterns hold significant meaning. To address this issue, concise representation such as closed patterns is proposed. Unfortunately, existing methods utilize support or occurrence as frequency measurements, which have drawbacks. Support overlooks the isomorphic quantity of a single graph, while occurrence lacks the downward closure property. In this paper, we introduce an approach for mining frequent closed subgraphs. A novel measure MMNI (multiple minimum node image) is introduced to strike a balance between support and occurrence measures. Additionally, we design a novel structure to store occurrence information. We develop a pruning strategy and employ an early termination strategy to enhance efficiency. To evaluate the performance of our algorithm, we conduct experiments on seven real datasets, considering four aspects. The results demonstrate that our algorithm has high efficiency and performance compared to the state-of-the-art algorithm for closed subgraph mining. In several cases, our method requires only 50% of the time consumed by previous approaches. We also present a real-world application example in the domain of bike-sharing systems.},
  archive      = {J_ISCI},
  author       = {Xinyang Chen and Jiayu Cai and Guoting Chen and Wensheng Gan and Amaël Broustet},
  doi          = {10.1016/j.ins.2024.120363},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120363},
  shortjournal = {Inf. Sci.},
  title        = {FCSG-miner: Frequent closed subgraph mining in multi-graphs},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MAInt: A multi-task learning model with automatic feature
interaction learning for personalized recommendations. <em>ISCI</em>,
<em>665</em>, 120362. (<a
href="https://doi.org/10.1016/j.ins.2024.120362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, more and more recommender systems apply multi-task learning to provide users with more accurate personalized recommendations. However, most of the existing multi-task learning models ignore the importance of explicit feature interactions in different tasks, which are an important part of recommender system models. In addition, the knowledge sharing mechanism of the existing model is difficult to meet the needs of all tasks, resulting in the performance degradation of some tasks. To address these issues, we propose a Multi-task learning model based on Automatic feature Interaction learning (MAInt). The Tasks Interaction Layer in MAInt automatically learns explicit feature interactions in different tasks through self-attention neural networks. At the same time, this process allows each task to interact with each other, so that each task can adaptively extract helpful information from other task features. We conducted multiple experiments on two popular public datasets: Census-income Dataset and Ali-CCP Dataset, and the experimental results verified the effectiveness of our proposed model.},
  archive      = {J_ISCI},
  author       = {Pu Yin and Yetao Sun and Ziyi Gao and Rui Wang and Yuan Yao},
  doi          = {10.1016/j.ins.2024.120362},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120362},
  shortjournal = {Inf. Sci.},
  title        = {MAInt: A multi-task learning model with automatic feature interaction learning for personalized recommendations},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Regret-based budgeted decision rules under severe
uncertainty. <em>ISCI</em>, <em>665</em>, 120361. (<a
href="https://doi.org/10.1016/j.ins.2024.120361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One way to make decisions under uncertainty is to select an optimal option from a possible range of options, by maximizing the expected utilities derived from a probability model. However, under severe uncertainty, identifying precise probabilities is hard. For this reason, imprecise probability models uncertainty through convex sets of probabilities, and considers decision rules that can return multiple options to reflect insufficient information. Many well-founded decision rules have been studied in the past, but none of those standard rules are able to control the number of returned alternatives. This can be a problem for large decision problems, due to the cognitive burden decision makers have to face when presented with a large number of alternatives. Our contribution proposes regret-based ideas to construct new decision rules which return a bounded number of options, where the limit on the number of options is set in advance by the decision maker as an expression of their cognitive limitation. We also study their consistency and numerical behaviour.},
  archive      = {J_ISCI},
  author       = {Nawapon Nakharutai and Sébastien Destercke and Matthias C.M. Troffaes},
  doi          = {10.1016/j.ins.2024.120361},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120361},
  shortjournal = {Inf. Sci.},
  title        = {Regret-based budgeted decision rules under severe uncertainty},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic selection of machine learning models for time-series
data. <em>ISCI</em>, <em>665</em>, 120360. (<a
href="https://doi.org/10.1016/j.ins.2024.120360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adapting to changes in time-series data is a major challenge in machine learning. This problem is particularly acute in the case of limited computing power (e.g., edge devices) that does not enable the independent training of new models. While multiple studies attempt to adequately train a machine learning model on rapidly shifting data (i.e., concept drift), the challenge of dynamically selecting the most effective machine learning model for future time steps has been largely overlooked. In this study, we propose A daptive machine learning for D ynamic EN vironments (ADEN ), a method for analyzing future trends in time-series data and selecting the most suitable ML model. Our approach models multiple aspects of the analyzed data and analyzes the behavior of multiple machine learning models on earlier time steps. By training ADEN on multiple datasets, we can deploy a zero-shot model that does not require additional training when applied to new datasets. Our evaluation, conducted on 46 time-series classification datasets, shows that ADEN not only outperforms all baselines in terms of average performance but is also capable of avoiding sudden drops in performance that characterize all other evaluated algorithms.},
  archive      = {J_ISCI},
  author       = {Rotem Hananya and Gilad Katz},
  doi          = {10.1016/j.ins.2024.120360},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120360},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic selection of machine learning models for time-series data},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-step ensemble under-sampling algorithm for massive
imbalanced data classification. <em>ISCI</em>, <em>665</em>, 120351. (<a
href="https://doi.org/10.1016/j.ins.2024.120351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data classification is a challenging problem in the field of machine learning. Class imbalance, class overlap, and large data volume significantly affect classification performance. Focusing on the impact of class overlap on classification effectiveness, we propose a two-step ensemble under-sampling algorithm based on boundary information mining (TSSE-BIM) with the goal of reducing the information loss from under-sampling methods on large-scale imbalanced data. In the first stage, the proposed method applies an improved equalization under-sampling strategy to mine sample contribution information and quickly obtains the distribution information of data relative to the decision boundary. In the second stage, based on the boundary information, a weighted boundary sampling is performed to remove noisy and highly overlapping samples. It is easy to retain samples with high contribution and effectively suppress the information loss caused by under-sampling. Then, the overall framework is designed based on a serial ensemble similar to boosting, where the weights of each base classifier are assigned to achieve a more powerful performance based on the false positive rate and false negative rate on the original data. Finally, extensive experiments indicate that TSSE-BIM outperforms state-of-the-art methods and ranks first on average under four metrics, especially F1 and MCC.},
  archive      = {J_ISCI},
  author       = {Lin Bai and Tong Ju and Hao Wang and Mingzhu Lei and Xiaoying Pan},
  doi          = {10.1016/j.ins.2024.120351},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120351},
  shortjournal = {Inf. Sci.},
  title        = {Two-step ensemble under-sampling algorithm for massive imbalanced data classification},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cryptanalysis and improvement of “group public key
encryption scheme supporting equality test without bilinear pairings.”
<em>ISCI</em>, <em>665</em>, 120349. (<a
href="https://doi.org/10.1016/j.ins.2024.120349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public key encryption with equality test (PKEET) is a novel primitive which supports equality comparisons on two encrypted messages. Currently, most of the existing PKEET schemes are based on bilinear pairing and require heavy computational overheads. To address this issue, Shen et al. recently proposed an efficient group public key encryption supporting equality test without bilinear pairings scheme. Compared with other schemes, their scheme reduces the usage of expensive bilinear pairing operations and enjoys higher computation efficiency. They claimed that their scheme achieved one-wayness security in the random oracle model and resisted offline message recovery attack. In this letter, we analyze Shen et al.&#39;s scheme through two concrete attacks and demonstrate that their scheme can not support the above two security requirements. An improved scheme is provided to overcome the security vulnerabilities in their scheme. Performance analysis shows that our improved scheme has certain advantages in both computation overhead and storage overhead.},
  archive      = {J_ISCI},
  author       = {Qijia Zhang and Youliang Tian},
  doi          = {10.1016/j.ins.2024.120349},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120349},
  shortjournal = {Inf. Sci.},
  title        = {Cryptanalysis and improvement of “group public key encryption scheme supporting equality test without bilinear pairings”},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An online low-dimension fuzzy modeling method for
time-varying processes. <em>ISCI</em>, <em>665</em>, 120348. (<a
href="https://doi.org/10.1016/j.ins.2024.120348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many industrial processes are full of nonlinearity and noise. Fuzzy modeling often leads to issues with dimension disaster and poor robustness for such processes. To address these issues, an online low-dimension fuzzy method (OLDF) is proposed here. First, an explicit mapping-based low-dimension fuzzy method (EMLF) is proposed to handle intricate nonlinear and noisy processes. In this method, similar fuzzy sets are combined into larger ones using a novel similarity criterion to reduce the fuzzy rules. Then, an explicit mapping strategy is developed to represent the local nonlinearities in each enlarged fuzzy set through an explicit mapping function. Subsequently, a robust objective function is constructed to improve the robustness of EMLF model. This objective function minimizes both the mean and variance of the modeling error, ensuring robust performance even in scenarios featuring non-Gaussian noise or outliers. After that, an online update strategy is designed to account for time-varying dynamics. It designs an adaptive detection mechanism to identify changes in dynamic behaviors. Following detection, global and local updating strategies are developed to dynamically update model parameters. Further analysis and proof highlight the effectiveness of the proposed method. Experiments with time-varying processes also confirm its success.},
  archive      = {J_ISCI},
  author       = {Yunxu Bai and Xinjiang Lu},
  doi          = {10.1016/j.ins.2024.120348},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120348},
  shortjournal = {Inf. Sci.},
  title        = {An online low-dimension fuzzy modeling method for time-varying processes},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph-SeTES: A graph based search task extraction using
siamese network. <em>ISCI</em>, <em>665</em>, 120346. (<a
href="https://doi.org/10.1016/j.ins.2024.120346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Search task extraction is a sub-process for query suggestion/reformulation, personalized recommendation, and advertisement in search engines and e-commerce platforms. However, they face both internal and external challenges. Internal challenges include short and misspelled queries and incomplete keywords. External challenges include an unknown number of clusters and a limited number of labeled datasets. Deep-learning models require a large amount of data for training; however, search task datasets are rare and small. To overcome these limitations, we proposed Graph-SeTES, which integrates feature extraction with a decision network that utilizes both distance metrics and decision networks. The existing graph-clustering algorithms use the similarities between search query pairs. Because the Siamese network (SN) finds similarities between two objects, it fits search task extraction. Compared with existing models, SN requires fewer parameters for training due to the shared weights. However, it yields good results even with less labeled data, overcoming the external challenges. We benefit from both distance metrics and narrowing of the linear layers for decision networks. Graph-SeTES was compared with state-of-the-art models, and it outperformed its counterparts. The results were 6% better than those of the best baseline on the CSTE dataset, which maintained this performance difference on the WSMC12 dataset.},
  archive      = {J_ISCI},
  author       = {Nurullah Ates and Yusuf Yaslan},
  doi          = {10.1016/j.ins.2024.120346},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120346},
  shortjournal = {Inf. Sci.},
  title        = {Graph-SeTES: A graph based search task extraction using siamese network},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An extended multi-expert concept lattice-based heterogeneous
multi-attribute group decision-making approach. <em>ISCI</em>,
<em>665</em>, 120345. (<a
href="https://doi.org/10.1016/j.ins.2024.120345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical multi-attribute group decision-making (MAGDM) problems, it is common to utilize heterogeneous representation forms to express distinct preference information for different experts, primarily due to their diverse backgrounds. To address the problem of reducing information loss from the aggregation of experts&#39; opinions in heterogeneous MAGDM as well as improving the interpretability of the decision-making process, this paper introduces a concept lattice-based heterogeneous MAGDM approach. The heterogeneous multi-expert formal context is first proposed to capture the heterogeneous evaluation information of alternatives provided by different experts. Then, extended multi-expert concept lattices are constructed to aggregate evaluation information of alternatives by different experts. In this case, all concepts are considered to minimize information loss during the aggregation process. Second, to obtain more reasonable decision results, the distance between the concept intents and the heterogeneous positive and negative ideal solutions is considered, and the alternatives are ranked based on this measure. In addition, the MAGDM process for each alternative is visualized using the extended multi-expert concept lattices. This representation aids in identifying key concepts, their interdependencies, and the overall impact on the decision result. Finally, numerical examples and comparative analysis validate the validity and rationality of the proposed approach in heterogeneous MAGDM.},
  archive      = {J_ISCI},
  author       = {Kuo Pang and Chao Fu and Luis Martínez and Jun Liu and Li Zou and Mingyu Lu},
  doi          = {10.1016/j.ins.2024.120345},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120345},
  shortjournal = {Inf. Sci.},
  title        = {An extended multi-expert concept lattice-based heterogeneous multi-attribute group decision-making approach},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Next generation of computer vision for plant disease
monitoring in precision agriculture: A contemporary survey, taxonomy,
experiments, and future direction. <em>ISCI</em>, <em>665</em>, 120338.
(<a href="https://doi.org/10.1016/j.ins.2024.120338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient and rational monitoring of plant health is an essential prerequisite for ensuring optimal crop production and resource management in the field of agriculture. Computer vision techniques have revolutionized visual disease monitoring with their exceptional visual recognition performance. However, despite the outstanding results, the widespread acceptance of these methods in agriculture practice is still in its early stages. This study presents a comprehensive survey of the next generation of computer vision models applied to plant disease monitoring in precision agriculture. Our study begins by tracing the evolution of agricultural computer vision research over the past decade, encompassing legacy methods such as convolutional neural networks (CNNs), progressing to newer techniques like vision transformers (ViTs), and culminating in cutting-edge vision multi-layer perceptrons (MLPs). Next, our study embraces both qualitative and quantitative approaches, supporting a profound review of literature and classifying methodologies and experimental approaches. A significant contribution lies in our comprehensive taxonomy, offering a fine-grained categorization of current computer vision models. This taxonomy meticulously highlights the potentials and limitations of these models while explaining their roles in improving plant disease management. Moreover, extensive experimental comparisons are conducted on PlantVillage dataset to evaluate the performance of state-of-the-art computer-vision models for plant recognition data. The obtained results are then utilized to draw insightful conclusions about the behavior of these models and provide guidance for selecting the most suitable one for specific tasks at hand. Additionally, we discuss open research avenues and future directions of computer-vision models in plant disease management including challenges related to the data scarcity, the computational efficiency, need for explainability, and multi-modal analysis.},
  archive      = {J_ISCI},
  author       = {Weiping Ding and Mohamed Abdel-Basset and Ibrahim Alrashdi and Hossam Hawash},
  doi          = {10.1016/j.ins.2024.120338},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120338},
  shortjournal = {Inf. Sci.},
  title        = {Next generation of computer vision for plant disease monitoring in precision agriculture: A contemporary survey, taxonomy, experiments, and future direction},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VSDHS-CIEA: Color image encryption algorithm based on novel
variable-structure discrete hyperchaotic system and cross-plane
confusion strategy. <em>ISCI</em>, <em>665</em>, 120332. (<a
href="https://doi.org/10.1016/j.ins.2024.120332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the color image encryption algorithm based on chaos theory has become the focus of current research. When encrypting color images, the common practice is to treat color images as different gray components and process them severally, which results in more redundancy and low efficiency. The security of chaotic cryptosystems also depends on the performance of the chaotic systems adopted. The structures of many current chaotic systems are fixed, making their behaviors highly predictable. Additionally, the range of chaotic region parameters is limited and discontinuous. To solve the above-mentioned problems, a new color image encryption algorithm (CIEA) using fractal and chaos theory is presented, which fully considers the inherent connection among the RGB components of color images. First, we propose a variable-structure discrete hyperchaotic system (VSDHS) to solve the dilemma encountered by existing chaotic systems. The excellent dynamic properties of VSDHS are verified by rigorous mathematical proof and simulation performance analyses. Then, VSDHS-CIEA is designed using fractal theory and VSDHS. The algorithm makes full use of the inherent connection among the different components of color images and performs cross-plane confusion. Simulations and performance analyses prove that VSDHS-CIEA has higher security and better performance than some representative image encryption algorithms.},
  archive      = {J_ISCI},
  author       = {Hangming Zhang and Hanping Hu and Weiping Ding},
  doi          = {10.1016/j.ins.2024.120332},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120332},
  shortjournal = {Inf. Sci.},
  title        = {VSDHS-CIEA: Color image encryption algorithm based on novel variable-structure discrete hyperchaotic system and cross-plane confusion strategy},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy laplace transform method for a fractional fuzzy
economic model based on market equilibrium. <em>ISCI</em>, <em>665</em>,
120308. (<a href="https://doi.org/10.1016/j.ins.2024.120308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy fractional models are of interest because they are very effective in describing real-world problems, but the analytical investigation of these models is often complex. Therefore, presenting a practical method for the analytical solution of these models is of particular importance. Hence, in this paper, first, the Laplace transform of the fuzzy ABC fractional derivative and its properties are introduced using the strongly generalized Hukuhara differentiability concept, and an analytical method for solving the fuzzy ABC fractional differential equation based on the Laplace transform is proposed. In the following, to show the comprehensiveness and appropriateness of the method, since the parameters are imprecise and ambiguous in economic problems, the price adjustment equation is modeled in the form of a fuzzy ABC fractional differential equation using the fuzzy ABC fractional derivative, and the fuzzy price for the adjustment equation is obtained using the proposed analytical fuzzy price. Finally, the effectiveness of the proposed approach is demonstrated with numerical examples.},
  archive      = {J_ISCI},
  author       = {Fatemeh Babakordi and Tofigh Allahviranloo and M.R. Shahriari and Muammer Catak},
  doi          = {10.1016/j.ins.2024.120308},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120308},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy laplace transform method for a fractional fuzzy economic model based on market equilibrium},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TAILOR: InTer-feAture distinctIon fiLter fusiOn pRuning.
<em>ISCI</em>, <em>665</em>, 120229. (<a
href="https://doi.org/10.1016/j.ins.2024.120229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Filter pruning is an effective method for reducing the size of convolutional neural networks without sacrificing performance. Most filter pruning methods prioritize filters with high information content, but fail to consider that filters with low information content might capture essential features. Moreover, we have discovered that the distinctions among feature maps generated by filters can identify crucial features. Based on this insight, we propose a novel pruning method called inTer-feAture distinctIon fiLter fusiOn pRuning (TAILOR), which fuses the feature distinctions between filters. TAILOR randomly selects multiple filter sets within a convolutional layer and calculates the output feature maps of the next convolutional layer of these sets. Subsequently, an intelligent distinction optimization scheme is proposed to obtain the optimal filter set for filter pruning, which supplants the original convolutional layer. Experimental results indicated that the inter-feature distinctions among filters significantly affect filter pruning. TAILOR outperforms state-of-the-art filter-pruning methods in terms of model prediction accuracy, floating-point operations, and parameter scale. For instance, with VGG-16, TAILOR achieves a 73.89% FLOPs reduction by removing 91.85% of the parameters, while improving accuracy by 0.36% on the CIFAR-10.},
  archive      = {J_ISCI},
  author       = {Xuming Han and Yali Chu and Ke Wang and Limin Wang and Lin Yue and Weiping Ding},
  doi          = {10.1016/j.ins.2024.120229},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120229},
  shortjournal = {Inf. Sci.},
  title        = {TAILOR: InTer-feAture distinctIon fiLter fusiOn pRuning},
  volume       = {665},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Complexity-aided time series modeling and forecasting under
a decomposition-aggregation framework. <em>ISCI</em>, <em>664</em>,
120352. (<a href="https://doi.org/10.1016/j.ins.2024.120352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complexity of time series has always been of significant interest to researchers; however, it is not yet effectively explored in assisting time series prediction modeling. In this study, we develop a decomposition-aggregation time series prediction framework sufficiently applying the complexity concept from two aspects. One aspect is realized during the process of allocating information granularity onto each decomposed subsequence (with comparably lower complexity). The other aspect is realized through constituting the objective function of a prediction model (a granular neural network in this paper) which is built with a subsequence individually. To capture several critical patterns of a time series, it is decomposed into several subsequences and used to train a granular neural network independently. An effective aggregation strategy is then adopted to aggregate those predicted information granules which are the outputs of local granular neural networks. The quality of the global output information granule is assessed by analyzing the relationship of coverage and specificity and keeping in mind the overall information granularity. Experimental studies show that the decomposition-aggregation strategy prediction results are better than the non-decomposed one and the complexity-aided objective function performs better than the objective function without complexity.},
  archive      = {J_ISCI},
  author       = {Mingli Song and Ruobing Wang},
  doi          = {10.1016/j.ins.2024.120352},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120352},
  shortjournal = {Inf. Sci.},
  title        = {Complexity-aided time series modeling and forecasting under a decomposition-aggregation framework},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FlexibleFL: Mitigating poisoning attacks with contributions
in cloud-edge federated learning systems. <em>ISCI</em>, <em>664</em>,
120350. (<a href="https://doi.org/10.1016/j.ins.2024.120350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud-edge architecture is an emerging technology that aims to meet the growing demands of intelligent applications. To address the issues of machine learning privacy leakages and benefiting from imbalanced data distribution, federated learning has been widely applied. Nevertheless, they present inherent vulnerabilities that make them vulnerable to poisoning attacks. Existing defense techniques are largely attack-rigid: they are designed to recognize client properties or model updates directly, aimed at specific attack scenarios or rules, but may not work well for critical feature patterns or flexible attack methods, mainly due to the potential influence of redundant features and model performance on defense. Yet few flexible defense methods have been developed. In this paper, we propose FlexibleFL, a flexible defense method against poisoning attacks in cloud-edge federated learning system (CEFL). The key idea of FlexibleFL is to evaluate the quality of uploaded model parameters and further determine the contribution of participants through an optimal threshold selection strategy. Based on these differences, FlexibleFL can thus implement penalties to potential attackers in a way that involves assigning the updated federated model. Extensive results demonstrate that our method has significant advantages in countering poisoning attacks in IID and Non-IID scenarios, and can effectively protect CEFL systems.},
  archive      = {J_ISCI},
  author       = {Yaru Zhao and Yihao Cao and Jianbiao Zhang and Haoxiang Huang and Yanhui Liu},
  doi          = {10.1016/j.ins.2024.120350},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120350},
  shortjournal = {Inf. Sci.},
  title        = {FlexibleFL: Mitigating poisoning attacks with contributions in cloud-edge federated learning systems},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-path target-aware contrastive regression for action
quality assessment. <em>ISCI</em>, <em>664</em>, 120347. (<a
href="https://doi.org/10.1016/j.ins.2024.120347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action quality assessment (AQA) is a challenging vision task due to the complexity and variance of the scoring rules embedded in the videos. Recent approaches have reduced the prediction difficulty of AQA via learning action differences between videos, but there are still challenges in learning scoring rules and capturing feature differences. To address these challenges, we propose a two-path target-aware contrastive regression (T 2 CR) framework. We propose to fuse direct and contrastive regression and exploit the consistency of information across multiple visual fields. Specifically, we first directly learn the relational mapping between global video features and scoring rules, which builds occupational domain prior knowledge to better capture local differences between videos. Then, we acquire the auxiliary visual fields of the videos through sparse sampling to learn the commonality of feature representations in multiple visual fields and eliminate the effect of subjective noise from a single visual field. To demonstrate the effectiveness of T 2 CR, we conduct extensive experiments on four AQA datasets (MTL-AQA, FineDiving, AQA-7, JIGSAWS). Our method is superior to state-of-the-art methods without elaborate structural design and fine-grained information.},
  archive      = {J_ISCI},
  author       = {Xiao Ke and Huangbiao Xu and Xiaofeng Lin and Wenzhong Guo},
  doi          = {10.1016/j.ins.2024.120347},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120347},
  shortjournal = {Inf. Sci.},
  title        = {Two-path target-aware contrastive regression for action quality assessment},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Resource-aware multi-criteria vehicle participation for
federated learning in internet of vehicles. <em>ISCI</em>, <em>664</em>,
120344. (<a href="https://doi.org/10.1016/j.ins.2024.120344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL), as a safe distributed training mode, provides strong support for the edge intelligence of the Internet of Vehicles (IoV) to realize efficient collaborative control and safe data sharing. However, due to the resource limitation and the instability of training environment in the complex IoV, ideal performance of FL cannot be achieved. Since considering the actual resource constraints and federated task requirements, the diversified device selection criteria make the resource-aware vehicle selection problem become a multi-criteria selection problem. To effectively support FL for IoV, the resource-aware multi-criteria vehicle selection problem was described as a many-objective optimization problem, and a resource-aware many-objective vehicle selection model (RA-MaOVSM) is proposed to optimize resource efficiency. The RA-MaOVSM considering heterogeneous resources (like computation resources, communication resources, energy resources and data resources) of on-board devices in IoV, and realizes the joint optimization of learning efficiency, energy cost and global performance. Additionally, a novel probability distribution combination game strategy is applied to many-objective evolutionary algorithm (MaOEA) for improving the model solving performance. Simulation results demonstrate that RA-MaOVSM can effectively optimize the IoV resources and FL model performance, and the designed algorithm exhibits good convergence and distribution, achieving a good balance among multiple device selection criteria.},
  archive      = {J_ISCI},
  author       = {Jie Wen and Jingbo Zhang and Zhixia Zhang and Zhihua Cui and Xingjuan Cai and Jinjun Chen},
  doi          = {10.1016/j.ins.2024.120344},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120344},
  shortjournal = {Inf. Sci.},
  title        = {Resource-aware multi-criteria vehicle participation for federated learning in internet of vehicles},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CRmod: Context-aware rule-guided reasoning over temporal
knowledge graph. <em>ISCI</em>, <em>664</em>, 120343. (<a
href="https://doi.org/10.1016/j.ins.2024.120343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge graphs have been widely used in artificial intelligence, but they are still incomplete. Therefore, the reasoning task is still a research hotspot. The existing temporal knowledge graph reasoning methods are mainly based on embedding. These methods do not take the textual information of entities and relations into account, making the reasoning results not relevant. Besides, other reasoning methods ignore interpretable logic rules. To improve reasoning results relevance and interpretability, we propose the temporal knowledge graph reasoning model CRmod ( C ontext-aware R ule-guided mod el). Through the confidence of contextual neighbors and the relevance of different neighbor 4-tuples, CRmod takes context information into account and improves the relevance of reasoning results. At the same time, considering the diversity of path rules, six temporal logic rules are proposed. Besides, time information consistency of temporal logic rules is constrained, which achieves the effect of real-time reasoning. We evaluated our model on three datasets: ICEWS18, ICEWS05-15, and GDELT. Specifically, in the experimental results concerning the Mean Reciprocal Rank (MRR) metric on the ICEWS18 and ICEWS05-15 datasets, our model showed improvements over the previous State-Of-The-Art (SOTA) models by 3.24% and 16.88%, respectively. Experiments show that CRmod does improve the relevance and interpretability of the reasoning results compared with the existing temporal knowledge graph reasoning models.},
  archive      = {J_ISCI},
  author       = {Lin Zhu and Die Chai and Luyi Bai},
  doi          = {10.1016/j.ins.2024.120343},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120343},
  shortjournal = {Inf. Sci.},
  title        = {CRmod: Context-aware rule-guided reasoning over temporal knowledge graph},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Output feedback containment fuzzy control for multi-agent
systems with quantitative input and tunable reference signals.
<em>ISCI</em>, <em>664</em>, 120340. (<a
href="https://doi.org/10.1016/j.ins.2024.120340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For multi-agent systems with quantitative input, we propose a novel containment control scheme to guarantee that the agents can enter a convex hull generated by the leader&#39;s signals after starting from any initial position. The problem with existing schemes is that the reference signals of the agents are affected by the communication topology such that the position of the reference signal cannot be changed when this communication topology is determined. To solve this problem, the proposed scheme can generate a flexible and adjustable reference signal for each agent. This has the advantage of reducing the probability of collisions among agents. Meanwhile, to address the situation where some agents cannot receive reference signals, we design an estimator to generate an adjustable estimation signal for each specific agent to ensure that all agents continue moving within the convex hull. In addition, by combining the fuzzy observer with the command filter design method, we devise a novel controller design scheme for quantitative input, which ensures that all signals in closed-loop multi-agent systems are uniformly and ultimately bounded. Finally, the simulation results demonstrate the feasibility and superiority of the proposed scheme for controlling multi-agent systems.},
  archive      = {J_ISCI},
  author       = {Mengyi Jiang and Yonghui Yang and Chuang Gao and Libing Wu and Anatolii K. Pogodaev},
  doi          = {10.1016/j.ins.2024.120340},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120340},
  shortjournal = {Inf. Sci.},
  title        = {Output feedback containment fuzzy control for multi-agent systems with quantitative input and tunable reference signals},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A self-organizing assisted multi-task algorithm for
constrained multi-objective optimization problems. <em>ISCI</em>,
<em>664</em>, 120339. (<a
href="https://doi.org/10.1016/j.ins.2024.120339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems (CMOPs) require a delicate balance between satisfying constraints and optimizing objectives. Existing constrained multi-objective evolutionary algorithms (CMOEAs) often struggle to balance convergence, diversity, and feasibility, especially when dealing with CMOPs that have complex feasible regions. This paper proposes a multi-task-based self-organizing mapping evolutionary algorithm (MTSOM) to tackle this challenge, which includes a main and auxiliary task. Two populations independently optimize two tasks without considering constraints in the early stage. Subsequently, in the middle stage, both tasks explore the distribution structure of the population in parallel by employing a novel constraint-to-constraint self-organizing mapping (SOM) approach. In the late stage, the main task fully considers feasibility, while the auxiliary task focuses solely on the highest priority constraints. This approach enables rapid convergence toward feasible regions. To evaluate MTSOM’s effectiveness, we conducted a series of experiments on five benchmark suites. Results indicate that MTSOM is competitive when compared to other state-of-the-art CMOEAs. Additionally, our proposed constraint-to-constraint SOM is superior in handling complex CMOPs.},
  archive      = {J_ISCI},
  author       = {Qianlin Ye and Wanliang Wang and Guoqing Li and Rui Dai},
  doi          = {10.1016/j.ins.2024.120339},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120339},
  shortjournal = {Inf. Sci.},
  title        = {A self-organizing assisted multi-task algorithm for constrained multi-objective optimization problems},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time mittag-leffler synchronization of delayed
fractional-order discrete-time complex-valued genetic regulatory
networks: Decomposition and direct approaches. <em>ISCI</em>,
<em>664</em>, 120337. (<a
href="https://doi.org/10.1016/j.ins.2024.120337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex-valued molecular model of mRNA and protein plays a crucial role in the regulatory mechanisms governing gene expression in the genetic regulatory network (GRN). In this study, we introduced a novel GRN utilizing the fractional-order discrete-time complex-valued molecular model of mRNA and protein. Both decomposition and a direct approach are employed to investigate the nonlinear regulatory function within complex-valued molecular models. New conditions are established to ensure the finite-time Mittag-Leffler synchronization (FTMLS) of the error model dynamics. Feedback controllers are applied to derive the FTMLS conditions for delayed fractional-order discrete-time complex-valued genetic regulatory networks (DFDTCVGRNs). By applying the first-order backward difference on the Lyapunov functional under the definition of fractional Caputo difference and fractional calculus theory, sufficient conditions are derived. Finally, two numerical examples are provided to illustrate the FTMLS criteria obtained.},
  archive      = {J_ISCI},
  author       = {Mourad Kchaou and G. Narayanan and M. Syed Ali and Sumaya Sanober and Grienggrai Rajchakit and Bandana Priya},
  doi          = {10.1016/j.ins.2024.120337},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120337},
  shortjournal = {Inf. Sci.},
  title        = {Finite-time mittag-leffler synchronization of delayed fractional-order discrete-time complex-valued genetic regulatory networks: Decomposition and direct approaches},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). View-specific anchors coupled tensorial bipartite graph
learning for incomplete multi-view clustering. <em>ISCI</em>,
<em>664</em>, 120335. (<a
href="https://doi.org/10.1016/j.ins.2024.120335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incomplete multi-view clustering (IMVC) aims to explore the consensus and complementary information embedded in incomplete multi-view data, so as to accurately aggregate all samples into different clusters. Existing IMVC methods still have the following issues that need to be further solved: how to efficiently (1) alleviate the computational complexity; (2) capture the complementary information from views; (3) uncover the high-order correlations underlying incomplete multi-view data. To address these problems, a new method, called view-specific anchors coupled tensorial bipartite graph learning for incomplete multi-view clustering (VA-TBGIMC), is proposed in this paper. Specifically, view-specific anchors are learned from non-missing samples to represent the distribution of all samples including missing ones. With the help of high-quality anchors, the bipartite graph between all samples and anchors is constructed, which can preserve the complementary information. Meanwhile, these bipartite graphs are stacked into a tensor which is imposed with a low-rank constraint to adequately capture the inter-view and inter-sample correlations from incomplete multi-view data. Further, the augmented graph of bipartite graph is constrained by Laplacian rank to learn a consensus cluster indicator. A large number of experiments validate the superiority and efficiency of the proposed method in terms of clustering performance and time consumption.},
  archive      = {J_ISCI},
  author       = {Xuemei Han and Fei Zhou and Zhenwen Ren and Xueyuan Wang and Xiaojian You},
  doi          = {10.1016/j.ins.2024.120335},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120335},
  shortjournal = {Inf. Sci.},
  title        = {View-specific anchors coupled tensorial bipartite graph learning for incomplete multi-view clustering},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New uncertainty measurement for hybrid data and its
application in attribute reduction. <em>ISCI</em>, <em>664</em>, 120334.
(<a href="https://doi.org/10.1016/j.ins.2024.120334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to limitations in data acquisition, data in real life often contains a wealth of uncertain information. Uncertainty measurement (UM) constructed within the framework of rough set theory (RST) is an important tool for processing uncertain information. Some basic UMs in RST such as classification precision, rough membership degree, dependence degree, and attribute importance cannot accurately measure the uncertainty of a hybrid information system (HIS). For example, dependence degree only considers the information provided by the lower approximation of the decision and ignores the upper approximation, which may lead to some information loss. In addition to these basic UMs, some extended entropy-based UMs such as rough entropy, information entropy and conditional entropy are also frequently used to measure the uncertainty of a HIS. However, these three UMs also have their own drawbacks. For instance, rough entropy is sensitive to the distribution of hybrid data. When the distribution of hybrid data is uneven, the calculation results of rough entropy may be greatly affected, leading to a decrease in measurement accuracy. This paper proposes four new UMs in a HIS and provides an application in attribute reduction. First of all, a distance function is defined to deal with each type of attribute in a HIS and construct a tolerance relation. On this basis, four UMs are listed to measure the uncertainty of a HIS. Next, the strength and weakness of the proposed UMs are verified by statistical analysis. Subsequently, the UM with the best performance is selected to design an attribute reduction algorithm. Finally, the designed algorithm is compared with other five attribute reduction algorithms to show its superior performance.},
  archive      = {J_ISCI},
  author       = {Haixin Huang and Zhaowen Li and Fang Liu and Ching-Feng Wen},
  doi          = {10.1016/j.ins.2024.120334},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120334},
  shortjournal = {Inf. Sci.},
  title        = {New uncertainty measurement for hybrid data and its application in attribute reduction},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Statistical tests for multiplicative consistency of fuzzy
preference relations: A monte carlo simulation. <em>ISCI</em>,
<em>664</em>, 120333. (<a
href="https://doi.org/10.1016/j.ins.2024.120333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy preference relation (FPR) models the preference information provided by decision-makers using pairwise comparison of alternatives. The extant consistency test of FPRs, as a premise of expert opinions aggregation, suffers from the rule unfairness problem in different cases. Specifically, it is too loose in the lower-order cases and too strict in the higher-order cases. To address this issue, two statistical tests for the multiplicative consistency of FPRs are proposed. Based on multiplicative transitivity, an indirect average-based consistency index is proposed to allow for perturbed weights without an arbitrary choice of the weight derivation approach. This improves the robustness of the analysis of the consistency of the FPRs as results for a particular FPR no longer depend on the choice of the weight derivation approach. Moreover, the Monte Carlo simulation is applied to derive the sampling distribution of the indirect average-based consistency index. Two multiplicative consistency tests for the FPRs are proposed. In this context, the probabilities of Type I and Type II errors are governed by significance levels. Finally, the numerical examples and comparative analysis illustrate the effectiveness of the proposed consistency tests.},
  archive      = {J_ISCI},
  author       = {Dandan Luo and Chonghui Zhang and Weihua Su and Shouzhen Zeng and Tomas Balezentis},
  doi          = {10.1016/j.ins.2024.120333},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120333},
  shortjournal = {Inf. Sci.},
  title        = {Statistical tests for multiplicative consistency of fuzzy preference relations: A monte carlo simulation},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A logic-based framework for characterizing nexus of
similarity within knowledge bases. <em>ISCI</em>, <em>664</em>, 120331.
(<a href="https://doi.org/10.1016/j.ins.2024.120331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similarities play a pivotal role in diverse real-world scenarios, driving extensive research into methodologies for measuring entity similarity and expanding sets of entities with similar ones. Machines are nowadays adept at performing these tasks by taking in some regard relevant interconnected properties shared by entities, which we term nexus of similarity . To the best of our knowledge, however, there lacks a general logic-based framework for ‘characterizing’ nexus of similarity between (tuples of) entities within a given relational knowledge base represented via some arbitrary formalism. Essentially, there is no way to formally express such nexus in a comprehensive and concise manner, making them understandable to both machines and humans. Moreover, the classical notion of expanding a set of entities overlooks the inherent human tendency to naturally generalize entities in a taxonomic way. In light of what was discussed above, we introduce the novel notion of selective knowledge base , denoted by S = ( K , ς ) S=(K,ς) , designed to enhance any pre-existing relational knowledge base K with a summary selector ς . For any tuple τ of entities, ς selects a relevant portion of the knowledge entailed by K that describes τ . Subsequently, we design a nexus explanation language , called N C F NCF , with an associated semantics. This allows us to delve into the task of explaining and characterizing the nexus of similarity among (tuples of) entities within a selective knowledge base. Then, we introduce the notions of explanation , characterization , canonical characterization , and core characterization , demonstrating that they always exist and are computable. Furthermore, we introduce the notions of essential expansion and expansion graph , formally generalizing the classical notion of linear expansions by showcasing that expansions are naturally taxonomic. We also study key reasoning tasks related to the computation of characterizations and expansions, and analyze their tractability under various computational assumptions. Finally, we contextualize our framework within the existing literature by exploring related technical problems, analyze our design choices in a critical way, and investigate the adaptability and effectiveness of our approach in real-world scenarios.},
  archive      = {J_ISCI},
  author       = {Giovanni Amendola and Marco Manna and Aldo Ricioppo},
  doi          = {10.1016/j.ins.2024.120331},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120331},
  shortjournal = {Inf. Sci.},
  title        = {A logic-based framework for characterizing nexus of similarity within knowledge bases},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An incentive mechanism design for federated learning with
multiple task publishers by contract theory approach. <em>ISCI</em>,
<em>664</em>, 120330. (<a
href="https://doi.org/10.1016/j.ins.2024.120330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of model training of the federated learning system, how to design an incentive mechanism to attract more high-quality worker nodes to join is a key issue. The existing researches on federated learning incentive mechanism only consider the scenario of single task publisher with multiple worker nodes. In the scenario of multi task publishers and multiple worker nodes, the competition between different task publishers makes the entire research process more complicated, and the contract design in the single task publisher scenario cannot be directly applied. To solve this problem, this paper proposes an incentive mechanism based on contract theory in the multi task publisher scenario and studies its application in federated learning. Simulation experiments show that this mechanism is effective for federated learning and can achieve the purpose of encouraging worker nodes to join and improve the efficiency of federated learning.},
  archive      = {J_ISCI},
  author       = {Shichang Xuan and Mengda Wang and Jingyi Zhang and Wei Wang and Dapeng Man and Wu Yang},
  doi          = {10.1016/j.ins.2024.120330},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120330},
  shortjournal = {Inf. Sci.},
  title        = {An incentive mechanism design for federated learning with multiple task publishers by contract theory approach},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). A trust active and trace back based trust management system
about effective data collection for mobile IoT services. <em>ISCI</em>,
<em>664</em>, 120329. (<a
href="https://doi.org/10.1016/j.ins.2024.120329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Crowdsensing (MCs) is a widely applicable and inexpensive data-obtaining method that leverages mobile devices to sense and report data without deploying sensors. The rapid development of the Integration of IoT systems, as well as the widespread use of communication satellites, make MCs further develop and receive extensive attention from researchers. One key issue is how to ensure the reliability of the reported data to avoid the presence of malicious participants leading to poor IoT service quality. In this paper, we proposed an Active and Trace Back based Trust Management (ATBTM) algorithm to evaluate the trust of participants and handle malicious participants. The main innovations are: (1) An active trust evaluation approach for MCs is proposed, which uses an Unmanned Aerial Vehicle (UAV) to collect data as a baseline to verify the reliability of the data reported by participants. Then, the data reported by high reputation participants can also be used as a sub-baseline to verify the trust of some participants. (2) A traceback based trust evaluation method is also proposed. In this approach, some reliable devices provide historical sensing data that has been collected but not reported. Then the system compares it to real data with corresponding timestamps to evaluate the trust of other participants. Sufficient theoretical analysis and experimental results demonstrate that the proposed ATBTM framework can effectively identify the malicious workers, and conquer the drawbacks of lacking trust evaluation method in existed MCs.},
  archive      = {J_ISCI},
  author       = {Rui Zhang and Anfeng Liu and Tian Wang and Neal N. Xiong and Athanasios V. Vasilakos},
  doi          = {10.1016/j.ins.2024.120329},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120329},
  shortjournal = {Inf. Sci.},
  title        = {A trust active and trace back based trust management system about effective data collection for mobile IoT services},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Selection of sustainable food suppliers using the
pythagorean fuzzy CRITIC-MARCOS method. <em>ISCI</em>, <em>664</em>,
120326. (<a href="https://doi.org/10.1016/j.ins.2024.120326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustainable food supplier selection (SFSS) can be handled as an uncertain decision-making issue. The Pythagorean fuzzy set (PFS), a type of non-standard fuzzy set, offers an expanded description space for articulating fuzzy and uncertain data. Accordingly, this paper proposes a Pythagorean fuzzy synthetic decision method-based selection framework for solving the SFSS problem within a subjective context. Then, the weighted distance measures for the PFS are introduced to derive the importance degrees of the experts, which can provide a more objective decision result. Then, an information fusion method with a PFS-weighted power average (WPA) operator is introduced to form a group decision matrix competent to accommodate the deviation effect. Next, an extended PF-measurement of alternatives and ranking according to compromise solution (MARCOS) method integrating PF-criteria importance through inter-criteria correlation (CRITIC) is presented to calculate the priority of each supplier, which can capture the inter-correlations between criteria. Finally, a numerical example of SFSS is implemented to show the application of the proposed synthetic decision approach. Subsequently, the sensitivity analysis of distance parameters and comparison analysis among different SFSS approaches were conducted to test the rationality and advantages of the proposed framework for resolving the SFSS problem. The results show that the reported method can provide a practical way to resolve the SFSS problems with uncertain data.},
  archive      = {J_ISCI},
  author       = {Yi Wang and Weizhong Wang and Zelin Wang and Muhammet Deveci and Sankar Kumar Roy and Seifedine Kadry},
  doi          = {10.1016/j.ins.2024.120326},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120326},
  shortjournal = {Inf. Sci.},
  title        = {Selection of sustainable food suppliers using the pythagorean fuzzy CRITIC-MARCOS method},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-attribute decision-making based on picture fuzzy
distance measure-based relative closeness coefficients and modified
combined compromise solution method. <em>ISCI</em>, <em>664</em>,
120325. (<a href="https://doi.org/10.1016/j.ins.2024.120325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new distance measure between picture fuzzy sets (PFSs) to overcome the drawbacks of the existing distance measures between PFSs. We also propose a weight-determination method to determine attributes’ weights using the proposed distance measure between PFSs. We also propose a novel multi-attribute decision-making (MADM) method on the basis of the proposed distance measure between PFSs and the modified combined compromise solution (CoCoSo) method. The proposed MADM method can overcome the drawbacks of the existing MADM methods based on PFSs. It gives us a very useful way for MADM in picture fuzzy environments.},
  archive      = {J_ISCI},
  author       = {Arunodaya Raj Mishra and Shyi-Ming Chen and Pratibha Rani},
  doi          = {10.1016/j.ins.2024.120325},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120325},
  shortjournal = {Inf. Sci.},
  title        = {Multi-attribute decision-making based on picture fuzzy distance measure-based relative closeness coefficients and modified combined compromise solution method},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time and memory scalable algorithms for clustering tendency
assessment of big data. <em>ISCI</em>, <em>664</em>, 120324. (<a
href="https://doi.org/10.1016/j.ins.2024.120324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-volume and high-dimensional big datasets are being generated quickly. They are expected to provide data-driven solutions for various pressing challenges such as cybersecurity, credit card fraud, network intrusion detection, etc. The visual assessment of clustering tendency (VAT) family of algorithms provides an excellent tool for assessing clustering tendency and subsequent clustering of these novel datasets to extract groups and anomalies to better understand the data generation phenomenon. However, VAT and improved VAT (iVAT) algorithms are plagued with O ( n 2 ) O(n2) time and space complexity as they use Prim&#39;s algorithm for building Euclidean minimum spanning tree (EMST) of the data points, leaving it inapplicable to large datasets. This paper develops three novel time- and memory-scalable algorithms for fast computation of VAT EMST by reducing the search space of the following possible EMST edge and using an efficient data structure, the k-d tree. Next, we develop a novel approach to compute iVAT reordered dissimilarity image (RDI) in a novel memory-preserving manner using the EMST edge lengths calculated previously without having to compute memory intensive n × n n×n VAT RDI. We experimented on several synthetic and real-life datasets to showcase that the proposed approaches can help quickly assess their clustering tendency in a memory-saving manner. We also demonstrate the applicability of the proposed methods for the anomaly detection task in large volumes of high-dimensional data.},
  archive      = {J_ISCI},
  author       = {Kartik Vishal Deshpande and Dheeraj Kumar},
  doi          = {10.1016/j.ins.2024.120324},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120324},
  shortjournal = {Inf. Sci.},
  title        = {Time and memory scalable algorithms for clustering tendency assessment of big data},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DIGWO-n-BEATS: An evolutionary time series prediction method
for situation prediction. <em>ISCI</em>, <em>664</em>, 120316. (<a
href="https://doi.org/10.1016/j.ins.2024.120316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Situation awareness is a key technology in many decision systems, but its performance bottleneck in the third step, namely situation prediction, has not been overcome yet. This step involves time series prediction and commonly uses deep learning methods. However, there are significant performance differences among these methods, and the tuning of their hyperparameters has not been thoroughly investigated. To address these challenges, a novel prediction method named Distributed Improved Gray Wolf Optimizer-Neural Basis Expansion Analysis for Time-Series (DIGWO-N-BEATS) is proposed for situation prediction tasks. First, an architecture based on N-BEATS, which is a cutting-edge paradigm, is formulated for modeling situation value time series. Second, a novel improved evolutionary algorithm, which can converge in parallel, is proposed to optimize thirteen hyperparameters and the model structures of N-BEATS. The experiment results demonstrate that DIGWO-N-BEATS outperforms the six most competitive baselines, reducing the average MAPE on two real-world situation awareness datasets and two time-series prediction datasets by 8.18%, 1.12%, 9.92%, and 4.98%, respectively. Furthermore, DIGWO-N-BEATS exhibits good convergence in hyperparameter optimization tasks and scalability.},
  archive      = {J_ISCI},
  author       = {Hao Lin and Chundong Wang},
  doi          = {10.1016/j.ins.2024.120316},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120316},
  shortjournal = {Inf. Sci.},
  title        = {DIGWO-N-BEATS: An evolutionary time series prediction method for situation prediction},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The multi-task transfer learning for multiple data streams
with uncertain data. <em>ISCI</em>, <em>664</em>, 120314. (<a
href="https://doi.org/10.1016/j.ins.2024.120314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In existing research on data streams, most problems are processed and studied based on single data streams. However, there exist multiple data streams and the reaching data may contain noise information which is considered uncertain in representation. In this paper, we propose the multi-task transfer learning for multiple data streams with uncertain data (MTUMDS), which can make use of the similarity of multiple data streams to carry out multi-task learning that can improve the classification ability of the data stream model. At the same time, transfer learning is applied for each single data stream, which transfers knowledge from the known classifiers of the previous time windows to the current target window classifier. This can settle the situation that the concept drift causes model fitness reduction. Then, in view of the noise and collection error hidden in the real data, boundary constraints are generated for each sample to build the SVM classifier to solve the uncertainty of the data. A large number of experiments in multiple data streams show that our approach has better performance and robustness than previous studies.},
  archive      = {J_ISCI},
  author       = {Bo Liu and Yongsheng Huang and Yanshan Xiao and Zhiyu Zheng and Peng Sun and Shilei Zhao and Xiaokai Li and Tiantian Peng},
  doi          = {10.1016/j.ins.2024.120314},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120314},
  shortjournal = {Inf. Sci.},
  title        = {The multi-task transfer learning for multiple data streams with uncertain data},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed model free adaptive fault-tolerant consensus
tracking control for multiagent systems with actuator faults.
<em>ISCI</em>, <em>664</em>, 120313. (<a
href="https://doi.org/10.1016/j.ins.2024.120313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The model free fault-tolerant consensus tracking control problem is studied for the multiagent systems with actuator faults. To reduce the impact of fault, an adaptive estimation law is developed to estimate the fault information online, which doesn&#39;t need an additional training and can reduce the computational cost. With the help of the adaptive fault compensation, a distributed model free adaptive fault-tolerant consensus tracking mechanism is designed to guarantee that agents are able to track the expected signal. Furthermore, only the input/output data of agents are employed throughout the design process, the system dynamics are not required. The effectiveness of developed approach is illustrated through the simulation examples.},
  archive      = {J_ISCI},
  author       = {Yuan Wang and Zhanshan Wang},
  doi          = {10.1016/j.ins.2024.120313},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120313},
  shortjournal = {Inf. Sci.},
  title        = {Distributed model free adaptive fault-tolerant consensus tracking control for multiagent systems with actuator faults},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal matching-aware co-attention networks with mutual
knowledge distillation for fake news detection. <em>ISCI</em>,
<em>664</em>, 120310. (<a
href="https://doi.org/10.1016/j.ins.2024.120310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news often involves multimedia information such as text and image to mislead readers, proliferating and expanding its influence. Most existing fake news detection methods apply the co-attention mechanism to fuse multimodal features while ignoring the consistency of image and text in co-attention. In this paper, we propose multimodal matching-aware co-attention networks with mutual knowledge distillation for improving fake news detection. Specifically, we design an image-text matching-aware co-attention mechanism which captures the alignment of image and text for better multimodal fusion. The image-text matching representation can be obtained via a vision-language pre-trained model. Additionally, based on the designed image-text matching-aware co-attention mechanism, we propose to build two co-attention networks respectively centered on text and image for mutual knowledge distillation to improve fake news detection. Extensive experiments on three benchmark datasets demonstrate that our proposed model outperforms existing methods on multimodal fake news detection.},
  archive      = {J_ISCI},
  author       = {Linmei Hu and Ziwang Zhao and Weijian Qi and Xuemeng Song and Liqiang Nie},
  doi          = {10.1016/j.ins.2024.120310},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120310},
  shortjournal = {Inf. Sci.},
  title        = {Multimodal matching-aware co-attention networks with mutual knowledge distillation for fake news detection},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transformation and learning of the non-equidimensional
hesitant fuzzy information based on an extended generative adversarial
network. <em>ISCI</em>, <em>664</em>, 120307. (<a
href="https://doi.org/10.1016/j.ins.2024.120307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the subjective evaluation process, the hesitant fuzzy set (HFS), as a convenient and robust presentation tool, cannot only suitably address the decision makers’ (DMs’) or experts’ hesitant and uncertain issues but also can arise the dimension curse puzzle. Furthermore, the decision-making result is just derived according to the given objective and subjective information, without considering the DM’s subjective evaluation and the environment’s dynamic influence. Unlike the previous studies, this paper tries to address them from the deep learning viewpoint. To this end, we first define the non-equidimensional HFS (NHFS) and then introduce the equidimensional and classification characters into the NHFS to further develop the equidimensional HFS (EHFS) and the EHFS with the optimal classification result. Then, the equidimensional hesitant fuzzy-generative adversarial network (EHF-GAN) model is proposed to transform the hesitant fuzzy information from the non-equidimensional to the equidimensional form. The generalization and the convergence of the new model are proven to show the models’ reasonability. In addition, the double-learning algorithm of the EHF-GAN model is designed, which can fuse the DMs’ dynamic judgments and derive the optimal decision-making results. Lastly, this paper applies the proposed model and algorithm to an illustrative example of the new smart city enterprises and then shows their feasibility and effectiveness.},
  archive      = {J_ISCI},
  author       = {Man Liu and Wei Zhou and Zeshui Xu},
  doi          = {10.1016/j.ins.2024.120307},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120307},
  shortjournal = {Inf. Sci.},
  title        = {Transformation and learning of the non-equidimensional hesitant fuzzy information based on an extended generative adversarial network},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accurate multi-view clustering to seek the cross-viewed yet
uniform sample assignment via tensor feature matching. <em>ISCI</em>,
<em>664</em>, 120305. (<a
href="https://doi.org/10.1016/j.ins.2024.120305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering has become one of the popular clustering branches with data accumulation from multiple domains. Unfortunately, a large heterogeneity gap exists due to cross-view discrepancy, resulting in inaccurate sample-wise similarity estimation. Furthermore, the popular multi-view clustering methods heavily rely on sample-wise similarity measurements, which often lead to suboptimal clustering performance due to inaccurate similarity estimation across views. To tackle these challenges, this paper presents an accurate multi-view clustering method from a standpoint of inter-view feature-wise matching to bypass the inaccurate sample-wise similarity that leverages tensor feature matching for cross-viewed yet uniform sample assignment, named by multi-view clustering via tensor feature matching (MC-TFM). Specifically, our approach begins with exploring a comprehensive feature matching tensor by exploiting both intra-view and inter-view correlations among multi-view features. Subsequently, a feature matching matrix, which preserves the correlations and importance of multi-view features for guiding the cross-viewed yet uniform sample assignment, is estimated based on this tensor. Furthermore, these correlations and importance are maintained into two coded feature bases by decomposing the feature matching matrix. Finally, a sample assignment matrix is learned via jointly reconstructing the samples using the two bases further cooperating with spectral clustering. In this way, the heterogeneity gap is bridged by tensor feature matching, and the inaccurate sample-wise similarity estimation is omitted by using feature-wise matching to guide sample-wise assignment. Extensive experiments conducted on seven real-world datasets highlight the effectiveness of the cross-viewed yet uniform sample assignment, demonstrating the potential of our approach in accurate multi-view clustering tasks.},
  archive      = {J_ISCI},
  author       = {Yue Zhang and Wuxiu Quan and Tatsuya Akutsu and Li Liu and Hongmin Cai and Bin Zhang},
  doi          = {10.1016/j.ins.2024.120305},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120305},
  shortjournal = {Inf. Sci.},
  title        = {Accurate multi-view clustering to seek the cross-viewed yet uniform sample assignment via tensor feature matching},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Logical activation functions for training arbitrary
probabilistic boolean operations. <em>ISCI</em>, <em>664</em>, 120304.
(<a href="https://doi.org/10.1016/j.ins.2024.120304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we introduce a family of novel activation functions for deep neural networks that approximate n-ary, or n-argument, probabilistic logic. Logic has long been used to encode complex relationships between claims that are either true or false. Thus, these activation functions provide a step towards models that can efficiently encode information. Unfortunately, typical feedforward networks with elementwise activation functions cannot capture certain relationships succinctly, such as the exclusive disjunction (p xor q) and conditioned disjunction (if c then p else q). Our n-ary activation functions address this challenge by approximating belief functions (probabilistic Boolean logic) with logit representations of probability and experiments demonstrate the ability to learn arbitrary logical ground truths in a single layer. Further, by representing belief tables using a basis that associates the number of nonzero parameters with the effective arity of each belief function, we forge a concrete relationship between logical complexity and sparsity, thus opening new optimization approaches to suppress logical complexity during training. We provide a computationally efficient PyTorch implementation and test our activation functions against other logic-approximating activation functions on both traditional machine learning tasks as well as reproducing known logical relationships.},
  archive      = {J_ISCI},
  author       = {Jed A. Duersch and Tommie A. Catanach and Niladri Das},
  doi          = {10.1016/j.ins.2024.120304},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120304},
  shortjournal = {Inf. Sci.},
  title        = {Logical activation functions for training arbitrary probabilistic boolean operations},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust supervisory control for automated manufacturing
systems with unreliable resources by analyzing reachable state space.
<em>ISCI</em>, <em>664</em>, 120258. (<a
href="https://doi.org/10.1016/j.ins.2024.120258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust supervisory control is an important issue for automated manufacturing systems (AMSs) with multiple unreliable resources. This study uses Petri nets to model failure-prone AMSs with multi-unit and multi-type resource acquisitions and releases. First, we propose the necessary and sufficient condition for the robustness of a supervisor. Then, two kinds of states, namely blocking-markings (BMs) and result-in-BMs (RBMs), are found to cause blocking during system operation, and further they are defined precisely based on the structure perfect activity circuit (PAC) in Petri net model. An algorithm of polynomial complexity is presented to determine whether a BM or RBM is co-reachable from a non-BM or non-RBM. By the aid of this algorithm, we compute the reduced state space that does not contain any BM or RBM without enumerating each reachable state. Based on the reduced state space, an optimal robust supervisor is established, not only guaranteeing the continuous production of all job types even if some resources fail, but also having the most reachable states. Some experiments are used to validate the effectiveness and efficiency of the proposed method.},
  archive      = {J_ISCI},
  author       = {Yanxiang Feng and Sida Ren and Xiaoling Li and Ye Cao and Yikang Yang},
  doi          = {10.1016/j.ins.2024.120258},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120258},
  shortjournal = {Inf. Sci.},
  title        = {Robust supervisory control for automated manufacturing systems with unreliable resources by analyzing reachable state space},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). The quantum secret sharing schemes based on hyperstar
access structures. <em>ISCI</em>, <em>664</em>, 120202. (<a
href="https://doi.org/10.1016/j.ins.2024.120202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss in some detail how the quantum secret sharing schemes based on a class of irregular quantum network structures are designed, where these structures are consisting of hyperstar access structures with three hyper-edges. Firstly, two kinds of classical secret sharing schemes are explicitly established for these irregular network structures. Moreover, these shares from the participants in these classical secret sharing schemes are implemented by the quantum secret sharing scheme, i.e. the parameters of the unitary transformation used in the quantum secret sharing schemes are shares of the corresponding participants in these classical secret sharing schemes. Since these schemes are constructed based on the irregular network structures with the optimal information rate, these constructed quantum secret sharing schemes also have the highest efficiency. Meanwhile, the identity authentication of these protocols ensures their security, making these schemes feasible and more practical using current technology.},
  archive      = {J_ISCI},
  author       = {Lei Li and Zhi Li},
  doi          = {10.1016/j.ins.2024.120202},
  journal      = {Information Sciences},
  month        = {4},
  pages        = {120202},
  shortjournal = {Inf. Sci.},
  title        = {The quantum secret sharing schemes based on hyperstar access structures},
  volume       = {664},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel TODIM-based multi-attribute decision making method
under information described by z-numbers for selecting online b&amp;b.
<em>ISCI</em>, <em>663</em>, 120315. (<a
href="https://doi.org/10.1016/j.ins.2024.120315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study designs a new TODIM-based multi-attribute decision making (MADM) method under information described by Z -numbers for selecting online Bed and Breakfast (B&amp;B), which includes extracting the evaluation attributes and obtaining the best online B&amp;B. To do that, first the fine-tuned Bidirectional Encoder Representation from Transformers (BERT) model is used to analyze the sentiment of all online reviews from nine regions of Airbnb, which these reviews about online B&amp;Bs are divided into positive and negative comments. And then Term Frequency-Inverse Document Frequency (TF-IDF) is used to extract attribute feature words of positive and negative comments. Their intersection is sought to determine the attributes of the tourists&#39; online B&amp;B selection. Next, the ranking technique of Z -number and the distance of Z -number are put forward. Finally, a novel TODIM-based MADM method under information described by Z -numbers is proposed to select the B&amp;Bs by the online review of B&amp;Bs obtained from Ctrip.com. The advantage of this method is that it not only considers the reliability of online reviews, but also reflects the psychological factors of tourists. The feasibility of the proposed method is illustrated by ranking the B&amp;Bs, and the flexibility and superiority of the method are highlighted by the sensitivity analysis and comparative analysis.},
  archive      = {J_ISCI},
  author       = {Dong Qiu and Chengcheng Wang and Jialiang Xie},
  doi          = {10.1016/j.ins.2024.120315},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120315},
  shortjournal = {Inf. Sci.},
  title        = {A novel TODIM-based multi-attribute decision making method under information described by Z-numbers for selecting online B&amp;B},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards social-welfare and confidence optimizing approach to
examining barriers for digital transformation in SMCEs. <em>ISCI</em>,
<em>663</em>, 120312. (<a
href="https://doi.org/10.1016/j.ins.2024.120312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital transformation (DT) stands as a pivotal technological revolution that has emerged as a critical development strategy across industries for its effectiveness in fostering competitive advantages. However, the adoption of DT within the construction industry remains notably lagging, and small and medium-sized construction enterprises (SMCEs), constrained by limited resources, antiquated technologies, and constrained risk tolerance compared to large enterprises, encounter heightened impediments in undertaking DT. Current research on DT in the construction industry focuses predominantly on large enterprises or the industry holistically. These studies allocate relatively diminished focus to the imprecision of expert opinions and the impact of expert behavioral factors on decision outcomes. We construct a barriers examination framework aimed at ranking the barriers for DT in SMCEs. The proposed framework comprises two pivotal components: (1) the technical, organizational, and environmental barriers for DT in SMCEs; (2) an enhanced collective opinion generation paradigm driven by the social-welfare and confidence optimizing approach. Following the proposed framework, experts are tasked with assessing 14 barriers based on 5 levels of importance. The probability theory approach is applied to model expert opinions as probability distribution functions (PDFs) to reduce the inherent imprecision of expert opinions. The proposed social-welfare and confidence optimizing approach is utilized for aggregating individual PDFs to generate collective PDFs representing the importance level of each barrier. An empirical survey on SMCEs in Wuhan proves the feasibility and validity of the proposed barriers examination framework and indicates that the largest barrier to implement DT for SMCEs in Wuhan is the lack of standards and regulations, followed by the lack of clear strategic planning. The study not only summarizes the barriers for DT in SMCEs, but also adopts the social-welfare and confidence optimizing approach to improve the objectivity and reliability of the collective opinion, therefore, the conclusion can provide a reference for SMCEs to implement DT.},
  archive      = {J_ISCI},
  author       = {Zhen-Song Chen and Yan Wang and Ya-Qiang Xu and Zhengze Zhu and Yue-Hua Chen and Mirosław J. Skibniewski},
  doi          = {10.1016/j.ins.2024.120312},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120312},
  shortjournal = {Inf. Sci.},
  title        = {Towards social-welfare and confidence optimizing approach to examining barriers for digital transformation in SMCEs},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AWGAN: An adaptive weighting GAN approach for oversampling
imbalanced datasets. <em>ISCI</em>, <em>663</em>, 120311. (<a
href="https://doi.org/10.1016/j.ins.2024.120311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oversampling is a widely employed technique for addressing imbalanced datasets, facing challenges like class overlaps, intra-class imbalance, and noise. In this paper, we introduce an adaptive weighted oversampling algorithm grounded in generative adversarial networks, which we term AWGAN. To begin, our method computes the local and global densities for each instance, confirming its distribution within its local neighborhood, thereby enabling accurate identification and elimination of noisy instances. Subsequently, we devise a weight calculation strategy based on boundary division. Minority class instances are classified into safe and boundary instances, and weights are calculated based on the density of each instance and its distance from the surrounding instances, assigning different weights to overlapping and non-overlapping regions, and sparse and dense region instances, in order to solve the problems of class overlap and intra-class imbalance. Finally, GAN is used to construct a balanced dataset by adaptively generating minority class instances that match the real data distribution based on the weights. We evaluate AWGAN against six traditional oversampling methods and five GAN-based oversampling methods. The experimental results demonstrate that AWGAN significantly enhances classifier performance, as evident in its F1-Score, AUC, G-mean, and MCC on 21 diverse datasets.},
  archive      = {J_ISCI},
  author       = {Shaopeng Guan and Xiaoyan Zhao and Yuewei Xue and Hao Pan},
  doi          = {10.1016/j.ins.2024.120311},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120311},
  shortjournal = {Inf. Sci.},
  title        = {AWGAN: An adaptive weighting GAN approach for oversampling imbalanced datasets},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Optimized third-generation prospect theory-based three-way
decision approach for conflict analysis in multi-scale z-number
information systems. <em>ISCI</em>, <em>663</em>, 120309. (<a
href="https://doi.org/10.1016/j.ins.2024.120309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been limited research on considering decision-makers psychological factors and risk attitudes in the early three-way decision theory and methods. Behavioral three-way decision models can better describe and analyze decision-makers risk preferences and behaviors, with prospect theory being prominent. This paper introduces a third-generation prospect theory-based three-way decision model. It characterizes uncertain reference points for decision-maker preferences through positive/negative ideal points and medians. Due to nonlinear weighting functions in prospect theory, closed-form solutions for three-way decision thresholds are absent. The paper introduces α -model and β -model optimizations for numerical threshold solutions, simplifying three-way decision rules. Additionally, the proposed optimized three-way decision model is applied to conflict analysis, considering multi-scale and Z-number information&#39;s impact on conflict evaluation. Effective methods for deriving three-way conflict analysis rules and outcomes from multi-scale Z-number information systems are studied. Audit team conflict analysis examples validate the validity and feasibility of the proposed models and methods. Finally, several experimental results with data sets confirm overall performance.},
  archive      = {J_ISCI},
  author       = {Tianxing Wang and Bing Huang and Huaxiong Li},
  doi          = {10.1016/j.ins.2024.120309},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120309},
  shortjournal = {Inf. Sci.},
  title        = {Optimized third-generation prospect theory-based three-way decision approach for conflict analysis in multi-scale Z-number information systems},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy adaptive containment control of non-strict feedback
multi-agent systems with prescribed time and accuracy under arbitrary
initial conditions. <em>ISCI</em>, <em>663</em>, 120306. (<a
href="https://doi.org/10.1016/j.ins.2024.120306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the containment control problem is investigated for a class of non-strict feedback nonlinear multi-agent systems with arbitrary initial states. The state observation disturbance, defined as the deviation between the observed and true values of the state, is taken into account in the addressed system. Fuzzy logic systems and adaptive techniques are accordingly introduced to handle the unknown nonlinear terms and unknown disturbances. Based on a transformation function and a new Lyapunov function, an improved fuzzy adaptive control protocol is developed, which ensures that the output tracking error of each follower converges to a predefined region within a predefined settling time and allows the initial states of the agents to be arbitrarily bounded. Moreover, the error (between the input and output of the filter inherent to the dynamic surface control) can be accurately compensated under the newly designed Lyapunov function. The simultaneous consideration of the asymmetric input saturation and unknown time-varying control gain coefficients in the model makes the results established in this paper more general. Finally, the effectiveness of the proposed control protocol is verified by two simulation experiments.},
  archive      = {J_ISCI},
  author       = {Dong-Dong Deng and Xiao-Wen Zhao and Qiang Lai and Song Liu},
  doi          = {10.1016/j.ins.2024.120306},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120306},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy adaptive containment control of non-strict feedback multi-agent systems with prescribed time and accuracy under arbitrary initial conditions},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive fuzzy sliding mode control of uncertain
nonholonomic wheeled mobile robot with external disturbance and actuator
saturation. <em>ISCI</em>, <em>663</em>, 120303. (<a
href="https://doi.org/10.1016/j.ins.2024.120303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper developed a modified barrier function-based adaptive sliding mode control (MBFASMC) method to improve the tracking precision and robustness performance of the nonholonomic wheeled mobile robot (NWMR), which is subject to actuator saturation and external disturbance. Owing to the modified positive semi-definite barrier function (MPSDBF), the requirement for disturbance bound and the overestimation of control gain are eliminated. The nonsingular terminal sliding manifold and MPSDBF-based adaptive mechanism can guarantee that the sliding variables and the posture errors of NWMR converge to precisely predefined ultimate bounds in a finite time. In order to compensate for the adverse effect of input saturation, an auxiliary dynamics is proposed based on saturation error and used to construct the MBFASMC. Compared to the recent anti-saturation control methods, the demand for saturation level is released in the proposed control method. Moreover, a modified barrier function-based adaptive fuzzy sliding mode control (MBFAFSMC) is provided to relieve the control chattering problem. By Lyapunov analysis, it is validated that the proposed methods can ensure the pre-specified and finite-time convergence performance of the uncertain NWMR. The MBFASMC and MBFAFSMC are also applied to an actual NWMR experimental platform with artificial disturbances to verify the effectiveness of the proposed methods.},
  archive      = {J_ISCI},
  author       = {Yunjun Zheng and Jinchuan Zheng and Ke Shao and Han Zhao and Zhihong Man and Zhe Sun},
  doi          = {10.1016/j.ins.2024.120303},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120303},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fuzzy sliding mode control of uncertain nonholonomic wheeled mobile robot with external disturbance and actuator saturation},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A similarity-based three-way multiattribute decision model
under constrained pythagorean fuzzy environment. <em>ISCI</em>,
<em>663</em>, 120302. (<a
href="https://doi.org/10.1016/j.ins.2024.120302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A variety of fuzzy sets, especially Pythagorean fuzzy sets (PFSs), are commonly utilized to describe the ambiguity of information in three-way decision (3WD) models. PFSs can handle fuzzy information well but ignore the description of stochastic information. To address this issue, in this paper, we attempt to construct a novel three-way multiattribute decision model by combining 3WD with constrained Pythagorean fuzzy sets (CPFSs) which can measure the reliability of PFSs. Firstly, we introduce the concept of constrained Pythagorean fuzzy information systems (CPFISs). Comprehensive positive and negative similarities of objects are given in a CPFIS by introducing normalization, score function, comparison rules, and positive and negative ideal solutions. Secondly, by comprehensive positive and negative similarities, novel formulas for calculating comprehensive relative utility function values are obtained and an objective method for estimating conditional probabilities is presented in the absence of decision attributes. Based on the above knowledge, we establish a similarity-based three-way multiattribute decision model in a CPFIS. Furthermore, we conduct a case analysis of appendicitis to realize the application of our proposed model and several comparative analyses to demonstrate the effectiveness and superiority of our model. Finally, the good performance of the new model is verified through experimental analyses.},
  archive      = {J_ISCI},
  author       = {Hai-Long Yang and Jing Liu and Yanhong She and Li-Na Ma},
  doi          = {10.1016/j.ins.2024.120302},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120302},
  shortjournal = {Inf. Sci.},
  title        = {A similarity-based three-way multiattribute decision model under constrained pythagorean fuzzy environment},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-strategy multi-modal multi-objective evolutionary
algorithm using macro and micro archive sets. <em>ISCI</em>,
<em>663</em>, 120301. (<a
href="https://doi.org/10.1016/j.ins.2024.120301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-modal multi-objective optimization problems (MMOPs), more than one decision vector is mapped to the same objective vector. The loss of the optimal decision vector is a huge challenge, which result in the loss of population diversity. To effectively tackle this issue and preserve population diversity, it is imperative to fully leverage both macro and micro perspectives. The macro perspective is based on subpopulations divided by centroids, whereas the micro is based on individuals with higher priorities. Therefore, a multi-strategy multi-modal multi-objective evolutionary algorithm using macro and micro archive set (MMMEA) is proposed. Among them, the macro archive set (MAA) uses the centroid truncation strategy, which controls the global of the algorithm through the centroid. This strategy can ensure the diversity of the population. The micro archive set (MIA) uses a priority truncation strategy based on the perspective of individuals to filter the population information by priority. Different individuals in the population have dissimilar properties at various times, so the emphasis of generating offspring is also distinct. For this reason, the multistage multi-strategy method is proposed to generate offspring based on different individual information. With the purpose of verifying the feasibility of the algorithm, MMMEA is compared with seven advanced multi-modal multi-objective optimization algorithms (MMOEAs) on 28 test problems. The experimental results show that MMMEA can effectively solve multi-modal multi-objective optimization problems. MMMEA is competitive on most of the test problems.},
  archive      = {J_ISCI},
  author       = {Hu Peng and Sixiang Zhang and Lin Li and Boyang Qu and Xuezhi Yue and Zhijian Wu},
  doi          = {10.1016/j.ins.2024.120301},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120301},
  shortjournal = {Inf. Sci.},
  title        = {Multi-strategy multi-modal multi-objective evolutionary algorithm using macro and micro archive sets},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Keywords attention for fake news detection using few
positive labels. <em>ISCI</em>, <em>663</em>, 120300. (<a
href="https://doi.org/10.1016/j.ins.2024.120300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news detection (FND) tools are essential to increase the reliability of information in social media. FND can be approached as a machine learning classification problem so that discriminative features can be automatically extracted. However, this requires a large news set, which in turn implies a considerable amount of human experts&#39; effort for labeling. In this paper, we explore Positive and Unlabeled Learning (PUL) to reduce the labeling cost. In particular, we improve PUL with the network-based Label Propagation (PU-LP) algorithm. PU-LP achieved competitive results in FND exploiting relations between news and terms and using few labeled fake news. We propose integrating an attention mechanism in PU-LP that can define which terms in the network are more relevant for detecting fake news. We use GNEE, a state-of-the-art algorithm based on graph attention networks. Our proposal outperforms state-of-the-art methods, improving F 1 F1 in 2% to 10%, especially when only 10% labeled fake news are available. It is competitive with the binary baseline, even when nearly half of the data is labeled. Discrimination ability is also visualized through t-SNE. We also present an analysis of the limitations of our approach according to the type of text found in each dataset.},
  archive      = {J_ISCI},
  author       = {Mariana Caravanti de Souza and Marcos Paulo Silva Gôlo and Alípio Mário Guedes Jorge and Evelin Carvalho Freire de Amorim and Ricardo Nuno Taborda Campos and Ricardo Marcondes Marcacini and Solange Oliveira Rezende},
  doi          = {10.1016/j.ins.2024.120300},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120300},
  shortjournal = {Inf. Sci.},
  title        = {Keywords attention for fake news detection using few positive labels},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive framework for explainable cluster analysis.
<em>ISCI</em>, <em>663</em>, 120282. (<a
href="https://doi.org/10.1016/j.ins.2024.120282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has proven to be a powerful tool for knowledge extraction from large data sets across different domains. Data quality and results interpretability are essential when applying machine learning to inform decision-making processes. This is especially true for clustering methods, which are frequently employed for extracting knowledge from large data sets, due to their unsupervised nature. Although there are significant recent developments in explainable artificial intelligence (XAI) applied to unsupervised problems, they focus primarily on cluster interpretability and often overlook data quality challenges. Moreover, these developments are typically designed to use specific clustering algorithms, limiting their adaptability to incorporate alternative techniques. We propose a novel and comprehensive four-step sequential framework for explainable cluster analysis on high-dimensional mixed-type data to address these limitations. The framework encompasses data preprocessing, dimensionality reduction, clustering, and classification to ensure robust and explainable results. The proposed methodology has also been implemented in an open-source Python package called Clust-learn, designed to be accessible and customizable for researchers and practitioners. The framework has been validated by applying a case study focusing on large-scale assessments in education, effectively illustrating the strength and usefulness of the methodology in extracting and synthesizing knowledge from complex real-world data.},
  archive      = {J_ISCI},
  author       = {Miguel Alvarez-Garcia and Raquel Ibar-Alonso and Mar Arenas-Parra},
  doi          = {10.1016/j.ins.2024.120282},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120282},
  shortjournal = {Inf. Sci.},
  title        = {A comprehensive framework for explainable cluster analysis},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust two-stage minimum asymmetric cost consensus models
under uncertainty circumstances. <em>ISCI</em>, <em>663</em>, 120279.
(<a href="https://doi.org/10.1016/j.ins.2024.120279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group decision-making (GDM) problems in the real world are becoming more complex, and various uncertain factors exist. However, most scholars ignore the uncertainty in the GDM and the moderator cannot accurately predict the unit upward and downward adjustment costs of decision makers (DMs). To overcome these issues, this paper constructs the novel minimum cost consensus models with directional constraints (MCCM-DCs) based on robust optimization under uncertainty circumstances. Firstly, we construct two-stage asymmetric adjustment cost consensus models with better flexibility. The first stage focuses on establishing a consensus opinion, while the second stage entails deliberation on the adjustment deviations of the DMs. Further, considering the uncertainty of the unit adjustment cost, robust optimization is introduced to describe three different uncertainty scenarios in the second stage of the models. Then robust two-stage minimum asymmetric cost consensus models (TRMCCM-DCs) are proposed, which is closer to reality. Finally, the proposed models are applied to the case of water pollution control negotiations in the Taihu Basin in China, and further sensitivity analysis and comparison analysis are conducted to verify the validity of the models.},
  archive      = {J_ISCI},
  author       = {Ying Ji and Yingying Li and Chethana Wijekoon},
  doi          = {10.1016/j.ins.2024.120279},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120279},
  shortjournal = {Inf. Sci.},
  title        = {Robust two-stage minimum asymmetric cost consensus models under uncertainty circumstances},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised feature selection using orthogonal
encoder-decoder factorization. <em>ISCI</em>, <em>663</em>, 120277. (<a
href="https://doi.org/10.1016/j.ins.2024.120277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature selection (UFS) is a fundamental task in machine learning and data analysis, aimed at identifying a subset of non-redundant and relevant features from a high-dimensional dataset. Embedded methods seamlessly integrate feature selection into model training, resulting in more efficient and interpretable models. Current embedded UFS methods primarily rely on self-representation or pseudo-supervised feature selection approaches to address redundancy and irrelevant feature issues, respectively. Nevertheless, there is currently a lack of research showcasing the fusion of these two approaches. This paper proposes the Orthogonal Encoder-Decoder factorization for unsupervised Feature Selection (OEDFS) model, combining the strengths of self-representation and pseudo-supervised approaches. This method draws inspiration from the self-representation properties of autoencoder architectures and leverages encoder and decoder factorizations to simulate a pseudo-supervised feature selection approach. To further enhance the part-based characteristics of factorization, orthogonality constraints and local structure preservation restrictions are incorporated into the objective function. The optimization process is based on the multiplicative update rule, ensuring efficient convergence. To assess the effectiveness of the proposed method, comprehensive experiments are conducted on 14 datasets and compare the results with eight state-of-the-art methods. The experimental results demonstrate the superior performance of the proposed approach in terms of UFS efficiency.},
  archive      = {J_ISCI},
  author       = {Maryam Mozafari and Seyed Amjad Seyedi and Rojiar Pir Mohammadiani and Fardin Akhlaghian Tab},
  doi          = {10.1016/j.ins.2024.120277},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120277},
  shortjournal = {Inf. Sci.},
  title        = {Unsupervised feature selection using orthogonal encoder-decoder factorization},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FE-RNN: A fuzzy embedded recurrent neural network for
improving interpretability of underlying neural network. <em>ISCI</em>,
<em>663</em>, 120276. (<a
href="https://doi.org/10.1016/j.ins.2024.120276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning enables effective predictions. But deep structures face some challenges on human interpretability compared to conventional techniques, e.g., fuzzy inference systems. It motivates more research works to alleviate the black box nature of deep structures with performance maintained. This paper proposes a fuzzy-embedded recurrent neural network (FE-RNN) to improve interpretability of the underlying neural networks. It is a parallel deep structure comprising an RNN and a Pseudo Outer-Product based Fuzzy Neural Network (POPFNN) that share a common set of input and output linguistic concepts. The inference processes undertaken are associated by RNN using fuzzy rules in the embedded POPFNN. Fuzzy IF-THEN rules provide better interpretability of the inference process of the hybrid networks. It allows an effective realisation of a data driven implication using RNN in the modelling of fuzzy entailment within a fuzzy neural networks (FNN) structure. FE-RNN obtains more consistent results than other FNN in the experiment using the Mackey-Glass dataset. FE-RNN achieves about 99% correlation for forecasting prices of market indexes. Its interpretability is also discussed. FE-RNN then acts as a prediction tool in a financial trading system using forecast-assisted technical indicators optimised with Genetic Algorithms. It outperforms the benchmark trading strategies in the trading experiments.},
  archive      = {J_ISCI},
  author       = {James Chee Min Tan and Qi Cao and Chai Quek},
  doi          = {10.1016/j.ins.2024.120276},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120276},
  shortjournal = {Inf. Sci.},
  title        = {FE-RNN: A fuzzy embedded recurrent neural network for improving interpretability of underlying neural network},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ordered weighted geometric averaging operators for basic
uncertain information. <em>ISCI</em>, <em>663</em>, 120275. (<a
href="https://doi.org/10.1016/j.ins.2024.120275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Basic Uncertain Information (BUI) was proposed as an information granule that simultaneously accounts for both the value of the input and the certainty about that value. To aggregate BUI granules using Ordered Weighted Averaging (OWA) operators with bi-polar optimism–pessimism preferences, the ordered weighted averaging (BUIOWA) operators have been proposed recently. As weighted geometric mean is an alternative aggregation operator to weighted mean, the ordered weighted geometric averaging operator (OWGA) is the alternative to the OWA operator. Therefore, this study proposes basic uncertain information ordered weighted geometric averaging (BUIOWGA) operators to serve as the alternative aggregation choice to BUIOWA operators. Unlike BUIOWA operators, BUIOWGA operators have three different types, BUIOWGA type I, BUIOWGA type II, and BUIOWGA type III, with an increasing order relation. Several monotonicities, properties, and relations are proposed for the three different BUIOWGA operators and the BUIOWA operator. Finally, we present comparative analysis, numerical examples , and applications.},
  archive      = {J_ISCI},
  author       = {LeSheng Jin and Radko Mesiar and Tapan Senapati and Chiranjibe Jana and Chao Ma and Diego García-Zamora and Ronald R. Yager},
  doi          = {10.1016/j.ins.2024.120275},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120275},
  shortjournal = {Inf. Sci.},
  title        = {Ordered weighted geometric averaging operators for basic uncertain information},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A causal representation learning based model for time series
prediction under external interference. <em>ISCI</em>, <em>663</em>,
120270. (<a href="https://doi.org/10.1016/j.ins.2024.120270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of artificial neural networks, time-series prediction techniques are becoming more mature. While the prediction of time-series data under external interference remains a challenge. The different distribution of data before and after the external interference and the out-of-distribution of different datasets will lead to poor prediction accuracy, robustness, and generalization ability of the general prediction models. Thus, firstly, we propose a conditional causal representation (CCR) model based on causal representation learning, which solves these problems by extracting interference-related causal representations and learning causal mechanisms subject to external interference. Secondly, we demonstrate that the interference-related causal representations should satisfy three properties: independence of non-causal factors and other causal representations, mutually independent dimensions, and causality sufficient for the prediction. Based on these properties, the causal representation abstraction component is designed to extract interference-related causal representations. Thirdly, we demonstrate the conditional structure is equivalent to the causal mechanism if the conditions of the conditional structure are interference-related causal representations, and based on this, the conditional causal network (CCN) component is designed to learn the causal mechanisms subject to external interference. The experimental results show that the CCR has good prediction accuracy, robustness, and generalization ability.},
  archive      = {J_ISCI},
  author       = {Xuanzhi Feng and Dongxu Fan and Shuhao Jiang and Jianxiong Zhang and Bing Guo and Xuefeng Ding and Dasha Hu and Yuming Jiang},
  doi          = {10.1016/j.ins.2024.120270},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120270},
  shortjournal = {Inf. Sci.},
  title        = {A causal representation learning based model for time series prediction under external interference},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Enhanced NSGA-II-based feature selection method for
high-dimensional classification. <em>ISCI</em>, <em>663</em>, 120269.
(<a href="https://doi.org/10.1016/j.ins.2024.120269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection in high-dimensional data faces significant challenges owing to large and discrete decision spaces. In this study, we propose a feature selection method based on the nondominated sorting genetic algorithm-II (NSGA-II) to enhance the performance of feature selection in high-dimensional data. This study makes four contributions: 1) The sparse initialization strategy is used to sparsen the search space and accelerate the convergence speed of the algorithm; 2) the guided selection operator is employed to strike a balance between exploration and exploitation abilities; 3) an intra-population evolution-based mutation operator dynamically shrinks the search space; and 4) a greedy repair strategy is adopted to generate improved feature subsets. The proposed method was validated on 15 publicly available high-dimensional datasets and compared with eight competitive multi-objective feature selection methods. The results demonstrate that the proposed method can achieve superior classification accuracy in a shorter time, with a smaller subset of features containing less redundancy.},
  archive      = {J_ISCI},
  author       = {Min Li and Huan Ma and Siyu Lv and Lei Wang and Shaobo Deng},
  doi          = {10.1016/j.ins.2024.120269},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120269},
  shortjournal = {Inf. Sci.},
  title        = {Enhanced NSGA-II-based feature selection method for high-dimensional classification},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A general convergence analysis method for evolutionary
multi-objective optimization algorithm. <em>ISCI</em>, <em>663</em>,
120267. (<a href="https://doi.org/10.1016/j.ins.2024.120267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convergence analysis of multi-objective optimization algorithm has been an area of vital interest to the research community. With this regard, a number of approaches have been proposed and studied. However, these studies and developed proposals cannot cope with more than 3-dimensional optimization problems. Generally speaking, interpolation planes are formed by 3-dimension data. So, when the dimensionality of the Pareto front is more than 3, the dimensionality of Pareto front will be reduced to 3 by involving principal component analysis. This may lead to some important data being missed. Due to missing data, the formed interpolation plane is usually inaccurate and uneven. This will give rise to difficulties to evaluate the distance between the Pareto front and the optimal Pareto front. Subsequently, it is not easy to evaluate exact convergence time and with this regard the existing solutions lack general. Having this in mind, this paper develops a general convergence analysis (GCAM) for evolutionary multi-objective optimization algorithm (EMOA). In this approach, two originality aspects come to existence: one associates with the interpolation plane convergence analysis while the second concerns the improved drift analysis of evolutionary algorithm. Firstly, for more than 3-dimensional space, the dimensionality of the Pareto front set becomes reduced to 3 through a locally linear embedding. This overcomes the irregular interpolation plane problem and produce a high-quality interpolation. Secondly, this study originally analyzes the convergence of EMOA by engaging an improved drift analysis. Finally, we determine the first stopping time of EMOA by analyzing the convergence metric. The experimental results demonstrate that the proposed method exhibits better performance in comparison with CAD, CAL, and CAC. Specifically, the error proportion of SMS-EMOA, AR-MOEA, SPEA2+SDE, GFM-MOEA has been decreased by 12%, 15%, 21%, 19% and 17%, respectively.},
  archive      = {J_ISCI},
  author       = {Tie Cai and Hui Wang},
  doi          = {10.1016/j.ins.2024.120267},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120267},
  shortjournal = {Inf. Sci.},
  title        = {A general convergence analysis method for evolutionary multi-objective optimization algorithm},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel multi-objective optimization framework for optimal
integrated energy system planning with demand response under multiple
uncertainties. <em>ISCI</em>, <em>663</em>, 120252. (<a
href="https://doi.org/10.1016/j.ins.2024.120252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The planning of integrated energy systems (IES) faces significant challenges due to the presence of multiple uncertainties caused by stochastic demands and renewable energy generation. Particularly, how to balance different conflicted objectives in IES planning under multiple uncertainties is a major obstacle with few studies. Thus, this paper proposes a novel multi-objective optimization framework (MOOF) for uncertain IES planning with demand response to achieve the synergistic enhancement of multiple performance indicators of the system while ensuring its flexibility and safety. The proposed MOOF encompasses several key steps. Firstly, a multi-objective optimization model under various uncertainties is constructed, with the minimization of investment and operating costs, maximization of exergy efficiency, and minimization of carbon emissions as optimization objectives. Secondly, the chance constraint approach is used to convert the constraint conditions into deterministic ones. Subsequently, the Pareto dominance concept is incorporated into robust, interval, and opportunistic optimization techniques to obtain three deterministic transformation methods for multi-objective optimization with uncertainty. Further, a high-efficiency constrained multi-objective coevolutionary algorithm (CMCA) is developed to solve the proposed planning model, which has the characteristics of nonlinearity, and high-dimensional complexity. Finally, the effectiveness of the proposed MOOF and CMCA is verified through numerous case studies.},
  archive      = {J_ISCI},
  author       = {Yingchao Dong and Cong Wang and Hongli Zhang and Xiaojun Zhou},
  doi          = {10.1016/j.ins.2024.120252},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120252},
  shortjournal = {Inf. Sci.},
  title        = {A novel multi-objective optimization framework for optimal integrated energy system planning with demand response under multiple uncertainties},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel grey relational clustering model under sequential
three-way decision framework. <em>ISCI</em>, <em>663</em>, 120248. (<a
href="https://doi.org/10.1016/j.ins.2024.120248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of addressing clustering problems with small samples, grey relational clustering (GRC) plays a crucial role. Currently, a three-way GRC has gained popularity, particularly for its ability to handle the uncertain relationship between objects and classes. However, explicit clustering for some objects may not be achievable when employing the one-step decision, which is often a coarse-grained approach. In such cases, re-clustering these objects with a finer granularity becomes necessary. This is where the sequential three-way decision (STWD) proves to be an effective solution. Therefore, this paper is dedicated to designing a novel GRC under the STWD framework, namely GRC-STWD. Specifically, recognizing that some existing threshold calculations in GRCs can be overly subjective and that a pair-wise global threshold may not efficiently leverage available information for accurate object clustering, we introduce a novel threshold algorithm to address these limitations. Furthermore, we propose a conditional probability calculation method combining TOPSIS and grey relational degrees for clustering data lacking decision attributes or class labels. As the development of GRC within portfolio environments remains relatively nascent, we apply the proposed model to portfolio strategy construction. Finally, comparative and experimental analyses validate the model&#39;s effectiveness and feasibility. Notably, the developed model serves as a generalization of GRC, contributing to the broader advancement of GRC and STWD methodologies.},
  archive      = {J_ISCI},
  author       = {Jing Tu and Shuhua Su and Jianfeng Xu},
  doi          = {10.1016/j.ins.2024.120248},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120248},
  shortjournal = {Inf. Sci.},
  title        = {A novel grey relational clustering model under sequential three-way decision framework},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A unified framework of community hiding using symmetric
nonnegative matrix factorization. <em>ISCI</em>, <em>663</em>, 120235.
(<a href="https://doi.org/10.1016/j.ins.2024.120235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection can help us to deeply understand community structures and reveal potential social relationships among members. However, as people&#39;s concerns over the excessive mining of personal information have grown, the idea of community hiding has been proposed for privacy protection. Most existing community hiding methods based on heuristic approaches and genetic algorithms ignore the generative process of the network and cannot provide a better explanation of the rationality of the hiding mechanism. In addition, they are not simultaneously applicable to the global community, target community, or target nodes. In this study, we address the community hiding problem on three scales: global community hiding (macroscopic), target community hiding (mesoscopic), and target node hiding (microscopic). We propose a unified community hiding framework (CH-SNMF) that can be applied to all three scales. The basic idea is to use symmetric nonnegative matrix factorization to describe the network generative mechanism. It has a potential clustering capability that can mine key links and link sets during the network generation process. Therefore, they can be used to disrupt community structures with minimal perturbation budgets. The experimental results show that CH-SNMF outperforms many advanced baseline methods and effectively protects organizational and individual privacy.},
  archive      = {J_ISCI},
  author       = {Dong Liu and Ruoxue Jia and Xia Liu and Wensheng Zhang},
  doi          = {10.1016/j.ins.2024.120235},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120235},
  shortjournal = {Inf. Sci.},
  title        = {A unified framework of community hiding using symmetric nonnegative matrix factorization},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A survey on z-number-based decision analysis methods and
applications: What’s going on and how to go further? <em>ISCI</em>,
<em>663</em>, 120234. (<a
href="https://doi.org/10.1016/j.ins.2024.120234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Z-numbers are efficient tools to represent uncertain information through restriction and reliability measurement. Z-numbers and their variants have been integrated with diverse decision-analysis methods to solve practical decision-making problems. To make researchers understand the research status and challenges in this area, this paper provides an overview of publications related to Z-number-based decision analysis methods and applications. Firstly, a bibliometric analysis is conducted to present the trends and hotspots in this research domain. To uncover theoretical developments of Z-numbers, concepts and operation rules of Z-numbers and their variants are then recalled. Furthermore, decision analysis methods regarding multiple criteria decision analysis, optimization, prediction, and reasoning within the context of Z-numbers are summarized. Applications of Z-number-based decision analysis methods are categorized into six different fields including business and financial management, industrial engineering and management, energy management, medical and healthcare management, environment and sustainable development, and others. Findings, challenges, and future research directions are further discussed. It is hoped that this paper can provide insights for scholars and practitioners in the fields of Z-number-based decision analysis and applications.},
  archive      = {J_ISCI},
  author       = {Huchang Liao and Fan Liu and Yue Xiao and Zheng Wu and Edmundas Kazimieras Zavadskas},
  doi          = {10.1016/j.ins.2024.120234},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120234},
  shortjournal = {Inf. Sci.},
  title        = {A survey on Z-number-based decision analysis methods and applications: What’s going on and how to go further?},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic annotation of protected attributes to support
fairness optimization. <em>ISCI</em>, <em>663</em>, 120188. (<a
href="https://doi.org/10.1016/j.ins.2024.120188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has shown that the unaware automation of high-risk decision-making tasks can result in unfair decisions being made. The most common approaches to address this problem adopt definitions of fairness based on protected attributes. Precise annotation of protected attributes enables the application of bias mitigation techniques to commonly unlabeled kinds of data (e.g., images, text, etc.). This paper proposes a framework to automatically annotate protected attributes in data collections. The framework focuses on providing a single interface to annotate protected attributes of different types (e.g., gender, race, etc.) and from different kinds of data. Internally, the framework coordinates multiple sensors to produce the final annotation. Several sensors for textual data are proposed. An optimization search technique is designed to tune the framework to specific domains. Additionally, a small dataset of movie reviews —annotated with gender and sentiment— was created. The evaluation in datasets of texts from diverse domains shows the quality of the annotations and their effectiveness to be used as a proxy to estimate fairness in datasets and machine learning models. The source code is available online for the research community.},
  archive      = {J_ISCI},
  author       = {Juan Pablo Consuegra-Ayala and Yoan Gutiérrez and Yudivian Almeida-Cruz and Manuel Palomar},
  doi          = {10.1016/j.ins.2024.120188},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120188},
  shortjournal = {Inf. Sci.},
  title        = {Automatic annotation of protected attributes to support fairness optimization},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive highly improving the accuracy of clustering
algorithm based on kernel density estimation. <em>ISCI</em>,
<em>663</em>, 120187. (<a
href="https://doi.org/10.1016/j.ins.2024.120187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Highly Improving the Accuracy of Clustering (HIAC) algorithm is designed to enhance clustering accuracy by introducing a gravitational force between data objects, drawing them closer together, and employing a decision graph to establish a weight threshold for differentiating neighbor classes and outliers. Despite its strengths, HIAC faces two shortcomings: (1) its inability to generate effective decision graphs for small-scale datasets and (2) the non-smooth probability curve within the decision graph, making threshold determination by visual inspection both difficult and imprecise. This study presents an improved adaptive algorithm based on Kernel Density Estimation (KDE-AHIAC). This approach automatically selects the bandwidth based on the density and distribution of the data, utilizing the kernel density function to create a decision graph that applies to any dataset. For threshold selection, we introduce an adaptive calculation method that leverages the smoothness and continuity of the kernel density curve, replacing the observational approach. Additionally, we incorporate an outlier test model using Analysis of Similarity (ANOSIM) to avert misclassification of valid samples as outliers. Through comprehensive experimentation, we tested KDE-AHIAC and found that it offers notable improvements over HIAC. KDE-AHIAC enhances the clustering accuracy of the dataset by 66.05% compared to the original data and by 6.22% over HIAC.},
  archive      = {J_ISCI},
  author       = {Yue Pu and Wenbin Yao and Xiaoyong Li and Adi Alhudhaif},
  doi          = {10.1016/j.ins.2024.120187},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120187},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive highly improving the accuracy of clustering algorithm based on kernel density estimation},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy compensation of model predictive control for PMSMs
with external disturbances. <em>ISCI</em>, <em>663</em>, 120106. (<a
href="https://doi.org/10.1016/j.ins.2024.120106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some high-speed scenarios, encoders may prove ineffective in providing real-time feedback, thereby increasing the installation and maintenance costs of Permanent Magnet Synchronous Motors (PMSMs). Consequently, the development of sensorless algorithms for medium and high-speed scenarios will enhance the practical applicability of PMSMs. In contrast to the angle estimation scheme for a rotated coordinate system, model predictive control (MPC) commences from the stationary coordinate system to explore Lyapunov stability and directly derive speed and angle based on the stability condition. The primary advantage of this approach lies in its ability to mitigate the accumulation of observation angle iteration errors, while simultaneously simplifying stability conditions. Furthermore, it is important to note that uncertain factors will significantly impede the performance of PMSMs. Subsequently, various fuzzy schemes are introduced to mitigate the impact of uncertain factors in the sensorless mode, and a rigorous proof is provided for the relationship between the fuzzy error and current error. Furthermore, a comprehensive analysis of controller stability conditions is conducted. Ultimately, experimental results demonstrate that the proposed fuzzy compensations effectively counteract external disturbances.},
  archive      = {J_ISCI},
  author       = {Sai Zhang and Anwen Shen and Xin Luo and Qipeng Tang and Zicheng Li and Hou-Neng Wang},
  doi          = {10.1016/j.ins.2024.120106},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120106},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy compensation of model predictive control for PMSMs with external disturbances},
  volume       = {663},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Disentangling clusters from non-euclidean data via graph
frequency reorganization. <em>ISCI</em>, <em>662</em>, 120288. (<a
href="https://doi.org/10.1016/j.ins.2024.120288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In light of the growing need for non-Euclidean data analysis, graphs have been recognized as an effective tool for characterizing the distribution and correlation of such data, thus inspiring many graph-based developments for various applications such as clustering, of non-Euclidean data. However, under unsupervised scenarios, the construction of graphs from unlabeled data often involves numerous noisy links, consequently leading to serious performance degradation in concerned applications. To resolve this issue, we propose a novel method, referred to as Graph Frequency Reorganization (GFR), to enhance the discriminability of potential clusters and the associated graph quality. GFR shows capability far beyond the suboptimality in unsupervised graph construction . Furthermore, a fast version of GFR is proposed to reduce its computation overhead for large-scale datasets. Consequently, the obtained unsupervised clustering results can be significantly upgraded using the GFR data (i.e., the data after the GFR processing). To evaluate the effectiveness of the GFR, some experimental results on ten real-world datasets are provided to demonstrate that the overall clustering performance of a simple k-means using the GFR data is superior to several state-of-the-art graph-based clustering methods 1 .},
  archive      = {J_ISCI},
  author       = {Yangli-ao Geng and Chong-Yung Chi and Wenju Sun and Jing Zhang and Qingyong Li},
  doi          = {10.1016/j.ins.2024.120288},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120288},
  shortjournal = {Inf. Sci.},
  title        = {Disentangling clusters from non-euclidean data via graph frequency reorganization},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mining incomplete data using global and saturated
probabilistic approximations based on characteristic sets and maximal
consistent blocks. <em>ISCI</em>, <em>662</em>, 120287. (<a
href="https://doi.org/10.1016/j.ins.2024.120287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss a rough set approach to missing attribute values. Among many ways of interpreting missing values, in this paper we focus on two interpretations, lost values and “do not care” conditions. Using these interpretations, global and saturated probabilistic approximations are constructed with two types of granules: characteristic sets and maximal consistent blocks. We compare eight approaches, combining two interpretations of missing attribute values, two types of probabilistic approximations with two types of granules using an error rate that is computed as a result of ten-fold cross-validation. Using a 5% level of statistical significance, we present the experimental results for these eight approaches, showing statistically significant differences between all approaches to mining incomplete data. The results also show that no one method and approach is the best for every data set and that all eight approaches should be attempted. The final section of the paper presents the idea of concept-compatible data sets. We show that for these types of data sets, global and saturated probabilistic approximations for a concept are identical to the concept. We also show that for an incomplete data set with no duplicate rows using the lost interpretation of missing attribute values, the data set is concept-compatible.},
  archive      = {J_ISCI},
  author       = {Patrick G. Clark and Jerzy W. Grzymala-Busse and Zdzislaw S. Hippe and Teresa Mroczek},
  doi          = {10.1016/j.ins.2024.120287},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120287},
  shortjournal = {Inf. Sci.},
  title        = {Mining incomplete data using global and saturated probabilistic approximations based on characteristic sets and maximal consistent blocks},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Outlier detection method based on high-density iteration.
<em>ISCI</em>, <em>662</em>, 120286. (<a
href="https://doi.org/10.1016/j.ins.2024.120286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In conventional outlier detection , global outliers are easily identified, but the efficacy diminishes when faced with local outliers within clusters of varying densities. Conversely, while the local outlier factor excels in detecting local anomalies, its performance falters as the number of outliers increases. To address these limitations and cater to intricate datasets by ensuring adept detection of both global and local outliers, this paper introduces a novel outlier detection approach known as High-Density Iteration (HDIOD). The methodology begins by leveraging a combination of the Gaussian kernel function and k -nearest neighbors to compute the local kernel density for each sample. Subsequently, the process involves comparing the local kernel density of a given sample with that of its k -neighbors. If the sample&#39;s local kernel density is lower than the maximum density among its neighbors, it selects the neighbor with the highest local kernel density within its k -neighbors as the new object for comparison. This iterative process continues, where the set of k -neighbors for all objects constitutes the extended k -neighbors of the original sample . The final step involves utilizing the ratio of the maximum local kernel density within the extended k -nearest neighbors to the local density of the sample as a measure of the sample&#39;s outlier degree. Experimental evaluations conducted on 12 synthetic datasets and 19 real-world datasets demonstrate the effectiveness of the HDIOD method. Comparative analyses with 13 commonly used outlier detection methods underscore the high detection accuracy and robustness of HDIOD to parameter variations.},
  archive      = {J_ISCI},
  author       = {Yu Zhou and Hao Xia and Dahui Yu and Jiaoyang Cheng and Jichun Li},
  doi          = {10.1016/j.ins.2024.120286},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120286},
  shortjournal = {Inf. Sci.},
  title        = {Outlier detection method based on high-density iteration},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). State estimation of switched finite-field networks: A
multi-valued particle filter approach. <em>ISCI</em>, <em>662</em>,
120285. (<a href="https://doi.org/10.1016/j.ins.2024.120285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel and robust framework for state estimation of switched finite-field networks (SFFNs), which are a class of multi-valued logical networks that can model complex systems . The paper uses the semi-tensor product (STP) method to transform the dynamical model of SFFNs into an algebraic form, which can be easily manipulated and analyzed. The paper then applies a Monte-Carlo-based sequential importance sampling (SIS) filter to estimate the state of SFFNs from noisy and incomplete observations. The paper also introduces a resampling algorithm (RA) to prevent the particle degeneracy problem (PDP), which can affect the accuracy and efficiency of the filter. Finally, the paper demonstrates the performance and advantages of the proposed multi-valued particle filter (MVPF) framework through three examples.},
  archive      = {J_ISCI},
  author       = {Haodong Chen and Lulu Li and Jianquan Lu},
  doi          = {10.1016/j.ins.2024.120285},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120285},
  shortjournal = {Inf. Sci.},
  title        = {State estimation of switched finite-field networks: A multi-valued particle filter approach},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tri-level conflict analysis from the angle of three-valued
concept analysis. <em>ISCI</em>, <em>662</em>, 120284. (<a
href="https://doi.org/10.1016/j.ins.2024.120284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conflict analysis is the process of examining a conflict situation with the purpose of understanding its causes and dynamics, and identifying effective strategies for resolution or management. The three-valued situation table is the basis of conflict analysis, upon which different theories are used to identify agent alliances and analyze key conflicts among agents. Traditional conflict analysis typically treats a neutral attitude as an uncertain attitude that can be converted into either the support or opposition attitude to form weak alliances. However, in some cases, the neutral attitude is considered as a deterministic third type of attitude distinct from support and opposition. Drawing inspiration from the tri-level model of three-way decision, we propose a tri-level conflict analysis model demonstrating how to deal with different considerations of neutral attitude and make conflict analysis systematically. Then, recognizing the similarity between the three-valued formal context and the three-valued situation table, we introduce a tri-level structure of concepts in a three-valued formal context and use it for tri-level conflict analysis. We also propose two quantitative indicators, stability and tightness, to evaluate different coalition(s)-bundle(s) couplings. Finally, we use a real conflict situation related to development policy to illustrate the research findings of this paper.},
  archive      = {J_ISCI},
  author       = {Ruisi Ren and Jianjun Qi and Ling Wei and Xiaosong Wei},
  doi          = {10.1016/j.ins.2024.120284},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120284},
  shortjournal = {Inf. Sci.},
  title        = {Tri-level conflict analysis from the angle of three-valued concept analysis},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Backdoor attack detection via prediction trustworthiness
assessment. <em>ISCI</em>, <em>662</em>, 120283. (<a
href="https://doi.org/10.1016/j.ins.2024.120283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backdoor attack aims to compromise clean models without arousing suspicion, in which poisoned models behave normally for clean inputs yet return adversary-desired results when triggers appear. Due to the great insidiousness and hazard of backdoor attacks, backdoor defences have been attracting a lot of attention in the machine learning security community. Apart from most backdoor mitigation defences, our defence aims to determine whether the prediction of the classifier is trustworthy. More specifically, we scrutinize whether the prediction result is determined by the adversary-defined trigger or the semantic information of an input. To accomplish this goal, we devise a novel algorithm named feature aggregation, which requires only benign inputs and aims to separate the feature representation distributions of poisoned inputs from those of benign ones. The feature aggregation minimizes the distance between intra-benign feature representations and maximizes the distance between benign and poisoned feature representations. Then, we employ flow-based probability density estimation to model the distribution of benign feature representations. Since the likelihood of poisoned inputs over the estimated distribution is significantly smaller than those of benign ones, they can be identified based on an adaptive threshold. Experimental results show that our method outperforms state-of-the-art defences.},
  archive      = {J_ISCI},
  author       = {Nan Zhong and Zhenxing Qian and Xinpeng Zhang},
  doi          = {10.1016/j.ins.2024.120283},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120283},
  shortjournal = {Inf. Sci.},
  title        = {Backdoor attack detection via prediction trustworthiness assessment},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bilevel fuzzy clustering via adaptive similarity graphs
fusion. <em>ISCI</em>, <em>662</em>, 120281. (<a
href="https://doi.org/10.1016/j.ins.2024.120281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of fuzzy clustering relies heavily on the features of the input data . However, traditional fuzzy clustering methods focus on primitive features that represent the physical properties of data, such as the shape and color of objects. Usually, these properties could only capture the local distribution of data, while ignoring the global structure of data. Fortunately, by performing spectral analysis on the similarity graph of data, spectral clustering methods explore more on the global structure. However, capturing a decent global structure by constructing an ideal similarity graph is not easy. In this paper, we propose a novel fuzzy clustering method, the bilevel fuzzy clustering via adaptive similarity graphs fusion (BFCS), to solve the problems mentioned above at the same time. On the one hand, the global data structure is investigated by building an adaptive similarity graph using autoweighted fusion. On the other hand, the consistent memberships for both fuzzy clustering and spectral clustering are formulated into one objective function to simultaneously retain the local physical properties and the global data structure. Notably, the proposed method shows good scalability, and the bilevel structure of the algorithm makes its application to large datasets easy. Extensive experiments demonstrate the promising clustering performance of the proposed BFCS on synthetic and real datasets.},
  archive      = {J_ISCI},
  author       = {Yin-Ping Zhao and Xiangfeng Dai and Yongyong Chen and Chuanbin Zhang and Long Chen and Yue Zhao},
  doi          = {10.1016/j.ins.2024.120281},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120281},
  shortjournal = {Inf. Sci.},
  title        = {Bilevel fuzzy clustering via adaptive similarity graphs fusion},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Chernoff fusion using observability gramian-centric
weighting. <em>ISCI</em>, <em>662</em>, 120280. (<a
href="https://doi.org/10.1016/j.ins.2024.120280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, an observability Gramian (OG)-based Chernoff fusion (CF) rule is investigated for dealing with unknown correlated probability density functions (PDFs). Specifically, we introduce a generalised uniform observability (GUO) condition, which ensures that error covariances and estimate errors are bounded under nonlinear settings within the extended Kalman filter (EKF) framework. Leveraging the GUO condition, we develop an OG-centric weighting selection method that optimises fusion weights while guaranteeing non-divergent performance using an approximated Chernoff fusion (ACF) algorithm. The resulting OG-centric weights are then embedded to develop an OG-based approximated Chernoff fusion (OGBACF) algorithm that can compute fusion weights and error covariances in parallel. Finally, we conduct simulations to demonstrate the efficacy of our proposed fusion methodology.},
  archive      = {J_ISCI},
  author       = {Wangyan Li and Yuru Hu and Lifeng Wu and Guoliang Wei and Fuwen Yang},
  doi          = {10.1016/j.ins.2024.120280},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120280},
  shortjournal = {Inf. Sci.},
  title        = {Chernoff fusion using observability gramian-centric weighting},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linear asymmetric laplace fuzzy information granule and its
application in short-to-medium term prediction for financial time
series. <em>ISCI</em>, <em>662</em>, 120278. (<a
href="https://doi.org/10.1016/j.ins.2024.120278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian fuzzy information granule (GFIG) and its linear form provide a novel perspective for time series modeling . However, numerous studies show that asymmetric Laplace distribution has unique advantages over the Gaussian one, which motivate us to construct asymmetric Laplace distribution based fuzzy information granules and pursue their properties and applications. Three main contributions are made in this paper. First, asymmetric Laplace fuzzy information granule (ALFIG) on one-dimensional fuzzy number space is proposed, then its linear operations and distance metric are discussed. Second, membership-weighted kernel line is proposed to construct linear-ALFIG for extracting plenty of trend information contained within time series specially. Third, a linear-ALFIG based Long Short-Term Memory model (A-LSTM) is proposed for short-to-medium term prediction of financial time series. Experiment results show that: ( i ) Fitting errors of linear-ALFIG are significantly lower than that of linear-GFIG for datasets that exactly obey asymmetric Laplace distribution; ( ii ) A-LSTM has statistically absolute advantages in short-to-medium term prediction under significance level α = 0.1 α=0.1 (in most cases α = 0.05 α=0.05 in fact), which not only predicts direction, amplitude and changepoints of future trends, but also delivers comprehensive, transparent and user-oriented results.},
  archive      = {J_ISCI},
  author       = {Hong Yang and Lina Wang},
  doi          = {10.1016/j.ins.2024.120278},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120278},
  shortjournal = {Inf. Sci.},
  title        = {Linear asymmetric laplace fuzzy information granule and its application in short-to-medium term prediction for financial time series},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LC-TDC: A low cost and truth data collection scheme by using
missing data imputation in sparse mobile crowdsensing. <em>ISCI</em>,
<em>662</em>, 120274. (<a
href="https://doi.org/10.1016/j.ins.2024.120274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Crowd Sensing (MCS) is a promising computing paradigm for data collection harnessing ubiquitous workers equipped with sensing devices. While some studies have delved into quality-based and truthful data collection in sparse MCS, a research gap persists in the domain of low-cost and truthful data collection for the Post-Unknown Worker Recruitment (PUWR) problem, where the sensing qualities of workers remain unknown even after the platform acquires their data. We first attempt to tackle these challenges by proposing a Low Cost and Truth Data Collection (LC-TDC) scheme. Firstly, the Deep Matrix Factorization (DMF) model is utilized to infer data, facilitating the evaluation of workers&#39; trustworthiness and missing data imputation . This approach not only prevents the acceptance of erroneous or malicious data but also contributes to the reduction of data collection costs. Secondly, we propose a method to recalibrate worker quality based on historical data , accelerating worker identification at almost no cost. Thirdly, a profit optimization algorithm is proposed to determine the optimal number of verified workers according to the platform&#39;s accuracy in identifying workers, which can maximize the platform&#39;s utility in the long term. Extensive experimental results demonstrate that the proposed LC-TDC scheme outperforms previous strategies in terms of data accuracy, cost, and platform profit.},
  archive      = {J_ISCI},
  author       = {Bochang Yang and Anfeng Liu and Neal N. Xiong and Tian Wang and Shaobo Zhang},
  doi          = {10.1016/j.ins.2024.120274},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120274},
  shortjournal = {Inf. Sci.},
  title        = {LC-TDC: A low cost and truth data collection scheme by using missing data imputation in sparse mobile crowdsensing},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An imbalanced contrastive classification method via
similarity comparison within sample-neighbors with adaptive generation
coefficient. <em>ISCI</em>, <em>662</em>, 120273. (<a
href="https://doi.org/10.1016/j.ins.2024.120273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correct discrimination of samples in overlapping regions is crucial in imbalanced classification problems. Data-level methods generate new samples in overlapping areas to obtain a clearer classification boundary. However, the generated samples&#39; reliability cannot be guaranteed and additional noise will be introduced. Recently, although a few researchers have introduced contrastive learning to address the above problems, they have neither explored the differences in information content of samples in the contrastive task, nor considered the complex samples in overlapping areas. This paper proposes a contrastive classification method based on the similarity comparison of sample-neighbors, which transforms the traditional label prediction task into a similarity analysis task. Considering the distribution of neighbor category and the information content in the comparison task, each sample&#39;s unique generation coefficient is calculated. On this basis, a similarity loss with the target-neighbor sample group is designed so that the model can calculate the similarity between different samples. Meanwhile, extra discriminator will supervise the generated samples of variational autoencoder (VAE), which prompts the model to focus on the characteristics of individual samples. Experimental results on 39 public datasets show that the proposed method outperforms typical imbalanced classification methods.},
  archive      = {J_ISCI},
  author       = {Zhihang Meng and Xin Gao and Feng Zhai and Baofeng Li and Chun Xiao and Qiangwei Li and Bing Xue and Jiansheng Lu},
  doi          = {10.1016/j.ins.2024.120273},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120273},
  shortjournal = {Inf. Sci.},
  title        = {An imbalanced contrastive classification method via similarity comparison within sample-neighbors with adaptive generation coefficient},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 3D meta-classification: A meta-learning approach for
selecting 3D point-cloud classification algorithm. <em>ISCI</em>,
<em>662</em>, 120272. (<a
href="https://doi.org/10.1016/j.ins.2024.120272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Algorithm selection technology, aimed at choosing the most suitable algorithm for a given machine learning task, has achieved significant success in the domain of 2D vision. However, few studies have explored its application to the 3D point cloud domain. The rapid proliferation and development of 3D point cloud classification algorithms underscore the urgent need for exploration in selecting these algorithms. In this paper, we propose a novel meta-learning-based 3D classification approach , termed 3D meta-classification , to address this gap. The approach operates at both the base-level and meta-level phases. At the base level, candidate 3D classification algorithms constantly classify various 3D datasets, recording their classification performance as empirical knowledge. As for the meta-level phase, it specifically tailors the 3D meta-knowledge generator, 3D meta-feature extractor, and 3D meta-database constructor to establish the 3D meta-database, capturing the relationship between the 3D meta-features and empirical knowledge. Leveraging the 3D meta-database, the 3D classification meta-learner trains the meta-model and predicts suitable algorithms for new incoming 3D datasets. Extensive experiments are conducted to select the best-performing classification algorithm for specific 3D datasets from ModelNet40. The results demonstrate the effectiveness of the proposed 3D meta-classification model; the accuracies of one-from-two and one-from-three algorithm selection tasks reach over 98% and 80%, respectively.},
  archive      = {J_ISCI},
  author       = {Fan Xu and Jun Chen and Yizhou Shi and Tianchen Ruan and Qihui Wu and Xiaofei Zhang},
  doi          = {10.1016/j.ins.2024.120272},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120272},
  shortjournal = {Inf. Sci.},
  title        = {3D meta-classification: A meta-learning approach for selecting 3D point-cloud classification algorithm},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hierarchical overlapping community detection method based
on closed trail distance and maximal cliques. <em>ISCI</em>,
<em>662</em>, 120271. (<a
href="https://doi.org/10.1016/j.ins.2024.120271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important feature of real networks is their hierarchy and the existence of overlapping communities. Hierarchical agglomerative clustering is one way to determine the hierarchy of a network. To ensure the existence of overlapping communities, it is appropriate to choose the base elements for clustering – edges, cliques , etc. These base elements can then have common vertices and naturally provide the possibility of overlap. The proposed community detection method uses hierarchical agglomerative clustering on the 2-edge-connected component of the graph. Communities are constructed from maximal cliques as base elements. Novel dissimilarities for hierarchical agglomerative clustering were introduced for the merging of cliques. The dissimilarities use the size of the overlapped cliques and closed trail distance to express dissimilarity between communities in networks. The single linkage approach contains and extends the results of k -CPM. The proposed algorithm utilizing deterministic dissimilarity achieves comparable or superior outcomes compared to standard algorithms used for hierarchical or overlapping community detection.},
  archive      = {J_ISCI},
  author       = {Pavla Dráždilová and Petr Prokop and Jan Platoš and Václav Snášel},
  doi          = {10.1016/j.ins.2024.120271},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120271},
  shortjournal = {Inf. Sci.},
  title        = {A hierarchical overlapping community detection method based on closed trail distance and maximal cliques},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge-enhanced online doctor recommendation framework
based on knowledge graph and joint learning. <em>ISCI</em>,
<em>662</em>, 120268. (<a
href="https://doi.org/10.1016/j.ins.2024.120268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A well-performed doctor recommendation system is significant for both patients and Online Medical Consultation Platforms (OMCPs). Though previous studies have proposed many doctor recommendation methods, some are overly personalized for implementation in large-scale OMCPs, while some other machine learning-based approaches perform poorly due to the simplistic information available about patients and doctors on OMCPs. This research proposes an online doctor recommendation framework based on knowledge graph (KG) and joint learning to address these problems. The framework first constructs a comprehensive medical KG, including details about doctors on the platform and a wealth of medical knowledge, to better extract features of doctors and patients. It obtains feature representations of doctors from the medical KG and extracts features from patients’ consultation texts at both sentence and word levels using word embedding and KG embedding . Finally, these features are fed into a deep neural network to calculate the recommendation probability . All processes are learned simultaneously within an overall framework. Extensive experiments conducted on four real datasets illustrate the superior performance of our model and the effectiveness of incorporating KG into doctor recommendation in providing interpretations for the recommendation results.},
  archive      = {J_ISCI},
  author       = {Fengyu Zhang and Xihua Li},
  doi          = {10.1016/j.ins.2024.120268},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120268},
  shortjournal = {Inf. Sci.},
  title        = {Knowledge-enhanced online doctor recommendation framework based on knowledge graph and joint learning},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fixed-time fuzzy tracking control for high-order nonstrict
feedback nonlinear systems with unknown virtual control gains and
actuator faults. <em>ISCI</em>, <em>662</em>, 120266. (<a
href="https://doi.org/10.1016/j.ins.2024.120266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, fuzzy fault-tolerant tracking control is investigated for high-order nonstrict feedback nonlinear systems in fixed time interval . The gain fault and bias fault in actuator are considered for high-order nonstrict feedback nonlinear systems . Contrary to the existing results, an adaptive estimation tactic is proposed to estimate the coexisting uncertainties such that no priori knowledge is needed for the adaptive parameters, in spite of unknown virtual control gains, nonlinear uncertainties, time-varying disturbances and actuator faults . Based on this tactic, the unknown virtual control gains are slackened to completely unknown, which is more practical. Unlike the general fixed time control tactics, the singularity problem has been overthrew by using the inequality transformation strategy without destroying the control performance. The growth assumptions are removed and the complex nonstrict feedback structure is overcome with the support of fuzzy logic systems (FLS). Finally, two examples demonstrate the validity of the formulated method.},
  archive      = {J_ISCI},
  author       = {Junchang Zhai and Huanqing Wang and Hongxia Cui and Yuping Qin},
  doi          = {10.1016/j.ins.2024.120266},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120266},
  shortjournal = {Inf. Sci.},
  title        = {Fixed-time fuzzy tracking control for high-order nonstrict feedback nonlinear systems with unknown virtual control gains and actuator faults},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HarmoSATE: Harmonized embedding-based self-attentive encoder
to improve accuracy of privacy-preserving federated predictive analysis.
<em>ISCI</em>, <em>662</em>, 120265. (<a
href="https://doi.org/10.1016/j.ins.2024.120265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate privacy-preserving prediction using electronic health record (EHR) data distributed in multiple hospitals is essential to enable stakeholders related to healthcare services to obtain useful information without privacy leakage . In this paper, we propose harmonized embedding-based self-attentive encoder (HarmoSATE), which is a new method for privacy-preserving federated predictive analysis . We extract contextual embeddings of local institutions using Word2Vec, and then harmonize locally-trained embeddings using a neural network-based harmonization technique. The proposed method uses a deep representative encoder based on self-attention to learn complex and dynamic patterns inherent to harmonized embeddings of medical concepts. To evaluate our method, we implemented experiments using sequential medical codes collected from the Medical Information Mart for Intensive Care-III dataset in a distributed setting. It achieved a significant increase in average AUC, ranging from 3% to 8% depending on the experiments compared to baseline models , demonstrating superior prediction accuracy of a patient&#39;s diagnosis in the next admission. HarmoSATE can be a useful alternative to obtain accurate and practical results for various predictive tasks that use sensitive and distributed EHR data while preserving patients&#39; privacy.},
  archive      = {J_ISCI},
  author       = {Taek-Ho Lee and Suhyeon Kim and Junghye Lee and Chi-Hyuck Jun},
  doi          = {10.1016/j.ins.2024.120265},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120265},
  shortjournal = {Inf. Sci.},
  title        = {HarmoSATE: Harmonized embedding-based self-attentive encoder to improve accuracy of privacy-preserving federated predictive analysis},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic heterogeneous attributed network embedding.
<em>ISCI</em>, <em>662</em>, 120264. (<a
href="https://doi.org/10.1016/j.ins.2024.120264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information networks generally exhibit three characteristics, namely dynamicity, heterogeneity, and node attribute diversity. However, most existing network embedding approaches only consider two of the three when embedding each node into low-dimensional space. Adding to such an existing approach a technique of processing the remaining characteristic can easily cause incompatibility. One solution to process the three characteristics together is to treat the dynamic heterogeneous attributed network (DHAN) as a temporal sequence of heterogeneous attributed network (HAN) snapshots. For example, existing graph convolutional networks (GCNs)-based DHAN embedding approaches embed the HAN snapshots to get static representations offline, and then dynamically capture temporal dependencies between adjacent snapshots online to maintain fresh representations of the DHAN. However, those approaches encounter the convergence problem when stacking multiple convolutional layers to capture more topological information. Some other existing approaches dynamically update the representations of HAN snapshots online, neglecting the efficiency requirement of online scenarios and the temporal dependencies between snapshots. To address the two issues, we propose a new framework called Dynamic Heterogeneous Attributed Network Embedding (DHANE), consisting of a static model MGAT and a dynamic model NICE. MGAT captures more topological information while maintaining GCN convergence by performing metagraph-based attention in each convolutional layer. NICE preserves network freshness while reducing the computational load of the update by only examining network changes and updating their embedding representations. Extensive experiments show that DHANE achieves up to 27× speedup and 9.1-26.4% higher accuracy on several real dynamic heterogeneous attributed networks for online classification.},
  archive      = {J_ISCI},
  author       = {Hongbo Li and Wenli Zheng and Feilong Tang and Yitong Song and Bin Yao and Yanmin Zhu},
  doi          = {10.1016/j.ins.2024.120264},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120264},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic heterogeneous attributed network embedding},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A majority affiliation based under-sampling method for class
imbalance problem. <em>ISCI</em>, <em>662</em>, 120263. (<a
href="https://doi.org/10.1016/j.ins.2024.120263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance poses difficulties in training a classifier that perform well on minority classes, especially when there is a high imbalance ratio and significant class overlap. Existing data-level methods often suffer from problems like information loss and overfitting. To address these problems, we introduce a novel majority affiliation based under-sampling method (MAUS). The MAUS method employs a support vector data description model to capture the distribution of the minority class, thereby forming a hyper-sphere to establish a majority affiliation for each sample. The high-dimensional hyper-sphere constructed through all minority class samples avoids the problem of overfitting. Leveraging the majority affiliation in conjunction with the k-nearest neighbor algorithm, MAUS is capable of identifying region of class overlap and subsequently removing majority samples within these regions that negatively impact classification performance. This selective removal process minimizes excessive information loss at classification boundaries while alleviating the issue of class overlap. Furthermore, by removing those majority samples that are situated far from the classification boundary, MAUS reduces the imbalance ratio to the expected value, resulting in the attainment of a balanced dataset. To validate the effectiveness of our method, we conducted extensive experiments comparing it with state-of-the-art methods on 30 publicly available datasets. The results indicate that our approach outperforms existing methods on most of datasets and classifiers.},
  archive      = {J_ISCI},
  author       = {Ying Xie and Xian Huang and Feng Qin and Fagen Li and Xuyang Ding},
  doi          = {10.1016/j.ins.2024.120263},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120263},
  shortjournal = {Inf. Sci.},
  title        = {A majority affiliation based under-sampling method for class imbalance problem},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy preserving rare itemset mining. <em>ISCI</em>,
<em>662</em>, 120262. (<a
href="https://doi.org/10.1016/j.ins.2024.120262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, rare pattern mining has shown great vitality in some real-world fields, such as disease diagnosis, criminal behavior analysis, anomaly detection in networks, and so on. When data organizations publish or share information publicly, shared data can be at risk of leakage as data mining techniques may discover sensitive knowledge and information. To keep competitors from obtaining hidden information after processing the database, privacy-preserving data mining (PPDM) has been proposed and studied widely. However, most of the techniques in PPDM are applied to frequent pattern mining and cannot deal with the privacy protection problems in rare pattern mining, such as network vulnerability detection and abnormal medical data. To address this limitation, we introduce a privacy-preserving technique for rare pattern mining. In this paper, two novel algorithms named Longest Transaction-Minimum Item Number (LT-MIN) and Longest Transaction-Maximum Item Number (LT-MAX) are proposed to hide sensitive rare itemsets and return the sanitized database. These two algorithms succeed in hiding target itemsets while minimizing the side effects on the original database. What&#39;s more, they employ a projection mechanism to reduce the time spent scanning the database. Besides using the traditional evaluation criteria in PPDM, we also propose two additional similarity measures to evaluate the performance from the perspective of the itemsets and the structural integrity of the database. The experimental results indicate that the proposed algorithms can hide sensitive rare itemsets successfully and efficiently, and the evaluation methods used can become the evaluation criteria for privacy-preserving rare itemset mining (PPRIM).},
  archive      = {J_ISCI},
  author       = {Yijie Gui and Wensheng Gan and Yongdong Wu and Philip S. Yu},
  doi          = {10.1016/j.ins.2024.120262},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120262},
  shortjournal = {Inf. Sci.},
  title        = {Privacy preserving rare itemset mining},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Almost surely safe exploration and exploitation for deep
reinforcement learning with state safety estimation. <em>ISCI</em>,
<em>662</em>, 120261. (<a
href="https://doi.org/10.1016/j.ins.2024.120261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to address the challenge of constrained reinforcement learning (CRL), which seeks to maximize cumulative rewards while making agents avoid risks. Existing CRL methods can typically ensure that the final trained policy could meet specified constraints. But during training process, the safety of the agent cannot be guaranteed. In this research, we put forward a safe proximal policy optimization (SPPO) method under the assumption of the continuity of states&#39; safety values. The proposed SPPO can make agents achieve satisfactory cumulative rewards while realizing zero constraint violations in the learning phase. In our method, an uncertainty estimation technique of states&#39; safety value is utilized to get a safe state set H t Ht . Then, H t Ht is applied to intervene in the agent&#39;s exploration. As a consequence, the safety of the agent can be achieved. Moreover, we theoretically guarantee that the agent will not violate the safety constraint with almost 100% probability . Considerable empirical experiments demonstrate that the SPPO algorithm can achieve higher cumulative rewards and lower total cost (near zero) than existing state-of-the-art CRL approaches .},
  archive      = {J_ISCI},
  author       = {Ke Lin and Yanjie Li and Qi Liu and Duantengchuan Li and Xiongtao Shi and Shiyu Chen},
  doi          = {10.1016/j.ins.2024.120261},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120261},
  shortjournal = {Inf. Sci.},
  title        = {Almost surely safe exploration and exploitation for deep reinforcement learning with state safety estimation},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Event-triggered security consensus of continuous-time
multi-agent systems against complex cooperative attacks. <em>ISCI</em>,
<em>662</em>, 120260. (<a
href="https://doi.org/10.1016/j.ins.2024.120260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers event-triggered security consensus of continuous-time multi-agent systems (MASs) subject to complex cooperative attacks. First, false data injection attacks (FDIAs) and denial-of-service (DoS) attacks are modeled under a unified framework through the Bernoulli process , which provides a comprehensive understanding of the challenges posed by these attacks in MASs. Second, an improved event-triggered mechanism (ETM) based on aperiodic sampling is constructed, which avoids the Zeno phenomenon and has the potential to improve the efficiency and resilience of MASs. In addition, it can be combined with detection signals to address the challenge of determining trigger times under DoS attacks, which is an important contribution. Third, to overcome the impact of complex cooperative attacks, this article analyses the security consensus of MASs in three steps by combining the characteristics of trigger time and attack time. Based on this, security consensus is guaranteed. Finally, a practical example is used to demonstrate the feasibility of the proposed ETM.},
  archive      = {J_ISCI},
  author       = {Weihai Zhang and Zunjie Yu and Xiushan Jiang},
  doi          = {10.1016/j.ins.2024.120260},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120260},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered security consensus of continuous-time multi-agent systems against complex cooperative attacks},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed neural tensor completion for network monitoring
data recovery. <em>ISCI</em>, <em>662</em>, 120259. (<a
href="https://doi.org/10.1016/j.ins.2024.120259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network monitoring data is usually incomplete, accurate and fast recovery of missing data is of great significance for practical applications. The tensor-based nonlinear methods have attracted recent attentions with their capability of capturing complex interactions among data for more accurate recovery. However, the training process of existing methods is often time-consuming due to massive data and unreasonable network resource allocation . Thus motivated, we propose a distributed neural tensor completion method, named D-NORM, which simultaneously optimizes both recovery accuracy and time. Specifically, D-NORM adopts two schemes to solve the resulting optimization problem . First, we design a parameter-efficient multi-layer architecture with convolutional neural network to learn nonlinear correlations among data. Second, we reformulate the initial model as an equivalent set function optimization problem under a matroid base constraint. After constructing an approximate supermodular function to substitute the objective set function with provable upper bound, we propose an approximation algorithm based on the two-stage search procedure with theoretical performance guarantee to rationally allocate computing resources and efficiently recover missing data. Extensive experiments conducted on real-world datasets validate the superiority of D-NORM in both efficiency and effectiveness.},
  archive      = {J_ISCI},
  author       = {Chunsheng Liu and Kun Xie and Tao Wu and Chunlai Ma and Tao Ma},
  doi          = {10.1016/j.ins.2024.120259},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120259},
  shortjournal = {Inf. Sci.},
  title        = {Distributed neural tensor completion for network monitoring data recovery},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incremental clickstream pattern mining with search
boundaries. <em>ISCI</em>, <em>662</em>, 120257. (<a
href="https://doi.org/10.1016/j.ins.2024.120257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been a growing interest in sequential pattern mining in data mining , with a particular focus on clickstream pattern mining. These areas hold the potential for discovering valuable patterns. However, traditional mining algorithms in these domains often assume that databases are static, simplifying the mining process. In reality, databases are updated incrementally over time, partially rendering a portion of the previous results invalid. This necessitates rerunning algorithms on updated databases to obtain accurate frequent patterns . As database size increases, this approach can become time-consuming and affect performance. To tackle this issue, we propose PSB-CUP to mine frequent clickstream patterns in an incremental update manner. PSB-CUP employs the concept of search borders to reduce the search space and the information retained in memory. Furthermore, an IDList generation method called “partial imbalance join” was proposed to reconstruct possibly missing information during the incremental process. This join method, however, requires more extra information to be cached in exchange for speed. We then improve this technique by introducing “recursive imbalance join”, removing the need for extra cached data in the PSB-CUP + algorithm. The experimental results show that our proposed algorithms are efficient for incremental clickstream pattern mining.},
  archive      = {J_ISCI},
  author       = {Huy M. Huynh and Nam N. Pham and Zuzana K. Oplatkova and Loan T.T. Nguyen and Ngoc Thanh Nguyen and Unil Yun and Bay Vo},
  doi          = {10.1016/j.ins.2024.120257},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120257},
  shortjournal = {Inf. Sci.},
  title        = {Incremental clickstream pattern mining with search boundaries},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EMOTIF – a system for modeling 3D environment evaluation
based on 7D emotional vectors. <em>ISCI</em>, <em>662</em>, 120256. (<a
href="https://doi.org/10.1016/j.ins.2024.120256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is widely known that the decisions being made concern objects representing a set of characteristics whose importance is unique for every decision-maker. However, including this aspect in analyses is a challenge for many researchers. Classically applied information analysis methods fail to consider the synergy of these characteristics and ignore the impact of behavioural aspects that are inseparable from the decision-maker. The study proposed a solution based on an emotion detection technology using Computer Vision and Neural Networks. The presented approach comprises three main components: the detection of emotions using CNN – acquiring input vector value elements to the model for evaluation of space features; MLP for the assessment of anthropogenic and natural space features; and the verification of the utilitarian nature, usability, and suitability for the use of the developed solution. The novelty of the paper relates to the proposition of the new approaches by demonstrating that the assessment of the impact of an object’s features is a synergistic, inseparable conglomerate (Fusion Features), which thus indicates the greater usability of the results such studies in the analysis of a particular phenomenon, structure, or system.},
  archive      = {J_ISCI},
  author       = {Artur Janowski and Małgorzata Renigier-Biłozor and Marek Walacik and Aneta Chmielewska},
  doi          = {10.1016/j.ins.2024.120256},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120256},
  shortjournal = {Inf. Sci.},
  title        = {EMOTIF – a system for modeling 3D environment evaluation based on 7D emotional vectors},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explorer-actor-critic: Better actors for deep reinforcement
learning. <em>ISCI</em>, <em>662</em>, 120255. (<a
href="https://doi.org/10.1016/j.ins.2024.120255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Actor-critic deep reinforcement learning methods have demonstrated significant performance in many challenging decision-making and control tasks, but also suffer from high sample complexity and overestimation bias. Current researches focus on using underestimation to balance overestimation and reducing bias through ensemble learning , but introducing underestimation bias and excessive network costs. In this paper, we first analyze the effect of action selection policy on estimation bias. Then, we propose the Explorer-Actor-Critic (EAC) method that gives a more conservative objective for the actor to reduce overestimation, introduces a learnable explorer to improve exploration ability, and uses an action mixing mechanism to mitigate experience distribution bias. Furthermore, we apply the EAC method to TD3 and SAC and verify its effectiveness through extensive comparison and ablation experiments. Our algorithm not only outperforms state-of-the-art algorithms, but also is compatible with other actor-critic methods.},
  archive      = {J_ISCI},
  author       = {Junwei Zhang and Shuai Han and Xi Xiong and Sheng Zhu and Shuai Lü},
  doi          = {10.1016/j.ins.2024.120255},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120255},
  shortjournal = {Inf. Sci.},
  title        = {Explorer-actor-critic: Better actors for deep reinforcement learning},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An extended self-representation model of complex networks
for link prediction. <em>ISCI</em>, <em>662</em>, 120254. (<a
href="https://doi.org/10.1016/j.ins.2024.120254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a fundamental problem in network science, link prediction is both theoretically significant and practically useful. Many existing link prediction algorithms rely on predefined assumptions about the link formation mechanism of the network, limiting their generalizability . The recently proposed Network Self-Representation (NSR) model avoids such predefined assumptions by representing the likelihood of link existence between two nodes as a linear transformation of their neighboring connections, resulting in a more generic link prediction approach. To further improve the self-learning capability, this study proposes an Extended Network Self-Representation (ENSR) model. Instead of leveraging a linear transformation as the NSR function, the ENSR model considers the likelihood of link existence as a general function of the adjacency matrix . This study further formulates the ENSR model as an optimization model and analytically derives a critical property of its optimal solution, based on which the optimal ENSR function is approximated by polynomial regression . Experiments on 15 real-world networks show that our proposed ENSR model achieves better link prediction performance than the NSR model as well as several other benchmark algorithms. Notably, the ENSR function&#39;s coefficients match the contributions of multi-hop paths to link prediction. In most cases, the self-learned coefficients by the ENSR model align with the predefined assumptions of the second-best link prediction algorithms, which implies that the ENSR model can adaptively discover the underlying link formation mechanisms of complex networks.},
  archive      = {J_ISCI},
  author       = {Yuxuan Xiu and Xinglu Liu and Kexin Cao and Bokui Chen and Wai Kin Victor Chan},
  doi          = {10.1016/j.ins.2024.120254},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120254},
  shortjournal = {Inf. Sci.},
  title        = {An extended self-representation model of complex networks for link prediction},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards privacy-preserving category-aware POI recommendation
over encrypted LBSN data. <em>ISCI</em>, <em>662</em>, 120253. (<a
href="https://doi.org/10.1016/j.ins.2024.120253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularity of location-based social networks (LBSNs), locations and social relationships, point-of-interests (POIs) categories have been considered to be important factors in POI recommendation services . The boom of cloud computing has driven data owners to outsource their LBSN data and services to the cloud. However, as the data usually contains sensitive information , it should be encrypted before being outsourced. Consequently, the POI recommendations have to be processed over encrypted data . Although several secure LBSNs-based POI recommendation schemes have been proposed, they either do not apply to the outsourcing scenario or have issues with recommendation accuracy. To overcome these limitations, we propose an efficient and privacy-preserving category-aware POI recommendation scheme (PCAPR) over encrypted LBSN data. Specifically, we first index social relationships with Bloom filters and organize them into a vantage point tree. Then, we design a Merge-tree to index the user-POI dataset. Based on these two trees, we design an efficient LBSNs-based and category-aware POI recommendation algorithm to support a threshold POI recommendation. After that, we design two secure protocols to protect the privacy in the designed algorithm and present a PCAPR scheme. Our analysis confirms the PCAPR scheme ensures privacy while our performance evaluation underscores its efficiency.},
  archive      = {J_ISCI},
  author       = {Lili Sun and Yandong Zheng and Rongxing Lu and Hui Zhu and Yonggang Zhang},
  doi          = {10.1016/j.ins.2024.120253},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120253},
  shortjournal = {Inf. Sci.},
  title        = {Towards privacy-preserving category-aware POI recommendation over encrypted LBSN data},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Disorder-resistant fusion estimator design for nonlinear
stochastic systems in the presence of measurement quantization.
<em>ISCI</em>, <em>662</em>, 120251. (<a
href="https://doi.org/10.1016/j.ins.2024.120251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we thoroughly study a new nonlinear disorder-resistant fusion estimation problem under both packet disorder and measurement quantization. Packet disorder, which occurs due mainly to random transmission delays (RTDs), are characterized via a series of integer-valued functions and random variables obeying certain distributions. Sensor measurements are logarithmically quantized before entering designated communication networks. The upper bounds on the filtering error covariances are acquired and later minimized by appropriately designing gain parameters of both local and fusion estimators. For fusion estimation, all local estimates and filtering covariances are integrated at a fusion center through the well-known federated criterion. Moreover, the fusion performance is examined by means of assessing the resistance of the designed estimator against the RTD-induced disorder. Simulation examples are presented to illustrate the applicability of the proposed disorder-resistant fusion estimator.},
  archive      = {J_ISCI},
  author       = {Hang Geng and Zidong Wang and Jun Hu and Guoping Lu and Qing-Long Han and Yuhua Cheng},
  doi          = {10.1016/j.ins.2024.120251},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120251},
  shortjournal = {Inf. Sci.},
  title        = {Disorder-resistant fusion estimator design for nonlinear stochastic systems in the presence of measurement quantization},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MAR-GSA: Mixed attraction and repulsion based gravitational
search algorithm. <em>ISCI</em>, <em>662</em>, 120250. (<a
href="https://doi.org/10.1016/j.ins.2024.120250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a population-based stochastic optimization algorithm , Gravitational Search Algorithm (GSA) has attracted numerous interests and has been applied in various applications. However, GSA has drawbacks such as uneven search and premature convergence in practical applications. This paper specifically explains the inherent characteristic of GSA in prioritizing the center position. Correspondingly, an improvement strategy of fitness normalization with mass shift is proposed, creating a situation where gravity and repulsion are mixed. Then, the global best mechanism with weights is incorporated into the particle&#39;s velocity update formula, which compensates for the difficulties in the later exploitation stage . Finally, an empirical formula for the initial gravitational constant related to the size of the solution space is proposed, which enhances the global search ability together with the former strategy. 12 shifted benchmark functions are used to construct 20 optimization problems ranging from 2 to 120 dimensions. The average performance of the proposed algorithm, other GSA and well-known algorithms are compared under the same budget. The results demonstrate that the proposed GSA not only effectively addresses the drawbacks of GSA and maintains good performance , but also exhibits strong competitiveness compared to various similar algorithms.},
  archive      = {J_ISCI},
  author       = {Zhiqiang Qian and Yongfang Xie and Shiwen Xie},
  doi          = {10.1016/j.ins.2024.120250},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120250},
  shortjournal = {Inf. Sci.},
  title        = {MAR-GSA: Mixed attraction and repulsion based gravitational search algorithm},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel interval approximation method for passivity and
stability analysis of delayed neural networks. <em>ISCI</em>,
<em>662</em>, 120249. (<a
href="https://doi.org/10.1016/j.ins.2024.120249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies passivity analysis and stability analysis for neural networks with time-variant delay. The time-variant delay is presumed to respond in trigonometric form. Firstly, a novel interval approximation method is constructed with adjustable parameters, which can be adjusted to reduce conservatism. According to the feature of time delay in trigonometric form, the specific allowable delay set can be obtained. Secondly, by introducing the delay-product-type parts in Lyapunov-Krasovskii functional (LKF), the emphatically improved passivity criterion and stability criterion with less conservatism are obtained by using the advanced inequalities. Finally, two numerical simulations are listed where our work can obtain larger maximum allowable delay bounds compared with other works, which demonstrate that the results based on the interval approximation method are less conservative.},
  archive      = {J_ISCI},
  author       = {Yunfei Qiu and Xuechao Qiu},
  doi          = {10.1016/j.ins.2024.120249},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120249},
  shortjournal = {Inf. Sci.},
  title        = {A novel interval approximation method for passivity and stability analysis of delayed neural networks},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Attribute reduction for hybrid data based on statistical
distribution of data and fuzzy evidence theory. <em>ISCI</em>,
<em>662</em>, 120247. (<a
href="https://doi.org/10.1016/j.ins.2024.120247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybrid information system (HIS) refers to an information system (IS) including categorical attributes and numerical attributes. For an HIS, it is common to use neighborhood rough set model (NRS-model) to process different types of data. However, NRS-model applies the same neighborhood radius to deal with numerical data , which may lead to a decrease in classification ability of data. Fuzzy evidence theory is an important uncertainty reasoning method. It has been widely used in medical diagnosis , decision analysis and information fusion and other fields by virtue of its strengths of depicting uncertainty or unknown information. In this paper, fuzzy rough set model (FRS-model) based on statistical distribution of data is proposed to handle hybrid data and this model is combined with fuzzy evidence theory to design attribute reduction algorithms. Firstly, according to the statistical distribution of hybrid data, fuzzy similarity relation for each attribute is constructed and then FRS-model is established on the basis of the constructed fuzzy similarity relation. The advantage of this model lies in using different fuzzy similarity radii to construct fuzzy similarity relations, and improving the classification ability of data. After that, fuzzy belief map and fuzzy plausibility map are defined by means of fuzzy evidence theory. Subsequently, the above two maps are used to design attribute reduction algorithms . Furthermore, an overlap degree function is proposed to pre-sort attributes when designing algorithms, which can greatly reduce the times of searching for an attribute subset and ensure that the attributes with high separability are selected first. Finally, the experimental results indicate that the designed algorithms perform well in classification tasks and outlier detection tasks compared to some existing algorithms.},
  archive      = {J_ISCI},
  author       = {Zhaowen Li and Haixin Huang and Qin Huang and Yonghua Lin},
  doi          = {10.1016/j.ins.2024.120247},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120247},
  shortjournal = {Inf. Sci.},
  title        = {Attribute reduction for hybrid data based on statistical distribution of data and fuzzy evidence theory},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A surrogate-assisted differential evolution with
fitness-independent parameter adaptation for high-dimensional expensive
optimization. <em>ISCI</em>, <em>662</em>, 120246. (<a
href="https://doi.org/10.1016/j.ins.2024.120246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms (SAEAs) have gained considerable attention owing to their ability of tackling expensive optimization problems (EOPs). The surrogate model can be used to replace real fitness value with approximated one, thus greatly reducing computational cost in expensive function evaluations . However, most existing SAEAs are designed for expensive optimization with low or medium dimensions owing to the curse of dimensionality . To improve the performance for solving high-dimensional expensive optimization problems (HEOPs), a surrogate-assisted Differential Evolution with fitness-independent parameter adaptation (SADE-FI) is proposed in the paper. The SADE-FI algorithm consists of a global surrogate-assisted prescreening strategy (GSA-PS) and a local surrogate-assisted DE with fitness-independent parameter adaptation (LSA-FIDE). The main highlights of the paper can be summarized as follows: First, both global and local surrogates are employed to approximate the fitness value of candidate offspring in GSA-PS and LSA-FIDE, respectively. Second, a fitness-independent parameter adaptation mechanism is firstly incorporated into the framework of surrogate-assisted DE as an efficient parameter adaptation for surrogate-assisted search. Third, both the kernel space determination mechanism and linear population size reduction strategy are implemented to enhance the exploitation capability of LSA-FIDE. To validate the performance of SADE-FI, it was tested on expensive benchmark functions on 30D, 50D, 100D, and 200D, as well as a real-world antenna array design problem. The optimization results were compared with state-of-the-art algorithms, and the results indicate that SADE-FI has a significant performance advantage in solving HEOPs.},
  archive      = {J_ISCI},
  author       = {Laiqi Yu and Chongle Ren and Zhenyu Meng},
  doi          = {10.1016/j.ins.2024.120246},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120246},
  shortjournal = {Inf. Sci.},
  title        = {A surrogate-assisted differential evolution with fitness-independent parameter adaptation for high-dimensional expensive optimization},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving transferability of 3D adversarial attacks with
scale and shear transformations. <em>ISCI</em>, <em>662</em>, 120245.
(<a href="https://doi.org/10.1016/j.ins.2024.120245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As deep learning models become increasingly integral to various 3D applications, concerns about their vulnerability to adversarial attacks grow in tandem. This paper addresses the challenge of enhancing the transferability of 3D adversarial attacks, a critical aspect for evaluating model robustness across diverse scenarios. We propose a novel approach leveraging scale and shear transformations to generate adversarial examples that exhibit improved transferability across multiple 3D models. Our methodology involves carefully integrating scale and shear transformations into the adversarial perturbation generation process with only a marginal increase in computational time . The proposed attack method operates within the Carlini-Wagner (CW) optimization framework. For each iteration, it employs two hyperparameters: p a pa , determining the probability of transforming the input point cloud, and p s ps , deciding whether to shear or scale the point cloud. Limited to scaling and shearing transformations, Scale and Shear (SS) attack seamlessly integrates with established attack methods, enhancing flexibility and compatibility in adversarial attacks on 3D models. Extensive experiments show that the SS attack proposed in this paper can be seamlessly combined with the existing state-of-the-art (SOTA) 3D point cloud attack methods to form more powerful attack methods, and the SS attack improves the transferability over 3.6 times compared to the baseline. Moreover, while substantially outperforming the baseline methods , the SS attack achieves SOTA transferability under various defenses. Our code will be available online at: https://github.com/cuge1995/SS-attack .},
  archive      = {J_ISCI},
  author       = {Jinlai Zhang and Yinpeng Dong and Jun Zhu and Jihong Zhu and Minchi Kuang and Xiaming Yuan},
  doi          = {10.1016/j.ins.2024.120245},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120245},
  shortjournal = {Inf. Sci.},
  title        = {Improving transferability of 3D adversarial attacks with scale and shear transformations},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stabilization of stochastic systems with sampled-state
feedback controllers. <em>ISCI</em>, <em>662</em>, 120244. (<a
href="https://doi.org/10.1016/j.ins.2024.120244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the stabilization of continuous-time stochastic systems by a sampled-state feedback controller (SFC) placed in either drift or diffusion terms . Different from the traditionally state feedback controllers, the controller of a stochastic system in this paper is connected through a communication network, whose state needs to be sampled. Because of the controller state being sampled and Brownian motion existing simultaneously, it will be a challenge to ensure the stabilization of the closed-loop stochastic system. Particularly, it is very difficult to analyze the sampled-state error. To address this issue, an approach based on the exact integral solution to the stochastic error system is developed, in which some novel enlarging techniques are presented. Then, several stabilization conditions of stochastic systems based on the SFC added in the drift and diffusion terms respectively are established, whose upper sampling bound can be deduced and some of which are less conservative in terms of providing a larger sampling bound. Finally, the effectiveness and advantages of the proposed methods are illustrated with several numerical examples .},
  archive      = {J_ISCI},
  author       = {Guoliang Wang and Siyong Song and Yande Zhang},
  doi          = {10.1016/j.ins.2024.120244},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120244},
  shortjournal = {Inf. Sci.},
  title        = {Stabilization of stochastic systems with sampled-state feedback controllers},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Event-triggered fixed-time bipartite consensus for
nonlinear disturbed multi-agent systems with leader-follower and
leaderless controller. <em>ISCI</em>, <em>662</em>, 120243. (<a
href="https://doi.org/10.1016/j.ins.2024.120243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The event-triggered fixed-time bipartite consensus inside the domain of disturbed nonlinear multi-agent systems is examined in this study. A multitude of essential prerequisites are stipulated within signed networks, both in favor of and in opposition to leadership roles within nonlinear multi-agent systems, with the aim of ensuring the attainment of fixed-time bipartite consensus. Firstly, the control protocol is suggested to ensure the possibility of achieving bipartite fixed-time tracking consensus in multi-agent systems when there is a leader present. These control strategies have demonstrated the absence of Zeno behavior in studies. Secondly, the bipartite consensus without leaders is also discussed, as is Zeno behavior. Finally, with the goal of substantiating the reliability of the theoretical conclusions, illustrations are served by offering a couple of numeric instances.},
  archive      = {J_ISCI},
  author       = {Wei Zhang and Qian Huang and Adi Alhudhaif},
  doi          = {10.1016/j.ins.2024.120243},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120243},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered fixed-time bipartite consensus for nonlinear disturbed multi-agent systems with leader-follower and leaderless controller},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised data lakes discovery through unsupervised
metadata-driven weighted similarity. <em>ISCI</em>, <em>662</em>,
120242. (<a href="https://doi.org/10.1016/j.ins.2024.120242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data engineers invest significant effort in the early stages of data analysis , including identifying relevant datasets in large and complex data lakes. Data retrieval efficiency becomes an urgent concern as data volumes continue to increase with structures that vary in size and complexity. This paper presents a novel strategy for accelerating data discovery in data lakes. Our approach integrates self-supervised techniques and weighted similarity estimation for efficient dataset classification, facilitating faster search and retrieval. By extracting meta-feature characteristics, our approach improves data traceability in data lakes through clustering, resulting in significant improvements in modularity, showing an efficiency gain of 69.8%. Regarding dataset search through classification, it consistently achieves AUC-ROC scores exceeding 0.85, indicating strong performance in class differentiation. Finally, our method reduces the overall execution time more than twofold and shows promising applications for addressing real-world challenges in various data lake domains.},
  archive      = {J_ISCI},
  author       = {I Made Putrama and Peter Martinek},
  doi          = {10.1016/j.ins.2024.120242},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120242},
  shortjournal = {Inf. Sci.},
  title        = {Self-supervised data lakes discovery through unsupervised metadata-driven weighted similarity},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exponential stability of stochastic multi-layer complex
network with regime-switching diffusion via aperiodically intermittent
control. <em>ISCI</em>, <em>662</em>, 120241. (<a
href="https://doi.org/10.1016/j.ins.2024.120241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper pays attention to investigating the exponential stability of stochastic multi-layer complex network with regime-switching diffusion (SMLCNRSD). Different from the existing stability results on stochastic complex network, what we research is to consider the regularity of the solution process under the local conditions , and make use of the truncation method to obtain the global existence and uniqueness of the solution. Using graph theory, Lyapunov method , as well as some stochastic analysis techniques, several sufficient criteria for exponential stability are attained by aperiodically intermittent control. Finally, the theoretical results are applied to study the exponential stability of a two-layer Hindmarsh-Rose neuron network with regime-switching diffusion. Moreover, the effectiveness of the results provided has been well demonstrated through numerical simulations.},
  archive      = {J_ISCI},
  author       = {Jiamin Zhou and Chunmei Zhang and Huiling Chen},
  doi          = {10.1016/j.ins.2024.120241},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120241},
  shortjournal = {Inf. Sci.},
  title        = {Exponential stability of stochastic multi-layer complex network with regime-switching diffusion via aperiodically intermittent control},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global inverse optimality for a class of recurrent neural
networks with multiple proportional delays. <em>ISCI</em>, <em>662</em>,
120240. (<a href="https://doi.org/10.1016/j.ins.2024.120240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper formulates two novel theoretical designs of input-to-state stabilizing control for a class of recurrent neural networks with multiple proportional delays. The analysis tool developed in this paper is based on Lyapunov function and inverse optimality method, which does not require solving Hamilton-Jacobi-Bellman equations. Two inverse optimal feedback laws are constructed via the dimensions of state and input, which ensure the input-state stability for the considered system. When the dimensions of state and input are different, we establish a scalar function and give one of the control laws by Sontag&#39;s formula. Furthermore, the designs of inverse optimal control reach both global inverse optimality and global asymptotic stability of the system for some meaningful cost functional. Four numerical examples are provided to show the effectiveness of the inverse optimal control.},
  archive      = {J_ISCI},
  author       = {Weijun Ma and Xuhui Guo and Huaizhu Wang and Yuanshi Zheng},
  doi          = {10.1016/j.ins.2024.120240},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120240},
  shortjournal = {Inf. Sci.},
  title        = {Global inverse optimality for a class of recurrent neural networks with multiple proportional delays},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 12-lead ECG signal classification for detecting ECG
arrhythmia via an information bottleneck-based multi-scale network.
<em>ISCI</em>, <em>662</em>, 120239. (<a
href="https://doi.org/10.1016/j.ins.2024.120239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 12-lead electrocardiogram (ECG) is a reliable diagnostic tool for detecting and treating severe cardiovascular conditions like arrhythmia and heart attack. Deep neural networks (DNNs) have achieved higher accuracy in recent years than traditional ECG signal classification task methods. Convolutional neural network (CNN) and Transformer are the two mainstream architectures of DNN, respectively good at extracting local and global features from input data . This paper proposes the multi-scale convolutional Transformer network (MCTnet), an efficient combination of Transformer encoder and CNN for ECG signal classification. MCTnet utilizes the advantages of CNN and self-attention mechanisms to capture potential features in ECG signal accurately. The dual-branch Transformer encoder extracts different-scale feature representations, enabling the capture of both local and global information. Additionally, an information bottleneck method eliminates redundant information and enhances task-relevant information in the learned representations. To evaluate the performance of MCTnet, comprehensive experiments are conducted on three commonly used ECG datasets. The results demonstrate that MCTnet outperforms current deep learning-based models, highlighting its effectiveness in ECG signal classification. It also shows that the performance of the model can be effectively improved by utilizing multi-scale representation learning and information bottleneck.},
  archive      = {J_ISCI},
  author       = {Siyuan Zhang and Cheng Lian and Bingrong Xu and Yixin Su and Adi Alhudhaif},
  doi          = {10.1016/j.ins.2024.120239},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120239},
  shortjournal = {Inf. Sci.},
  title        = {12-lead ECG signal classification for detecting ECG arrhythmia via an information bottleneck-based multi-scale network},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An opinions-updating model for large-scale group
decision-making driven by autonomous learning. <em>ISCI</em>,
<em>662</em>, 120238. (<a
href="https://doi.org/10.1016/j.ins.2024.120238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aspires to explore and construct a more objective and automated large-scale group decision-making (LSGDM) model. The concept of vacillation degree based on probabilistic double hierarchy linguistic term set is proposed to describe the characteristics of decision makers (DMs). The criteria weights are obtained by entropy measure , and then a clustering method is constructed. Moreover, the autonomous learning probability is presented to characterize the extent to which DMs accept the opinions of others. The complex connections between DMs can be more clearly described by visualizing the autonomous learning. Considering the deficiencies of the existing feedback adjustment mechanism on the setting of the suggested adjustment range, the autonomous learning and opinions-updating process for internal and external subgroups are designed. Then consensus judgment method is also proposed from subgroups and group. Based on the above work, an opinions-updating model for LSGDM driven by autonomous learning is constructed. The validity of the model is verified by a case study of emergency medical service agency selection. Finally, three simulation models and comparative analysis are established to test the opinions-updating model.},
  archive      = {J_ISCI},
  author       = {Xiaoting Cheng and Kai Zhang and Tong Wu and Zeshui Xu and Xunjie Gou},
  doi          = {10.1016/j.ins.2024.120238},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120238},
  shortjournal = {Inf. Sci.},
  title        = {An opinions-updating model for large-scale group decision-making driven by autonomous learning},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fully distributed adaptive cooperative output regulation of
heterogeneous multi-agent systems with hybrid event-triggering
mechanism. <em>ISCI</em>, <em>662</em>, 120237. (<a
href="https://doi.org/10.1016/j.ins.2024.120237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on the event-triggered cooperative output regulation problem (CORP) of multi-agent systems with heterogeneous dynamics. Two design criteria are required be achieved: event-triggered communication between agents has strictly positive minimum inter-event time (MIET), and global information with respect to communication topology is not needed to implement the event-triggered control strategy . These two criteria are significant, but cannot be simultaneously satisfied using the relevant existing results. In this work, two event-triggered observers with hybrid triggering conditions are developed to estimate the matrix and state of the exosystem, the MIET is enforced to be positive by incorporating an auxiliary function with decreasing dynamics into the event-triggering mechanism (ETM). This is more stringent than simply removing Zeno behavior and is more useful in engineering applications . Additionally, distributed controllers are developed based on the estimated state and regulator equation. The proposed method, which is better and more useful than the up-to-date results in literature, and can satisfy the two design criteria as mentioned before. Finally, numerical examples are provided to demonstrate the effectiveness.},
  archive      = {J_ISCI},
  author       = {Guanglei Zhao and Yucong Tang and Changchun Hua},
  doi          = {10.1016/j.ins.2024.120237},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120237},
  shortjournal = {Inf. Sci.},
  title        = {Fully distributed adaptive cooperative output regulation of heterogeneous multi-agent systems with hybrid event-triggering mechanism},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonzero-sum games using actor-critic neural networks: A
dynamic event-triggered adaptive dynamic programming. <em>ISCI</em>,
<em>662</em>, 120236. (<a
href="https://doi.org/10.1016/j.ins.2024.120236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly investigates the nonzero-sum games of nonlinear systems with unmatched uncertainty by using actor-critic neural networks . To handle the unmatched components, an auxiliary system with a modified value function is constructed, which transforms the robust stabilization issue into the optimal control issue. Then, a novel dynamic event-triggering condition is designed to further save bandwidth via introducing a dynamic variable. In addition, the actor-critic algorithm is employed in adaptive dynamic programming to achieve Nash equilibrium , which is tuned together with the control policy. By constructing appropriate Lyapunov functions , a criterion is established to ensure that the considered system is uniformly ultimately bounded. Finally, the effectiveness of the developed strategy is demonstrated by an example.},
  archive      = {J_ISCI},
  author       = {Hao Shen and Ziwei Li and Jing Wang and Jinde Cao},
  doi          = {10.1016/j.ins.2024.120236},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120236},
  shortjournal = {Inf. Sci.},
  title        = {Nonzero-sum games using actor-critic neural networks: A dynamic event-triggered adaptive dynamic programming},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consistency improvement and local consensus adjustment for
probabilistic linguistic preference relations considering personalized
individual semantics. <em>ISCI</em>, <em>662</em>, 120233. (<a
href="https://doi.org/10.1016/j.ins.2024.120233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the challenge of facilitating overall problem solving and improving the overall efficiency of intelligent systems efforts through group decision making (GDM) by experts at all stages of the systems, this paper proposes an approach that focuses on improving consistency and enhancing local consensus. The proposed approach specifically considers the probabilistic linguistic preference relations (PLPRs) and incorporates personalized individual semantics (PISs) of decision makers (DMs). For the consistency procedure, we construct an expectation-additive consistency-driven semantic model to acquire PISs of different DMs. Secondly, the preference relation (PR) which does not satisfy the consistency is improved based on a minimum adjustment model. In particular, according to the expected value with PISs this paper, DMs offer PLPRs can be transformed into fuzzy preference relations (FPRs) correspondently for making decisions. For the FPRs, a virtue consensus measure is explored for the consensus reaching process (CRP) from two levels to combine the average value and variance of pair similarities, which effectively improves the accuracy of the consensus measurement. Next, a collective consensus level is calculated to replace the consensus threshold objectively, and then the DMs and alternative pairs that do not reach consensus are identified locally from two levels. Subsequently, an optimisation model that combines the two objectives is developed to improve the consensus level while ensuring consistency. Finally, our method is applied to a publicly available air quality dataset, and the consensus and ranking results are discussed in comparison with other advanced methods to confirm the superiority of the established method.},
  archive      = {J_ISCI},
  author       = {Xueling Ma and Jinxing Zhu and Gang Kou and Jianming Zhan},
  doi          = {10.1016/j.ins.2024.120233},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120233},
  shortjournal = {Inf. Sci.},
  title        = {Consistency improvement and local consensus adjustment for probabilistic linguistic preference relations considering personalized individual semantics},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Validating and constructing behavioral models for simulation
and projection using automated knowledge extraction. <em>ISCI</em>,
<em>662</em>, 120232. (<a
href="https://doi.org/10.1016/j.ins.2024.120232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human behavior may be one of the most challenging phenomena to model and validate. This paper proposes a method for automatically extracting and compiling evidence on human behavior determinants into a knowledge graph. The method (1) extracts associations of behavior determinants and choice options in relation to study groups and moderators from published studies using Natural Language Processing and Deep Learning , (2) synthesizes the extracted evidence into a knowledge graph, and (3) sub-selects the model components and relationships that are relevant and robust. The method can be used to either (4a) construct a structurally valid simulation model before proceeding with calibration or (4b) to validate the structure of existing simulation models. To demonstrate the feasibility of the method, we discuss an example implementation with mode of transport as behavior choice. We find that including non-frequently studied significant behavior determinants drastically improves the model&#39;s explanatory power in comparison to only including frequently studied variables. The paper serves as a proof-of-concept which can be reused, extended or adapted for various purposes.},
  archive      = {J_ISCI},
  author       = {Tabea S. Sonnenschein and G. Ardine de Wit and Nicolette R. den Braver and Roel C.H. Vermeulen and Simon Scheider},
  doi          = {10.1016/j.ins.2024.120232},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120232},
  shortjournal = {Inf. Sci.},
  title        = {Validating and constructing behavioral models for simulation and projection using automated knowledge extraction},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Probabilistic rotation modeling based on directional mixture
density networks. <em>ISCI</em>, <em>662</em>, 120231. (<a
href="https://doi.org/10.1016/j.ins.2024.120231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting 3D rotations from a single image presents a significant challenge, primarily due to the inherent uncertainty arising from factors such as high symmetry, self-obscuration, and noise in the 3D environment. In this work, we propose a novel multimodal-based probabilistic model that integrates the matrix Fisher distribution and von Mises Fisher distribution into a mixture density network. Our model not only captures the inherent uncertainty of the object but also learns this uncertainty directly from the training data , thereby enhancing the robustness, flexibility, and efficiency of the model. To further refine the model&#39;s ability to handle ambiguities and recognize multiple distinct modes, we introduce a relaxed version of the winner-take-all loss function. This adaptation significantly improves the model&#39;s capability in accurately representing complex multimodal distributions . The performance of our model is rigorously assessed using two challenging datasets: Pascal3D+ and ModelNet10-SO(3). Extensive experimental analysis highlights the model&#39;s exceptional capability to fit complex multimodal distributions. Notably, when tested on the ModelNet10-SO(3) dataset, which is characterized by its ambiguity, and the more unequivocal Pascal3D+ dataset, our model outperforms the prevailing top baseline models by achieving accuracy improvements of 2.7% and 3.4%, respectively, at the minimum angle threshold. These results not only demonstrate our model&#39;s advanced capabilities in fitting complex distributions but also validate its effectiveness in accurately predicting 3D rotations in both ambiguous and unambiguous scenarios.},
  archive      = {J_ISCI},
  author       = {Lidan Zeng and Wentao Fan and Nizar Bouguila},
  doi          = {10.1016/j.ins.2024.120231},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120231},
  shortjournal = {Inf. Sci.},
  title        = {Probabilistic rotation modeling based on directional mixture density networks},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic multi-granularity spatial-temporal graph attention
network for traffic forecasting. <em>ISCI</em>, <em>662</em>, 120230.
(<a href="https://doi.org/10.1016/j.ins.2024.120230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting, as the cornerstone of the development of intelligent transportation systems , plays a crucial role in facilitating accurate control and management of urban traffic. By treating sensors as nodes in a road network , recent research on modeling complex spatial-temporal graph structures has achieved notable advancements in traffic forecasting. However, limited by the increasing number of sensors and recorded data points , most of the recent studies on spatial-temporal graph neural network (STGNN) research concentrate on aggregating short-term (e.g. recent one-hour) traffic history to predict future data. Furthermore, almost all previous STGNNs neglect to incorporate the cyclical patterns that appear in the traffic historical data . For example, the cyclical patterns of traffic on the same day or hour of each week can help improve the accuracy of future traffic predictions . In this paper, we propose a novel Dynamic Multi-Granularity Spatial-Temporal Graph Attention Network (DmgSTGAT) framework for traffic forecasting, which leverages multi-granularity spatial-temporal correlations across different time-scales and variables to efficiently consider cyclical patterns in traffic data. We also design effective temporal encoding and transformer encoding layers to produce meaningful multi-granularity sensor-level, day-level, hour-level, and point-level representations. The multi-granularity spatial-temporal graph attention network can use the produced representations to extract useful but sparsely distributed patterns accurately, which also avoids the influence of extra noise from the long-term history. Experimental results on four real-world traffic datasets show that DmgSTGAT can achieve state-of-the-art performance with the help of multi-granularity cyclical patterns compared with various recent baselines.},
  archive      = {J_ISCI},
  author       = {Wei Sang and Huiliang Zhang and Xianchang Kang and Ping Nie and Xin Meng and Benoit Boulet and Pei Sun},
  doi          = {10.1016/j.ins.2024.120230},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120230},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic multi-granularity spatial-temporal graph attention network for traffic forecasting},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Noisy feature decomposition-based multi-label learning with
missing labels. <em>ISCI</em>, <em>662</em>, 120228. (<a
href="https://doi.org/10.1016/j.ins.2024.120228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multi-label learning with missing labels (MLML) has become a popular topic. The major challenge for MLML is enhancing the performance of classifiers in the presence of missing labels. Most existing algorithms focus on recovering missing labels using label correlations. However, incomplete label correlations in the early stages of recovery may adversely affect the results. To address this problem, we focus on the original task of finding the mapping between labels and features and propose a Noisy Feature Decomposition-based Multi-label learning with Missing Labels (NFDMML) method. Specifically, the label information is assumed to be integral, and the features corresponding to missing labels are defined as noisy features. Not recovering the missing labels, we reduce the interference of noisy features in the classifications. Accordingly, the MLML problem is converted into a feature decomposition problem. Based on label correlation, a low-rank relationship is used to eliminate the features caused by missing labels, and reverse mapping is employed to preserve the features corresponding to the relevant labels. We conduct detailed experiments on multiple datasets, and the results clearly demonstrate that the proposed method achieves competitive performance over other algorithms.},
  archive      = {J_ISCI},
  author       = {Jiaman Ding and Yihang Zhang and Lianyin Jia and Xiaodong Fu and Ying Jiang},
  doi          = {10.1016/j.ins.2024.120228},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120228},
  shortjournal = {Inf. Sci.},
  title        = {Noisy feature decomposition-based multi-label learning with missing labels},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Unsupervised feature selection via dual space-based low
redundancy scores and extended OLSDA. <em>ISCI</em>, <em>662</em>,
120227. (<a href="https://doi.org/10.1016/j.ins.2024.120227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering is a widely used method for unsupervised feature selection (UFS) to generate pseudo labels. Nonetheless, it is acknowledged that graph algorithms suffer from issues such as redundancy and the dissatisfaction of connectivity, which greatly affect the quality of the learning local manifold. Moreover, existing UFS methods usually ignore the linear dependency among features and the role of non-negative semantics of the predicted labels. Hence, a novel algorithm using dual space-based low redundancy scores and extended orthogonal least square discriminant analysis (OLSDA), abbreviated as DLSEO, is proposed in this paper. Specifically, extended OLSDA is employed to derive non-negative clustering labels and a manifold structure, which avoids explicitly constructing a Laplacian graph . The dual space-based low redundancy scores related to mutual information eliminate redundant data and features, preventing their interference in the feature selection process. Moreover, ℓ 2 , 1 − 2 ℓ2,1−2 -norm is introduced to simultaneously guarantee the feature weight matrix&#39;s sparsity and ensure the selection of salient features . The results of experiments conducted on twelve benchmark datasets compared with several relevant methods show the superiority of DLSEO.},
  archive      = {J_ISCI},
  author       = {Duanzhang Li and Hongmei Chen and Yong Mi and Chuan Luo and Shi-Jinn Horng and Tianrui Li},
  doi          = {10.1016/j.ins.2024.120227},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120227},
  shortjournal = {Inf. Sci.},
  title        = {Unsupervised feature selection via dual space-based low redundancy scores and extended OLSDA},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient heuristic power analysis framework based on
hill-climbing algorithm. <em>ISCI</em>, <em>662</em>, 120226. (<a
href="https://doi.org/10.1016/j.ins.2024.120226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional nonprofiling side-channel analysis frequently adopts divide-and-conquer strategy to recover the secret key of a cryptographic algorithm . Only a single key byte is used, whereas the remaining bytes are considered extraneous noise. If the cryptographic algorithm is implemented in hardware with parallel processing , the strategy will lead to the inefficient use of information. The combination of intelligent algorithms and side-channel analysis offers a different idea for nonprofiling methods for parallel hardware implementations. It transforms the problem of key recovery into key optimization. In this paper, we adopt this idea and propose an efficient heuristic framework to assist correlation power analysis. The multipoint hill-climbing algorithm will be used to find the optimal key candidates with higher scores, and the correct key will be found in the optimal key candidates by key enumeration. Multiple bytes of the secret key are used to take full advantage of the helpful information. Besides, two search strategies are introduced to overcome the efficiency problem, and two key enumeration strategies are introduced to solve the key recovery problem when the traces are insufficient. Experimental results on the public DPA Contest V1 dataset show that the heuristic framework performs better than other classical methods, verifying its effectiveness.},
  archive      = {J_ISCI},
  author       = {Shaofei Sun and Shijun Ding and An Wang and Yaoling Ding and Congming Wei and Liehuang Zhu and Yongjuan Wang},
  doi          = {10.1016/j.ins.2024.120226},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120226},
  shortjournal = {Inf. Sci.},
  title        = {An efficient heuristic power analysis framework based on hill-climbing algorithm},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conditional image hiding network based on style transfer.
<em>ISCI</em>, <em>662</em>, 120225. (<a
href="https://doi.org/10.1016/j.ins.2024.120225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various data hiding methods have been suggested to hide secret images within stego images . However, many of them could be easily detected by steganalytic tools due to their large hidden information. In this paper, we enhance the undetectability of image hiding network by mapping latent representation conditional on secret information . We extend the idea of image generation-based steganography and propose a transformer-based image hiding network that can hide a secret image with the same size as the target image. The proposed scheme uses style transferring to help map latent representation. The hiding network of the proposed scheme consists of three modules: encoding, transfer, and synthesis modules. The encoding module extracts the latent representations from content and secret images, the transfer module stylizes the latent representation, and the synthesis module fuses the latent representations to synthesize a target image with the secret image hidden in it. A new synthesis module and corresponding extraction network are developed to enhance recovery accuracy. The proposed scheme shows high image quality on both target images and recovered secret images. Furthermore, it can resist steganalytic tools and thus provide good security.},
  archive      = {J_ISCI},
  author       = {Fenghua Zhang and Bingwen Feng and Zhihua Xia and Jian Weng and Wei Lu and Bing Chen},
  doi          = {10.1016/j.ins.2024.120225},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120225},
  shortjournal = {Inf. Sci.},
  title        = {Conditional image hiding network based on style transfer},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-singular fixed-time consensus tracking of high-order
multi-agent systems with unmatched uncertainties and practical state
constraints. <em>ISCI</em>, <em>662</em>, 120224. (<a
href="https://doi.org/10.1016/j.ins.2024.120224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a fixed-time consensus-tracking problem of an uncertain nonlinear multi-agent system with practical state constraints that can be fully or partially constrained is considered. A novel unified transformation is proposed to address practical state constraints. Based on the proposed transformation function, a distributed fixed-time observer is designed for the followers to approximate the transformation of a leader&#39;s output. Furthermore, we apply an adaptive neural network technique and add a power integrator technique to design a nonsingular fixed-time controller that ensures practical fixed-time consensus tracking and satisfies state constraints. Finally, simulations are performed to verify the theoretical results.},
  archive      = {J_ISCI},
  author       = {Chaoqun Guo and Jiangping Hu and Ju H. Park and Bijoy Kumar Ghosh},
  doi          = {10.1016/j.ins.2024.120224},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120224},
  shortjournal = {Inf. Sci.},
  title        = {Non-singular fixed-time consensus tracking of high-order multi-agent systems with unmatched uncertainties and practical state constraints},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiview latent space learning with progressively
fine-tuned deep features for unsupervised domain adaptation.
<em>ISCI</em>, <em>662</em>, 120223. (<a
href="https://doi.org/10.1016/j.ins.2024.120223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation (UDA) and Multi-source Domain Adaptation (MDA) have emerged as practical techniques to address the domain shift between source and target domains with different statistical distributions, where the target domain often has unlabeled samples . In recent years, end-to-end training approaches have been employed to learn domain-invariant representations, which enable customized adaptations simultaneously for UDA and MDA tasks. Although the conventional pseudo-labeling approach can leverage unlabeled target samples, the potential for inaccurate pseudo-labeling is counterproductive. This work proposes a multiview latent space learning framework with progressively fine-tuned deep features to improve UDA and MDA performance. Specifically, we construct three views, including features directly extracted from pre-trained deep learning models , fine-tuned features with source samples, and fine-tuned features with source samples and pseudo-labeled target samples, to enable unsupervised clustering analysis . More importantly, we utilize a multiview-based selective pseudo-labeling approach that selects the most confident labeled target samples with the maximum conditional probability . Through systematic experiential evaluations incorporating deep learning backbones such as ResNet-50 and DeiT-base, we demonstrate that our proposed multiview latent space learning method consistently outperforms state-of-the-art approaches on various UDA and MDA tasks.},
  archive      = {J_ISCI},
  author       = {Chenyang Zhu and Qian Wang and Yunxin Xie and Shoukun Xu},
  doi          = {10.1016/j.ins.2024.120223},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120223},
  shortjournal = {Inf. Sci.},
  title        = {Multiview latent space learning with progressively fine-tuned deep features for unsupervised domain adaptation},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Rectifying inaccurate unsupervised learning for robust time
series anomaly detection. <em>ISCI</em>, <em>662</em>, 120222. (<a
href="https://doi.org/10.1016/j.ins.2024.120222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised time series anomaly detection is a challenging task. Data contamination brings more challenges for the existing methods that rely on completely clean training data . Moreover, sparse anomaly knowledge leads to the deviation of the learned normality boundary. In this work, we propose a time series anomaly detection method, namely, Rectified Inaccurate Anomaly Detection (RiAD), for training an anomaly detector under data contamination. Specifically, to improve the normality description learned from the data, we propose two key components: an Augmented Uncertainty Estimation Module and Adaptive Reconstruction Loss. These components adaptively penalize uncertainty prediction and anomalous outliers to enforce the learning of valid normality description from normal samples instead of anomalous ones. Furthermore, we design an Anomaly Injection Module, which injects anomaly knowledge into the model by generating different types of simulated anomaly examples to learn accurate normality boundary and utilizes the Awareness Memory Module to prevent unexpected generalization of anomalous information. Extensive experiments on ten real-world datasets demonstrate the superiority of the proposed method over state-of-the-art methods and achieve superior performance in settings with different levels of anomaly contamination.},
  archive      = {J_ISCI},
  author       = {Zejian Chen and Zuoyong Li and Xinwei Chen and Xiaobo Chen and Haoyi Fan and Rong Hu},
  doi          = {10.1016/j.ins.2024.120222},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120222},
  shortjournal = {Inf. Sci.},
  title        = {Rectifying inaccurate unsupervised learning for robust time series anomaly detection},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improvement of full consistency multiple objective
optimization based on concept of stratification theory and PageRank and
linguistic polytopic hesitant fuzzy sets. <em>ISCI</em>, <em>662</em>,
120221. (<a href="https://doi.org/10.1016/j.ins.2024.120221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Innovative, Resilient, and Green Supplier Selection (IRGSS) is an emerging need often viewed as a complex multi-criteria decision-making problem. However, overly stringent restrictions on the assessed values, such as q-rung ortho -pair hesitant fuzzy uncertain linguistic sets, and dependent uncertainty events affecting criterion weights threaten the decision’s reliability. Thus, LPHFS-SPFUCOM-MULTIMOORA is proposed to address these challenges. First, the paper proposes novel Linguistic Polytopic Hesitant Fuzzy sets (LPHFSs), which assume the sum of the q th qth power of the three types of memberships is not greater than 1 and relax the constraints on the assessed values. Second, the Full Consistency Method (FUCOM) is improved to find weights by integrating the Concept of Stratification Theory (CST) and PageRank, named SPFUCOM. CST depicts the occurrence process of uncertain events and PageRank finds their occurrence probabilities considering dependency. Third, the multiplicative Multi-objective Optimization by Ratio Analysis (MULTIMOORA) is novelly applied with SPFUCOM and LPHFSs to rank suppliers. Finally, a case from an electric vehicle manufacturer is studied to illustrate the applicability of the proposed method. Through sensitivity and comparative analyses, the rationality and advantages of the proposed method are verified. This study can provide insights for managers to solve the IRGSS problem.},
  archive      = {J_ISCI},
  author       = {Xu Zhang and Mark Goh and Sijun Bai and Dragan Pamucar and Libiao Bai},
  doi          = {10.1016/j.ins.2024.120221},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120221},
  shortjournal = {Inf. Sci.},
  title        = {Improvement of full consistency multiple objective optimization based on concept of stratification theory and PageRank and linguistic polytopic hesitant fuzzy sets},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guaranteed cost extended dissipative stabilization of
switched IT2 fuzzy systems via intermittent control and its
applications. <em>ISCI</em>, <em>662</em>, 120220. (<a
href="https://doi.org/10.1016/j.ins.2024.120220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the guaranteed cost extended dissipative stabilization problem of switched IT-2 fuzzy systems (SFSs) via intermittent control. Firstly, we propose a new class of system performance coefficients, taking both the extended dissipative performance and quadratic cost function performance into account. Then, by using a switched-path-dependent fuzzy Lyapunov functions (SFLFs) approach, the membership-function-shape-dependent (MFSD) existence conditions of a set of intermittent controllers are established. Furthermore, we apply the designed intermittent control scheme to three practical control problems: 1) A controller/actuator-failure-triggered intermittent controller is designed, and the guaranteed cost extended dissipative performance of SFSs is ensured in the presence of controller/actuator failures; 2) A switching-triggered intermittent controller is designed, and the guaranteed cost extended dissipative performance of SFSs is ensured in the presence of transmission delay of switching signal, and the asynchronous phenomena is eliminated; 3) A hybrid-triggered intermittent controller is designed, and the guaranteed cost extended dissipative performance of SFSs is ensured while the control resources are saved. Finally, the effectiveness of the results are demonstrated through a robot arm model.},
  archive      = {J_ISCI},
  author       = {Yang Li and Tianping Zhang and Hongbin Zhang},
  doi          = {10.1016/j.ins.2024.120220},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120220},
  shortjournal = {Inf. Sci.},
  title        = {Guaranteed cost extended dissipative stabilization of switched IT2 fuzzy systems via intermittent control and its applications},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring properties and inequalities for geometrically
arithmetically-cr-convex functions with cr-order relative entropy.
<em>ISCI</em>, <em>662</em>, 120219. (<a
href="https://doi.org/10.1016/j.ins.2024.120219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new class of interval-valued functions which we call Geometrically Arithmetically Cr-convex functions (GA-Cr-convex functions) and investigate its properties. We explore necessary and sufficient conditions for an interval-valued function to be a GA-Cr-convex function through two distinct approaches. Firstly, we propose these conditions connecting GA-Cr-convex functions with two real-valued GA-convex functions, and secondly, we examine them with respect to a Cr-convex function. Furthermore, we employ our findings to establish generalizations of several renowned inequalities including Jensen&#39;s inequality , Jensen-Mercer inequality, and Hermite-Hadamard inequality for GA-Cr-convex functions. The derived inequalities are consistent with the corresponding inequalities for real-valued functions. Consequently, we re-capture several significant results from recent literature. We also define a strong version of the newly introduced class, investigate its properties and prove well-known inequalities for the strong version as well. Lastly, we demonstrate applications of the Cr-order inequalities in information science by defining Cr-relative entropy via log-sum inequality for interval-valued functions. For Cr-order relative entropy , we prove non–negativity, joint convexity and monotonicity to generalize these properties, previously known for Tsallis relative entropy . Consequently, we obtain a generalization of data (information) processing inequality to complete the impact of our work in three directions including generalization, consistency with literature, and applications in information theory .},
  archive      = {J_ISCI},
  author       = {Asfand Fahad and Yuanheng Wang and Zammad Ali and Riaz Hussain and Shigeru Furuichi},
  doi          = {10.1016/j.ins.2024.120219},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120219},
  shortjournal = {Inf. Sci.},
  title        = {Exploring properties and inequalities for geometrically arithmetically-cr-convex functions with cr-order relative entropy},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Studying the memory property and event-triggered control of
fractional systems. <em>ISCI</em>, <em>662</em>, 120218. (<a
href="https://doi.org/10.1016/j.ins.2024.120218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the memory property and the historical dynamic information of a fractional system via event-triggered control are studied. A unit step function is introduced and the control input is taken as a piecewise function. By theorem analysis and numerical simulations, it is shown that the fractional calculus of a piecewise function is relevant to the entire historical dynamic information and cannot be calculated in segments because of its memory property. So, the state of a fractional system via event-triggered control is affected by all input from the initial time , but not the triggering time , to the current time. But in previous studies, this property is neglected and the historical dynamic information has not been fully studied, which disagrees with the real physical systems . Therefore, the historical dynamic information of a fractional system via event-triggered control should be studied in order to satisfy the demands in engineering.},
  archive      = {J_ISCI},
  author       = {Jianbing Hu},
  doi          = {10.1016/j.ins.2024.120218},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120218},
  shortjournal = {Inf. Sci.},
  title        = {Studying the memory property and event-triggered control of fractional systems},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated distillation and blockchain empowered secure
knowledge sharing for internet of medical things. <em>ISCI</em>,
<em>662</em>, 120217. (<a
href="https://doi.org/10.1016/j.ins.2024.120217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of Internet of Things (IoT) and Artificial Intelligence (AI) technologies, smart services have penetrated into every aspect of our daily lives, including the medical treatment and healthcare fields. However, due to security and privacy issues, medical data cannot be easily shared, which may lead to the situation of the so-called data silos. Challenges in existing approaches when building medical data sharing models can be summarized as: i) It is very challenging to ensure that the privacy of the medical data is protected and to identify the ownership of medical data; ii) Their models always result in poor performance or have the problem of excessive communication overhead due to the large amount of model parameters; iii) The current scenario of combining federated learning and blockchain generally ignores the load on nodes, which may easily lead to a lack of efficiency and fairness during the consensus process. In this study, we propose a Federated Distillation and Blockchain empowered Secure Knowledge Sharing (FDBC-SKS) model, which transforms the data sharing problem into a collaborative model knowledge sharing problem, aiming to provide a lightweight distributed deep learning framework in Internet of Medical Things (IoMT) environments. A peer-to-peer federated distillation mechanism is designed to enable a decentralized federated learning with better model flexibility and less communication consumption, based on the better knowledge utilization from each local model. A reinforcement learning enhanced consensus mechanism for blockchain is devised to improve the model convergence performance, alleviate the problem of low computational efficiency, while enhancing the fairness in terms of node load balancing during the node selection and block generation process. Experiment and evaluation results based on two real-world datasets demonstrate the usefulness of our proposed model toward secure and effective data sharing in IoMT oriented smart application development compared with other similar methods.},
  archive      = {J_ISCI},
  author       = {Xiaokang Zhou and Wang Huang and Wei Liang and Zheng Yan and Jianhua Ma and Yi Pan and Kevin I-Kai Wang},
  doi          = {10.1016/j.ins.2024.120217},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120217},
  shortjournal = {Inf. Sci.},
  title        = {Federated distillation and blockchain empowered secure knowledge sharing for internet of medical things},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian and stochastic game joint approach for cross-layer
optimal defensive decision-making in industrial cyber-physical systems.
<em>ISCI</em>, <em>662</em>, 120216. (<a
href="https://doi.org/10.1016/j.ins.2024.120216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The propagation of cyber-attacks targeting modern industrial cyber-physical systems (ICPSs) is considered a sophisticated and persistent cross-layer penetration process, posing significant cyber-to-physical (C2P) risks to critical industrial infrastructures. However, existing defensive solutions for ICPSs lack the global defensive decision-making capacity against such persistent and stealthy cross-layer threats. This paper proposes a Bayesian-Stochastic hybrid game-theoretic approach that can generate optimal defensive strategies throughout the cross-layer penetration lifecycle, even without full information about attackers. Specifically, we first present a unified quantification framework to guarantee consistent utility function configurations in a cyber-physical layer integrated system . Then, we propose a state transition-based stochastic game model to characterize the dynamic evolution process of cross-layer penetration. The attack-defense interaction in each state is modeled as an incomplete-information Bayesian game to capture the inherent uncertainties of attacker information . Furthermore, a multi-agent Bayesian Q-learning (MABQL) algorithm is developed to learn the optimal defensive strategies despite incomplete information . The proposed approach is implemented and assessed based on a real-world ICPS testbed and the numerical results validate its feasibility and effectiveness for making optimal defensive decisions.},
  archive      = {J_ISCI},
  author       = {Pengchao Yao and Zhengze Jiang and Bingjing Yan and Qiang Yang and Wenhai Wang},
  doi          = {10.1016/j.ins.2024.120216},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120216},
  shortjournal = {Inf. Sci.},
  title        = {Bayesian and stochastic game joint approach for cross-layer optimal defensive decision-making in industrial cyber-physical systems},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Network-level short-term traffic state prediction
incorporating critical nodes: A knowledge-based deep fusion approach.
<em>ISCI</em>, <em>662</em>, 120215. (<a
href="https://doi.org/10.1016/j.ins.2024.120215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The critical nodes (CNs) in urban transportation networks, defined as road entities (such as road segments or detectors in a road network) that present highly volatile traffic states, can significantly impact the overall traffic conditions. However, recent studies are unable to explicitly address CNs in traffic state prediction tasks. In this study, we develop a novel knowledge-based graph convolutional gated recurrent network incorporating critical nodes (KGCGRN-CN) to forecast the network-level short-term traffic states. The KGCGRN-CN model consists of three learning blocks: (i) a spectral graph convolution block that captures the network-level and CN-level spatial features in the data; (ii) a novel knowledge-based spatial feature fusion block that tailors the fusion of the network-level and the CN-level spatial features using geographical and traffic information of each road entity; and (iii) a temporal feature learning block, which captures the temporal patterns of the fused features. The KGCGRN-CN model is compared with several state-of-the-art benchmark models using a real-world freeway dataset. Results show that the developed model outperforms the benchmark models by a mean absolute error of 1.03 km/h on average. Further numerical experiments are conducted to demonstrate the effectiveness of the KGCGRN-CN model.},
  archive      = {J_ISCI},
  author       = {Haipeng Cui and Shukai Chen and Hua Wang and Qiang Meng},
  doi          = {10.1016/j.ins.2024.120215},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120215},
  shortjournal = {Inf. Sci.},
  title        = {Network-level short-term traffic state prediction incorporating critical nodes: A knowledge-based deep fusion approach},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Local sparse discriminative feature selection.
<em>ISCI</em>, <em>662</em>, 120214. (<a
href="https://doi.org/10.1016/j.ins.2024.120214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection has been widely used in machine learning for a long time. In this paper, we propose a supervised local sparse discriminative feature selection method named LSDFS to obtain sparse features by imposing ℓ 2 , 0 ℓ2,0 -norm constraint on transformation matrix . Differently from traditional approaches, our method does not require approximation or relaxation schemes, such as ℓ 2 , p ℓ2,p -norm to solve long-standing challenge. Our method is based on the trace difference form of Linear Discriminant Analysis (LDA), which can efficiently obtain discriminative information in low-dimensional space. In order to explore the local structure of data which contains more discriminative information, we adopt a sparse connections graph between anchor points and data points instead of fully-connected graph with time-consuming, and add a decay parameter to avoid trivial solutions , making the model more precisely. Extensive experiments conducted on synthetic datasets and several real-world datasets have demonstrated the advantages of our method.},
  archive      = {J_ISCI},
  author       = {Canyu Zhang and Shaojun Shi and Yanping Chen and Feiping Nie and Rong Wang},
  doi          = {10.1016/j.ins.2024.120214},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120214},
  shortjournal = {Inf. Sci.},
  title        = {Local sparse discriminative feature selection},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring on role of location in intelligent news
recommendation from data analysis perspective. <em>ISCI</em>,
<em>662</em>, 120213. (<a
href="https://doi.org/10.1016/j.ins.2024.120213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location factor of recommender systems has been extensively studied in the past decade . However, there is no research thoroughly analyzing location’s role in news recommendation. In this paper, a comprehensive exploration on role of location in news recommendation is presented. First of all, based on analysis of real news datasets, we find that news recommendation differs from spatial item recommendation. Location affects news consumption behaviors of users with two-fold aspects including geographic feature and semantic feature . Regarding geographic feature, location influences news recommendation according to region rather than latitude-longitude level. Furthermore, interesting news topics are also impacted by semantic feature of location. Semantic feature may play a more positive role than geographic feature. The novel findings consistently manifest that, as non-spatial items, news differ from spatial items in that location influences users&#39; selection in terms of different pattern and degree. In summary, geographic and semantic features influence reading preference through mapping locations into special topics. Changing of location topics leads to varying of reading preference. The news datasets in this paper belong to check in data. NewsREEL dataset is from a company, and it is provided by German researcher. The location data in Twitter dataset is also check in data. NetEase news dataset are collected from NetEase news websites, and the type of location data is city or region.},
  archive      = {J_ISCI},
  author       = {Pengtao Lv and Qinghui Zhang and Lei Shi and Zhenhan Guan and Yanfeng Fan and Jie Li and Kaiyang Zhong and Muhammet Deveci},
  doi          = {10.1016/j.ins.2024.120213},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120213},
  shortjournal = {Inf. Sci.},
  title        = {Exploring on role of location in intelligent news recommendation from data analysis perspective},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy inference system with interpretable fuzzy rules:
Advancing explainable artificial intelligence for disease diagnosis—a
comprehensive review. <em>ISCI</em>, <em>662</em>, 120212. (<a
href="https://doi.org/10.1016/j.ins.2024.120212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpretable artificial intelligence (AI), also known as explainable AI , is indispensable in establishing trustable AI for bench-to-bedside translation, with substantial implications for human well-being. However, the majority of existing research in this area has centered on designing complex and sophisticated methods, regardless of their interpretability . Consequently, the main prerequisite for implementing trustworthy AI in medical domains has not been met. Scientists have developed various explanation methods for interpretable AI. Among these methods, fuzzy rules embedded in a fuzzy inference system (FIS) have emerged as a novel and powerful tool to bridge the communication gap between humans and advanced AI machines. However, there have been few reviews of the use of FISs in medical diagnosis . In addition, the application of fuzzy rules to different kinds of multimodal medical data has received insufficient attention, despite the potential use of fuzzy rules in designing appropriate methodologies for available datasets. This review provides a fundamental understanding of interpretability and fuzzy rules, conducts comparative analyses of the use of fuzzy rules and other explanation methods in handling three major types of multimodal data (i.e., sequence signals, medical images, and tabular data), and offers insights into appropriate fuzzy rule application scenarios and recommendations for future research.},
  archive      = {J_ISCI},
  author       = {Jin Cao and Ta Zhou and Shaohua Zhi and Saikit Lam and Ge Ren and Yuanpeng Zhang and Yongqiang Wang and Yanjing Dong and Jing Cai},
  doi          = {10.1016/j.ins.2024.120212},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120212},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy inference system with interpretable fuzzy rules: Advancing explainable artificial intelligence for disease diagnosis—A comprehensive review},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy disaggregation risk resilience through
microaggregation and discrete fourier transform. <em>ISCI</em>,
<em>662</em>, 120211. (<a
href="https://doi.org/10.1016/j.ins.2024.120211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Progress in the field of Non-Intrusive Load Monitoring (NILM) has been attributed to the rise in the application of artificial intelligence . Nevertheless, the ability of energy disaggregation algorithms to disaggregate different appliance signatures from aggregated smart grid data poses some privacy issues. This paper introduces a new notion of disclosure risk termed energy disaggregation risk. The performance of Sequence-to-Sequence (Seq2Seq) NILM deep learning algorithm along with three activation extraction methods are studied using two publicly available datasets. To understand the extent of disclosure, we study three inference attacks on aggregated data . The results show that Variance Sensitive Thresholding (VST) event detection method outperformed the other two methods in revealing households&#39; lifestyles based on the signature of the appliances. To reduce energy disaggregation risk, we investigate the performance of two privacy-preserving mechanisms based on microaggregation and Discrete Fourier Transform (DFT). Empirically, for the first scenario of inference attack on UK-DALE, VST produces disaggregation risks of 99%, 100%, 89% and 99% for fridge, dish washer, microwave, and kettle respectively. For washing machine , Activation Time Extraction (ATE) method produces a disaggregation risk of 87%. We obtain similar results for other inference attack scenarios and the risk reduces using the two privacy-protection mechanisms.},
  archive      = {J_ISCI},
  author       = {Kayode S. Adewole and Vicenç Torra},
  doi          = {10.1016/j.ins.2024.120211},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120211},
  shortjournal = {Inf. Sci.},
  title        = {Energy disaggregation risk resilience through microaggregation and discrete fourier transform},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inductive autoencoder for efficiently compressing RDF
graphs. <em>ISCI</em>, <em>662</em>, 120210. (<a
href="https://doi.org/10.1016/j.ins.2024.120210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flexible paradigm of the Resource Description Framework (RDF) has accelerated the rate at which raw data is published on the web. Therefore, the volume of generated RDF data has increased impressively in the last decade, which promotes the use of compression to manage and reduce the size of RDF datasets. Furthermore, researchers have recently tried to reconstruct convolution and pooling procedures to better suit the structure of graphs and make convolutional neural networks (CNNs) more applicable to RDF graph data. In this study, we propose the Multi Kernel Inductive RDF Graph Convolution Network (MKIR-GCN), which, rather than compressing nodes/edges independently, uses similarities between nodes and the structure of graphs to reduce the size of all nodes and edges simultaneously to efficiently compress the RDF graph. By considering the topology and similarity of a network&#39;s nodes, our proposed attention based on similarity for RDF graph pooling (ASGPool) picks the most informative and representative nodes . In dynamic graphs, our proposed MKIR-GCN layer may learn more generic node representations by focusing on diverse characteristics. Through extensive experimentation, we can conclude that the proposed approach significantly improves compression over the existing graph representation learning schemes and RDF graph compression schemes .},
  archive      = {J_ISCI},
  author       = {Tangina Sultana and Md. Delowar Hossain and Md Golam Morshed and Tariq Habib Afridi and Young-Koo Lee},
  doi          = {10.1016/j.ins.2024.120210},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120210},
  shortjournal = {Inf. Sci.},
  title        = {Inductive autoencoder for efficiently compressing RDF graphs},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A lightweight multi-vector DDoS detection framework for
IoT-enabled mobile health informatics systems using deep learning.
<em>ISCI</em>, <em>662</em>, 120209. (<a
href="https://doi.org/10.1016/j.ins.2024.120209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth in adopting Internet of Things (IoT) applications and services has rendered IoT security an essential concern that must be handled promptly. Multi-vector Distributed Denial of Service (DDoS) attacks are more intensified forms of DDoS attacks, and the anomaly-based Intrusion Detection System (IDS) schemes are the best suitable for detecting and mitigating them. However, deploying anomaly-based IDS frameworks in healthcare systems is particularly difficult since it involves longer processing times, increased complexity, and the need to preserve temporal features. This study presents a novel anomaly-based IDS framework that utilizes proposed stacked modified Gated Recurrent Units (mGRU) to detect and identify the Multi-vector DDoS attacks in mobile healthcare informatics systems. In order to generate user-specific results, we have developed two instances of IDS, namely the Binary Classification Engine (BCE) and the Multi-label Classification Engine (MCE). The empirical results demonstrate that the proposed mGRU-based IDS models outperform the standard GRU-based IDS models, with a reduction in time consumption of around 2% on the CICIoT2023 and CICDDoS2019 datasets. The proposed IDS instances provide leading-edge metrics, lightweight features, and user-specific results, making them suitable for effective deployment in time-critical healthcare applications and services.},
  archive      = {J_ISCI},
  author       = {Aswani Devi Aguru and Suresh Babu Erukala},
  doi          = {10.1016/j.ins.2024.120209},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120209},
  shortjournal = {Inf. Sci.},
  title        = {A lightweight multi-vector DDoS detection framework for IoT-enabled mobile health informatics systems using deep learning},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated semi-supervised learning with tolerant guidance
and powerful classifier in edge scenarios. <em>ISCI</em>, <em>662</em>,
120201. (<a href="https://doi.org/10.1016/j.ins.2024.120201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning is a distributed machine learning method that offers inherent advantages in efficient learning and privacy protection within edge computing scenarios. However, terminal nodes often encounter challenges such as insufficient datasets and a significant amount of unlabelled data , leading to reduced accuracy in multi-party collaborative training models. Prior approaches have typically relied on a single pseudo label from unlabelled data to guide model training, limiting the utilization of knowledge within these data. To address this, this paper proposes a federated semi-supervised learning method (FedTG) tailored for image classification . Specifically, we leverage multiple high probability pseudo labels from unlabelled data to participate in semi-supervised learning, rather than relying on a single pseudo label. This approach mitigates the potential harm caused by errors in a single pseudo label and enables the model to fully capture the knowledge within the unlabelled data. Additionally, recognizing the significance of model classifiers (final neural network layer) in image classification tasks , we propose the exclusion of model classifier updates during the training process using unlabelled data to maintain optimal classification performance. Experiments conducted on real datasets have demonstrated that the FedTG method effectively enhances the accuracy of traditional Federated Learning model.},
  archive      = {J_ISCI},
  author       = {Jinbo Wang and Xikai Pei and Ruijin Wang and Fengli Zhang and Ting Chen},
  doi          = {10.1016/j.ins.2024.120201},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120201},
  shortjournal = {Inf. Sci.},
  title        = {Federated semi-supervised learning with tolerant guidance and powerful classifier in edge scenarios},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). A cascading elimination-based evolutionary algorithm with
variable classification mutation for many-objective optimization.
<em>ISCI</em>, <em>662</em>, 120200. (<a
href="https://doi.org/10.1016/j.ins.2024.120200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-objective evolutionary algorithms have gained significant achievements over the years. However, the difficulty in balancing convergence and diversity of the population remains. In this paper, we propose a cascading elimination based evolutionary algorithm with variable classification mutation, termed CEEA, for many-objective optimization. In CEEA, a cascading elimination mechanism based on the binary quality indicator and balanceable fitness estimation (BFE) is proposed for eliminating poor individuals one by one and further balancing convergence and diversity of the population. To be specific, two individuals with the minimum binary quality indicator value are found from the population, where these two individuals may exist in the dominance relation and have more similar search directions . If the relation of two selected individuals is dominance, the dominated individual is eliminated. Otherwise, one individual is eliminated by the BFE method. In addition, a binary quality indicator based variable classification mutation strategy is developed to produce promising individuals, and further improve the search efficiency of CEEA. Experimental studies on three well-known benchmark test suites, a combinational optimization problem , and a real-world engineering application have demonstrated that our CEEA has a superior performance to its peer competitors on various many-objective problems.},
  archive      = {J_ISCI},
  author       = {Wei Zhang and Jianchang Liu and Wanting Yang and Shubin Tan},
  doi          = {10.1016/j.ins.2024.120200},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120200},
  shortjournal = {Inf. Sci.},
  title        = {A cascading elimination-based evolutionary algorithm with variable classification mutation for many-objective optimization},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CoPE: Composition-based poincaré embeddings for link
prediction in knowledge graphs. <em>ISCI</em>, <em>662</em>, 120197. (<a
href="https://doi.org/10.1016/j.ins.2024.120197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph (KG) embedding methods predict missing links by computing the similarities between entities. The existing embedding methods are designed with either shallow or deep architectures. Shallow methods are scalable to large KGs but are limited in capturing fine-grained semantics. Deep methods can capture rich semantic interactions, but they require numerous model parameters. This study proposes a novel embedding model that effectively combines the strengths of both shallow and deep models. In particular, the proposed model adopts the design principles of shallow models and incorporates an expressive compositional operator inspired by deep models. This approach maintains the scalability while significantly enhancing the expressive capacity of the proposed model. Moreover, the proposed model learns embeddings using the Poincaré ball model of hyperbolic geometry to preserve the hierarchies between entities. The experimental results demonstrated the effectiveness of learning Poincaré embeddings with an expressive compositional operator. Notably, a substantial improvement of 2.4% in the Mean Reciprocal Rank (MRR) and a 1.4% improvement in hit@1 was observed on the CoDEx-m and CoDEx-s datasets, respectively, when compared to the current state-of-the-art methods. The proposed model was implemented using PyTorch 1.8.1, and experiments were conducted on a server with an NVIDIA GeForce RTX 2080 Ti GPU .},
  archive      = {J_ISCI},
  author       = {Adnan Zeb and Summaya Saif and Junde Chen and James Jianqiao Yu and Qingshan Jiang and Defu Zhang},
  doi          = {10.1016/j.ins.2024.120197},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120197},
  shortjournal = {Inf. Sci.},
  title        = {CoPE: Composition-based poincaré embeddings for link prediction in knowledge graphs},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-task stochastic configuration network with autonomous
linking and its application in wastewater treatment processes.
<em>ISCI</em>, <em>662</em>, 120195. (<a
href="https://doi.org/10.1016/j.ins.2024.120195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic configuration networks (SCNs) have been widely used for modeling complex industrial process due to their rapid learning speed, ease of implementation, and universal approximation capability. For modeling water quality parameters in wastewater treatment processes (WWTP), however, multiple complex tasks are often required to be modelled simultaneously. In this paper, a multi-task stochastic configuration network with autonomous linking characteristic is proposed to further develop the modeling capability of SCNs to deal with multi-tasks and achieve simultaneous measurement of multiple critical water quality parameters in the WWTP. The method can autonomously construct corresponding common nodes and proprietary nodes according to the distribution characteristics of different tasks to model the shared and private information among these tasks. Specifically, the relevant information between these tasks is explored by constructing common nodes; then personalized approximation of each task is achieved by constructing proprietary nodes for different tasks, thus improving the overall modeling performance of the model. A series of benchmark experiments and an industrial case from WWTP are carried out to verify the superiority of the proposed method. Experimental results demonstrate that our proposed method has a promising potential for multi-task data modeling .},
  archive      = {J_ISCI},
  author       = {Kang Li and Limin Zhang and Junfei Qiao},
  doi          = {10.1016/j.ins.2024.120195},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120195},
  shortjournal = {Inf. Sci.},
  title        = {Multi-task stochastic configuration network with autonomous linking and its application in wastewater treatment processes},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic event-triggered robust optimal tracking control for
multi-player nonzero-sum games with mismatched uncertainties and
asymmetric constrained inputs. <em>ISCI</em>, <em>662</em>, 120177. (<a
href="https://doi.org/10.1016/j.ins.2024.120177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel dynamic event-triggered robust optimal tracking control method is proposed for multi-player nonzero-sum game problem with mismatched uncertainties and asymmetric constrained inputs. First, the original asymmetric constrained-input multi-player system is transformed into a new multi-player system with symmetric constrained inputs implemented by the state-space transformation technique, and an augmented system is established based on the new system and the desired trajectory . Next, an auxiliary augmentation system is constructed to handle the robust tracking control problem. Then, a critic neural network with a novel modified weight updating law is established for each player to solve the event-triggered coupled Hamilton–Jacobi equations, which relaxes the restrictions of initial admissible control and persistence of excitation condition . Furthermore, efficient communication and computing are obtained by the newly established dynamic event-triggered mechanism, and the Zeno behavior can be excluded by introducing an exponential term . The uniformly ultimately bounded properties of all signals are proved. Finally, two numerical examples verify the effectiveness of the designed method.},
  archive      = {J_ISCI},
  author       = {Haoming Zou and Guoshan Zhang and Wanquan Liu and Zhiguo Yan},
  doi          = {10.1016/j.ins.2024.120177},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120177},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic event-triggered robust optimal tracking control for multi-player nonzero-sum games with mismatched uncertainties and asymmetric constrained inputs},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel extended rule-based system based on k-nearest
neighbor graph. <em>ISCI</em>, <em>662</em>, 120158. (<a
href="https://doi.org/10.1016/j.ins.2024.120158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Belief Rule-Based (BRB) system faces the rule combination explosion issue, making it challenging to construct the rule base efficiently. The Extended Belief Rule-Based (EBRB) system offers a solution to this problem by using data-driven methods. However, using EBRB system requires the traversal of the entire rule base, which can be time-consuming and result in the activation of many irrelevant rules, leading to an incorrect decision. Existing search optimization methods can somewhat solve this issue, but they have limitations. Moreover, the calculation of the rule activation weight only considers the similarity between input data and a single rule, ignoring the influence of the rule linkage. To address these problems, we propose a new EBRB system based on the K-Nearest Neighbor graph index (Graph-EBRB). We introduce the Hierarchical Navigable Small World (HNSW) algorithm to create the K-Nearest Neighbor graph index of the EBRB system. This index allows us to efficiently search and activate a set of key rules. We also propose a new activation weight calculation method based on the Graph Convolution Neural Network (GCN), and we optimize the system performance using a parameter learning strategy. We conduct a comprehensive experiment on 14 commonly used public data sets, and the results show that Graph-EBRB system significantly improves the reasoning efficiency and accuracy of the EBRB system. Finally, we apply the Graph-EBRB system to tree disease identification and achieve excellent classification performance, identifying over 90% of the diseased trees on the complete dataset.},
  archive      = {J_ISCI},
  author       = {Yang-Geng Fu and Xin-Yi Lin and Geng-Chao Fang and Jin Li and Hong-Yi Cai and Xiao-Ting Gong and Ying-Ming Wang},
  doi          = {10.1016/j.ins.2024.120158},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120158},
  shortjournal = {Inf. Sci.},
  title        = {A novel extended rule-based system based on K-nearest neighbor graph},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive fixed-time tracking control for uncertain nonlinear
systems with unknown control coefficients and prescribed performance.
<em>ISCI</em>, <em>662</em>, 120152. (<a
href="https://doi.org/10.1016/j.ins.2024.120152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper delves into the problem of fixed-time neural network adaptive prescribed performance control for a category of nonstrict-feedback systems with time-varying unknown control coefficients (UCCs). Firstly, two key technical lemmas are proposed. One is to put forward a novel fixed-time stability lemma with a more precise upper-bound estimate of the settling time. The other is to present a new lemma based on a category of type-B Nussbaum functions (TBNFs), which can effectively address the time-varying UCCs in the systems. Secondly, neural networks are employed to approach the uncertain nonlinear terms , and a fixed-time performance function and a nonlinear shifting function are constructed to eliminate the restriction of tracking error in terms of initial condition. Then, to overcome the singularity problem, the switched virtual controllers are designed with the help of the novel fixed-time stability lemma and dynamic surface control technique. It turns out that the tracking error converges to a predefined asymmetric constraint region within a fixed time and the closed-loop system is practically fixed-time stable. Finally, a numerical example and a mass-spring-damper system are provided to verify the effectiveness of the presented design method.},
  archive      = {J_ISCI},
  author       = {Xiaojing Qi and Chen Yang and Shengyuan Xu},
  doi          = {10.1016/j.ins.2024.120152},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120152},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fixed-time tracking control for uncertain nonlinear systems with unknown control coefficients and prescribed performance},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vine copula structure representations using graphs and
matrices. <em>ISCI</em>, <em>662</em>, 120151. (<a
href="https://doi.org/10.1016/j.ins.2024.120151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A widespread methodology for modeling modern day information, which consists of high-dimensional digital measurements, is to use vine copulas; they can flexibly encode the underlying dependence structure of the data. Here we introduce a new algorithm to encode complete and truncated vines in a matrix, and as such, storing the information content of vines in a virtual environment. The conditional independence structure encoded by a vine can be represented in graph terms. We summarize these representations, and show equivalence between them. We show a new result, namely that when a perfect elimination ordering of a vine structure is given, then it can be uniquely represented with a matrix. Nápoles has shown a way to represent vines in a matrix, and we algorithmify this previous approach, while also showing a new method for constructing such a matrix, through cherry tree sequences, which can also store truncated vines. Moreover, this new algorithm can directly build truncated vines by storing each level separately - without building up the entire vine, which would be necessary in Nápoles&#39; algorithm. We calculate the runtime of these algorithms. Lastly, we prove that these two matrix-building algorithms are equivalent if the same perfect elimination ordering is being used.},
  archive      = {J_ISCI},
  author       = {Dániel Pfeifer and Edith Alice Kovács},
  doi          = {10.1016/j.ins.2024.120151},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120151},
  shortjournal = {Inf. Sci.},
  title        = {Vine copula structure representations using graphs and matrices},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Forward-porting and its limitations in fuzzer evaluation.
<em>ISCI</em>, <em>662</em>, 120142. (<a
href="https://doi.org/10.1016/j.ins.2024.120142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forward-porting reintroduces previously detected and patched software bugs from older versions into later ones to create benchmarking workloads for fuzzing. These benchmarks gauge a fuzzer&#39;s performance by testing its ability to detect or trigger these bugs during a fuzzing campaign. In this study, we evaluate the reliability of forward porting in establishing dependable fuzzing benchmarks and their suitability for fair and accurate fuzzer evaluation. We utilize online resources, forward porting, fuzzing experiments, and triaging to scrutinize the workloads of a state-of-the-art fuzzing benchmark. We uncover seven factors, including software architecture changes, misconfigurations , supply chain issues, and developer errors, all of which compromise the success of forward porting. We determine that the ‘ground truth’ established through forward porting is only occasionally ‘true’ due to unaccounted-for underlying bugs in all examined software applications undergoing this process. These findings question the reliability of forward porting in generating dependable fuzzing benchmarks. Furthermore, our experimental results suggest that relying on forward porting-based ground truth and verification metrics could lead to misleading evaluations of fuzzer performance. Ultimately, we propose insights into the development of fuzzing benchmarks to ensure more dependable assessments of fuzzers .},
  archive      = {J_ISCI},
  author       = {Haroon Elahi and Guojun Wang},
  doi          = {10.1016/j.ins.2024.120142},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120142},
  shortjournal = {Inf. Sci.},
  title        = {Forward-porting and its limitations in fuzzer evaluation},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pseudo unlearning via sample swapping with hash.
<em>ISCI</em>, <em>662</em>, 120135. (<a
href="https://doi.org/10.1016/j.ins.2024.120135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Unlearning is a recently proposed paradigm to make an machine learning (ML) model delete specific data. Specifically, the data owner has the right to ask the machine learning as a service (MLaaS) provider to remove the impact of specific data on the trained model, so as to protect the privacy of the forgotten data. However, in order to achieve the desired effect, the unlearning operation does come at a certain cost. Therefore, the dishonest MLaaS provider has an incentive to create fake forgetting feedback to deceive the data owner&#39;s unlearning verification without performing any unlearning operations. The primary objective of the paper is to understand the potential vulnerabilities within machine unlearning mechanisms and contribute to the development of more robust, trustworthy, and secure unlearning solutions. We propose the concept of Pseudo Unlearning for the first time, and designs an efficient scheme, s ample s wapping with h ash (SSH), for the membership inference attack verification mechanism. We conduct extensive experiments on different datasets, and the performance achieved in the evaluation metrics as well as the verification mechanisms of membership inference attack shows the feasibility of pseudo unlearning .},
  archive      = {J_ISCI},
  author       = {Lang Li and Xiaojun Ren and Hongyang Yan and Xiaozhang Liu and Zhenxin Zhang},
  doi          = {10.1016/j.ins.2024.120135},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120135},
  shortjournal = {Inf. Sci.},
  title        = {Pseudo unlearning via sample swapping with hash},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimized bipartite formation control for multiagent systems
with obstacle and collision avoidance. <em>ISCI</em>, <em>662</em>,
120122. (<a href="https://doi.org/10.1016/j.ins.2024.120122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers an optimal bipartite formation control problem for high-order nonlinear multiagent systems (MASs) with the consideration of obstacle/collision avoidance. Contrary to existing literature, the control strategy designed in this paper can render the agents in a bipartite formation to complete the obstacle/collision avoidance tasks without requiring the obstacles to be located on the coordinate axis. To save resources, an identifier-critic-actor-based optimized formation control scheme is designed for MASs. An obstacle/collision avoidance approach based on dynamical systems (DS) is designed for high-order nonlinear MASs. Different from the existing related results, the proposed DS-based obstacle/collision avoidance approach can avoid the phenomenon that the control quantities approach infinity near obstacles or other agents, and eliminate the dependence on global information. Finally, a simulation example is given to validate the proposed control method .},
  archive      = {J_ISCI},
  author       = {Xuefei Wang and Dan Ye and Fang Wei},
  doi          = {10.1016/j.ins.2024.120122},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120122},
  shortjournal = {Inf. Sci.},
  title        = {Optimized bipartite formation control for multiagent systems with obstacle and collision avoidance},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Group decision-making method with trust-based weight and
reliability parameters. <em>ISCI</em>, <em>662</em>, 120089. (<a
href="https://doi.org/10.1016/j.ins.2024.120089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies on group decision-making (GDM) have highlighted the significance of the reliability parameter, which is considered to be the second critical parameter, after weight, of an information source. In practice, trust among decision makers (DMs) also should receive attention because of the interaction among DMs. Thus, in this study, we introduce trust as a third parameter and focus on differentiating among these three information parameters. First, we apply the generalized combination (GC) rule to extract and fuse individual information. Then, we implement the procedures of consensus measure and information selection based on similarity. Next, we adjust the selected inconsistent information using trust-based weight and reliability parameters to facilitate group consensus. During the consensus reaching process, the weight and reliability parameters are dynamically and differentially determined. Finally, the proposed method is summarized as a GDM framework. We introduce a case simulation study to verify the feasibility of the proposed method and conduct a numerical comparison and comparative discussion to demonstrate that the proposed method provides a fresh perspective on developing GDM with consensus. In particular, this framework is suitable for addressing GDM problems involving uncertainty in high-dimensional information with wide discrepancy.},
  archive      = {J_ISCI},
  author       = {Su-Su Wang and Yuan-Wei Du},
  doi          = {10.1016/j.ins.2024.120089},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120089},
  shortjournal = {Inf. Sci.},
  title        = {Group decision-making method with trust-based weight and reliability parameters},
  volume       = {662},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-criteria sequential three-state three-way decision
consensus model based on set pair analysis theory. <em>ISCI</em>,
<em>661</em>, 120199. (<a
href="https://doi.org/10.1016/j.ins.2024.120199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The three-way decision (3WD) theory involves two states of objects corresponding to consensus and conflict states in multi-criteria group decision-making (MCGDM) problems. However, the set pair analysis (SPA) theory provides a three-state perspective by incorporating the uncertainty state. Inspired of this, we propose a multi-criteria sequential three-state three-way decision (TS3WD) consensus model to reach the group consensus. Firstly, we propose the concept of consensus set pair probability space. Drawing upon SPA theory, the set pair consensus rules are designed to obtain the consensus set pair probability space which is categorized into three states including consensus, uncertainty and conflict. Secondly, the TS3WD model is presented by extending two states of classic 3WD model into three states. Related to the consensus set pair probability space and extended loss functions, the three-state decision rules and simplified decision rules are derived. Furthermore, the consensus feedback mechanism and rules based on the sequential TS3WD consensus model are proposed to adjust uncertainty and conflict opinions, in which the consensus adjustment model and coefficient adjustment strategy play essential roles. Finally, a connection number (CN) is applied to rank all alternatives and some experimental analyses are conducted to demonstrate the effectiveness and feasibility of the proposed model.},
  archive      = {J_ISCI},
  author       = {Han Wang and Yanbing Ju and Peiwu Dong and Petra Maresova and Tian Ju and Enrique Herrera-Viedma},
  doi          = {10.1016/j.ins.2024.120199},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120199},
  shortjournal = {Inf. Sci.},
  title        = {Multi-criteria sequential three-state three-way decision consensus model based on set pair analysis theory},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-fragile mixed event-triggered networked control for
takagi-sugeno systems subject to actuator faults and external
disturbances. <em>ISCI</em>, <em>661</em>, 120198. (<a
href="https://doi.org/10.1016/j.ins.2024.120198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the problem of non-fragile event-triggered networked controller design for Takagi-Sugeno (T-S) systems subject to actuator faults , external disturbances , and network-induced delays. To stabilize this class of Networked Control Systems (NCSs), a new Mixed Event Triggered Control (METC) control scheme, including memory data, is proposed to cope with actuator faults modeled as both additive and multiplicative terms acting as uncertainties in a non-fragile control law. Then, from a convenient choice of a Lyapunov-Krasovskii functional, together with appropriate relaxation techniques, providing boundedness conditions for actuator faults and assuming a prescribed H ∞ H∞ disturbance attenuation level, relaxed LMI-based conditions are proposed to guarantee the non-fragile closed-loop NCS stability with METC. Two theorems are proposed. The first one deals with the NCSs stability analysis (i.e. assuming the controller&#39;s gains known), and the second one extends to their stabilization (i.e. the non-fragile controller design). Both these theorems allow the simultaneous design of the proposed METC condition. The proposed LMI-based conditions allow to further relax the admissible network-induced delay and event-triggered packet release intervals. Three simulation examples illustrate the effectiveness of the proposed METC design and highlight the conservatism improvements brought by this proposal with respect to previous related results from the literature.},
  archive      = {J_ISCI},
  author       = {Mohamed Rouamel and Kevin Guelton and Fayçal Bourahala and Adriano N.D. Lopes and Laurent Arcese},
  doi          = {10.1016/j.ins.2024.120198},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120198},
  shortjournal = {Inf. Sci.},
  title        = {Non-fragile mixed event-triggered networked control for takagi-sugeno systems subject to actuator faults and external disturbances},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Balancing the signals: Bayesian equilibrium selection for
high-speed railway sensor defense. <em>ISCI</em>, <em>661</em>, 120196.
(<a href="https://doi.org/10.1016/j.ins.2024.120196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-speed railway systems face frequent cybersecurity threats targeting their information networks. Continuous operation of protection mechanisms on wireless sensors results in persistent energy consumption, which is undesirable. To address this, we propose an optimal defense strategy selection approach for High-speed Railway Wireless Sensor Networks (HSR-WSNs) using an enhanced signaling game model. We first establish the basic elements and overall structure of the model, considering the presence of incomplete information and dynamic interactions between players. This paper provides background on signaling games, including theoretical concepts of equilibrium strategies and locations. We then develop a system to quantify payoffs for offensive and defensive tactics, incorporating distance and usage frequency weights. Finally, Long Short-Term Memory (LSTM) and the public UNSW-NB15 dataset are leveraged to augment assumptions and reduce human subjectivity in results. Experiments demonstrate the model effectively identifies energy balance points for HSR-WSNs and determines appropriate protection strategies. The work contributes to enhancing the selection of effective defense techniques against network attacks in wireless sensor systems . This has significant practical implications in enabling optimized energy usage and functionality of secured sensor nodes .},
  archive      = {J_ISCI},
  author       = {Sheng-Hua Xiong and Mo-Ran Qiu and Gang Li and Hao Zhang and Zhen-Song Chen},
  doi          = {10.1016/j.ins.2024.120196},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120196},
  shortjournal = {Inf. Sci.},
  title        = {Balancing the signals: Bayesian equilibrium selection for high-speed railway sensor defense},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analytical-solution-based interval fuzzy utility acquisition
and decision making with interval-valued fuzzy preference relations
based on additive consistency. <em>ISCI</em>, <em>661</em>, 120194. (<a
href="https://doi.org/10.1016/j.ins.2024.120194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acquiring an analytical solution of interval fuzzy utility vectors (IFUVs) from interval-valued fuzzy preference relations (IVFPRs) plays a key role in improving the efficiency and performance of decision making with IVFPRs. This study devises formulas to compute uncertainty indices of interval-valued fuzzy assessments and IVFPRs, and builds uncertainty constraints among fuzzy assessments in an additively consistent IVFPR. By dividing all IVFPRs with the same size into two categories, least square models with constraints of uncertainty indices are set up and their analytical solutions are found to respectively acquire normalized IFUVs from the two categories of IVFPRs. The analytical solutions are then integrated into unified computational formulas acquiring normalized IFUVs from IVFPRs. On the basis of analytical-solution-based IFUVs, a distance based additive consistency index is devised and a novel acceptability concept is presented by taking both additive inconsistency acceptability and uncertainty acceptability into account. Subsequently, this paper proposes a multi-criteria decision making method with highlighting individual characteristics of alternatives. An illustration with one consistent IVFPR and three inconsistent IVFPRs is offered and a comparative study is implemented to validate the models presented. An annual-performance-evaluation-based outstanding teacher recommendation problem is utilized to show the practicality of the decision method proposed.},
  archive      = {J_ISCI},
  author       = {Xuan Yang and Xiayu Tong and Zhou-Jing Wang},
  doi          = {10.1016/j.ins.2024.120194},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120194},
  shortjournal = {Inf. Sci.},
  title        = {Analytical-solution-based interval fuzzy utility acquisition and decision making with interval-valued fuzzy preference relations based on additive consistency},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A cluster prediction strategy with the induced mutation for
dynamic multi-objective optimization. <em>ISCI</em>, <em>661</em>,
120193. (<a href="https://doi.org/10.1016/j.ins.2024.120193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multi-objective optimization problems (DMOPs) are multi-objective optimization problems in which at least one objective and/or related parameter vary over time. The challenge of solving DMOPs is to efficiently and accurately track the true Pareto-optimal set when the environment undergoes changes. However, many existing prediction-based methods overlook the distinct individual movement directions and the available information in the objective space , leading to biased predictions and misleading the subsequent search process. To address this issue, this paper proposes a prediction method called IMDMOEA, which relies on cluster center points and induced mutation. Specifically, employing linear prediction methods based on cluster center points in the decision space enables the algorithm to rapidly capture the population&#39;s evolutionary direction and distributional shape. Additionally, to enhance the algorithm&#39;s adaptability to significant environmental changes, the induced mutation strategy corrects the population&#39;s evolutionary direction by selecting promising individuals for mutation based on the predicted result of the Pareto front in the objective space. These two complementary strategies enable the algorithm to respond faster and more effectively to environmental changes. Finally, the proposed algorithm is evaluated using the JY, dMOP, FDA, and F test suites. The experimental results demonstrate that IMDMOEA competes favorably with other state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Kangyu Xu and Yizhang Xia and Juan Zou and Zhanglu Hou and Shengxiang Yang and Yaru Hu and Yuan Liu},
  doi          = {10.1016/j.ins.2024.120193},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120193},
  shortjournal = {Inf. Sci.},
  title        = {A cluster prediction strategy with the induced mutation for dynamic multi-objective optimization},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameter estimation of multivariable wiener nonlinear
systems by the improved particle swarm optimization and coupling
identification. <em>ISCI</em>, <em>661</em>, 120192. (<a
href="https://doi.org/10.1016/j.ins.2024.120192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the parameter estimation of multivariable Wiener nonlinear systems . To solve the inconsistency problem of the parameter vector and the parameter matrix, the coupling identification concept is applied. Combined with particle swarm optimization (PSO) and an auxiliary model, the partially coupled improved particle swarm optimization (PC-IPSO) method is proposed. In this algorithm, the adaptive feedback inertia weight is improved to accelerate the convergence speed, and the retirement update mechanism is introduced to improve the optimization ability of the basic PSO algorithm . To verify the performance of PC-IPSO, we also derive a multivariable improved PSO (M-IPSO) method for comparison. The computational complexity analysis shows that the PC-IPSO algorithm requires less computational resources than the M-IPSO algorithm. Then, the convergence of the improved PSO method is analyzed. The simulation results indicate that the PC-IPSO method has a faster convergence speed and higher identification accuracy than the M-IPSO and several existing state-of-the-art methods for multivariable Wiener system identification .},
  archive      = {J_ISCI},
  author       = {Tiancheng Zong and Junhong Li and Guoping Lu},
  doi          = {10.1016/j.ins.2024.120192},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120192},
  shortjournal = {Inf. Sci.},
  title        = {Parameter estimation of multivariable wiener nonlinear systems by the improved particle swarm optimization and coupling identification},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contrastive deep convolutional transform k-means clustering.
<em>ISCI</em>, <em>661</em>, 120191. (<a
href="https://doi.org/10.1016/j.ins.2024.120191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep clustering has gained the immense attention of researchers in recent years. Most of the deep clustering approaches are based on auto-encoders which consist of an encoder-decoder framework. In these approaches, the clustering module is embedded in the latent space of auto-encoders. The auto-encoder based deep clustering approaches require learning of encoder weights as well as decoder weights. Moreover, due to the unsupervised learning strategy, these approaches lack in learning the discriminative features that can help in generating better clusters. This work introduces a novel clustering approach based on Contrastive Deep Convolutional Transform Learning (DCTL) framework. The proposed approach mitigates the problem of lack of supervision in DCTL based K-means clustering approach by embedding the contrastive learning into it. To embed the contrastive learning, the positive pairs and negative pairs of data samples are generated by reconstructing the data samples from the DCTL learnt representation itself and thus eliminates the requirement of data augmentation for embedding contrastive learning. The experimental results on several benchmark facial images datasets demonstrate that the proposed framework gives better clustering performance as compared to the current state-of-the-art deep clustering approaches especially in data constrained scenarios.},
  archive      = {J_ISCI},
  author       = {Anurag Goel and Angshul Majumdar},
  doi          = {10.1016/j.ins.2024.120191},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120191},
  shortjournal = {Inf. Sci.},
  title        = {Contrastive deep convolutional transform k-means clustering},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Security-based distributed fuzzy funnel cooperative control
for uncertain nonlinear multi-agent systems against DoS attacks.
<em>ISCI</em>, <em>661</em>, 120189. (<a
href="https://doi.org/10.1016/j.ins.2024.120189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on the distributed funnel cooperative control of nonlinear multi-agent systems suffering denial-of-service (DoS) attacks, which aim to disrupt communication links between agents and can lead to discontinuities in system outputs. First, an actual measurement model of output signals is given, and a fuzzy switching observer is designed by utilizing the practical output model to obtain the unknown states. Second, a funnel-based tracking control strategy is presented by skillfully blinding the funnel function and backstepping technique to defend against DoS attacks. A crucial stability criterion is established by combining an improved average dwell time (ADT) approach and Lyapunov stability theory that integrates the constraints imposed by DoS attacks. In particular, based on an appropriate error transformation, the developed control law has a simpler structure than existing barrier function methods to solve performance constraints. It guarantees that the output of each follower agent y i yi is able to track the reference signal y d yd , and synchronization errors ϵ i = ∑ s = 1 M a i , s ( y i − y s ) + b i ( y i − y d ) ϵi=∑s=1Mai,s(yi−ys)+bi(yi−yd) are consistently confined within a prearranged performance funnel F ϕ Fϕ , (that is, ( t , ϵ i ( t ) ) ∈ F ϕ , ∀ t (t,ϵi(t))∈Fϕ,∀t ). Ultimately, a simulation example is presented to prove the validity of the established solution.},
  archive      = {J_ISCI},
  author       = {Yuan-Yuan Li and Yuan-Xin Li},
  doi          = {10.1016/j.ins.2024.120189},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120189},
  shortjournal = {Inf. Sci.},
  title        = {Security-based distributed fuzzy funnel cooperative control for uncertain nonlinear multi-agent systems against DoS attacks},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient multi-objective neural architecture search
framework via policy gradient algorithm. <em>ISCI</em>, <em>661</em>,
120186. (<a href="https://doi.org/10.1016/j.ins.2024.120186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differentiable architecture search plays a prominent role in Neural Architecture Search (NAS) and exhibits preferable efficiency than traditional heuristic NAS methods, including those based on evolutionary algorithms (EA) and reinforcement learning (RL). However, differentiable NAS methods encounter challenges when dealing with non-differentiable objectives like energy efficiency, resource constraints , and other non-differentiable metrics, especially under multi-objective search scenarios. While the multi-objective NAS research addresses these challenges, the individual training required for each candidate architecture demands significant computational resources . To bridge this gap, this work combines the efficiency of the differentiable NAS with metrics compatibility in multi-objective NAS. The architectures are discretely sampled by the architecture parameter α within the differentiable NAS framework, and α are directly optimised by the policy gradient algorithm. This approach eliminates the need for a sampling controller to be learned and enables the encompassment of non-differentiable metrics. We provide an efficient NAS framework that can be readily customized to address real-world multi-objective NAS (MNAS) scenarios, encompassing factors such as resource limitations and platform specialization. Notably, compared with other multi-objective NAS methods, our NAS framework effectively decreases the computational burden (accounting for just 1/6 of the NSGA-Net). This search framework is also compatible with the other efficiency and performance improvement strategies under the differentiable NAS framework.},
  archive      = {J_ISCI},
  author       = {Bo Lyu and Yin Yang and Yuting Cao and Pengcheng Wang and Jian Zhu and Jingfei Chang and Shiping Wen},
  doi          = {10.1016/j.ins.2024.120186},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120186},
  shortjournal = {Inf. Sci.},
  title        = {Efficient multi-objective neural architecture search framework via policy gradient algorithm},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning-based multi-objective differential
evolution algorithm for feature selection. <em>ISCI</em>, <em>661</em>,
120185. (<a href="https://doi.org/10.1016/j.ins.2024.120185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature Selection (FS) can be used to determine the optimal subset of features from a raw dataset by reducing dimensionality and improving accuracy. In this study, a reinforcement learning-based multi-objective differential evolution algorithm (RLMODE) for FS is proposed, which is modeled as a multi-objective optimization problem . First, a reinforcement learning-based offspring generation strategy is designed. The offspring generation strategy is based on the Q-learning framework, which considers each individual in the population as an agent. The dominance relationship between an agent and its predecessor is used to encode the state. A well-chosen action set containing three typical differential evolution mutation operators is available for each agent. The reward is used to update the exclusive Q-table. Moreover, a novel Pareto front (PF) relearning strategy is devised to allow adequate communication between individuals on the PF. The PF relearning strategy reevaluates the potential value of all individuals on the PF as a whole. This promotes the propagation of excellent solutions and improves PF diversity. The proposed RLMODE initially demonstrates its strength in benchmarks. The excellent results for 17 datasets demonstrate RLMODE’s merits in terms of dimensionality reduction and accuracy improvement. Therefore, the proposed RLMODE method is a promising FS technique.},
  archive      = {J_ISCI},
  author       = {Xiaobing Yu and Zhengpeng Hu and Wenguan Luo and Yu Xue},
  doi          = {10.1016/j.ins.2024.120185},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120185},
  shortjournal = {Inf. Sci.},
  title        = {Reinforcement learning-based multi-objective differential evolution algorithm for feature selection},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MOODY: An ontology-driven framework for standardizing
multi-objective evolutionary algorithms. <em>ISCI</em>, <em>661</em>,
120184. (<a href="https://doi.org/10.1016/j.ins.2024.120184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of semantic technologies , particularly ontologies, in the realm of multi-objective evolutionary algorithms is overlook despite their effectiveness in knowledge representation. In this paper, we introduce MOODY, an ontology specifically tailored to formalize these kinds of algorithms, encompassing their respective parameters , and multi-objective optimization problems based on a characterization of their search space landscapes. MOODY is designed to be particularly applicable in automatic algorithm configuration, which involves the search of the parameters of an optimization algorithm to optimize its performance. In this context, we observe a notable absence of standardized components, parameters, and related considerations, such as problem characteristics and algorithm configurations. This lack of standardization introduces difficulties in the selection of valid component combinations and in the re-use of algorithmic configurations between different algorithm implementations. MOODY offers a means to infuse semantic annotations into the configurations found by automatic tools, enabling efficient querying of the results and seamless integration across diverse sources through their incorporation into a knowledge graph. We validate our proposal by presenting four case studies .},
  archive      = {J_ISCI},
  author       = {José F. Aldana-Martín and María del Mar Roldán-García and Antonio J. Nebro and José F. Aldana-Montes},
  doi          = {10.1016/j.ins.2024.120184},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120184},
  shortjournal = {Inf. Sci.},
  title        = {MOODY: An ontology-driven framework for standardizing multi-objective evolutionary algorithms},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boundary-wise loss for medical image segmentation based on
fuzzy rough sets. <em>ISCI</em>, <em>661</em>, 120183. (<a
href="https://doi.org/10.1016/j.ins.2024.120183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The loss function plays an important role in deep learning models as it determines the model convergence behavior and performance. In semantic segmentation , many methods utilize pixel-wise (e.g. cross-entropy) and region-wise (e.g. dice) losses while boundary-wise loss is underexplored. It is known that one of the key aims of semantic segmentation is to precisely delineate objects&#39; boundaries. Hence, it is essential to design a loss function that measures the errors around objects&#39; boundaries. Fuzzy rough sets are constituted by the fuzzy equivalence relation, which is commonly used to measure the difference between two sets. In this paper, the lower approximation of fuzzy rough sets is proposed to construct the boundary-wise loss in deep learning models for the first time. The experiments with various segmentation models and datasets have verified that the proposed fuzzy rough sets loss is superior to other boundary-wise losses in terms of segmentation accuracy and time complexity. Compared with the commonly used pixel-wise and region-wise losses, the proposed boundary-wise loss performs similarly in dice coefficient, pixel-wise accuracy, but has a better performance in Hausdorff distance and symmetric surface distance. It indicates that the proposed loss provides a better guidance for segmentation models in producing more accurate shapes of the target objects. Code is available online at Github: https://github.com/qiaolin1992/Boundary-Loss .},
  archive      = {J_ISCI},
  author       = {Qiao Lin and Xin Chen and Chao Chen and Jonathan M. Garibaldi},
  doi          = {10.1016/j.ins.2024.120183},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120183},
  shortjournal = {Inf. Sci.},
  title        = {Boundary-wise loss for medical image segmentation based on fuzzy rough sets},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerating actor-critic-based algorithms via pseudo-labels
derived from prior knowledge. <em>ISCI</em>, <em>661</em>, 120182. (<a
href="https://doi.org/10.1016/j.ins.2024.120182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the huge success of reinforcement learning (RL) in solving many difficult problems, its Achilles heel has always been sample inefficiency. On the other hand, in RL, taking advantage of prior knowledge, intentionally or unintentionally, has usually been avoided, so that, training an agent from scratch is common. This not only causes sample inefficiency but also endangers safety –especially during exploration. In this paper, we help the agent learn from the environment by using the pre-existing (but not necessarily exact or complete) solution for a task. Our proposed method can be integrated with any RL algorithm developed based on policy gradient and actor-critic methods. The results on five tasks with different difficulty levels by using two well-known actor-critic-based methods as the backbone of our proposed method (SAC and TD3) show our success in greatly improving sample efficiency and final performance. We have gained these results alongside robustness to noisy environments at the cost of just a slight computational overhead, which is negligible.},
  archive      = {J_ISCI},
  author       = {Ali Beikmohammadi and Sindri Magnússon},
  doi          = {10.1016/j.ins.2024.120182},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120182},
  shortjournal = {Inf. Sci.},
  title        = {Accelerating actor-critic-based algorithms via pseudo-labels derived from prior knowledge},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transformations of mixed solution types of interval linear
equations system with boundaries on its left-hand side to linear
inequalities with binary variables. <em>ISCI</em>, <em>661</em>, 120179.
(<a href="https://doi.org/10.1016/j.ins.2024.120179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To determine the solution set of an interval linear equations system A x = b Ax=b , it is necessary to know the semantics of the system. In addition to strong and weak semantics, there are four other important semantics: tolerance, control, left-localized, and right-localized. A solution x with one of these semantics provides that particular behavior in every equation of the system. It could happen that there is a solution x with one semantic in some equations and another semantic in the remaining equations of the system. This solution generates another solution type. We provide fifteen combinations of solution types generated by tolerance, control, left-localized, and right-localized semantics and prove that the solution set containing all four semantics is the weak (united) solution set. We show that each of these fifteen nonnegative solution types with some given boundaries on A x Ax can be transformed to be the solution set of linear inequalities with binary variables. The transformed system is deterministic and can be used in a linear programming problem with interval linear equation constraints to find an optimistic solution satisfying the semantics of the interval linear equations. Task management and course assignment examples are provided to show the necessity of these solution types.},
  archive      = {J_ISCI},
  author       = {Phantipa Thipwiwatpotjana and Artur Gorka and Weldon Lodwick and Worrawate Leela-apiradee},
  doi          = {10.1016/j.ins.2024.120179},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120179},
  shortjournal = {Inf. Sci.},
  title        = {Transformations of mixed solution types of interval linear equations system with boundaries on its left-hand side to linear inequalities with binary variables},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view unsupervised feature selection with consensus
partition and diverse graph. <em>ISCI</em>, <em>661</em>, 120178. (<a
href="https://doi.org/10.1016/j.ins.2024.120178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view unsupervised feature selection has gained significant attention in effectively reducing the dimensionality of unlabeled data collected from multiple sources. Many existing methods integrate the tasks of graph learning and feature selection to select informative features. While these methods have demonstrated promising results, they usually construct a consensus graph by merging multiple graphs or consider the consistent graph of all views. However, due to the view heterogeneity, it becomes difficult to identify a shared similarity structure. On the other hand, the clustering outcome remains consistent across all views. In light of this, we propose generating multiple graphs that are as mutually exclusive as possible to enhance the complementarity between views. Additionally, our method bridges graph learning and consensus clustering to leverage the indicator consistency. We also present an effective algorithm to optimize the objective function. Finally, extensive experiments on six benchmark datasets demonstrate that our method outperforms state-of-the-art methods. The code is available at https://github.com/HdTgon/2023-INS-CDMvFS .},
  archive      = {J_ISCI},
  author       = {Zhiwen Cao and Xijiong Xie and Yuqi Li},
  doi          = {10.1016/j.ins.2024.120178},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120178},
  shortjournal = {Inf. Sci.},
  title        = {Multi-view unsupervised feature selection with consensus partition and diverse graph},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NLPSweep: A comprehensive defense scheme for mitigating NLP
backdoor attacks. <em>ISCI</em>, <em>661</em>, 120176. (<a
href="https://doi.org/10.1016/j.ins.2024.120176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural language processing (NLP) backdoor attacks have become a hidden threat to modern NLP applications. Most of the existing defense methods defend against specific types of backdoor attacks, and they generally fail to defend against invisible backdoors with syntactically correct triggers. This paper proposes NLPSweep, a comprehensive defense scheme that can defend against five common types of backdoor attacks, namely, character, word, sentence, homograph, and learnable textual attacks. Specifically, we propose a framework that can discover an effective defense solution without prior knowledge of the attacks. The defense solution is optimized from the framework and can defend against various attacks while ensuring high accuracy. Finally, we verify the effectiveness of NLPSweep on two pretrained models (BERT and XLNET) on three classic datasets (SST-2, IMDB, and OLID) and compare it with five state-of-the-art defense methods, namely, ONION, Pred, RAP, Fine-pruning, and STRIP. The experimental results demonstrate that NLPSweep has an average model accuracy (ACC) greater than 0.922 and that the average attack success rate (ASR) is only 0.202, outperforming the compared methods. Furthermore, NLPSweep is tested on the real-world Yelp dataset and it can effectively defend against backdoor attacks with the ASR less than 0.07 and the ACC greater than 0.973. 1},
  archive      = {J_ISCI},
  author       = {Tao Xiang and Fei Ouyang and Di Zhang and Chunlong Xie and Hao Wang},
  doi          = {10.1016/j.ins.2024.120176},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120176},
  shortjournal = {Inf. Sci.},
  title        = {NLPSweep: A comprehensive defense scheme for mitigating NLP backdoor attacks},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-granularity distance with its application for
decision making. <em>ISCI</em>, <em>661</em>, 120168. (<a
href="https://doi.org/10.1016/j.ins.2024.120168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In decision-making systems, conflict management is an important concept that represents the degree of dissimilarity between bodies of evidence, ultimately enhancing decision-making performance. Jousselme&#39;s distance, as the most commonly employed one so far, is used to measure the distance between basic belief assignments (BBAs) in Dempster-Shafer (D-S) evidence theory. However, the Jousselme&#39;s distance has limitations, which can also be demonstrated in other methods theoretically. To address this issue, a BBA refinement method and a novel multi-granularity distance are proposed in this paper. Moreover, the methods are verified to be effective in the problems that Jousselme&#39;s distance cannot satisfy. Additionally, a hypothetical physical model is employed to verify the practicability of the proposed methods with multiple granularity . Furthermore, based on the proposed multiple granularity distance, a novel decision-making algorithm is designed. The results validate that the proposed decision-making method is beneficially applicable to classification scenarios and different real-world data.},
  archive      = {J_ISCI},
  author       = {Yangyang Zhao and Zhanhao Zhang and Fuyuan Xiao},
  doi          = {10.1016/j.ins.2024.120168},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120168},
  shortjournal = {Inf. Sci.},
  title        = {A multi-granularity distance with its application for decision making},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Communication-efficient and privacy-preserving large-scale
federated learning counteracting heterogeneity. <em>ISCI</em>,
<em>661</em>, 120167. (<a
href="https://doi.org/10.1016/j.ins.2024.120167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a commonly distributed framework for large-scale learning, where a model is learned over massively distributed remote devices without sharing information on devices. It has at least three key challenges: heterogeneity in federated networks , privacy and communication costs. In this paper, we propose three federated learning algorithms to handle these issues gradually. First, we introduce a FedSfDane algorithm ( DANE with S hrinkage f actor for Fed erated learning), which improves the inexact approximation of the full gradient, captures statistical heterogeneity and restrains systems heterogeneity across the devices. For avoiding possible privacy leakage in federated learning, a P rivacy-preserving FedSfDane algorithm (PFedSfDane) is proposed, which is resistant to adversary attacks. Further, we give a novel C ommunication-efficient PFedSfDane (CPFedSfDane) algorithm for large-scale federated networks, which effectively handles the above three challenges. We give convergence guarantees for the three algorithms to convex and non-convex learning problems. Numerical experiments illustrate our algorithms outperform FedDANE, FedAvg and FedProx algorithms, especially for highly heterogeneous federated networks. CPFedSfDane improves the prediction accuracy of the state-of-the-art FedDANE algorithm by about 15.0% on sent140 dataset, and has high privacy protection and communication efficiency.},
  archive      = {J_ISCI},
  author       = {Xingcai Zhou and Guang Yang},
  doi          = {10.1016/j.ins.2024.120167},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120167},
  shortjournal = {Inf. Sci.},
  title        = {Communication-efficient and privacy-preserving large-scale federated learning counteracting heterogeneity},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-reservoir echo state network with five-elements cycle.
<em>ISCI</em>, <em>661</em>, 120166. (<a
href="https://doi.org/10.1016/j.ins.2024.120166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Echo state network (ESN) is reservoir computing model that effectively replace recurrent neural network (RNN). However, building reservoir in traditional ESN often has randomness, making it difficult to effectively determine the reservoir that matches a given task. Therefore, a multi-reservoir ESN based on five-elements cycle (FEC-MRESN) is proposed to design the reservoir automatically in this paper. First, FEC-MRESN designs a pruning algorithm using a top-down strategy to remove redundant neurons from the reservoir based on the generation and restriction relations between elements in the five-elements cycle. Second, based on the reservoir neurons retained by the pruning algorithm, an exponential weight assignment method is studied to achieve deterministic assignment of reservoir weights. Finally, FEC-MRESN is tested on some time series benchmark datasets. The experimental results show that FEC-MRESN not only improves prediction accuracy, but also removes redundant reservoir neurons, improves network generalization performance and training efficiency.},
  archive      = {J_ISCI},
  author       = {Bowen Wang and Shuxian Lun and Ming Li and Xiaodong Lu},
  doi          = {10.1016/j.ins.2024.120166},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120166},
  shortjournal = {Inf. Sci.},
  title        = {Multi-reservoir echo state network with five-elements cycle},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PML-ED: A method of partial multi-label learning by using
encoder-decoder framework and exploring label correlation.
<em>ISCI</em>, <em>661</em>, 120165. (<a
href="https://doi.org/10.1016/j.ins.2024.120165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial multi-label learning (PML) addresses problems where each instance is assigned a candidate label set and only a subset of these candidate labels is correct. The major challenge of PML is that the training procedure can be easily misguided by noisy labels. Current studies on PML have revealed two significant drawbacks. First, most of them do not sufficiently explore complex label correlations, which could improve the effectiveness of label disambiguation. Second, PML models heavily rely on prior assumptions, limiting their applicability to specific scenarios. In this work, we propose a novel method of PML based on the Encoder-Decoder Framework (PML-ED) to address the drawbacks. PML-ED initially achieves the distribution of label probability through a KNN label attention mechanism. It then adopts Conditional Layer Normalization (CLN) to extract the high-order label correlation and relaxes the prior assumption of label noise by introducing a universal Encoder-Decoder framework. This approach makes PML-ED not only more efficient compared to the state-of-the-art methods, but also capable of handling the data with large noisy labels across different domains. Experimental results on 28 benchmark datasets demonstrate that the proposed PML-ED model, when benchmarked against nine leading-edge PML algorithms, achieves the highest average ranking across five evaluation criteria.},
  archive      = {J_ISCI},
  author       = {Zhenwu Wang and Fanghan Liu and Mengjie Han and Hongjian Tang and Benting Wan},
  doi          = {10.1016/j.ins.2024.120165},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120165},
  shortjournal = {Inf. Sci.},
  title        = {PML-ED: A method of partial multi-label learning by using encoder-decoder framework and exploring label correlation},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Community detection in decentralized social networks with
local differential privacy. <em>ISCI</em>, <em>661</em>, 120164. (<a
href="https://doi.org/10.1016/j.ins.2024.120164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection under local differential privacy has been a research hotspot recently. Most existing methods primarily rely on the edge local differential privacy model (edge-LDP), compromising privacy strength for high utility. In addition, they adopt a way of agglomerating nodes one by one to construct communities (or clusters) through multiple iterations, suffering from significant noise and low detection efficiency. Moreover, the error accumulation caused by large-scale iterations is not conducive to detection accuracy. To address these issues, we propose a privacy-preserving community detection method, CD-LDP, based on node-LDP, achieving efficient and accurate community construction by aggregating grouped units instead of individual nodes and delimiting the interaction to three rounds. Specifically, we propose a privacy-preserving global social network construction method to gain connectivity information among all nodes through two rounds of interactions. In addition, a novel perturbation mechanism based on the star social network structure is devised, which improves the accuracy of the global social network by reducing the probability of generating fake edges. Secondly, we design a privacy-preserving node grouping approach leveraging clustering coefficients and Haar discrete wavelet transform in the third round, achieving low noise injection and high-quality node grouping through lossless dimensionality reduction. Lastly, we develop a fast unit merging algorithm combining modularity and Huffman trees to realize efficient and accurate community building by reducing the aggregation possibility of nodes with low similarity. Theoretical analysis and experimentation on real-world datasets testify that our solution can efficiently extract high-quality community structures while satisfying node-LDP.},
  archive      = {J_ISCI},
  author       = {Nan Fu and Weiwei Ni and Lihe Hou and Dongyue Zhang and Ruyu Zhang},
  doi          = {10.1016/j.ins.2024.120164},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120164},
  shortjournal = {Inf. Sci.},
  title        = {Community detection in decentralized social networks with local differential privacy},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A connectivity-preserving performance guarantee for
cooperative control method with improved switching event-triggered
mechanism. <em>ISCI</em>, <em>661</em>, 120163. (<a
href="https://doi.org/10.1016/j.ins.2024.120163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An adaptive tracking control scheme is designed for multiagent systems. To ensure a certain communication range between agents, a connectivity-preserving performance guarantee mechanism is proposed, which increases the consideration of the connection information between agents and the leader to further improve the cooperativity. Meanwhile, different from traditional constraint error methods, a boundary-based prescribed performance control scheme is constructed, which has the characteristic of getting the variable preset boundary. Furthermore, the improved switching event-triggered mechanism is developed, and the threshold parameters can be adjusted in real-time to adaptively change the update frequency of the controller. All signals are bounded in the closed-loop system. Finally, some simulation results affirm the validity of the control scheme.},
  archive      = {J_ISCI},
  author       = {Dongni Li and Hongjing Liang and Liang Cao},
  doi          = {10.1016/j.ins.2024.120163},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120163},
  shortjournal = {Inf. Sci.},
  title        = {A connectivity-preserving performance guarantee for cooperative control method with improved switching event-triggered mechanism},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prioritization of sustainable approaches for smart waste
management of automotive fuel cells of road freight vehicles using the
q-rung orthopair fuzzy CRITIC-EDAS method. <em>ISCI</em>, <em>661</em>,
120162. (<a href="https://doi.org/10.1016/j.ins.2024.120162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuel cell electric vehicles (FCEVs) are a contemporary technology that is making headway in the expanding automotive industry. To promote FCEV effectiveness, environmentally acceptable limits need to be considered during their whole life cycle. End-of-life automotive fuel cells (AFCs) are one of the major contemporary challenges facing the sustainable business of transportation companies. The paper introduces a hybrid q-rung orthopair fuzzy (q-ROF)-based methodology to handle uncertainties and vagueness. It couples and extends the criteria importance through intercriteria correlation (CRITIC) and evaluation based on distance from average solution (EDAS) methods with q-ROF sets. This research aims to provide essential methodological and practical frameworks, as well as guidelines for improving the effectiveness of engaged FCEVs in transportation companies. The q-ROF CRITIC-EDAS methodology provides a systematic method for prioritizing sustainable approaches for smart waste management of AFCs of road freight vehicles . The incorporation of the real-life case study demonstrates its practical applicability and validity. The introduced q-ROF CRITIC-EDAS model could be extensively applied to the AFC waste management in order to assist stakeholders in making decisions consistent with the sustainability objectives.},
  archive      = {J_ISCI},
  author       = {Hafiz Muhammad Athar Farid and Svetlana Dabic-Miletic and Muhammad Riaz and Vladimir Simic and Dragan Pamucar},
  doi          = {10.1016/j.ins.2024.120162},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120162},
  shortjournal = {Inf. Sci.},
  title        = {Prioritization of sustainable approaches for smart waste management of automotive fuel cells of road freight vehicles using the q-rung orthopair fuzzy CRITIC-EDAS method},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assessing and selecting sustainable refrigerated road
vehicles in food logistics using a novel multi-criteria group
decision-making model. <em>ISCI</em>, <em>661</em>, 120161. (<a
href="https://doi.org/10.1016/j.ins.2024.120161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, food loss and waste (FLW) have become an essential issue at the top of the international community&#39;s agenda. Since more people are afflicted by this problem every day, the global population would be forced into poverty and starvation without finding an immediate solution. Therefore, in order to decrease FLW, well-designed and sustainable food and cold supply chains (FCSCs) are needed. Additionally, refrigerated transportation systems can be crucial in developing sustainable supply chains. According to some empirical research, the technological capabilities of reefer vehicles or trailers differ significantly. Thus, selecting the reefer vehicle is a complex decision-making problem and selecting appropriate reefer vehicles may have a critical role in constructing successful supply chain systems and reducing food waste and loss. The current research proposes an efficient, robust and practical decision-making framework that can overcome uncertainties to tackle this decision-making problem. The managerial and strategic implications of the study also aid in decreasing FLW and restructuring FSC for industrial context and support to the UN&#39;s sustainable development goals (SDGs). Later, an exhaustive sensitivity analysis was conducted to examine the developed model&#39;s validity and application, confirming the model&#39;s robustness and dependability .},
  archive      = {J_ISCI},
  author       = {Ömer Faruk Görçün and Erfan Babaee Tirkolaee and Hande Küçükönder and Chandra Prakash Garg},
  doi          = {10.1016/j.ins.2024.120161},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120161},
  shortjournal = {Inf. Sci.},
  title        = {Assessing and selecting sustainable refrigerated road vehicles in food logistics using a novel multi-criteria group decision-making model},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards robust learning with noisy and pseudo labels for
text classification. <em>ISCI</em>, <em>661</em>, 120160. (<a
href="https://doi.org/10.1016/j.ins.2024.120160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlike Positive Training (PT), Negative Training (NT) is an indirect learning technique that trains the model on a combination of clean and noisy data using complementary labels, which are randomly generated from the label space except for the actual label. Although clean samples have identical distributions to the test samples, they are treated with the same level of uncertainty as noisy samples because of the complementary labeling of NT. Consequently, their contribution to the overall performance is relatively lower. We propose a Learning with Noisy and Pseudo Label (LNPL) framework, which jointly trains the model using PT and NT on clean and noisy data, respectively. We aim to enable direct learning on clean samples while leveraging the robustness of NT against noise in a unified framework. To mitigate the abundance of noisy instances, we leverage a gradient reversal layer at the top of LNPL as a regularization term to mislead the recognition of the source of the instance (e.g., clean or noisy). Moreover, we introduce a self-training LNPL that performs a semi-supervised text classification task as a learning with noisy pseudo-label problem. Extensive experiments on various textual benchmark datasets demonstrate that LNPL is robust and consistently outperforms the alternatives. The code is available on GitHub. 1},
  archive      = {J_ISCI},
  author       = {Murtadha Ahmed and Bo Wen and Luo Ao and Shengfeng Pan and Jianlin Su and Xinxin Cao and Yunfeng Liu},
  doi          = {10.1016/j.ins.2024.120160},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120160},
  shortjournal = {Inf. Sci.},
  title        = {Towards robust learning with noisy and pseudo labels for text classification},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised discovery of interpretable visual concepts.
<em>ISCI</em>, <em>661</em>, 120159. (<a
href="https://doi.org/10.1016/j.ins.2024.120159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Providing interpretability of deep-learning models to non-experts, while fundamental for a responsible real-world usage, is challenging. Attribution maps from xAI techniques, such as Integrated Gradients, are a typical example of a visualization technique containing a high level of information, but with difficult interpretation. In this paper, we propose two methods, Maximum Activation Groups Extraction (MAGE) and Multiscale Interpretable Visualization (Ms-IV), to explain the model&#39;s decision, enhancing global interpretability . MAGE finds, for a given CNN , combinations of features which, globally, form a semantic meaning, that we call concepts . We group these similar feature patterns by clustering in “concepts”, that we visualize through Ms-IV. This last method is inspired by Occlusion and Sensitivity analysis (incorporating causality) and uses a novel metric, called Class-aware Order Correlation ( CAOC CAOC ), to globally evaluate the most important image regions according to the model&#39;s decision space. We compare our approach to xAI methods such as LIME and Integrated Gradients. Experimental results evince the Ms-IV higher localization and faithfulness values. Finally, qualitative evaluation of combined MAGE and Ms-IV demonstrates humans&#39; ability to agree, based on the visualization, with the decision of clusters&#39; concepts; and, to detect, among a given set of networks, the existence of bias.},
  archive      = {J_ISCI},
  author       = {Caroline Mazini Rodrigues and Nicolas Boutry and Laurent Najman},
  doi          = {10.1016/j.ins.2024.120159},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120159},
  shortjournal = {Inf. Sci.},
  title        = {Unsupervised discovery of interpretable visual concepts},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design and prediction of self-organizing interval type-2
fuzzy wavelet neural network. <em>ISCI</em>, <em>661</em>, 120157. (<a
href="https://doi.org/10.1016/j.ins.2024.120157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a self-organizing interval type-2 fuzzy wavelet neural network (SIT2FWNN) model for predicting and identifying nonlinear systems. Based on traditional TSK interval type-2 fuzzy neural network (IT2FNN), the proposed SIT2FWNN utilizes the wavelet basis function with the locating abilities of time-domain and frequency-domain as the consequent of fuzzy rules, combining the capacity of IT2FNN to handle the uncertainty and the great learning potentiality of wavelet neural network (WNN). For the structural adjustment of SIT2FWNN, fuzzy rules are added and deleted according to the Euclidean distance between the input layer and the fuzzification layer. The self-organizing algorithm can delete redundant and unimportant fuzzy rules, thus optimizing the structure of SIT2FWNN and simplifying the calculation. In parameter learning, the AdaBound algorithm and self-adaptive gradient learning algorithm are used to find optimal values of unknown parameters of the SIT2FWNN model. Finally, the designed SIT2FWNN model is applied in the predictions of short-term traffic flow, Mackey-Glass time series, and the opening index of the Shanghai stock index. The evaluation comparison between the proposed model and similar studies proves that SIT2FWNN has higher prediction accuracy and speed.},
  archive      = {J_ISCI},
  author       = {Xuan Liu and Taoyan Zhao and Jiangtao Cao and Ping Li},
  doi          = {10.1016/j.ins.2024.120157},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120157},
  shortjournal = {Inf. Sci.},
  title        = {Design and prediction of self-organizing interval type-2 fuzzy wavelet neural network},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised graph denoising via feature-driven matrix
factorization. <em>ISCI</em>, <em>661</em>, 120156. (<a
href="https://doi.org/10.1016/j.ins.2024.120156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph denoising is becoming a promising solution for robust graph embedding , which aims to construct an ideal network by removing noisy edges. Currently, the mainstream denoising approaches often build upon the low-rank assumption by removing high-rank harmful edges with singular value decomposition. Although this approach often allows yielding good graph embedding, the high time complexity limits its application to large-scale networks. In this paper, we propose an effective and efficient algorithm for robust graph embedding: L atent F eature-driven G raph D enoising (LFGD). The basic idea is to leverage node latent features to construct an ideal low-rank network by exploiting the relationship between topology and feature information. To this end, the original features are first mapped into a latent space, and then a low-rank network is reconstructed by imposing the semantic preservation loss and structure loss (including regression loss and sparsity constraint). In addition, we propose a sampling-based strategy to further speed up the proposed method, which finally results in linear time complexity. LFGD works independently of downstream task, which makes the denoised structure more general and reliable. Extensive experiments have demonstrated the superiority of the LFGD to many state-of-the-art algorithms under various attacks in terms of node classification , robustness and running time. Our code is available at: https://github.com/hanwangme/LFGD .},
  archive      = {J_ISCI},
  author       = {Han Wang and Zhili Qin and Zejun Sun and Qinli Yang and Junming Shao},
  doi          = {10.1016/j.ins.2024.120156},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120156},
  shortjournal = {Inf. Sci.},
  title        = {Unsupervised graph denoising via feature-driven matrix factorization},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective compression for CNNs via evolutionary
algorithm. <em>ISCI</em>, <em>661</em>, 120155. (<a
href="https://doi.org/10.1016/j.ins.2024.120155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Filter pruning has been successfully applied in convolutional neural networks (CNN) to reduce model redundancy and speed up inference. Current pruning algorithms require setting a target value for a pruned model, which is not conducive to the rapid implementation in practical application. Firstly, for a target model, it may be necessary to pay attention to multiple performances at the same time, but it is hard to keep the best trade-off among indicators. Secondly, it is time-consuming to find a suitable model by pruning in a trial-and-error way. Therefore, this paper attempts to combine the most concerning indicators into a search target, rather than producing a model that only contains some pre-defined constraint. Specifically, the multi-object differential evolution algorithm is introduced into the search process, which is used to obtain a set of sparse structures that have taken all useful indicators into account. Then select proper sub-network to retrain from search results according to actual requirements. Experiments on multiple advanced CNN networks show that our algorithm can compress different indicators while keeping comparable or better performance than prior works. On ImageNet, pruning based on ResNet50 reduces FLOPs by 60.4%, while the accuracy of top-1 and top-5 only loses 1.09% and 0.57%, respectively.},
  archive      = {J_ISCI},
  author       = {Youzao Lian and Peng Peng and Kai Jiang and Weisheng Xu},
  doi          = {10.1016/j.ins.2024.120155},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120155},
  shortjournal = {Inf. Sci.},
  title        = {Multi-objective compression for CNNs via evolutionary algorithm},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient conflict analysis method based on splitting and
merging of formal contexts. <em>ISCI</em>, <em>661</em>, 120154. (<a
href="https://doi.org/10.1016/j.ins.2024.120154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conflict situations are widespread nearly in all corners of social life, and the efficiency of conflict analysis still has much room especially for large-scale data sets. To this end, this study presents an information fusion method of fast conflict analysis based on formal concept analysis. Firstly, a novel type of three-way concepts is defined to neatly deal with three-valued formal contexts. Then, fast computation of conflict analysis is explored by using an information fusion technique. Specifically, conflict analysis based on horizontal splitting and merging of formal contexts and the one based on vertical splitting and merging of formal contexts are respectively investigated. Finally, systematic experiments are carried out on both synthetic data sets and real cases to evaluate the performance of the proposed method. According to the experimental results, conflict analysis based on vertical splitting and merging of formal contexts can effectively improve the performance, which may not be realized by using the horizontal splitting and merging strategy in some cases. This study may shed light on formal concept analysis based multi-source big data analysis.},
  archive      = {J_ISCI},
  author       = {Huilai Zhi and Zhenhao Qi and Yinan Li},
  doi          = {10.1016/j.ins.2024.120154},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120154},
  shortjournal = {Inf. Sci.},
  title        = {An efficient conflict analysis method based on splitting and merging of formal contexts},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). IeMTLF: Interaction-enhanced multi-task learning framework
for next location prediction. <em>ISCI</em>, <em>661</em>, 120153. (<a
href="https://doi.org/10.1016/j.ins.2024.120153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location-Based Services (LBSs) provide spatial and semantic information of various locations, thanks to the advances in mobile devices and commercial map services. However, most existing studies on next location prediction neglect the semantic information and do not investigate the effects of different levels of semantic granularity . To address these issues, we propose an Interaction-enhanced Multi-Task Learning Framework (IeMTLF) that jointly predicts the next location and its semantic category and leverages higher-order feature interactions to enrich the semantic learning process. Moreover, we examine the effect of two different levels of semantic granularity , namely, specific and abstract, on prediction performance. We conducted extensive experiments on two real-world datasets and demonstrate that IeMTLF outperforms seven baselines on all evaluation metrics , with a maximum gain of more than 13% for Acc@5 compared to the state-of-the-art method. Our implementation code is available at https://github.com/mrc-wyh/IeMTLF .},
  archive      = {J_ISCI},
  author       = {Yahui Wang and Hongchang Chen and Shuxin Liu and Kai Wang and Xing Li and Yuxiang Hu},
  doi          = {10.1016/j.ins.2024.120153},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120153},
  shortjournal = {Inf. Sci.},
  title        = {IeMTLF: Interaction-enhanced multi-task learning framework for next location prediction},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MRIformer: A multi-resolution interactive transformer for
wind speed multi-step prediction. <em>ISCI</em>, <em>661</em>, 120150.
(<a href="https://doi.org/10.1016/j.ins.2024.120150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind speed prediction is crucial for managing energy consumption in wind farms. Traditional wind speed prediction techniques often overlook two essential characteristics of wind speed data: (a) the downsampled wind speed data can retain cyclic and trend information, which is valuable for the model. (b) Multi-resolution speed data exhibited distinct patterns, enabling the model to extract insights from various perspectives. Considering the above two characteristics, this paper presents a novel approach called the Multi-Resolution Interactive transformer (MRIformer), which consists of the ASI block and the MRI block. The ASI block utilizes two different attention mechanisms to extract temporal information and enhance interactive learning among subsequences while downsampling wind speed data. The MRI block utilizes a tree structure to stack multiple layers of ASI blocks, enabling the analysis of wind speed data at various resolutions. By incorporating residual connections and multi-head attention, the MRI block effectively fuses data with different resolutions. Comparative experiments on three real-world datasets led to the following conclusions. (a) MRIformer exceeded 14 state-of-the-art baselines on all datasets and achieved a performance improvement of over 7.5%. (b) The effectiveness of the designed structure is demonstrated through component replacement and ablation experiments.},
  archive      = {J_ISCI},
  author       = {Chengqing Yu and Guangxi Yan and Chengming Yu and Xinwei Liu and Xiwei Mi},
  doi          = {10.1016/j.ins.2024.120150},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120150},
  shortjournal = {Inf. Sci.},
  title        = {MRIformer: A multi-resolution interactive transformer for wind speed multi-step prediction},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy membership-function-dependent design of aperiodic
sample-data control scheme for nonlinear PMSG-based WECS with
quantization measurements via refined looped lyapunov functional.
<em>ISCI</em>, <em>661</em>, 120149. (<a
href="https://doi.org/10.1016/j.ins.2024.120149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript investigates the fuzzy memory sampled-data control (MSDC) scheme for the nonlinear permanent magnet synchronous generator (PMSG)-based wind energy conversion system (WECS) with quantization measurements. First, due to the complex nonlinearity , a Takagi-Sugeno (T-S) fuzzy modeling approach is successfully applied to the dynamics of nonlinear PMSG-based WECS. Second, by using the information of both quantized aperiodic sampling pattern and signal transmission delay, an H ∞ H∞ -based fuzzy quantized controller is put forward to ensure the stable performance as well as disturbance suppression index of the considered PMSG model by utilizing the refined looped Lyapunov functional (RLLF) approach. This RLLF perfectly utilizes more realistic information about the time derivative of the fuzzy membership function and actual sampling pattern. Then, two new integral inequalities are introduced to approximate the quadratic integral terms arising from the derivative of RLLF. Next, we establish some less conservative stabilization results in terms of linear matrix inequalities (LMIs) using the constructed RLLF, along with the proposed integral inequalities and fuzzy membership function-dependent (MFD) switching ideas. Finally, the simulation studies of PMGS-based WECS are validated numerically, and then a comparative example is provided to emphasize the superiority and relevance of the suggested approach.},
  archive      = {J_ISCI},
  author       = {Pratap Anbalagan and Young Hoon Joo},
  doi          = {10.1016/j.ins.2024.120149},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120149},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy membership-function-dependent design of aperiodic sample-data control scheme for nonlinear PMSG-based WECS with quantization measurements via refined looped lyapunov functional},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive fuzzy finite-time PID backstepping control for
chaotic systems with full states constraints and unmodeled dynamics.
<em>ISCI</em>, <em>661</em>, 120148. (<a
href="https://doi.org/10.1016/j.ins.2024.120148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the problem that the controlled object and system model cannot be fully mastered or the system parameters cannot be well obtained through conventional measurement methods, in this paper, a novel adaptive fuzzy finite-time PID backstepping control method is developed for a class of nonlinear chaotic systems with full state constraints and unmodeled dynamics. The unmodeled dynamics are handled by employing a dynamic signal. To avoid the violations of full state constraints (FSCs), a barrier Lyapunov function is used to implement a PID backstepping framework, whose merit consists in that three control gain constants K P KP , K I KI and K D KD with corresponding proportional relationships are designed to further improve control precision. Besides, the PID control method also embodies three dynamic gain components Δ K P ΔKP , Δ K I ΔKI and Δ K D ΔKD , all of which are free functions that can be self-tuning online, and have a significant link with the adaptive law and modify accordingly. Finally, theoretical analysis confirms that all signals are ultimately uniformly bounded, the error signal converges to a nearby area near the origin in a finite-time, and the FSCs are not smashed. The practicality of the proposed method is confirmed by two simulation studies using the second-order Duffing chaotic system and third-order Chua&#39;s circuit .},
  archive      = {J_ISCI},
  author       = {Xiulan Zhang and Xingyue Yang and Chengdai Huang and Jinde Cao and Heng Liu},
  doi          = {10.1016/j.ins.2024.120148},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120148},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fuzzy finite-time PID backstepping control for chaotic systems with full states constraints and unmodeled dynamics},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-task subspace clustering. <em>ISCI</em>, <em>661</em>,
120147. (<a href="https://doi.org/10.1016/j.ins.2024.120147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, subspace clustering and multi-task clustering have received extensive attention due to their wide practical applications. Traditional subspace clustering is limited to exploring the underlying subspaces within a single task, while traditional multi-task clustering usually ignores the data distributed in some low-dimensional subspaces. However, multiple subspace clustering tasks, in reality, may be related. To resolve this issue, we introduce a multi-task subspace clustering method , which unifies transfer learning , local structure learning , and self-representation learning into a single paradigm. In particular, we suggest learning a projection matrix to perform dimensionality reduction, and exploring correlations among multiple tasks simultaneously. In addition, we design an efficient algorithm to solve the objective. The experimental findings demonstrate that the approach suggested in this study exhibits superior performance compared to the existing state-of-the-art methods in the domains of subspace clustering and multi-task clustering. Our MATLAB codes are available at https://github.com/HeKind/MTSC .},
  archive      = {J_ISCI},
  author       = {Guo Zhong and Chi-Man Pun},
  doi          = {10.1016/j.ins.2024.120147},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120147},
  shortjournal = {Inf. Sci.},
  title        = {Multi-task subspace clustering},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Video-based working condition recognition of fused
magnesium furnace with stochastic configuration networks. <em>ISCI</em>,
<em>661</em>, 120146. (<a
href="https://doi.org/10.1016/j.ins.2024.120146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Working condition recognition of a fused magnesium furnace (FMF) suffers from unbalanced under-burning condition samples, inconsistent quality of training samples and difficulty in characterizing dynamic production processes with images. This paper presents a novel approach to detect the under-burning working condition in FMF based on a 3D-cycle-generative adversarial network (3D-cycle-GAN) and Video Swin Transformer-Stochastic Configuration Networks (Video Swin-SCNs). Firstly, to resolve the temporal discontinuity defect caused by Cycle-GAN through the visual appearance of video composite frames, we construct a motion consistency-based 3D-Cycle-GAN model that considers the visual appearance and temporal continuity constraints of unpaired video transitions and is designed to generate video samples of under-burning working conditions. Secondly, a reinforcement learning approach is used to assess the value of the video quality and to filter out possible low-quality samples generated. Finally, the local attention is extended from the spatial domain to the spatial-temporal domain to solve the difficulty in characterizing the dynamic production process with the static images. The spatial-temporal features from the Video Swin Transformer are fed into SCNs to classify the working conditions. The experiment results indicate the effectiveness and feasibility of the proposed method.},
  archive      = {J_ISCI},
  author       = {Weitao Li and Xinru Zhang and Qian Zhang and Pinglu Hu},
  doi          = {10.1016/j.ins.2024.120146},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120146},
  shortjournal = {Inf. Sci.},
  title        = {Video-based working condition recognition of fused magnesium furnace with stochastic configuration networks},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust corrective control against fundamental and
non-fundamental mode attacks with application to an asynchronous digital
system. <em>ISCI</em>, <em>661</em>, 120145. (<a
href="https://doi.org/10.1016/j.ins.2024.120145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a robust model matching corrective control scheme for input/state asynchronous sequential machines (ASMs) vulnerable to both fundamental and non-fundamental mode attacks. Specifically, when non-fundamental mode attacks occur, ASMs undergo unauthorized state transitions in their transient behaviors , reaching faulty states. The attack outcome is exacerbated if non-fundamental mode attacks occur during the procedure of model matching by the controller. We address the necessary and sufficient condition and design procedure for a state-burst-feedback corrective controller that eliminates the adverse effect of both fundamental and non-fundamental mode attacks, while matching the stable-state behavior of the closed-loop system to that of a reference model. To demonstrate the synthesis of the controller and applicability of the proposed scheme, a practical ASM termed the payload data manager and the corrective controller are implemented on field-programmable gate array (FPGA) circuits. Experimental results are provided on model matching and robust corrective control overcoming both fundamental and non-fundamental mode attacks.},
  archive      = {J_ISCI},
  author       = {Jung-Min Yang and Seong Woo Kwak},
  doi          = {10.1016/j.ins.2024.120145},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120145},
  shortjournal = {Inf. Sci.},
  title        = {Robust corrective control against fundamental and non-fundamental mode attacks with application to an asynchronous digital system},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Strict intuitionistic fuzzy distance/similarity measures
based on jensen-shannon divergence. <em>ISCI</em>, <em>661</em>, 120144.
(<a href="https://doi.org/10.1016/j.ins.2024.120144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Being a pair of dual concepts, the normalized distance and similarity measures are important tools for decision-making and pattern recognition under the intuitionistic fuzzy set framework. In this paper, we first construct some counterexamples to illustrate that two existing similarity measures do not meet the axiomatic definition of intuitionistic fuzzy similarity measures. We then show that (1) these two measures cannot effectively distinguish some intuitionistic fuzzy values (IFVs); (2) except for the endpoints, there exist infinitely many pairs of IFVs, where the maximum distance “1” can be achieved under these two distances, leading to counter-intuitive results. To overcome these drawbacks, we introduce the concept of strict intuitionistic fuzzy distance measure (SIFDisM) and strict intuitionistic fuzzy similarity measure (SIFSimM), and propose an improved intuitionistic fuzzy distance measure based on Jensen-Shannon divergence. Moreover, we prove that (1) it is a SIFDisM; (2) its dual similarity measure is a SIFSimM; (3) its induced entropy is an intuitionistic fuzzy entropy. Comparative analysis and numerical examples demonstrate that our proposed distance measure is superior to the existing ones. In particular, our proposed distance measure can better distinguish and rank intuitionistic fuzzy sets.},
  archive      = {J_ISCI},
  author       = {Xinxing Wu and Zhiyi Zhu and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2024.120144},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120144},
  shortjournal = {Inf. Sci.},
  title        = {Strict intuitionistic fuzzy distance/similarity measures based on jensen-shannon divergence},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A MOEA/d with adaptive weight subspace for regular and
irregular multi-objective optimization problems. <em>ISCI</em>,
<em>661</em>, 120143. (<a
href="https://doi.org/10.1016/j.ins.2024.120143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of the decomposition-based multi-objective optimization algorithm (MOEA/D) is dependent on the consistency of the Pareto front and the distribution of the weight vectors . Uniformly distributed weight vectors have a great advantage in solving Pareto fronts with simplex-like shapes. However, the fronts of real-world problems to be solved are often irregular, and fixed weight vectors are likely to cause deterioration of the solution. To obtain a set of solution sets that are uniformly distributed in the objective space , a MOEA/D-based weight adaptive updating algorithm (called MOEA/D-AWS) is proposed. First, the subproblem evolutionary matrix similarity is used to determine when to adjust the weight vectors. Second, the objective space is divided by creating a subspace of weight vectors to increase population diversity. Third, partial weights are given a second chance to be selected based on the subspace size. Experimental tests are conducted with seven representative algorithms on benchmark functions DTLZ1-7, IDTLZ1-2, MaF1-7, and WFG1-5 (with objective numbers of 3, 5, 8, 10, and 15). The results show that MOEA/D-AWS is more effective for irregular Pareto fronts, especially discontinuous, degenerate, and sharp-tailed Pareto front problems.},
  archive      = {J_ISCI},
  author       = {Qinghua Gu and Kexin Li and Dan Wang and Di Liu},
  doi          = {10.1016/j.ins.2024.120143},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120143},
  shortjournal = {Inf. Sci.},
  title        = {A MOEA/D with adaptive weight subspace for regular and irregular multi-objective optimization problems},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective optimization of planning single-tuned
harmonic filter utilizing interactive forest algorithm. <em>ISCI</em>,
<em>661</em>, 120141. (<a
href="https://doi.org/10.1016/j.ins.2024.120141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an interactive forest algorithm for planning single-tuned harmonic filters for electric power distribution systems. The planning of harmonic filters is a complex problem that must consider multiple objectives, including minimizing the total cost of installed filters and the individual and total harmonic distortion while adhering to operational constraints, such as the voltage drop, the current loading and the harmonic limits. Moreover, system perturbations must be considered, such as frequency variations. This paper proposes a new method for multi-objective optimization of planning single-tuned harmonic filters utilizing the proposed interactive forest algorithm with a non-differentiable multi-objective function involving continuous and discrete variables. A multi-objective optimization technique based on the proposed interactive forest algorithm is proposed. In the interactive approach, planners set expectations for each objective and use the forest algorithm to figure out the optimization problems . The results of the Pareto Front are analyzed and the answers are searched through the interactive process to identify a solution that meets the planner’s expectations, allowing for practical compromise or satisfactory solutions. A case study is reported to show the superiority of the proposed method.},
  archive      = {J_ISCI},
  author       = {Ying-Tung Hsiao and Shu-Min Lin and Shyi-Ming Chen and Chih-Ju Chou},
  doi          = {10.1016/j.ins.2024.120141},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120141},
  shortjournal = {Inf. Sci.},
  title        = {Multi-objective optimization of planning single-tuned harmonic filter utilizing interactive forest algorithm},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unlock the potential: Unveiling the untapped possibilities
of blockchain technology in revolutionizing internet of medical
things-based environments through systematic review and future research
propositions. <em>ISCI</em>, <em>661</em>, 120140. (<a
href="https://doi.org/10.1016/j.ins.2024.120140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Medical Things (IoMTs) has rapidly gained popularity recently, and the need for self-health assessment and the resulting reduction in treatment waiting periods have sped up the usage of IoMTs. Unfortunately, the growing usage of IoMTs has also brought up issues that have unintended effects, including a lack of data management, an unsafe network environment, privacy and security concerns. To address the problems with IoMT applications, distributed ledger technology, which forms the basis of blockchain technology (BCT), has emerged as a practical solution. The utility of BCT to support IoMT-based settings has been demonstrated by academic research. However, no analysis of the literature has been performed to comprehend BCT performance in IoMT scenarios. Therefore, the present study offers a thorough literature review of 182 studies on the use of BCT in an IoMT environment, drawn from 70 pioneering journals included in the WoS database. It also outlines recommendations for future research areas. This study adds to the body of literature in three main ways using a mix of bibliographic and content analysis. It starts out by outlining the structure of how BCT works in an IoMT setting. Secondly, it provides a roadmap that takes into account the factors that might aid in BCT proliferation in IoMT situations. Thirdly, the paper outlines the prerequisites for BCT&#39;s effective adoption and use in an IoMT environment. The implications of the recognized clusters and the factors influencing the properties and outcomes of BCT are covered in the article&#39;s conclusion. This is the first effort to investigate BCT&#39;s function within the context of the IoMT environment; this has become crucial since BCT has developed popularity in IoMT contexts. The article highlights many aspects that may help to improve comprehension of this important issue by utilizing the provided outline as a guide and identifying major knowledge gaps.},
  archive      = {J_ISCI},
  author       = {Ashutosh Samadhiya and Anil Kumar and Jose Arturo Garza-Reyes and Sunil Luthra and Francisco del Olmo García},
  doi          = {10.1016/j.ins.2024.120140},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120140},
  shortjournal = {Inf. Sci.},
  title        = {Unlock the potential: Unveiling the untapped possibilities of blockchain technology in revolutionizing internet of medical things-based environments through systematic review and future research propositions},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A holistic global-local stochastic configuration network
modeling framework with antinoise awareness for efficient
semi-supervised regression. <em>ISCI</em>, <em>661</em>, 120132. (<a
href="https://doi.org/10.1016/j.ins.2024.120132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic configuration network (SCN) has become a sound model due to its universal approximation property with the adaptive configuration of hidden node parameters under a supervision mechanism. However, the basic SCN is essentially a global optimization model and omits the local data structure information, which can be mined by investigating abundant unlabeled samples . In order to address this problem, a holistic SCN modeling framework involving global and local constraints (GLSCN) is presented for effective semi-supervised regression development. For one thing, the model empirical error and the L2 regularization term are assigned from the viewpoint of global optimization. For another, two different local regularization constraints are designed where manifold regularization is utilized to construct local nearest neighbor graphs between samples for taking full advantage of unlabeled samples, and consistency regularization constraint is introduced to further handle the potential random noise. By injecting random noise into the unlabeled samples, local consistency regularization can enforce the prediction consistency effect of unlabeled samples and improve the local smoothness of each sample further. In this way, not only can a large amount of unlabeled information be fully exploited, but the model robustness is also effectively enhanced. Lastly, the validity of the developed GLSCN is demonstrated by two industrial cases of a sulfur recovery unit and a continuous stirred tank reactor .},
  archive      = {J_ISCI},
  author       = {Xiaogang Deng and Yue Zhao and Jing Zhang and Xuejing Li and Ziheng Wang},
  doi          = {10.1016/j.ins.2024.120132},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120132},
  shortjournal = {Inf. Sci.},
  title        = {A holistic global-local stochastic configuration network modeling framework with antinoise awareness for efficient semi-supervised regression},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large-scale consensus with dynamic trust and optimal
reference in social network under incomplete probabilistic linguistic
circumstance. <em>ISCI</em>, <em>661</em>, 120123. (<a
href="https://doi.org/10.1016/j.ins.2024.120123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consensus plays a pivotal role in large-scale group decision-making, and the social network relationship significantly impacts the consensus reaching process (CRP). Consequently, there is considerable focus on achieving large-scale consensus within social network (LSC-SN). Typically, experts are used to expressing their evaluations with language that can be effectively characterized by probabilistic linguistic term set (PLTS). However, the existing distance measure of PLTS exhibits drawbacks, and PLTSs provided by experts might be incomplete. To address the two challenges, this research defines an improved distance measure and proposes an estimation method for incomplete PLTS from the perspectives of trust relationships, collaborative filtering, and confidence level. Subsequently, in the CRP, a hierarchical clustering algorithm based on the trust-similarity measure is developed to cluster experts who share mutual trust and similar evaluations. Then, a consensus model employing dynamic trust and optimal reference is introduced to achieve both intra-cluster and inter-cluster consensus simultaneously. Finally, to illustrate the feasibility and advantage of the proposed model, a numerical experiment and the comparative analyses are conducted.},
  archive      = {J_ISCI},
  author       = {Xiaoli Tian and Wenxiu Ma and Lunwen Wu and Mengying Xie and Gang Kou},
  doi          = {10.1016/j.ins.2024.120123},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120123},
  shortjournal = {Inf. Sci.},
  title        = {Large-scale consensus with dynamic trust and optimal reference in social network under incomplete probabilistic linguistic circumstance},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-organized swarm robot for multi-target trapping based
on self-regulated density interaction. <em>ISCI</em>, <em>661</em>,
120119. (<a href="https://doi.org/10.1016/j.ins.2024.120119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In swarm robotics , multi-target trapping usually relies on global information or explicit communication, posing a challenge for robots to autonomously self-organize and trap multiple targets with only local perceptual data . We present a self-regulated density-based approach for self-organized multi-target trapping. This method employs density-based negative feedback control and density-distance weighted target selection. Our approach leverages distributed perception, where robots perceive nearby peers within their sensory range, eliminating the need for explicit information exchange and enabling autonomous trapping. During task execution, negative feedback control adjusts swarm density, ensuring it reaches an optimal level. Building on this, individual robots use density fields and relative target positions to select suitable targets, achieving self-regulated dispersed selection and multi-target trapping. We validate our approach through numerical simulations and real-world robot experiments . Results demonstrate stable self-organization, efficient self-regulated dispersed target selection, and successful target trapping, even with a limited number of trapping robots in low-redundancy scenarios.},
  archive      = {J_ISCI},
  author       = {Yuchen Zhou and Yuan Tao and Xiaokang Lei and Xingguang Peng},
  doi          = {10.1016/j.ins.2024.120119},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120119},
  shortjournal = {Inf. Sci.},
  title        = {Self-organized swarm robot for multi-target trapping based on self-regulated density interaction},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid sampling method for highly imbalanced and
overlapped data classification with complex distribution. <em>ISCI</em>,
<em>661</em>, 120117. (<a
href="https://doi.org/10.1016/j.ins.2024.120117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance and overlap coupling is the primary cause of performance degradation for classifiers . Unfortunately, it always occurs. In this paper, we propose a hybrid sampling method derived from optimized generative adversarial network and natural neighbor search (HD-GNNS) for this scenario. The new approach considers both the global distribution and local distribution of the minority class to improve the data distribution fundamentally. First, natural neighbor search with Fisher’s discriminant ratio is conducted to screen overlapped sample subset and remove noise samples. It effectively overcomes the parameter sensitivity by adaptively determining the search radius. Then, an encoder with squeeze and excite block is introduced into generative adversarial network, and the structure of generative adversarial network is optimized with cross-layer and low-rank matrix. It better captures the distribution characteristics of minority samples in overlapped subset for oversampling. Afterwards, the local density of majority samples in overlapped subset is calculated by the aforementioned natural neighbor search method, and Thornton’s Separation Index is used to implement under-sampling adaptively. We evaluate the proposed approach on 1 artificial dataset, 14 UCI datasets and 8 real-word datasets. The experimental results show that the proposed HD-GNNS exhibits more impressive performance compared to other benchmark methods.},
  archive      = {J_ISCI},
  author       = {Yansong Liu and Li Zhu and Lei Ding and He Sui and Wenli Shang},
  doi          = {10.1016/j.ins.2024.120117},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120117},
  shortjournal = {Inf. Sci.},
  title        = {A hybrid sampling method for highly imbalanced and overlapped data classification with complex distribution},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Progressive neural network for multi-horizon time series
forecasting. <em>ISCI</em>, <em>661</em>, 120112. (<a
href="https://doi.org/10.1016/j.ins.2024.120112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce ProNet , an novel deep learning approach designed for multi-horizon time series forecasting, adaptively blending autoregressive (AR) and non-autoregressive (NAR) strategies. Our method involves dividing the forecasting horizon into segments, predicting the most crucial steps in each segment non-autoregressively, and the remaining steps autoregressively. The segmentation process relies on latent variables, which effectively capture the significance of individual time steps through variational inference. In comparison to AR models , ProNet showcases remarkable advantages, requiring fewer AR iterations, resulting in faster prediction speed, and mitigating error accumulation. On the other hand, when compared to NAR models, ProNet takes into account the interdependency of predictions in the output space, leading to improved forecasting accuracy . Our comprehensive evaluation, encompassing four large datasets, and an ablation study, demonstrate the effectiveness of ProNet, highlighting its superior performance in terms of accuracy and prediction speed, outperforming state-of-the-art AR and NAR forecasting models .},
  archive      = {J_ISCI},
  author       = {Yang Lin},
  doi          = {10.1016/j.ins.2024.120112},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120112},
  shortjournal = {Inf. Sci.},
  title        = {Progressive neural network for multi-horizon time series forecasting},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Embedding model of multilayer networks structure and its
application to identify influential nodes. <em>ISCI</em>, <em>661</em>,
120111. (<a href="https://doi.org/10.1016/j.ins.2024.120111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, there are many indexes used to quantify the structure of single layer complex networks, but multilayer networks are affected by the number of layers, which are difficult to represent the structure and complicated to calculate. In this paper, we propose a network embedding method to represent the structure information of multilayer networks, which reduces the computational complexity . After the structure of the multilayer networks is expressed, the key nodes in the network are mined to help control the spread of the epidemic, suppress the spread of rumors, and optimize the structure of the network. However, it is difficult to quantify this problem precisely because of the difference of judgment indexes. On the basis of representing the structure of multilayer networks, we propose a fuzzy Tsallis eXtropy (FTE) method for quantifying influential nodes in multilayer networks by combining fuzzy theory and entropy. In addition, FTE is tested by some practical networks and compared with other methods. The results reveal that the proposed method is effective.},
  archive      = {J_ISCI},
  author       = {Mingli Lei and Kang Hao Cheong},
  doi          = {10.1016/j.ins.2024.120111},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120111},
  shortjournal = {Inf. Sci.},
  title        = {Embedding model of multilayer networks structure and its application to identify influential nodes},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An integrated complex t-spherical fuzzy set and soft set
model for quantum computing and energy resource planning. <em>ISCI</em>,
<em>661</em>, 120101. (<a
href="https://doi.org/10.1016/j.ins.2024.120101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the Complex T-Spherical Fuzzy Soft Set (CTSFSS), a novel and practical model for representing two-dimensional ambiguous information. This is achieved by integrating the Complex T-Spherical Fuzzy Set (CTSFS) with the Soft Set (SS). The development of the CTSFSS theory is motivated by the absence of neutral membership in complex q-rung orthopair fuzzy soft sets and the limitations of Traditional Spherical Fuzzy Soft Sets (TSFSS) in capturing two-dimensional data. Data storage and processing in the modern technological landscape necessitate sophisticated algorithmic computations and robust representation of information. To this end, computational systems predominantly rely on a binary system structured on two fundamental states: 0 (off) and 1 (on). Moreover, the significance of energy resources and computer-aided tools is underscored in this domain, especially considering the potential impact of quantum computing and advances in energy resources on the evolution of digital technology. In addressing these complexities, we propose Complex T-Spherical Fuzzy Soft Relations (CTSFSRs), formulated through the Cartesian product of two CTSFSSs. These relations are adept at handling complex and uncertain data in real-world scenarios. We define and categorize various types of CTSFSRs, followed by an in-depth analysis of their outcomes. Additionally, this paper introduces innovative visualization techniques based on CTSFSRs, tailored for decision-making processes involving energy resources and quantum computing applications. The efficacy and applicability of these proposed methodologies are substantiated through comparative analysis with existing models.},
  archive      = {J_ISCI},
  author       = {Naeem Jan and Jeonghwan Gwak and Dragan Pamucar and Hyoungku Kang},
  doi          = {10.1016/j.ins.2024.120101},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120101},
  shortjournal = {Inf. Sci.},
  title        = {An integrated complex T-spherical fuzzy set and soft set model for quantum computing and energy resource planning},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient and effective (k,p)-core-based community search
over attributed heterogeneous information networks. <em>ISCI</em>,
<em>661</em>, 120076. (<a
href="https://doi.org/10.1016/j.ins.2023.120076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a heterogeneous information network (HIN) G and a query node q , community search (CS) over an HIN identifies a cohesive subgraph from G that contains q . Although HINs with attributes on nodes (called AHINs) are prevalent today, the CS over AHINs (CS-AHIN) is ignored in the literature. Though we can convert an AHIN to an attributed homogeneous graph given a meta-path, then apply the CS approaches for attributed homogeneous graphs to solve CS-AHIN, it is problematic for two reasons. (1) Complete graph conversion is time-consuming and unnecessary, because the search only involves the query node&#39;s neighborhood, not the entire graph. (2) Existing attribute cohesiveness metrics are not strict enough to reflect substantial similarities among the community&#39;s pairwise nodes. To resolve this, we define the CS-AHIN problem atop a strict attribute cohesiveness metric that supports textual and numerical attributes simultaneously. We show the problem is NP-hard. To address it, we propose an exact baseline to return the global optimal result. Then, we propose three heuristic algorithms using a general greedy search framework to speed up the efficiency. Moreover, we present a cohesiveness-aware proximity graph-based index to boost the performance. Comprehensive experimental studies on various real-world datasets demonstrate our method&#39;s superiority.},
  archive      = {J_ISCI},
  author       = {Yuxiang Wang and Chengjie Gu and Xiaoliang Xu and Xinjun Zeng and Xiangyu Ke and Tianxing Wu},
  doi          = {10.1016/j.ins.2023.120076},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120076},
  shortjournal = {Inf. Sci.},
  title        = {Efficient and effective (k,P)-core-based community search over attributed heterogeneous information networks},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SimRE: Simple contrastive learning with soft logical rule
for knowledge graph embedding. <em>ISCI</em>, <em>661</em>, 120069. (<a
href="https://doi.org/10.1016/j.ins.2023.120069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs serve as a pivotal framework for the structured representation of information regarding entities and relations. However, in the real world, these knowledge graphs are often incomplete and harboring missing facts. Knowledge graph completion (KGC) has emerged as a central research focus, entailing the automated prediction of these missing facts and garnering substantial scholarly attention in recent years. Text-based knowledge graph embedding methods have demonstrated considerable potential for tackling the challenges associated with KGC by employing pre-trained language models . However, their limitation lies in the lack of logical features, which constrains the efficacy of capturing intricate patterns within knowledge graphs. This paper proposed SimRE, a straightforward contrastive learning framework augmented with soft logic rules. SimRE introduces a self-supervised framework that leverages the input rule bodies to predict the corresponding rule heads through a contrastive objective. We introduced two rule sampling techniques to enhance the efficiency and accuracy of the model: in-batch rule negatives and pre-batch rule negatives. SimRE employs a simple method for integrating logical features with the text-based model. The experimental results on benchmark datasets demonstrate that the proposed approach outperforms state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Dong Zhang and Zhe Rong and Chengyuan Xue and Guanyu Li},
  doi          = {10.1016/j.ins.2023.120069},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120069},
  shortjournal = {Inf. Sci.},
  title        = {SimRE: Simple contrastive learning with soft logical rule for knowledge graph embedding},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel parameter-free and parametric same degree
distribution-based dimensionality reduction algorithms for trustworthy
data structure preserving. <em>ISCI</em>, <em>661</em>, 120030. (<a
href="https://doi.org/10.1016/j.ins.2023.120030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective dimensionality reduction method, Same Degree Distribution (SDD) has been demonstrated to be able to maintain better data structure than other dimensionality reduction methods, including Principal Component Analysis (PCA), Multidimensional Scaling (MDS), Isomap, Locally Linear Embedding (LLE), Laplacian Eigen-maps (LE), Uniform Manifold Approximation and Projection (UMAP) and t -Stochastic Neighbour Embedding ( t -SNE). In addition, SDD does not require tuning the number of neighbours or perplexity to scale the structure capturing performance. Instead, it requires tuning the degree of degree-distribution ranging in e certain interval. Hence, tuning the degree of degree-distribution makes SDD a less costly method than other methods that require tuning the number of neighbours or perplexity. Although these advantages, SDD is still an expensive method compared with parameter-free methods such as PCA and MDS. A parameter-free SDD is proposed based on standard SDD, with two main differences : 1) it does not require tuning the degree of degree-distribution in the entire range from 1 to 15, but only uses degree 1; and 2) it re-scales the pairwise distances in the range [0, 2] instead of range [0, 1]. A theoretical analysis is presented to prove the better performance of parameter-free SDD. In addition, the performances of the proposed parameter-free SDD and the standard SDD have been experimentally compared in terms of structure capturing and computational time . This paper also proposes a parametric version of SDD using a deep neural network approach to learn the mapping based on the samples of the original data and their corresponding embedded representations in a low dimensional space. Comparative experiments have been undertaken with SDD and other methods such as Isomap, t -SNE and UMAP to demonstrate the effectiveness of the proposed parametric SDD with several popular synthetic and real datasets such as Churn, SEER Breast Cancer, AVletters (LIPS Reading) and MNIST.},
  archive      = {J_ISCI},
  author       = {Laureta Hajderanj and Daqing Chen and Sandra Dudley and Guillaume Gilloppe and Baptiste Sivy},
  doi          = {10.1016/j.ins.2023.120030},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120030},
  shortjournal = {Inf. Sci.},
  title        = {Novel parameter-free and parametric same degree distribution-based dimensionality reduction algorithms for trustworthy data structure preserving},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive fixed-time consensus control of nonlinear
multiagent systems with dead-zone output. <em>ISCI</em>, <em>661</em>,
119998. (<a href="https://doi.org/10.1016/j.ins.2023.119998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a fixed-time leader-follower consensus tracking control scheme for uncertain multiagent systems with unknown dead-zone output. First, a novel approximate dead-zone model was introduced to accurately represent the dead-zone phenomenon in the output channel of nonlinear multiagent systems. Furthermore, the model presented is a smooth function, which greatly simplifies the process of fusing it with the backstepping technique. Second, we present a Nussbaum function to compensate for the uncertain gain from the output dead-zone nonlinearity . Third, unlike previous works, we first consider practical fixed-time consensus issues for multiagent systems with output dead-zone. Finally, according to the fixed-time control theory , the tracking error of the multiagent systems converges to the region around zero within a fixed time, which is confirmed by the simulations.},
  archive      = {J_ISCI},
  author       = {Wenjun Peng and Licheng Zheng and C.L. Philip Chen and Zongze Wu and Zhi Liu},
  doi          = {10.1016/j.ins.2023.119998},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {119998},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fixed-time consensus control of nonlinear multiagent systems with dead-zone output},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An interpretable image classification model combining a
fuzzy neural network with a variational autoencoder inspired by the
human brain. <em>ISCI</em>, <em>661</em>, 119885. (<a
href="https://doi.org/10.1016/j.ins.2023.119885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy neural networks (FNNs) have gained attention for their interpretability and self-learning ability. However, they struggle with interpreting high-dimensional unstructured data and the problem of “rule explosion”. To address this, a model called VAE-FNN is proposed, which combines a FNN with a variational autoencoder (VAE). The VAE-FNN simulates the image perception, feature extraction, inductive reasoning , and adjustment learning processes in the human brain. An encoder is used to simulate the visual cortex for extracting features from complex images, reducing the dimensionality, and mitigating the rule explosion problem. The fuzzy neural network classifier (FNNC) simulates the reasoning functions of the parietal and prefrontal cortex in the human brain and achieves interpretable classification based on the encoder’s output features. A training algorithm is designed to improve the stability of the FNNC. The VAE-FNN’s training method adjusts the feature extraction process based on reconstruction and classification effects, enabling the model to obtain advanced and semantic classification features. Detailed experimental results on two image datasets demonstrate that the proposed model can extract high-level classification features and provide explanations consistent with human intuition while achieving high-precision classification. The experimental results on the other two datasets further validate the effectiveness of the proposed model.},
  archive      = {J_ISCI},
  author       = {Ke Zhang and Wenning Hao and Xiaohan Yu and Tianhao Shao},
  doi          = {10.1016/j.ins.2023.119885},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {119885},
  shortjournal = {Inf. Sci.},
  title        = {An interpretable image classification model combining a fuzzy neural network with a variational autoencoder inspired by the human brain},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive fixed-time inverse optimal consensus of multi-agent
systems with limited-time interval state constraints. <em>ISCI</em>,
<em>661</em>, 119884. (<a
href="https://doi.org/10.1016/j.ins.2023.119884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a study on fixed-time adaptive fuzzy inverse optimal consensus for multi-agent systems (MASs) subject to limited-time interval state constraints . To handle the constraints that occur within a limited-time interval during the system&#39;s operating cycle, we introduce a shifting function to shift the boundary and a state-dependent transformation function to transform the constrained MASs into non-constrained ones. We then propose an adaptive fixed-time inverse optimal consensus controller that achieves the convergence of consensus error within a fixed-time and inverse optimality without directly learning the solution of the Hamilton-Jacobi-Bellman (HJB) equations. To establish the criteria for fixed-time stabilization, we design an auxiliary controller instead of the auxiliary system and introduce two Lyapunov functions to prove the inverse optimality and fixed-time stabilization. The developed consensus scheme ensures that the synchronization error asymptotically converges to a user-predefined region within a fixed settling time. We validate the effectiveness of the developed scheme through a simulation example.},
  archive      = {J_ISCI},
  author       = {Lei Yan and Zhi Liu and C.L. Philip Chen and Yun Zhang and Zongze Wu},
  doi          = {10.1016/j.ins.2023.119884},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {119884},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fixed-time inverse optimal consensus of multi-agent systems with limited-time interval state constraints},
  volume       = {661},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary multitasking for solving nonlinear equation
systems. <em>ISCI</em>, <em>660</em>, 120139. (<a
href="https://doi.org/10.1016/j.ins.2024.120139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few years, many evolutionary algorithms have been developed to find multiple roots of the nonlinear equation system (NES). However, they can only solve one NES in a single run, ignoring the potentially useful information and solving experience derived from different NESs. To this end, an evolutionary multitasking NES optimization framework called MTNES, is proposed for the first time in this paper for solving multiple NESs simultaneously. Specifically, we first initialize multiple NES tasks in a 0-1 unified search space to establish an implicit relationship between NESs to facilitate knowledge transfer. Then, combining differential evolution and neighborhood technique, a neighborhood knowledge transfer is presented to reduce negative knowledge transfer and thus help find more roots. In addition, a novel resource reallocation mechanism is developed to release the found roots, thereby improving population diversity as well as aiding the search for more promising areas. Numerous empirical results reveal that the proposed approach can achieve a higher root rate and success rate when compared with several well-established algorithms on eighteen complex NESs. Moreover, experimental results on two real-world applications further show the potential practicability of the proposed multitasking NES-solving framework.},
  archive      = {J_ISCI},
  author       = {Shuijia Li and Wenyin Gong and Ray Lim and Zuowen Liao and Qiong Gu},
  doi          = {10.1016/j.ins.2024.120139},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120139},
  shortjournal = {Inf. Sci.},
  title        = {Evolutionary multitasking for solving nonlinear equation systems},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive key-frame selection-based facial expression
recognition via multi-cue dynamic features hybrid fusion. <em>ISCI</em>,
<em>660</em>, 120138. (<a
href="https://doi.org/10.1016/j.ins.2024.120138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-cue dynamic features hybrid fusion (MDF-HF) method for video-based facial expression recognition is presented. It is composed of key-frame selection, multi-cue dynamic feature extraction, and information fusion components. An adaptive key-frame selection strategy is first designed in the training procedure to extract pivotal facial images from video sequences, addressing the challenge of imbalanced data distribution and improving data quality . The similarity threshold used for key-frame selection is automatically adjusted based on the number of image frames in each expression category, creating a flexible frame processing procedure. Multi-cue spatio-temporal feature descriptors are then designed to acquire diverse dynamic feature representations from the selected key-frame sequences. With parallel computation, different levels of semantic information are extracted simultaneously to explore facial expression deformation in video clips. To integrate features from multiple cues, a weighted stacking ensemble strategy is devised, preserving unique feature characteristics while exploring interrelationships among the multi-cue features. The proposed method is evaluated on three benchmark datasets: eNTERFACE&#39;05, BAUM-1s, and AFEW, achieving average accuracies of 59.7%, 57.5%, and 54.7%, respectively. The MDF-HF method exhibits superior performance, compared to state-of-the-art methods in facial expression recognition, offering a robust solution for recognizing facial expressions in dynamic and unconstrained video scenarios.},
  archive      = {J_ISCI},
  author       = {Bei Pan and Kaoru Hirota and Yaping Dai and Zhiyang Jia and Edwardo F. Fukushima and Jinhua She},
  doi          = {10.1016/j.ins.2024.120138},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120138},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive key-frame selection-based facial expression recognition via multi-cue dynamic features hybrid fusion},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Solution of the basic tolerant interval and fuzzy equation
using shifted membership function method with examples of applications.
<em>ISCI</em>, <em>660</em>, 120137. (<a
href="https://doi.org/10.1016/j.ins.2024.120137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article presents a new method of solving the basic tolerant interval and fuzzy equation called Shifted Membership Function (SMF) method. The method provides a deeper look into the geometric intricacies related to the inclusion of one membership function in another, and thus enables the exact solution of the basic tolerance equations, including those equations that could not be solved so far. The article presents several practical examples of the application of SMF-method which makes it easier to understand. The SMF-method is the starting point for finding other types of solutions (control solution, united solution) for basic equations, systems of linear fuzzy equations and non-linear equations with many uncertainties.},
  archive      = {J_ISCI},
  author       = {Andrzej Piegat and Marcin Pluciński},
  doi          = {10.1016/j.ins.2024.120137},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120137},
  shortjournal = {Inf. Sci.},
  title        = {Solution of the basic tolerant interval and fuzzy equation using shifted membership function method with examples of applications},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-LRA: Multi logical residual architecture for spiking
neural networks. <em>ISCI</em>, <em>660</em>, 120136. (<a
href="https://doi.org/10.1016/j.ins.2024.120136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, it has been noticed that certain current state-of-the-art (SOTA) spiking neural networks incorporated non-spike data by use of residual connections and count coding. However, these architectures may not be well-suited for the neuromorphic chips optimized primarily for processing binary inputs and floating-point weights. On the other hand, some pure-spike structures, such as SEW-AND and SEW-IAND, have been found to exhibit spike vanishing and limited capacity. To overcome these shortcomings, we analyze the energy consumption and expressive ability of binary and integer inputs on neuromorphic chips, and then propose a new Multi Logical Residual Architecture (Multi-LRA) , which eliminates non-spike computation on neuromorphic chips and addresses the issues of spike vanishing and limited capacity in SEW-AND and SEW-IAND. Furthermore, we prove that the upper bound of conditional entropy of Multi-LRA is higher than that of SEW-AND and logical-OR, which means that Multi-LRA has better capacity and may avoid the spike vanishing. Finally, experiments on CIFAR-10 have shown that Multi-LRA can significantly reduce energy consumption because of its pure-spike computation and logical operation, where Multi-LRA-ResNet50 can reach the SOTA accuracy 96.27% in just 4 time steps. In addition, the effectiveness of Multi-LRA has been validated on ImageNet, CIFAR10-DVS and DVS128 Gesture.},
  archive      = {J_ISCI},
  author       = {Hangchi Shen and Huamin Wang and Yuqi Ma and Long Li and Shukai Duan and Shiping Wen},
  doi          = {10.1016/j.ins.2024.120136},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120136},
  shortjournal = {Inf. Sci.},
  title        = {Multi-LRA: Multi logical residual architecture for spiking neural networks},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Information bottleneck based knowledge selection for
commonsense reasoning. <em>ISCI</em>, <em>660</em>, 120134. (<a
href="https://doi.org/10.1016/j.ins.2024.120134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {KG-augmented models usually endow existing models with external knowledge graphs, which achieve promising performance in various knowledge-intensive tasks, such as commonsense reasoning. Existing methods mainly first exploited heuristic ways for retrieving the relevant knowledge subgraphs according to the input, and then utilized some effective encoders, such as GNNs , to encode the symbolic knowledge into the neural reasoning networks. However, whether the whole retrieved knowledge subgraphs are really relevant or useful for the reasoning process was seldom considered. Actually, according to our observations and analysis, most retrieved knowledge is noisy and useless to the reasoning models, which would hurt the final performance. To remedy this, this paper proposes information bottleneck based knowledge selection ( IBKS ), which is able to select useful knowledge from the retrieved knowledge subgraph. Expectedly, the selected knowledge could better improve the commonsense reasoning ability of the model. Moreover, IBKS is model-agnostic and could be plugged into any existing KG-augmented model. Extensive experimental results show that IBKS could effectively improve commonsense reasoning performance.},
  archive      = {J_ISCI},
  author       = {Zhao Yang and Yuanzhe Zhang and Pengfei Cao and Cao Liu and Jiansong Chen and Jun Zhao and Kang Liu},
  doi          = {10.1016/j.ins.2024.120134},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120134},
  shortjournal = {Inf. Sci.},
  title        = {Information bottleneck based knowledge selection for commonsense reasoning},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A data-knowledge-driven interval type-2 fuzzy neural network
with interpretability and self-adaptive structure. <em>ISCI</em>,
<em>660</em>, 120133. (<a
href="https://doi.org/10.1016/j.ins.2024.120133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval type-2 fuzzy neural networks (IT2FNNs) have gained sustainable attention and wide applications because of their power of adaptive fuzzy modeling . Although the existing models accurately simulate the relationships between inputs and outputs by various adaptive learning algorithms, the parameters and fuzzy rules characterizing the model behaviors no longer have explicit interpretations. To achieve good interpretability and generalization performance , this paper proposes a novel data-knowledge-driven IT2FNN (DKIT2FNN). Unlike accuracy-oriented model fitting, DKIT2FNN pioneers the use of famous association rule mining techniques to automatically explore the interpretable rule knowledge, which intuitively presents conditional relation patterns among features. Using the obtained knowledge, the DKIT2FNN model is accomplished in a single-hidden layer network framework, in which the antecedent structure of each fuzzy rule is determined by the relation patterns provided by rule knowledge. In addition, an adversarial incremental learning algorithm is proposed for the self-organizing modeling of DKIT2FNN. Besides automatically assembling a compact rule base , it integrates the label adversarial training to reinforce the model&#39;s capability against label noise. We validate the DKIT2FNN on classification benchmark datasets with label noise and compare it with state-of-the-art non-fuzzy and neuro-fuzzy methods. The results demonstrate that the proposed DKIT2FNN achieves robust classification performance and good interpretability .},
  archive      = {J_ISCI},
  author       = {Kaiyuan Bai and Wenyu Zhang and Shiping Wen and Chaoyue Zhao and Weiye Meng and Yu Zeng and Dan Jia},
  doi          = {10.1016/j.ins.2024.120133},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120133},
  shortjournal = {Inf. Sci.},
  title        = {A data-knowledge-driven interval type-2 fuzzy neural network with interpretability and self-adaptive structure},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). L-net: A lightweight convolutional neural network for
devices with low computing power. <em>ISCI</em>, <em>660</em>, 120131.
(<a href="https://doi.org/10.1016/j.ins.2024.120131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) has demonstrated exceptional success across various domains, including computer vision , natural language processing , and speech recognition. However, the training and inference processes of DL models typically require substantial computational resources and storage space, presenting a significant challenge within the Internet of Things (IoT) domain. This study contributes theoretically to the field of lightweight DL by proposing L-Net, a lightweight convolutional neural network designed specifically for low-compute devices. The L-Net addresses challenges associated with channel interaction disparities and vanishing gradients. To further improve the network performance, we introduce the residual enhanced channel attention (or R-ECA) module, which combines a bypass mechanism derived from simplified residual learning with the attention mechanism&#39;s cross-channel interaction. Additionally, we replace the rectified linear unit function (or ReLU) with an exponential linear unit (or ELU) function to enhance the network&#39;s nonlinear expression capability and training speed. We conducted object recognition experiments and compared the accuracy and prediction stability of L-Net with well-known models, such as AlexNet, VGG11, SqueezeNet, ResNet , and MobileNet, to assess its efficacy. Using the CIFAR-10 dataset and our custom dataset of apple tree leaf diseases, our experimental results demonstrate that, with relatively smaller model parameters, L-Net performs exceptionally well in terms of mean Average Precision ( mAP ), achieving 0.906. Furthermore, when applied to our custom dataset, L-Net exhibits relatively consistent performance across various dataset splits under different ratios, outperforming the majority of models.},
  archive      = {J_ISCI},
  author       = {Hua Shen and Zhiwei Wang and Jixin Zhang and Mingwu Zhang},
  doi          = {10.1016/j.ins.2024.120131},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120131},
  shortjournal = {Inf. Sci.},
  title        = {L-net: A lightweight convolutional neural network for devices with low computing power},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ICGNet: An intensity-controllable generation network based
on covering learning for face attribute synthesis. <em>ISCI</em>,
<em>660</em>, 120130. (<a
href="https://doi.org/10.1016/j.ins.2024.120130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face-attribute synthesis is a typical application of neural network technology. However, most current methods suffer from the problem of uncontrollable attribute intensity. In this study, we proposed a novel intensity-controllable generation network (ICGNet) based on covering learning for face attribute synthesis. Specifically, it includes an encoder module based on the principle of homology continuity between homologous samples to map different facial images onto the face feature space , which constructs sufficient and effective representation vectors by extracting the input information from different condition spaces. It then models the relationships between attribute instances and representational vectors in space to ensure accurate synthesis of the target attribute and complete preservation of the irrelevant region. Finally, the progressive changes in the facial attributes by applying different intensity constraints to the representation vectors. ICGNet achieves intensity-controllable face editing compared to other methods by extracting sufficient and effective representation features, exploring and transferring attribute relationships, and maintaining identity information . The source code is available at https://github.com/kllaodong/-ICGNet .},
  archive      = {J_ISCI},
  author       = {Xin Ning and Feng He and Xiaoli Dong and Weijun Li and Fayadh Alenezi and Prayag Tiwari},
  doi          = {10.1016/j.ins.2024.120130},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120130},
  shortjournal = {Inf. Sci.},
  title        = {ICGNet: An intensity-controllable generation network based on covering learning for face attribute synthesis},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Μ-stability and instability of multiple equilibrium points
in delayed neural networks with general discontinuous activation
functions. <em>ISCI</em>, <em>660</em>, 120129. (<a
href="https://doi.org/10.1016/j.ins.2024.120129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a general type of discontinuous activation functions (AFs) and studies the μ -stability of multiple equilibrium points (EPs) in delayed neural networks (DNNs). By judging 4 n algebraic inequalities and the nonsingularity of an M -matrix, DNNs with the general discontinuous AFs can be shown to have 5 n 5n EPs, therein 3 n 3n EPs are locally μ -stable. Moreover, these 3 n 3n EPs are located at the points of continuity of the AF. Compared with the existing general continuous AF, DNNs with the general discontinuous AF can have more total/stable EPs. Hence, DNNs with the general discontinuous AF could store a much larger number of memory patterns if they are applied to associative memory . In addition, the attraction basin (AB) of each stable EP in DNNs is estimated. Two numerical examples are shown to testify the validity of the obtained results.},
  archive      = {J_ISCI},
  author       = {Yang Liu and Zhen Wang and Min Xiao},
  doi          = {10.1016/j.ins.2024.120129},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120129},
  shortjournal = {Inf. Sci.},
  title        = {μ-stability and instability of multiple equilibrium points in delayed neural networks with general discontinuous activation functions},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trajectory modeling via random utility inverse reinforcement
learning. <em>ISCI</em>, <em>660</em>, 120128. (<a
href="https://doi.org/10.1016/j.ins.2024.120128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of modeling trajectories of drivers in a road network from the perspective of inverse reinforcement learning . Cars are detected by sensors placed on sparsely distributed points on the street network of a city. As rational agents, drivers are trying to maximize some reward function unknown to an external observer. We apply the concept of random utility from econometrics to model the unknown reward function as a function of observed and unobserved features. In contrast to current inverse reinforcement learning approaches , we do not assume that agents act according to a stochastic policy ; rather, we assume that agents act according to a deterministic optimal policy and show that randomness in data arises because the exact rewards are not fully observed by an external observer. We introduce the concept of extended state to cope with unobserved features and develop a Markov decision process formulation of drivers decisions. We present theoretical results which guarantee the existence of solutions and show that maximum entropy inverse reinforcement learning is a particular case of our approach. Finally, we illustrate Bayesian inference on model parameters through a case study with real trajectory data from a large city in Brazil.},
  archive      = {J_ISCI},
  author       = {Anselmo R. Pitombeira-Neto and Helano P. Santos and Ticiana L. Coelho da Silva and José Antonio F. de Macedo},
  doi          = {10.1016/j.ins.2024.120128},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120128},
  shortjournal = {Inf. Sci.},
  title        = {Trajectory modeling via random utility inverse reinforcement learning},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Elasticity unleashed: Fine-grained cloud scaling through
distributed three-way decision fusion with multi-head attention.
<em>ISCI</em>, <em>660</em>, 120127. (<a
href="https://doi.org/10.1016/j.ins.2024.120127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of cloud computing , elastic resource scaling has emerged as a critical challenge. Cloud platforms must efficiently allocate resources to match dynamic workloads . This study addresses the key trade-off between responsiveness and prudence in scaling a novel distributed three-way decision fusion approach. Distributed three-way decisions of immediate, delayed, or no scaling are made at coarse and fine-time granularity levels. Subsequently, a multi-head attention mechanism intelligently fuses these decisions, weighing the relevance of the different granularities to synthesize an integrated scaling strategy. The reactiveness of sudden workload changes are balanced during fusion by considering long-term trends. Comprehensive experiments on real-world data demonstrated that the proposed fusion strategy substantially improves resource efficiency and adherence to service-level agreements compared to existing methods. Multi-head attention imparts autonomy in adapting to diverse operating conditions. The proposed principled methodology and attention-based decision aggregation hold significance for efficient, adaptive, and interpretable cloud scaling mechanisms .},
  archive      = {J_ISCI},
  author       = {Chunmao Jiang and Ying Duan},
  doi          = {10.1016/j.ins.2024.120127},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120127},
  shortjournal = {Inf. Sci.},
  title        = {Elasticity unleashed: Fine-grained cloud scaling through distributed three-way decision fusion with multi-head attention},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A preference group consensus method with three-way decisions
and regret theory under multi-scale information systems. <em>ISCI</em>,
<em>660</em>, 120126. (<a
href="https://doi.org/10.1016/j.ins.2024.120126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The foundation of intelligent computing and expert systems relies on the data processing conducted within the realm of multi-scale information systems (MSISs). Data processing within MSISs caters to diverse analytical needs, where the preference hierarchy among various factors plays a vital role in the consensus reaching process (CRP). Additionally, the three-way decisions (TWD) theory serves as an efficient tool, while regret theory (RT) quantifies decision-makers&#39; risk inclinations associated with various psychological behaviors. Thus, the paper aims to introduce an innovative approach known as the CRP-TWD-RT-MSIS method. The study draws inspiration from spatial geometry, incorporating concepts like points, lines, surfaces, and bodies to create MSISs. This process generates a matrix of fuzzy preference relations (FPRs) among distinct decision-makers through data preprocessing . In addition, the paper explores feedback mechanisms based on identification and directional rules, as well as those rooted in minimal adjustments or cost considerations. Simultaneously, it takes negotiation and discussion time into account, culminating in the development of a personalized adjustment optimization model that focuses on minimizing time costs. In the end, the method&#39;s effectiveness and superiority are validated through a case study and a comparative analysis of real data from the Chinese Weather and Meteorological Bureau&#39;s website.},
  archive      = {J_ISCI},
  author       = {Yibin Xiao and Jianming Zhan and Chao Zhang and Peide Liu},
  doi          = {10.1016/j.ins.2024.120126},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120126},
  shortjournal = {Inf. Sci.},
  title        = {A preference group consensus method with three-way decisions and regret theory under multi-scale information systems},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dynamic multi-objective evolutionary algorithm based on
genetic engineering and improved particle swarm prediction strategy.
<em>ISCI</em>, <em>660</em>, 120125. (<a
href="https://doi.org/10.1016/j.ins.2024.120125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary and particle swarm optimisation (PSO) algorithms are widely used to solve various optimisation problems . However, both methods have limitations when applied to dynamic multi-objective optimisation problems. Therefore, we propose a dynamic multi-objective evolutionary algorithm based on genetic engineering and improved particle swarm prediction. Genetic engineering encompasses gene sequencing and editing, whereas improved particle swarm prediction involves enhancing information utilisation and dynamic performance. The improved PSO can be better combined with dynamic multi-objective optimization problems (DMOPs) for predicting changing populations, which we call improved particle swarm prediction. Gene sequencing clarifies the functions of different genes during the evolution process, and gene editing enables the algorithm to effectively avoid local optima . Expanding on this foundation, we redefined the notions of particle and global bests in the PSO strategy to improve the information utilisation. Additionally, we innovatively introduced the concept of acceleration, which greatly enhances the dynamic performance of the PSO. Finally, we conducted two experiments to verify the accuracy of our gene sequencing strategy and the performance of our optimisation algorithm . The results indicate that gene sequencing can effectively classify genes, and the developed optimisation algorithm significantly outperforms similar, state-of-the-art, and classical algorithms in terms of distribution and dynamics on 25 test problems.},
  archive      = {J_ISCI},
  author       = {Yue Yang and Yongjie Ma and Yan Zhao and Wenping Zhang and Yu Wang},
  doi          = {10.1016/j.ins.2024.120125},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120125},
  shortjournal = {Inf. Sci.},
  title        = {A dynamic multi-objective evolutionary algorithm based on genetic engineering and improved particle swarm prediction strategy},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unifying view for the mixture model of sparse gaussian
processes. <em>ISCI</em>, <em>660</em>, 120124. (<a
href="https://doi.org/10.1016/j.ins.2024.120124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mixture of Gaussian processes (MGP) is generally accurate but slow in multimodal probabilistic regression. To reduce the computational burden of MGP, a mixture of sparse Gaussian processes (MSGP) with a fully independent training conditional (FITC) approximation was designed. However, MSGP with FITC is not always accurate. In this paper, we propose MSGP with a variational inference (VI) approximation to overcome this problem and establish a unifying view of MSGPs with FITC and VI based on their marginal likelihoods to explore the relationship between two MSGPs. Experiments on synthetic and real-world datasets show that MSGP with VI is more favorable than MSGP with FITC in certain behaviors, such as lower heteroscedasticity of noise, less clumping behavior of inducing inputs, more effective recovery of the full MGP and higher probabilistic regression accuracy at similar efficiency.},
  archive      = {J_ISCI},
  author       = {Yurong Xie and Di Wu and Zhe Qiang},
  doi          = {10.1016/j.ins.2024.120124},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120124},
  shortjournal = {Inf. Sci.},
  title        = {A unifying view for the mixture model of sparse gaussian processes},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust autoencoder feature selector for unsupervised feature
selection. <em>ISCI</em>, <em>660</em>, 120121. (<a
href="https://doi.org/10.1016/j.ins.2024.120121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Feature Selection (UFS) methods are known to produce models with excellent ability to select high-quality features. This advantage, however, is challenged when analyzing noisy real-world data, where anomalies are prevalent. For example, there may be a feature (anomalous feature) that is corrupted across many samples or a sample (anomalous sample) that has more corruptions than its peers. Previous literature focused on addressing anomalous samples, and methods that are robust to both types of anomalies have been under-explored. This paper proposes a novel general framework for reconstruction-based UFS methods, which can be embedded into the feature learning process to simultaneously remove anomalous samples and features. Specifically, the framework learns double binary weight vectors to assign 0 weights to samples or features with the highest reconstruction errors and 1 weights to the others when computing reconstruction errors. By discarding the 0-weighted samples and features when updating the model parameters, the anomalies in the data are excluded. This allows the model to focus more on learning from the clean part of the noisy data . Our proposed framework is then integrated with AutoEncoder Feature Selector (AEFS [10] ) to develop a new method, which jointly performs anomaly removal and feature selection. The experimental results demonstrate the effectiveness of the proposed framework. Particularly, processing both types of anomalies provides better robustness than processing only one type. Moreover, our proposed method outperforms several state-of-the-art methods on various real-world datasets.},
  archive      = {J_ISCI},
  author       = {Yunzhi Ling and Feiping Nie and Weizhong Yu and Yunhao Ling and Xuelong Li},
  doi          = {10.1016/j.ins.2024.120121},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120121},
  shortjournal = {Inf. Sci.},
  title        = {Robust autoencoder feature selector for unsupervised feature selection},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mean-based borda count for paradox-free comparisons of
optimization algorithms. <em>ISCI</em>, <em>660</em>, 120120. (<a
href="https://doi.org/10.1016/j.ins.2024.120120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical comparisons are essential for selecting an efficient optimization algorithm for specific problems arising from various human practices. Note that recent researches have shown that paradoxes may occur for comparisons of the numerical performance of optimization algorithms, particularly the cycle-ranking paradox. Paradox-free is still open for some popular data analysis methods based on hypothesis testing (HT), which motivates us to design a class of HT-based paradox-free data analysis methods. The numerical comparison of optimization algorithms is analyzed for dimensional reduction in a matrix. The data collected during the experiment is stored in a four-dimensional matrix, which is then reduced to three-dimensional, two-dimensional, and finally a one-dimensional ranking vector. Then a mean-based Borda count (MeanBordaCount/T) is proposed to eliminate the cycle-ranking paradox that arises from the HT-based data analysis methods where HTs are performed on each problem. Specifically, hypothesis testing is replaced primarily by mean comparison, which has been proven that the result of hypothesis testing is the same as the result based only on mean comparisons, except that the former contains more equal or tied results. The Borda count is adopted to eliminate cycle-ranking in the final dimensional reduction. Finally, MeanBordaCount/T is proved to be the best choice among all HT-type methods, at least in the sense that it can minimize the error of pairwise comparisons .},
  archive      = {J_ISCI},
  author       = {Qunfeng Liu and Yunpeng Jing and Yuan Yan and Yun Li},
  doi          = {10.1016/j.ins.2024.120120},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120120},
  shortjournal = {Inf. Sci.},
  title        = {Mean-based borda count for paradox-free comparisons of optimization algorithms},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized dissemblance index as a difference of first
moments of fuzzy numbers – a new perspective on the distance of fuzzy
numbers. <em>ISCI</em>, <em>660</em>, 120118. (<a
href="https://doi.org/10.1016/j.ins.2024.120118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the formulation of the dissemblance index as a basis for the calculation of distances of fuzzy numbers and explores its potential linkages with standard and possibilistic moments of fuzzy numbers. Applying the LSC transformation introduced recently by Luukka, Stoklasa and Collan we transform the general formulation of the dissemblance index into its “probabilistic” analogy and show that the result can be interpreted as a difference of COGs of the respective fuzzy numbers (potentially with hedges applied to them). We also show that the difference of possibilistic means is a special case of the general dissemblance index, when w = 1 w=1 . We also propose a generalized version of the possibilistic mean of a fuzzy number and prove its properties. We discuss the implications of this relationship on the practical use of the generalized dissemblance index and investigate its performance in the task of ranking of fuzzy numbers.},
  archive      = {J_ISCI},
  author       = {Jan Stoklasa and Pasi Luukka and Jana Stoklasová},
  doi          = {10.1016/j.ins.2024.120118},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120118},
  shortjournal = {Inf. Sci.},
  title        = {Generalized dissemblance index as a difference of first moments of fuzzy numbers – a new perspective on the distance of fuzzy numbers},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph model for conflict resolution based on the combination
of probabilistic uncertain linguistic and EDAS method. <em>ISCI</em>,
<em>660</em>, 120116. (<a
href="https://doi.org/10.1016/j.ins.2024.120116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ranking of decision makers (DMs)’ preferences for feasible states in the graph model for conflict resolution (GMCR) is crucial for accurately determining stability results. This paper addresses the issue of subjective ranking methods lacking theoretical foundation and causing ambiguity when the number of feasible states is high by proposing the implementation of the multi-attribute decision-making (MADM) method in the GMCR. The paper utilizes the average level to choose evaluation based on distance from average solution (EDAS) method for determining the DM’s preference ranking, which can effectively reduce the impact of anomalous evaluations. Further, the PUL-EDAS method based on probabilistic uncertainty linguistics (PUL) is developed, which overcomes the shortcomings of the traditional EDAS method, which only applies to the simple evaluation of information. The PUL aligns with DMs’ daily evaluation practice by providing an interval for the quality of qualitative linguistic evaluations. Furthermore, it utilizes an objective aggregation method to calculate comprehensive evaluation information from all DMs. In addition, the four fundamental stability definitions, applicable solely under crisp preferences, are extended to the PUL context, providing related extended definitions. Finally, to ensure the scientific validity and practicality of the proposed theory, this paper selects digital rural governance as the research context for conflict calculus analysis, comparing it with other MADM methods in the preference ranking section.},
  archive      = {J_ISCI},
  author       = {Peide Liu and Xue Wang and Yingxin Fu and Peng Wang},
  doi          = {10.1016/j.ins.2024.120116},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120116},
  shortjournal = {Inf. Sci.},
  title        = {Graph model for conflict resolution based on the combination of probabilistic uncertain linguistic and EDAS method},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Control laws synthesis to satisfy generalized mutual
exclusion constraints for timed event graphs networks using min-plus
algebra. <em>ISCI</em>, <em>660</em>, 120115. (<a
href="https://doi.org/10.1016/j.ins.2024.120115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper focuses on the Generalized Mutual Exclusion Constraints (GMECs) problem in the Network of Timed Event Graphs (NTEGs). A new formal method for state feedback control using Min-Plus algebra formalisms is proposed. For this purpose, the dynamic behavior of the NTEGs and GMECs are respectively described by linear equations and weighted inequalities in Min-Plus algebra. Based on these mathematical tools, control laws are computed to satisfy the constraints that are imposed on the NTEGs in case sufficient conditions are verified. The established controllers are represented by monitor places which supervise the system to ensure all GMECs. Finally, a case study of an AGV network is carried out to illustrate theoretical results and demonstrate the efficiency of developed approaches.},
  archive      = {J_ISCI},
  author       = {Jihene Rajah and Said Amari and Maher Barkallah and Mohamed Haddar},
  doi          = {10.1016/j.ins.2024.120115},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120115},
  shortjournal = {Inf. Sci.},
  title        = {Control laws synthesis to satisfy generalized mutual exclusion constraints for timed event graphs networks using min-plus algebra},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UP-DPC: Ultra-scalable parallel density peak clustering.
<em>ISCI</em>, <em>660</em>, 120114. (<a
href="https://doi.org/10.1016/j.ins.2024.120114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density Peak Clustering (DPC) is a highly effective density-based clustering algorithm , but its scalability is limited by the expensive Density Peak Estimation (DPE) step. To address this challenge, we propose UP-DPC: Ultra-Scalable Parallel Density Peak Clustering, a novel framework that employs approximate Density Peak Estimation and performs DPC on LDP-wise graphs. This approach enables UP-DPC to handle datasets of arbitrary scale without relying on spatial indexing for acceleration. Furthermore, we introduce a five-layer computational architecture and leverage parallel computation techniques to further enhance the speed and efficiency of UP-DPC. To evaluate the scalability and effectiveness of UP-DPC, we conduct extensive experiments on 14 datasets, including the large/web-scale datasets, and compare UP-DPC with 21 algorithms. Notably, on the MNIST8M dataset consisting of 8,000k data objects, UP-DPC achieves an NMI (Normalized Mutual Information) value of 0.6464 in just 35.41 seconds, outperforming the state-of-the-art GPU-based method, which only archives an NMI of 0.045 in 56.96 seconds. These results demonstrate the superior scalability and effectiveness of UP-DPC in handling large/web-scale datasets. The proposed framework offers significant improvements over existing methods and shows promise as a solution for density-based clustering tasks .},
  archive      = {J_ISCI},
  author       = {Luyao Ma and Geping Yang and Yiyang Yang and Xiang Chen and Juan Lu and Zhiguo Gong and Zhifeng Hao},
  doi          = {10.1016/j.ins.2024.120114},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120114},
  shortjournal = {Inf. Sci.},
  title        = {UP-DPC: Ultra-scalable parallel density peak clustering},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel one-bit dynamic quantizer for event-triggered
control systems. <em>ISCI</em>, <em>660</em>, 120113. (<a
href="https://doi.org/10.1016/j.ins.2024.120113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the problem of feedback stabilization of networked control linear systems with unknown initial state . In particular, the sampling and the quantization effects of network are considered and we propose a quantized event-triggered control technique to handle this case. To cope with unknown initial state, a novel exponential dynamic quantizer is synthesized, which enables to capture the state in a finite time . Moreover, the dynamic quantization policy only depends on the sign of the quantization error and allows for one-bit transmission rather than packet-based transmission, which is desirable in practice. Then, the quantized state measurements are transmitted to the controller using an event-triggering mechanism to reduce the amount of transmissions over the network. The approach ensures global asymptotic stability property for the closed-loop system and prevents the occurrence of Zeno behavior. The entire closed-loop system is represented as a hybrid dynamical system and the closed-loop stability is assessed using suitable Lyapunov functions . The effectiveness of the proposed approach is demonstrated through numerical simulations.},
  archive      = {J_ISCI},
  author       = {Dhafer Almakhles and Mahmoud Abdelrahim},
  doi          = {10.1016/j.ins.2024.120113},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120113},
  shortjournal = {Inf. Sci.},
  title        = {A novel one-bit dynamic quantizer for event-triggered control systems},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dimensional difference-based population size adjustment
framework for differential evolution. <em>ISCI</em>, <em>660</em>,
120110. (<a href="https://doi.org/10.1016/j.ins.2024.120110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problems of premature convergence and evolutionary stagnation faced by differential evolution (DE), a dimensional difference-based population size adjustment framework (DDPSA) is proposed in this work. The framework monitors the speed of convergence based on the dimensional difference between the parent and the offspring, to judge the problem faced by the current population. An adaptive mechanism of population size is designed at the population level to adjust the convergence speed and avoid the above two issues timely. Besides, For the two types of stagnant individuals caused by premature convergence and evolutionary stagnation, two replacement techniques based on the history and elite are proposed at the individual level, respectively, to assist them in restoring normal evolution, cooperating with the mechanism of population size adjustment. The DDPSA framework is introduced into ten DE algorithms and tested in the CEC 2014 and CEC 2017 benchmark suites, as well as four practical problems. The experimental results show that the DDPSA framework can effectively enhance the competitiveness of DEs, which is particularly obvious in some complex multimodal scenarios, achieving significant improvement in terms of DEs&#39; performance on 71.4% and 60.5% of multimodal functions in CEC 2014 and CEC 2017, respectively.},
  archive      = {J_ISCI},
  author       = {Yifan Qin and Libao Deng and Chunlei Li and Lili Zhang},
  doi          = {10.1016/j.ins.2024.120110},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120110},
  shortjournal = {Inf. Sci.},
  title        = {A dimensional difference-based population size adjustment framework for differential evolution},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Key grids based batch-incremental CLIQUE clustering
algorithm considering cluster structure changes. <em>ISCI</em>,
<em>660</em>, 120109. (<a
href="https://doi.org/10.1016/j.ins.2024.120109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the network environment, data from various industries is dynamic and large-scale. Traditional clustering algorithms struggle to effectively utilize existing clustering results when faced with continuously evolving data, which makes the incremental grid-based clustering highly regarded. However, the existing incremental grid-based clustering algorithms fail to adequately consider the impact of newly added data on the original cluster structure. To address this issue, the key grids based batch-incremental CLIQUE clustering algorithm is proposed. The algorithm designates the incremental data mapping grids, which are or their neighbour girds are mixed with original data, as key grids to fully consider the cluster structure changes caused by the incremental data. Moreover, the cluster similarity coefficient based on grid features is introduced to measure density differences between the incremental data and the original clusters, and the cluster membership degree is defined to further consider the cluster membership of boundary sparse grid data and the identification of noise points. All of which ensures that the algorithm can adaptively create, merge or split clusters with the arrival of new data. Experimental results show that the proposed algorithm can adaptively adjust the cluster structure during incremental clustering, outperforming in accuracy and efficiency when clustering large-scale, dynamically changing data.},
  archive      = {J_ISCI},
  author       = {Fumin Ma and Cheng Wang and Jian Huang and Qiuping Zhong and Tengfei Zhang},
  doi          = {10.1016/j.ins.2024.120109},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120109},
  shortjournal = {Inf. Sci.},
  title        = {Key grids based batch-incremental CLIQUE clustering algorithm considering cluster structure changes},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MSLR: A self-supervised representation learning method for
tabular data based on multi-scale ladder reconstruction. <em>ISCI</em>,
<em>660</em>, 120108. (<a
href="https://doi.org/10.1016/j.ins.2024.120108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tabular data are widely used for prediction tasks, but they often suffer from the curse of dimensionality and noise, leading to degradation in the performance and robustness of prediction models. Self-supervised representation learning has emerged as a promising technique to overcome these challenges, but most existing methods are applicable to images, text, and others rather than tabular data. In this study, we propose a novel self-supervised representation learning method for tabular data based on multi-scale ladder reconstruction (MSLR). The method effectively learns low-dimensional and noise-resistant representations, thereby improving the prediction performance across various tabular datasets. The idea of MSLR is to employ a binning method to generate a sequence of fuzzy data with different noise scales, followed by training a neural network to recover the raw data from the most corrupted data in a circular manner. This process allows MSLR to learn fine-grained changes caused by noise while maintaining consistency and similarity at a coarse granularity. The proposed method is evaluated on five real-world datasets, namely, MIMIC-IV, Thyroid, Heart, Pima, and Adult, and compared with several baselines. The experimental results of downstream prediction tasks show that MSLR is robust to noisy data and performs better than other existing baseline methods.},
  archive      = {J_ISCI},
  author       = {Xutao Weng and Hong Song and Yucong Lin and Xi Zhang and Bowen Liu and You Wu and Jian Yang},
  doi          = {10.1016/j.ins.2024.120108},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120108},
  shortjournal = {Inf. Sci.},
  title        = {MSLR: A self-supervised representation learning method for tabular data based on multi-scale ladder reconstruction},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid mix-up contrastive knowledge distillation.
<em>ISCI</em>, <em>660</em>, 120107. (<a
href="https://doi.org/10.1016/j.ins.2024.120107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) aims to build a lightweight deep neural network model under the guidance of a large-scale teacher model for model simplicity. Despite improved model efficiency through the KD technique, the performance gap between a teacher model and the trained student model remains significant. This is because the knowledge of the teacher model is not effectively transferred to the student model since the mapping landscape of the large-scale teacher model is not fully explored. To tackle this research gap, we propose a novel H ybrid M ix-up C ontrastive K nowledge D istillation (HMCKD) approach, which facilitates a thorough and reliable mapping solution space exploration in order to significantly improve the performance of the student model. Specifically, we design a hybrid mixing strategy, including image-level mixing and feature-level mixing, to form a smoother mapping landscape as a means to provide a stronger guidance in order to embed its richer dark knowledge from a teacher model to its student model. Additionally, we apply two other strategies, including contrastive learning and top-k guided selection, in order to ensure more effective knowledge transferability from the teacher model. Extensive experiments have proved that our proposed HMCKD approach outperforms state-of-the-art knowledge distillation methods when tested on 6 publicly available datasets, such as CIFAR-100, CIFAR-100-C, STL-10, SVHN, TinyImageNet, and ImageNet. Particularly on CIFAR-100 dataset, the average accuracy of students using HMCKD increased by 1.47%. Further, both the visualization results and similarity quantifications have confirmed the narrowed knowledge gap between the teacher and student models. Our source code is available at https://github.com/lambett/HMCKD .},
  archive      = {J_ISCI},
  author       = {Jian Zhang and Ze Tao and Kehua Guo and Haowei Li and Shichao Zhang},
  doi          = {10.1016/j.ins.2024.120107},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120107},
  shortjournal = {Inf. Sci.},
  title        = {Hybrid mix-up contrastive knowledge distillation},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards retraining-free RNA modification prediction with
incremental learning. <em>ISCI</em>, <em>660</em>, 120105. (<a
href="https://doi.org/10.1016/j.ins.2024.120105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RNA modifications are important for deciphering the function of cells and their regulatory mechanisms. In recent years, researchers have developed many deep learning methods to identify specific modifications. However, these methods require model retraining for each new RNA modification and cannot progressively identify the newly identified RNA modifications. To address this challenge, we propose an innovative incremental learning framework that incorporates multiple incremental learning methods. Our experimental results confirm the efficacy of incremental learning strategies in addressing the RNA modification challenge. By uniquely targeting 10 RNA modification types in a class incremental setting, our framework exhibits superior performance. Notably, it can be extended to new category methylation predictions without the need for retraining with previous data, improving computational efficiency. Through the accumulation of knowledge, the model is able to evolve and continuously learn the differences across methylation, mitigating the problem of catastrophic forgetting during deep learning model training. Overall, our framework provides various alternatives to enhance the prediction of novel RNA modifications and illuminates the potential of incremental learning in tacking numerous genome data.},
  archive      = {J_ISCI},
  author       = {Jianbo Qiao and Junru Jin and Haoqing Yu and Leyi Wei},
  doi          = {10.1016/j.ins.2024.120105},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120105},
  shortjournal = {Inf. Sci.},
  title        = {Towards retraining-free RNA modification prediction with incremental learning},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Collaborative resource allocation-based differential
evolution for solving numerical optimization problems. <em>ISCI</em>,
<em>660</em>, 120104. (<a
href="https://doi.org/10.1016/j.ins.2024.120104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) is an efficient and powerful population-based search algorithm for solving numerical optimization problems in continuous spaces. It has been proven that multi-strategy DE algorithms are more effective than single-strategy DE algorithms in addressing benchmark and real-world problems. However, most multi-strategy DE variants focus on maintaining population diversity and balancing exploitation and exploration, ignoring the dynamic allocation of computational resources . Moreover, the success of these algorithms often depends on additional designed techniques, leading to increased computational complexity . In this paper, the Collaborative Resource Allocation-based Differential Evolution (CRADE) is introduced. It involves a collaborative resource allocation mechanism that utilizes the historical performance ranking of three mutation strategies to automatically allocate computational resources to various subpopulations during the search process. The parameter adaptation technique is used to adjust the associated control parameters of different mutation strategies. As a result, the most efficient mutation strategy consumes the majority of computational resources at different search stages to mitigate inefficient search under constrained resources. The performance of CRADE is evaluated on the well-known CEC2013 benchmark function set. The paper also investigates its application in the parameter identification of photovoltaic solar cells and modules. The overall results show that CRADE exhibits superior and competitive performance compared to other state-of-the-art algorithms. Consequently, CRADE has emerged as a novel and effective approach for addressing numerical optimization problems , distinguished by its excellence, practicality, and unwavering reliability.},
  archive      = {J_ISCI},
  author       = {Yaxin Li and Jing Liang and Caitong Yue and Kunjie Yu and Xuanxuan Ban and Peng Chen},
  doi          = {10.1016/j.ins.2024.120104},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120104},
  shortjournal = {Inf. Sci.},
  title        = {Collaborative resource allocation-based differential evolution for solving numerical optimization problems},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-armed linear bandits with latent biases.
<em>ISCI</em>, <em>660</em>, 120103. (<a
href="https://doi.org/10.1016/j.ins.2024.120103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a linear stochastic bandit model, each arm corresponds to a vector in Euclidean space , and the expected return observed at each time step is determined by an unknown linear function of the selected arm. This paper addresses the challenge of identifying the optimal arm in a linear stochastic bandit model, where latent biases corrupt each arm&#39;s expected reward. Unlike traditional linear bandit problems, where the observed return directly represents the reward, this paper considers a scenario where the unbiased reward at each time step remains unobservable. This model is particularly relevant in situations where the observed return is influenced by latent biases that need to be carefully excluded from the learning model. For example, in recommendation systems designed to prevent racially discriminatory suggestions, it is crucial to ensure that the users&#39; race does not influence the system. However, the observed return, such as click-through rates, may have already been influenced by racial attributes. In the case where there are finitely many arms, we develop a strategy to achieve O ( | D | log ⁡ n ) O(|D|log⁡n) regret, where | D | |D| is the number of arms and n is the number of time steps. In the case where each arm is chosen from an infinite compact set , our strategy achieves O ( n 2 / 3 ( log ⁡ n ) 1 / 2 ) O(n2/3(log⁡n)1/2) regret. Experiments verify the efficiency of our strategy.},
  archive      = {J_ISCI},
  author       = {Qiyu Kang and Wee Peng Tay and Rui She and Sijie Wang and Xiaoqian Liu and Yuan-Rui Yang},
  doi          = {10.1016/j.ins.2024.120103},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120103},
  shortjournal = {Inf. Sci.},
  title        = {Multi-armed linear bandits with latent biases},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Controllable forward secure identity-based encryption with
equality test in privacy-preserving text similarity analysis.
<em>ISCI</em>, <em>660</em>, 120099. (<a
href="https://doi.org/10.1016/j.ins.2024.120099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text similarity measures have become increasingly pivotal in text-related research and applications, encompassing tasks such as information retrieval, text classification , document clustering . Unveiling the equality relationship between encrypted words is fundamental for ensuring privacy-preserving text similarity. Identity-based encryption with equality test (IBEET) emerges as a promising solution for computing similarity over encrypted data in cloud environment. However, prevalent IBEET schemes often lack control over the lifespan of trapdoors, potentially leading to misuse and unauthorized disclosure of users&#39; privacy. In this paper, we introduce a novel primitive known as controllable forward secure identity-based encryption with equality test (CFS-IBEET), designed to support both permanent trapdoor and temporary trapdoor. We present a concrete CFS-IBEET scheme based on bilinear pairing and conduct a comprehensive security analysis against two types of adversaries in random oracle model . The comprehensive performance evaluation shows that our CFS-IBEET scheme offers significant advantages of high efficiency of encryption, decryption, trapdoor generation and test algorithms as well as the guarantee of controllable forward security, showcasing its applicability for collaborative filtering recommendation system in E-commerce age.},
  archive      = {J_ISCI},
  author       = {Sha Ma and Zhiqing Ye and Qiong Huang and Chengyu Jiang},
  doi          = {10.1016/j.ins.2024.120099},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120099},
  shortjournal = {Inf. Sci.},
  title        = {Controllable forward secure identity-based encryption with equality test in privacy-preserving text similarity analysis},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Deep graph tensor learning for temporal link prediction.
<em>ISCI</em>, <em>660</em>, 120085. (<a
href="https://doi.org/10.1016/j.ins.2023.120085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge discovery on dynamic graphs has received much attention in recent years. As a key task of dynamic graph research, the goal of temporal link prediction is to accurately predict the time-varying links in dynamic networks. Uncertainty in link emergence is a major challenge in this research, as it is not easy to learn stable and reliable link-level feature representations, which are usually readily available on static graphs. In order to adapt to the ever-changing graph structure, this paper proposes to construct a deep graph tensor learning model, which can capture the contextual characteristics of graph evolution from both the graph structure (spatial) mode and the link sequence (temporal) mode. Therefore, compared to link prediction on static graphs, temporal link prediction can benefit more from the link-level embedding representations coupled with spatio-temporal features. The experimental results on seven public dynamic graph datasets show that the prediction accuracy obtained by the new model is overall better than competing models such as GC-LSTM, EvolveGCN, and HTGN. In the meantime, as a result of getting rid of the traditional RNN learning paradigm, the new model is also significantly better than the traditional temporal graph learning model in terms of training efficiency.},
  archive      = {J_ISCI},
  author       = {Zhen Liu and Zhongyi Li and Wen Li and Lixin Duan},
  doi          = {10.1016/j.ins.2023.120085},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120085},
  shortjournal = {Inf. Sci.},
  title        = {Deep graph tensor learning for temporal link prediction},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A lattice-based forward secure IBE scheme for internet of
things. <em>ISCI</em>, <em>660</em>, 120083. (<a
href="https://doi.org/10.1016/j.ins.2023.120083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is gaining popularity as it can effectively connect the real world with the Internet. However, security and privacy issues are widely considered the major obstructions to its widespread adoption. Hence, various cryptographic tools (e.g., encryption and signature schemes) have been proposed to build secure and authenticated channels for data communication in IoT. In this work, we investigate the well-known encryption scheme called identity-based encryption (IBE) for IoT-oriented applications. In particular, we are mainly interested in forward-secure IBE (fs-IBE) which could still protect the data transferred in the past when the current secret key stored in the IoT device is stolen. To this end, we propose an fs-IBE scheme which, as far as we know, is the first construction of fs-IBE that can resist quantum attacks. Our scheme is based on the lattice-based hardness assumption namely Learning with Error (LWE), which is widely adopted for designing other quantum-resistant cryptographic schemes. At the core of our design is the minimal cover mechanism in the context of binary tree and we rigorously prove the security of our scheme in the forward-secure, selective ID, chosen-plaintext attack (CPA) model. Besides the post-quantum security, our scheme enjoys comparatively compact ciphertext and secret key, and thus it is suitable for bandwidth-limited IoT communication.},
  archive      = {J_ISCI},
  author       = {Renjie Jin and Longjiang Qu and Rongmao Chen and Zhichao Yang and Yi Wang},
  doi          = {10.1016/j.ins.2023.120083},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120083},
  shortjournal = {Inf. Sci.},
  title        = {A lattice-based forward secure IBE scheme for internet of things},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An enhanced equilibrium optimizer for solving complex
optimization problems. <em>ISCI</em>, <em>660</em>, 120077. (<a
href="https://doi.org/10.1016/j.ins.2023.120077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Equilibrium Optimizer (EO), despite its acceptable performance in several complex problems, suffers from low exploitation ability with unbalanced exploration, stagnation in local optima and poor convergence rate. To enhance the performance of the EO, the authors infused the intelligence of quasi-opposite numbers and chaotic-maps into the EO and proposed a Quasi-Oppositional Chaotic Equilibrium Optimizer (QOCEO) that consists of Quasi-Opposition based learning for improving the scalability, Chaotic Time Parameter for ensuring a proper balance between exploration and exploitation, and Chaotic Local Search for reducing the local stagnation. The performance of QOCEO and several contemporary metaheuristics have been evaluated on 96 benchmark functions (including classical benchmark, CEC-2017, CEC-2019, CEC-2020 and CEC-2022) and six constrained engineering optimization problems employing several statistical tests. The average rank Friedman test confirms that for all 96 benchmark functions, QOCEO outperforms CMA-ES, OBTLEO, m-EO, EO, LSHADE-SPACMA, SPS_L_SHADE_EIG, SHADE by 88%, 83%, 49%, 35%, 27%, 18% and 5%, respectively. Comparing the results of Bonferroni-Dunn and Holm’s tests, QOCEO outperforms PSO, GWO, EO, HGSO, SSA, and GSA for classical benchmark functions with 30, 100, 300, and 500 dimensions. Further, QOCEO outperform CMA-ES, OBTLEO, m-EO, EO, LSHADE-SPACMA for all 96 benchmark functions and statistically similar to SPS_L_SHADE_EIG, SHADE and EBOwithCMAR.},
  archive      = {J_ISCI},
  author       = {Romio Atha and Abhishek Rajan and Sourav Mallick},
  doi          = {10.1016/j.ins.2023.120077},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120077},
  shortjournal = {Inf. Sci.},
  title        = {An enhanced equilibrium optimizer for solving complex optimization problems},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synergy between blockchain technology and internet of
medical things in healthcare: A way to sustainable society.
<em>ISCI</em>, <em>660</em>, 120049. (<a
href="https://doi.org/10.1016/j.ins.2023.120049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we investigate the synergy between the Internet of Medical Things (IoMT) and blockchain technology in healthcare for sustainable societies. To address the research goal, a state-of-the-art review on the IoMT and blockchain in healthcare is conducted. The study’s novelty lies in a new approach toward “ medical data ,” as a potential economic asset for value creation with the help of disruptive technologies. IoMT technology gathers real-time medical data and extracts knowledge in digital healthcare systems. Blockchain technology ensures transparency, privacy, and security in a distributed healthcare ecosystem. Indeed, these two technologies bring greater data connectivity and interoperability, where data is not isolated and underutilized anymore. IoMT-blockchain solutions offer a new paradigm of predictive, integrated, and personalized healthcare services based on medical data for individuals’ vitality and enhanced life expectancy. On a broader scale, healthy people make society more sustainable and resilient, where citizens actively involve in development planning and solving community issues by sharing and monetizing their personal health data. The current research broadens the horizons of researchers and policy-makers through current trends and future research directions.},
  archive      = {J_ISCI},
  author       = {Mahsa Sadeghi and Amin Mahmoudi},
  doi          = {10.1016/j.ins.2023.120049},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120049},
  shortjournal = {Inf. Sci.},
  title        = {Synergy between blockchain technology and internet of medical things in healthcare: A way to sustainable society},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Corrigendum to “deep state-space model for predicting
cryptocurrency price” [inform. Sci. 618 (2022) 417–433]. <em>ISCI</em>,
<em>660</em>, 120031. (<a
href="https://doi.org/10.1016/j.ins.2023.120031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISCI},
  author       = {Shalini Sharma and Angshul Majumdar},
  doi          = {10.1016/j.ins.2023.120031},
  journal      = {Information Sciences},
  month        = {3},
  pages        = {120031},
  shortjournal = {Inf. Sci.},
  title        = {Corrigendum to “Deep state-space model for predicting cryptocurrency price” [Inform. sci. 618 (2022) 417–433]},
  volume       = {660},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Standard specification-based intrusion detection for
hierarchical industrial control systems. <em>ISCI</em>, <em>659</em>,
120102. (<a href="https://doi.org/10.1016/j.ins.2024.120102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a specification-based, process-aware, Intrusion Detection System (IDS) for complex Industrial Control Systems (ICSs). Complex ICSs are distributed and hierarchical control systems built on top of local control loops which are the system&#39;s elementary building blocks . Process-aware attacks are sophisticated cyberattacks that aim to compromise the safety of the controlled physical process. Our approach aims to link safety specifications and security properties. Thus, we use international and industry standards specifications concerning local safety, global safety and networks of the industrial process, in order to obtain security properties. The obtained security properties are cybersecurity related requirements . They are translated into security patterns in order to be runtime monitored by our network IDS . This latter relies on a distributed monitoring framework, capturing network traffic between the local loops and the distributed control level, as well as between distributed control and supervisory control. We implemented and evaluated our IDS on a real ICS. We experimentally show that our IDS detects a large spectrum of attacks. We also show that our distributed IDS is scalable since its detection response time as a function of the number of monitored security patterns, is linear. A demonstrator comprising code extracts is made available.},
  archive      = {J_ISCI},
  author       = {Estelle Hotellier and Franck Sicard and Julien Francq and Stéphane Mocanu},
  doi          = {10.1016/j.ins.2024.120102},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120102},
  shortjournal = {Inf. Sci.},
  title        = {Standard specification-based intrusion detection for hierarchical industrial control systems},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solution of z-number-based multi-objective linear
programming models with different membership functions. <em>ISCI</em>,
<em>659</em>, 120100. (<a
href="https://doi.org/10.1016/j.ins.2024.120100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a universe full of fuzziness and uncertainty, it is an absolute blessing if some information is reliable to some degree. Considering the amount of uncertainty, Zadeh proposed the idea of Z -number, which carries both uncertainty and the reliability of the information. Uncertain information can be reliably conveyed using Z -numbers. On the other hand, one of the important and widely used decision-making techniques is linear programming. Currently, linear programming has been extensively explored using fuzzy information. Decisions made using linear programming with uncertain data are highly uncertain due to the lack of reliability of the information. An effective decision-making method is multi-objective linear programming (MOLP), in which the decision-maker attempts to draw conclusions from information containing conflicting attributes. In the MOLP problem , there may be different solution vectors corresponding to each objective function. One needs to find a compromise solution vector that satisfies each objective function to a certain extent based on the decision maker&#39;s suggested preferences. In this study, we use Z -number and MOLP to model the Z -number MOLP problem (ZMOLPP). Furthermore, we propose a strategy for solving ZMOLPP by transforming it into a crisp MOLP problem , and finally converting this crisp MOLP problem into a single-objective linear programming problem (LPP) using different shape functions. Additionally, we compare the results with existing MOLP problems in fuzzy settings to validate the proposed strategy.},
  archive      = {J_ISCI},
  author       = {Muhammad Akram and Inayat Ullah},
  doi          = {10.1016/j.ins.2024.120100},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120100},
  shortjournal = {Inf. Sci.},
  title        = {Solution of Z-number-based multi-objective linear programming models with different membership functions},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction of x-ray fluorescence copper grade using
regularized stochastic configuration networks. <em>ISCI</em>,
<em>659</em>, 120098. (<a
href="https://doi.org/10.1016/j.ins.2024.120098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In copper ore flotation processes, accurate measurement and estimation of the copper grade of the final products are crucial for field operations and control. Due to the presence of multicollinearity and outliers in the measured data, the existing on-stream X-ray fluorescence grade analyzer is inaccurate. To address these issues, this study proposes a robust data modeling algorithm to improve the performance of copper grade prediction. Specifically, a regularized stochastic configuration network and a generalized M−estimation method are used to overcome the uncertainties in the processing data. The experimental results clearly demonstrate that the proposed model outperforms other modeling algorithms in terms of prediction accuracy and robustness.},
  archive      = {J_ISCI},
  author       = {Kai Sun and Lei Zhao and Pengxin Tian and Jianjun Zhao and Dianhui Wang},
  doi          = {10.1016/j.ins.2024.120098},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120098},
  shortjournal = {Inf. Sci.},
  title        = {Prediction of X-ray fluorescence copper grade using regularized stochastic configuration networks},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Multi-layer representation for cross-view action
recognition. <em>ISCI</em>, <em>659</em>, 120088. (<a
href="https://doi.org/10.1016/j.ins.2024.120088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Daily action recognition is an important application domain in computer vision . Considering the complex temporal structure and view changes of daily actions, we propose a multi-layer representation for cross-view action recognition (MRCAR) based on two-stage optimization using a training set and a validation set. In the first stage, a cross-view atomic dictionary learning model is constructed based on jointly sparse constraints, utilizing the original features of the training set. Subsequently, a shared atomic dictionary, containing representative view-independent information, is obtained through alternating optimization. In the second stage, a reconstruction function based on the obtained shared atomic dictionary is developed. This function is employed to acquire sparse codes for the training and validation sets, enhancing the representativeness of motion atoms and improving overall recognition performance. Finally, experimental results from the WVU (West Virginia University) dataset and the NTU (Nanyang Technological University) RGB-D 120 dataset demonstrate that the proposed MRCAR method achieves an accuracy improvement of 3%-20% over recent state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Zhigang Liu and Yin Wu and Ziyang Yin},
  doi          = {10.1016/j.ins.2024.120088},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120088},
  shortjournal = {Inf. Sci.},
  title        = {Multi-layer representation for cross-view action recognition},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neuro-adaptive non-singular terminal sliding mode control
for distributed fixed-time synchronization of higher-order uncertain
multi-agent nonlinear systems. <em>ISCI</em>, <em>659</em>, 120087. (<a
href="https://doi.org/10.1016/j.ins.2023.120087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel design for a distributed fixed-time synchronization controller based on neuro-adaptive non-singular terminal sliding mode control for higher-order multi-agent nonlinear systems . In this study, a distributed control strategy is employed in which networked nonlinear systems , referred to as nodes, communicate through a predefined network topology . Within this framework, a leader-follower configuration is adopted, designating one node as the leader and the others as follower agents. Notably, the dynamics of the agents are assumed to be unknown, leading to the development of a generalized uncertain higher-order nonlinear dynamical system model that accounts for the disturbed dynamics of all agents, including the matched bounded uncertainty with an upper algebraic bound. The control design leverages radial basis function neural networks for approximation , effectively addressing unknown nonlinear terms , such as drift terms and input channels. Importantly, the proposed technique successfully mitigated matched-type uncertainty, resulting in rapid sliding-mode enforcement with reduced chattering and stress. This innovative approach establishes fixed-time synchronization by creating a sliding mode with respect to the sliding surface of networked synchronization mismatches. To underscore the effectiveness of this approach, a simulation example that vividly illustrates its captivating properties and contributions is presented.},
  archive      = {J_ISCI},
  author       = {Safeer Ullah and Qudrat Khan and Monji Mohamed Zaidi and Lyu-Guang Hua},
  doi          = {10.1016/j.ins.2023.120087},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120087},
  shortjournal = {Inf. Sci.},
  title        = {Neuro-adaptive non-singular terminal sliding mode control for distributed fixed-time synchronization of higher-order uncertain multi-agent nonlinear systems},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Output-constrained fixed-time coordinated control for
multi-agent systems with event-triggered and delayed communication.
<em>ISCI</em>, <em>659</em>, 120086. (<a
href="https://doi.org/10.1016/j.ins.2023.120086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a fixed-time coordinated controller for high-order multi-agent systems dealing with output constraints and switching digraphs while considering event-triggered and delayed communication. To tackle the scenario where only a subset of agents have direct access to the leader, a novel event-triggered fixed-time observer is first devised. This observer effectively estimates the state of the leader, considering the influence of communication delays. Subsequently, a neural network-based fixed-time controller is formulated under output constraints, utilizing the estimated leader commands to achieve the desired control objectives . Finally, practical experiments are conducted using omni-mecanum-wheeled robots to demonstrate the practical feasibility and superior performance of the theoretical findings. This study contributes significantly by tackling the challenging problem of output-constrained fixed-time coordinated control in event-triggered and delayed communication within switching digraphs. This area has yet to be previously explored.},
  archive      = {J_ISCI},
  author       = {Jierui Zhang and Hongwei Xia and Guangcheng Ma},
  doi          = {10.1016/j.ins.2023.120086},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120086},
  shortjournal = {Inf. Sci.},
  title        = {Output-constrained fixed-time coordinated control for multi-agent systems with event-triggered and delayed communication},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel detection method for ore-coke ratio of blast furnace
based on structure-texture entropy of images. <em>ISCI</em>,
<em>659</em>, 120084. (<a
href="https://doi.org/10.1016/j.ins.2023.120084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ore-coke ratio is crucial for regulating gas flow distribution, enhancing permeability, and ensuring smooth operation of the blast furnace . Direct detection of the ore-coke ratio, leveraging the structure and texture differences in ore and coke images, is a widely accepted method. The harsh environment of the blast furnace results in unclear burden surface images, making it challenging to differentiate between ore and coke. This complicates image-based direct detection for ore-coke ratio, with few studies addressing this issue. This paper firstly introduces a structure-texture entropy, grounded in information entropy, to effectively differentiate between ore and coke. Then, a structure-texture enhancement algorithm based on image extreme dark features is proposed to optimize the accuracy of the structure-texture entropy. Finally, based on the high-accuracy structure-texture entropy, a novel algorithm for burden surface area extraction is presented. This method uses feature vector clustering and functional optimization for real-time ore-coke ratio detection. Industrial experiments demonstrate that the proposed method achieves high-accuracy ore-coke ratio detection, meeting the requirements for long-term stability of the blast furnace.},
  archive      = {J_ISCI},
  author       = {Zhipeng Chen and Jingyi Wu and Ling Shen and Weihua Gui},
  doi          = {10.1016/j.ins.2023.120084},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120084},
  shortjournal = {Inf. Sci.},
  title        = {A novel detection method for ore-coke ratio of blast furnace based on structure-texture entropy of images},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Grid neighbourhood based three way clustering (3WC).
<em>ISCI</em>, <em>659</em>, 120082. (<a
href="https://doi.org/10.1016/j.ins.2023.120082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key idea behind three-way clustering (3WC) is to group items into three regions to reveal patterns that might not be apparent using two-way clustering. Three-way clustering, contrasting with two-way, considers data across three regions instead of two regions. The three regions are referred to as inside, outside, and partial regions, contrary to the two-way clustering that uses inside and outside regions. The objects in the inside region are members of a cluster, whereas those in the outside region are not, and partial objects may be members of a cluster. Three-way clustering encounters two challenges: 1) Investigation of sophisticated evaluation functions. 2) Finding an optimized pair of thresholds used to identify three regions for a cluster. In the context of Three-Way Clustering (3WC), applying conditional probability can be beneficial for assessing the likelihood of patterns or relationships within each region. In this study, the first challenge is addressed by employing a grid-based approach for a sophisticated evaluation function based on conditional probability . Whereas the second challenge is addressed by employing the elbow-based method to determine a pair of thresholds within a grid-based histogram. Further, two approaches namely the OGN3 and RGN3 are introduced to discover clear and crisp clusters. Experimental results on UCI and Kaggle datasets indicate improvements for commonly used F1 measures for OGN3 and RGN3 up to 4.97% and 12.88%, respectively},
  archive      = {J_ISCI},
  author       = {Muhammad Shoaib and Tamleek Ali Tanveer and Bahar Ali and Bashir Hayat and Anwar Shah},
  doi          = {10.1016/j.ins.2023.120082},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120082},
  shortjournal = {Inf. Sci.},
  title        = {Grid neighbourhood based three way clustering (3WC)},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combining intra-risk and contagion risk for enterprise
bankruptcy prediction using graph neural networks. <em>ISCI</em>,
<em>659</em>, 120081. (<a
href="https://doi.org/10.1016/j.ins.2023.120081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the bankruptcy risk of small and medium-sized enterprises (SMEs) is crucial for making decisions about loans. Existing studies in both finance and AI research fields, however, tend to only consider either the intra-risk or contagion risk of enterprises, ignoring their interactions and combinatorial effects. This study for the first time considers both types of risk and their joint effects in bankruptcy prediction . Specifically, we first propose an enterprise intra-risk encoder based on statistically significant enterprise risk indicators for its intra-risk learning. Then, we propose an enterprise contagion risk encoder based on an enterprise knowledge graph for its contagion risk embedding. In particular, the contagion risk encoder includes both the newly proposed Heterogeneous Hyper-Graph Neural Networks (HHGNN) and Hierarchical Graph Transformer Networks (HGTN). Using these two types of encoders, we design a unified framework to simultaneously capture intra-risk and contagion risk for bankruptcy prediction. To evaluate the model, we collect real-world multi-sources data on SMEs and build a novel benchmark dataset called SMEsD. We provide open access to the dataset, which is expected to further promote research on financial risk analysis . Experiments on SMEsD against twelve state-of-the-art baselines demonstrate the effectiveness of the proposed model for bankruptcy prediction.},
  archive      = {J_ISCI},
  author       = {Shaopeng Wei and Jia Lv and Yu Guo and Qing Yang and Xingyan Chen and Yu Zhao and Qing Li and Fuzhen Zhuang and Gang Kou},
  doi          = {10.1016/j.ins.2023.120081},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120081},
  shortjournal = {Inf. Sci.},
  title        = {Combining intra-risk and contagion risk for enterprise bankruptcy prediction using graph neural networks},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Random generation of linearly constrained fuzzy measures and
domain coverage performance evaluation. <em>ISCI</em>, <em>659</em>,
120080. (<a href="https://doi.org/10.1016/j.ins.2023.120080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The random generation of fuzzy measures under complex linear constraints holds significance in various fields, including optimization solutions, machine learning , decision making, and property investigation. However, most existing random generation methods primarily focus on addressing the monotonicity and normalization conditions inherent in the construction of fuzzy measures, rather than the linear constraints that are crucial for representing special families of fuzzy measures and additional preference information. In this paper, we present two categories of methods to address the generation of linearly constrained fuzzy measures using linear programming models. These methods enable a comprehensive exploration and coverage of the entire feasible convex domain . The first category involves randomly selecting a subset and assigning measure values within the allowable range under given linear constraints. The second category utilizes convex combinations of constrained extreme fuzzy measures and vertex fuzzy measures. Then we employ some indices of fuzzy measures, objective functions, and distances to domain boundaries to evaluate the coverage performance of these methods across the entire feasible domain . We further provide enhancement techniques to improve the coverage ratios. Finally, we discuss and demonstrate potential applications of these generation methods in practical scenarios.},
  archive      = {J_ISCI},
  author       = {Jian-Zhang Wu and Gleb Beliakov and Simon James and Marek Gagolewski},
  doi          = {10.1016/j.ins.2023.120080},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120080},
  shortjournal = {Inf. Sci.},
  title        = {Random generation of linearly constrained fuzzy measures and domain coverage performance evaluation},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comment on “an efficient identity-based signature scheme
with provable security.” <em>ISCI</em>, <em>659</em>, 120079. (<a
href="https://doi.org/10.1016/j.ins.2023.120079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this comment paper, we reveal a security issue in an efficient identity-based signature (IBS) scheme that has been proven secure in the standard model. More specifically, we perform a key-only attack on the IBS scheme to break its universal unforgeability. Since the security notion of universal unforgeability under key-only attack ( uuf-koa ) is a weaker notion than the existential unforgeability under chosen message attack ( euf-cma ), this invalidates the euf-cma security claimed by the IBS scheme. Subsequently, we propose a fix to achieve a stronger seuf-cma security without a random oracle.},
  archive      = {J_ISCI},
  author       = {Syh-Yuan Tan and Swee-Huay Heng},
  doi          = {10.1016/j.ins.2023.120079},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120079},
  shortjournal = {Inf. Sci.},
  title        = {Comment on “An efficient identity-based signature scheme with provable security”},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fixed-time neural networks with time-invariant and
time-varying coefficients for mixed variational inequalities.
<em>ISCI</em>, <em>659</em>, 120078. (<a
href="https://doi.org/10.1016/j.ins.2023.120078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops several fixed-time neural networks for solving mixed variational inequalities (MVIs). The proposed networks are highly efficient and with fixed-time convergence. First, based on the conventional forward-backward-forward neural network (FNN) and sliding mode control technique, a time-invariant fixed-time FNN (FxTFNN) is designed. Next, the Euclidean norm of FNN is introduced into FxTFNN to design the modified FxTFNN (MFxTFNN). It is shown that the proposed FxTFNN and MFxTFNN have fixed-time convergence properties and their settling-time functions are independent of the initial values . The proposed FxTFNN and MFxTFNN can be used to solve the Lasso problem and apply sparse signal reconstruction and image reconstruction. In addition, by introducing time-varying coefficients based on FxTFNN and MFxTFNN, time-varying FxTFNN (TFxTFNN) and time-varying MFxTFNN (TMFxTFNN) are developed. Finally, experimental results of numerical example , signal reconstruction, and image reconstruction are used to verify the effectiveness and superiority of the proposed neural networks .},
  archive      = {J_ISCI},
  author       = {Hongsong Wen and Xing He and Jing Xu and Mingliang Zhou and Tingwen Huang},
  doi          = {10.1016/j.ins.2023.120078},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120078},
  shortjournal = {Inf. Sci.},
  title        = {Fixed-time neural networks with time-invariant and time-varying coefficients for mixed variational inequalities},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using easy coefficients conjecture for rotation symmetric
boolean functions. <em>ISCI</em>, <em>659</em>, 120075. (<a
href="https://doi.org/10.1016/j.ins.2023.120075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Boolean function in n variables is rotation symmetric (RS) if it is invariant under powers of ρ ( x 1 , … , x n ) = ( x 2 , … , x n , x 1 ) ρ(x1,…,xn)=(x2,…,xn,x1) . An RS function is called monomial rotation symmetric (MRS) if it is generated by applying powers of ρ to a single monomial . Completing earlier research on special cases, the author showed in 2018 that for any RS function f n fn in n variables, the sequence of Hamming weights w t ( f n ) wt(fn) for all values of n satisfies a linear recurrence relation. It was also proved that the associated recursion polynomial could be explicitly calculated as the minimal polynomial of a rules matrix and an algorithm for computing the rules matrix was explained. Examples showed that the usual formula which gives the values of w t ( f n ) − 2 n − 1 wt(fn)−2n−1 as a linear combination of powers of the irrational roots of the minimal polynomial has simple coefficients which are all 1/2 if the multiset made up of the roots of the characteristic polynomial of the rules matrix is used instead, no matter what the degree of the Boolean function is. The conjecture that this is always true is called the Easy Coefficients Conjecture (ECC). The special case of MRS quadratics was proved in an earlier paper. The present paper gives some ECC applications valid for any function for which the ECC is true, even though there is a proof only for the quadratic MRS case so far.},
  archive      = {J_ISCI},
  author       = {Thomas W. Cusick},
  doi          = {10.1016/j.ins.2023.120075},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120075},
  shortjournal = {Inf. Sci.},
  title        = {Using easy coefficients conjecture for rotation symmetric boolean functions},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fishing risky behavior recognition based on adaptive
transformer, reinforcement learning and stochastic configuration
networks. <em>ISCI</em>, <em>659</em>, 120074. (<a
href="https://doi.org/10.1016/j.ins.2023.120074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fishing behavior in a high-voltage environment may lead to electric shock accidents. This paper proposes a fishing risky behavior recognition method based on adaptive Transformer, reinforcement learning and stochastic configuration networks (SCNs). Firstly, the fishing behavior image sample training set is evaluated using the actor network based on linear entropy in the reinforcement learning module to select suitable training samples that possess abundant straight-line elements. Subsequently, the selected training samples are fed into a multi-scale spatial deep convolution to extract continuous spatial features of elongated objects. The deformable Transformer network, enhanced with adaptive encoding and decoding layers through SCNs, is used to obtain the position and detection results of the fishing rod. The trained Transformer model is evaluated by a defined credibility evaluation metric for acquiring rewards to update the training sample set iteratively. Then, an adaptive adjustment mechanism is constructed for the encoding and decoding layers of the adaptive Transformer network to establish a library of adaptive Transformer models with different encoding and decoding layer levels to accommodate the feature requirements of training samples in various scenarios. Finally, the blending learning method for combining the detection results from the model library is integrated with human body object detection and pose estimation methods, and a predefined expert system is utilized for logic reasoning on fishing risky behavior. Experimental results demonstrate the effectiveness of the proposed method in this paper.},
  archive      = {J_ISCI},
  author       = {Shengshi Yang and Lijian Ding and Weitao Li and Wei Sun and Qiyue Li},
  doi          = {10.1016/j.ins.2023.120074},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120074},
  shortjournal = {Inf. Sci.},
  title        = {Fishing risky behavior recognition based on adaptive transformer, reinforcement learning and stochastic configuration networks},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rough set theory applied to finite dimensional vector
spaces. <em>ISCI</em>, <em>659</em>, 120072. (<a
href="https://doi.org/10.1016/j.ins.2023.120072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study finite dimensional vector spaces using rough set theory (RST) by defining a Boolean information system I B IB associated with a vector space V V for a given basis B . We define an indiscernibility relation on V V and investigate different partitions induced on V V . We identify that every reduct of the information system is a basis of V V and the core is empty in the case of V V over field F with | F | ≥ 3 |F|≥3 . We study the measure of dependency between different subsets of V V . Moreover, we define three posets and prove that these posets are isomorphic and complete. We study lower and upper approximations for different subsets of V V and determine rough and exact sets. We give the general form of the entries of the discernibility matrix. We determine essential sets and the essential dimension of the information system, and prove that minimal entries of the discernibility matrix coincide with the essential sets. Finally, we demonstrate the use of the developed theory by providing two practical examples.},
  archive      = {J_ISCI},
  author       = {Abeer Fatima and Imran Javaid},
  doi          = {10.1016/j.ins.2023.120072},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120072},
  shortjournal = {Inf. Sci.},
  title        = {Rough set theory applied to finite dimensional vector spaces},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Asynchronous dissipative control for nonhomogeneous markov
jump systems with dual markovian wireless fading channels.
<em>ISCI</em>, <em>659</em>, 120071. (<a
href="https://doi.org/10.1016/j.ins.2023.120071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is devoted to the matter of asynchronous state feedback control for a class of nonhomogeneous Markov jump systems subjected to the dual Markovian wireless fading channel. A key feature here is that dual Markov chain is employed to model the stochastically switching of channel state with nonhomogeneous Markov process , which characterize both the transition of channel mode itself and the dependence on the system mode. Meanwhile, channel state-dependent packet dropout rate is time-varying with different channel mode. In the case of that, existing methods are difficult to deal with, resulting in the degradation of system performance . To this end, hidden Markov model-based asynchronous controller is firstly presented with compensated measurements. Secondly, co-designing with the asynchronous controller, a novel dynamic compensator is constructed to handle the mismatched measurements. Then, since both the Markov process of system and channel are considered, dual mode-dependent Lyapunov functional is constructed to verify the stochastic stability of the augmented system , as well as the strictly dissipative performance, which leads to less conservatism compared to the single mode-dependent one. Finally, a boost converter model driven by pulse-width-modulation is presented to demonstrate the validation of the proposed strategies.},
  archive      = {J_ISCI},
  author       = {Jian Wang and Jiuxiang Dong},
  doi          = {10.1016/j.ins.2023.120071},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120071},
  shortjournal = {Inf. Sci.},
  title        = {Asynchronous dissipative control for nonhomogeneous markov jump systems with dual markovian wireless fading channels},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Game-theoretic modeling and analysis of cyberbullying
spreading on OSNs. <em>ISCI</em>, <em>659</em>, 120067. (<a
href="https://doi.org/10.1016/j.ins.2023.120067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of online social networks (OSNs) has enabled seamless cyberbullying activities, which not only cause psychological harm to victims but also bring disharmony to society. From the perspective of OSN platform administrators, strategic decision making towards when/how to launch an anti-cyberbullying campaign is the key to mitigating its negative impact . Hence, this paper develops a dynamic anti-cyberbullying investment solution to mitigate the adverse impact of strategic cyberbullying phenomena cost-effectively. Specifically, this paper first quantifies the payoffs of the attacker/bullying instigator and the defender/platform administrator based on a newly proposed propagation model . Then, considering the budget-constrained factor for both sides, a differential game-theoretical model is proposed to simulate each party&#39;s optimal trade-off between cost and benefit. Next, by utilizing Pontryagin Maximum/Minimum Principle, a set of necessary conditions for a Nash equilibrium strategy profile have been proposed. Based on the forward-backward sweep method, an iterative algorithm (SCR optimization algorithm) is tailored to solve the conditions numerically. Through experiments conducted under Facebook, Youtube and Twitter sub-networks, the algorithm&#39;s performance has been evaluated by inspecting its convergence speed and payoff compared with randomized profiles. Consequently, the resulting strategies are verified to exhibit superior performance in dealing with cyberbullying spreading.},
  archive      = {J_ISCI},
  author       = {Qi Chu and Yang Qin and Lu-Xing Yang and Xiaofan Yang},
  doi          = {10.1016/j.ins.2023.120067},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120067},
  shortjournal = {Inf. Sci.},
  title        = {Game-theoretic modeling and analysis of cyberbullying spreading on OSNs},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contrastive fine-tuning for low-resource graph-level
transfer learning. <em>ISCI</em>, <em>659</em>, 120066. (<a
href="https://doi.org/10.1016/j.ins.2023.120066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to insufficient supervision and the gap between pre-training pretext tasks and downstream tasks, transferring pre-trained graph neural networks (GNNs) to downstream tasks in low-resource scenarios remains challenging. In this paper, a Contrastive Fine-tuning (Con-tuning) framework is proposed for low-resource graph-level transfer learning , and a graph-level supervised contrastive learning (SCL) task is designed within the framework as the first attempt to introduce SCL for fine-tuning processes of pre-trained GNNs. The SCL task compensates for the insufficient supervision problem in low-resource scenarios and narrows the gap between pretext tasks and downstream tasks. To further reinforce the supervision signal in the SCL task, we devise a graphon theory based labeled graph generator to extract the generalized knowledge of a specific class of graphs. Based on this knowledge, graph-level templates are generated for each class and used as contrastive samples in the SCL task. Then, the proposed Con-tuning framework jointly learns the SCL task and downstream tasks to effectively fine-tune the pre-trained GNNs for downstream tasks. Extensive experiments with eight real-world datasets show that Con-tuning framework enables pre-trained GNNs to achieve better performance on graph-level downstream tasks in low-resource settings.},
  archive      = {J_ISCI},
  author       = {Yutai Duan and Jie Liu and Shaowei Chen and Jianhua Wu},
  doi          = {10.1016/j.ins.2023.120066},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120066},
  shortjournal = {Inf. Sci.},
  title        = {Contrastive fine-tuning for low-resource graph-level transfer learning},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Fuzzy neuron modeling of incomplete data for missing value
imputation. <em>ISCI</em>, <em>659</em>, 120065. (<a
href="https://doi.org/10.1016/j.ins.2023.120065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing values are a common problem found in many real-world datasets, and cannot be avoided. It is a challenging task to model incomplete data and reasonably impute missing values. This paper focuses on regression imputation and uses a tracking-removed autoencoder (TRAE) to construct the mutual fitting correlation on incomplete data. Considering the differences in regression relationships across different sample categories, we introduce Takagi-Sugeno (TS) fuzzy architecture and propose a category-based tracking-removed autoencoder (TS-TRAE) to model incomplete data for missing value imputation. The TS-TRAE model partitions the incomplete dataset into several subclusters using membership information obtained from fuzzy clustering, then establishes a TRAE-based submodel to mine relationships within each subcluster for precise modeling of incomplete data. During model training, in order to fully utilize all existing values, we treat missing values as variables and propose an iterative learning method that optimizes missing variables and network parameters collaboratively. This method allows incomplete samples to participate in model training while also enabling the imputation of missing values. The TS-TRAE model integrates the inner category structure of incomplete data and the attribute association features effectively. The experimental results verify the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Zheng Zhang and Xiaoming Yan and Liyong Zhang and Xiaochen Lai and Wei Lu},
  doi          = {10.1016/j.ins.2023.120065},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120065},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy neuron modeling of incomplete data for missing value imputation},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LCEMH: Label correlation enhanced multi-modal hashing for
efficient multi-modal retrieval. <em>ISCI</em>, <em>659</em>, 120064.
(<a href="https://doi.org/10.1016/j.ins.2023.120064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised multi-modal hashing can effectively improve the discriminative power of hash codes by leveraging semantic label information. However, most existing supervised multi-modal hashing models generally rely on discrete labels for supervision. They only provide limited guidance and may not fully capture the potential semantic similarity between multi-modal data. Moreover, the binary constraints of hash codes further restrict their ability to fully capture the rich semantic information embedded in the labels. To address these limitations, we propose a Label Correlation Enhanced Multi-modal Hashing (LCEMH) approach for efficient multi-modal retrieval. Specifically, our proposed model can effectively expand the inter-class boundaries of discrete labels to further enrich the supervision of similarity. Additionally, we directly transform the acquired richer label information into hash codes simply and effectively, thus retaining more comprehensive information in the labels with minimal quantization loss, and enhancing the discriminant ability of the generated hash codes. Experimental results on three public multimedia retrieval datasets demonstrate the superiority of LCEMH in performance. The source code of LCEMH is available online at: https://github.com/ChaoqunZheng/LCEMH .},
  archive      = {J_ISCI},
  author       = {Chaoqun Zheng and Lei Zhu and Zheng Zhang and Wenjun Duan and Wenpeng Lu},
  doi          = {10.1016/j.ins.2023.120064},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120064},
  shortjournal = {Inf. Sci.},
  title        = {LCEMH: Label correlation enhanced multi-modal hashing for efficient multi-modal retrieval},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Three-way decision-making methods with multi-intuitionistic
β-neighborhood-based multiattribute group decision-making problems.
<em>ISCI</em>, <em>659</em>, 120063. (<a
href="https://doi.org/10.1016/j.ins.2023.120063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiattribute group decision-making (MAGDM) is a decision analysis method used to address decision-making problems that have multiple attributes and multiple decision alternatives. It is generally believed that multigranulation rough sets (MGRSs) are a twofold scheme to solve MAGDM problems. Thus, in this paper, we aim to generalize MGRSs and decision-theoretic rough sets (DTRSs) to intuitionistic fuzzy β -covering (IF β C) information systems and propose a novel MAGDM method to handle decision-making problems, which not only deepens the cognition of the three-way decision (3WD) model but also expands its application in decision-making problems. The paper first introduces a novel conditional probability using the ideal positive degree of intuitionistic fuzzy numbers (IFNs) and then investigates its properties. Second, in the IF β C environment, we utilize the proposed conditional probabilities to construct two types of multigranulation decision-theoretic rough set (MGDTRS) models, an optimistic strategy and a pessimistic strategy, discuss their theoretical properties and explore the relationship between the two strategies. Third, a novel MAGDM method for multi-intuitionistic β -neighborhoods is established in accordance with the proposed MGDTRS model. We also establish an algorithm for the proposed MAGDM method. Fourth, we apply the proposed method to address several MAGDM problems. By conducting comparative analysis with existing methods, we demonstrate the effectiveness of the proposed method and discuss the advantages and limitations of the proposed method. Furthermore, we conduct extensive parameter experimentation analysis on the proposed method from different perspectives. The experimental results demonstrate the stability and effectiveness of our proposed method.},
  archive      = {J_ISCI},
  author       = {Deji Selang and Haidong Zhang and Yanping He},
  doi          = {10.1016/j.ins.2023.120063},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120063},
  shortjournal = {Inf. Sci.},
  title        = {Three-way decision-making methods with multi-intuitionistic β-neighborhood-based multiattribute group decision-making problems},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dynamic similarity weighted evolving fuzzy system for
concept drift of data streams. <em>ISCI</em>, <em>659</em>, 120062. (<a
href="https://doi.org/10.1016/j.ins.2023.120062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial markets and weather prediction are generating streaming data at a rapid rate. The frequent concept drifts in these data streams pose significant challenges to learners during training and prediction. Concept drift means the distribution of data in the data stream changes dramatically at any time, and it can lead to decreased effectiveness in many data-driven systems. So, obtaining online models that adapt to concept drift is essential. In the face of concept drifts in data streams, most proposed evolving fuzzy systems (EFSs) suffer from two problems. First, it is difficult to quickly adapt to a drastic change in a short period, such as sudden drift. Second, most ensemble EFSs adjust the weights according to the error, which will easily lead to the risk of under-training and repeated training of the base model. To solve the above problems, we propose a new type of ensemble EFS called dynamic similarity weighted evolving fuzzy system (DSW-EFS). Unlike existing ensemble EFSs, DSW-EFS assigns weights to base learners based on the similarity between data distributions , and each base learner describes only one data distribution in the data stream. This ensemble method enables DSW-EFS to describe multiple data distributions in the data stream and quickly adapt to multiple concept drifts. To ensure the accuracy of drift detection , we propose a Gaussian mixture model (GMM)-based concept drift detection algorithm that can obtain the similarity between data distributions. This detection method can achieve high accuracy based on a smaller sliding window size. The DSW-EFS model is tested from concept drifts and prediction accuracy in the experimental part. The results show that DSW-EFS can quickly adapt to concept drift by assigning weights to base learners based on similarity when concept drifts occur. Moreover, DWS-EFS achieves high prediction accuracy on most datasets.},
  archive      = {J_ISCI},
  author       = {Haoli Li and Tao Zhao},
  doi          = {10.1016/j.ins.2023.120062},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120062},
  shortjournal = {Inf. Sci.},
  title        = {A dynamic similarity weighted evolving fuzzy system for concept drift of data streams},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wasserstein adversarial learning based temporal knowledge
graph embedding. <em>ISCI</em>, <em>659</em>, 120061. (<a
href="https://doi.org/10.1016/j.ins.2023.120061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on knowledge graph embedding (KGE) has emerged as an active field in which most existing KGE approaches mainly focus on static structural data and ignore the influence of temporal variation involved in time-aware triples. In order to deal with this issue, several temporal knowledge graph embedding (TKGE) approaches have been proposed to integrate temporal and structural information. However, these methods only employ a uniformly random sampling to construct negative facts. As a consequence, the corrupted samples are often too simplistic for training an effective model. In this paper, we propose a new temporal knowledge graph embedding framework by introducing adversarial learning to further refine the performance of traditional TKGE models. In our framework, a generator is utilized to construct high-quality plausible quadruples and a discriminator learns to obtain the embeddings of entities and relations based on both positive and negative samples. Meanwhile, we also apply a Gumbel-Softmax relaxation and the Wasserstein distance to prevent vanishing gradient problems on discrete data; an inherent flaw in traditional generative adversarial networks . Through comprehensive experimentation on temporal datasets, the results indicate that our proposed framework can attain significant improvements based on benchmark models and also demonstrate the effectiveness and applicability of our framework.},
  archive      = {J_ISCI},
  author       = {Yuanfei Dai and Wenzhong Guo and Carsten Eickhoff},
  doi          = {10.1016/j.ins.2023.120061},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120061},
  shortjournal = {Inf. Sci.},
  title        = {Wasserstein adversarial learning based temporal knowledge graph embedding},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PTCAS: Prompt tuning with continuous answer search for
relation extraction. <em>ISCI</em>, <em>659</em>, 120060. (<a
href="https://doi.org/10.1016/j.ins.2023.120060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tremendous progress has been made in the development of fine-tuned pretrained language models (PLMs) that achieve outstanding results on almost all natural language processing (NLP) tasks. Further stimulation of rich knowledge distribution within PLMs can be achieved through additional prompts for fine-tuning, namely, prompt tuning. Generally, prompt engineering involves prompt template engineering, which is the process of searching for an appropriate template for a specific task, and answer engineering, whose objective is to seek an answer space and map it to the original task label set. Existing prompt-based methods are primarily designed manually and search for appropriate verbalization in a discrete answer space, which is insufficient and always results in suboptimal performance for complex NLP tasks such as relation extraction (RE). Therefore, we propose a novel prompt-tuning method with a continuous answer search for RE, which enables the model to find optimal answer word representations in a continuous space through gradient descent and thus fully exploit the relation semantics . To further exploit entity-type information and integrate structured knowledge into our approach, we designed and added an additional TransH-based structured knowledge constraint to the optimization procedure . We conducted comprehensive experiments on four RE benchmarks to evaluate the effectiveness of the proposed approach. The experimental results show that our approach achieves competitive or superior performance without manual answer engineering compared to existing baselines under both fully supervised and low-resource scenarios.},
  archive      = {J_ISCI},
  author       = {Yang Chen and Bowen Shi and Ke Xu},
  doi          = {10.1016/j.ins.2023.120060},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120060},
  shortjournal = {Inf. Sci.},
  title        = {PTCAS: Prompt tuning with continuous answer search for relation extraction},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KPI-HGNN: Key provenance identification based on a
heterogeneous graph neural network for big data access control.
<em>ISCI</em>, <em>659</em>, 120059. (<a
href="https://doi.org/10.1016/j.ins.2023.120059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic access control of big data has received much attention in recent years because of the characteristics of dynamic generation and multi-source aggregation of big data resources. Provenance-based access control defines dependency paths between resource states through provenance data, and it can dynamically realize access control according to different stages and states of resources. However, big data systems involve huge resources, and the state transition process is complex. The existing research on provenance-based access control techniques faces problems such as low efficiency of manually formulating dependency paths, redundant information in provenance data, and uneven distribution of resources. To solve these problems, this paper proposes a key provenance identification framework KPI-HGNN based on the heterogeneous graph neural network. In the framework, a community detection algorithm based on the heterogeneous graph neural network is designed to realize automatic identification and division of corresponding regions of big data resources through feature fusion of multiple types of nodes and edges. Meanwhile, a key node identification algorithm based on the heterogeneous graph attention network is designed to identify the key node in each community by weighted aggregation of the neighboring node attention coefficients. Besides, a key dependency path discovery algorithm is designed, and access control rules are automatically generated based on key dependency paths. The experimental results indicate that the community detection clustering index of the proposed method is better, the Top-5% key node identification accuracy is higher, and the resource coverage rate and the average percentage number product of key nodes of the provenance-based access control rules are better than those of the baseline method. These results indicate that the proposed key provenance identification framework can efficiently solve the problems in identifying key provenance information faced by dynamic access control of big data.},
  archive      = {J_ISCI},
  author       = {Dibin Shan and Xuehui Du and Wenjuan Wang and Na Wang and Aodi Liu},
  doi          = {10.1016/j.ins.2023.120059},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120059},
  shortjournal = {Inf. Sci.},
  title        = {KPI-HGNN: Key provenance identification based on a heterogeneous graph neural network for big data access control},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automata for knowledge assessment based on the structure of
observed learning outcome taxonomy. <em>ISCI</em>, <em>659</em>, 120058.
(<a href="https://doi.org/10.1016/j.ins.2023.120058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of adaptive assessment of individuals&#39; knowledge by knowledge space theory has been implemented in deterministic finite automata . However, such automata are not suitable for polytomous situations, which limits the application of automata for knowledge assessment . To overcome this limitation, this paper combines the structure of observed learning outcome (SOLO) taxonomy with the response scale and proposes an automata knowledge assessment process that can assess individuals&#39; knowledge in polytomous situations. Specifically, an automaton suitable for assessing knowledge in the SOLO taxonomy situation is proposed, and a questioning rule is provided based on the quasi-order relation between items. Then, relying on the automaton state update and the questioning rule, an automata knowledge assessment process for knowledge assessment in the SOLO taxonomy situation is given. Finally, empirical research and simulation experiments show that it is necessary to provide a questioning rule for the automaton and that the automata knowledge assessment process proposed in this paper is feasible.},
  archive      = {J_ISCI},
  author       = {Yin-Feng Zhou and Hai-Long Yang and Jin-Jin Li and Yi-Dong Lin},
  doi          = {10.1016/j.ins.2023.120058},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120058},
  shortjournal = {Inf. Sci.},
  title        = {Automata for knowledge assessment based on the structure of observed learning outcome taxonomy},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using outlier elimination to assess learning-based
correspondence matching methods. <em>ISCI</em>, <em>659</em>, 120056.
(<a href="https://doi.org/10.1016/j.ins.2023.120056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning (DL) technology has been widely used in correspondence matching. The learning-based models are usually trained on benign image pairs with partial overlaps. Since DL model is usually data-dependent, non-overlapping images may be used as poison samples to fool the model and produce false registrations. In this study, we propose an outlier elimination-based assessment method (OEAM) to assess the registrations of learning-based correspondence matching method on partially overlapping and non-overlapping images. OEAM first eliminates outliers based on spatial paradox. Then OEAM implements registration assessment in two streams using the obtained core correspondence set. If the cardinality of the core set is sufficiently small, the input registration is assessed as a low-quality registration. Otherwise, it is assessed to be of high quality, and OEAM improves its registration performance using the core set. OEAM is a post-processing technique imposed on learning-based method. The comparison experiments are implemented on outdoor (YFCC100M) and indoor (SUN3D) datasets using four deep learning-based methods. The experimental results on registrations of partially overlapping images show that OEAM can reliably infer low-quality registrations and improve performance on high-quality registrations. The experiments on registrations of non-overlapping images demonstrate that learning-based methods are vulnerable to poisoning attacks launched by non-overlapping images, and OEAM is robust against poisoning attacks crafted by non-overlapping images.},
  archive      = {J_ISCI},
  author       = {Xintao Ding and Yonglong Luo and Biao Jie and Qingde Li and Yongqiang Cheng},
  doi          = {10.1016/j.ins.2023.120056},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120056},
  shortjournal = {Inf. Sci.},
  title        = {Using outlier elimination to assess learning-based correspondence matching methods},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The nesterov accelerated gradient algorithm for
auto-regressive exogenous models with random lost measurements:
Interpolation method and auxiliary model method. <em>ISCI</em>,
<em>659</em>, 120055. (<a
href="https://doi.org/10.1016/j.ins.2023.120055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For ARX models with random lost measurements, this article proposes an interpolation and auxiliary model based Nesterov accelerated gradient algorithm. This algorithm utilizes the interpolation and auxiliary model methods to fill in lost measurements. The parameters are estimated with better accuracy based on the interpolated input and predicted output data. Two simulation examples are presented to verify the effective of the proposed algorithm.},
  archive      = {J_ISCI},
  author       = {Fei Xu and Lianyuan Cheng and Jing Chen and Quanmin Zhu},
  doi          = {10.1016/j.ins.2023.120055},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120055},
  shortjournal = {Inf. Sci.},
  title        = {The nesterov accelerated gradient algorithm for auto-regressive exogenous models with random lost measurements: Interpolation method and auxiliary model method},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An evolutionary algorithm based on fully connected weight
networks for mixed-variable multi-objective optimization. <em>ISCI</em>,
<em>659</em>, 120053. (<a
href="https://doi.org/10.1016/j.ins.2023.120053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective optimization research has mostly focused on continuous-variable problems. However, real-world optimization problems often involve multiple types of variables (continuous, integer, and discrete) and multiple conflicting optimization objectives, called mixed-variable multi-objective optimization problems (MVMOPs). Discrete variables make the decision space of the problem discrete. In contrast, while different types of variables need different treatments by the evolutionary algorithm , which poses a challenge to the efficient search of the evolutionary algorithm . Therefore, we propose an evolutionary algorithm based on a fully connected weight network (FCWNEA). The fully connected network structure characterizes the entire decision space, the node access count records the frequency of visits to the node, and the weights of connections and the activity of variables estimate the distribution of the decision space. This information assists in generating offspring solutions. To evaluate the performance of the proposed algorithm, we conduct empirical experiments on different types of problems. The results show that the proposed algorithm has a significant advantage in mixed-variable multi-objective problems. Moreover, the proposed algorithm is also quite competitive in continuous problems and can better handle the correlation between variables in optimization problems.},
  archive      = {J_ISCI},
  author       = {Nanjiang Dong and Tao Zhang and Rui Wang and Xiangke Liao and Ling Wang},
  doi          = {10.1016/j.ins.2023.120053},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120053},
  shortjournal = {Inf. Sci.},
  title        = {An evolutionary algorithm based on fully connected weight networks for mixed-variable multi-objective optimization},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-agent cooperative operation based on cross-domain
zero-shot learning. <em>ISCI</em>, <em>659</em>, 120052. (<a
href="https://doi.org/10.1016/j.ins.2023.120052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent systems (MAS) based on reinforcement learning have shown impressive performance in complex tasks. However, they are still weak when it comes to addressing tasks without any samples. In this paper, we design a 2D ground and a 3D underwater cooperative task, which serve as the source and target tasks, respectively. The MAS requires learning prior knowledge that can be generalized to the target task from the source task. To solve this problem, we propose cross-domain zero-shot learning (CDZSL) for MAS cooperative operation. Specifically, we first construct a state transition graph by decomposing the source tasks into multiple state phases. Subsequently, we describe the task description document for MAS and construct the task-related semantic embedding space, which effectively combats the semantic gap . Then, we propose zero-shot learning based on feature synthesis mapping (FSM), which synthesizes the feature centers of the unseen classes by the features of seen classes. During knowledge transfer, FSM is employed to assist MAS&#39;s decisions-making in the target task. Finally, extensive experiments show that CDZSL, compared with MAX-Q, improves the adaptability of MAS, where the cost of physical time for the first time to complete the new task is reduced by eight times.},
  archive      = {J_ISCI},
  author       = {Cheng Ding and Zhi Zheng},
  doi          = {10.1016/j.ins.2023.120052},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120052},
  shortjournal = {Inf. Sci.},
  title        = {Multi-agent cooperative operation based on cross-domain zero-shot learning},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generated admissible orders for intervals by matrices and
continuous functions. <em>ISCI</em>, <em>659</em>, 120051. (<a
href="https://doi.org/10.1016/j.ins.2023.120051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we systematically study the algebraic structures of the spaces L ( [ 0 , 1 ] ) L([0,1]) , encompassing all closed subintervals of [ 0 , 1 ] [0,1] , under the generated admissible orders. We first prove that the admissible order on L ( [ 0 , 1 ] ) L([0,1]) generated by a non-degenerate matrix must be the form of two weighted averaging operators . As a corollary, we deduce that each admissible order on L ( [ 0 , 1 ] ) L([0,1]) generated by a non-degenerate matrix and the standard order ≤ on [ 0 , 1 ] [0,1] are not isomorphic. Furthermore, we show that each admissible order on L ( [ 0 , 1 ] ) L([0,1]) derived from two continuous mappings and the standard order ≤ on [ 0 , 1 ] [0,1] are not isomorphic, partially answering a conjecture proposed by Santana et al. (2020) [38] . Besides, we prove that L ( [ 0 , 1 ] ) L([0,1]) is a complete lattice under the admissible order generated by two continuous mappings. This is the first result regarding the completeness of L ( [ 0 , 1 ] ) L([0,1]) . Finally, we apply the admissible orders to solve a minimal path problem within the context of interval-valued fuzzy weighted graph . The above results theoretically refine the study of the classification, non-isomorphism, and completeness of admissible orders, while expanding the scope of interval-valued fuzzy sets in practical applications.},
  archive      = {J_ISCI},
  author       = {Xinxing Wu and Shyi-Ming Chen and Xu Zhang},
  doi          = {10.1016/j.ins.2023.120051},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120051},
  shortjournal = {Inf. Sci.},
  title        = {Generated admissible orders for intervals by matrices and continuous functions},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An explainable prediction method based on fuzzy rough sets,
TOPSIS and hexagons of opposition: Applications to the analysis of
information disorder. <em>ISCI</em>, <em>659</em>, 120050. (<a
href="https://doi.org/10.1016/j.ins.2023.120050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach for predicting and explaining instances of Information Disorder. The paper reports two significant findings: i) the use of structures of opposition to describe relationships between instances of Information Disorder, and ii) the development of an explainable prediction method that combines Fuzzy Rough Sets and TOPSIS with these structures. The findings have the potential to assist analysts and decision-makers in gaining a deeper understanding of the phenomenon of Information Disorder. The results are based on real data and demonstrate promising applications for future research.},
  archive      = {J_ISCI},
  author       = {Angelo Gaeta and Vincenzo Loia and Francesco Orciuoli},
  doi          = {10.1016/j.ins.2023.120050},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120050},
  shortjournal = {Inf. Sci.},
  title        = {An explainable prediction method based on fuzzy rough sets, TOPSIS and hexagons of opposition: Applications to the analysis of information disorder},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DDEP: Evolutionary pruning using distilled dataset.
<em>ISCI</em>, <em>659</em>, 120048. (<a
href="https://doi.org/10.1016/j.ins.2023.120048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network pruning has been a hot topic in recent years, and many popular pruning methods rely on network design expertise. However, the pruning process usually involves manual intervention and can be difficult for users who lack prior knowledge. Automatic pruning using evolutionary algorithms shows great promise, but it must address the challenge of performing time-consuming model evaluations and searching through a large solution space . Dataset distillation is a technique that compresses the original dataset to decrease the cost of fine-tuning models. In this paper, we explore the potential of using the distilled dataset to exhibit a similar role as the real dataset in network pruning, and proposed the evolutionary pruning framework using distilled dataset. Specifically, the network pruning pipeline is carried out on the distilled dataset to significantly reduce the model evaluation cost, and the number of filters in the convolutional layer is directly coded to narrow the search space . In addition, a tailored evolutionary algorithm is proposed that takes the form of constrained optimization to search the most suitable pruned network. The experiments conducted on VGG16, VGG19 , ResNet56, and ResNet110 demonstrate that the proposed method reduces at least 41.56% of the flops and achieves competitive results with little compromising accuracy.},
  archive      = {J_ISCI},
  author       = {Xingwang Wang and Yafeng Sun and Xinyue Chen and Haixiao Xu},
  doi          = {10.1016/j.ins.2023.120048},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120048},
  shortjournal = {Inf. Sci.},
  title        = {DDEP: Evolutionary pruning using distilled dataset},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Noise-aware and correlation analysis-based for fuzzy-rough
feature selection. <em>ISCI</em>, <em>659</em>, 120047. (<a
href="https://doi.org/10.1016/j.ins.2023.120047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection has gained significant attention, with a focus on removing redundant or irrelevant features to improve subsequent machine learning tasks. The fuzzy rough set is extensively utilized for feature selection because of its ability to manage uncertainty. The fuzzy dependency-based approach represents an effective branch within the domain of fuzzy rough set models. However, it has been revealed that fuzzy dependency function is not robust to noise data while the noise objects often occur. Furthermore, as the size of dataset increases, the computational complexity of evaluating metrics also tends to increase due to potentially unnecessary computational effort . Hence, to address both of these research issues simultaneously, we propose a f uzzy r ough c orrelation- b ased feature selection algorithm , denoted as FRCB. The introduction of neighborhood radius constraints and granularity conditions aims to interpret and mitigate the impact of noisy data by partitioning objects into a Core-Boundary-Outlier structure. A more robust hybrid fuzzy relation and correlation-based fuzzy rough dependency is proposed by considering the representativeness and attractiveness of the core to other objects within the internal class, as well as the impacts on other objects in external classes. To minimize processing overhead and time complexity, redundant features are identified through correlation analysis, which involves evaluating, ranking, and grouping before proceeding to the next iteration. The experiments were conducted using eleven datasets. The analysis of the noise curves and the raw data curve indicates that the proposed correlation-based fuzzy rough dependency is more robust than other benchmarking methods. Moreover, the results of the classification and running time comparisons indicate that the FRCB algorithm proposed in this study exhibits superior performance compared to the baseline methods .},
  archive      = {J_ISCI},
  author       = {Haiqing Zhang and Xi Yu and Tianrui Li and Daiwei Li and Dan Tang and Lei He},
  doi          = {10.1016/j.ins.2023.120047},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120047},
  shortjournal = {Inf. Sci.},
  title        = {Noise-aware and correlation analysis-based for fuzzy-rough feature selection},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy fractional epidemiological model for middle east
respiratory syndrome coronavirus on complex heterogeneous network using
caputo derivative. <em>ISCI</em>, <em>659</em>, 120046. (<a
href="https://doi.org/10.1016/j.ins.2023.120046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a new fuzzy fractional epidemiological model to investigate the Middle East respiratory syndrome coronavirus on a complex heterogeneous network using fuzzy Caputo gH -differentiability. The model configuration follows a susceptible-infectious-susceptible (SIS) structure for human and camel populations. The equations for the camel population are developed due to its significant role as an animal source for spreading the virus, together with the direct interaction between human and animal populations. Some characteristic properties and results are extracted using fuzzy Caputo derivative . Theoretical findings regarding the existence and uniqueness of mild solutions to fuzzy initial value problems are presented using the general contraction principle . The virus outbreak behavior is discussed using two approaches: an analytical approach using fuzzy Laplace transform and a proposed numerical scheme using integral equations. To enhance the novelty of the work, the proposed numerical scheme is used to solve the fuzzy fractional epidemiological model and provides graphical representations to illustrate the uncertain behavior of the fractional epidemiological model. These numerical experiments show that the magnitude of the disease effect depends on the fractional order and the value of degree in the network. The results of this study suggest that we can overcome the impact of spreading the disease by adhering to infection prevention measures when dealing with animal populations.},
  archive      = {J_ISCI},
  author       = {Ghulam Muhammad and Muhammad Akram},
  doi          = {10.1016/j.ins.2023.120046},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120046},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy fractional epidemiological model for middle east respiratory syndrome coronavirus on complex heterogeneous network using caputo derivative},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EM-IFCM: Fuzzy c-means clustering algorithm based on edge
modification for imbalanced data. <em>ISCI</em>, <em>659</em>, 120029.
(<a href="https://doi.org/10.1016/j.ins.2023.120029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The improved fuzzy c-means (IFCM) algorithm is an effective technique for handling the “uniform effect” in imbalanced data clustering ; it adjusts the weight of each class based on the fuzzy size between clusters. However, the IFCM algorithm produces a “siphon effect” as the imbalance rate increases. It misclassifies the samples in small classes into large ones. Our analysis shows that this effect occurs because all samples have the same weight value of the same classes, the membership values are polarized, resulting in the model failing to converge to the correct interval. Thus, we propose an imbalanced fuzzy c-means clustering based on edge modification (EM-IFCM) algorithm to alleviate the “siphon effect” of the IFCM algorithm. It exhibits stronger inter-class separability by dynamically adjusting the weight of the samples to enhance the influence of edge samples on the model. In addition, we analyze the effectiveness and complexity of the algorithm and proved its convergence. Finally, we conduct extensive experiments on synthesis, machine-learning, and image-segmentation datasets and compare the results with those of six algorithms. The experimental results show that EM-IFCM has higher accuracy and exhibits an imbalance rate that is at least 1.94 times higher than that of the other algorithms.},
  archive      = {J_ISCI},
  author       = {Yue Pu and Wenbin Yao and Xiaoyong Li},
  doi          = {10.1016/j.ins.2023.120029},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120029},
  shortjournal = {Inf. Sci.},
  title        = {EM-IFCM: Fuzzy c-means clustering algorithm based on edge modification for imbalanced data},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ordinal motifs in lattices. <em>ISCI</em>, <em>659</em>,
120009. (<a href="https://doi.org/10.1016/j.ins.2023.120009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lattices are a commonly used structure for the representation and analysis of relational and ontological knowledge. In particular, the analysis of these requires a decomposition of a large and high-dimensional lattice into a set of understandably large parts. With the present work we propose /ordinal motifs/ as analytical units of meaning. We study these ordinal substructures (or standard scales) through order-embeddings and (full) scale-measures of formal contexts from the field of formal concept analysis. We show that the underlying decision problems are NP-complete and provide results on how one can incrementally identify ordinal motifs to save computational effort . Accompanying our theoretical results, we demonstrate how ordinal motifs can be leveraged to achieve textual explanations based on principles from human computer interaction .},
  archive      = {J_ISCI},
  author       = {Johannes Hirth and Viktoria Horn and Gerd Stumme and Tom Hanika},
  doi          = {10.1016/j.ins.2023.120009},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120009},
  shortjournal = {Inf. Sci.},
  title        = {Ordinal motifs in lattices},
  volume       = {659},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Perception and expression-based dual expert decision-making
approach to information sciences with integrated quantum fuzzy modelling
for renewable energy project selection. <em>ISCI</em>, <em>658</em>,
120073. (<a href="https://doi.org/10.1016/j.ins.2023.120073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Choosing the right projects in renewable energy investments is very significant. Due to this issue, necessary improvements to the performance indicators of these projects should be made. However, every improvement made also leads to an increase in costs. There is a need for a priority analysis to find the most important factors affecting the selection of the right renewable energy projects. Accordingly, this study aims to evaluate critical determinants of renewable energy project selection and provide effective investment strategies for this situation with a new fuzzy decision-making model. First, the indicators of renewable energy project selection are analyzed by perception and expression-based quantum Spherical fuzzy M−SWARA. The weights of these determinants are also calculated by DEMATEL to check the reliability of the results. Secondly, the priorities of renewable energy project selection are ranked by considering perception and expression-based quantum Spherical fuzzy ELECTRE. This calculation is also made by TOPSIS methodology to measure the reliability of the findings. The main contribution of this manuscript is that perception and expression-based evaluation can be carried out in the proposed model. In this process, the facial expressions and emotions of the decision makers are considered so that the hesitancy of these people while answering these questions can be included in the evaluation process. Another important novelty is that a new decision-making model (M−SWARA) is also proposed. This new technique provides an opportunity to consider causality relationship between the criteria to reach the most significant ones. The weighting results are the same for both M−SWARA and DEMATEL approaches. This situation gives information that the findings are coherent and valid. Market analysis has the greatest value in both perception-based (0.272) and expression-based (0.259) evaluations. Owing to this analysis, it is possible to clearly understand the supply–demand balance in the market. The ranking results indicate that technical adequacy is the most significant priority alternative for the selection of the appropriate renewable energy alternatives.},
  archive      = {J_ISCI},
  author       = {Gang Kou and Dragan Pamucar and Hasan Dinçer and Muhammet Deveci and Serhat Yüksel and Muhammad Umar},
  doi          = {10.1016/j.ins.2023.120073},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120073},
  shortjournal = {Inf. Sci.},
  title        = {Perception and expression-based dual expert decision-making approach to information sciences with integrated quantum fuzzy modelling for renewable energy project selection},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning approach for detection of unfavorable driving
state based on multiple phase synchronization between multi-channel EEG
signals. <em>ISCI</em>, <em>658</em>, 120070. (<a
href="https://doi.org/10.1016/j.ins.2023.120070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, electroencephalogram (EEG) signals have gained significant popularity in the detection and recognition of drivers&#39; unfavorable driving states (UDS) and related aspects. However, the methods that rely on traditional EEG features and evaluate different electrodes or brain regions separately have somewhat limited the further development of recognition effectiveness. To address this, this study analyzes the phase relationships between electrodes in EEG signals to reveal the functional networks and connectivity patterns within the brain. Three phase synchronization (PS) methods, namely phase locking value (PLV), corrected imaginary phase locking value (CIPLV), and weighted phase lag index (WPLI), are used to construct connectivity matrices and networks in six classic sub-rhythmic bands. Additionally, a 2D convolutional neural network (CNN) with fewer learning parameters is designed to automatically learn high-level abstractions and the most discriminative features , thereby avoiding the laborious and subjective process of manual feature extraction. The proposed method has been compared with traditional classification algorithms using a leave-one-out cross-validation strategy. The comparative results indicate that our proposed approach, which combines WPLI phase synchronization in the gamma1 sub-rhythmic band with a pyramid-structured CNN model , achieves significantly higher accuracy in recognizing drivers&#39; UDS than other conventional methods through a one-way analysis of variance (ANOVA) followed by post hoc multiple comparisons with Tukey analysis. Furthermore, our proposed 2D-CNN model contains fewer parameters, making it more competitive for further practical applications in real-world driving scenarios.},
  archive      = {J_ISCI},
  author       = {Jichi Chen and Yuguo Cui and Hong Wang and Enqiu He and Adi Alhudhaif},
  doi          = {10.1016/j.ins.2023.120070},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120070},
  shortjournal = {Inf. Sci.},
  title        = {Deep learning approach for detection of unfavorable driving state based on multiple phase synchronization between multi-channel EEG signals},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GradDiff: Gradient-based membership inference attacks
against federated distillation with differential comparison.
<em>ISCI</em>, <em>658</em>, 120068. (<a
href="https://doi.org/10.1016/j.ins.2023.120068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Membership inference attacks (MIAs) has demonstrated a great threat to federated learning (FL) and its extension federated distillation (FD). However, existing research on MIAs against FD is insufficient. In this paper, we propose a novel membership inference attack named GradDiff, which is a passive gradient-based MIA employing differential comparison. Additionally, to make full use of the federated training process, we also design the gradient drift attack (GradDrift), an active version of GradDiff, in which the attacker modifies the target model by gradient tuning and is able to obtain more information about membership privacy. We conduct extensive experiments on three real-world datasets to evaluate the effectiveness of the proposed attacks. The results show that our proposed attacks can outperform the existing baseline methods in terms of precision and recall. Besides, we perform a thorough investigation of the factors that may influence the performance of MIAs against FD.},
  archive      = {J_ISCI},
  author       = {Xiaodong Wang and Longfei Wu and Zhitao Guan},
  doi          = {10.1016/j.ins.2023.120068},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120068},
  shortjournal = {Inf. Sci.},
  title        = {GradDiff: Gradient-based membership inference attacks against federated distillation with differential comparison},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DeepSecDrive: An explainable deep learning framework for
real-time detection of cyberattack in in-vehicle networks.
<em>ISCI</em>, <em>658</em>, 120057. (<a
href="https://doi.org/10.1016/j.ins.2023.120057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous driving (AD) technologies are becoming increasingly popular, promising significant enhancements in road safety and efficiency. However, the susceptibility of autonomous vehicles to cyberattacks highlights the critical need for protecting the security and dependability of in-vehicular networks (IVNs). This study proposes a lightweight, efficient, and explainable deep learning framework, DeepSecDrive, for early detection of security threats against IVN. DeepSecDrive presents robust feature extractor units designed with deformable convolutions and a lightweight non-local network (LNLN). The former promotes dynamic change of receptive field to enhance extraction of complex features from the traffics of in-vehicle networks, while the latter enables learning contextual representations and non-local relationships in vehicular data. DeepSecDrive integrates Shapley Additive exPlanations to construct multi-level interpretability units, providing local and global explanations for model decisions in terms of feature contributions to the overall performance. Proof-of-concept experiments are conducted to evaluate the efficacy and durability of DeepSecDrive on real-world IVN attacks from Car-Hacking dataset, and the experimental results demonstrate the ability of our model to outperform state-of-the-art detection methods.},
  archive      = {J_ISCI},
  author       = {Weiping Ding and Ibrahim Alrashdi and Hossam Hawash and Mohamed Abdel-Basset},
  doi          = {10.1016/j.ins.2023.120057},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120057},
  shortjournal = {Inf. Sci.},
  title        = {DeepSecDrive: An explainable deep learning framework for real-time detection of cyberattack in in-vehicle networks},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An electronic medical record access control model based on
intuitionistic fuzzy trust. <em>ISCI</em>, <em>658</em>, 120054. (<a
href="https://doi.org/10.1016/j.ins.2023.120054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic Medical Records (EMR), as the core data of medical big data , has improved the efficiency of medical services in the process of sharing and use, but a series of data privacy leakage problems have emerged. Access control technology can ensure users&#39; legitimate and appropriate access to data resources, but traditional access control has many limitations such as static and coarse-grained, which is difficult to meet in the dynamic and complex healthcare environment. We create a model to solve the privacy leakage problem of healthcare big data. The model utilizes the Latent Delicacy Allocation (LDA) topic model to quickly search documents and extract the topic probability distributions between the target patient and other patients&#39; electronic medical records, which improves the efficiency of medical record document analysis; Calculating physician access similarity, we quantify physician access behavior to more accurately describe physician access behavior in the form of data. We combined the intuitionistic fuzzy theory with the trust evaluation method to create a novel trust evaluation method-- Intuitionistic Fuzzy Trust Evaluation Method, which can reflect the uncertainty characteristics that exist in the physician&#39;s diagnostic and treatment process when quantifying the trust of the access by using this method, and it is more flexible and practical, which enhances the accuracy of the quantification of the trust. Improving the traditional trust aggregation method by adding a time window and time decay function, the optimized method improves the accuracy of trust aggregation, and the experimental results are more in line with the actual law. We created a new intuitionistic fuzzy trust access control model using a relative entropy-based intuitionistic fuzzy clustering algorithm and a reward and punishment mechanism to achieve adaptive and dynamic access control for physician access behavior. Experiments show that the access control model based on intuitionistic fuzzy trust proposed in this article achieves 95% correctness in identifying user access behaviors and 94.29% correctness in identifying excessive user access behaviors. Experiments have proved that this model has obvious advantages over other models in the process of privacy protection of electronic medical record systems and has certain control effects.},
  archive      = {J_ISCI},
  author       = {Rong Jiang and Rui Liu and Tao Zhang and Weiping Ding and Shenghu Tian},
  doi          = {10.1016/j.ins.2023.120054},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120054},
  shortjournal = {Inf. Sci.},
  title        = {An electronic medical record access control model based on intuitionistic fuzzy trust},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A sequential three-way decision model for classification
with multilevel information gain and regret value optimization.
<em>ISCI</em>, <em>658</em>, 120041. (<a
href="https://doi.org/10.1016/j.ins.2023.120041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sequential three-way decision (S3WD) model plays a vital role in solving classification problems. This model comprises three fundamental elements, namely, conditional probability , cost function , and decision thresholds. The typical conditional probability estimation methods are bifurcated into two branches: equivalence class-based methods, which coincide with human recognition, and machine learning-based methods that rely on big data for high precision. This study synergizes two branches by introducing a novel algorithm that integrates the K-nearest neighbor method and Bayes rule for estimating conditional probabilities, enhancing both interpretability and precision. Regarding the cost function and decision thresholds, the inherent weak point in existing cost-sensitive S3WD models is the computation of three pairwise adjacent regions with subjectively given cost values and decision thresholds. To overcome the subjective arbitrariness bottleneck, an objective function is established by extending the definitions of information gain and regret value across a multilevel granularity structure. Subsequently, an adapted particle swarm optimization algorithm is utilized to optimize the decision thresholds and tri-partitions. Accordingly, a novel framework of the S3WD model is constructed. Finally, extensive experimental results substantiate the effectiveness and superiority of the proposed model in the realm of classification, as evidenced from both technical and empirical standpoints.},
  archive      = {J_ISCI},
  author       = {Pei Liang and Dingfei Lei and Xianglang Gao and Junhua Hu and KwaiSang Chin},
  doi          = {10.1016/j.ins.2023.120041},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120041},
  shortjournal = {Inf. Sci.},
  title        = {A sequential three-way decision model for classification with multilevel information gain and regret value optimization},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A provably stable neural network turing machine with finite
precision and time. <em>ISCI</em>, <em>658</em>, 120034. (<a
href="https://doi.org/10.1016/j.ins.2023.120034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a neural stack architecture with a differentiable parameterized stack operator approximating stack push and pop operations. We prove the stability of this stack architecture for arbitrarily many stack operations, showing that the state of the neural stack still closely resembles the state of a discrete stack. Using the neural stack with a recurrent neural network , we devise a neural network Pushdown Automaton (nnPDA). A new theoretical bound shows that an nnPDA can recognize any PDA using only finite precision state neurons in finite time . By using two neural stacks to construct a neural tape together with a recurrent neural network , we define a neural network Turing Machine (nnTM). Just like the neural stack, we show these architectures are also stable. Furthermore, we show the nnTM is Turing complete. It requires finite precision state neurons with an arbitrary number of stack neurons to recognize any TM in finite time, thus providing a new and much stronger computational upper bound for neural networks that are Turing complete.},
  archive      = {J_ISCI},
  author       = {John Stogin and Ankur Mali and C. Lee Giles},
  doi          = {10.1016/j.ins.2023.120034},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120034},
  shortjournal = {Inf. Sci.},
  title        = {A provably stable neural network turing machine with finite precision and time},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised generative adversarial networks for improved
colorectal polyp classification using histopathological images.
<em>ISCI</em>, <em>658</em>, 120033. (<a
href="https://doi.org/10.1016/j.ins.2023.120033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early and accurate detection of dysplasia in colorectal polyps can improve prognosis and increase survival chances. Recently, automated learning-based approaches using histopathological images have been adopted for improved classification of polyps. The supervised learning approaches do not provide a reliable classification performance due to limited annotated samples. But, in unsupervised learning , some hidden features are extracted from the unlabeled data which may not be effective in discriminating the complex patterns of the dataset. A generative adversarial network (GAN) is proposed in this work based on a semi-supervised framework for colorectal polyp classification using histopathological images. Our framework learns the discriminating features in an adversarial manner from the limited labeled and huge unlabeled data. In the supervised mode, the discriminator of the proposed model is trained to classify the real histopathological images, whereas, in the unsupervised mode, it tries to discriminate between real and fake images, similar to the classical GAN network. By training in unsupervised mode, the discriminator can identify and extract the subtle features from unlabeled images, to develop a generalized robust model. Our technique yielded classification accuracies of 87.50% and 76.25% using 25% and 50% majority voting schemes, respectively, on the UniToPatho dataset.},
  archive      = {J_ISCI},
  author       = {Pradipta Sasmal and Vanshali Sharma and Allam Jaya Prakash and M.K. Bhuyan and Kiran Kumar Patro and Nagwan Abdel Samee and Hayam Alamro and Yuji Iwahori and Ryszard Tadeusiewicz and U. Rajendra Acharya and Paweł Pławiak},
  doi          = {10.1016/j.ins.2023.120033},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120033},
  shortjournal = {Inf. Sci.},
  title        = {Semi-supervised generative adversarial networks for improved colorectal polyp classification using histopathological images},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Question-response representation with dual-level contrastive
learning for improving knowledge tracing. <em>ISCI</em>, <em>658</em>,
120032. (<a href="https://doi.org/10.1016/j.ins.2023.120032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question-response representation (aka. embedding) lies at the core for knowledge tracing, which is pivotal to model students&#39; evolving knowledge states for predicting their future performance. Existing efforts typically learn question-response representations in a supervised manner, thus inevitably neglecting to excavate implicit information existed in student-question-concept connections and suffering from the issue of data sparsity due to rare student-question interactions. Inspired by the recent success of self-supervised learning, in this paper, we propose a Q uestion- R esponse representation with dual-level C ontrastive L earning ( QRCL ) for improving knowledge tracing, to address the aforementioned problems. Our approach comprehensively considers three types of views for obtaining question-response representations: the native fold views derived from native interaction between students and questions, the augmented fold views generated by contrastive augmentation with Singular Value Decomposition (SVD), and the co-response relation views acquired by means of correlation among questions. By using delicately designed contrastive rules, Graph Neural Networks (GNNs) are adopted as backbone to encode the information from each view for better generating question-response representation. Extensive experimental results conducted on five datasets clearly show our proposed method has the capability in effectively predicting students&#39; performances.},
  archive      = {J_ISCI},
  author       = {Yan Zhao and Huifang Ma and Jing Wang and Xiangchun He and Liang Chang},
  doi          = {10.1016/j.ins.2023.120032},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120032},
  shortjournal = {Inf. Sci.},
  title        = {Question-response representation with dual-level contrastive learning for improving knowledge tracing},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A dynamic adaptive multi-view fusion graph convolutional
network recommendation model with dilated mask convolution mechanism.
<em>ISCI</em>, <em>658</em>, 120028. (<a
href="https://doi.org/10.1016/j.ins.2023.120028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Networks (GCNs) has shown promise in recommendation systems. However, a critical issue known as the over-smoothing problem has been identified in GCN models. This problem arises as the number of layers in the model increases, leading to a decrease in model performance due to node representations becoming excessively similar. Various strategies have been proposed to combat this issue, like preserving node-specific information or introducing high-order neighbors. Unfortunately, these approaches overlook a crucial factor known as Visual Overlap Strength (VOS), which plays a significant role in the over-smoothing problem. VOS measures the extent of neighborhood overlap between nodes in the graph. To address the over-smoothing problem, this paper offers a comprehensive analysis of the issue and introduces the concept of VOS between nodes. We present a novel solution in the form of the Dynamic Adaptive Multi-view fusion GCN model with dilAted maSK convolution mechanism (DAMASK-GCN). This model dynamically adjusts the perceptual field of nodes, captures high-order information, and alleviates the impact of VOS through the utilization of dilated mask convolution and an adaptive attention fusion mechanism. Extensive experiments on six popular recommendation system datasets demonstrate DAMASK-GCN&#39;s effectiveness in reducing over-smoothing and outperforming existing GCN-based recommendation models.},
  archive      = {J_ISCI},
  author       = {Jian Liao and Feng Liu and Jianxing Zheng and Suge Wang and Deyu Li and Qian Chen},
  doi          = {10.1016/j.ins.2023.120028},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120028},
  shortjournal = {Inf. Sci.},
  title        = {A dynamic adaptive multi-view fusion graph convolutional network recommendation model with dilated mask convolution mechanism},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-interference assessment in colored net systems via
integer linear programming. <em>ISCI</em>, <em>658</em>, 120027. (<a
href="https://doi.org/10.1016/j.ins.2023.120027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event-related information leaks are a potential security hazard in information systems . Non-interference is a security property to describe event-related information security. Non-interference assessment is to detect whether a public observer can infer the occurrences of private events from the observation of public ones. To assess the non-interference of information systems, the utilization of formal modeling tools, especially Petri nets (PNs), is an effective way used in most previous works. However, for large-scale systems, non-interference assessment leads to the problem of state explosion in the context of basic net systems (NSs) defined by PNs. In this paper, considering the structural similarity of large-scale systems, colored PNs are used to model them more compactly and efficiently. We focus on the assessment of two typical non-interference properties, i.e., strong nondeterministic non-interference (SNNI) and bisimulation SNNI (BSNNI), in colored NSs (CNSs). Specifically, we propose a non-interference assessment method for bounded CNSs based on the definitions of SNNI and BSNNI in the context of CNSs. This method involves coarse and fine assessments. A coarse assessment is achieved via integer linear programming (ILP) by leveraging the structural similarity of systems. In contrast, the fine assessment can be fulfilled using ILP-based analysis or firing way analysis based on the results obtained by the coarse assessment, which is not essentially necessary. In particular, a fine assessment is necessary only if a coarse assessment is failed to obtain accurate assessment results. Finally, efficiency analysis reveals that our method reduces assessment redundancy and improves assessment efficiency.},
  archive      = {J_ISCI},
  author       = {Wenjing Zhong and Jinjing Zhao and Hesuan Hu},
  doi          = {10.1016/j.ins.2023.120027},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120027},
  shortjournal = {Inf. Sci.},
  title        = {Non-interference assessment in colored net systems via integer linear programming},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust adaptive filtering based on m-estimation-based
minimum error entropy criterion. <em>ISCI</em>, <em>658</em>, 120026.
(<a href="https://doi.org/10.1016/j.ins.2023.120026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Renyi’s entropy, as a crucial similarity measure of information quantity, is the cornerstone of the minimum error entropy (MEE) criterion. However, the conventional MEE cost had to employ a computationally feasible estimator to approximate the error entropy directly from the data samples, which could be contaminated by large interference outliers, and the performance of MEE could deteriorate in the presence of complex non-Gaussian noises. To address this problem, utilizing the robust statistical properties of M-estimation, the M-estimators are introduced to the MEE criterion by down-weighting or discarding large error residuals; we can then proceed to obtain a more accurate Renyi’s-entropy estimator compared to the empirical form under the recalculated error distribution. This innovative approach could be simply implemented while ensuring great robustness. Therefore, a robust adaption criterion called the M-estimation-based minimum error entropy (MMEE), and its corresponding adaptive filtering algorithm are proposed that detect and bound the influence of outliers in non-Gaussian noise. In addition, the mean stability and steady-state performance of the proposed MMEE are evaluated, furthermore, we theoretically prove that the MMEE algorithm could achieve lower steady-state error than MEE under the same conditions. Simulation results verify our theoretical predictions, and demonstrate the superiority and robustness of the MMEE algorithm compared with several existing robust filtering algorithms for restraining various non-Gaussian noises.},
  archive      = {J_ISCI},
  author       = {Shan Zhong and Ziyi Wang and Gang Wang and Yuzheng Zhou and Xingli Zhou and Bei Peng},
  doi          = {10.1016/j.ins.2023.120026},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120026},
  shortjournal = {Inf. Sci.},
  title        = {Robust adaptive filtering based on M-estimation-based minimum error entropy criterion},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A full process algebraic representation of ant colony
optimization. <em>ISCI</em>, <em>658</em>, 120025. (<a
href="https://doi.org/10.1016/j.ins.2023.120025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a process algebra capable of specifying parallelized Ant Colony Optimization algorithms in full detail: PA 2 CO. After explaining the basis of three different ACO algorithms (Ant System, MAX-MIN Ant System, and Ant Colony System), we formally define PA 2 CO and use it for representing several types of implementations with different parallel schemes. In particular fine-grained and coarse-grained specifications, each one taking advantage of parallel executions at different levels of system granularity , are formalized.},
  archive      = {J_ISCI},
  author       = {María García and Natalia López and Ismael Rodríguez},
  doi          = {10.1016/j.ins.2023.120025},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120025},
  shortjournal = {Inf. Sci.},
  title        = {A full process algebraic representation of ant colony optimization},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A neural tensor decomposition model for high-order sparse
data recovery. <em>ISCI</em>, <em>658</em>, 120024. (<a
href="https://doi.org/10.1016/j.ins.2023.120024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor decomposition has attracted wide attention in the low-rank tensor completion (LRTC) problem because of its marvelous recovering ability to missing entries. However, previous LRTC methods are generally based on linear and shallow models, which are prone to overfitting when the data is sparse, resulting in significantly degraded performance. Meanwhile, the models are highly sensitive and suffer from the difficult rank selection problem. To address these issues, we propose an effective and novel tensor-ring (TR) decomposition method based on the convolutional computation (ConvTR), which can be regarded as a natural extension of deep learning models for the LRTC problem. Specifically, ConvTR employs a multi-layer convolutional neural network (CNN) to model the complex interactions between TR factors. Each element in the index vector of the observation tensor can be embedded as a corresponding tensor slice in the factor tensor decomposed by the TR model. These individual slice matrices are then concatenated to get a wider matrix used for extracting the nonlinear features by feeding them into a 2D convolutional layer . A fully-connected layer is utilized to aggregate the final convoluted features to a scalar value , which is the desired missing entry indexed by the original index vector exactly. Extensive experiments on various common datasets verified the effectiveness of the proposed method and demonstrated its superior to the traditional TR-based completion methods and other state-of-the-art network-based methods.},
  archive      = {J_ISCI},
  author       = {Tianchi Liao and Jinghua Yang and Chuan Chen and Zibin Zheng},
  doi          = {10.1016/j.ins.2023.120024},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120024},
  shortjournal = {Inf. Sci.},
  title        = {A neural tensor decomposition model for high-order sparse data recovery},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A data-driven fault detection approach for unknown
large-scale systems based on GA-SVM. <em>ISCI</em>, <em>658</em>,
120023. (<a href="https://doi.org/10.1016/j.ins.2023.120023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the data-driven fault detection (FD) problem for large-scale systems with unknown system matrices and interconnection signals. Due to the existence of the unknown system matrices and interconnection terms, the FD problem of large-scale systems is hardly solved by the existing model-based methods. To tackle this problem, the interconnection terms are firstly estimated by the subspace intersection technique. Then, based on the estimated interconnection terms and input-output data, the support vector machine (SVM) is constructed to design fault detector for each subsystem. Furthermore, genetic algorithm (GA) is introduced to optimize the parameters of SVM such that FD performance is improved. Finally, a numerical example is adopted to illustrate the effectiveness of the developed FD approach.},
  archive      = {J_ISCI},
  author       = {Zhenlei Ma and Xiaojian Li and Jie Sun},
  doi          = {10.1016/j.ins.2023.120023},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120023},
  shortjournal = {Inf. Sci.},
  title        = {A data-driven fault detection approach for unknown large-scale systems based on GA-SVM},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RelJoin: Relative-cost-based selection of distributed join
methods for query plan optimization. <em>ISCI</em>, <em>658</em>,
120022. (<a href="https://doi.org/10.1016/j.ins.2023.120022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting appropriate distributed join methods for logical join operations in a query plan is crucial for the performance of data-intensive scalable computing (DISC). Different network communication patterns in the data exchange phase generate varying network communication workloads and significantly affect the distributed join performance. However, most cost-based query optimizers focus on the local computing cost and do not precisely model the network communication cost. We propose a cost model for various distributed join methods to optimize join queries in DISC platforms. Our method precisely measures the network and local computing workloads in different execution phases, using information on the size and cardinality statistics of datasets and cluster join parallelism . Our cost model reveals the importance of the relative size of the joining datasets. We implement an efficient distributed join selection strategy, known as RelJoin in SparkSQL, which is an industry-prevalent distributed data processing framework. RelJoin uses runtime adaptive statistics for accurate cost estimation and selects optimal distributed join methods for logical joins to optimize the physical query plan. The evaluation results on the TPC-DS benchmark show that RelJoin performs best in 62 of the 97 queries and can reduce the average query time by 21% compared with other strategies. 1},
  archive      = {J_ISCI},
  author       = {Feng Liang and Francis C.M. Lau and Heming Cui and Yupeng Li and Bing Lin and Chengming Li and Xiping Hu},
  doi          = {10.1016/j.ins.2023.120022},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120022},
  shortjournal = {Inf. Sci.},
  title        = {RelJoin: Relative-cost-based selection of distributed join methods for query plan optimization},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel deterministic and probabilistic forecasting methods
for crude oil price employing optimized deep learning, statistical and
hybrid models. <em>ISCI</em>, <em>658</em>, 120021. (<a
href="https://doi.org/10.1016/j.ins.2023.120021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, individual and hybrid methods are proposed employing optimized statistical and deep learning (DL) models for deterministic (point) and probabilistic (interval) forecasting of crude oil price time series. The statistical models are optimized using the Forecast package of R. To enhance the performance of DL models, a novel pruning DE-DL method is proposed, which employs the differential evolution (DE) algorithm to optimize architecture and continuous and discrete-valued hyper-parameters. The proposed DE-DL method is so generic that it can be applied to optimize different DL models for any supervised learning problem. Five DL models (LSTM, BiLSTM, GRU, CNN, and ConvLSTM) are optimized for forecasting monthly crude oil prices and hybridized with an optimized ARIMA model for developing optimized additive and multiplicative hybrid forecasting models. The effectiveness of the proposed methods is evaluated through deterministic and probabilistic forecasting measures, comparing the results with six optimized statistical models, thirteen machine learning models, five optimized DL models, and ten optimized hybrid models. It is observed from the simulation results that the proposed optimized Additive-ARIMA-GRU hybrid model provides statistically superior forecasts, and the t Location Scale distribution is more suitable than the Gaussian distribution for computing reliable prediction intervals with different significance levels.},
  archive      = {J_ISCI},
  author       = {Sourav Kumar Purohit and Sibarama Panigrahi},
  doi          = {10.1016/j.ins.2023.120021},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120021},
  shortjournal = {Inf. Sci.},
  title        = {Novel deterministic and probabilistic forecasting methods for crude oil price employing optimized deep learning, statistical and hybrid models},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Topological equivalence classification and enumeration of
n-input linearly separable boolean functions. <em>ISCI</em>,
<em>658</em>, 120020. (<a
href="https://doi.org/10.1016/j.ins.2023.120020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A perceptron , as an “artificial neuron”, plays a crucial role in the research of neural networks . As a mathematical model of linearly separable Boolean functions , perceptron neurons can realize any nonlinearly separable Boolean function. Linearly separable Boolean functions can be divided into a smaller number of the same functional classes. These functional classes are equivalent to the core basic units (AND, NOT, OR, and other components) that make up the circuit. Therefore, the research on the classification problem of linearly separable Boolean functions is very important. In this study, a novel algorithm, called a topological equivalence classification algorithm , is proposed for classifying balanced linearly separable Boolean functions. By the proposed algorithm, the total number of the topological equivalence classes and the number of balanced linearly separable Boolean functions in each of the topological equivalence classes are obtained. According to the one-to-one correspondence between n-input balanced linearly separable Boolean functions and n-1-input linearly separable Boolean functions, we get the topological classification of linearly separable Boolean functions. As for n = 9 n=9 , the accurate results of classification and counting the number of linearly separable Boolean functions are obtained: There are 53 , 063 , 448 53,063,448 topological equivalence classes, and the total number of linearly separable Boolean functions is 144 , 380 , 202 , 286 , 068 , 288 144,380,202,286,068,288 .},
  archive      = {J_ISCI},
  author       = {Qinbin He and Fangyue Chen and Wei Jin},
  doi          = {10.1016/j.ins.2023.120020},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120020},
  shortjournal = {Inf. Sci.},
  title        = {Topological equivalence classification and enumeration of n-input linearly separable boolean functions},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DGTRL: Deep graph transfer reinforcement learning method
based on fusion of knowledge and data. <em>ISCI</em>, <em>658</em>,
120019. (<a href="https://doi.org/10.1016/j.ins.2023.120019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning has shown promising application effects in many fields. However, issues such as low sample efficiency and weak knowledge transfer and generalization capabilities constrain its in-depth development. This paper proposes a deep graph transfer reinforcement learning method based on knowledge and data fusion. Through knowledge transfer between tasks and data training in exploration, efficient learning driven by knowledge and data fusion is realized. First, we map the trajectories of agents in the source and target domains into graph structures to represent knowledge and environmental models and use a graph matching method to match the knowledge adaptation domain based on similarity. Second, real-time transfer of source domain knowledge is carried out in a similar mapping domain, and policy mapping, verification, and adaptive transfer mechanisms based on knowledge reuse frequency are designed to effectively improve the transfer effect. Finally, we evaluate and validate the proposed algorithm, mechanism, and their application effectiveness in diverse and multitask knowledge transfer scenarios using three indicators in environments such as maze. The results show that the method improves the target task time indicators by 84.7% and 70% under the conditions of no verification exploration and a standard transfer setting, respectively, achieving significant knowledge reuse effects.},
  archive      = {J_ISCI},
  author       = {Genxin Chen and Jin Qi and Yu Gao and Xingjian Zhu and Zhenjiang Dong and Yanfei Sun},
  doi          = {10.1016/j.ins.2023.120019},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120019},
  shortjournal = {Inf. Sci.},
  title        = {DGTRL: Deep graph transfer reinforcement learning method based on fusion of knowledge and data},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DTC-MDD: A spatiotemporal data acquisition technology for
privacy-preserving in MCS. <em>ISCI</em>, <em>658</em>, 120018. (<a
href="https://doi.org/10.1016/j.ins.2023.120018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some attackers in the Internet of Things submit falsified high-quality data to cause harm to users. To prevent malicious workers from reporting untruthful data for skyline computation in Mobile Crowd Sensing, we propose a double trust check-based spatiotemporal data acquisition scheme, DTC-MDD. In DTC-MDD, worker trust uses four-way validation to obtain reliable worker trust evaluations. Then, based on Probabilistic Skyline Calculation, we propose a worker selection algorithm to select high-trust, high-quality workers for data reporting. We also introduce the Non-Interactive Encrypted Integer Comparison Protocol to safeguard privacy between workers and users from malicious attacks . Finally, through extensive simulations on real datasets, DTC-MDD effectively enhances the quality and security of spatiotemporal data acquisition. DTC-MDD improved the data quality and reliability of candidate worker sets by 16.2% and 49.1%, respectively, and the data quality and reliability of the first skyline worker by 21.4% and 320.0%, respectively.},
  archive      = {J_ISCI},
  author       = {Runfu Liang and Lingyi Chen and Anfeng Liu and Neal N. Xiong and Shaobo Zhang and Athanasios V. Vasilakos},
  doi          = {10.1016/j.ins.2023.120018},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120018},
  shortjournal = {Inf. Sci.},
  title        = {DTC-MDD: A spatiotemporal data acquisition technology for privacy-preserving in MCS},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A graph neural network with context filtering and feature
correction for conversational emotion recognition. <em>ISCI</em>,
<em>658</em>, 120017. (<a
href="https://doi.org/10.1016/j.ins.2023.120017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational emotion recognition represents an important machine-learning problem with a wide variety of deployment possibilities. The key challenge in this area is how to properly capture the key conversational aspects that facilitate reliable emotion recognition, including utterance semantics, temporal order, informative contextual cues, speaker interactions as well as other relevant factors. In this paper, we present a novel Graph Neural Network approach for conversational emotion recognition at the utterance level. Our method addresses the outlined challenges and represents conversations in the form of graph structures that naturally encode temporal order, speaker dependencies, and even long-distance context. To efficiently capture the semantic content of the conversations, we leverage the zero-shot feature-extraction capabilities of pre-trained large-scale language models and then integrate two key contributions into the graph neural network to ensure competitive recognition results. The first is a novel context filter that establishes meaningful utterance dependencies for the graph construction procedure and removes low-relevance and uninformative utterances from being used as a source of contextual information for the recognition task. The second contribution is a feature-correction procedure that adjusts the information content in the generated feature representations through a gating mechanism to improve their discriminative power and reduce emotion-prediction errors. We conduct extensive experiments on four commonly used conversational datasets, i.e., IEMOCAP, MELD, Dailydialog, and EmoryNLP, to demonstrate the capabilities of the developed graph neural network with context filtering and error-correction capabilities. The results of the experiments point to highly promising performance, especially when compared to state-of-the-art competitors from the literature.},
  archive      = {J_ISCI},
  author       = {Chenquan Gan and Jiahao Zheng and Qingyi Zhu and Deepak Kumar Jain and Vitomir Štruc},
  doi          = {10.1016/j.ins.2023.120017},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120017},
  shortjournal = {Inf. Sci.},
  title        = {A graph neural network with context filtering and feature correction for conversational emotion recognition},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Failure mode and effects analysis in consensus-based GDM for
surface-guided deep inspiration breath-hold breast radiotherapy for
breast cancer under the framework of linguistic z-number. <em>ISCI</em>,
<em>658</em>, 120016. (<a
href="https://doi.org/10.1016/j.ins.2023.120016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the cancer patients cannot get the usual treatment in the advanced stage of the disease. In particular, for breast cancer, it is to use a special kind of radiation that targets the tumor while the patient holds their breath. This is called surface-guided (SG) breast radiotherapy (RT) with deep inspiration breath-hold (DIBH). This treatment is very complicated and different from the normal way of treating breast cancer. It can also have many errors and problems that are not well-studied or understood. To prevent these problems, we need to use a method called failure mode and effects analysis (FMEA). This method helps us find and rank the possible risks and how to avoid them. In keeping with this aim, this paper studies consensus-reaching process-based group decision-making (GDM) with completely unknown risk factors&#39; weights and the gained-lost dominance score (GLDS)-based ranking process. We cannot avoid the uncertainty related to relativity information in medical science. Therefore, in this study, we offer the experts to provide their opinions using the linguistic Z number (LZN) because LZN is designed to capture such types of information in medical science. For the consensus-reaching process (CRP), the relativity among experts is considered for consensus measurement, and the minimum adjustment sum with group consensus opinion-based feedback is offered. For unknown weight of risk factors, we don&#39;t know how much each risk factor weighs. So, we use a method that combines two ways of calculating weights. One way is a subjective weight computation process, and the other way is based on the data using entropy and division. Finally, we applied our proposed CRP-based GDM approach for ranking the identified FMs related to the SG DIBH RT process. We conduct sensitive, comparative, and statistical assessments to ensure our method is reasonable and practical.},
  archive      = {J_ISCI},
  author       = {Prasenjit Mandal and Sovan Samanta and Madhumangal Pal},
  doi          = {10.1016/j.ins.2023.120016},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120016},
  shortjournal = {Inf. Sci.},
  title        = {Failure mode and effects analysis in consensus-based GDM for surface-guided deep inspiration breath-hold breast radiotherapy for breast cancer under the framework of linguistic Z-number},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fully secure lattice-based signcryption with designated
equality test in standard model. <em>ISCI</em>, <em>658</em>, 120015.
(<a href="https://doi.org/10.1016/j.ins.2023.120015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In hospital information systems , large volumes of electronic diagnostic records (EDRs) take up most of the storage space. While cloud server providers can reduce the local storage burden on hospitals and provide data-sharing services, the potential threat of sensitive data leakage and non-traceability of diagnoses prevents hospitals from uploading patients&#39; diagnostic records to remote cloud servers directly. Therefore, to address security and traceability issues, we propose a new construction of post-quantum secure signcryption scheme with a designated equality test based on lattices (LB-SCDET) in this paper. Our LB-SCDET scheme allows a designated tester to perform equality tests on signcrypt-ciphertexts of EDRs without leaking what the EDRs actually are. Compared to the recent LB-SCET scheme proposed by Le et al., our LB-SCDET scheme implements a designated mechanism and is secure against offline message recovery attacks (OMRA). The comparison shows that our scheme enjoys a higher level of security, albeit the ciphertext size is slightly larger. Finally, we prove the scheme to be secure under the hardness of the Learning-with-Errors problem and unidirectionality of the Short-Integer-Solution problem. To be of independent interest, we show that the LB-SCET scheme fails to achieve the claimed IND-CCA security.},
  archive      = {J_ISCI},
  author       = {Kaifeng Xiao and Xinjian Chen and Hongbo Li and Jianye Huang and Willy Susilo and Qiong Huang},
  doi          = {10.1016/j.ins.2023.120015},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120015},
  shortjournal = {Inf. Sci.},
  title        = {A fully secure lattice-based signcryption with designated equality test in standard model},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prescribed performance event-triggered fuzzy optimal
tracking control for strict-feedback nonlinear systems. <em>ISCI</em>,
<em>658</em>, 120014. (<a
href="https://doi.org/10.1016/j.ins.2023.120014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prescribed performance event-triggered optimal tracking control problem is considered for a class of uncertain strict-feedback nonlinear systems with external disturbances . First, the disturbance observers are constructed to estimate external disturbances. Then, the controller contains an adaptive fuzzy controller and an optimal compensation term, in which the unknown nonlinearities and cost function are approximated by the fuzzy logic systems . An adaptive fuzzy controller is established by the dynamic surface control (DSC) technique, which is addressed to handle “computation complexity” issue occurred in conventional backstepping approach. Based on adaptive dynamic programming (ADP) method, an optimal compensation term is developed by minimizing the cost function. Furthermore, communication load is reduced via embedding event-triggered mechanism. In addition, the tracking error can be restricted in the prescribed region with the aid of the prescribed performance control. Thus, the whole control scheme can not only ensure that the tracking error converges to a boundary but also achieve optimization, reduce the communication burden and avoid “computation complexity” issue. The boundedness of all signals in the closed-loop is proved. Finally, the simulation examples illustrate the validity of the designed control scheme.},
  archive      = {J_ISCI},
  author       = {Zongsheng Huang and Xiaoyang Gao and Tieshan Li and Yue Long and Hanqing Yang},
  doi          = {10.1016/j.ins.2023.120014},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120014},
  shortjournal = {Inf. Sci.},
  title        = {Prescribed performance event-triggered fuzzy optimal tracking control for strict-feedback nonlinear systems},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse regularized correlation filter for UAV object
tracking with adaptive contextual learning and keyfilter selection.
<em>ISCI</em>, <em>658</em>, 120013. (<a
href="https://doi.org/10.1016/j.ins.2023.120013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, correlation filter has been widely applied in unmanned aerial vehicle (UAV) tracking due to its high frame rates, robustness and low calculation resources. However, it is fragile because of two inherent defects, i.e., boundary effect and filter corruption. To handle them, in this work, we propose a novel ℓ 1 ℓ1 regularization correlation filter with adaptive contextual learning and keyfilter selection for UAV tracking. Firstly, we adaptively detect the positions of effective contextual distractors by the aid of the distribution of local maximum values on the response map of current frame which is generated by using the previous correlation filter model. Next, we eliminate inconsistent labels for the tracked target by removing one on each distractor and develop a new score scheme for each distractor. Then, we can select the keyfilter from the filters pool by finding the maximal similarity between the target at the current frame and the target template corresponding to each filter in the filters pool. Finally, quantitative and qualitative experiments on three authoritative UAV datasets show that the proposed method is superior to the state-of-the-art tracking methods based on correlation filter framework.},
  archive      = {J_ISCI},
  author       = {Zhangjian Ji and Kai Feng and Yuhua Qian and Jiye Liang},
  doi          = {10.1016/j.ins.2023.120013},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120013},
  shortjournal = {Inf. Sci.},
  title        = {Sparse regularized correlation filter for UAV object tracking with adaptive contextual learning and keyfilter selection},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive multi-channel contrastive graph convolutional
network with graph and feature fusion. <em>ISCI</em>, <em>658</em>,
120012. (<a href="https://doi.org/10.1016/j.ins.2023.120012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The domain of multi-view semi-supervised classification is an appealing topic in real-world applications. Due to the powerful capability of gathering information from neighbors, Graph Convolutional Network (GCN) has become a hotspot in the classification task . However, most of multi-view classification works based on GCN only assign weights for feature fusion , and directly consider the weighted sum of the adjacency matrices , ignoring the interaction and correlation among features. These may be problematic since aggregating the matrices from less relevant views may destroy the original topology space, leading to undesired performance. To tackle the aforementioned challenges, this paper presents an Adaptive Multi-Channel Graph Convolutional Network (AMC-GCN). To extract the interactive information, AMC-GCN designs a deep interactive feature integration network to incorporate consensus and complementary information. To fuse the graph structures, AMC-GCN exploits the relevance between views and imposes an adjacency matrix fusion network on constructing multiple GCN channels, thereby delivering discriminative information on graphs. To enhance the homogeneity of the framework, AMC-GCN applies a contrastive loss to joint learning during the optimization for classification. With these considerations, AMC-GCN exploits relevant and interactive information between views to promote graph and feature fusion. Substantial experimental results on real-world datasets verify the superiority of AMC-GCN.},
  archive      = {J_ISCI},
  author       = {Luying Zhong and Jielong Lu and Zhaoliang Chen and Na Song and Shiping Wang},
  doi          = {10.1016/j.ins.2023.120012},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120012},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive multi-channel contrastive graph convolutional network with graph and feature fusion},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). A novel method to information fusion in multi-source
incomplete interval-valued data via conditional information entropy:
Application to mutual information entropy based attribute reduction.
<em>ISCI</em>, <em>658</em>, 120011. (<a
href="https://doi.org/10.1016/j.ins.2023.120011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of explosive data growth, data sources and volumes are rapidly increasing. A multi-source data refers to information from multi-sources. However, not every source of information is equally important; some sources are more important and some are essentially worthless. Therefore, it is very meaningful to study how to select the most valuable sources and to efficiently fuse information. Multi-source incomplete interval-valued data (MSIIV-data) is an important kind of multi-source data. This paper proposes a novel method to information fusion in MSIIV-data via conditional information entropy (CIE) and considers its application to attribute reduction based on mutual information entropy. First, the distance between two information values for each incomplete interval-valued data is defined, the neighborhood classes with a tunable parameter are obtained, and the neighborhood granularity structure is established. Then, a source selection method is given via CIE, which is used to fuse MSIIV-data into single-source incomplete interval-valued data (SSIIV-data). Based on the minimization of CIE, this method allows worthy and reliable information sources to be chosen. Moreover, an attribute reduction algorithm (denoted as MMQPSO) for the fused SSIIV-data is proposed by means of combining mutual information entropy and QPSO-algorithm. Finally, experiments are done to validate the effectiveness of the proposed algorithms. The results of experiment and statistical test on 12 datasets show that the proposed algorithms have certain feasibility and advancement than 6 other advanced algorithms.},
  archive      = {J_ISCI},
  author       = {Zhaowen Li and Jianming Liu and Yichun Peng and Ching-Feng Wen},
  doi          = {10.1016/j.ins.2023.120011},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120011},
  shortjournal = {Inf. Sci.},
  title        = {A novel method to information fusion in multi-source incomplete interval-valued data via conditional information entropy: Application to mutual information entropy based attribute reduction},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot regression with differentiable reference model.
<em>ISCI</em>, <em>658</em>, 120010. (<a
href="https://doi.org/10.1016/j.ins.2023.120010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise control models of industrial manufacturing are essential for high-quality products. In specific industrial fields, there usually exist certain theoretical results and analytical reference models. Due to the diversity of the control input and complex coupling effect on results, the analytical reference model often has strong assumptions and simplified conditions, so that the error can be large. However, it can characterize the overall trend of the real control curve. Deep learning is a promising solution for precise control model, but the huge data demand hinders its application. To this end, we propose a novel few-shot regression framework based on a differentiable reference model, where the gradient of reference model is used as the prior of the function fitter. We implement the framework on a neural network , named G radient G uided N etwork, GGN, achieving accurate regression with few samples. Experimental results of sinusoidal regression and roll bend forming problem demonstrate the effectiveness and superior performance compared with meta learning methods. In addition, by combining the trend of the theoretical reference model with real data , our method also achieves better results than the reference model.},
  archive      = {J_ISCI},
  author       = {Peng Shi and Guoyan Huang and Hongdou He and Guyu Zhao and Xiaobing Hao and Yifang Huang},
  doi          = {10.1016/j.ins.2023.120010},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120010},
  shortjournal = {Inf. Sci.},
  title        = {Few-shot regression with differentiable reference model},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global precise consensus tracking control for uncertain
multiagent systems in cooperation-competition networks. <em>ISCI</em>,
<em>658</em>, 120006. (<a
href="https://doi.org/10.1016/j.ins.2023.120006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multiagent systems (MASs) play a crucial role in practical applications, and the global precise control of MASs under cooperative-competitive networks presents significant challenges. This paper addresses the global precise consensus tracking control problem for uncertain MASs in cooperation-competition networks. A novel framework of distributed event-based prescribed-time observer (EPTO) is proposed for the followers, which allows to accurately estimate the leader&#39;s state within a prescribed time interval . Moreover, the design of event-triggered conditions for each EPTO reduces the communication load between neighboring agents by avoiding the continuous transmission of neighbor states. Using the observed values after triggering within the backstepping method framework, a global bipartite control scheme is then developed to expedite the convergence time, enhance the convergence performance, and perform precise tracking control for high-order uncertain MASs. The distinctive feature of the proposed global bipartite control scheme lies in the design of a novel controller, which improves the semi-global control result of the existing schemes. Finally, two simulation examples are presented to demonstrate the effectiveness of the EPTO-based bipartite control scheme.},
  archive      = {J_ISCI},
  author       = {Zan Li and Yingnan Pan and Tianjiao An and Bo Dong and Xiaogang Dong},
  doi          = {10.1016/j.ins.2023.120006},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120006},
  shortjournal = {Inf. Sci.},
  title        = {Global precise consensus tracking control for uncertain multiagent systems in cooperation-competition networks},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heterogeneous graph knowledge distillation neural network
incorporating multiple relations and cross-semantic interactions.
<em>ISCI</em>, <em>658</em>, 120004. (<a
href="https://doi.org/10.1016/j.ins.2023.120004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the study of real-world graphs has revealed their inherent heterogeneity, prompting growing research interest in heterogeneous graphs. Characterized by diverse node and relation types, heterogeneous graphs have led to the development of heterogeneous graph neural networks , which possess the remarkable ability of modeling such heterogeneity. Consequently, researchers have embraced these networks, applying them in various domains. A prevalent approach is using meta-path based methods in heterogeneous graph neural networks . However, a significant limitation arises from the fact that such methods tend to overlook vital attribute information within intermediate nodes and disregard relevant semantics across various meta-paths. To address the above limitations, we propose a new model named HGNN-MRCS. Specifically, HGNN-MRCS incorporates three key components, i.e., a relation aware module to encapsulate the attribute information of the intermediate nodes; a meta-path aware technique to facilitate learning of semantic information of each meta-path and enable higher-order representation learning ; and a knowledge distillation strategy to learn relevant semantics across meta-paths and fuse them. Experimental results on four real-world datasets demonstrate the superior performance of this work over the SOAT methods. The source codes of this work are available at https://github.com/ZZY-GraphMiningLab/HGNN-MRCS .},
  archive      = {J_ISCI},
  author       = {Jinhu Fu and Chao Li and Zhongying Zhao and Qingtian Zeng},
  doi          = {10.1016/j.ins.2023.120004},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120004},
  shortjournal = {Inf. Sci.},
  title        = {Heterogeneous graph knowledge distillation neural network incorporating multiple relations and cross-semantic interactions},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A noise-resistant graph neural network by semi-supervised
contrastive learning. <em>ISCI</em>, <em>658</em>, 120001. (<a
href="https://doi.org/10.1016/j.ins.2023.120001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have been widely applied for representation learning on the graph data in real applications, but few of them are designed to conduct representation learning on the graph data with noisy labels. Its key challenge is that the feature embeddings of nodes with noisy labels (noisy nodes for short) are close to those of unlabeled nodes so that the classifier constructed by GNNs is influenced by noisy nodes. To address this issue, in this paper, we propose a noise-resistant graph neural network with semi-supervised contrastive learning to push noisy nodes far away from unlabeled nodes in the embedding space. To do this, we design a constraint of semi-supervised contrastive learning and put it into the objective function of GNNs. Specifically, the proposed constraint enlarges the distance between noisy nodes and unlabeled nodes by pushing noisy nodes far away from their unlabeled neighbors in the embedding space. As a result, the embeddings of unlabeled nodes are influenced by noisy label less. Moreover, we intuitively analyze the feasibility of our proposed constraint. Comprehensive experiments on real datasets further verify the effectiveness of our proposed method over previous SOTA methods in terms of classification tasks with different ratio levels of noisy labels.},
  archive      = {J_ISCI},
  author       = {Zhengyu Lu and Junbo Ma and Zongqian Wu and Bo Zhou and Xiaofeng Zhu},
  doi          = {10.1016/j.ins.2023.120001},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120001},
  shortjournal = {Inf. Sci.},
  title        = {A noise-resistant graph neural network by semi-supervised contrastive learning},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differentially private enhanced permissioned blockchain for
private data sharing in industrial IoT. <em>ISCI</em>, <em>658</em>,
119997. (<a href="https://doi.org/10.1016/j.ins.2023.119997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of permissioned blockchain such as Hyperledger fabric (HF) and Industrial internet of Things (IIoT) has opened new opportunities for interdependent supply chain partners to improve their performance through data sharing and coordination. The multichannel mechanism, private data collection and querying mechanism of HF enable private data sharing, transparency, traceability, and verification across the supply chain. However, the existing querying mechanism of HF needs further improvement for statistical data sharing because the query is evaluated on the original data recorded on the ledger. As a result, it gives rise to privacy issues such as leaking of business secrets, tracking of resources and assets, and disclosing of personal information. Therefore, we solve this problem by proposing a differentially private enhanced permissioned blockchain for private data sharing in the context of supply chain in IIoT which is known as (EDH-IIoT). First, we integrate differential privacy into the chaincode (smart contract) of HF which evaluates the query and adds a calibrated noise into it. Second, we propose an algorithm to efficiently utilize ϵ through reuse of the privacy budget for the repeated queries. Third, we also propose an algorithm to track the privacy budget ( ϵ ) and avoid the degrade of privacy preservation in case of multiple queries on the same portion of the ledger&#39;s data. Furthermore, the reuse and tracking of ϵ enables the data owner to ensure that ϵ does not exceed the threshold which is the maximum privacy budget ( ϵ t ). Finally, we model two privacy attacks namely linking attack and composition attack to evaluate and compare privacy preservation, and the efficiency of reuse of ϵ with the default chaincode of HF and traditional differential privacy model, respectively. The results confirm that EDH-IIoT obtains an accuracy of 97% in the shared data for ϵ = 1, and a reduction of 35.96% in spending of ϵ .},
  archive      = {J_ISCI},
  author       = {Muhammad Islam and Mubashir Husain Rehmani and Jinjun Chen},
  doi          = {10.1016/j.ins.2023.119997},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119997},
  shortjournal = {Inf. Sci.},
  title        = {Differentially private enhanced permissioned blockchain for private data sharing in industrial IoT},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel three-way decision-making method for logistics
enterprises’ carbon trading considering attribute reduction and
hesitation degree. <em>ISCI</em>, <em>658</em>, 119996. (<a
href="https://doi.org/10.1016/j.ins.2023.119996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, against the background of carbon trading policies, carbon dioxide is attributed commodity properties for market trading within carbon trading. Relevant data show that, in recent years, logistics enterprises have been facing continuously growing demand and carbon emissions have continuously increased; therefore, enterprises urgently need to strengthen their green transformation. Scientific and rational decision-making tools play a meaningful role in helping enterprises improve their competitiveness. In this context, a new three-way decision-making model based on attribute reduction and hesitation degree is proposed. First, an attribute reduction is performed. The attributes of three types of logistics enterprises are simplified according to the carbon emission evaluation attributes proposed in this study to determine their respective minimum attribute sets. Subsequently, the decision and loss function matrices are established considering the hesitation degree. The conditional probability is calculated using intuitionistic fuzzy similarity, and the probability threshold is calculated using the loss function matrix considering the hesitation degree. Finally, case studies and comparative analyses are conducted to illustrate the practicality and rationality of the proposed method.},
  archive      = {J_ISCI},
  author       = {Ling Liu and Yujie He and Dan Yang and Sen Liu},
  doi          = {10.1016/j.ins.2023.119996},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119996},
  shortjournal = {Inf. Sci.},
  title        = {A novel three-way decision-making method for logistics enterprises’ carbon trading considering attribute reduction and hesitation degree},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A cloud model-based interval-valued evidence fusion method
and its application in fault diagnosis. <em>ISCI</em>, <em>658</em>,
119995. (<a href="https://doi.org/10.1016/j.ins.2023.119995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In fault diagnosis methods based on evidence fusion, a piece of evidence is usually extracted from the fault feature information, which uses the single-valued belief degrees (SVB) to measure the likelihoods of the different fault modes happening. However, SVB seems rough and incomplete for modeling fault information with uncertainty. Therefore, an interval-valued evidence (IVE) fusion method is proposed via cloud model. Compared to the SVB structure, the IVE with the interval-valued belief structure contains more useful fault information. Firstly, the nominal normal cloud model (NCM) about each fault mode and the test normal cloud model (TNCM) are established through the statistical analysis of the historical and testing fault sample data , respectively. TNCMs are matched with each NCM to obtain the corresponding IVE. Then, a novel IVE reasoning rule is defined to combine all IVEs coming from different fault features. Finally, in the fault diagnosis experiments of motor rotors , the proposed method is verified to provide more accurate fault decision results compared to the traditional evidence fusion method. Furthermore, the proposed method is extended to solve general data classification problems with benchmark datasets of University of California Irvine (UCI), showing it has better classification ability compared to some classification methods.},
  archive      = {J_ISCI},
  author       = {Xiaobin Xu and Haohao Guo and Zehui Zhang and Shanen Yu and Leilei Chang and Felix Steyskal and Georg Brunauer},
  doi          = {10.1016/j.ins.2023.119995},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119995},
  shortjournal = {Inf. Sci.},
  title        = {A cloud model-based interval-valued evidence fusion method and its application in fault diagnosis},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Formation control for linear multi-agent systems with
asynchronously sampled outputs. <em>ISCI</em>, <em>658</em>, 119992. (<a
href="https://doi.org/10.1016/j.ins.2023.119992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The focus of this paper is to investigate the problem of formation control for linear multi-agent systems through output feedback, utilizing the asynchronous sampled-data mechanism. Each agent matches one state observer to estimate its own state by only using the asynchronously sampled outputs. Based on the asynchronously sampled estimates of states, we develop a formation control law that operates in a distributed manner. The establishment of auxiliary time sequences plays a significant role in coping with the difficulty of asynchronous sampling. Through the study, an explicit upper bound of sampling periods and admissible formation condition, which guarantee that the predefined geometric shape is asymptotically formed, are given. Two examples are eventually carried out to show that formation is achieved successfully.},
  archive      = {J_ISCI},
  author       = {Quangui He and Wei Liu},
  doi          = {10.1016/j.ins.2023.119992},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119992},
  shortjournal = {Inf. Sci.},
  title        = {Formation control for linear multi-agent systems with asynchronously sampled outputs},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cloud ensemble learning for fault diagnosis of rolling
bearings with stochastic configuration networks. <em>ISCI</em>,
<em>658</em>, 119991. (<a
href="https://doi.org/10.1016/j.ins.2023.119991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scarcity of fault samples poses a significant challenge for fault diagnosis of rolling bearings in industrial environment. Conventional fault diagnosis methods struggle to achieve satisfactory results in the few-shot scenarios. Furthermore, common entropy-based feature extraction methods fail to adaptively represent the uncertainty information hidden in vibration signals . To overcome these issues, this article proposes a stochastic configuration network-based cloud ensemble learning (SCN-CEL). Firstly, a cloud feature extraction method is developed to effectively capture fault information from vibration signals while accounting for their inherent uncertainty based on backward cloud generator (BCG) of cloud model (CM), without requiring hyperparameter settings. Subsequently, a cloud oversampling (COS) method is proposed to augment the feature space of limited samples and generate sufficient samples for improving diagnostic accuracy based on bidirectional cloud generator. Finally, we introduce an ensemble model that combines SCNs with multiple constrained COS to comprehensively characterize uncertain fault information and advance the generalization of diagnosis machine. By harnessing the constructive incremental learning of SCN, SCN-CEL guarantees both efficient modeling and accurate prediction for bearing fault diagnosis. Extensive experiments evaluate the effectiveness of each module in SCN-CEL and demonstrate its favorable performance in distinguishing fault categories of rolling bearings in the few-shot scenarios.},
  archive      = {J_ISCI},
  author       = {Wei Dai and Jiang Liu and Lanhao Wang},
  doi          = {10.1016/j.ins.2023.119991},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119991},
  shortjournal = {Inf. Sci.},
  title        = {Cloud ensemble learning for fault diagnosis of rolling bearings with stochastic configuration networks},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-attribute decision-making based on similarity measure
between picture fuzzy sets and the MARCOS method. <em>ISCI</em>,
<em>658</em>, 119990. (<a
href="https://doi.org/10.1016/j.ins.2023.119990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new similarity measure (SM) between picture fuzzy sets (PFSs). The proposed SM between PFSs can overcome the drawbacks of the existing SMs between PFSs. We also propose a weight-determination approach based on the proposed SM between PFSs to determine attributes’ weights in picture fuzzy environments. We also propose a new multi-attribute decision-making (MADM) approach based on the proposed SM between PFSs and the Measurement of Alternatives and Ranking according to Compromise Solution (MARCOS) method for MADM with picture fuzzy information. The proposed MADM approach can overcome the shortcomings of the existing MADM approaches based on PFSs. It provides us a very useful approach for MADM in picture fuzzy settings.},
  archive      = {J_ISCI},
  author       = {Pratibha Rani and Shyi-Ming Chen and Arunodaya Raj Mishra},
  doi          = {10.1016/j.ins.2023.119990},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119990},
  shortjournal = {Inf. Sci.},
  title        = {Multi-attribute decision-making based on similarity measure between picture fuzzy sets and the MARCOS method},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The q-gradient LMS spline adaptive filtering algorithm and
its variable step-size variant. <em>ISCI</em>, <em>658</em>, 119983. (<a
href="https://doi.org/10.1016/j.ins.2023.119983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an innovation q-gradient least-mean-square (LMS) spline adaptive filtering (S-AF) algorithm (SAF-qLMS) on the basis of the theory of q-derivative is proposed. The q-calculus confronts the issue of slow convergence by mitigating the over-reliance of LMS-type algorithms on the diffusion of eigenvalues in the input correlation matrix . Compared to conventional derivatives, the SAF-qLMS exploits q-calculus to compute the secant of the cost function , enabling it to take larger steps in the search direction for q &gt; 1 q&amp;gt;1 . Furthermore, for balancing the convergence rate and steady-state error of SAF-qLMS and solving the deficiency of the fixed step-size, the SAF-VqLMS based on variable step-size is further proposed. Finally, the convergence conditions of the SAF-qLMS are discussed. Simulations in a correlated Gaussian input environment confirm the outstanding performance of the proposed algorithms for nonlinear system identification .},
  archive      = {J_ISCI},
  author       = {Yuan Gao and Haiquan Zhao and Yingying Zhu and Jingwei Lou},
  doi          = {10.1016/j.ins.2023.119983},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119983},
  shortjournal = {Inf. Sci.},
  title        = {The q-gradient LMS spline adaptive filtering algorithm and its variable step-size variant},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). RCPM_CFI: A regional core pattern mining method based on
core feature influence. <em>ISCI</em>, <em>658</em>, 119895. (<a
href="https://doi.org/10.1016/j.ins.2023.119895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regional co-location pattern mining is a branch of spatial co-location pattern mining, which is used to discover co-location patterns that prevalently co-occur in local regions. The regional co-location patterns can reveal the association relationships among spatial features in the local regions. However, in practice, the association relationship between certain features is asymmetrical, and some features play a key (core) role in the relationship, as central position. To explore the regional co-location patterns with core feature (called r egional c ore p atterns (RCPs)) as well as their prevalent regions, this paper presents a regional partition method based on the influence of core feature. Additionally, a r egional c ore p attern m ining (RCPM) algorithm is proposed to mine the RCPs and unveil their spatial distribution resulting from the arrangement of core feature. In the regional partition stage, we propose a partition criterion that takes into account the influence of core feature. This criterion aims to comprehensively address the spatial distribution relationship between core instances and their neighboring non-core instances, ensuring the partition process is rational and complete. In the RCPM stage, we propose a core-based nearest affiliation measure method to assess the neighbor relationship between core and non-core instances, which can consider the fact that there is competition between spatial instances of the same spatial feature. And, to effectively calculate pattern prevalence and quickly identify RCPs, we present a data structure called Core_Hash to store the influence relationship between core and non-core instances. Extensive experimental evaluations and analyses are conducted on synthetic and real-world datasets. Compared to the existing algorithms, our proposed algorithms yield more reasonable and comprehensive RCPs and demonstrate good efficiency and scalability.},
  archive      = {J_ISCI},
  author       = {Dongsheng Wang and Lizhen Wang and Xiwen Jiang and Peizhong Yang},
  doi          = {10.1016/j.ins.2023.119895},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119895},
  shortjournal = {Inf. Sci.},
  title        = {RCPM_CFI: A regional core pattern mining method based on core feature influence},
  volume       = {658},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluation of intelligent transportation system
implementation alternatives in metaverse using a fermatean fuzzy
distance measure-based OCRA model. <em>ISCI</em>, <em>657</em>, 120008.
(<a href="https://doi.org/10.1016/j.ins.2023.120008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of the Metaverse, an immersive simulated world with parallels to reality, has gained significant prominence in recent times. Initially popularized through gaming, the Metaverse is now poised to infiltrate various aspects of human life. Intelligent transportation systems represent a promising yet challenging domain for Metaverse integration. Alternative implementations can create challenges in different dimensions. A comprehensive evaluation that takes challenges and opportunities for the different dimensions into account is required in decision making process of choosing the best implementation method. This study presents the development of a novel evaluation model, the Fermatean Fuzzy Operational Competitiveness Rating (OCRA) model, which incorporates the Fermatean Fuzzy Distance Measure (FF-DM) and Relative Closeness Coefficient (FF-RCC) techniques. The model is tested in a case to rank three alternative approaches, considering criteria of four key dimensions: managerial, safety, user, and urban mobility. In the first stage, the FF-DM and FF-RCC-based tool is employed to determine the criteria weights. In the second stage, an enhanced version of the Fermatean Fuzzy OCRA model, utilizing FF-DM and FF-RCC, is employed to rank the alternatives. The findings indicate that policymakers&#39; decisions in traffic management hold the potential to shape the trajectory of the Metaverse movement, representing an unparalleled opportunity with implications that extend beyond our current comprehension.},
  archive      = {J_ISCI},
  author       = {Muhammet Deveci and Arunodaya Raj Mishra and Pratibha Rani and Ilgin Gokasar and Mehtap Isik and Dursun Delen and Keng-Boon Ooi and Tugrul Daim},
  doi          = {10.1016/j.ins.2023.120008},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120008},
  shortjournal = {Inf. Sci.},
  title        = {Evaluation of intelligent transportation system implementation alternatives in metaverse using a fermatean fuzzy distance measure-based OCRA model},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RCAR-UNet: Retinal vessel segmentation network algorithm via
novel rough attention mechanism. <em>ISCI</em>, <em>657</em>, 120007.
(<a href="https://doi.org/10.1016/j.ins.2023.120007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The health status of the retinal blood vessels is a significant reference for rapid and non-invasive diagnosis of various ophthalmological, diabetic, and cardio-cerebrovascular diseases. However, retinal vessels are characterized by ambiguous boundaries, with multiple thicknesses and obscured lesion areas. These phenomena cause deep neural networks to face the characteristic channel uncertainty when segmenting retinal blood vessels. The uncertainty in feature channels will affect the channel attention coefficient, making the deep neural network incapable of paying attention to the detailed features of retinal vessels. This study proposes a retinal vessel segmentation via a rough channel attention mechanism . First, the method integrates deep neural networks to learn complex features and rough sets to handle uncertainty for designing rough neurons. Second, a rough channel attention mechanism module is constructed based on rough neurons, and embedded in U-Net skip connection for the integration of high-level and low-level features. Then, the residual connections are added to transmit low-level features to high-level to enrich network feature extraction and help back-propagate the gradient when training the model. Finally, multiple comparison experiments were carried out on three public fundus retinal image datasets to verify the validity of Rough Channel Attention Residual U-Net (RCAR-UNet) model. The results show that the RCAR-UNet model offers high superiority in accuracy, sensitivity, F1, and Jaccard similarity , especially for the precise segmentation of fragile blood vessels, guaranteeing blood vessels’ continuity.},
  archive      = {J_ISCI},
  author       = {Weiping Ding and Ying Sun and Jiashuang Huang and Hengrong Ju and Chongsheng Zhang and Guang Yang and Chin-Teng Lin},
  doi          = {10.1016/j.ins.2023.120007},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120007},
  shortjournal = {Inf. Sci.},
  title        = {RCAR-UNet: Retinal vessel segmentation network algorithm via novel rough attention mechanism},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Aggregating diverse evaluations in group decision making:
An approach based on wisdom of crowds. <em>ISCI</em>, <em>657</em>,
120005. (<a href="https://doi.org/10.1016/j.ins.2023.120005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group decision-making (GDM) requires individuals to weigh and aggregate individual evaluations. Diverse evaluations within a group usually require a consensus reaching process (CRP). However, CRP does not aim to improve group evaluation accuracy. The wisdom of crowds (WOC) applies statistical aggregations to obtain group predictions, without necessitating a certain degree of group consensus. Current WOC techniques identify individual expertise levels based on real outcomes of events, or individuals&#39; meta-information, which might not be obtainable in GDM problems. This study proposes an approach for GDM problems with diverse evaluations provided by individuals with different expertise levels. It weighs individuals based on their contributions to the group, by estimating the evaluated attributes&#39; real outcomes and updating individual weights within a time series. The approach is verified by real collected data and simulated data , then compared with several similar weighting methods and CRP techniques. The results demonstrate the approach&#39;s good performance in large groups, with improved identification of expertise levels in diverse groups, without requiring a large number of time points in the time-series.},
  archive      = {J_ISCI},
  author       = {Hai Wang and Guowei Yang and Zeshui Xu},
  doi          = {10.1016/j.ins.2023.120005},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120005},
  shortjournal = {Inf. Sci.},
  title        = {Aggregating diverse evaluations in group decision making: An approach based on wisdom of crowds},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Memetic segmentation based on variable lag aware for
multivariate time series. <em>ISCI</em>, <em>657</em>, 120003. (<a
href="https://doi.org/10.1016/j.ins.2023.120003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The memetic segmentation algorithm has been proposed to obtain precise segmentation results through efficient local refinement. However, this algorithm overlooks the consideration of time lags among variables or spatial locations in multivariate time series data . Although some researchers have adopted dynamic programming to eliminate time lags and obtain segmentation results iteratively, they have failed to achieve simultaneous optimization for both lag awareness and segmentation. To address this problem, we propose a memetic segmentation algorithm based on variable lag-aware for multivariate time series (MSVLAMTS), which enhances the encoding operation of the memetic algorithm to optimize both time-lag awareness and segmentation positions. Furthermore, MSVLAMTS incorporates the self-distribution of multivariate time series and the correlation between variables to construct a maximum likelihood function for fitness evaluation, and further improves the optimization strategy of the memetic algorithm. Experiment results on artificial and real datasets demonstrate that MSVLAMTS exhibits superior performance in both time-lag awareness and segmentation. It effectively resolves the challenge of variable time-lag awareness in multivariate time series data and enhances the accuracy of collaborative segmentation.},
  archive      = {J_ISCI},
  author       = {Ling Wang and Peng Shen},
  doi          = {10.1016/j.ins.2023.120003},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120003},
  shortjournal = {Inf. Sci.},
  title        = {Memetic segmentation based on variable lag aware for multivariate time series},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Low-tubal-rank tensor completion via local and nonlocal
knowledge. <em>ISCI</em>, <em>657</em>, 120002. (<a
href="https://doi.org/10.1016/j.ins.2023.120002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many previous studies have indicated that exploiting prior information about the underlying tensor data is a sound approach for completing missing or damaged entries. This prior information can be divided into three commonly used categories: low-rankness, local piecewise smoothness, and nonlocal self-similarity (NSS) priors. Although existing methods based on these priors have gained considerable attention, the majority of studies utilize only one or two of these priors, leading to inadequate extraction of structural information from tensors. To address this limitation and comprehensively depict the inherent structural information of underlying tensor data, this article develops a novel tensor completion framework that can simultaneously utilize the three abovementioned priors within a plug-and-play framework. More precisely, we adopt the tensor correlated total variation (t-CTV) norm as a robust representation for capturing the combined effects of low-rankness and local piecewise smoothness priors, eliminating the need for a trade-off parameter in the process; meanwhile, we introduce an advanced denoiser to explore the NSS prior. Furthermore, to address the presented optimization model, we design an alternating direction method of multipliers (ADMM) algorithm and innovatively provide its corresponding global convergence guarantees. Extensive numerical experiments on real tensor data, including color, medical and hyperspectral images , demonstrate that the proposed method surpasses various advanced approaches in terms of both quality metrics and visual effects.},
  archive      = {J_ISCI},
  author       = {Weichao Kong and Feng Zhang and Wenjin Qin and Qingrong Feng and Jianjun Wang},
  doi          = {10.1016/j.ins.2023.120002},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120002},
  shortjournal = {Inf. Sci.},
  title        = {Low-tubal-rank tensor completion via local and nonlocal knowledge},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ERA*: Enhanced relaxed a* algorithm for solving the shortest
path problem in regular grid maps. <em>ISCI</em>, <em>657</em>, 120000.
(<a href="https://doi.org/10.1016/j.ins.2023.120000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel algorithm for solving the point-to-point shortest path problem in a static regular 8-neighbor connectivity (G8) grid. This algorithm can be seen as a generalization of Hadlock algorithm to G8 grids, and is shown to be theoretically equivalent to the relaxed ⁎ A ⁎ A⁎ ( ⁎ R A ⁎ RA⁎ ) algorithm in terms of the provided solution&#39;s path length, but with substantial time and memory savings, due to a completely different computation strategy, based on defining a set of lookup matrices. Through an experimental study on grid maps of various types and sizes (1290 runs on 43 maps), it is proven to be 2.25 times faster than ⁎ R A ⁎ RA⁎ and 17 times faster than the original ⁎ A ⁎ A⁎ , in average. Moreover, it is more memory-efficient, since it does not need to store a G score matrix .},
  archive      = {J_ISCI},
  author       = {Adel Ammar},
  doi          = {10.1016/j.ins.2023.120000},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {120000},
  shortjournal = {Inf. Sci.},
  title        = {ERA*: Enhanced relaxed a* algorithm for solving the shortest path problem in regular grid maps},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dynamic three-way conflict analysis model with adaptive
thresholds. <em>ISCI</em>, <em>657</em>, 119999. (<a
href="https://doi.org/10.1016/j.ins.2023.119999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way conflict analysis model, based on information systems , is about trisecting, getting coalitions and decision-making. Since the model is proposed by Yao, many models have been proposed to enrich the field of three-way conflict analysis. In this paper, we propose a new three-way conflict analysis model. Our work can be divided into four parts. First, we define new fuzzy granules and an new approximation operator to obtain better trisections. Second, we introduce dynamic information systems which are generalizations of classical information systems. The new information systems enable us to induce trisections dynamically. Third, a new Bayesian algorithm is proposed for thresholds-computing which plays an important role in inducing trisections. In the classical Bayesian approach , there are six original parameters given subjectively. And in our algorithm, the parameters are replaced by three centers and a distance measure . Finally, our new model is applied to tourism planning in two cases, one can be presented by a dynamic information system and the other one can be presented by a dispersed information system generalized from dynamic information system.},
  archive      = {J_ISCI},
  author       = {Xiaonan Li and Yucong Yan},
  doi          = {10.1016/j.ins.2023.119999},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119999},
  shortjournal = {Inf. Sci.},
  title        = {A dynamic three-way conflict analysis model with adaptive thresholds},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed fault-tolerant consensus for one-sided lipschitz
multiagent systems based on error decomposition and jointly observable
condition. <em>ISCI</em>, <em>657</em>, 119994. (<a
href="https://doi.org/10.1016/j.ins.2023.119994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the performance guaranteed tracking control problem for one-sided Lipschitz (OSL) multiagent systems (MASs) with unknown actuator faults under jointly observable condition (JOC). Unlike the recent results where the state or output information of the leader should be known to its neighbors, only partial output information of the leader can be obtained by its neighbors under JOC in this article. One challenge focuses on the distributed observer design with OSL dynamics under JOC. The studied problem is proceeded in two steps. Firstly, to deal with the difficulty caused by OSL dynamics, an error decomposition technique is used to design the distributed observer. Secondly, based on this observer, a distributed adaptive fault-tolerant protocol with guaranteed performance is designed to realize tracking task. Note that unlike the existing ideas, actuator faults of an agent will not have effect on the dynamics of its neighbors over the communication graph in this article. Simulation results illustrate the developed algorithm.},
  archive      = {J_ISCI},
  author       = {Wang Yang and Jiuxiang Dong},
  doi          = {10.1016/j.ins.2023.119994},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119994},
  shortjournal = {Inf. Sci.},
  title        = {Distributed fault-tolerant consensus for one-sided lipschitz multiagent systems based on error decomposition and jointly observable condition},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust and efficient algorithms for conversational
contextual bandit. <em>ISCI</em>, <em>657</em>, 119993. (<a
href="https://doi.org/10.1016/j.ins.2023.119993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational contextual bandit is one of the notable variants of contextual bandit and it is shown to have superior performance in recommendation applications. The core idea of conversational contextual bandits utilizing is conversational feedback from users to improve the speed of learning user preference. We show that in real-world applications conversational feedback can be imbalanced and such feedback causes the latest conversational contextual bandit algorithm to conduct many conversations but has a slower learning speed than the baseline algorithm without conversational feedback. How to deal with imbalanced conversational feedback? How to schedule conversations across the learning horizon? In-depth analysis of the limitations of one representative conversational contextual bandit algorithm reveals insights to design ICF-UCB (( I mbalanced C onversational F eedback U pper C onfidence B ound)) algorithm, which maintains a fast learning speed under imbalanced feedbacks. ICF-UCB achieves this by adaptively eliminating conversations that may slow down the learning speed. Furthermore, ICF-UCB adaptively schedules conversations to the decision rounds where suboptimal actions may trap the decision maker . It also adaptively selects appropriate conversations to avoid such traps. This algorithm is shown to have sublinear regret. Extensive experiments on synthetic datasets and public real-world datasets (from Yelp and TripAdvisor) validate the superior performance of ICF-UCB for recommendation tasks.},
  archive      = {J_ISCI},
  author       = {Haoran Gu and Yunni Xia and Hong Xie and Xiaoyu Shi and Mingsheng Shang},
  doi          = {10.1016/j.ins.2023.119993},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119993},
  shortjournal = {Inf. Sci.},
  title        = {Robust and efficient algorithms for conversational contextual bandit},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new comprehensive decision making method under bimodal
information. <em>ISCI</em>, <em>657</em>, 119989. (<a
href="https://doi.org/10.1016/j.ins.2023.119989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces comprehensive and theoretically-driven approach to decision making under bimodal uncertainty in form of Z-numbers. The proposed decision making approach relies on synergy of consistency-driven preferences construction method, eigenvector determination method of Z-number valued matrixes proposed by author and his colleagues and modified WSM model. Consistency-driven preferences construction method is used to obtain a consistent Z-valued pair-wise comparison matrix (PCM) given inconsistent one. Indeed, initial Z-number-valued degrees of pairwise comparison of criteria importance provided by a decision maker are often inconsistent. Next, an eigenvector of the consistent Z-valued PCM is computed to derive criteria importance weights. To arrive at normalized Z-values of criteria, a normalization technique is proposed. Overall evaluations of alternatives are computed as a weighted sum of normalized criteria values. Finally, overall values are compared by using ranking of Z-numbers. The suggested decision method is rank reversal free. Correctness and feasibility of suggested method is illustrated by example.},
  archive      = {J_ISCI},
  author       = {Rafig R. Aliyev},
  doi          = {10.1016/j.ins.2023.119989},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119989},
  shortjournal = {Inf. Sci.},
  title        = {A new comprehensive decision making method under bimodal information},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synchronization of fuzzy-chaotic systems with z-controller
in secure communication. <em>ISCI</em>, <em>657</em>, 119988. (<a
href="https://doi.org/10.1016/j.ins.2023.119988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft Computing approaches may be effectively used for the aim to improve security of communication systems . Recently, we proposed a technique for fuzzy-chaotic masking signals generation. In this paper we developed this approach further. It is proposed a procedure for receiver and transmitter synchronization by using fuzzy chaotic systems (fuzzy Lorentz systems). The receiver system utilizes a fuzzy controller based on the use of Z-numbers in If-Then rules. The transmitter system is designed in form of a classical fuzzy system. The fuzzy controller is used to synchronize the fuzzy Lorentz system-based receiver and transmitter at a minimal error.},
  archive      = {J_ISCI},
  author       = {Kanan M. Babanli and Rana Ortac Kabaoglu},
  doi          = {10.1016/j.ins.2023.119988},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119988},
  shortjournal = {Inf. Sci.},
  title        = {Synchronization of fuzzy-chaotic systems with Z-controller in secure communication},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uncertainty-aware multi-criteria decision analysis for
evaluation of explainable artificial intelligence methods: A use case
from the healthcare domain. <em>ISCI</em>, <em>657</em>, 119987. (<a
href="https://doi.org/10.1016/j.ins.2023.119987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a Z-numbers-based Weighted Sum Model (WSM) tailored to evaluate user satisfaction with explanations provided by Explainable Artificial Intelligence (XAI) methods in the healthcare domain. Focusing on the interpretability of XAI, we measure how users perceive the adequacy of explanations through the lens of SHapley Additive exPlanations (SHAP), Individual Conditional Expectation (ICE) plots, and Counterfactual Explanations (CFE). By conducting interviews with healthcare professionals, we integrate their qualitative feedback with quantitative analysis to assess the effectiveness of these methods. The results present a user-centric perspective on the clarity, relevance, and trustworthiness of the generated post-hoc explanations. This study advances the fields of information sciences and healthcare by offering a systematic approach for evaluating XAI, enhancing the transparency and reliability of AI in critical decision-making processes.},
  archive      = {J_ISCI},
  author       = {Kamala Aliyeva and Nijat Mehdiyev},
  doi          = {10.1016/j.ins.2023.119987},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119987},
  shortjournal = {Inf. Sci.},
  title        = {Uncertainty-aware multi-criteria decision analysis for evaluation of explainable artificial intelligence methods: A use case from the healthcare domain},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust GEPSVM classifier: An efficient iterative
optimization framework. <em>ISCI</em>, <em>657</em>, 119986. (<a
href="https://doi.org/10.1016/j.ins.2023.119986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proximal support vector machine via generalized eigenvalues (GEPSVM) is a well-known pattern classification method. GEPSVM, however, is prone to outliers due to its use of the squared L 2 -norm distance criterion. A robust GEPSVM version is proposed to tackle this problem using L 1 -norm distance optimization technique (GEPSVM L1 ). As optimizing a GEPSVM L1 with L 1 -norm terms can be challenging, we have developed an iterative algorithm to address the L 1 -norm ratio problem associated with GEPSVM L1 . Furthermore, an efficient iterative optimization framework has been developed to conveniently address related optimization problems. The research contribution of this paper lies in providing a theoretical analysis of the algorithm’s convergence. Besides, we find that the L 1 -norm distance-based methods in real-world applications, especially for handling samples with outliers, sometimes provides an unsatisfactory recognition result. Thus, a generalized version of GEPSVM L1 is proposed. The L 1 -norm distance is replaced with a L p -norm distance in GEPSVM L1 (GEPSVM Lp ). It is the robust counterpart of GEPSVM L1 and GEPSVM. It is worth noting that we fine-tune GEPSVM Lp ’s parameters to strike a balance between training time and classification accuracy, an especially crucial step for larger datasets. Our experiments indicate that the proposed GEPSVM Lp is more efficient and robust than the competitors in numerous experimental settings. Overall, our work demonstrates the importance of developing robust pattern classification methods in the presence of outliers and provides a practical solution for handling such cases in real-world applications.},
  archive      = {J_ISCI},
  author       = {He Yan and Yan Liu and Yanmeng Li and Qiaolin Ye and Dong-Jun Yu and Yong Qi},
  doi          = {10.1016/j.ins.2023.119986},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119986},
  shortjournal = {Inf. Sci.},
  title        = {Robust GEPSVM classifier: An efficient iterative optimization framework},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CDSC: Causal decomposition based on spectral clustering.
<em>ISCI</em>, <em>657</em>, 119985. (<a
href="https://doi.org/10.1016/j.ins.2023.119985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal discovery is pivotal across numerous scientific and engineering disciplines. General causal discovery methods often falter in accuracy and efficiency when dealing with high-dimensional data due to the curse of dimensionality . While recent advancements in recursive constraint-based methods offer some improvements for high-dimensional causal discovery, their reliance on high-order conditional independence (CI) tests in causal decomposition hinders efficiency and accuracy. To address this challenge, we introduce a novel causal decomposition method based on spectral clustering , called CDSC, tailored for enhanced high-dimensional causal discovery. Concretely, CDSC first constructs the Laplacian matrix of the original variable set based on correlation distance. Then, CDSC decomposes the original variable set into multiple subsets without CI tests and recovers the causal structure of each subset. After determining these causal structures, CDSC merges these sub-results into a complete causal structure. A notable advantage of CDSC over other causal decomposition methods lies in its use of simplified spectral clustering. CDSC preserves the connectivity of the subsets to avoid destroying the causality in partitioned subsets. Moreover, we analyze the validity and time complexity of CDSC theoretically. Exclusive experiments on various real-world causal structures show that CDSC outperforms the state-of-the-arts both in accuracy and efficiency significantly.},
  archive      = {J_ISCI},
  author       = {Shaofan Chen and Yuzhong Peng and Guoyuan He and Hao Zhang and Li Cai and Chengdong Wei},
  doi          = {10.1016/j.ins.2023.119985},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119985},
  shortjournal = {Inf. Sci.},
  title        = {CDSC: Causal decomposition based on spectral clustering},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Multiattribute decision making based on q-rung orthopair
fuzzy yager prioritized weighted arithmetic aggregation operator of
q-rung orthopair fuzzy numbers. <em>ISCI</em>, <em>657</em>, 119984. (<a
href="https://doi.org/10.1016/j.ins.2023.119984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new approach for multiattribute decision making (MADM) using the proposed q -rung orthopair fuzzy Yager prioritized weighted arithmetic ( q -ROFYPWA) aggregation operator (AO) of q -rung orthopair fuzzy numbers ( q -ROFNs). Firstly, we propose the q -ROFYPWA AO of q -ROFNs based on Yager’s t -conorm and t -norm and the concept of prioritized average AO. The proposed q -ROFYPWA AO consider the prioritized relationship among aggregating q -ROFNs. Moreover, we present several properties of the proposed q -ROFYPWA AO. Then, we propose a new MADM approach based on the proposed q -ROFYPWA AO of q -ROFNs. The propsoed MADM approach considers the prioritization among the attributes to overcome the drawbacks of the existing MADM approaches, where they cannot distinguish the ranking orders of the alternatives in some situations. The proposed MADM approach is very useful for MADM in the environment of q -ROFNs.},
  archive      = {J_ISCI},
  author       = {Kamal Kumar and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2023.119984},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119984},
  shortjournal = {Inf. Sci.},
  title        = {Multiattribute decision making based on q-rung orthopair fuzzy yager prioritized weighted arithmetic aggregation operator of q-rung orthopair fuzzy numbers},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differential flatness properties and multivariable adaptive
fuzzy control of hormonal system dynamics. <em>ISCI</em>, <em>657</em>,
119982. (<a href="https://doi.org/10.1016/j.ins.2023.119982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-based control for hormonal (ovarian) system dynamics and for administering in a computationally optimized manner the associated pharmaceutical treatment has been little investigated up to now. Although there has been prior work on the modeling of the ovarian system dynamics and its stability features, there have been hardly any results for applying to the ovarian system exogenous computer-based control. This is due to the complexity, nonlinearity and the high dimensionality of this system. Actually, the ovarian system exhibits nonlinear dynamics which is modeled by a set of thirteen coupled nonlinear differential equations , while receiving only two control inputs. Besides, the fact that the parameters of the model cannot be precisely identified and the fact that any mathematical model for such a biosystem is likely to be subjected to uncertainties and external perturbations, make the application of model-based control schemes for this system be questionable. To overcome this, the paper proposes model-free adaptive fuzzy control based on differential flatness theory for the complex dynamics of the ovarian system. It is proven that the dynamic model of the ovarian system, having as state variables the LH and the FSH hormones and their derivatives, is a differentially flat one. This means that all its state variables and its control inputs can be written as differential functions of the flat output and its derivatives. By exploiting differential flatness properties the system&#39;s dynamic model is written in the multivariable linear canonical (Brunovsky) form, for which the design of a state feedback controller becomes possible. After this transformation, the new control inputs of the system contain unknown nonlinear parts , which are identified with the use of neurofuzzy approximators . Lyapunov stability analysis shows that H-infinity tracking performance is achieved for the feedback control loop and this assures improved robustness to the aforementioned model uncertainty as well as to external perturbations.},
  archive      = {J_ISCI},
  author       = {G. Rigatos},
  doi          = {10.1016/j.ins.2023.119982},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119982},
  shortjournal = {Inf. Sci.},
  title        = {Differential flatness properties and multivariable adaptive fuzzy control of hormonal system dynamics},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hierarchy of jumping restarting automata. <em>ISCI</em>,
<em>657</em>, 119981. (<a
href="https://doi.org/10.1016/j.ins.2023.119981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Restarting automata are a formal model for the linguistic technique of analysis by reduction. In earlier works, all the variants of restarting automata proceed always in a continuous manner. Here we introduce jumping restarting automata that only scan the key information from the input in a discontinuous fashion, which can greatly improve the efficiency in describing the process of a computation. Such an automaton can jump right and skip over a part of tape content. In this work, we investigate the language classes defined through various types of jumping restarting automata. First, we prove that jumping restarting automata can characterize various long-familiar classes of formal languages by taking different degrees, which indicate the number of jump-right operations allowed to be performed per cycle. Further, we show that the language classes defined through jumping restarting automata without auxiliary symbols yield infinite hierarchies based on degrees. Particularly, we prove that for the types of jumping restarting automata with auxiliary symbols, the variant that can continue reading after executing a rewrite operation is strictly more expressive than the variant that cannot do so. This is the first time that the variants above are shown to have different expressive powers in nonmonotone case.},
  archive      = {J_ISCI},
  author       = {Qichao Wang and Yongming Li},
  doi          = {10.1016/j.ins.2023.119981},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119981},
  shortjournal = {Inf. Sci.},
  title        = {A hierarchy of jumping restarting automata},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A bipolar-valued fuzzy set is an intersected interval-valued
fuzzy set. <em>ISCI</em>, <em>657</em>, 119980. (<a
href="https://doi.org/10.1016/j.ins.2023.119980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper shows that a bipolar-valued fuzzy set and a special interval-valued fuzzy set, whose cut-off point of left and right ends of the interval-valued membership is λ λ ( 0 &lt; λ &lt; 1 ) (0&amp;lt;λ&amp;lt;1) , are identical from a mathematical point of view. All results on bipolar-valued fuzzy sets can be obtained by corresponding results of interval-valued fuzzy sets or fuzzy sets. This paper does not completely reject bipolar-valued fuzzy sets, but points the way for such research.},
  archive      = {J_ISCI},
  author       = {Bao Qing Hu and Ka-fai Cedric Yiu},
  doi          = {10.1016/j.ins.2023.119980},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119980},
  shortjournal = {Inf. Sci.},
  title        = {A bipolar-valued fuzzy set is an intersected interval-valued fuzzy set},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Resilient heuristic aggregation of judgments in the pairwise
comparisons method. <em>ISCI</em>, <em>657</em>, 119979. (<a
href="https://doi.org/10.1016/j.ins.2023.119979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In decision-making methods, it is common to assume that the experts are honest and professional. However, this is not the case when one or more experts in the pairwise-based group decision-making framework, such as the group analytic hierarchy process , try to manipulate results in their favor. This paper aims to introduce two heuristics enabling detection of manipulators and minimizing their effect on the group consensus by diminishing their weights. The first heuristic is based on the assumption that manipulators will provide judgments that can be considered outliers with respect to those of the other experts in the group. The second heuristic assumes that dishonest judgments are less consistent than the average consistency of the group. Both approaches are illustrated with numerical examples and simulations.},
  archive      = {J_ISCI},
  author       = {Konrad Kułakowski and Jacek Szybowski and Jiri Mazurek and Sebastian Ernst},
  doi          = {10.1016/j.ins.2023.119979},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119979},
  shortjournal = {Inf. Sci.},
  title        = {Resilient heuristic aggregation of judgments in the pairwise comparisons method},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A time series anomaly detection method based on
series-parallel transformers with spatial and temporal association
discrepancies. <em>ISCI</em>, <em>657</em>, 119978. (<a
href="https://doi.org/10.1016/j.ins.2023.119978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series anomaly detection methods can discover malfunctions in a complex system by detecting anomalies in the monitoring data . Multivariate time series have complex temporal and spatial correlations . Existing methods that explicitly model both correlations only extract semantic information sequentially in a single temporal-spatial or spatial-temporal order. However, different orders have a significant influence on the method&#39;s performance. In addition, a static graph structure trained on normal data has difficulties capturing the change of correlations between features when anomalies occur, limiting the method&#39;s performance. This paper proposes the Spatial-Temporal Anomaly Transformer (STAT), which extracts semantic information comprehensively by combining both spatial-temporal and temporal-spatial orders. STAT uses the Temporal Anomaly Transformer and the Spatial Anomaly Transformer (SAT) to explicitly compute temporal and spatial association discrepancies to conduct anomaly detection . Since the topological structure is usually unknown, SAT adopts a trainable hypersphere to learn the prior-association between features on normal data and computes the distance between the attention weights and the center of the hypersphere as the spatial association discrepancy. AUC and two recently proposed evaluation metrics are used to compare STAT with various typical methods on public data sets, proving that our method can achieve state-of-the-art performance.},
  archive      = {J_ISCI},
  author       = {Shiyuan Fu and Xin Gao and Feng Zhai and Baofeng Li and Bing Xue and Jiahao Yu and Zhihang Meng and Guangyao Zhang},
  doi          = {10.1016/j.ins.2023.119978},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119978},
  shortjournal = {Inf. Sci.},
  title        = {A time series anomaly detection method based on series-parallel transformers with spatial and temporal association discrepancies},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-objective evolutionary algorithm based on dimension
exploration and discrepancy evolution for UAV path planning problem.
<em>ISCI</em>, <em>657</em>, 119977. (<a
href="https://doi.org/10.1016/j.ins.2023.119977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is a crucial process for unmanned aerial vehicles (UAVs) and involves finding a path that is both short and safe. However, with the ever-increasing complexity of the environment, solving the UAV path-planning problem is challenging. Traditional path-planning methods cannot handle conflicting goals effectively, and existing objective methods lack targeted exploration mechanisms, resulting in unsatisfactory outcomes. By modeling the UAV path-planning problem via multi-objective optimization, this study designed a reasonable objective function composition for the model and considered obstacle avoidance as a hard constraint to satisfy the actual situation . A multi-objective evolutionary algorithm based on dimensional exploration and discrepancy evolution (MOEA-2DE) is presented. In particular, MOEA-2DE utilizes dimensional perturbation to identify key dimensions to facilitate prior exploration and enhance the targeted search. An adaptive evolution strategy based on population discrepancy was employed to assess the evolution process, and various methods were adopted to balance convergence and diversity. The effectiveness of the MOEA-2DE was demonstrated through the design of two intricate terrain sets and comparisons with various classic and state-of-the-art multi-objective evolutionary algorithms (MOEAs), including those designed for UAV path planning across multiple metrics. The results verify the superiority of MOEA-2DE in terms of both convergence speed and final effect.},
  archive      = {J_ISCI},
  author       = {Xiuju Xu and Chengyu Xie and Zongfu Luo and Chuanfu Zhang and Tao Zhang},
  doi          = {10.1016/j.ins.2023.119977},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119977},
  shortjournal = {Inf. Sci.},
  title        = {A multi-objective evolutionary algorithm based on dimension exploration and discrepancy evolution for UAV path planning problem},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FedGL: Federated graph learning framework with global
self-supervision. <em>ISCI</em>, <em>657</em>, 119976. (<a
href="https://doi.org/10.1016/j.ins.2023.119976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph data are ubiquitous in the real world. Graph learning (GL) attempts to mine and analyze graph data so that valuable information can be discovered. Existing GL methods are designed for centralized scenarios . However, in practical scenarios, graph data are usually distributed across different organizations, resulting in isolated data silos. To address this problem, we incorporate federated learning into GL and propose a general Fed erated G raph L earning framework called FedGL. FedGL is capable of obtaining a high-quality global graph model while protecting data privacy by discovering the global self-supervision information during the federated training. Specifically, we propose uploading prediction results and node embeddings to the server for discovering the global pseudo labels and global pseudo graph. These are then distributed to each client to enrich the training labels and complement the graph structure respectively, thereby improving the quality of each local model. Moreover, the global self-supervision enables information of each client to flow and be shared in a privacy-preserving manner, thus alleviating the heterogeneity and utilizing the complementarity of graph data among different clients. Finally, experimental results show that FedGL significantly outperforms baselines on four widely used graph datasets.},
  archive      = {J_ISCI},
  author       = {Chuan Chen and Ziyue Xu and Weibo Hu and Zibin Zheng and Jie Zhang},
  doi          = {10.1016/j.ins.2023.119976},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119976},
  shortjournal = {Inf. Sci.},
  title        = {FedGL: Federated graph learning framework with global self-supervision},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Patient deterioration detection using one-class
classification via cluster period estimation subtask. <em>ISCI</em>,
<em>657</em>, 119975. (<a
href="https://doi.org/10.1016/j.ins.2023.119975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deterioration is the significant degradation of the physical state prior to death. Detecting the deterioration of patients could provide an early warning to their families in instances of homecare, to clinicians treating hospitalized patients and to nurses by clients of retirement homes. Traditional supervised machine learning is not helpful for this purpose because the deterioration has individual differences for each patient, and the model cannot access the information about deterioration from healthy patients. This paper applies one-class classification (OCC) to detect deterioration changes. OCC can provide an early warning because the model can learn from only normal conditions. In particular, a one-class time-series classification (OCTSC) algorithm has been developed by combining K-means clustering with sliding windows and a linear regression subtask. The core idea is to detect the change in the signal period related to heart/breathing rate. For this purpose, clustering is applied to sliding windows, and the period is estimated using linear regression for the time index of arbitrary cluster. The deterioration change is detected by unseen scores computed as the error of linear regression subtask for cluster index.},
  archive      = {J_ISCI},
  author       = {Toshitaka Hayashi and Dalibor Cimr and Filip Studnička and Hamido Fujita and Damián Bušovský and Richard Cimler},
  doi          = {10.1016/j.ins.2023.119975},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119975},
  shortjournal = {Inf. Sci.},
  title        = {Patient deterioration detection using one-class classification via cluster period estimation subtask},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards real-world traffic prediction and data imputation: A
multi-task pretraining and fine-tuning approach. <em>ISCI</em>,
<em>657</em>, 119972. (<a
href="https://doi.org/10.1016/j.ins.2023.119972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world traffic prediction is challenging and requires accuracy, efficiency, and generalizability for applications. Most studies used two-step data imputation-prediction procedures or recurrent networks to perform predictions based on imputed data, resulting in error accumulation. Training the same model independently for different missing rates and missing data patterns requires high computational costs. This strategy cannot be integrated with existing methods, causing low generalizability . We propose a multi-task pretraining and fine-tuning (MTPF) approach to address these issues. Specifically, we pretrain an encoder and decoders with different missing data patterns and missing rates and an adversarial noise to learn the correlations between different scenarios and generate robust hidden representations. The encoder and decoder perform fine-tuning for specific missing data scenarios after pretraining. Multiple parallel tasks, including prediction, data imputation , contrastive learning , and adaptive graph learning, are used for pretraining to enable the model to learn the hidden representation for prediction and data imputation during fine-tuning. The MTPF is compared with nine baseline models for prediction and five baseline models for data imputation using two real-world datasets. The experimental results show that MTPF outperforms many state-of-the-art baseline models, has a shorter training time, and is a model-agnostic off-the-shelf plug-in that improves baseline model performance.},
  archive      = {J_ISCI},
  author       = {Yansong Qu and Zhenlong Li and Xiaohua Zhao and Jushang Ou},
  doi          = {10.1016/j.ins.2023.119972},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119972},
  shortjournal = {Inf. Sci.},
  title        = {Towards real-world traffic prediction and data imputation: A multi-task pretraining and fine-tuning approach},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Brain-inspired GCN: Modularity-based siamese simple graph
convolutional networks. <em>ISCI</em>, <em>657</em>, 119971. (<a
href="https://doi.org/10.1016/j.ins.2023.119971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In graph representation learning, Graph Convolutional Networks (GCNs) and their variants have received much attention. However, GCNs encounter oversmoothing as the models get deeper, limiting their ability to aggregate node representations within high-order neighborhood. Inspired by the modular structure of the brain network, we propose Modularity-based Siamese Simple Graph Convolution (MS-SGC), a Siamese network architecture that incorporates the characteristics of brain modular structure into graph convolutional networks. Spectral clustering is leveraged to detect the modular structure in the graph, and then the weight of cross edges between modules is lowered. Siamese network is adopted to combine the modularity-preserved graph representation with the original graph representation, improving classification performance and reducing oversmoothing. Furthermore, a graph convolution method that functions as a linear low-pass graph filter is elaborated through spectral analysis to preserve the similarity of nodes within the same module and further alleviate the oversmoothing problem. We validate the effectiveness of MS-SGC on citation networks and extend our experimental analysis to various downstream tasks. Extensive experiments demonstrate that MS-SGC outperforms state-of-the-arts while reducing the time and computation complexity for node classification . Moreover, MS-SGC achieves competitive performance compared to other state-of-the-arts in node clustering, community prediction and text classification tasks .},
  archive      = {J_ISCI},
  author       = {Xiao Yao and Huyue Zhu and Min Gu},
  doi          = {10.1016/j.ins.2023.119971},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119971},
  shortjournal = {Inf. Sci.},
  title        = {Brain-inspired GCN: Modularity-based siamese simple graph convolutional networks},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Majority vote in social networks. <em>ISCI</em>,
<em>657</em>, 119970. (<a
href="https://doi.org/10.1016/j.ins.2023.119970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a graph G and suppose that initially each node is colored either black or white. In the majority model, in each round all nodes simultaneously update their color to the most frequent color among their neighbors. Experiments on the graph data from the real world social networks (SNs) suggest that if an extremely small set of high-degree nodes, often referred to as the elites, all agree on a color, that color becomes the dominant color at the end of the process. We propose two countermeasures that can be adopted by individual nodes relatively easily and guarantee that the elites will not have this disproportionate power to engineer the dominant output color. The first countermeasure essentially requires each node to make some new connections at random, while the second one demands the nodes to be more reluctant towards changing their color. We verify their effectiveness and correctness both theoretically and experimentally. We also investigate the majority model and a variant of it when the initial coloring is random on the real world SNs and several random graph models . In particular, our results on the Erdős-Rényi and regular random graphs confirm or support several theoretical findings or conjectures by the prior work regarding the threshold behavior of the process.},
  archive      = {J_ISCI},
  author       = {Charlotte Out and Ahad N. Zehmakan},
  doi          = {10.1016/j.ins.2023.119970},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119970},
  shortjournal = {Inf. Sci.},
  title        = {Majority vote in social networks},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting communities in attributed networks through
bi-direction penalized clustering and its application. <em>ISCI</em>,
<em>657</em>, 119969. (<a
href="https://doi.org/10.1016/j.ins.2023.119969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploiting heterogeneous information in attributed networks to improve the performance of community detection has attracted considerable research attention. Although variational graph autoencoder (VGAE)-based methods have been proven to be effective strategies, they perform community detection based on assumptions regarding the dimension of embedding and the number of communities, limiting their effectiveness and applicability. In this study, we combined VGAE-based methods and a bi-direction penalized clustering algorithm (BiPClust) for community detection. Our approach addresses the issues of dimension selection and community number determination by automatically optimizing penalized clustering. Both the computational algorithm and statistical theorems confirm that BiPClust effectively mitigates the impacts of redundant embedding and determines the unknown number of communities. Furthermore, applying the proposed methods to community detection on benchmark datasets and syndicated investment networks in China reveals that BiPClust surpasses other methods in performance.},
  archive      = {J_ISCI},
  author       = {Hu Yang and Wenjing Xiang and Jar-Der Luo and Qiuyan Zhang},
  doi          = {10.1016/j.ins.2023.119969},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119969},
  shortjournal = {Inf. Sci.},
  title        = {Detecting communities in attributed networks through bi-direction penalized clustering and its application},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel transformation methods from semi-three-way decision
spaces to three-way decision spaces and their applications.
<em>ISCI</em>, <em>657</em>, 119962. (<a
href="https://doi.org/10.1016/j.ins.2023.119962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a vital theoretical research of three-way decision (3WD), three-way decision space (3WDS) further enriches the theory on 3WD and enhances its application. In 3WDS, decision evaluation function (DEF) is an indispensable component and plays a crucial role in practical decision problems. But, a large number of valuable functions are the semi-decision evaluation functions (S-DEFs). For this problem, Hu gave many S-DEFs and presented a transformation method from S-DEFs to DEFs. Since then, it has led to a research hotspot that is the introduction of the usual aggregation functions (AFs) into the transformation method of Hu&#39;s form. This paper focuses on the new form of transformation methods from semi-three-way decision spaces (S-3WDSs) to 3WDSs and their applications. Firstly, we present a new form of transformation method with parameter σ from S-DEFs to DEFs. And, we verify both theoretically and experimentally that this introduced parameter σ provides a valid window to dynamically adjust 3WDSs by changing the parameter σ , respectively. Notably, this new form of transformation method covers all existing 3WDSs transformation methods except the representable uninorms-based methods. Secondly, we give a more general function named with F F -function, which can be introduced to these construction methods in the same way as usual AFs. This enables decision-makers to select more suitable functions for solving practical problems. Thirdly, based on the new form, usual AFs and F F -functions, we present some new construction methods of S-DEFs (resp. DEFs) related to fuzzy sets , interval-valued fuzzy sets and random sets. Finally, to make up for the application of the theory of 3WDSs in complex datasets, we select 7 complex datasets for experimenting and conduct comparative and sensitivity analysis to test the viability and efficacy of our methods. Notably, we also give an algorithm to calculate the thresholds α and β , which can adjust the optimal thresholds α and β according to different 3WDSs.},
  archive      = {J_ISCI},
  author       = {Yiding Wang and Junsheng Qiao and Tengbiao Li},
  doi          = {10.1016/j.ins.2023.119962},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119962},
  shortjournal = {Inf. Sci.},
  title        = {Novel transformation methods from semi-three-way decision spaces to three-way decision spaces and their applications},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multipopulation multitasking evolutionary scheme with
adaptive knowledge transfer to solve the clustered minimum routing cost
tree problem. <em>ISCI</em>, <em>657</em>, 119961. (<a
href="https://doi.org/10.1016/j.ins.2023.119961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement in communication technology nowadays has increased the number of networked devices exponentially. Thus, network applications begin to cluster terminals to address scalability, privacy, and device connectivity with low routing costs. A recently introduced NP-hard problem called the Clustered Minimum Routing Cost Tree (CluMRCT) problem is assessed to be a fundamental key in designing an efficient network with low routing costs. Lately, some evolutionary multitasking meta-heuristics have been proposed to tackle multiple CluMRCT problems concurrently. However, these previous studies still have some limitations, such as only being applicable to complete graphs or there is no mechanism for effective knowledge transfer between problems when solving them simultaneously. To overcome these limitations, this paper proposes a novel multi-population multitasking evolutionary framework to address the problem. The individual representation is developed based on Network random key scheme and can be applied to both sparse and complete graphs. Moreover, our proposal can adaptively exploit positive knowledge transfer by adjusting the number of individuals migrating from other populations to a particular task. Then, the proposed algorithm is experimented on various data types and compared with other state-of-the-art algorithms. The experimental results show the proposal&#39;s effectiveness in most cases of the dataset, followed by detailed comparison, evaluation, and analysis.},
  archive      = {J_ISCI},
  author       = {Nguyen Binh Long and Do Tuan Anh and Ha-Bang Ban and Huynh Thi Thanh Binh},
  doi          = {10.1016/j.ins.2023.119961},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119961},
  shortjournal = {Inf. Sci.},
  title        = {A multipopulation multitasking evolutionary scheme with adaptive knowledge transfer to solve the clustered minimum routing cost tree problem},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint group and pairwise localities embedding for feature
extraction. <em>ISCI</em>, <em>657</em>, 119960. (<a
href="https://doi.org/10.1016/j.ins.2023.119960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many practical applications generate high-dimensional data, which poses challenges in terms of computational time and storage. To address this issue, feature extraction has become a popular research topic . Learning by way of graph embedding is useful for discovering potential intrinsic low-dimensional structures and has thus gained wide attention. However, traditional embedding models typically utilize only one graph or one type of multiple graphs to capture local relationships, which may be insufficient for high-dimensional data that may exhibit different kinds of local relationships. To overcome this drawback, we developed a joint embedding framework that incorporates multiple types of graphs. Under this framework, a novel joint group and pairwise locality embedding model (GPE) is proposed. The GPE model has the following distinctive merits: (1) it simultaneously incorporates simple graphs, hypergraphs , and probabilistic hypergraphs, enabling the use of not only one type of multiple graphs but also multiple types of multiple graphs; (2) it can leverage both group relationships and pairwise graphs to discover local information during feature extraction; and (3) its objective function can be solved using an alternating optimization strategy , which involves solving eigenvalue problems and quadratic programming problems, resulting in very fast convergence. Finally, we arranged classification tasks and clustering tasks on several high-dimensional real-world datasets, and the experimental results prove that the identification capability of GPE is encouraging.},
  archive      = {J_ISCI},
  author       = {Wenjun Hu and Ke Zhang and Shitong Wang and Yong Zhang},
  doi          = {10.1016/j.ins.2023.119960},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119960},
  shortjournal = {Inf. Sci.},
  title        = {Joint group and pairwise localities embedding for feature extraction},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differentially private trajectory event streams publishing
under data dependence constraints. <em>ISCI</em>, <em>657</em>, 119959.
(<a href="https://doi.org/10.1016/j.ins.2023.119959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential Privacy (DP), as a de facto privacy-preserving paradigm, can be widely applied in numerous event streams publishing schemes to protect private events (i.e., trajectory points of users). However, most existing schemes assume these events are independent, which is a vulnerable assumption that can lead to unforeseeable privacy degradation. The privacy-preserving for event streams publishing under data dependence is still challenging because existing dependence quantify models cannot dynamically measure the degree of dependent relationships between events. In this paper, we investigate the privacy degradation issue of trajectory event streams publishing and propose ( Θ , ϵ ) (Θ,ϵ) -dependent privacy mechanism to mitigate this issue. Specifically, we introduce spatial dependence to model the dependent relationship between events in trajectory data and extend it to quantify the influence of multiple dependent events on the target event. We define the notion of max dissimilarity to formalize the privacy level of DP mechanisms in trajectory event streams publishing. The proposed notion of global dependent coefficient helps the private mechanism to provide the expected privacy level by calibrating the added noise. We further achieve ω -event privacy protection over trajectory event streams under data dependence constraints with ( Θ , ϵ ) (Θ,ϵ) -dependent privacy mechanism. Theoretical analysis proves our scheme provides the expected privacy guarantee under data dependence constraints. Extensive experiments validate our scheme is efficient and effective.},
  archive      = {J_ISCI},
  author       = {Yuan Shen and Wei Song and Yang Cao and Zechen Liu and Zhe Wei and Zhiyong Peng},
  doi          = {10.1016/j.ins.2023.119959},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119959},
  shortjournal = {Inf. Sci.},
  title        = {Differentially private trajectory event streams publishing under data dependence constraints},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Defining and visualizing process execution variants from
partially ordered event data. <em>ISCI</em>, <em>657</em>, 119958. (<a
href="https://doi.org/10.1016/j.ins.2023.119958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The execution of operational processes generates event data stored in enterprise information systems . Process mining techniques analyze such event data to obtain insights vital for decision-makers to improve the reviewed process. In this context, event data visualizations are essential. We focus on visualizing variants describing process executions that are control flow equivalent. Such variants are an integral concept for process mining and are used, for instance, for data exploration and filtering. We propose high-level and low-level variants covering different levels of abstraction and present corresponding visualizations. Compared to existing variant visualizations, we support partially ordered event data and allow for heterogeneous temporal information per event, i.e., we support both time intervals and time points . We evaluate our contributions using automated experiments showing practical applicability to real-life event data. Finally, we present a user study indicating significantly improved usefulness and ease of use of the proposed high-level variant visualization compared to existing variant visualizations for typical analysis tasks.},
  archive      = {J_ISCI},
  author       = {Daniel Schuster and Francesca Zerbato and Sebastiaan J. van Zelst and Wil M.P. van der Aalst},
  doi          = {10.1016/j.ins.2023.119958},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119958},
  shortjournal = {Inf. Sci.},
  title        = {Defining and visualizing process execution variants from partially ordered event data},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel efficient rank-revealing QR matrix and schur
decomposition method for big data mining and clustering (RRQR-SDM).
<em>ISCI</em>, <em>657</em>, 119957. (<a
href="https://doi.org/10.1016/j.ins.2023.119957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big Data is an emerging technology with enormous potential to develop business and its administration. Due to the enormous volume, efficient data mining and clustering methods are crucial to extracting meaningful insights and patterns from large-scale datasets. Problems may arise from the need to analyze, capture, share, store, and visualize the data. Several methods have already been proposed for mining knowledge from big data. It is practically inefficient or impossible to handle these massive data using the proposed methods in a single machine because big data are frequently acquired from dispersed locations and stored on several machines. Matrix decomposition is one of the critical strategies to retrieve knowledge from diverse, noisy, huge data generated by modern applications and stored in dispersed locations. This study proposes a novel approach called the Rank-Revealing QR Matrix and Schur Decomposition Method (RRQR-SDM) specifically designed for big data mining and clustering tasks . The RRQR-SDM is designed to reveal the rank of the data matrix in a computationally efficient manner by using a modified QR decomposition, eliminating the need for expensive Singular Value Decomposition (SVD) computations. The proposed RRQR-SDM method offers several advantages over existing approaches. Firstly, exploiting the inherent low-rank structure reduces the computational complexity associated with large-scale datasets. By revealing the rank of the input matrix, it enables dimensionality reduction and efficient data compression . Secondly, the Schur decomposition enhances the interpretability of the data by providing a clear separation between the relevant and irrelevant components. This feature makes the RRQR-SDM method particularly suitable for data mining and clustering tasks where identifying the most significant features is essential. To evaluate the performance of the RRQR-SDM method, extensive experiments were conducted on various big data datasets. The results demonstrate that the proposed method outperforms state-of-the-art computational efficiency and clustering accuracy techniques.},
  archive      = {J_ISCI},
  author       = {D. Paulraj and K.A. Mohamed Junaid and T. Sethukarasi and M. Vigilson Prem and S. Neelakandan and Adi Alhudhaif and Norah Alnaim},
  doi          = {10.1016/j.ins.2023.119957},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119957},
  shortjournal = {Inf. Sci.},
  title        = {A novel efficient rank-revealing QR matrix and schur decomposition method for big data mining and clustering (RRQR-SDM)},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cost-sensitive thresholding over a two-dimensional decision
region for fraud detection. <em>ISCI</em>, <em>657</em>, 119956. (<a
href="https://doi.org/10.1016/j.ins.2023.119956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit fraud poses a challenging task in terms of detection. It can result in significant losses depending on the amount, so a cost-sensitive perspective needs to be taken. Classical approaches focus on estimating the probability of fraud and selecting a decision threshold, but they often fail to consider the transaction amount or account for the cumulative losses incurred within the sample. Consequently, these approaches can result in sub-optimal strategies. A new thresholding approach is proposed, based on the construction of a two-dimensional decision space with an estimated probability and the credit amount. This expansion allows more freedom for the optimal classification rule search, which is performed with a new algorithm. The proposed method generalizes previous approaches, so an improvement is consistently achieved. In addition, it allows a restricted search. This is shown in a study of two real data sets, comparing the results obtained by a wide range of classifiers .},
  archive      = {J_ISCI},
  author       = {Jorge C-Rella and Ricardo Cao and Juan M. Vilar},
  doi          = {10.1016/j.ins.2023.119956},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119956},
  shortjournal = {Inf. Sci.},
  title        = {Cost-sensitive thresholding over a two-dimensional decision region for fraud detection},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimator-based event-triggered output synchronization for
heterogeneous multi-agent systems under denial-of-service attacks and
actuator faults. <em>ISCI</em>, <em>657</em>, 119955. (<a
href="https://doi.org/10.1016/j.ins.2023.119955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the output synchronization problem with an event-triggered communication scheme for a class of heterogeneous multi-agent systems under denial-of-service (DoS) attacks and actuator faults . DoS attacks may render the followers incapable of acquiring the leader&#39;s states and actuator faults may cause the actuators to not perform the control operation well. Comparing with the previous studies adopting the continuous communication mechanism, a novel switching estimator with an event-triggered communication strategy is designed to estimate the leader&#39;s states for each follower. By using the Lyapunov stability theory and the average dwell time method, sufficient conditions for the upper bound of the frequency of DoS attacks are derived. The estimation error system is proved to be exponentially stable. Besides, in order to compensate for actuator faults, a distributed adaptive fault-tolerant controller is proposed. The conditions for the stability of the output regulation error when the systems suffer from DoS attacks and actuator faults are given. A simulation example is proposed to prove the effectiveness of the main results.},
  archive      = {J_ISCI},
  author       = {Kaiyue Dong and Guang-Hong Yang and Huimin Wang},
  doi          = {10.1016/j.ins.2023.119955},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119955},
  shortjournal = {Inf. Sci.},
  title        = {Estimator-based event-triggered output synchronization for heterogeneous multi-agent systems under denial-of-service attacks and actuator faults},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A game-theory-based scheme to facilitate consensus latency
minimization in sharding blockchain. <em>ISCI</em>, <em>657</em>,
119954. (<a href="https://doi.org/10.1016/j.ins.2023.119954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unbalanced consensus latency in reaching a consensus on transactions occurs due to differences in the ability of different committees to process transactions. As the consensus latency accumulates, the transaction throughput of the sharding blockchain significantly decreases. This article proposes a consensus latency minimization scheme to improve the transaction throughput. According to a time-varying directed graph and a non-cooperative game model solved by a distributed algorithm, we show that the generalized Nash equilibrium for all committees are to balance the differences in consensus latency among various committees and to minimize the consensus latency throughout the whole period. The security of the proposed scheme is analyzed by considering the peaceful equilibrium, and the committee actions asymptotically converge to a generalized Nash equilibrium . Through the comparisons with other baseline algorithms via simulation experiments, we demonstrate that our proposed scheme could result in the optimal consensus latency and throughput. Therefore, the proposed consensus latency minimization scheme effectively avoids the existing problem of the transaction throughput in sharding blockchain and provides a viable and security instrument for the sharding blockchain operator to improve the transaction throughput performance throughout the whole period.},
  archive      = {J_ISCI},
  author       = {Cheng Guo and Binbin Zheng and Yingmo Jie and Yining Liu and Yan Hu},
  doi          = {10.1016/j.ins.2023.119954},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119954},
  shortjournal = {Inf. Sci.},
  title        = {A game-theory-based scheme to facilitate consensus latency minimization in sharding blockchain},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lagrangian dual theory and stability analysis for fuzzy
optimization problems. <em>ISCI</em>, <em>657</em>, 119953. (<a
href="https://doi.org/10.1016/j.ins.2023.119953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the Lagrangian dual theory for a class of fuzzy optimization problems with equality and inequality constraints . To begin with, the Lagrangian dual problem corresponding to the primal fuzzy optimization problem is established by introducing the Lagrangian fuzzy-valued function, and the weak dual theorem is derived. Subsequently, a necessary and sufficient condition for the existence of saddle-points is formulated, which serves as the fundamental basis for proving the strong dual theorem. The stability of the optimization model when its constraints are perturbed by parameters is then analyzed. Finally, the developed Lagrangian dual theory is applied to support vector machines to address the binary classification problem of triangular fuzzy number datasets.},
  archive      = {J_ISCI},
  author       = {Fangfang Shi and Guoju Ye and Wei Liu and Dafang Zhao and Savin Treanţǎ},
  doi          = {10.1016/j.ins.2023.119953},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119953},
  shortjournal = {Inf. Sci.},
  title        = {Lagrangian dual theory and stability analysis for fuzzy optimization problems},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Breaking the curse of dimensional collapse in graph
contrastive learning: A whitening perspective. <em>ISCI</em>,
<em>657</em>, 119952. (<a
href="https://doi.org/10.1016/j.ins.2023.119952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimensional collapse in graph contrastive learning (GCL) confines node embeddings to their lower-dimensional subspace, diminishing their distinguishability. However, the causes and solutions of this curse remain relatively underexplored. In statistics , whitening presents a powerful tool to eliminate correlations among multiple variables. This motivates us to relieve the dimensional collapse of GCL from a whitening perspective. In this paper, we propose an intuitive analysis suggesting that high similarity scores of node embeddings may cause dimensional collapse, providing more evidence for its presence. Considering the success of whitening in statistics, we introduce a new plug-and-play module called the hitening raph ontrastive earning ( WGCL ) to address the dimensional collapse issue in existing GCL methods. WGCL plugin standardises the covariance matrices of dimensions, eliminating correlations among node embeddings&#39; dimensions. Additionally, we enhance the conventional GCL training objective by introducing a mutual information maximisation loss between input features and node embeddings to maintain information capacity. Our experiments demonstrate that WGCL effectively addresses dimensional collapse, leading to an average improvement of 0.93% (up to 2.0%) in classification accuracy across three GCL backbones on nine widely-used datasets. The code to reproduce the experiments is available at https://github.com/acboyty/WGCL .},
  archive      = {J_ISCI},
  author       = {Yang Tao and Kai Guo and Yizhen Zheng and Shirui Pan and Xiaofeng Cao and Yi Chang},
  doi          = {10.1016/j.ins.2023.119952},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119952},
  shortjournal = {Inf. Sci.},
  title        = {Breaking the curse of dimensional collapse in graph contrastive learning: A whitening perspective},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TRNN: An efficient time-series recurrent neural network for
stock price prediction. <em>ISCI</em>, <em>657</em>, 119951. (<a
href="https://doi.org/10.1016/j.ins.2023.119951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction results in big data analysis can vary greatly depending on the data preprocessing methods used. Time series-based processing methods are particularly advantageous for prediction. While popular neural network models such as Back Propagation (BP), Recurrent Neural Network (RNN), and Long Short-Term Memory (LSTM) are based on weight, loss function, and other factors, their training efficiency is still relatively low. In this paper, we propose an efficient Time-series Recurrent Neural Network (TRNN) for stock price prediction. In the proposed model, trading volume is established and sliding windows are used to process the time series data . The trends and turning points of the data are extracted according to financial market features, and data compression is achieved. To improve the impact of recent trading volume on the current stock price, the price-volume relationship is upgraded from one dimension to two dimensions based on RNN. The information about trading volume is processed and compressed to establish the TRNN model, which guarantees both accuracy and efficiency. We compare our TRNN model with the original RNN and LSTM models in terms of efficiency and accuracy. We further discuss the feasibility of related expanded schemes of our TRNN model, as well as the extendability of the time-series compression and TRNN model to other fields.},
  archive      = {J_ISCI},
  author       = {Minrong Lu and Xuerong Xu},
  doi          = {10.1016/j.ins.2023.119951},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119951},
  shortjournal = {Inf. Sci.},
  title        = {TRNN: An efficient time-series recurrent neural network for stock price prediction},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Outlier detection in a multiset-valued information system
based on rough set theory and granular computing. <em>ISCI</em>,
<em>657</em>, 119950. (<a
href="https://doi.org/10.1016/j.ins.2023.119950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection on data with missing information values is especially tricky because the uncertainty caused by missing information values may contribute to an object being an outlier. A multiset-valued information system (MSVIS) is an information system (IS) in which information values are multisets. This kind of IS is a useful way of handling datasets with missing information values. In this paper, we study outlier detection in an MSVIS based on rough set theory and granular computing . First, some concepts of multisets and probability distribution sets are reviewed, and the fact that a weak one-to-one correspondence exists between multisets and rational probability distribution sets is illustrated. In this way, multisets may be treated as rational probability distribution sets. Then, an MSVIS can be induced by an incomplete information system (IIS) and viewed as the result of information fusion of multiple categorical ISs. Next, a tolerance relation in an MSVIS is constructed with the induced rational probability distribution sets. Then, the outlier factor in an MSVIS is formulated, and the corresponding outlier detection algorithm is proposed. Finally, the performance evaluation by AUC (area under the curve) and F1-score shows the superiority of the proposed algorithm over some existing algorithms.},
  archive      = {J_ISCI},
  author       = {Yan Song and Hai Lin and Zhaowen Li},
  doi          = {10.1016/j.ins.2023.119950},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119950},
  shortjournal = {Inf. Sci.},
  title        = {Outlier detection in a multiset-valued information system based on rough set theory and granular computing},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An effective population-based iterated greedy algorithm for
solving the multi-AGV scheduling problem with unloading safety
detection. <em>ISCI</em>, <em>657</em>, 119949. (<a
href="https://doi.org/10.1016/j.ins.2023.119949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing prevalence of automated guided vehicles (AGVs), the multi-AGV scheduling problem has become a hot research topic in recent years. However, little attention has been devoted to unloading safety detection for multi-AGV scheduling. This paper investigates a multi-AGV scheduling problem with unloading safety detection (MAGVS USD ) in a matrix manufacturing workshop. The aim is to minimize the total cost composed of travel cost, penalty cost and cost of AGV used. To address the MAGVS USD , a mixed-integer linear programming model and a population-based iterated greedy (PIG) algorithm are proposed. In the PIG, a hyper-heuristic based on neighborhood operators and a population-based initialization method are proposed to obtain multiple high-quality initial solutions. The two-stage destruction strategy is designed to avoid falling into the local optimal solution and to enhance its ability to explore a larger solution space. The two-choice reconstruction strategy is developed to obtain better neighbor solutions by switching the search landscape. The local search based on the winning neighbor operators is proposed to dynamically adapt to each distribution situation in the workshop. A large number of experimental results demonstrate the proposed algorithm&#39;s superiority over existing algorithms in addressing the considered problem.},
  archive      = {J_ISCI},
  author       = {Wenqiang Zou and Jiazhen Zou and Hongyan Sang and Leilei Meng and Quanke Pan},
  doi          = {10.1016/j.ins.2023.119949},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119949},
  shortjournal = {Inf. Sci.},
  title        = {An effective population-based iterated greedy algorithm for solving the multi-AGV scheduling problem with unloading safety detection},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy-based adaptive event-triggered control for nonlinear
cyber-physical systems against deception attacks via a single parameter
learning method. <em>ISCI</em>, <em>657</em>, 119948. (<a
href="https://doi.org/10.1016/j.ins.2023.119948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the adaptive fuzzy control issue of cyber-physical systems (CPSs) against unknown deception attacks and external disturbance . Based on the backstepping design framework, the uncertainty term composed of the approximation error term generated by the fuzzy logic system , the external disturbance and the deception attack signals are regarded as a whole in the recursive design process. Then, by combining the single parameter learning method with the adaptive fuzzy technique, the uncertain terms containing approximation error, disturbance and injection attacks can be transformed into the form of linear parameterization with only one unknown scalar parameter, which greatly reduce the calculation process. In addition, the dynamic event-triggered adaptive control technology can be integrated into the control design to reduce the amount of data transmission. Theoretical analysis shows that all the signals in the closed-loop system are bounded under the proposed control scheme, and the Zeno behavior is excluded. Finally, the two-stage chemical reactor and mass-spring-damper systems are employed to demonstrate the validity of the proposed adaptive fuzzy control solution.},
  archive      = {J_ISCI},
  author       = {Ning Zhao and Yongjie Tian and Huiyan Zhang and Enrique Herrera-Viedma},
  doi          = {10.1016/j.ins.2023.119948},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119948},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy-based adaptive event-triggered control for nonlinear cyber-physical systems against deception attacks via a single parameter learning method},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reweighted robust and discriminative latent subspace
projection for face recognition. <em>ISCI</em>, <em>657</em>, 119947.
(<a href="https://doi.org/10.1016/j.ins.2023.119947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace projection has been widely studied to implement the feature extraction for face recognition. However, it scarcely facilitates exploring the label information in the subspace projection procedure. The feature extraction and classification are usually divided into two separate procedures. This fails to explore the discriminative information from the training data , and thus degrades the discrimination of the extracted features and lowers the face recognition accuracy . To address this issue, we present a novel reweighted robust and discriminative latent subspace projection (ReRDLSP) method which organically integrates the reweighted latent low-rank representation model and discriminative ridge regression into a union framework. We employ a reweighted nuclear norm minimization to realize the low-rank regularization , which provides adaptive weighted values assignment, regularizes the representation matrix adaptively, and thus boosts the capability and flexibility of the method. Moreover, a discriminative ridge regression method is presented by employing a nonnegative relaxation, which enlarges the margins of the face samples from different classes as much as possible and boosts the freedom of fitting the label information. The computational complexity and convergence analysis are also discussed in detail. Extensive experiments are demonstrated and very promising results are achieved compared with some state-of-the-art face recognition methods .},
  archive      = {J_ISCI},
  author       = {Dongxu Cheng and Xinman Zhang and Xuebin Xu},
  doi          = {10.1016/j.ins.2023.119947},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119947},
  shortjournal = {Inf. Sci.},
  title        = {Reweighted robust and discriminative latent subspace projection for face recognition},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximating robust pareto fronts by the MEOF-based
multiobjective evolutionary algorithm with two-level surrogate models.
<em>ISCI</em>, <em>657</em>, 119946. (<a
href="https://doi.org/10.1016/j.ins.2023.119946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multiobjective optimization problems (MOPs) under uncertain environments are very challenging to be solved due to the sensitivities of some robust decision variables. To find the robust Pareto fronts (PFs) of these MOPs, the mean effective objective function (MEOF) is often used for evaluating the qualities of solutions in the existing evolutionary multiobjective optimization (EMO) algorithms. In the MEOF evaluation , the objective function values of multiple solutions in the neighborhood of a certain solution should be averaged. As a result, the MEOF-based EMO algorithms consume a large number of function evaluations to find robust PFs with high qualities. To overcome this weakness, we propose a new MEOF-based EMO framework with two-level surrogate models , denoted by EMO-MEOF/TS, which utilizes radial basis function and Gaussian process model to predict high-quality robust solutions at the levels of global search and local search . Some experiments are conducted to evaluate the performance of the proposed framework on some modified MOPs with robust decision variables. Our experimental results demonstrate that EMO-MEOF/TS is advantageous against several robust MOEAs in approximating the PFs of MOPs with robust characteristics.},
  archive      = {J_ISCI},
  author       = {Yuxiang Shui and Hui Li and Jianyong Sun and Qingfu Zhang},
  doi          = {10.1016/j.ins.2023.119946},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119946},
  shortjournal = {Inf. Sci.},
  title        = {Approximating robust pareto fronts by the MEOF-based multiobjective evolutionary algorithm with two-level surrogate models},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature selection based on self-information combining
double-quantitative class weights and three-order approximation
accuracies in neighborhood rough sets. <em>ISCI</em>, <em>657</em>,
119945. (<a href="https://doi.org/10.1016/j.ins.2023.119945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is related to information processing, and its measurement and algorithm use various intelligent methodologies, such as neighborhood rough sets (NRSs). At present by NRSs, the relative neighborhood self-information (Relative-NSI) introduces an information function for algebraic characterization, and its feature selection algorithm (NSI-FS) has been successfully applied. However, Relative-NSI and NSI-FS ignore the underlying recognition information of decision classes; thus, they have the advancement space. In this study, absolute rates and correlative coefficients of decision classes are double-quantitatively introduced, and three-order approximation accuracies are systematically established to induce a robust self-information measure; thus, corresponding feature selection optimally improves NSI-FS to have generalization abilities . Firstly, three-order approximation accuracies are constructed by using two-time class weights of absolute rates and Spearman&#39;s correlation coefficients, and the new measure called ClaWNSI promotes Relative-NSI in terms of class recognition. Then, the three-order approximation accuracies and subsequent ClaWNSI are evolved in matrix forms, and relevant class weights of Spearman&#39;s correlation coefficients are realized by two vectors from approximation matrices . Furthermore, ClaWNSI and its feature significance motivate a heuristic selection algorithm (called ClaWNSI-FS). Finally, data experiments on 14 datasets validate ClaWNSI and ClaWNSI-FS; ClaWNSI-FS outperforms NSI-FS and five other contrast algorithms to acquire better classification performance.},
  archive      = {J_ISCI},
  author       = {Jiefang Jiang and Xianyong Zhang},
  doi          = {10.1016/j.ins.2023.119945},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119945},
  shortjournal = {Inf. Sci.},
  title        = {Feature selection based on self-information combining double-quantitative class weights and three-order approximation accuracies in neighborhood rough sets},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Strategic information sharing in the dual-channel closed
loop supply chain with nonlinear production cost. <em>ISCI</em>,
<em>657</em>, 119944. (<a
href="https://doi.org/10.1016/j.ins.2023.119944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the strategy of information sharing within a closed loop supply chain comprising three echelons and dual channels. By considering the supplier’s collecting activities and the two formats of nonlinear production costs ( i.e. , production diseconomy and production economy) faced by the manufacturer, we construct and utilize game-theoretic models to determine the optimal strategy ( i.e. , no sharing, sharing information solely with the manufacturer, sharing with the supplier, and sharing with both the manufacturer and supplier) for information sharing by the retailer. The findings indicate that the retailer&#39;s inclination to voluntarily share information and the most effective approach are significantly influenced by the interplay between the supplier&#39;s recycling efficiency and the manufacturer&#39;s nonlinear production cost. Specifically, in the context of production diseconomy, it is commonly observed that the retailer can derive advantages by engaging in information sharing with a supplier who possesses a high recycling efficiency. In contract, the retailer would share the information when the recycling efficiency is high or the production economy coefficient is large. Otherwise, no sharing strategy can be considered as the optimal choice. Ultimately, the study aims to assess the effects of various approaches to sharing information on the remaining participants within the supply chain.},
  archive      = {J_ISCI},
  author       = {Tong-Yuan Wang and Zhen-Song Chen and Xian-Jia Wang and Kannan Govindan and Miroslaw J. Skibniewski},
  doi          = {10.1016/j.ins.2023.119944},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119944},
  shortjournal = {Inf. Sci.},
  title        = {Strategic information sharing in the dual-channel closed loop supply chain with nonlinear production cost},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient algorithm deciding chaos for linear cellular
automata over (z/mZ)n with applications to data encryption.
<em>ISCI</em>, <em>657</em>, 119942. (<a
href="https://doi.org/10.1016/j.ins.2023.119942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide an efficient algorithm deciding chaos for linear cellular automata (LCA) over ( Z / m Z ) n (Z/mZ)n , a large and important class of cellular automata (CA) which may exhibit many of the complex features typical of general CA and are used in many applications. The efficiency of our algorithm is mainly due to fact that it avoids the computation of the prime factor decomposition of m which is a well-known difficult task. Instead of factoring m we make use of a new and efficient generalized technique for computing the greatest common divisor (gcd) of polynomials with coefficients not belonging to a field, which in itself is an interesting result. We wish also to emphasize that the gcd computations required by our algorithm always involve polynomials of degree at most n . We also illustrate the impact of our algorithm in real-world applications regarding the growing domain of cryptosystems , the latter being often based on LCA over ( Z / m Z ) n (Z/mZ)n with n &gt; 1 n&amp;gt;1 . As a matter of facts, since cryptosystems have to satisfy the so-called confusion and diffusion properties (which are ensured if the involved LCA is chaotic) our algorithm turns out to be an important tool for building chaotic LCA over ( Z / m Z ) n (Z/mZ)n and, hence, for improving the existing methods based on them.},
  archive      = {J_ISCI},
  author       = {Alberto Dennunzio and Enrico Formenti and Luciano Margara},
  doi          = {10.1016/j.ins.2023.119942},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119942},
  shortjournal = {Inf. Sci.},
  title        = {An efficient algorithm deciding chaos for linear cellular automata over (Z/mZ)n with applications to data encryption},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Partially-defined equivalence relations: Relationship with
orthopartitions and connection to rough sets. <em>ISCI</em>,
<em>657</em>, 119941. (<a
href="https://doi.org/10.1016/j.ins.2023.119941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce partially-defined equivalence relations as a type of equivalence relation that incorporates uncertainty. In these relations, certain pairs of objects are not definitively determined to be related or unrelated. The relationship with orthopartitions is put forward, providing the conditions under which an orthopartition can be transformed into an equivalent partially-defined equivalence relation and vice versa. Additionally, we explore their connection with reducts in rough set theory , offering insights into the characterization of similarity reducts in terms of orthopartitions.},
  archive      = {J_ISCI},
  author       = {Stefania Boffa and Andrea Campagner and Davide Ciucci},
  doi          = {10.1016/j.ins.2023.119941},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119941},
  shortjournal = {Inf. Sci.},
  title        = {Partially-defined equivalence relations: Relationship with orthopartitions and connection to rough sets},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neuroevolutionary diversity policy search for
multi-objective reinforcement learning. <em>ISCI</em>, <em>657</em>,
119932. (<a href="https://doi.org/10.1016/j.ins.2023.119932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential decision-making requires balancing multiple conflicting objectives through multi-objective reinforcement learning (MORL). Moreover, decision-makers desire dense solutions that satisfy their requirements and consider the trade-offs between different objectives (Pareto optimal solutions). Most deep reinforcement learning methods focus on single-objective problems or solve multi-objective problems using simple linear combinations , which may oversimplify the underlying problem and lead to suboptimal results. This study proposes a neuroevolutionary diversity policy search approach to address MORL problems. It employs neural networks , each equipped with a buffer for storing recent experiences, representing individuals in a population. The non-dominated sorting method and diversity distance metric are employed in the evolutionary process to select high-quality solutions as teachers . The teachers use gradient-based genetic operators to guide the population to produce high-quality offspring, thereby achieving dense Pareto optimal solutions . Furthermore, we introduce three MORL benchmarks with distinct characteristics: (1) a continuous deep sea treasure with convex and nonconvex Pareto fronts ; (2) a multi-objective mountain car with sparse rewards and a discontinuous Pareto front; and (3) a multi-objective HalfCheetah with high-dimensional action-state spaces. The experimental results on the three MORL benchmarks demonstrate the superiority of the proposed algorithm in obtaining dense and high-quality Pareto optimal solutions.},
  archive      = {J_ISCI},
  author       = {Dan Zhou and Jiqing Du and Sachiyo Arai},
  doi          = {10.1016/j.ins.2023.119932},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119932},
  shortjournal = {Inf. Sci.},
  title        = {Neuroevolutionary diversity policy search for multi-objective reinforcement learning},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Opinion evolution and dynamic trust-driven consensus model
in large-scale group decision-making under incomplete information.
<em>ISCI</em>, <em>657</em>, 119925. (<a
href="https://doi.org/10.1016/j.ins.2023.119925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shift to a new era of dealing with big data has driven continuous progress and development in computer science, artificial intelligence and machine learning . This change has led to the application of advanced techniques in the realm of decision science, particularly in the area of large-scale group decision-making (LSGDM). However, although these existing techniques have become the core of LSGDM methods , they are still limited in solving problems facing incomplete data. In addition, due to the rise of social media platforms such as Weibo, WeChat and Twitter, which build bridges for communication between decision makers (DMs), this brings new opportunities and challenges for consensus research. To address this set of issues, this study develops a consensus architecture that combines dynamic social network and opinion evolution in the context of an incomplete multi-attribute LSGDM. It is worth mentioning that the proposed consensus framework is a novel decision-making system that can be used to complete the estimation of the missing values and the consensus reaching process (CRP) by simulating the realistic decision-making scenarios. Firstly, considering the size of the trust value and the length of the path, a new trust propagation method is designed to achieve a more reliable estimation of the unknown trust value. Secondly, this paper establishes a missing value estimation method by virtue of the improved DeGroot model, which is able to obtain complete evaluation information by simulating the opinion formation process of DMs. Next, a hierarchical clustering algorithm with stronger robustness is constructed, which not only can adaptively complete the clustering process , but also integrally considers two attributes of trust and opinion similarity. In light of the above research, this study designs an opinion evolution and dynamic trust-driven consensus model, referred to as the DSN-DG-LSGDM model. Finally, the sensitivity analysis and experiments on a real dataset verify the significant superiority of the constructed DSN-DG-LSGDM model compared with the extant LSGDM consensus models.},
  archive      = {J_ISCI},
  author       = {Yufeng Shen and Xueling Ma and Zeshui Xu and Enrique Herrera-Viedma and Petra Maresova and Jianming Zhan},
  doi          = {10.1016/j.ins.2023.119925},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119925},
  shortjournal = {Inf. Sci.},
  title        = {Opinion evolution and dynamic trust-driven consensus model in large-scale group decision-making under incomplete information},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient approach of high average utility pattern mining
with indexed list-based structure in dynamic environments.
<em>ISCI</em>, <em>657</em>, 119924. (<a
href="https://doi.org/10.1016/j.ins.2023.119924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various studies on high utility pattern mining have been conducted to satisfy the emerging need to consider the characteristics of real-world databases, such as the importance and quantity of items. In the traditional utility-based framework, the mining result is influenced by the number of items in a pattern, or in some cases, single utilities of items. In order to overcome this drawback, high average utility pattern mining has been proposed. It provides more interesting results since it takes into account the average utility of patterns by considering their lengths. Methods based on this concept have emerged in recent years, including ones that target incremental environments. However, existing algorithms create an enormous number of candidate patterns or require complex operations during the mining process. To address this degradation, we propose a new and more efficient approach for mining high average utility patterns in dynamic environments. The proposed algorithm utilizes a data structure more efficient than previous ones, which takes the form of an indexed list. It also incorporates efficient realigning and mining techniques for handling incremental data and accurately mining results. Experimental results show the superiority of the proposed approach in terms of runtime, memory usage, scalability, and accuracy.},
  archive      = {J_ISCI},
  author       = {Hyeonmo Kim and Hanju Kim and Myungha Cho and Bay Vo and Jerry Chun-Wei Lin and Hamido Fujita and Unil Yun},
  doi          = {10.1016/j.ins.2023.119924},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119924},
  shortjournal = {Inf. Sci.},
  title        = {Efficient approach of high average utility pattern mining with indexed list-based structure in dynamic environments},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Secure message recovery in presence of the cyber-attack
using discrete-time chaotic modulation approach. <em>ISCI</em>,
<em>657</em>, 119923. (<a
href="https://doi.org/10.1016/j.ins.2023.119923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The secure message recovery problem in presence of cyber-attack is considered in this paper. The message is modulated by a master chaotic system which may be vulnerable to a cyber-attack and then transmitted to a receiver. By designing a novel observer at the receiver side, the message is recovered correctly. All the design process is performed in discrete-time domain which is suitable for digital communications. Besides, there are no restrictions on the message signal and nonlinear term signature matrix which makes the proposed approach more suitable in the real applications. Numerical simulations are introduced to show the feasibility and the superior performance of the proposed scheme in comparison with the conventional methods.},
  archive      = {J_ISCI},
  author       = {Marzieh Samimiat and Ali-Akbar Ahmadi},
  doi          = {10.1016/j.ins.2023.119923},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119923},
  shortjournal = {Inf. Sci.},
  title        = {Secure message recovery in presence of the cyber-attack using discrete-time chaotic modulation approach},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Three-way group consensus with experts’ attitudes based on
probabilistic linguistic preference relations. <em>ISCI</em>,
<em>657</em>, 119919. (<a
href="https://doi.org/10.1016/j.ins.2023.119919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent decision-making collaborates with big data analytics to navigate the intricate landscape of the digital economy, orchestrating data-driven strategies to achieve the most favorable results. Through the integration of specific objectives and relevant data, intelligent decision-making involves the modeling, analysis, and realization of decisions. This comprehensive process seamlessly incorporates elements such as constraints, strategies, preferences, and uncertainty, ultimately leading to the autonomous achievement of optimal outcomes. In this context, the probabilistic linguistic preference relation (PLPR) serves as a recently introduced form of linguistic evaluations, offering adaptable expression of expert preference assessments. Within the domain of preferences, consistency emerges as a pivotal consideration. Extremes occur when calculating the additive consistency of PLPR using expectation values. To comprehensively address the trouble, this paper introduces an innovative planning model that employs deviation degrees. The establishment of a consistency threshold is approached objectively using the principle of minimum individual regret and maximum group delight. Once consistency is established, the process advances to consensus reaching process (CRP). During the consensus feedback phase, the infusion of the three-way decision (TWD) theory accounts for distinct expert modification attitudes, while ensuring consistency remains upheld throughout the modification procedure. For clarity, the proposed technique is referred to as the TWD-GC-EA method. Notably, the effectiveness of the designed approach is demonstrated through its application to a real-world scenario. Furthermore, a comparative assessment is conducted against several other consensus methods to validate its efficacy and superiority.},
  archive      = {J_ISCI},
  author       = {Xinru Han and Jianming Zhan and Yukun Bao and Bingzhen Sun},
  doi          = {10.1016/j.ins.2023.119919},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119919},
  shortjournal = {Inf. Sci.},
  title        = {Three-way group consensus with experts&#39; attitudes based on probabilistic linguistic preference relations},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MixCam-attack: Boosting the transferability of adversarial
examples with targeted data augmentation. <em>ISCI</em>, <em>657</em>,
119918. (<a href="https://doi.org/10.1016/j.ins.2023.119918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many black-box adversarial attack algorithms perform attacks on machine learning models based on the transferability of adversarial examples , and the input transformation-based attack is one of the most effective methods. However, existing input transformation methods ignore that each pixel contributes differently to the output of the model, and the focus regions of different models on the same images are similar. Therefore, this paper proposes a targeted data augmentation-based adversarial attack algorithm named MixCam, which augments the input data based on the contribution of each pixel to the prediction result. This is done to enhance the transferability of the crafted adversarial example from the perspective of shifting the regions to which the model pays most of its attention. In addition, this paper proposes further boosting the transferability of the crafted adversarial examples by fusing the class activation maps of multiple models for the input image. Furthermore, the MixCam can integrate other input transformation methods to further boost the transferability of crafted adversarial examples. Extensive experiments on ImageNet demonstrate that MixCam outperforms other state-of-the-art methods in black-box attacks against considered adversarially trained models, with an average increase of 11.7% and 10.7% in attack success rates for single and ensemble attack settings, respectively.},
  archive      = {J_ISCI},
  author       = {Sensen Guo and Xiaoyu Li and Peican Zhu and Baocang Wang and Zhiying Mu and Jinxiong Zhao},
  doi          = {10.1016/j.ins.2023.119918},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119918},
  shortjournal = {Inf. Sci.},
  title        = {MixCam-attack: Boosting the transferability of adversarial examples with targeted data augmentation},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-dimensional improved attribute reductions based on
distance granulation and condition entropy in incomplete interval-valued
decision systems. <em>ISCI</em>, <em>657</em>, 119910. (<a
href="https://doi.org/10.1016/j.ins.2023.119910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reductions rely on knowledge granulation and information measurement. Aiming at incomplete interval-valued decision systems (IIVDSs), an attribute reduction (with the FSR-AR/HS-AR algorithm) emerges by combining distance granulation and condition entropies ; however, its distance measurement has defects for maximum and minimum fillings, while its condition entropy has promotion space on information enrichment. This paper utilizes FSR-AR/HS-AR to make the two-dimensional improvements of distance granulation and condition entropy to improve IIVDS-driven attribute reductions. Concretely, distance measures and similarity degrees are corrected via range completion and statistical enhancement, and the condition entropy is deepened by replacing credibility with coverage-credibility, so 2 × 2 = 4 2×2=4 reduction algorithms extend and improve FSR-AR/HS-AR. First, new maximal and minimal distances are defined via complete search and statistical optimization of missing values, so an amended fuzzy α -similarity relation induces knowledge granulation. Then, improved informational, conditional, joint entropies , and mutual information are established via coverage-credibility, and they obtain system equations and granulation nonmonotonicity. Furthermore, the two-dimensional improvements generate 2 × 2 = 4 2×2=4 attribute reductions, and the corresponding heuristic algorithms include FSR-AR/HS-AR and three improved algorithms. Finally, improvements in uncertainty measures and reduction algorithms are validated via table examples and data experiments, and the three novel algorithms outperform FSR-AR/HS-AR and contrastive algorithms for classification performances.},
  archive      = {J_ISCI},
  author       = {Benwei Chen and Xianyong Zhang and Zhong Yuan},
  doi          = {10.1016/j.ins.2023.119910},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119910},
  shortjournal = {Inf. Sci.},
  title        = {Two-dimensional improved attribute reductions based on distance granulation and condition entropy in incomplete interval-valued decision systems},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EEG-TransMTL: A transformer-based multi-task learning
network for thermal comfort evaluation of railway passenger from EEG.
<em>ISCI</em>, <em>657</em>, 119908. (<a
href="https://doi.org/10.1016/j.ins.2023.119908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evaluation of thermal comfort for railway passengers holds considerable importance, not only in reducing energy consumption but also in enhancing the passengers&#39; experience. This paper presents a Transformer-based multi-task learning network (TransMTL) designed for railway passenger thermal comfort evaluation using EEG. We utilized manual features to extract temporal and frequency information , while a Transformer encoder distilled spatial information. The multi-task learning structure enhances model robustness by leveraging thermal comfort task correlations. We conducted experiments during winter and summer with high-speed railway passengers, establishing a comprehensive EEG dataset. The results demonstrated that our proposed EEG-TransMTL model outperformed classical machine learning and deep learning models in all four thermal comfort evaluation tasks, achieving accuracy rates of 65.00%, 66.70%, 80.38%, and 71.01%, respectively. We enhanced model interpretability by visualizing attention weights from the Transformer encoder, identifying key EEG channels. A simplified model utilizing only eight crucial channels also delivered notable performance. This research provides a practical and neuro-mechanism interpretable solution for thermal comfort evaluation.},
  archive      = {J_ISCI},
  author       = {Chaojie Fan and Shuxiang Lin and Baoquan Cheng and Diya Xu and Kui Wang and Yong Peng and Sam Kwong},
  doi          = {10.1016/j.ins.2023.119908},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119908},
  shortjournal = {Inf. Sci.},
  title        = {EEG-TransMTL: A transformer-based multi-task learning network for thermal comfort evaluation of railway passenger from EEG},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). APGVAE: Adaptive disentangled representation learning with
the graph-based structure information. <em>ISCI</em>, <em>657</em>,
119903. (<a href="https://doi.org/10.1016/j.ins.2023.119903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks are used to learn task-oriented high-level representations in an end-to-end manner by building a multi-layer neural network. Generation models have developed rapidly with the emergence of deep neural networks . But it still has problems with the insufficient authenticity of generated images, the deficiency of diversity, consistency, and unexplainability in the generation process. Disentangled representation is an effective method to learn a high-level feature representation and realize the interpretability of deep neural networks . We propose a general disentangled representation learning network with variational autoencoder network as the basic framework for the image generation process. The graph-based structure of the priors is embedded in the last module of the deep encoder network to build the feature spaces by the class, task-oriented, and task-unrelated information respectively. Meanwhile the priors should be adaptively modified with the task relevance of a generated image. And the semi-supervised learning is further involved in the disentangled representation network framework to reduce the requirements of label and extend the majority of feature space under the task-unrelated feature assumption. Experimental results show that the proposed method is efficient for various types of images and has a good potential for further research and development.},
  archive      = {J_ISCI},
  author       = {Qiao Ke and Xinhui Jing and Marcin Woźniak and Shuang Xu and Yunji Liang and Jiangbin Zheng},
  doi          = {10.1016/j.ins.2023.119903},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119903},
  shortjournal = {Inf. Sci.},
  title        = {APGVAE: Adaptive disentangled representation learning with the graph-based structure information},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel privacy-preserving graph convolutional network via
secure matrix multiplication. <em>ISCI</em>, <em>657</em>, 119897. (<a
href="https://doi.org/10.1016/j.ins.2023.119897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional network (GCN) is one of the most representative methods in the realm of graph neural networks (GNNs). In the convolution process, GCN combines the structural information of the networks with the features of nodes. In practice, the structure information of the networks and the features of nodes may be controlled by different parties, which can render GCN ineffective when information sharing is constrained by privacy concerns or licensing issues. Therefore, it is of significant importance to design an effective and secure scheme for GCN that can collaboratively merge information from both parties while safeguarding their sensitive data. In this paper, we introduce S-GCN (i.e., Secure GCN Scheme), which employs secure matrix multiplication (SMM) to compute the product of two matrices in a privacy-preserving manner. The S-GCN scheme requires frequent utilization of SMM to merge information from both parties, resulting in high time and space complexity. To address this issue, we introduce SF-GCN (i.e., Secure and Fast GCN Scheme), which minimizes the use of SMM. Additionally, both S-GCN and SF-GCN may be susceptible to privacy breaches when dealing with dense networks. Hence, we further enhance security by introducing differential privacy through the Laplacian mechanism. Experimental results demonstrate that the proposed schemes do not significantly reduce accuracy in downstream tasks, and, more importantly, effectively protect the privacy information of both parties.},
  archive      = {J_ISCI},
  author       = {Hai-Feng Zhang and Feng Zhang and Huan Wang and Chuang Ma and Pei-Can Zhu},
  doi          = {10.1016/j.ins.2023.119897},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119897},
  shortjournal = {Inf. Sci.},
  title        = {A novel privacy-preserving graph convolutional network via secure matrix multiplication},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Selection of a viable blockchain service provider for data
management within the internet of medical things: An MCDM approach to
indian healthcare. <em>ISCI</em>, <em>657</em>, 119890. (<a
href="https://doi.org/10.1016/j.ins.2023.119890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health 4.0 is gaining significant attention globally to support better treatment and care for people. Digital technologies such as the IoMT “(”Internet of Medical Things“”) and blockchain substantially promote quality health services. Literature shows that embedding blockchain in IoMT is an effective way to attain secure and quality healthcare. Selecting a viable blockchain service provider (BSP) becomes a complex task and can be considered an MCDM “(”Multi-Criteria Decision-Making“”) problem. Earlier studies on BSP selection indicate that complex expressions cannot be well-modelled and methodical estimation of decision parameters by capturing hesitation and interaction of entities is not adequately explored. Driven by the issues, authors put forward a novel MCDM framework with (i) a double hierarchy linguistic structure for data collection in natural expressions; (ii) regret measure for experts&#39; reliability calculation; (iii) a weighted CRITIC approach for criteria weight determination, and (iv) CRADIS-Copeland algorithm for ranking BSPs. Finally, a case example from Recent Indian healthcare is exemplified to demonstrate the framework&#39;s applicability. Recently, the Indian healthcare sector launched initiatives/plans as part of Health 4.0 to promote data management for a better quality of treatment by seeking support from digital technologies such as IoMT and blockchains to ensure data privacy and improved customer experience . Sensitivity analysis and comparison with extant methods infer that (i) BC 1 BC1 , BC 5 BC5 , and BC 3 BC3 are the top three BSPs for the considered problem; (ii) criteria such as privacy aspects, intercommunication capability, global accessibility, and total cost constitute 58% importance in the supposed decision problem; (iii) developed model reduces human intervention/biases; (iv) developed model is robust to weight alteration and yields unique rank orders with both personalised and cumulative ordering of BSPs; and (v) proposed model produces broader rank values that aid in effective backup planning.},
  archive      = {J_ISCI},
  author       = {Raghunathan Krishankumar and Sundararajan Dhruva and Kattur S Ravichandran and Samarjit Kar},
  doi          = {10.1016/j.ins.2023.119890},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119890},
  shortjournal = {Inf. Sci.},
  title        = {Selection of a viable blockchain service provider for data management within the internet of medical things: An MCDM approach to indian healthcare},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Multi-view spatiotemporal learning for traffic forecasting.
<em>ISCI</em>, <em>657</em>, 119868. (<a
href="https://doi.org/10.1016/j.ins.2023.119868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spatiotemporal learning has been one of the most burning research topics in traffic data analytics for traffic forecasting, which is instrumental in developing the intelligent transportation systems . Capturing accurately and efficiently complex spatiotemporal dependencies of the road network is a critical prerequisite of the traffic spatiotemporal forecasting. This study proposes a multi-view spatiotemporal learning (MVSTL) framework, which combines the fast parallel learning (FPL) and the serial learning (SL) to juggle the receptive field with the fitting capability of the model. The FPL is proposed to capture the spatiotemporal correlations synchronously and efficiently by reducing the number of parameters significantly. As a supplement to the FPL, the SL, which extracts the spatial and temporal features serially, can expand the spatial/temporal receptive fields and avoid information overwriting. The evaluation of the MVSTL is carried out by employing four sets of traffic data from the LA freeway system, and the experiment results reveal that the MVSTL is able to perform better than the advanced methods in prediction accuracy.},
  archive      = {J_ISCI},
  author       = {Canyang Guo and Chi-Hua Chen and Feng-Jang Hwang and Ching-Chun Chang and Chin-Chen Chang},
  doi          = {10.1016/j.ins.2023.119868},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119868},
  shortjournal = {Inf. Sci.},
  title        = {Multi-view spatiotemporal learning for traffic forecasting},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Network traffic matrix prediction with incomplete data via
masked matrix modeling. <em>ISCI</em>, <em>657</em>, 119835. (<a
href="https://doi.org/10.1016/j.ins.2023.119835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic matrix (TM) prediction aims to forecast future traffic data for networks using historical traffic matrices. TM prediction plays a critical role in solving network engineering tasks such as routing management, capacity planning, and network security . Previous research assumes that the TM sequences fed into the prediction models are complete and precise. However, considering the unavoidable failure of network systems and their large monitoring costs, it is impractical to collect complete TMs from large-scale networks. In this paper, we study the TM prediction problem with randomly missing values. To perform TM completion, we introduce a masked matrix modeling method based on self-supervised learning that can learn better matrix representations . As the matrix completion and prediction tasks are highly correlated, we propose an end-to-end framework that performs the two tasks simultaneously through joint learning. Specifically, we design a 3D-UNet architecture that is able to exploit multi-scale spatio–temporal correlations in a TM sequence as the completion module. An LSTM2D architecture is employed as the prediction module to take advantage of spatio–temporal dependencies. Extensive experiments are conducted on publicly available datasets, and the results show that our model significantly outperforms previous state-of-the-art methods. Source code is available at https://github.com/FreeeBird/TM_prediction_random_missing .},
  archive      = {J_ISCI},
  author       = {Weiping Zheng and Yiyong Li and Minli Hong and Gansen Zhao and Xiaomao Fan},
  doi          = {10.1016/j.ins.2023.119835},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {119835},
  shortjournal = {Inf. Sci.},
  title        = {Network traffic matrix prediction with incomplete data via masked matrix modeling},
  volume       = {657},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). State estimation in labeled time petri net systems using
observed modified state class graph. <em>ISCI</em>, <em>656</em>,
119922. (<a href="https://doi.org/10.1016/j.ins.2023.119922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an improved method for the state estimation of a labeled time Petri net (LTPN) system with unobservable transitions. Precisely, we provide a computationally efficient graph, called an observed modified state class graph (OMSCG), that represents a partial state space of an LTPN system based on the logic label sequence of an observed time-label sequence (TLS), motivated by the modified state class graph reported in the literature. Taking advantage of the OMSCG, we can effectively estimate all the transition sequences that are logically consistent with a TLS. By employing the transitions-related timing constraints of the OMSCG, we then present an approach to determine the set of transition sequences that are timing consistent with a timed observation (i.e., a TLS observed at a time instant) by solving linear programming problems . Finally, we provide an algorithm to implement the state estimation of an LTPN system under a timed observation.},
  archive      = {J_ISCI},
  author       = {Liang Li and Mingxi Deng and Bin Liu and Zhiwu Li},
  doi          = {10.1016/j.ins.2023.119922},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119922},
  shortjournal = {Inf. Sci.},
  title        = {State estimation in labeled time petri net systems using observed modified state class graph},
  volume       = {656},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A novel distance measure based on dynamic time warping to
improve time series classification. <em>ISCI</em>, <em>656</em>, 119921.
(<a href="https://doi.org/10.1016/j.ins.2023.119921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic time warping (DTW) is the most widely used method to evaluate the similarity between time series. However, the DTW distance only takes into account the difference in amplitude, but does not reflect the time distortion information between them. In this paper, we propose a novel time similarity metric, called the time distortion coefficient , based on the DTW warping path to quantify the time distortion between time series. It is able to characterize the type and degree of time distortion between two time series at each point. By summing the absolute values of the time distortion coefficients, the overall time distortion is introduced to quantify time distortion between two time series. For the Nearest Neighbor (NN) based time series classification, a fusional similarity measure combining the DTW distance and the overall time distortion measure is proposed, which is able to evaluate the similarity in both amplitude and time domains. The experimental results conducted on the UCR time series classification archive datasets demonstrate that the proposed fusional similarity measure can significantly improve the classification accuracy of the 1-NN classifier with only a small amount of additional computational cost compared to the DTW distance and other metrics.},
  archive      = {J_ISCI},
  author       = {Yutao Liu and Yong-An Zhang and Ming Zeng and Jie Zhao},
  doi          = {10.1016/j.ins.2023.119921},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119921},
  shortjournal = {Inf. Sci.},
  title        = {A novel distance measure based on dynamic time warping to improve time series classification},
  volume       = {656},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An attention based approach for automated account linkage in
federated identity management. <em>ISCI</em>, <em>656</em>, 119920. (<a
href="https://doi.org/10.1016/j.ins.2023.119920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linking digital accounts belonging to the same user has progressed from a research topic to a foundation for security, user satisfaction, and developing next-generation services. Still, few studies address account linkage in domains other than social networks. This deficiency is particularly apparent in federated domains such as academia, where network-based information and contextual data are typically unavailable. To address this issue, we propose SmartSSO, a framework that aims to automate the account linkage process by analyzing user routines and behavior during login processes. SmartSSO adapts two self-attention-based models to generate new representations from user patterns in a lower-dimensional latent space where the learned structure is employed to identify related accounts held by a user. We show that the trained models on a large corpus of production data, including more than one million samples gathered over six months from 50,000 users, achieve over 98% accuracy in hit-precision.},
  archive      = {J_ISCI},
  author       = {Shirin Dabbaghi Varnosfaderani and Piotr Kasprzak and Aytaj Badirova and Ralph Krimmel and Christof Pohl and Ramin Yahyapour},
  doi          = {10.1016/j.ins.2023.119920},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119920},
  shortjournal = {Inf. Sci.},
  title        = {An attention based approach for automated account linkage in federated identity management},
  volume       = {656},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning shared and non-redundant label-specific features
for partial multi-label classification. <em>ISCI</em>, <em>656</em>,
119917. (<a href="https://doi.org/10.1016/j.ins.2023.119917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial multi-label learning (PML) is designed to address the challenge of having both ground-truth labels and noisy labels in the label set of training instances. In real-world applications, there are often noisy features in addition to noisy labels, but existing PML methods fail to filter out these noisy features or account for feature correlations, label correlations, and feature-label correlations together in the feature learning process. These oversights lead to poor classification accuracy , as the comprehensive exploration of feature and label information in PML can contribute significantly to disambiguation. To address this issue, we propose a novel PML framework that disambiguates candidate labels and learns label-specific features while taking into account all three types of correlations between features and labels. First, we capture high-order label correlations by employing the low-rank representation to obtain a complementary label matrix induced from the partial label matrix, which accounts for the presence of noisy labels. Then, we learn a shared and non-redundant label-specific data representation by incorporating intrinsic feature correlations and the learned label correlations to mitigate the impact of noisy features. Finally, we build a classifier by mapping the label-specific feature representation to the complementary label matrix to model the feature-label correlations. Various experiments validate the superiority of our method.},
  archive      = {J_ISCI},
  author       = {Yizhang Zou and Xuegang Hu and Peipei Li and Yuhang Ge},
  doi          = {10.1016/j.ins.2023.119917},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119917},
  shortjournal = {Inf. Sci.},
  title        = {Learning shared and non-redundant label-specific features for partial multi-label classification},
  volume       = {656},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sequence recommendation using multi-level self-attention
network with gated spiking neural p systems. <em>ISCI</em>,
<em>656</em>, 119916. (<a
href="https://doi.org/10.1016/j.ins.2023.119916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequence recommendation is used to predict the user&#39;s next potentially interesting items and behaviors. It not only focuses on the user&#39;s independent interaction behavior, but also considers the user&#39;s historical behavior sequence. However, sequence recommendation still faces some challenges: the existing models still have shortcomings in addressing long-term dependencies and fully utilizing contextual information in sequence recommendation. To address these challenges, we propose a four-channel model based on a multi-level self-attention network with gated spiking neural P (GSNP) systems, termed SR-MAG model. The four channels are divided into two groups, and each group is composed of an attention channel and an GSNP attention channel. Moreover, they process long-term sequences and short-term sequences respectively to obtain long-term or short-term attention channel features. These features are then passed through a self-attention network to effectively extract user context information. The proposed SR-MAG model is tested on three real datasets and compared with 10 baseline methods . Experimental results demonstrate the effectiveness of the proposed SR-MAG model in sequence recommendation tasks.},
  archive      = {J_ISCI},
  author       = {Xinzhu Bai and Yanping Huang and Hong Peng and Jun Wang and Qian Yang and David Orellana-Martín and Antonio Ramírez-de-Arellano and Mario J. Pérez-Jiménez},
  doi          = {10.1016/j.ins.2023.119916},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119916},
  shortjournal = {Inf. Sci.},
  title        = {Sequence recommendation using multi-level self-attention network with gated spiking neural p systems},
  volume       = {656},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ESSENT: An arithmetic optimization algorithm with enhanced
scatter search strategy for automated test case generation.
<em>ISCI</em>, <em>656</em>, 119915. (<a
href="https://doi.org/10.1016/j.ins.2023.119915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the main research tasks in software testing, automated test case generation based on path coverage (ATCG-PC) aims to achieve maximum path coverage with a minimized set of test cases. In ATCG-PC, the correlation among the dimensions of test cases is widely utilized in academia to minimize the search efforts of the search-based algorithm. Nevertheless, the information related to target path selection is not utilized, which leads to blind decision-making by the search-based algorithm during the target path selection. Therefore, this paper proposes an enhanced scatter search strategy by using opposition-based learning. An arithmetic optimization algorithm is also proposed to solve ATCG-PC based on the enhanced scatter search strategy, namely, ESSENT. The ESSENT algorithm selects the path with the lowest path entropy among the uncovered paths as the target path, and generates new test cases that cover the target path by modifying the dimensions of the existing test cases. The performance of the ESSENT algorithm is evaluated on six iFogSim subprograms and six Stanford coreNLP subprograms. Experiment results show that the ESSENT algorithm achieves a higher convergence rate than other state-of-the-art algorithms. Furthermore, it enables maximum path coverage with fewer test cases.},
  archive      = {J_ISCI},
  author       = {Xiguang Li and Baolu Feng and Yunhe Sun and Ammar Hawbani and Saeed Hammod Alsamhi and Liang Zhao},
  doi          = {10.1016/j.ins.2023.119915},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119915},
  shortjournal = {Inf. Sci.},
  title        = {ESSENT: An arithmetic optimization algorithm with enhanced scatter search strategy for automated test case generation},
  volume       = {656},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Refining one-class representation: A unified transformer for
unsupervised time-series anomaly detection. <em>ISCI</em>, <em>656</em>,
119914. (<a href="https://doi.org/10.1016/j.ins.2023.119914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deep unsupervised time-series anomaly detector depends on the one-class representation, which is more effective by only formulating the normal samples. However, normal samples are always mixed with anomalies in the unlabeled training dataset. The learned one-class representation may be biased and violates the one-class setting. To address this problem, we refine the one-class representation and propose a unified AMFormer (Active Masked transFormer) framework, which integrates Transformer with the masked operation mechanism and cost-sensitive learning theory. Specifically, we first develop a network-driven masked operation with Hadamard product transformation to damage the initial input samples. The encoder and decoder representations rebuild the processed incomplete samples, which avoids identical shortcuts and further enhances robustness. Secondly, we exploit the active MSE (Mean Squared Error) loss function to purify the training samples . The different weights are dynamically added to different kinds of samples according to their rebuilding-errors-based pseudo labels. The pseudo anomalies with more significant rebuilding errors are removed by putting lower weights. Finally, extensive experiments are conducted on four benchmark datasets. The experimental results demonstrate that our AMFormer outperforms the nine relevant benchmark algorithms, boosting the mean f1-score from 0.851 to 0.937.},
  archive      = {J_ISCI},
  author       = {Guoxiang Zhong and Fagui Liu and Jun Jiang and Bin Wang and C.L. Philip Chen},
  doi          = {10.1016/j.ins.2023.119914},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119914},
  shortjournal = {Inf. Sci.},
  title        = {Refining one-class representation: A unified transformer for unsupervised time-series anomaly detection},
  volume       = {656},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A memetic algorithm with fuzzy-based population control for
the joint order batching and picker routing problem. <em>ISCI</em>,
<em>656</em>, 119913. (<a
href="https://doi.org/10.1016/j.ins.2023.119913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The joint order batching and picker routing problem (JOBPRP) is a combinatorial optimization problem that occurs during in the order-picking operation of warehouse management. It consists of simultaneous assignment of customer orders to batches and routing of picking operations in the batches such that the total travel distance is minimized. In this paper, we develop a memetic algorithm with fuzzy-based population control (MA-FPC) to solve the JOBPRP. MA-FPC takes advantage of the hierarchical nature of the problem to design a batch exchange crossover (BEX) operator and a two-level local improvement procedure. BEX transfers complete batches from parent solutions to offsprings. Local improvement systematically employs a combined heuristic and exact routing approach to solve the picker routing problem. Furthermore, fuzzy-based population control is used to dynamically regulate population diversity during the search, which removes individuals from or adds individuals to the population. In numerical experiments, MA-FPC significantly outperforms state-of-the-art point-based and population-based algorithms developed for the order batching problem and JOBPRP with respect to solution quality in reasonable running times. Our algorithm improves the previous best-known solutions for 57 of the 64 benchmark instances.},
  archive      = {J_ISCI},
  author       = {Renchao Wu and Jianjun He and Xin Li and Zuguo Chen},
  doi          = {10.1016/j.ins.2023.119913},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119913},
  shortjournal = {Inf. Sci.},
  title        = {A memetic algorithm with fuzzy-based population control for the joint order batching and picker routing problem},
  volume       = {656},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Three-way decisions based on bipolar-valued fuzzy sets over
three-way decision spaces. <em>ISCI</em>, <em>656</em>, 119912. (<a
href="https://doi.org/10.1016/j.ins.2023.119912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of bipolar-valued fuzzy set was introduced by Zhang. Can we discuss three-way decisions based on bipolar-valued fuzzy sets over three-way decision spaces? In response to this problem, firstly, the paper discusses partially orders on truth values of bipolar-valued fuzzy sets and three-way decision spaces on this basis. Secondly, this paper presents construction method of decision evaluation functions based on bipolar-valued fuzzy sets over three-way decision spaces. Thirdly, this paper makes three-way decisions based on bipolar-valued fuzzy sets over three-way decision spaces and uses an example on an evaluation problem of credit card applicants to illustrate some notions of the (semi-, quasi-)three-way decision spaces and benefits of constructing methods from semi-(quasi-)decision evaluation functions to decision evaluation functions. Finally, the conclusions are summed up.},
  archive      = {J_ISCI},
  author       = {Bao Qing Hu},
  doi          = {10.1016/j.ins.2023.119912},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119912},
  shortjournal = {Inf. Sci.},
  title        = {Three-way decisions based on bipolar-valued fuzzy sets over three-way decision spaces},
  volume       = {656},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new multi-view multi-label model with privileged
information learning. <em>ISCI</em>, <em>656</em>, 119911. (<a
href="https://doi.org/10.1016/j.ins.2023.119911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-view multi-label learning (MVML), the data is described by multiple feature views and annotated by a number of categorical labels. At present, most of the existing MVML methods are proposed based on subspace learning, neural networks and so on. There is little work done on support vector machine (SVM)-based MVML. In this paper, we propose a novel SVM-based multi-view multi-label learning method with privileged information learning (MVMLP). By introducing the idea of privileged information learning, MVMLP implements both the consensus principle and complementarity principle in MVML. Specifically, we enforce similarity between the outputs of different views to explore the consensus information. Moreover, we allow different views to serve as privileged information for each other, such that the complementary information among distinct views can be introduced into the training process. MVMLP constructs an SVM-based model for each view and trains the models of multiple views jointly. The derived learning problem can be efficiently solved by adapting the Franke-Wolfe algorithm. Experimental results on real-life datasets show that MVMLP delivers explicitly better classification performance than state-of-the-art MVML methods.},
  archive      = {J_ISCI},
  author       = {Yanshan Xiao and Junfeng Chen and Bo Liu and Liang Zhao and Xiangjun Kong and Zhifeng Hao},
  doi          = {10.1016/j.ins.2023.119911},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119911},
  shortjournal = {Inf. Sci.},
  title        = {A new multi-view multi-label model with privileged information learning},
  volume       = {656},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decentralized finite-time adaptive neural FTC with unknown
powers and input constraints. <em>ISCI</em>, <em>656</em>, 119909. (<a
href="https://doi.org/10.1016/j.ins.2023.119909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the finite-time tracking problem of a class of nonlinear interconnected systems , where each subsystem not only is subject to actuator faults but also has unknown system input powers. Based on Lyapunov stability theory and decentralized control method , a novel finite-time adaptive fault-tolerant control (FTC) scheme is proposed such that each tracking error can converge to a small neighborhood of the origin in finite time . Different from the existing works on interconnected systems where the system input powers are assumed to be known and equal to one, the general case where the powers are unknown and larger than one is investigated in this work. Furthermore, input constraints are also applied to avoid actuator damage caused by control signal overshoot and jittering in this work. From theoretical analysis, each tracking error is proven to converge to a small neighborhood of the origin in finite time. Finally, a numerical example is given to demonstrate the validity of proposed control method.},
  archive      = {J_ISCI},
  author       = {Jiyu Zhu and Qikun Shen and Tianping Zhang and Yang Yi},
  doi          = {10.1016/j.ins.2023.119909},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119909},
  shortjournal = {Inf. Sci.},
  title        = {Decentralized finite-time adaptive neural FTC with unknown powers and input constraints},
  volume       = {656},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event causality identification via graph contrast-based
knowledge augmented networks. <em>ISCI</em>, <em>656</em>, 119905. (<a
href="https://doi.org/10.1016/j.ins.2023.119905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying causality between events is a crucial research task in natural language processing . However, existing methods either ignore background knowledge of events or do not consider interference of knowledge graph noise on event representations. In this paper, we propose a novel Graph Contrast-based Knowledge Augmented Network (GCKAN) for event causality identification task, which integrates comprehensive background knowledge of events from knowledge graphs and alleviates the knowledge graph noise problem. First, a descriptive knowledge augmentation module is proposed to aggregate one-hop neighbor information in knowledge graphs and learn meaningful descriptive knowledge of events. Then, a relational knowledge augmentation module is designed to encode multi-hop path information and learn latent reasoning knowledge between event pairs. In addition, trustworthiness-based and degree-based graph contrastive learning schemas are devised in the two modules respectively, which suppress knowledge graph noise during information aggregation and derive more robust knowledge-aware event representations. Extensive experiments on three public datasets demonstrate the consistent superiority of GCKAN over state-of-the-art knowledge-based techniques. Noise interference experiments and cross-topic adaptation experiments further verify the robustness and generalization of GCKAN.},
  archive      = {J_ISCI},
  author       = {Ling Ding and Jianting Chen and Peng Du and Yang Xiang},
  doi          = {10.1016/j.ins.2023.119905},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119905},
  shortjournal = {Inf. Sci.},
  title        = {Event causality identification via graph contrast-based knowledge augmented networks},
  volume       = {656},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Q-learning with heterogeneous update strategy.
<em>ISCI</em>, <em>656</em>, 119902. (<a
href="https://doi.org/10.1016/j.ins.2023.119902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A variety of algorithms has been proposed to mitigate the overestimation bias of Q-learning. These algorithms reduce the estimation of maximum Q-value, i.e., homogeneous update . As a result, some of these algorithms such as Double Q-learning suffer from the underestimation bias. Different from these algorithms, this paper proposes a heterogeneous update idea. It aims to enlarge the normalized gap between Q-value corresponding to the optimal action and that corresponding to the other actions. Based on heterogeneous update , we design HetUp Q-learning. More specifically, HetUp Q-learning increases the normalized gap by overestimating Q-value corresponding to the optimal action and underestimating Q-value corresponding to the other actions. However, one limitation is that our HetUp Q-learning takes the optimal action as input to decide whether a state-action pair should be overestimated or underestimated. To address this challenge, we apply a softmax strategy to estimate the optimal action and obtain HetUpSoft Q-learning. We also extend HetUpSoft Q-learning to HetUpSoft DQN for high-dimensional environments. Extensive experiment results show that our proposed methods outperform SOTA baselines drastically in different settings. In particular, HetUpSoft DQN improves the average score per episode over SOTA baselines by at least 55.49% and 32.26% in the Pixelcopter and Breakout environments, respectively.},
  archive      = {J_ISCI},
  author       = {Tao Tan and Hong Xie and Liang Feng},
  doi          = {10.1016/j.ins.2023.119902},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119902},
  shortjournal = {Inf. Sci.},
  title        = {Q-learning with heterogeneous update strategy},
  volume       = {656},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A data-driven optimisation method for a class of problems
with redundant variables and indefinite objective functions.
<em>ISCI</em>, <em>656</em>, 119899. (<a
href="https://doi.org/10.1016/j.ins.2023.119899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of practical problem-solving, multi-objective optimisation problems with redundant variables and indefinite objective functions (MOPRVIF) are becoming increasingly prevalent. MOPRVIF involve determining the optimal decision variables that optimise multiple objectives, leveraging the relational data of a set of variables and multiple objectives. For these problems, this paper focuses on the following two issues: one is the demand for a unified computational model to solve this problem; the other is how to improve the algorithm&#39;s deep intelligent search capability. In this regard, this paper designs a dual data-driven multi-objective optimisation method. The method used consisted of four parts: elimination of redundant variables (ERV), objective function construction (OFC), selection evolution operator (SEO), and multi-objective evolutionary algorithm (MOEA). MOEA was the main focus of the method. ERV is data preparation and variable selection according to multiple objectives. OFC involves constructing the relationship model between variables and objectives, and a high-accuracy model is important for guaranteeing reliable results. Furthermore, SEO can adjust the evolution operator during a deep search. This is an important guarantee for deep, intelligent search. MOEA combined OFC and SEO to form the final solution algorithm—Dual Data Driven Multi-Objective Evolutionary Algorithm (DDMOEA). DDMOEA was explored using two different disciplinary problems of drug compound optimisation and wild blueberry cultivation and benchmarks were selected. The first two problem domains are distinct. The first problem is more complex than the second; however, both encompass redundant variables and indefinite objective functions. Benchmarks are utilised independently to gauge the profound intelligent search capability. The experiments affirm that the dual data-driven optimization approach proposed in this paper is effective, practical, and scalable.},
  archive      = {J_ISCI},
  author       = {Jin Zhou and Kang Zhou and Gexiang Zhang and Ferrante Neri and Wangyang Shen and Weiping Jin},
  doi          = {10.1016/j.ins.2023.119899},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119899},
  shortjournal = {Inf. Sci.},
  title        = {A data-driven optimisation method for a class of problems with redundant variables and indefinite objective functions},
  volume       = {656},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Probabilistic consistency of stochastic multiplicative
comparison matrices based on monte carlo simulation. <em>ISCI</em>,
<em>656</em>, 119896. (<a
href="https://doi.org/10.1016/j.ins.2023.119896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic multiplicative comparison matrices (SMCMs) are widely accepted due to their flexibility in measuring various types of decision-makers&#39; uncertain preferences by treating the judgment as a random variable . However, few existing consistency indices for SMCMs account for the influence of uncertainty of SMCMs on consistency. This may lead to some contradictions in consistency measurement for SMCMs. This paper proposes a probabilistic consistency index ( PCI ) considering the uncertainty of SMCMs from a statistical perspective. The index satisfies the property of invariance under the permutation of the labels of objects. The influence of uncertainty on the PCI is discussed in detail by numerical simulation. In addition, the perfect consistency and acceptable consistency of SMCMs based on the PCI are introduced, and a general threshold determination algorithm for acceptable consistency of SMCMs based on Monte Carlo simulation is designed considering the uncertainty, the distribution and the order of an SMCM. Subsequently, a consistency improvement method for SMCMs based on stochastic programming is proposed, which preserves the original preference of decision-makers to the greatest extent. Finally, examples are given to illustrate the significance of the consistency verification by using the PCI , and the most likely preference structure is used as the ranking for SMCMs.},
  archive      = {J_ISCI},
  author       = {Yixin Wang and Ligang Zhou and Hao Li and Xianchao Dai},
  doi          = {10.1016/j.ins.2023.119896},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119896},
  shortjournal = {Inf. Sci.},
  title        = {Probabilistic consistency of stochastic multiplicative comparison matrices based on monte carlo simulation},
  volume       = {656},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dyformer: A dynamic transformer-based architecture for
multivariate time series classification. <em>ISCI</em>, <em>656</em>,
119881. (<a href="https://doi.org/10.1016/j.ins.2023.119881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series classification is a crucial task with applications in broad areas such as finance, medicine, and engineering. Transformer is promising for time series classification, but as a generic approach, they have limited capability to effectively capture the distinctive characteristics inherent in time series data and adapt to diverse architectural requirements. This paper proposes a novel dynamic transformer-based architecture called Dyformer to address the above limitations of traditional transformers in multivariate time series classification. Dyformer incorporates hierarchical pooling to decompose time series into subsequences with different frequency components. Then, it employs Dyformer modules to achieve adaptive learning strategies for different frequency components based on a dynamic architecture. Furthermore, we introduce feature-map-wise attention mechanisms to capture multi-scale temporal dependencies and a joint loss function to facilitate model training. To evaluate the performance of Dyformer, we conducted extensive experiments using 30 benchmark datasets. The results unequivocally demonstrate that our model consistently outperforms a multitude of state-of-the-art methods and baseline approaches. Our model also copes well with limited training samples when pre-trained.},
  archive      = {J_ISCI},
  author       = {Chao Yang and Xianzhi Wang and Lina Yao and Guodong Long and Guandong Xu},
  doi          = {10.1016/j.ins.2023.119881},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119881},
  shortjournal = {Inf. Sci.},
  title        = {Dyformer: A dynamic transformer-based architecture for multivariate time series classification},
  volume       = {656},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ideal uniform multipartite secret sharing schemes.
<em>ISCI</em>, <em>655</em>, 119907. (<a
href="https://doi.org/10.1016/j.ins.2023.119907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multipartite secret sharing schemes are those having a multipartite access structure, in which the set of participants is divided into several parts and all participants in the same part play an equivalent role. Secret sharing schemes for these access structures have gained attention, as they generalize threshold secret sharing. This work focuses on the construction of linear secret sharing schemes for ideal uniform multipartite access structures, while avoiding the inefficiencies and randomness of known constructions. To achieve this, we have developed two approaches. The first approach combines polymatroid-based techniques with Gabidulin codes, which efficiently realize a particular family of ideal uniform multipartite access structures. The efficiency of this method is derived from the unique properties of Gabidulin codes, which allow for polynomial share and secret sizes relative to the number of participants. Our second approach applies linear algebraic techniques and polymatroid-based techniques to explicitly design linear secret sharing schemes for arbitrary ideal uniform multipartite access structures. The efficiency of this method stems from the properties of polynomials over finite fields. The schemes from this method are efficient for smaller numbers of parts relative to the number of participants. In summary, we present explicit constructions of linear secret sharing schemes for ideal uniform multipartite access structures, which have important applications in cryptography.},
  archive      = {J_ISCI},
  author       = {Qi Chen and Xiaojun Ren and Li Hu and Yongzhi Cao},
  doi          = {10.1016/j.ins.2023.119907},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119907},
  shortjournal = {Inf. Sci.},
  title        = {Ideal uniform multipartite secret sharing schemes},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dual-population algorithm based on self-adaptive epsilon
method for constrained multi-objective optimization. <em>ISCI</em>,
<em>655</em>, 119906. (<a
href="https://doi.org/10.1016/j.ins.2023.119906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Balancing multiple objectives and various constraints is crucial for effectively solving constrained multi-objective optimization problems (CMOPs). Excessive focus on either convergence or feasibility may not result in favorable outcomes of the algorithm. To confront this challenge, this paper proposes a cooperative evolutionary algorithm named SaE-CMO, which aims to achieve a harmonious balance between convergence and feasibility by extracting valuable information from both feasible and infeasible regions. To achieve this, SaE-CMO employs a dual-population approach to enhance search progress, consisting of a main population, Population1, and an auxiliary population, Population2. These two populations complement each other to achieve optimal results. A newly proposed self-adaptive epsilon method is employed in both Population1 and Population2, using different comparison criteria to select next population from mating pools, respectively. Population2 can retain some solutions that are well-constrained but poorly converged, thereby preserving information about both the constrained and the unconstrained Pareto front . This property enables Population2 to assist Population1 in maintaining diversity in certain complex CMOPs. To verify the effectiveness of SaE-CMO, we conduct experiments on three benchmark test instances and four real-world CMOPs with some related state-of-the-art constrained multi-objective optimization algorithms , experimental results prove that the proposed algorithm outperforms the compared algorithms.},
  archive      = {J_ISCI},
  author       = {Shiquan Song and Kai Zhang and Ling Zhang and Ni Wu},
  doi          = {10.1016/j.ins.2023.119906},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119906},
  shortjournal = {Inf. Sci.},
  title        = {A dual-population algorithm based on self-adaptive epsilon method for constrained multi-objective optimization},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An ETH-based approach to securing industrial internet
systems against mutinous attacks. <em>ISCI</em>, <em>655</em>, 119904.
(<a href="https://doi.org/10.1016/j.ins.2023.119904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern manufacturing industries, industrial components are becoming increasingly open and interconnected which significantly promotes the collaboration capability and producing efficiency on one hand, while, on the other hand, makes the industrial internet more vulnerable to various threats and attacks. In order to defend a distributed industrial Internet network system against two kinds of typical mutinous attacks, i.e., Byzantine attacks and DDoS attacks , that happen inside of the system, this paper proposes an Ethereum-based securing strategy. First, a credit mechanism-based Bayesian inference method is developed to increase the system nodes&#39; sensitivity to malicious behavior and to improve system&#39;s robustness against false messages. Then, a miner selection method is proposed to avoid the information clog occurring in the system nodes&#39; txpools and improve the efficiency of the whole system. The constructed securing strategy consists of these two methods and is shown to be applicable to industrial scenarios involving both mobile and static nodes. Several simulations are presented to verify effectiveness of the proposed approach. It is found that the accuracy of identifying false messages broadcast by Byzantine attackers is about 90%.},
  archive      = {J_ISCI},
  author       = {Xianqi Yang and Qing Gao and Michael V. Basin and Hao Li and Xin Peng},
  doi          = {10.1016/j.ins.2023.119904},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119904},
  shortjournal = {Inf. Sci.},
  title        = {An ETH-based approach to securing industrial internet systems against mutinous attacks},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic event-triggered boundary control for exponential
consensus of multi-agent systems of impulsive PDEs with switching
topology. <em>ISCI</em>, <em>655</em>, 119901. (<a
href="https://doi.org/10.1016/j.ins.2023.119901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the exponential consensus issue for multi-agent systems (MASs) of impulsive partial differential equations (PDEs) with switching topology . A new observer-based dynamic event-triggered boundary control (DETBC) protocol is designed to realize the exponential consensus objective. By Lyapunov functional method, impulse control theory and inequality analysis technique, some conditions are addressed to ensure that the considered MASs achieve the exponential consensus in terms of linear matrix inequalities (LMIs). In addition, the theoretical analysis with respect to the exclusion of Zeno behaviors is given for the designed DETBC mechanism. Finally, two examples are established to indicate the validity of the obtained results.},
  archive      = {J_ISCI},
  author       = {Xiaofang Wang and Huaiqin Wu and Jinde Cao and Xia Li},
  doi          = {10.1016/j.ins.2023.119901},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119901},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic event-triggered boundary control for exponential consensus of multi-agent systems of impulsive PDEs with switching topology},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HRA-secure attribute-based threshold proxy re-encryption
from lattices. <em>ISCI</em>, <em>655</em>, 119900. (<a
href="https://doi.org/10.1016/j.ins.2023.119900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proxy re-encryption (PRE) allows a semi-trust proxy with a re-encryption key to transform a ciphertext encrypted under one key to an encryption of the same message under another key. Attribute-based proxy re-encryption (AB-PRE) is a generalization of PRE which enables fine-grained access control and delegation of encrypted data . However, traditional AB-PRE suffers from the single point of failure as it relies on a single proxy to perform ciphertext transformations. To resolve this problem, this paper introduces a new primitive called attribute-based threshold proxy re-encryption ( AB-TPRE ), that utilizes multiple ( N ) proxies for the transformations. In AB-TPRE , the re-encryption key is split into N shares, with each proxy receiving one share to generate a transformed ciphertext share. Only when a threshold ( t ) number of transformed ciphertext shares are combined can the transformed ciphertext be correctly generated. Furthermore, to address the security risk of shares leakage, we introduce a share updatable property that allows the re-encryption key shares to be refreshed. We propose a construction of AB-TPRE from lattices , and prove its security against the honest re-encryption attacks under the learning with errors (LWE) assumption, which is assumed to be quantum secure since up to now there is no known quantum algorithm to solve LWE in polynomial time .},
  archive      = {J_ISCI},
  author       = {Feixiang Zhao and Jian Weng and Wenli Xie and Ming Li and Jiasi Weng},
  doi          = {10.1016/j.ins.2023.119900},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119900},
  shortjournal = {Inf. Sci.},
  title        = {HRA-secure attribute-based threshold proxy re-encryption from lattices},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On generating trustworthy counterfactual explanations.
<em>ISCI</em>, <em>655</em>, 119898. (<a
href="https://doi.org/10.1016/j.ins.2023.119898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models like chatGPT exemplify AI success but necessitate a deeper understanding of trust in critical sectors. Trust can be achieved using counterfactual explanations, which is how humans become familiar with unknown processes; by understanding the hypothetical input circumstances under which the output changes. We argue that the generation of counterfactual explanations requires several aspects of the generated counterfactual instances, not just their counterfactual ability. We present a framework for generating counterfactual explanations that formulate its goal as a multiobjective optimization problem balancing three objectives: plausibility ; the intensity of changes; and adversarial power. We use a generative adversarial network to model the distribution of the input, along with a multiobjective counterfactual discovery solver balancing these objectives. We demonstrate the usefulness of six classification tasks with image and 3D data confirming with evidence the existence of a trade-off between the objectives, the consistency of the produced counterfactual explanations with human knowledge , and the capability of the framework to unveil the existence of concept-based biases and misrepresented attributes in the input domain of the audited model. Our pioneering effort shall inspire further work on the generation of plausible counterfactual explanations in real-world scenarios where attribute-/concept-based annotations are available for the domain under analysis.},
  archive      = {J_ISCI},
  author       = {Javier Del Ser and Alejandro Barredo-Arrieta and Natalia Díaz-Rodríguez and Francisco Herrera and Anna Saranti and Andreas Holzinger},
  doi          = {10.1016/j.ins.2023.119898},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119898},
  shortjournal = {Inf. Sci.},
  title        = {On generating trustworthy counterfactual explanations},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural network based adaptive finite-time distributed
estimation for an uncertain leader. <em>ISCI</em>, <em>655</em>, 119894.
(<a href="https://doi.org/10.1016/j.ins.2023.119894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a two-step finite-time distributed estimation scheme for an uncertain leader. Unlike the previous achievements, the leader with unknown nonlinearity and uncertain input is considered, and the whole scheme is fully distributed and output-based. Firstly, a local neural network (NN) finite-time observer is proposed to estimate the unavailable states / uncertain dynamics of the leader, where the NN is used to approximate the uncertain dynamics. Then, based on the local interaction among agents, an NN finite-time distributed observer is devised for all the followers to reconstruct the system states / NN weights broadcasted by the local observer. By utilizing a combination of the local and the distributed observer, the unavailable states and the uncertain dynamics of the leader can be reconstructed by each follower in a finite time . Finally, simulation examples are presented to demonstrate the validity of our scheme.},
  archive      = {J_ISCI},
  author       = {Changhong Wang and Jixing Lv and Yonggui kao and Yushi Jiang},
  doi          = {10.1016/j.ins.2023.119894},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119894},
  shortjournal = {Inf. Sci.},
  title        = {Neural network based adaptive finite-time distributed estimation for an uncertain leader},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A monte carlo fuzzy logistic regression framework against
imbalance and separation. <em>ISCI</em>, <em>655</em>, 119893. (<a
href="https://doi.org/10.1016/j.ins.2023.119893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a new fuzzy logistic regression framework with high classification performance against imbalance and separation while keeping the interpretability of classical logistic regression . Separation and imbalance are two core problems in logistic regression, which can result in biased coefficient estimates and inaccurate predictions. Existing research on fuzzy logistic regression primarily focuses on developing possibilistic models instead of using a logit link function that converts log-odds ratios to probabilities . At the same time, little consideration is given to issues of separation and imbalance. Our study aims to address these challenges by proposing new methods of fuzzifying binary variables and classifying subjects based on a comparison against a fuzzy threshold. We use combinations of fuzzy and crisp predictors, output, and coefficients to understand which combinations perform better under imbalance and separation. Numerical experiments with synthetic and real datasets are conducted to demonstrate the usefulness and superiority of the proposed framework. Seven crisp machine learning models are implemented for benchmarking in the numerical experiments. The proposed framework shows consistently strong performance results across datasets with imbalance or separation and performs equally well when such issues are absent. Meanwhile, the considered machine learning methods are significantly impacted by the imbalanced datasets.},
  archive      = {J_ISCI},
  author       = {Georgios Charizanos and Haydar Demirhan and Duygu İçen},
  doi          = {10.1016/j.ins.2023.119893},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119893},
  shortjournal = {Inf. Sci.},
  title        = {A monte carlo fuzzy logistic regression framework against imbalance and separation},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive finite-time projective synchronization of complex
networks with nonidentical nodes and quantized time-varying delayed
coupling. <em>ISCI</em>, <em>655</em>, 119891. (<a
href="https://doi.org/10.1016/j.ins.2023.119891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the asymptotic projective synchronization and finite-time projective synchronization (FPS) of complex networks (CNs) with nonidentical nodes and quantized time-varying delayed coupling. Adaptive control method and finite-time stability theory are employed to design a novel adaptive controller and its adaptive law. The effectiveness and stability of the proposed adaptive controller are demonstrated through rigorous derivations based on Lyapunov stability theory and non-smooth analysis. It is indispensable that through numerical simulation experiments and comparative analysis, we verify the validity of the theoretical results and show the proposed adaptive controller can realize the synchronization of CNs with different nodes. This study holds significant theoretical value and practical relevance for understanding and controlling CNs with quantized time-varying delayed coupling.},
  archive      = {J_ISCI},
  author       = {Qiang Lai and Qingxing Zeng and Xiao-Wen Zhao and Ming-Feng Ge and Guanghui Xu},
  doi          = {10.1016/j.ins.2023.119891},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119891},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive finite-time projective synchronization of complex networks with nonidentical nodes and quantized time-varying delayed coupling},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Best-worst individuals driven multiple-layered differential
evolution. <em>ISCI</em>, <em>655</em>, 119889. (<a
href="https://doi.org/10.1016/j.ins.2023.119889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional differential evolution (DE) algorithms have been widely used for optimisation problems but suffer from low performance and premature convergence. Hence, researchers have proposed advanced variants to enhance performance using information and strategies. However, the performance of the variants remains limited because they only utilise limited information of individuals. A more suitable search orientation for the algorithm is required to effectively leverage individual information and enhance the processing of mid-population data. This study presents a novel best-worst individual-driven multiple-layered differential evolution (BWDE) algorithm. A best-worst individual-driven mechanism is designed that leverages various pieces of individual information to overcome local optima or stagnation, facilitating escape from the current search space and maintaining group fitness levels. In addition, the five-layer structure of the BWDE algorithm allows for the adequate use of multiple layers of information to determine the evolutionary direction of a population. Consequently, a balance is achieved between population development and exploration at distinct evolutionary stages. Extensive experiments are conducted using the Congress on Evolutionary Computation (CEC) 2017 and 2011 standard benchmark functions to evaluate the effectiveness of the proposed algorithm. The results are compared with those of classical algorithms, a winning algorithm at a CEC competition, and state-of-the-art DE variants. The experimental results demonstrate that the proposed BWDE algorithm outperforms its competitors and achieves more competitive results.},
  archive      = {J_ISCI},
  author       = {Qingya Sui and Yang Yu and Kaiyu Wang and Lin Zhong and Zhenyu Lei and Shangce Gao},
  doi          = {10.1016/j.ins.2023.119889},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119889},
  shortjournal = {Inf. Sci.},
  title        = {Best-worst individuals driven multiple-layered differential evolution},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Progressive reinforcement learning for video summarization.
<em>ISCI</em>, <em>655</em>, 119888. (<a
href="https://doi.org/10.1016/j.ins.2023.119888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video summarization addresses generating video summaries to help watchers grasp the content of a video without watching it entirely. Many methods have engaged in automatic video summarization. Although these methods have performed well, they still suffer from limited training data and sparse reward problems. We propose a Progressive Reinforcement Learning Video Summarization structure (PRLVS) with an unsupervised reward. The reward measures the information and quality the selected frames convey without annotations. Striving to earn higher rewards, our PRLVS adopts a “T”-type human thinking paradigm: choosing some key frames and checking if their adjacent frames are better than them. To simulate this paradigm, we decompose the flat strategy into a hierarchical strategy consisting of a horizontal policy and a vertical policy. These two policies are optimized alternatively, which densifies the reward while reducing the exploration space. Their cooperation also makes the agent capture the context information of the whole video at every step. Extensive experimental results on two benchmark databases (i.e., SumMe, TVSum) show that our PRLVS outperforms the comparisons and approaches the supervised methods, which indicates that it is significant to integrate our unsupervised reward into the progressive reinforcement learning structure to address limited annotation and sparse reward problems.},
  archive      = {J_ISCI},
  author       = {Guolong Wang and Xun Wu and Junchi Yan},
  doi          = {10.1016/j.ins.2023.119888},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119888},
  shortjournal = {Inf. Sci.},
  title        = {Progressive reinforcement learning for video summarization},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Additively generated discrete quasi-overlap functions.
<em>ISCI</em>, <em>655</em>, 119887. (<a
href="https://doi.org/10.1016/j.ins.2023.119887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to meet the needs of solving qualitative information aggregation problems, the theoretical research on usual aggregation operators on finite chains has never been interrupted. As part of the previous research category , this study focuses on additive generators of discrete quasi-overlap functions recently proposed by the author. The main results are: (1) it introduces the concepts of additive generators, 1 2 12 -min-additive generators and concave additive generators of discrete quasi-overlap functions; (2) it provides several basic properties of additively generated, 1 2 12 -min-additively generated and concave additively generated discrete quasi-overlap functions; (3) it investigates migrativity property of additively generated quasi-overlap functions.},
  archive      = {J_ISCI},
  author       = {Junsheng Qiao},
  doi          = {10.1016/j.ins.2023.119887},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119887},
  shortjournal = {Inf. Sci.},
  title        = {Additively generated discrete quasi-overlap functions},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The pseudo-information entropy of z-number and its
applications in multi-attribute decision-making. <em>ISCI</em>,
<em>655</em>, 119886. (<a
href="https://doi.org/10.1016/j.ins.2023.119886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to find a reasonable and effective approach to describe the information contained in a specific Z -number, we introduce information entropy into Z -number environment in this paper, and investigate its applications in multi-attribute decision-making (MADM) issues. Moreover, aiming at the problem with the weighting indicated by Z -number values, we propose two novel weighting methodologies based on conditional entropy and sigmoid function, respectively. Firstly, on the basis of the maximum entropy principle, the optimization model to calculate the underlying probability distribution of Z -number is introduced. And then, we define Z -number pseudo-information entropy, and a novel Z-VIKOR method is proposed to solve a selecting regional circular economy development plan issue from the perspective of information entropy. Furthermore, we propose Z -number pseudo-conditional entropy, and the relationship between Z -number pseudo-information entropy and Z -number pseudo-conditional entropy is investigated. Subsequently, a weighting method based on information entropy of Z -number is proposed. In addition, we also introduce the weighting approach based on the sigmoid function decision-making method. Finally, we introduce a government new energy investment problem to verify and compare the effectiveness of the new weighting approaches. The new method gives a solution to the problem related to Z -number from the perspective of information entropy.},
  archive      = {J_ISCI},
  author       = {Bin Yang and Gongao Qi and Bo Xie},
  doi          = {10.1016/j.ins.2023.119886},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119886},
  shortjournal = {Inf. Sci.},
  title        = {The pseudo-information entropy of Z-number and its applications in multi-attribute decision-making},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Depth asynchronous time delay reservoir for nonlinear time
series forecasting task. <em>ISCI</em>, <em>655</em>, 119883. (<a
href="https://doi.org/10.1016/j.ins.2023.119883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The forecasting of nonlinear time series has a wide range of applications both in theoretical research and industrial production, as the fitting of nonlinear systems, the early warning of sunspot activity and the prediction of network traffic peaks in advance. These tasks require models with strong nonlinear mapping capabilities and sufficient short-term memory capacity. Single-node time delay Reservoir (TDR) have been frequently applied on nonlinear time series forecasting tasks. To address the lack of memory capacity of traditional TDR and its extended version (Delay Decoupled Reservoir (DDR), Deep Time-Delay Reservoir (DTDR)), we propose a Depth Asynchronous Time-Delay Reservoir (DATDR) model. Firstly, the model retains the deep network structure of the DTDR to ensure the dynamic properties of the model, and the history states of each layer are from the previous layers instead of the current layer. Secondly, the same signal input method as the DDR is used, i.e., each layer is fed with the original signal, and this data input method ensures that the feature of signal does not decay gradually during the transmission between layers. Finally, a time delay operator is inserted into two adjacent layers, and the memory capacity of the model could be controlled effectively by adjusting the delay time of the time delay operator to accommodate some time series prediction tasks that require long memory capacity. In this paper, eight datasets from three different types are used to validate the proposed model, including NARMA10-30, Mackey-Glass Chaos time series, He ́non map series, Sunspot Sequence, and two real network traffic datasets. Experiments show that proposed model gets significant improvement in memory capacity compared with TDR, DDR, and DTDR, and performs better for some nonlinear time series datasets especially some long-term memory datasets.},
  archive      = {J_ISCI},
  author       = {Meiming You and Guoqiang Wang and Zhao Yang and Xuesong Yang},
  doi          = {10.1016/j.ins.2023.119883},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119883},
  shortjournal = {Inf. Sci.},
  title        = {Depth asynchronous time delay reservoir for nonlinear time series forecasting task},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differentiate data by higher-order structures.
<em>ISCI</em>, <em>655</em>, 119882. (<a
href="https://doi.org/10.1016/j.ins.2023.119882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The comparison of two objects is a topic that exists widely in different research areas. In this study, the network distance is combined with the k -nearest neighbour network sequence to construct the topological structural distance ( TSD ). This indicator is used to quantitatively describe the difference between two sets of points in any metric structure. Several datasets were tested to demonstrate the effectiveness of this indicator. Calculations show that TSD can compare the intrinsic structure of low-dimensional and high-dimensional datasets and is not limited by dimension. In addition, TSD can also be used to characterize sets of points in discrete space , such as comparing the structure of different networks. The examples in this study show that TSD is a universal method for analyzing the intrinsic structure of data.},
  archive      = {J_ISCI},
  author       = {Chun-Xiao Nie},
  doi          = {10.1016/j.ins.2023.119882},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119882},
  shortjournal = {Inf. Sci.},
  title        = {Differentiate data by higher-order structures},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Irrelevant attribute resistance approach to binary
classification for imbalanced data. <em>ISCI</em>, <em>655</em>, 119880.
(<a href="https://doi.org/10.1016/j.ins.2023.119880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data distribution is a common feature in real-world datasets. For imbalanced data, the imbalanced characteristics of the classes have two negative effects on classification results , one of which is that the minority class is highly likely masked by the majority class so as to weaken the ability of the classifiers to identify the minority class. Another effect is that irrelevant attributes hidden in imbalanced data can create much noise to interfere the classifiers, thereby leading to that the classifiers could mistakenly treat noise as the minority classes. In this scenario, the performance of the classifiers is rapidly declined and the classifiers obtain incorrect classification results. To address this issue, this paper proposed a conformal transformation twin-hypersphere with fuzzy. The critical thought is that using conformal transformation to explore the regions containing minority classes, by so doing, minority classes can be more likely to be noticed by the classifier. Using the proposed fuzzy function assesses the contributions of points to the hypersphere training, through evaluating the contributions, noise can be determined, thereby increasing the ability of the classifier to noise resistance. Results on the synthetic and real datasets show that the proposed method outperforms the competitors in classification accuracy and noise resistance. Results also imply that the proposed method does not exhibit exponential calculation time, meaning that the method is suitable for the classification of large-scale imbalanced datasets. We demonstrate that conformal transformation can assist those non-linear kernels to find those hard-to-observe regions containing minority classes, thereby strengthening the adaptability of the classifiers to imbalanced data following complex distributions. Moreover, the non-linear kernels using conformal transformation can adapt to the situation where different sub-regions in sample space require different nonlinearities .},
  archive      = {J_ISCI},
  author       = {Jian Zheng and Xin Hu},
  doi          = {10.1016/j.ins.2023.119880},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119880},
  shortjournal = {Inf. Sci.},
  title        = {Irrelevant attribute resistance approach to binary classification for imbalanced data},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast and error-adaptive influence maximization based on
count-distinct sketches. <em>ISCI</em>, <em>655</em>, 119875. (<a
href="https://doi.org/10.1016/j.ins.2023.119875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization (IM) is the problem of finding a seed vertex set that maximizes the expected number of vertices influenced under a given diffusion model . Due to the NP-Hardness of finding an optimal seed set, high-quality yet expensive approximation algorithms have been frequently used. In addition, lightweight, sketch-based approaches, which do not step-by-step simulate the influence process, have been proposed in the literature to cope with the scale of today&#39;s networks. In this work, we describe a fast, error-adaptive approach that leverages Count-Distinct sketches and hash-based fused sampling to avoid step-by-step simulations and estimate the number of influenced vertices throughout a diffusion. Furthermore, for faster estimations, the sketches of a vertex for consecutive simulations are stored adjacently in memory. This allows the proposed algorithm to estimate the number of influenced vertices for multiple simulations at once. For faster processing, the proposed method automatically rebuilds the sketches after observing estimation errors above a given threshold. Our experimental results show that the proposed algorithm yields seed sets with comparable quality while being up to 3 , 337 × 3,337× faster than a state-of-the-art, high-quality influence maximization algorithm. In addition, it is up to 63× faster than a sketch-based approach while producing seed sets with 2%–10% better influence scores.},
  archive      = {J_ISCI},
  author       = {Gökhan Göktürk and Kamer Kaya},
  doi          = {10.1016/j.ins.2023.119875},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119875},
  shortjournal = {Inf. Sci.},
  title        = {Fast and error-adaptive influence maximization based on count-distinct sketches},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed adaptive neural network consensus control of
fractional-order multi-agent systems with unknown control directions.
<em>ISCI</em>, <em>655</em>, 119871. (<a
href="https://doi.org/10.1016/j.ins.2023.119871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, adaptive consensus control of leader-following fractional-order multi-agent systems whose each subsystem includes functional uncertainties, external disturbances , and unknown control directions is investigated utilizing neural networks and the Nussbaum function. The controller is synthesized within the framework of the backstepping algorithm, where the “explosion of complexity” problem is mitigated through the use of a command filter, and the adverse impact of filtered errors is decreased using compensation signals. The function uncertainties of each follower are approximated by neural networks , and a disturbance update law is developed to identify the boundary of the disturbance. Importantly, a general conclusion is provided to affirm the applicability of the Nussbaum function in addressing controller design for fractional-order systems with unknown control directions. Finally, the validity of the proposed approach is verified via two numerical examples .},
  archive      = {J_ISCI},
  author       = {Hongling Qiu and Iakov Korovin and Heng Liu and Sergey Gorbachev and Nadezhda Gorbacheva and Jinde Cao},
  doi          = {10.1016/j.ins.2023.119871},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119871},
  shortjournal = {Inf. Sci.},
  title        = {Distributed adaptive neural network consensus control of fractional-order multi-agent systems with unknown control directions},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-free adaptive dynamic event-triggered robust control
for unknown nonlinear systems using iterative neural dynamic
programming. <em>ISCI</em>, <em>655</em>, 119866. (<a
href="https://doi.org/10.1016/j.ins.2023.119866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an adaptive dynamic event-triggered (ADET) robust control method for unknown nonlinear systems using iterative neural dynamic programming (INDP). Firstly, the ADET robust control problem is transformed into an ADET optimal control problem by introducing an infinite domain integral function. Then, dynamic variables and adaptive thresholds are designed for discrete-time systems with auxiliary variables. The proposed ADET method reduces computation and transmission costs compared to existing static and dynamic event triggering methods. INDP is utilized to learn the optimal solution of the ADET Hamilton-Jacobi-Bellman equation within the heuristic dynamic programming (HDP) framework, providing system stability and algorithm convergence. The INDP algorithm employs model, action, and critic neural networks and includes a method to directly minimize the iterative cost function in the back-propagation process. The neural network implementation of the INDP algorithm is detailed. Simulation results demonstrate that the proposed ADET method based on INDP achieves faster convergence with fewer transmitted data and control updates.},
  archive      = {J_ISCI},
  author       = {Xin Tong and Dazhong Ma and Zhanshan Wang and Zhongyang Ming and Xiangpeng Xie},
  doi          = {10.1016/j.ins.2023.119866},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119866},
  shortjournal = {Inf. Sci.},
  title        = {Model-free adaptive dynamic event-triggered robust control for unknown nonlinear systems using iterative neural dynamic programming},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Granule description with undetermined values in a three-way
epistemic perspective. <em>ISCI</em>, <em>655</em>, 119863. (<a
href="https://doi.org/10.1016/j.ins.2023.119863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, the accuracy of formal concept based granule description with undetermined values still has plenty of room for improvement. For this purpose, this paper presents a granule description method for uncertain data in a three-way epistemic perspective. Specifically, we resort to a kind of three-way epistemic model, i.e., three-way concepts. Firstly, three-way concepts are investigated by their stabilities in formal contexts with undetermined values. Then, an incomplete granule description method is proposed by using a three-way epistemic perspective. Finally, the accuracy and efficiency of the proposed method are compared with the classical epistemic perspective based method. It can be shown that the former can obtain a higher description accuracy. Moreover, if basic granules are taken as priori knowledge , both the number and acquisition time of basic granules under the framework of three-way epistemic perspective are significantly more than those under the framework of formal concepts. However, once the prior knowledge is obtained, there is no significant difference in incomplete granule description in terms of time consumption.},
  archive      = {J_ISCI},
  author       = {Huilai Zhi and Yifan Ma and Yinan Li and Hongwei Wang},
  doi          = {10.1016/j.ins.2023.119863},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119863},
  shortjournal = {Inf. Sci.},
  title        = {Granule description with undetermined values in a three-way epistemic perspective},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lightweight multi-objective evolutionary neural architecture
search with low-cost proxy metrics. <em>ISCI</em>, <em>655</em>, 119856.
(<a href="https://doi.org/10.1016/j.ins.2023.119856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Objective Evolutionary Neural Architecture Search (MOENAS) methods employ evolutionary algorithms to approximate a set of architectures representing optimal trade-offs between network performance and complexity. Directly estimating network performance via error rates or losses incurs long runtimes due to the computationally expensive network training procedure. Instead, low-cost metrics that require no network training have been proposed as a proxy for network performance. However, these metrics might exhibit inconsistent correlations with network performance across different search spaces . The influences of training-based and training-free metrics on the effectiveness and efficiency of MOENAS are still under-explored. We introduce the Enhanced Training-Free MOENAS (E-TF-MOENAS) that employs the widely-used NSGA-II as the search algorithm and optimizes multiple training-free performance metrics as separate objectives. Experiments on NAS-Bench-101 and NAS-Bench-201 show that E-TF-MOENAS outperforms training-free methods that use a single training-free performance metric and could obtain comparable results to training-based methods but with approximately 30 times less computation cost. E-TF-MOENAS obtains architectures in NAS-Bench-201 with state-of-the-art mean accuracies of 94.37%, 73.50%, and 46.62% for CIFAR-10, CIFAR-100, and ImageNet16-120, respectively, within less than 3 GPU hours. It is beneficial to utilize multiple training-free proxy metrics simultaneously and E-TF-MOENAS provides a convenient framework for building such an efficient NAS approach. The source code can be found at https://github.com/ELO-Lab/E-TF-MOENAS .},
  archive      = {J_ISCI},
  author       = {Ngoc Hoang Luong and Quan Minh Phan and An Vo and Tan Ngoc Pham and Dzung Tri Bui},
  doi          = {10.1016/j.ins.2023.119856},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119856},
  shortjournal = {Inf. Sci.},
  title        = {Lightweight multi-objective evolutionary neural architecture search with low-cost proxy metrics},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic updating variable precision three-way concept method
based on two-way concept-cognitive learning in fuzzy formal contexts.
<em>ISCI</em>, <em>655</em>, 119818. (<a
href="https://doi.org/10.1016/j.ins.2023.119818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive learning and two-way learning are effective knowledge representations, which can simulate the human brain to learn concepts. The combination of both topics has achieved some results and improved conceptual evolution ability in fuzzy formal concept analysis (FFCA), but there are still some shortcomings: 1) FFCA does not consider the flexibility of concepts, which makes it difficult to select suitable concepts; 2) the existing necessary and sufficient concepts fail to learn directly from any information granules; 3) the cognitive learning mechanism ignores to integrate previously acquired knowledge into the present state in the process of dynamic concept learning. To tackle these issues, in this paper, we put forward a novel two-way concept-cognitive learning (TCCL) model based on three-way decision in fuzzy formal contexts. Firstly, we introduce the object and attribute operators to learn variable precision object induced three-way concept, where such concept has flexibility by adjusting thresholds. Then, to learn directly necessary and sufficient three-way concept from the given clues, we investigate a new TCCL model, which has low computation cost for concept learning. Furthermore, updating mechanism of three-way concept is discussed in dynamic learning environment. Finally, the conducted experiments explicate the effectiveness and feasibility of our proposed approach in the large-scale datasets.},
  archive      = {J_ISCI},
  author       = {Chengling Zhang and Eric C.C. Tsang and Weihua Xu and Yidong Lin and Lanzhen Yang and Jiaming Wu},
  doi          = {10.1016/j.ins.2023.119818},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119818},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic updating variable precision three-way concept method based on two-way concept-cognitive learning in fuzzy formal contexts},
  volume       = {655},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An effective and robust genetic algorithm with hybrid
multi-strategy and mechanism for airport gate allocation. <em>ISCI</em>,
<em>654</em>, 119892. (<a
href="https://doi.org/10.1016/j.ins.2023.119892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gate allocation is a combinatorial scheduling problem with multi-constraint and multi-objective. It is challenging to solve this problem when the size of flights increases continuously. As an adaptive technology with a random search ability, the genetic algorithm (GA) has been widely used for resource scheduling and combinatorial optimization. However, it is prone to slow convergence and falling into local optimal solutions. Therefore, an effective and robust GA based on hybrid multi-strategy of reverse learning, interval probability mutation, and phagocytosis mechanism, called RPIP-GA, is proposed to implement a new airport gate-allocation method. In the RPIP-GA, the population is divided into several subpopulations based on the fitness values of all individuals to prevent population degradation and improve population quality. The reverse learning strategy with elite retention is designed to initialize the population, expand the global search space, improve the quality of the original solution, and increase the population diversity. The phagocytosis mechanism is employed to implement a crossover operation to enhance the convergence rate and local search ability. An interval probability mutation technique is designed to improve the local search ability in the early stage and prevent falling into the local optimum in the later stage. The effectiveness of the RPIP-GA is validated using 45 complex functions selected from the benchmark functions and CEC 2017, 22 real-world engineering problems selected from CEC 2011, and an actual gate allocation problem via comparisons with the GA, PSO, GSA, DNLGSA, WMSDE, PADE, HIRCGA, and other algorithms. The experimental results show that the RPIP-GA can obtain optimal results with improved stability in most cases. The maximum allocation rate of actual airport gates reaches 98%, and the average convergence accuracy increases by 19% compared with that of the GA. The data used in the study is publicly available from the GitHub repository (https://github.com/xiaocangjiu).},
  archive      = {J_ISCI},
  author       = {Zhuoning Zhu and Xiang Li and Huayue Chen and Xiangbing Zhou and Wu Deng},
  doi          = {10.1016/j.ins.2023.119892},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119892},
  shortjournal = {Inf. Sci.},
  title        = {An effective and robust genetic algorithm with hybrid multi-strategy and mechanism for airport gate allocation},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Baseline energy modeling for improved measurement and
verification through the use of ensemble artificial intelligence models.
<em>ISCI</em>, <em>654</em>, 119879. (<a
href="https://doi.org/10.1016/j.ins.2023.119879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate estimation of energy savings is crucial for the effective implementation of energy conservation measures (ECMs). Simultaneously, the integration of Artificial Intelligence (AI) has revolutionized software engineering by imbuing software with intelligent capabilities and autonomy. In this paper, we propose an ensemble model for precisely estimating baseline energy consumption within the realm of AI-empowered autonomous software. The ensemble model combines predictions from three tree-based Machine Learning models, namely Random Forest , XGBoost , and LightGBM. Notably, our model emphasizes the provision of explainability , granting transparency and insights into the key factors influencing baseline energy consumption. To validate its effectiveness, we conduct experimental evaluations on a diverse cluster of real-world buildings in Latvia. The results demonstrate the superiority of our proposed ensemble model over individual models and even a deep learning network tailored for energy consumption estimation. These findings underscore the efficacy of AI-empowered models in the energy sector, offering a robust and interpretable solution for estimating energy savings.},
  archive      = {J_ISCI},
  author       = {Elissaios Sarmas and Aikaterini Forouli and Vangelis Marinakis and Haris Doukas},
  doi          = {10.1016/j.ins.2023.119879},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119879},
  shortjournal = {Inf. Sci.},
  title        = {Baseline energy modeling for improved measurement and verification through the use of ensemble artificial intelligence models},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Three-sided online stable task assignment in spatial
crowdsourcing. <em>ISCI</em>, <em>654</em>, 119878. (<a
href="https://doi.org/10.1016/j.ins.2023.119878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task assignment is the fundamental problem of crowdsourcing, which addresses the matching between service providers and demanders in urban services. As crowdsourcing has been receiving more attention, the focus of task assignment has expanded from one-sided or two-sided task assignment to three-sided task assignment. Recent research on the three-sided version aims at the online case or stable case, which only partially reflects the real scenario. In this paper, we consider a hybrid case that contains the aforementioned cases. Concretely, we propose a three-sided online stable task assignment problem. We first show the fundamental notations of task assignment. Then, we analyze and present the matching conditions and formulate the problem. As a warm-up, we propose three iconic algorithms as baselines and analyze their performance in the three-sided scenario. Inspired by two suggested matching technique in a two-sided task assignment problem, we present a new algorithm that divides the arrival sequence into three parts in which we utilize different strategies for different arrival intervals. It balances efficiency and effectiveness. In the experiment, all the algorithms are verified in size, memory, and time and tested on a real and a synthetic dataset . The results show that our algorithm maintains efficiency and effectiveness.},
  archive      = {J_ISCI},
  author       = {Weiyi Huang and Peng Li and Bo Li and Qin Liu and Lei Nie and Haizhou Bao},
  doi          = {10.1016/j.ins.2023.119878},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119878},
  shortjournal = {Inf. Sci.},
  title        = {Three-sided online stable task assignment in spatial crowdsourcing},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-level adversarial attacks for graph neural networks.
<em>ISCI</em>, <em>654</em>, 119877. (<a
href="https://doi.org/10.1016/j.ins.2023.119877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have achieved significant success in numerous graph-based applications. Unfortunately, they are sensitive to adversarial examples generated by modifying graphs with imperceptible perturbations. Therefore, researchers develop attack models to evaluate the robustness of GNNs or design corresponding defense models. However, traditional attack models can hardly determine the importance of perturbed graph structures, where the selection of attack targets lacks explainability . Moreover, these attack models are mainly designed for certain graph-learning tasks. In this study, we propose a two-level adversarial attack framework that reconciles task- and feature-level attacks on GNNs. First, instead of using only adversarial examples, we introduce a dual-view pipeline with two task-level optimization objectives that consider the original and adversarial examples separately. We theoretically demonstrate that this simple yet powerful loss not only improves attack performance but also exhibits strong explainability. Second, we propose a feature-level attack framework based on contrastive learning in which adversarial attacks are applied to the learned features. Our theoretical results imply that contrastive learning between original and adversarial examples can destroy the representation and discriminative abilities of GNNs. Experimental results for several datasets and different GNN architectures demonstrate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Chengxi Song and Lingfeng Niu and Minglong Lei},
  doi          = {10.1016/j.ins.2023.119877},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119877},
  shortjournal = {Inf. Sci.},
  title        = {Two-level adversarial attacks for graph neural networks},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fixed-time converging neurodynamic approach with
time-varying coefficients for l1-minimization problem. <em>ISCI</em>,
<em>654</em>, 119876. (<a
href="https://doi.org/10.1016/j.ins.2023.119876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel neurodynamic network to deal with l 1 l1 -minimization problem. In the framework of the fixed-time converging neurodynamic network (FxNN), time-varying coefficients are introduced to design the time-varying fixed-time converging neurodynamic network (TFxNN). It is shown that the fixed-time stability of the proposed TFxNN via the Lyapunov stability conditions. It is further shown that the proposed TFxNN trajectories from any initial points quickly converge to the unique equilibrium solution in fixed-time. A distinctive feature of the proposed TFxNN is its flexibility to choose time-varying coefficients to accelerate convergence. Simulation results based on signal and image reconstruction are presented that the proposed neurodynamic network is feasible and effective.},
  archive      = {J_ISCI},
  author       = {Jing Xu and Chuandong Li and Xing He and Hongsong Wen and Xiaoyu Zhang},
  doi          = {10.1016/j.ins.2023.119876},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119876},
  shortjournal = {Inf. Sci.},
  title        = {A fixed-time converging neurodynamic approach with time-varying coefficients for l1-minimization problem},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maximal chain-based choquet-like integrals. <em>ISCI</em>,
<em>654</em>, 119874. (<a
href="https://doi.org/10.1016/j.ins.2023.119874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The original idea of the discrete Choquet integral on nonnegative reals is based on a distinguished permutation making the inputs reordering nonincreasingly or nondecreasingly. This permutation generates the weights from the given capacity, and then a weighted arithmetic mean yields the value of the corresponding Choquet integral. Since the permutation relates to a maximal chain , we introduce a concept of MCC-integrals using the setting of maximal chains on the power set of a finite set . This approach provides a unified framework for several integrals of nonnegative vectors with respect to games. We study basic properties and various representations of these MCC-integrals subsuming known results for the Choquet integral as a special case. For supermodular games it is shown that the Choquet integral is the minimum of all product-based MCC-integrals. Further, we discuss symmetric and asymmetric extensions for real-valued inputs providing new insight into the construction of fuzzy integral quadruplets. During the way, we point out certain inaccuracies in the literature.},
  archive      = {J_ISCI},
  author       = {Ondrej Hutník and Miriam Kleinová},
  doi          = {10.1016/j.ins.2023.119874},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119874},
  shortjournal = {Inf. Sci.},
  title        = {Maximal chain-based choquet-like integrals},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FedSW: Federated learning with adaptive sample weights.
<em>ISCI</em>, <em>654</em>, 119873. (<a
href="https://doi.org/10.1016/j.ins.2023.119873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a machine learning approach in which a cluster of clients collaboratively trains a model without sharing the data of any clients. As the datasets of each client&#39;s task are typically noisy and statistically diverse, they are not easily learned by a global model, especially deep networks that are prone to overfitting on biased training data . This study proposes an adaptive sample weighting algorithm based on self-paced learning (SPL). Instead of weighting all samples equally, the algorithm assigns weights to each sample based on its impact on the global model. To achieve this, the client objectives are defined as the sum of the weighted empirical risks and the regularizer with respect to the weight of each sample. The final global model is obtained by alternately optimizing the model parameters and sample weights. By applying the implicit SPL regularizer, we derive an analytic formula for the optimal sample weights used in the experiments. We demonstrate that the algorithm converges and that our method is more stable and accurate than the series of federated averaging algorithms. Specifically, when 30% of the training data is corrupted, the test accuracy in our method is up to 50% higher than that achieved by the federated averaging algorithm.},
  archive      = {J_ISCI},
  author       = {Xingying Zhao and Dong Shen},
  doi          = {10.1016/j.ins.2023.119873},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119873},
  shortjournal = {Inf. Sci.},
  title        = {FedSW: Federated learning with adaptive sample weights},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Matrix-based vs. Vector-based linear discriminant analysis:
A comparison of regularized variants on multivariate time series data.
<em>ISCI</em>, <em>654</em>, 119872. (<a
href="https://doi.org/10.1016/j.ins.2023.119872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past two decades, matrix-based or bilinear discriminant analysis (BLDA) methods have received much attention. However, it has been reported that the traditional vector-based regularized LDA (RLDA) is still quite competitive and could outperform BLDA on some benchmark datasets. A central question is whether the superiority of the vector-based RLDA would always hold for general matrix data, or is there any type of matrix data on which BLDA would perform better than RLDA? Actually, the reported comparisons are found to suffer from two limitations: (i) the comparisons are only limited to image data , and (ii) regularized RLDA is compared with non-regularized BLDA. In this paper, we break the two limitations and investigate the central question on another type of matrix data, namely multivariate time series (MTS) data. We propose a new two-parameter regularized BLDA (RBLDA) for MTS data classification . To choose the two parameters, we develop an efficient model selection algorithm . The newly proposed RBLDA enables us to perform a fair comparison between vector-based RLDA and matrix-based RBLDA. Experiments on a number of real MTS data sets are conducted to compare RBLDA with RLDA and evaluate the proposed algorithm. The results reveal that the superiority of the vector-based RLDA does not always hold for general matrix data, and RBLDA outperforms RLDA on MTS data. Moreover, the proposed model selection algorithm is efficient, and RBLDA can produce better visualization of MTS data than RLDA.},
  archive      = {J_ISCI},
  author       = {Jianhua Zhao and Haiye Liang and Shulan Li and Zhiji Yang and Zhen Wang},
  doi          = {10.1016/j.ins.2023.119872},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119872},
  shortjournal = {Inf. Sci.},
  title        = {Matrix-based vs. vector-based linear discriminant analysis: A comparison of regularized variants on multivariate time series data},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Differential privacy may have a potential optimization
effect on some swarm intelligence algorithms besides privacy-preserving.
<em>ISCI</em>, <em>654</em>, 119870. (<a
href="https://doi.org/10.1016/j.ins.2023.119870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy (DP), as a promising privacy-preserving model, has attracted great interest from researchers in recent years. At present, research on the combination of deep learning and DP is active. In contrast, another widely used artificial intelligence technique, swarm intelligence (SI), has received little attention in the context of DP even though it also triggers privacy concerns. For this reason, this paper attempts to combine DP and SI for the first time and proposes a general differentially private swarm intelligence algorithm framework (DPSIAF). By utilizing the exponential mechanism, this framework can easily develop existing SI algorithms into the private versions. As examples, we apply it to four popular SI algorithms, and the related analyses demonstrate the effectiveness of our DPSIAF. More importantly, our private algorithms also exhibit some interesting experimental phenomena. In some cases, their performance is not strictly affected by the privacy budget, and one of them even outperforms its non-private version. These findings are different from the conventional cognition, which indicates DP owns the potential to serve as an optimization tool for some SI algorithms. Our study may provide a new perspective on DP and promote the synergy between metaheuristic optimization community and privacy computing community.},
  archive      = {J_ISCI},
  author       = {Zhiqiang Zhang and Hong Zhu and Meiyi Xie},
  doi          = {10.1016/j.ins.2023.119870},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119870},
  shortjournal = {Inf. Sci.},
  title        = {Differential privacy may have a potential optimization effect on some swarm intelligence algorithms besides privacy-preserving},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Zonotopic set-membership estimation for time-varying systems
subject to dynamical biases and quantization effects. <em>ISCI</em>,
<em>654</em>, 119869. (<a
href="https://doi.org/10.1016/j.ins.2023.119869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the zonotopic set-membership estimation (SME) problem is studied for time-varying systems subject to dynamical biases and uniform quantization . The considered dynamical bias evolves according to a certain dynamic process disturbed by unknown-but-bounded noises. The main objective of the paper is to propose a zonotopic SME method such that the real states are included in zonotopes described by linear image of an unit hypercube . By analyzing the dynamics of biases and states, the intersection set containing the state are first obtained based on the quantization measurements. Then, an auxiliary zonotope is constructed to bound the intersection where the center and generator matrix are presented recursively. Through orchestrating the correlation matrix , the F -Radius of such an auxiliary zonotope is further minimized. To reduce the computational burden, the desired zonotope with finite-dimensional generator matrix is constructed to externally approximate the auxiliary zonotope. Furthermore, the boundedness stability is analyzed for the developed zonotopic SME approach in the simulations presence of dynamical biases and uniform quantization. Finally, an example is provided to display the effectiveness of the SME method.},
  archive      = {J_ISCI},
  author       = {Hailong Tan and Bo Shen and Qi Li and Tingwen Huang},
  doi          = {10.1016/j.ins.2023.119869},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119869},
  shortjournal = {Inf. Sci.},
  title        = {Zonotopic set-membership estimation for time-varying systems subject to dynamical biases and quantization effects},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic adaptive multi-objective optimization algorithm
based on type detection. <em>ISCI</em>, <em>654</em>, 119867. (<a
href="https://doi.org/10.1016/j.ins.2023.119867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multi-objective optimization problems (DMOPs) are multi-objective problems that are influenced by dynamically changing environmental parameters. Most current algorithms for solving DMOPs only respond to dynamic changes in the decision space or objective space and also ignore the impact of the type of DMOPs on the algorithm. The changes in the Pareto-optimal solution (POS) and Pareto-optimal front (POF) may affect the type of change in DMOPs. Therefore, this paper proposed an adaptive dynamic multi-objective evolutionary algorithm for type detection (TDA-DMOEA). First, the dynamic detection operator is designed to identify the types of dynamic problems . The Wilcoxon signed-rank test and Hyper Volume (HV) are used to detect the difference of POS and POF in two adjacent environments respectively. Then, different response strategies are designed to cope with different types of changes in DMOP. In particular, a multi-angle-based transfer learning method (MA-TL) with a closed kernel function is derived when faced with simultaneous changes in POS and POF. Finally, a comprehensive study of the commonly used benchmark set of DMOPs is presented, and the proposed algorithm achieves better performance in optimizing DMOPs.},
  archive      = {J_ISCI},
  author       = {Xingjuan Cai and Linjie Wu and Tianhao Zhao and Di Wu and Wensheng Zhang and Jinjun Chen},
  doi          = {10.1016/j.ins.2023.119867},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119867},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic adaptive multi-objective optimization algorithm based on type detection},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lp synchronization of shunting inhibitory cellular neural
networks with multiple proportional delays. <em>ISCI</em>, <em>654</em>,
119865. (<a href="https://doi.org/10.1016/j.ins.2023.119865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, synchronization control of shunting inhibitory cellular neural networks with multiple proportional delays is studied. Firstly, a controller is designed to ensure L p Lp synchronization between the response and drive shunting inhibitory cellular neural networks . Then, a method based on system solutions is proposed to obtain L p Lp synchronization criteria. On the one hand, the synchronization criteria obtained by this method only contain some simple inequalities, and hence the calculation amount is greatly reduced. On the other hand, the method does not require the establishment of any Lyapunov–Krasovskii functional. The obtained L p Lp synchronization criteria are simpler and can be tested by standard software tools . Finally, a numerical example is given to illustrate the superiority of the proposed L p Lp synchronization criteria. It is worth emphasizing that the L p Lp synchronization control problem is analyzed for the first time in this paper.},
  archive      = {J_ISCI},
  author       = {Xin Wang and Xue Liang and Xian Zhang and Yu Xue},
  doi          = {10.1016/j.ins.2023.119865},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119865},
  shortjournal = {Inf. Sci.},
  title        = {Lp synchronization of shunting inhibitory cellular neural networks with multiple proportional delays},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-iterative border-peeling clustering algorithm based on
swap strategy. <em>ISCI</em>, <em>654</em>, 119864. (<a
href="https://doi.org/10.1016/j.ins.2023.119864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Border-Peeling algorithm is a recently proposed density based clustering algorithm . The method of peeling off border points by continuous iteration and calculating the density influence value by using the Gaussian kernel distance makes the algorithm more complex. At the same time, there is a risk of excessive peeling of small clusters on unbalanced datasets, which leads to a large number of noise misidentification . In order to reduce the time consumption and improve the clustering performance on unbalanced datasets, this paper proposes a non-iterative border-peeling clustering algorithm . First, the potential core points are determined by the centroids of k-nearest neighbor. Secondly, the points with lower local relative density in the core points and the points with higher relative density in the border points are exchanged to complete the distinction between the core points and the border points. Then basic DBSCAN method is used to cluster core points and noise points. Finally, the associations between the border points and the core points are based on the number of reverse nearest neighbors of the border points in the core points. Our method has achieved competitive results on 10 synthetic datasets and 8 UCI real-world datasets.},
  archive      = {J_ISCI},
  author       = {Hui Tu and Shifei Ding and Xiao Xu and Haiwei Hou and Chao Li and Ling Ding},
  doi          = {10.1016/j.ins.2023.119864},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119864},
  shortjournal = {Inf. Sci.},
  title        = {Non-iterative border-peeling clustering algorithm based on swap strategy},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonstationary online convex optimization with multiple
predictions. <em>ISCI</em>, <em>654</em>, 119862. (<a
href="https://doi.org/10.1016/j.ins.2023.119862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on dynamic regret for non-stationary online convex optimization with full information. State-of-the-art analysis shows that Implicit Online Mirror Descent (IOMD) combined with Hedge achieves an O ˜ ( min ⁡ { V T , ( 1 + P T ) T } ) O˜(min⁡{VT,(1+PT)T}) dynamic regret, where V T VT denotes the temporal variability of the loss functions and P T PT measures the path length reflecting the non-stationarity of the comparator sequence, and Optimistic IOMD (OptIOMD) enjoys the dynamic regret of O ( min ⁡ { V T ′ , ( 1 + P ) T } ) O(min⁡{VT′,(1+P)T}) , where V T ′ VT′ denotes the cumulative distance from the loss functions to an arbitrary predictor sequence, and P is an upper bound of the path-length P T PT . In order to further suppress dynamic regret, we propose an algorithm named Hedge-OptIOMD, which achieves an O ˜ ( min ⁡ { min j ∈ 1 : n ⁡ V T j , ( 1 + P T ) T } ) O˜(min⁡{minj∈1:n⁡VTj,(1+PT)T}) dynamic regret via multiple predictors , where V T j VTj represents the cumulative distance from the loss functions to the j -th predictor sequence. We also verify the advantages of Hedge-OptIOMD through numerical experiments.},
  archive      = {J_ISCI},
  author       = {Qing-xin Meng and Jian-wei Liu},
  doi          = {10.1016/j.ins.2023.119862},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119862},
  shortjournal = {Inf. Sci.},
  title        = {Nonstationary online convex optimization with multiple predictions},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Preference-based regret three-way decision method on
multiple decision information systems with linguistic z-numbers.
<em>ISCI</em>, <em>654</em>, 119861. (<a
href="https://doi.org/10.1016/j.ins.2023.119861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision theory (3WD) provides a reasonable solution to solve multi-criteria decision-making (MCDM) problems and reduces more decision risks than two-way decision (2WD). However, the impact of preferences on decision results has not been reasonably considered in 3WD. Thus, this paper proposes a preference-based regret 3WD model on multiple decision information systems (MDISs) with linguistic Z-numbers (LZNs) to address the defect. First of all, a Z-LINMAP method is proposed by extending LINMAP method into the LZNs environment to derive criteria weights, Z-number ideal solutions and preference coefficients. On the basis of preference coefficients, the consistency-order and inconsistency-order are defined and further the consistency and inconsistency equivalence classes are presented to derive the conditional probabilities of alternatives. Then, the regret loss functions based on regret theory are presented and the regret 3WD rules of a single decision information system are designed. Furthermore, the weighted expected regret loss function and loss score function are defined to classify and rank all alternatives for MDISs. Finally, the proposed 3WD model is applied to the image recognition case with human-computer interaction to verify the effectiveness, and the comparative and sensitivity analyses are carried out to demonstrate the feasibility of our model.},
  archive      = {J_ISCI},
  author       = {Han Wang and Yanbing Ju and Peiwu Dong and Aihua Wang and Francisco Javier Cabrerizo},
  doi          = {10.1016/j.ins.2023.119861},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119861},
  shortjournal = {Inf. Sci.},
  title        = {Preference-based regret three-way decision method on multiple decision information systems with linguistic Z-numbers},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Competitive swarm optimization with subset selection based
manifold learning for multimodal multi-objective optimization.
<em>ISCI</em>, <em>654</em>, 119860. (<a
href="https://doi.org/10.1016/j.ins.2023.119860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are two major challenges when handling the multimodal multi-objective optimization (MMO) problems. One is the loss of diversity since most of the evolutionary algorithms designed for MMO prefer the base algorithm with rapid convergence. Therefore, the extra niching or other diversity preserving mechanism is inevitable. The other is the distribution of the Pareto optimal solutions with imbalanced density. Since the Pareto optimal sets may show different characteristics in the decision space, it is tough to converge the solutions to the Pareto front uniformly. To address these issues, subset selection and manifold learning based competitive swarm optimization algorithm , namely MMO_CSO, is proposed. Competitive swarm optimizer which has well balance on both diversity and convergence is adopted. Moreover, a subset selection strategy is applied to select diversified individuals for learning the manifold structure of the Pareto set . Thereby, the subset selection based manifold learning mechanism is designed to generate the promising solutions which could approach the real Pareto solutions and fill the sparse Pareto subregion . Compared against six state-of-the-art peer algorithms, the proposed MMO_CSO has a better performance to search for the Pareto optimal solutions both in decision space and objective space on CEC2019 MMO benchmarks.},
  archive      = {J_ISCI},
  author       = {Weiwei Zhang and Yan Fan and Gary G. Yen and Feiyu Wang and Guoqing Li},
  doi          = {10.1016/j.ins.2023.119860},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119860},
  shortjournal = {Inf. Sci.},
  title        = {Competitive swarm optimization with subset selection based manifold learning for multimodal multi-objective optimization},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neighbor self-knowledge distillation. <em>ISCI</em>,
<em>654</em>, 119859. (<a
href="https://doi.org/10.1016/j.ins.2023.119859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-Knowledge Distillation (Self-KD), a technique that enables neural networks to learn from themselves, often relies on auxiliary modules or networks to generate supervisory signals for training. However, this approach incurs significant additional resource costs. Moreover, incorporating auxiliary classifiers within the network architecture creates a capacity mismatch when distilling knowledge from deep to shallow classifiers. This paper proposes a concise and efficient Self-KD method called Neighbor Self-Knowledge Distillation (NSKD), which introduces teacher assistants into the Self-KD by adding auxiliary classifiers to the shallow part of the network to construct distillations of multiple neighboring student-teacher assistant combinations to reduce the mismatch between the students&#39; and teachers&#39; abilities. During distillation, NSKD utilizes only the soft labels generated by each classifier and corresponding ground truth labels as supervisory signals, minimizing resource consumption. NSKD enables neighboring modules to learn from each other through neighboring distillation, enhancing overall network performance. Experimental results on five network models and seven popular datasets demonstrate the superiority of NSKD over other state-of-the-art Self-KD methods. Notably, NSKD achieves average accuracy improvements of 2.26%, 2.32%, and 2.4% on the CIFAR100, TinyImageNet, and fine-grained visual classification datasets.},
  archive      = {J_ISCI},
  author       = {Peng Liang and Weiwei Zhang and Junhuang Wang and Yufeng Guo},
  doi          = {10.1016/j.ins.2023.119859},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119859},
  shortjournal = {Inf. Sci.},
  title        = {Neighbor self-knowledge distillation},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vertex-substitution framework verifies the reconstruction
conjecture for finite undirected graphs. <em>ISCI</em>, <em>654</em>,
119858. (<a href="https://doi.org/10.1016/j.ins.2023.119858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Kelly-Ulam reconstruction conjecture proposes that a graph’s isomorphism class is determined by the classes of its multiset of vertex-deleted subgraphs. Although the conjecture has been verified for many families of undirected graphs, several cases remain unresolved. This analysis proposes a unified proof of the reconstruction conjecture for all finite undirected graphs. A vertex-substitution framework is introduced, in which vertex-deleted subgraphs are augmented by a substitute vertex connected universally with characteristic edge weight (an arbitrary constant outside the deck alphabet). Vertex-substituted subgraphs have as many vertices as the parent graph, permitting tensor representation of the deck reconstruction. Hypomorphism under vertex-deletion is shown to imply hypomorphism under vertex-substitution and vice-versa. In the vertex-substitution framework, bijections mapping cards between hypomorphic decks are shown to map vertices between the parent graphs, demonstrating that an isomorphic mapping always exists. The Kelly-Ulam reconstruction conjecture is verified for finite, undirected graphs on at least three vertices. The vertex-substitution framework provides a unified analytical approach to the reconstruction conjecture for all undirected graphs.},
  archive      = {J_ISCI},
  author       = {Robert John O&#39;Shea and Louis Wilkins},
  doi          = {10.1016/j.ins.2023.119858},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119858},
  shortjournal = {Inf. Sci.},
  title        = {Vertex-substitution framework verifies the reconstruction conjecture for finite undirected graphs},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning to compensate for lack of information: Extracting
latent knowledge for effective temporal knowledge graph completion.
<em>ISCI</em>, <em>654</em>, 119857. (<a
href="https://doi.org/10.1016/j.ins.2023.119857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of temporal knowledge graph embedding (TKGE) is to represent the entities and relations in a given temporal knowledge graph (TKG) as low-dimensional vectors ( i.e. , embeddings), which preserve both semantic information and temporal dynamics of the factual information. In this paper, we posit that the intrinsic difficulty of existing TKGE methods lies in the lack of information in KG snapshots with timestamps , each of which contains the facts that co-occur at a specific timestamp. To address this challenge, we propose a novel self-supervised TKGE approach, THOR ( T hree-tower grap H c O nvolution netwo R ks (GCNs)), which extracts latent knowledge from TKGs by jointly leveraging both temporal and atemporal dependencies between entities and the structural dependency between relations. THOR learns the embeddings of entities and relations, obtained from three-tower GCNs by (1) maximizing the likelihood of the facts in a TKG and (2) addressing the lack of information in a TKG based on the auxiliary supervision signals of each entity. Our experiments on three real-world datasets demonstrate that THOR significantly outperforms 17 competitors in terms of TKG completion tasks. THOR yields up to 9.37% higher accuracy than the best competitor.},
  archive      = {J_ISCI},
  author       = {Yeon-Chang Lee and JaeHyun Lee and Dongwon Lee and Sang-Wook Kim},
  doi          = {10.1016/j.ins.2023.119857},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119857},
  shortjournal = {Inf. Sci.},
  title        = {Learning to compensate for lack of information: Extracting latent knowledge for effective temporal knowledge graph completion},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CGN: Class gradient network for the construction of
adversarial samples. <em>ISCI</em>, <em>654</em>, 119855. (<a
href="https://doi.org/10.1016/j.ins.2023.119855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have tremendously succeeded in several computer vision-related fields. Nevertheless, previous research demonstrates that DNNs are vulnerable to adversarial sample attacks. Attackers add carefully designed perturbation noise to clean samples to form adversarial samples, which may lead to errors in the DNNs&#39; predictions. Consequently, the safety of deep learning has attracted much attention, and researchers have commenced exploring adversarial samples from different perspectives. In this paper, a method based on class gradient networks (CGN) is proposed, which can generate high-quality adversarial samples by designing multiple objective functions. Specifically, the adversarial sample&#39;s high-level features are guided to change by introducing a high-level class gradient matrix, and the classification loss and perturbation loss are combined to jointly train a generator to fit the distribution of adversarial noises. We conducted experiments on two standard datasets, Fashion-MNIST and CIFAR-10. The results demonstrate the superiority of our method in the transferability of adversarial samples on targeted attacks and indicate the approach outperforms the baseline method .},
  archive      = {J_ISCI},
  author       = {Xiang Li and Haiwang Guo and Xinyang Deng and Wen Jiang},
  doi          = {10.1016/j.ins.2023.119855},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119855},
  shortjournal = {Inf. Sci.},
  title        = {CGN: Class gradient network for the construction of adversarial samples},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CheXMed: A multimodal learning algorithm for pneumonia
detection in the elderly. <em>ISCI</em>, <em>654</em>, 119854. (<a
href="https://doi.org/10.1016/j.ins.2023.119854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pneumonia can be a deadly illness for particular populations, one of which is older adults. While studies have successfully trained artificial intelligent assisted diagnostic tools to detect pneumonia using chest X-ray images, they were targeted to the general population without stratification on age groups. This study (a) investigated the performance disparities between geriatric and younger patients when using chest X-ray images to detect pneumonia, and (b) developed and tested a multimodal model called CheXMed that incorporates clinical notes together with image data to improve pneumonia detection performance for older people. Accuracy, precision, recall, and F1-score were used for model performance evaluation. CheXMed outperforms baseline models on all evaluation metrics. The accuracy, precision, recall, and F1-score are 0.746, 0.746, 0.740, 0.743 for CheXMed, 0.645, 0.680, 0.535, 0.599 for CheXNet, 0.623, 0.655, 0.521, 0.580 for DenseNet121, and 0.610, 0.617, 0.543, 0.577 for ResNet18.},
  archive      = {J_ISCI},
  author       = {Hao Ren and Fengshi Jing and Zhurong Chen and Shan He and Jiandong Zhou and Le Liu and Ran Jing and Wanmin Lian and Junzhang Tian and Qingpeng Zhang and Zhongzhi Xu and Weibin Cheng},
  doi          = {10.1016/j.ins.2023.119854},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119854},
  shortjournal = {Inf. Sci.},
  title        = {CheXMed: A multimodal learning algorithm for pneumonia detection in the elderly},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Joint framework for tensor decomposition-based temporal
knowledge graph completion. <em>ISCI</em>, <em>654</em>, 119853. (<a
href="https://doi.org/10.1016/j.ins.2023.119853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) usually contain a lot of missing information , static knowledge graph completion (KGC) is widely used to solve their incompleteness. In recently, since the incompleteness of temporal KGs which typically contain lots of temporal facts, like (Barack Obama, Is-president-of, USA, 2008), temporal knowledge graph completion (TKGC) is proposed to predict the missing part of (?, Is-president-of, USA, 2008) or (Barack Obama, Is-president-of, ?, 2008). In particular, tensor decomposition method has shown excellent performance in KGC and therefore many existing methods extend it to TKGC. One of the key challenges is how to make full use of static information and effectively fuse static ( non-temporal ) and temporal information for improving the performance of TKGC. The existing models usually concatenate or sum the static and temporal embeddings directly. Moreover, we observe that neighborhood information of temporal facts may be very useful for inferring the missing parts of temporal facts while has not been fully explored and utilized. To address these challenges, we propose a joint framework composed of temporal and static modules for tensor decomposition-based TKGC. In temporal module, we propose a new neighborhood time sharing technology for aggregating richer temporal semantic information. The static module is proposed as an auxiliary model to further learn embedding representation of static information based on our proposed two training strategies (named typed entity strategy and adjacent active entity strategy). Finally, we propose a novel way of fusing static and temporal information through joint learning of two modules based on our proposed entity sharing technology. A series of comparison and ablation experiments show that our model can make better and full use of static information while capturing richer temporal semantic information, coupled with an effective fusion method, thus achieving state-of-the-art (SOTA) performance compared to existing tensor decomposition-based TKGC methods on four benchmark datasets.},
  archive      = {J_ISCI},
  author       = {Fu Zhang and Hongzhi Chen and Yuzhe Shi and Jingwei Cheng and Jinghao Lin},
  doi          = {10.1016/j.ins.2023.119853},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119853},
  shortjournal = {Inf. Sci.},
  title        = {Joint framework for tensor decomposition-based temporal knowledge graph completion},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-stage denoising framework for zero-shot learning with
noisy labels. <em>ISCI</em>, <em>654</em>, 119852. (<a
href="https://doi.org/10.1016/j.ins.2023.119852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although zero-shot learning (ZSL) has gained widespread concern due to its excellent capacity of recognizing new object classes without seeing any visual instances, most existing methods assume that all seen-class instances used for training are correctly labeled. In some real application scenarios, when it comes to noisy labels, ZSL will inevitably suffer accuracy collapse. To address the issue, a two-stage denoising framework (TSDF) is proposed for ZSL in this work. First, an ZSL-oriented Joint training with co-regularization (JoCoR) is developed, which includes a tailored loss function that helps remove suspected noisy-label instances prior to training a ZSL model. Second, a ramp-style loss function is designed to reduce negative impact brought by the remaining noisy labels. In order to facilitate incorporating the ramp-style loss into deep-architecture based ZSL models, a matched dynamic screening strategy (DSS) is also developed. Unlike the traditional concave-convex procedure (CCCP) framework, DSS handles the nonconvexity of the ramp-style loss without requiring an additional iterative loop, demonstrating notable advantages in efficiency. In addition, DSS could work without a predetermined truncating point in the ramp-style loss. Experimental results show that our proposed method achieves exciting results in various noisy-label environments.},
  archive      = {J_ISCI},
  author       = {Long Tang and Pan Zhao and Zhigeng Pan and Xingxing Duan and Panos M Pardalos},
  doi          = {10.1016/j.ins.2023.119852},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119852},
  shortjournal = {Inf. Sci.},
  title        = {A two-stage denoising framework for zero-shot learning with noisy labels},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). REPROT: Explaining the predictions of complex deep learning
architectures for object detection through reducts of an image.
<em>ISCI</em>, <em>654</em>, 119851. (<a
href="https://doi.org/10.1016/j.ins.2023.119851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep learning models can solve complex prediction problems, they have been criticized for being ‘black boxes’. This implies that their decisions are difficult, if not impossible, to explain by simply inspecting their internal knowledge structures. Explainable Artificial Intelligence has attempted to open the black-box through model-specific and agnostic post-hoc methods that generate visualizations or derive associations between the problem features and the model predictions. This paper proposes a new method, termed REPROT, that explains the decisions of complex deep learning architectures based on local reducts of an image. A ‘reduct’ is a set of sufficiently descriptive features that can fully characterize the acquired knowledge. The created reducts are used to build a ‘prototype image’ that visually explains the inference obtained by a black-box model for an image. We focus on deep learning architectures whose complexity and internal particularities demand adapting existing model-specific explanation methods, making the explanation process more difficult. Experimental results show that the black-box model can detect an object using the prototype image generated from the reduct. Hence, the explanations will be given by “the minimum set of features sufficient for the neural model to detect an object”. The confidence scores obtained by architectures such as Inception, Yolo, and Mask R-CNN are higher for prototype images built from the reduct than those built from the most important superpixels according to the LIME method. Moreover, the target object is not detected on several occasions through the LIME output, thus supporting the superiority of the proposed explanation method.},
  archive      = {J_ISCI},
  author       = {Marilyn Bello and Gonzalo Nápoles and Leonardo Concepción and Rafael Bello and Pablo Mesejo and Óscar Cordón},
  doi          = {10.1016/j.ins.2023.119851},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119851},
  shortjournal = {Inf. Sci.},
  title        = {REPROT: Explaining the predictions of complex deep learning architectures for object detection through reducts of an image},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An optimization-based three-way decision for multi-criteria
ranking strategy considering intuitionistic fuzzy concept.
<em>ISCI</em>, <em>654</em>, 119850. (<a
href="https://doi.org/10.1016/j.ins.2023.119850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As information continues to expand and uncertainty intensifies, traditional three-way decision methods in multi-criteria environments often appear inadequate when dealing with ranking problems. Most traditional three-way decision methods usually rely on subjective concepts or require decision-makers to specify probability parameters when constructing scheme descriptions, which leads to high subjectivity of the methods. Based on this background, this paper proposes an optimization-based three-way decision model for multi-criteria ranking strategy considering intuitionistic fuzzy concept, with the aim of mitigating the excessive subjectivity observed in most of the three-way decision methods. Firstly, a scheme-oriented intuitionistic fuzzy concept is defined to represent the decision-maker&#39;s fuzzy perception and selection of the scheme. Then, using the scheme-oriented intuitionistic fuzzy concept and the classic description of candidate schemes obtained through intuitionistic fuzzy c -means clustering algorithm , this paper provides a new method for estimating the conditional probability of the schemes that is not limited by parameter settings. Secondly, combining the scheme-oriented intuitionistic fuzzy concept and intuitionistic fuzzy information table, a new risk loss function is proposed, which is suitable for decision problems under intuitionistic fuzzy environment. Then, based on three-way decision model formulated using an optimization-based approach, an objective new ranking strategy is constructed. In addition, numerical analysis , comparative analysis, and parameter analysis are used to validate the rationality and feasibility of the presented ranking strategy. Finally, through quantitative analysis of multiple datasets and qualitative analysis of several ranking models, the operability of the new ranking strategy is verified.},
  archive      = {J_ISCI},
  author       = {Wang Mao and Kai Zhang and Xiangbin Liu and Jian Tang},
  doi          = {10.1016/j.ins.2023.119850},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119850},
  shortjournal = {Inf. Sci.},
  title        = {An optimization-based three-way decision for multi-criteria ranking strategy considering intuitionistic fuzzy concept},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep reinforcement learning-based online task offloading in
mobile edge computing networks. <em>ISCI</em>, <em>654</em>, 119849. (<a
href="https://doi.org/10.1016/j.ins.2023.119849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing has been a promising paradigm to reduce the computation delay of tasks and extend the battery life of Internet of Things devices. Most existing task offloading methods in mobile edge computing networks are based on stable task arrivals and homogeneous users. However, in practical network environments, the frequency at which an Internet of Things device generates tasks is typically time-variant, and user requirements for security guarantees and response performance are always differential. Motivated by this, we investigate online task offloading in mobile edge computing networks with diverse users. By dividing edge nodes into public and private ones, we present a novel collaboration architecture. Considering correlated arrivals, we construct a system model comprising local computing and cloud-edge computing models. Under a matrix-geometric solution framework, we analyze the system model to derive the overall task latency. For mobile edge computing networks with variable task arrival intensity, we propose a deep reinforcement learning-based online task scheduling algorithm to realize online task offloading. Experimental results demonstrate that compared to the offline task scheduling algorithm, for the correlation coefficient of 0, 0.1, and 0.2, the proposed online task scheduling algorithm can reduce the overall task latency by about 1.09%, 2.65%, and 4.34%, respectively.},
  archive      = {J_ISCI},
  author       = {Haixing Wu and Jingwei Geng and Xiaojun Bai and Shunfu Jin},
  doi          = {10.1016/j.ins.2023.119849},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119849},
  shortjournal = {Inf. Sci.},
  title        = {Deep reinforcement learning-based online task offloading in mobile edge computing networks},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A consensus model considers managing manipulative and
overconfident behaviours in large-scale group decision-making.
<em>ISCI</em>, <em>654</em>, 119848. (<a
href="https://doi.org/10.1016/j.ins.2023.119848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When dealing with large-scale group decision-making problems, the central emphasis lies in the objective and rational acquisition of a collective opinion acceptable to the majority of decision makers . Manipulative and overconfident behaviours are two common behaviours that make the decision results deviate from the objective facts in the decision-making process. To manage manipulative and overconfident behaviours in decision-making, this paper investigated a novel consensus model based on social networks. A novel efficient clustering model is first proposed in the model, in which the subgroups&#39; combined cohesion is considered. Furthermore, for the manipulative behaviour of decision makers , we proposed an improved method for the identification and management based on trust relationships. In the consensus reaching process, we proposed a new identification mechanism to promote consensus reaching effectively. In the feedback mechanism, the social network DeGroot model is employed to adjust the opinions of decision makers . Moreover, a management approach is proposed for the overconfident behaviour of decision makers in the social network DeGroot model. Lastly, the feasibility and applicability of the proposed model are verified by an illustrative example. Simulation experiments and comparative analysis demonstrate the effectiveness of the model in facilitating consensus reaching.},
  archive      = {J_ISCI},
  author       = {Xia Liang and Jie Guo and Peide Liu},
  doi          = {10.1016/j.ins.2023.119848},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119848},
  shortjournal = {Inf. Sci.},
  title        = {A consensus model considers managing manipulative and overconfident behaviours in large-scale group decision-making},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). AFC: An adaptive lossless floating-point compression
algorithm in time series database. <em>ISCI</em>, <em>654</em>, 119847.
(<a href="https://doi.org/10.1016/j.ins.2023.119847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The time series database is a specialized type of database specifically designed for storing and analyzing time series data . Compression of time series data is crucial for its performance. However, efficiently compressing time series data, particularly floating-point data, remains challenging. Existing compression algorithms are efficient for only a limited range of data patterns, indicating a lack of self-adaptation. In this paper, we propose an effective and A daptive lossless F loating-point C ompression algorithm AFC for time series databases. We devise four unique compression strategies, and based on the data patterns, AFC dynamically selects the appropriate strategy. These strategies handle data compression for diverse data patterns, enhancing the compression ratio and efficiency. The most suitable strategy is employed to achieve an optimal compression ratio . We compared our AFC algorithm with four state-of-the-art compression algorithms , namely Gorilla, FPC, TSXor, and Chimp, as well as various general-purpose compression algorithms such as LZ4 and Snappy. Experimental results demonstrate that our algorithm achieves an improvement of at least 20% in compression ratio and even up to 100% on certain datasets.},
  archive      = {J_ISCI},
  author       = {Haoyuan Chen and Liang Liu and Jingwen Meng and Wanying Lu},
  doi          = {10.1016/j.ins.2023.119847},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119847},
  shortjournal = {Inf. Sci.},
  title        = {AFC: An adaptive lossless floating-point compression algorithm in time series database},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Emergence of collective adaptive response based on visual
variation. <em>ISCI</em>, <em>654</em>, 119846. (<a
href="https://doi.org/10.1016/j.ins.2023.119846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Models are constantly being developed to replicate the collective behavior of biological groups. However, with popular vision-based models, it is difficult to capture the inter-individual differences in velocity from visual information; consequently, a vision-based group cannot produce an adaptive response to the movements of individuals within the group and reach consensus. To remedy this deficiency, based on the OODA (observation-orientation-decision-action) framework as an abstraction of collective behavior, this paper introduces an alignment response with visual variation as input to a vision-based model and proposes a method based on an adaptive mechanism for generating a collective adaptive response. Through experiments on coordinated collective behavior, the introduction of the proposed alignment response is demonstrated to shorten the time required for the vision-based group to reach consensus, and the polarization increases by 59.42%. In addition, cases of a group guided by an informed individual either performing a simple turn or following one of two complex trajectories are evaluated to verify the generation of a collective adaptive response. The introduction of the adaptive mechanism results in an 11.92% increase in the response. This study remedies the deficiencies of vision-based models and offers a theoretical foundation for addressing communication interference in unmanned swarms.},
  archive      = {J_ISCI},
  author       = {Jingtao Qi and Liang Bai and Yingmei Wei and Huaxi Zhang and Yandong Xiao},
  doi          = {10.1016/j.ins.2023.119846},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119846},
  shortjournal = {Inf. Sci.},
  title        = {Emergence of collective adaptive response based on visual variation},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal granularity selection based on algorithm stability
with application to attribute reduction in rough set theory.
<em>ISCI</em>, <em>654</em>, 119845. (<a
href="https://doi.org/10.1016/j.ins.2023.119845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal granularity selection is a key issue in rough set, by which decision rules can be generated to assign corresponding decision labels for new samples. The current evaluation criteria of optimal granularity mainly focus on the experimental effect of prediction algorithms , thus ignoring the theoretical relationship between granularity and the generalization ability of algorithms. In this paper, we study the issue overlooked above and propose a novel framework for optimal granularity selection with theoretical guarantee. In our framework, a rough set-based prediction algorithm that incorporates a global confidence as scoring function is introduced, which is characterized by the granularity-based loss function. On the bias, the relationship between granularity and the generalization ability of algorithm is studied by introducing the stability theory in machine learning . The generalization error bound of algorithm is derived as a theoretical guarantee for optimal granularity selection. Finally, a novel optimal granularity selection strategy with theoretical guarantee is proposed, which is combined with existing attribute reduction methods to design the attribute re-reduction algorithms for generate optimal granularity by reducing the relatively unimportant attributes. Numerical experiments verify the rationality of optimal granularity selection framework and prove the effectiveness of the optimal granularity generated by the attribute re-reduction algorithms.},
  archive      = {J_ISCI},
  author       = {Yue Gao and Degang Chen and Hui Wang},
  doi          = {10.1016/j.ins.2023.119845},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119845},
  shortjournal = {Inf. Sci.},
  title        = {Optimal granularity selection based on algorithm stability with application to attribute reduction in rough set theory},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel time series probabilistic prediction approach based
on the monotone quantile regression neural network. <em>ISCI</em>,
<em>654</em>, 119844. (<a
href="https://doi.org/10.1016/j.ins.2023.119844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantile regression is widely applied in various fields such as economy, energy, meteorological prediction research in recent years since it does not require distribution assumptions, has relatively loose conditions, and can effectively estimate the uncertainty of time series forecasting. In this paper, a monotone quantile regression neural network (MQRNN) framework is constructed for time series quantile forecasting. The proposed approach takes the monotonicity of quantile into consideration and handles the quantile crossing problem by adding the quantile information into the input structure and using the gradient based point-wise loss function. Aiming at the complex characteristics of time series, such as time-varying and asymmetric heavy-tailed features, a new quantile function is utilized to describe the complete conditional distribution information of data. Under this model framework, non-crossing multiple quantiles can be predicted simultaneously. The proposed approach is implemented based on artificial neural networks , and the constructed model is applied to actual data in different fields. The experimental results demonstrate that the proposed method combined with long short-term memory (LSTM) can provide accurate and reliable multi-quantile prediction, and alleviate the problem of quantile crossing.},
  archive      = {J_ISCI},
  author       = {Jianming Hu and Jingwei Tang and Zhi Liu},
  doi          = {10.1016/j.ins.2023.119844},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119844},
  shortjournal = {Inf. Sci.},
  title        = {A novel time series probabilistic prediction approach based on the monotone quantile regression neural network},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust synchronization of coupled logical networks subject
to stochastic function perturbations. <em>ISCI</em>, <em>654</em>,
119843. (<a href="https://doi.org/10.1016/j.ins.2023.119843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article analyzes the robust synchronization of coupled logical networks (LNs) subject to stochastic function perturbations (SFPs). Firstly, by defining a synchronization states set, the robustness of synchronization with probability one (SPO) is divided into two cases. According to these two cases, the rough reachable set and refined reachable set are constructed, based on which, several criteria are derived for the robust SPO of coupled LNs with SFPs. Secondly, with the help of rough reachable set and refined reachable set, several necessary and sufficient conditions are proposed to verify the synchronization in distribution of coupled LNs with SFPs. Finally, the obtained theoretical results are applied to an idealized model of protein-nucleic acid interactions.},
  archive      = {J_ISCI},
  author       = {Xinrong Yang and Haitao Li},
  doi          = {10.1016/j.ins.2023.119843},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119843},
  shortjournal = {Inf. Sci.},
  title        = {Robust synchronization of coupled logical networks subject to stochastic function perturbations},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computable aggregations of random variables. <em>ISCI</em>,
<em>654</em>, 119842. (<a
href="https://doi.org/10.1016/j.ins.2023.119842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aggregation theory is devoted to the fusing of several values into a unique output that summarizes the given information. Typically, the aggregation process is formalized in terms of an increasing mathematical function that maps the input values to the result, fulfilling some boundary conditions. However, this formalization can be too restrictive for some scenarios. In some cases, the inputs can be seen as observations of random variables , the aggregation result being also a random variable. In others, the aggregation process can be identified as a program that performs the aggregation rather than a mathematical function. In this direction, the concepts of aggregation of random variables and computable aggregation have been defined in the literature. This paper is devoted to the definition of computable aggregation of random variables, which are computer programs, not functions, that aggregate random variables, not numbers. Special attention is given to different possible alternatives to modelize random variables and monotonicity. The implementation of some examples is also provided.},
  archive      = {J_ISCI},
  author       = {Juan Baz and Irene Díaz and Luis Garmendia and Daniel Gómez and Luis Magdalena and Susana Montes},
  doi          = {10.1016/j.ins.2023.119842},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119842},
  shortjournal = {Inf. Sci.},
  title        = {Computable aggregations of random variables},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-stage knowledge distillation for sequential
recommendation with interest knowledge. <em>ISCI</em>, <em>654</em>,
119841. (<a href="https://doi.org/10.1016/j.ins.2023.119841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential models based on deep learning are widely used in sequential recommendation task, but the increase of model parameters results in a higher latency in the inference stage, which limits the real-time performance of the model. In order to make the model strike a balance between efficiency and effectiveness, the knowledge distillation technology is adopted to transfer the pre-trained knowledge from the large teacher model to the small student model. We propose a multi-stage knowledge distillation method based on interest knowledge, including interest representation knowledge and interest drift knowledge. In the process of knowledge transfer, expert distillation is designed to transform the knowledge dimension of student model to alleviate the loss of original knowledge information. Specially, curriculum learning is introduced for multi-stage knowledge learning, which further makes the teacher model effectively transfer the knowledge to the student model with limited ability. The proposed method on three real-world datasets including MovieLen-1M, Amazon Game and Steam datasets. The experimental results demonstrate that our method is superior to the other compared distillation method significantly and multi-stage learning makes the student model achieve the knowledge step by step for improvement.},
  archive      = {J_ISCI},
  author       = {Yongping Du and Jinyu Niu and Yuxin Wang and Xingnan Jin},
  doi          = {10.1016/j.ins.2023.119841},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119841},
  shortjournal = {Inf. Sci.},
  title        = {Multi-stage knowledge distillation for sequential recommendation with interest knowledge},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep joint adversarial learning for anomaly detection on
attribute networks. <em>ISCI</em>, <em>654</em>, 119840. (<a
href="https://doi.org/10.1016/j.ins.2023.119840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute network anomaly detection has attracted growing interest in recent years, which aims to separate the points whose behavior is clearly different from others. The complex interactions between the network structure and node attributes result in difficulty in detecting anomalous nodes on attribute networks. To alleviate the above mentioned issue, in this paper, we design a deep joint adversarial learning representation framework (JAANE) for attribute network anomaly detection , by capturing the consistency and complementarity between network structure and node attributes. Specifically, JAANE utilizes a weight-sharing encoder to learn the attribute embedding and structure embedding in a shared latent space. Then, the feature fusion module fuses the learned attribute embedding and structure embedding into the fused node embedding to capture the consistency and complementarity between them. Finally, the fused node embedding is regularized via adversarial learning, and the anomaly nodes outside the regularized hypersphere space can be effectively detected. The experiment results on the real-world datasets indicate that the proposed JAANE performs better than other state-of-the-art, which demonstrates the effectiveness of the proposed method. The source code and data are released in https://haoyfan.github.io/ .},
  archive      = {J_ISCI},
  author       = {Haoyi Fan and Ruidong Wang and Xunhua Huang and Fengbin Zhang and Zuoyong Li and Shimei Su},
  doi          = {10.1016/j.ins.2023.119840},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119840},
  shortjournal = {Inf. Sci.},
  title        = {Deep joint adversarial learning for anomaly detection on attribute networks},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel lightweight decentralized attribute-based signature
scheme for social co-governance. <em>ISCI</em>, <em>654</em>, 119839.
(<a href="https://doi.org/10.1016/j.ins.2023.119839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social co-governance is an effective way to solve public safety incidents such as COVID-19 incident. But the insiders wouldn’t share the firsthand information for fear of cyber-violence. Though most of researches paid attention to the data access control and security, less attention focused on the identity privacy. So, in this work, it constructed a lightweight decentralized attribute-based signature scheme with unconditional full anonymity (LDABS-UFA) scheme to protect user’s identity privacy security. It confuses the user’s private key with fuzzy factors, and prevents user’s privacy in the signature from being disclosed. It outsources some complex computing to cloud servers to reduce the user device performance overhead. The security analysis result shows that the scheme is UFA security, unforgeability and non-collusion. Besides, a social co-governance system based on lightweight blackbox-based traceable decentralized attribute-based signature (LWBT-DABS) scheme is proposed. By generating fingerprints for the data owner in the signature, regulators can monitor the entire system and prevent malicious user from spreading rumors. And it constructs an accountability mechanism to prevent the abuse of supervisory power. The performance analysis shows that the data signature of our scheme size is constant, and the scheme is feasibility and practicability.},
  archive      = {J_ISCI},
  author       = {Qi Tao and Xiaohui Cui and Adnan Iftekhar},
  doi          = {10.1016/j.ins.2023.119839},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119839},
  shortjournal = {Inf. Sci.},
  title        = {A novel lightweight decentralized attribute-based signature scheme for social co-governance},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rethinking data augmentation for adversarial robustness.
<em>ISCI</em>, <em>654</em>, 119838. (<a
href="https://doi.org/10.1016/j.ins.2023.119838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent work has proposed novel data augmentation methods to improve the adversarial robustness of deep neural networks . In this paper, we re-evaluate such methods through the lens of different metrics that characterize the augmented manifold, finding contradictory evidence. Our extensive empirical analysis involving 5 data augmentation methods, all tested with an increasing probability of augmentation, shows that: (i) novel data augmentation methods proposed to improve adversarial robustness only improve it when combined with classical augmentations (like image flipping and rotation), and even worsen adversarial robustness if used in isolation; and (ii) adversarial robustness is significantly affected by the augmentation probability, conversely to what is claimed in recent work. We conclude by discussing how to rethink the development and evaluation of novel data augmentation methods for adversarial robustness. Our open-source code is available at https://github.com/eghbalz/rethink_da_for_ar .},
  archive      = {J_ISCI},
  author       = {Hamid Eghbal-zadeh and Werner Zellinger and Maura Pintor and Kathrin Grosse and Khaled Koutini and Bernhard A. Moser and Battista Biggio and Gerhard Widmer},
  doi          = {10.1016/j.ins.2023.119838},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119838},
  shortjournal = {Inf. Sci.},
  title        = {Rethinking data augmentation for adversarial robustness},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A broad-deep fusion network-based fuzzy emotional intention
inference model for teaching validity evaluation. <em>ISCI</em>,
<em>654</em>, 119837. (<a
href="https://doi.org/10.1016/j.ins.2023.119837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A broad-deep fusion network-based fuzzy emotional inference model with personal information (BDFEI) is proposed for emotional intention understanding in human-robot interaction. It aims to understand students&#39; intentions and evaluate the teaching validity through quantitative analysis in the university teaching scene. Specifically, broad-deep fusion network is carried out for facial emotion and behavior recognition. Then, fuzzy inference with personal information is used to understand the intention. The V-A emotion space is used to quantify students&#39; studying status with originality, by mapping the output of Softmax. Finally, teaching validity is obtained by fuzzy inference. According to the recognition results, the accuracy on bimodal face and body gesture database (FABO) of our proposal is 12.21%, 1.89% and 0.78% higher than those of the sparse autoencoder-based fuzzy deep neural network (FDNNSA), geodesic flow kernel integrated with residual network (ResNet-101+GFK), the hierarchical classification fusion strategy (HCFS), respectively. Through the experiment on the self-built database, the accuracy of intention understanding is 90.48%, and the effectiveness of teaching validity evaluation method is confirmed.},
  archive      = {J_ISCI},
  author       = {Min Li and Luefeng Chen and Min Wu and Kaoru Hirota},
  doi          = {10.1016/j.ins.2023.119837},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119837},
  shortjournal = {Inf. Sci.},
  title        = {A broad-deep fusion network-based fuzzy emotional intention inference model for teaching validity evaluation},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel score function and standard coefficient-based
single-valued neutrosophic MCDM for live streaming sales. <em>ISCI</em>,
<em>654</em>, 119836. (<a
href="https://doi.org/10.1016/j.ins.2023.119836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-valued neutrosophic sets (SVNS) provide a comprehensive approach to express uncertainty in decision scenarios, surpassing the utility of fuzzy sets (FS) and intuitionistic fuzzy sets (IFS). Yet, current SVNS score function concepts stem from FS and IFS construction methods, showing inconsistencies. Thus, we introduce a novel SVNS score function based on inherent uncertainty essence. Additionally, we devise a standard coefficient to gauge SVNS standardization akin to fuzzy sets. Addressing SVNS researchability and limitations in fundamental concepts, especially the score function, we propose an SVNS-based multi-criteria decision-making (MCDM) model. This leverages the new score function and standard coefficient. We demonstrate its effectiveness on two decisions: “software engineer recruitment” with known weights and “investment selection” with unknown weights. Ultimately, we successfully applied the model to the field of live streaming sales to solve the actual MCDM problem. By comparing with existing methods, we affirm the model&#39;s validity and practicality. Compared to prior approaches, the new method exhibits: (1) Enhanced stability and credibility in result values and rankings, promoting robust optimal solutions. (2) Reduced computational steps and workload, enhancing usability and practicality.},
  archive      = {J_ISCI},
  author       = {Fei Wang},
  doi          = {10.1016/j.ins.2023.119836},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119836},
  shortjournal = {Inf. Sci.},
  title        = {Novel score function and standard coefficient-based single-valued neutrosophic MCDM for live streaming sales},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distinguishing latent interaction types from implicit
feedbacks for recommendation. <em>ISCI</em>, <em>654</em>, 119834. (<a
href="https://doi.org/10.1016/j.ins.2023.119834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For privacy considerations, many recommendation algorithms are only based on a kind of implicit feedbacks, where various user behaviors , like view, purchase and etc., are simplified as binary interactions. As side information is assumed not available, these algorithms mainly focus on how to encode users and items via a bipartite graph (viz. the user-item interaction matrix), while ignoring to encode edges for distinguishing the interaction types. In this paper, we argue that implicit feedbacks can be classified into a few user-item relations (viz., latent interaction types) via encoding the edges of a bipartite graph . In particular, we design an edge distinguishment module (EDM) into our neural recommendation model, called R elation- A ware N eural M odel ( RANM ). Based on the latent interaction types, we divide the bipartite graph into a few subgraphs, each consisting of only edges of the same relation and their connected user and item nodes. We propose a Relation-Aware Graph Neural Network (RAGNN) for learning user and item representations. For encoding items, we apply the RAGNN on the relation-aware bipartite graph; While for encoding a user, we first encode several latent interests each on one subgraph and then fuse these interest encodings as the user representation. Experiments on three public datasets validate that our approach of edge classification and representation learning help improving recommendation performance compared with the state-of-the-art competitors. The implementations are available at https://github.com/lulu0913/RAGNN .},
  archive      = {J_ISCI},
  author       = {Lingyun Lu and Bang Wang and Zizhuo Zhang and Shenghao Liu},
  doi          = {10.1016/j.ins.2023.119834},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119834},
  shortjournal = {Inf. Sci.},
  title        = {Distinguishing latent interaction types from implicit feedbacks for recommendation},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DR-GAT: Dynamic routing graph attention network for stock
recommendation. <em>ISCI</em>, <em>654</em>, 119833. (<a
href="https://doi.org/10.1016/j.ins.2023.119833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investors are increasingly interested in using financial technology to guide investment decisions. The phenomenon of “stock linkage” or “leading-lag” is often observed between related stocks on the stock market. Based on this feature of the stock market, complex relationships between stocks influence investment decisions. Existing methods use static prior relational data (e.g., industry relations and Wiki relations) to build corporate relation graph , while learning relational features using the same graph for all stocks. This description and use of corporate relationships ignored the dynamic nature of association relationships in time and space, limiting the ability to learn latent relationships between stocks. To address these issues, we propose a Dynamic Routing Graph Attention Network (DR-GAT) for stock recommendation. We propose a novel similarity measurement method called stock price trend similarity. To track the evolution of intercorporate relationships over time, we dynamically construct relation graph attention networks using prior knowledge and stock price trend similarity. Moreover, a newly designed relation graph router (RGR) can route each stock to an optimal relationship graph based on its volatility. Extensive experiments demonstrate the superiority of our DR-GAT method. It outperforms state-of-the-art methods achieving an average return ratio of 152% and 162% on NASDAQ and NYSE, respectively.},
  archive      = {J_ISCI},
  author       = {Zengyu Lei and Caiming Zhang and Yunyang Xu and Xuemei Li},
  doi          = {10.1016/j.ins.2023.119833},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119833},
  shortjournal = {Inf. Sci.},
  title        = {DR-GAT: Dynamic routing graph attention network for stock recommendation},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). General strong fuzzy solutions of complex fuzzy matrix
equations involving the moore-penrose weak group inverse. <em>ISCI</em>,
<em>654</em>, 119832. (<a
href="https://doi.org/10.1016/j.ins.2023.119832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the fuzzy solutions of the complex fuzzy matrix equation (CFME) C Z ˜ = W ˜ CZ˜=W˜ , in which C is a complex crisp matrix, and W ˜ W˜ is a complex fuzzy matrix. The purpose of this paper is three-fold. Firstly, the necessary and sufficient conditions for the existence of strong fuzzy solutions to the CFME are obtained using the MPWG inverse of the coefficient matrix . Secondly, we obtain a necessary and sufficient condition for the existence of S † , W G ≥ 0 S†,WG≥0 ( S † , W G S†,WG is called the Moore-Penrose weak group inverse of the coefficient matrix S ) in order to obtain a strong fuzzy matrix solution of CFME. Moreover, general strong fuzzy solutions of the CFME are derived and an algorithm for obtaining general strong fuzzy solutions of CFME by the MPWG inverse is also established. Finally, some numerical examples are given to illustrate the main results.},
  archive      = {J_ISCI},
  author       = {Jinzhao Wu and Hongjie Jiang and Mengyu He and Xiaoji Liu},
  doi          = {10.1016/j.ins.2023.119832},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119832},
  shortjournal = {Inf. Sci.},
  title        = {General strong fuzzy solutions of complex fuzzy matrix equations involving the moore-penrose weak group inverse},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-dimensional stereo face reconstruction for
psychological assistant diagnosis in medical meta-universe.
<em>ISCI</em>, <em>654</em>, 119831. (<a
href="https://doi.org/10.1016/j.ins.2023.119831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual reality/augmented reality (VR/AR) technology is very important for meta -cosmic medicine. It is the technical link between the material world and the virtual world. The realization of face-to-face psychological diagnosis with three-dimensional holography is a difficult problem in meta -cosmic medicine. Because psychological diagnosis needs to observe rapidly changing microexpressions, it is difficult to capture them. At present, most of the research is based on two dimensions, which cannot meet the real-time reconstruction requirements of meta -universe medicine. To solve these problems, this paper introduces a 3D facial reconstruction algorithm composed of multiresolution feature fusion and attention mechanisms. It can be used for psychological assistant diagnosis of meta -cosmic medicine. First, face alignment and 3D coordinate construction of the feature point cloud are carried out through a 3D convolution coding network. After that, multiresolution cost convolution is used to extract and match the color, facial bones, and depth features of texture images. Finally, the transposed three-dimensional convolution is used to decode and output. To achieve the real-time reconstruction of psychotherapy, we designed a three-dimensional channel attention mechanism module for acceleration. This makes this method suitable for the construction of virtual doctors and virtual patients in the virtual platform of the medical universe of psychological medicine and can also complete the construction of the virtual teaching platform of the medical universe.},
  archive      = {J_ISCI},
  author       = {Weiyi Kong and Zhisheng You and Shiyang Lyu and Xuebin Lv},
  doi          = {10.1016/j.ins.2023.119831},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119831},
  shortjournal = {Inf. Sci.},
  title        = {Multi-dimensional stereo face reconstruction for psychological assistant diagnosis in medical meta-universe},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Secure and efficient multi-key aggregation for federated
learning. <em>ISCI</em>, <em>654</em>, 119830. (<a
href="https://doi.org/10.1016/j.ins.2023.119830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a distributed machine learning framework that aims to provide privacy for local datasets while learning a global machine learning model. However, the updates exchanged in FL may indirectly reveal information about the local training datasets. To protect the confidentiality of updates, various solutions using cryptographic schemes such as secret sharing, differential privacy , and homomorphic encryption have been developed. The solutions using secret sharing often have high communication costs, while those using differential privacy require a trade-off between accuracy and privacy. Homomorphic encryption has been used to address these challenges to reduce communication costs and provide provable security . However, existing solutions based on homomorphic encryption require clients to use the same public-private key pair, which may lead to local updates disclosure. To address the existing challenges, we propose a secure and efficient multi-key aggregation protocol (MKAgg) that utilizes homomorphic encryption. The protocol allows clients to drop out at any point during the process. We construct MKAgg based on a two-server model and adopt a proxy re-encryption scheme with additively homomorphic properties to implement secure and efficient ciphertext transformation and calculation. We provide security proof to demonstrate that our MKAgg protocol meets the required security standards. Furthermore, we perform an efficiency analysis of MKAgg and evaluate its performance on various datasets. The results affirm that MKAgg is both effective and efficient for aggregation in the multi-key setting. We then apply MKAgg in FL and develop a multi-key privacy-preserving neural network scheme called MKPNFL. We analyze the security of MKPNFL and conduct tests using real-world datasets. The results demonstrate that MKPNFL is secure and practical for real-world applications.},
  archive      = {J_ISCI},
  author       = {Yanling Li and Junzuo Lai and Rong Zhang and Meng Sun},
  doi          = {10.1016/j.ins.2023.119830},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119830},
  shortjournal = {Inf. Sci.},
  title        = {Secure and efficient multi-key aggregation for federated learning},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Building consensus in multi-attribute group decision making
under a prospect theory-driven feedback adjustment mechanism.
<em>ISCI</em>, <em>654</em>, 119829. (<a
href="https://doi.org/10.1016/j.ins.2023.119829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reports a prospect theory-based consensus model in multi-attribute group decision making. First, the attribute expectations are regarded as the reference points of decision makers in prospect theory. The attribute values are transformed into the prospect values based on the value function . Then a new consensus measure is proposed to quantify the consensus level. A feedback adjustment mechanism is constructed to improve the consensus level under prospect theory. The convergence of the proposed algorithm is proved. It is found that the proposed mechanism can lessen the work burden of DMs as compared with the existing methods. Finally, the weights of attributes are computed by constructing an optimization model that maximizes the sum of prospect values. Case study and comparative analysis are offered to illustrate the novelty and advantage of the proposed model. The obtained results reveal that an increasing loss aversion enhances the difficulty of reaching consensus.},
  archive      = {J_ISCI},
  author       = {Fang Liu and Shi-Shan Wang and Xin-Yi Zhang},
  doi          = {10.1016/j.ins.2023.119829},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119829},
  shortjournal = {Inf. Sci.},
  title        = {Building consensus in multi-attribute group decision making under a prospect theory-driven feedback adjustment mechanism},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic budget allocation for sparsely labeled drifting data
streams. <em>ISCI</em>, <em>654</em>, 119821. (<a
href="https://doi.org/10.1016/j.ins.2023.119821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from non-stationary data streams is inherently challenging due to their evolving nature and concept drift. Furthermore, the assumption that all instances come labeled is often impractical in real-world applications. Many strategies have been proposed to tackle learning from sparsely labeled data streams. However, they typically rely on fixed labeling budgets, which can be a limitation in the context of drifting data streams. In this study, we introduce a novel active learning strategy that dynamically manages the labeling budget to optimize its utilization and adapt promptly to concept drift. Our approach continuously monitors the data stream for concept drift, and upon detecting such drift, it dynamically increases the maximum labeling budget for a predefined time window. This adjustment provides the classifier with more flexibility to adapt to the new concept. We conducted experiments using 7 synthetic data generators encompassing various drifting scenarios and 7 real-world data streams with different labeling budgets. Our results demonstrate that offering a flexible budget to the classifier can significantly enhance performance compared to merely increasing a fixed budget. Notably, our strategy outperformed state-of-the-art active learning strategies, all while maintaining a comparable or lower number of labeled instances. Experiments are available at https://github.com/gabrieljaguiar/DBAL .},
  archive      = {J_ISCI},
  author       = {Gabriel J. Aguiar and Alberto Cano},
  doi          = {10.1016/j.ins.2023.119821},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119821},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic budget allocation for sparsely labeled drifting data streams},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AQND: An asymmetric quorum-based neighbor discovery protocol
for reducing delay in sensor based systems. <em>ISCI</em>, <em>654</em>,
119820. (<a href="https://doi.org/10.1016/j.ins.2023.119820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighbor discovery is basic for Wireless Sensor Networks (WSNs) communication, which is the key to network performance. Since sensor nodes were powered by battery , sleep/active rotation was widely adopted to save energy, which led to the neighbor discovery problem. Many timely neighbor discovery protocols are proposed for wake-up scheduling to expedite the discovery and data routing while saving energy . In this paper, an asymmetric quorum-based neighbor discovery (AQND) protocol is proposed to reduce the delay of neighbor discovery and data routing while improving the energy utilization and maintaining a high lifetime. According to our theoretical analysis, the proposed AQND protocol outperforms previous strategies in main performance indicators such as reducing the average relative error of duty cycle, the maximum neighbor discovery delay and the end-to-end discovery delay while improving the energy utilization ratio. In addition, using the proposed AQND protocol to improve the above network performances doesn’t reduce lifetime. Maintaining the end-to-end delay consistent with the previous strategies, the lifetime of network can be improved.},
  archive      = {J_ISCI},
  author       = {Ziqing Xia and Zhangyang Gao and Anfeng Liu and Neal N. Xiong},
  doi          = {10.1016/j.ins.2023.119820},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119820},
  shortjournal = {Inf. Sci.},
  title        = {AQND: An asymmetric quorum-based neighbor discovery protocol for reducing delay in sensor based systems},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fractional order sliding mode control for an
omni-directional mobile robot based on self-organizing interval type-2
fuzzy neural network. <em>ISCI</em>, <em>654</em>, 119819. (<a
href="https://doi.org/10.1016/j.ins.2023.119819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Four-wheeled omnidirectional mobile robots (FM-OMR) are widely used in various fields due to their excellent steering ability and adaptability . As application scenarios expand, higher requirements are placed on their trajectory tracking capabilities. FM-OMR is highly complex and difficult to model accurately, and the system contains uncertainties. Therefore, achieving accurate trajectory tracking in the presence of system uncertainty is a pressing problem. Traditional control methods struggle to accurately estimate uncertainty, and existing controllers often rely on model parameters, resulting in poor transferability. To address this issue, this paper proposes a new control method based on an online self-organizing interval type II fuzzy neural network (SOIT2FNNFSMC). This method employs an online self-organizing algorithm to dynamically compensate for uncertainty, providing greater flexibility and accuracy compared to traditional approximation networks in terms of network construction and approximation performance. A new combined reaching law is proposed based on the characteristics of traditional reaching laws, resulting in improved chattering reduction. Additionally, fractional calculus is introduced to enhance the dynamic characteristics of the controller. Simulation and experimental results demonstrate the effectiveness of this method in achieving precise trajectory tracking while handling uncertainty and not relying on model parameter features. The self-organizing algorithm proposed in this method also provides a reference for the application of SOIT2FNN in FM-OMR.},
  archive      = {J_ISCI},
  author       = {Tao Zhao and Peng Qin and Songyi Dian and Bin Guo},
  doi          = {10.1016/j.ins.2023.119819},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119819},
  shortjournal = {Inf. Sci.},
  title        = {Fractional order sliding mode control for an omni-directional mobile robot based on self-organizing interval type-2 fuzzy neural network},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gas system scheduling strategy for steel metallurgical
process based on multi-objective differential evolution. <em>ISCI</em>,
<em>654</em>, 119817. (<a
href="https://doi.org/10.1016/j.ins.2023.119817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective gas system scheduling is vital for ensuring the safe operation and energy efficiency of steel production. However, the dynamic and cyclical nature of gas generation and consumption leads to fluctuations in gas network pressure and gas holder levels. To address this issue, this paper proposes a novel strategy for gas system scheduling based on multi-objective differential evolution. The originality lies in fully considering the workload of operators, effectively reducing the workload while ensuring gas network stability. We analyze the composition of the gas system and design a scheduling scheme. Subsequently, a novel gas holder level model based on mechanism analysis is established, which calculates the gas holder level by analyzing the volume and pressure of the gas. Then, a gas system scheduling model with a new objective function based on a multi-objective differential evolution algorithm is provided. By comparing with the two recent methods, this method reduced the number of adjustments by 13.9% and 9.75%, respectively, effectively reducing the workload while ensuring gas system stability . Through statistical analysis for eight consecutive months, the results show that this method can reduce the gas emission rate from 1.34% to 0.88%, demonstrating its correctness and effectiveness.},
  archive      = {J_ISCI},
  author       = {Lili Feng and Jun Peng and Zhaojun Huang},
  doi          = {10.1016/j.ins.2023.119817},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119817},
  shortjournal = {Inf. Sci.},
  title        = {Gas system scheduling strategy for steel metallurgical process based on multi-objective differential evolution},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proximity-based density description with regularized
reconstruction algorithm for anomaly detection. <em>ISCI</em>,
<em>654</em>, 119816. (<a
href="https://doi.org/10.1016/j.ins.2023.119816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses unsupervised anomaly detection using one-class classification, which constructs a decision boundary to determine if a new instance belongs to the target class. Existing one-class classification methods often fail in real-world scenarios due to their sensitivity to noise and inability to handle complex structures. We propose a proximity-based density description with a regularized reconstruction algorithm to overcome these limitations. Our method defines density-descriptive coefficients to reconstruct initial density and derives optimal coefficients by minimizing reconstruction error subject to sparsity and smoothness constraints. The sparsity constraint reduces noise effects, while the smoothness constraint encourages a flexible decision boundary. We evaluate our algorithm on benchmark datasets and compare it to existing methods, demonstrating superior performance.},
  archive      = {J_ISCI},
  author       = {Jaehong Yu and Hyungrok Do},
  doi          = {10.1016/j.ins.2023.119816},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119816},
  shortjournal = {Inf. Sci.},
  title        = {Proximity-based density description with regularized reconstruction algorithm for anomaly detection},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph neural networks with deep mutual learning for
designing multi-modal recommendation systems. <em>ISCI</em>,
<em>654</em>, 119815. (<a
href="https://doi.org/10.1016/j.ins.2023.119815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation services play a pivotal role in financial decision-making and multimedia content services, as they suggest investment operations and personalized items to users, typically characterized by multi-modal features such as visual, textual, and acoustic attributes. Graph Neural Networks (GNNs), demonstrating the immense potential for graph representation learning and recommendation systems, are capable of learning user/item embeddings by taking into account the graph topological structure and the multi-modal node features. Yet, a substantial number of multi-modal recommendation studies have seemingly ignored the inherent bias among different modalities during feature fusion , consequently leading to sub-optimal embeddings for items with multi-modal features. To mitigate this issue, we propose a novel multi-modal recommendation framework that integrates GNNs with deep mutual learning techniques, termed GNNMR. GNNMR uses the mutual knowledge distillation technique to collaboratively train multiple uni-modal bipartite user-item graphs. Each GNN is trained specifically on the uni-modal user-item bipartite graph , which is separated from the original multi-modal user-item bipartite graph , to generate uni-modal embeddings. These uni-modal embeddings then act as mutual supervision signals, allowing the model to uncover and synchronize the latent semantic relationships among different modalities. Subsequently, the model can conduct inference in an ensemble manner, leveraging uni-modal embeddings from diverse modalities. Experimental results on two real-world datasets demonstrate that the proposed GNNMR outperforms other multi-modal recommendation methods in the Top-K recommendation task.},
  archive      = {J_ISCI},
  author       = {Jianing Li and Chaoqun Yang and Guanhua Ye and Quoc Viet Hung Nguyen},
  doi          = {10.1016/j.ins.2023.119815},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119815},
  shortjournal = {Inf. Sci.},
  title        = {Graph neural networks with deep mutual learning for designing multi-modal recommendation systems},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonlinear directed acyclic graph estimation based on the
kernel partial correlation coefficient. <em>ISCI</em>, <em>654</em>,
119814. (<a href="https://doi.org/10.1016/j.ins.2023.119814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directed acyclic graphs (DAGs) are powerful tools for detecting causality among variables and thus, they have attracted increasing interest in recent years. In most previous studies, DAGs were estimated under the assumption of linearity between variables; however, this assumption is not usually true in real-world applications. Therefore, developing DAG estimation methods for nonlinear scenarios is of great interest. In this work, we propose a DAG estimation method based on the kernel partial correlation (KPC) coefficient to identify nonlinear interactions among variables. The method consists of three steps: neighborhood selection, skeleton estimation and direction detection. While all the steps are grounded on the KPC coefficient, we develop a threshold-based criterion to address the falsely discovered edges in the skeleton estimation step and utilize the asymmetric property of the KPC coefficient in the direction detection step. Numerical simulations demonstrate the advantages of the proposed method over various competing methods. Finally, we apply the proposed method to construct networks in three real-world structural equation modeling examples in the social sciences and on one DNA binding site dataset to demonstrate its effectiveness.},
  archive      = {J_ISCI},
  author       = {Qiying Wu and Huiwen Wang and Shan Lu},
  doi          = {10.1016/j.ins.2023.119814},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119814},
  shortjournal = {Inf. Sci.},
  title        = {Nonlinear directed acyclic graph estimation based on the kernel partial correlation coefficient},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An effective hybrid evolutionary algorithm for the set
orienteering problem. <em>ISCI</em>, <em>654</em>, 119813. (<a
href="https://doi.org/10.1016/j.ins.2023.119813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Set Orienteering Problem (SOP) is a variant of the popular Orienteering Problem (OP) arising from a number of real-life applications. The aim is to find a tour across a subset of customers, while maximizing the collected profit within a given travel time limit. In SOP, vertices (customers) are partitioned into clusters, where a profit is associated to each cluster. The profit of a cluster is collected only if at least one vertex belonging to the cluster is contained in the tour. For this NP-hard problem, we present a highly effective hybrid evolutionary algorithm that integrates a cluster-based crossover operator , a randomized mutation operator to generate multiple distinct promising offspring solutions, and a two-phase local refinement procedure that explores both feasible and infeasible solutions in search of high-quality local optima . Extensive experiments on 192 large benchmark instances show that the proposed algorithm significantly outperforms all the existing approaches from the SOP literature. In particular, it reports improved best-known solutions (new lower bounds) for 54 instances, while matching the existing best-known result for 133 instances. We further investigate the contribution of the key algorithmic elements to the success of the proposed approach.},
  archive      = {J_ISCI},
  author       = {Yongliang Lu and Una Benlic and Qinghua Wu},
  doi          = {10.1016/j.ins.2023.119813},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119813},
  shortjournal = {Inf. Sci.},
  title        = {An effective hybrid evolutionary algorithm for the set orienteering problem},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributionally robust joint chance-constrained
programming: Wasserstein metric and second-order moment constraints.
<em>ISCI</em>, <em>654</em>, 119812. (<a
href="https://doi.org/10.1016/j.ins.2023.119812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new approximate linear reformulation for distributionally robust joint chance programming with Wasserstein ambiguity sets and an efficient solution approach based on Benders decomposition . To provide a convex approximation to the distributionally robust chance constraint, we use the worst-case conditional value-at-risk constrained program. In addition, we derive an approach for distributionally robust joint chance programming with a hybrid ambiguity set that combines a Wasserstein ball with second-order moment constraints. This approach, which allows injecting domain knowledge into a Wasserstein ambiguity set and thus allows for less conservative solutions, has not been considered before. We propose two formulations of this problem, namely a semidefinite programming and a computationally favorable second-order cone programming formulation. The models and algorithms proposed in this paper are evaluated through computational experiments demonstrating their computational efficiency. In particular, the Benders decomposition algorithm is shown to be more than an order of magnitude faster than a standard solver allowing for the solution of large instances in a relatively short time.},
  archive      = {J_ISCI},
  author       = {Rashed Khanjani Shiraz and Zohreh Hosseini Nodeh and Ali Babapour-Azar and Michael Römer and Panos M. Pardalos},
  doi          = {10.1016/j.ins.2023.119812},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119812},
  shortjournal = {Inf. Sci.},
  title        = {Distributionally robust joint chance-constrained programming: Wasserstein metric and second-order moment constraints},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of a fuzzy likert scales to measure variables in
social sciences. <em>ISCI</em>, <em>654</em>, 119792. (<a
href="https://doi.org/10.1016/j.ins.2023.119792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Likert scale (LS) has been widely used to measure latent variables in the social sciences. Likert scales, with many advantages, exhibit some limitations and disadvantages, related mainly to processing ordinal data in interval scales and close-ended forced-choice questionnaires, which leads to the loss and distortion of information during the measurement process. This study describes how to develop and apply a fuzzy logic-based survey instrument to measure latent variables in social science. First, the survey participant chooses the agreement level depending on their opinion, assigns membership degree µ in the range − 1.0, and then assigns a 1-µ degree to the two (left and right) neighbouring levels. Setting a partial agreement degree instead of a fixed one reduces the loss and information distortion in the data-collection process. The model developed in this way allows converting any commonly used LS into a fuzzy Likert scale (FLS).},
  archive      = {J_ISCI},
  author       = {Konul Memmedova and Banu Ertuna},
  doi          = {10.1016/j.ins.2023.119792},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119792},
  shortjournal = {Inf. Sci.},
  title        = {Development of a fuzzy likert scales to measure variables in social sciences},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonlinear learning method for local causal structures.
<em>ISCI</em>, <em>654</em>, 119789. (<a
href="https://doi.org/10.1016/j.ins.2023.119789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the proliferation of causal learning techniques, aimed at extracting the abundant causal relationships embedded within observational data . In many scenarios, our primary focus lies in predicting a single target variable. In such cases, it becomes both inefficient and unnecessary to learn an entire causal network through advanced global learning methods. To address this challenge, the concept of local causal learning has been introduced to identify the direct causes and effects of a target variable of interest. However, current algorithms exhibit limitations stemming from their reliance on conditional independence tests, which only consider the linear and pairwise relationships but ignore the ubiquitous nonlinear and multivariate causality, making them lose efficacy in practical scenarios. This paper takes significant strides toward facilitating the real-world applications for local causal learning. To identify the nonlinear relations, this paper discovers the Markov boundary (MB) through calculating the minimal conditional covariance operator in reproducing kernel Hilbert space . This approach establishes a theoretical equivalence between the solution and MB. Subsequently, a nonlinear scoring mechanism for structure learning is employed based on the selected subset, yielding the optimal local causal structure . A series of extensive experiments serves to underscore the superiority of the proposed method.},
  archive      = {J_ISCI},
  author       = {Xingyu Wu and Yan Zhong and Zhaolong Ling and Jie Yang and Li Li and Weiguo Sheng and Bingbing Jiang},
  doi          = {10.1016/j.ins.2023.119789},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119789},
  shortjournal = {Inf. Sci.},
  title        = {Nonlinear learning method for local causal structures},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-stage robust reversible watermarking using polar
harmonic transform for high robustness and capacity. <em>ISCI</em>,
<em>654</em>, 119786. (<a
href="https://doi.org/10.1016/j.ins.2023.119786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing the robust reversible watermarking (RRW) with high robustness and capacity while maintaining invisibility and reversibility is a challenging problem. To alleviate this problem, we present a two-stage RRW scheme using the polar harmonic transform (PHT). In the first stage, it selects robust PHT moments for robust watermarking, develops an adaptive normalization strategy, and constructs a robust watermark embedding method. Specifically, the PHT moments with high robustness are first chosen via experimental simulations. The adaptive normalization strategy is then developed to adjust the robust watermark&#39;s embedding strength for the selected moments, aiming at achieving higher robustness. By adjusting quantized errors to integers, the standard distortion-compensated quantization index modulation (DC-QIM) is optimized. And the optimized DC-QIM for embedding robust watermark facilitates decreasing the number of bits of quantized errors representation and thus increasing the embedding capacity. In the second stage, the reversible watermarking is conducted to achieve reversibility in the absence of attacks. That is, distortions caused by the robust watermark embedding are inserted by a reversible watermarking technique . The proposed scheme performs better than state-of-the-arts in terms of bit error rate (BER) performance, according to extensive experimental results. Our code is available at https://github.com/yichao-tang/PHT-RRW .},
  archive      = {J_ISCI},
  author       = {Yichao Tang and Kangshun Li and Chuntao Wang and Shan Bian and Qiong Huang},
  doi          = {10.1016/j.ins.2023.119786},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119786},
  shortjournal = {Inf. Sci.},
  title        = {A two-stage robust reversible watermarking using polar harmonic transform for high robustness and capacity},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust explanations for graph neural network with neuron
explanation component. <em>ISCI</em>, <em>654</em>, 119785. (<a
href="https://doi.org/10.1016/j.ins.2023.119785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have been successfully applied to a variety of graph-structure analysis tasks. Besides their outstanding performance, the explanation for GNNs&#39; predictions is also an inextricable problem, which hinders trust in GNNs under practical scenarios. Consequently, great efforts have been made for interpreters of GNNs to understand their behavior. However, the existing works are still suffering two main problems: (i) explanation-shifting in normal explanation - the explanations provided by the interpreters are insufficient to precisely explain the behavior of the GNNs; (ii) gullibility failure in adversarial detection - the interpreters are easily bypassed by well-designed adversarial perturbations, resulting in the omission of anomalies. To address these issues, we propose a robust interpreter for GNN, named Neuron Explanation Component (NEC), from the perspective of the model neuron activation pattern . It measures the difference in GNNs&#39; neuron path distribution between subgraphs and the original graph to generate explanations for the model&#39;s prediction. NEC outperforms previous works in explanation accuracy, robustness against adversarial attacks and transferability among different GNN&#39;s interpreters. Extensive evaluations are conducted on 4 benchmarks, 6 interpreters and 2 scenarios (i.e., normal explanation and adversarial detection). Significant improvements in explanation ability and adversarial detection performance demonstrate NEC&#39;s superior performance.},
  archive      = {J_ISCI},
  author       = {Jinyin Chen and Guohan Huang and Haibin Zheng and Hang Du and Jian Zhang},
  doi          = {10.1016/j.ins.2023.119785},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119785},
  shortjournal = {Inf. Sci.},
  title        = {Robust explanations for graph neural network with neuron explanation component},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Secure internet of medical things (IoMT) based on ECMQV-MAC
authentication protocol and EKMC-SCP blockchain networking.
<em>ISCI</em>, <em>654</em>, 119783. (<a
href="https://doi.org/10.1016/j.ins.2023.119783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Medical Things (IoMT) is a collection of healthcare technologies (medical equipment, software applications, and services) that allows doctors, care providers, and medical test centers to store and exchange health data electronically. However, protecting data privacy via IoMT transmission is a difficult problem. To preserve privacy, blockchain integrated with IoMT enables resilience against a variety of attacks. Blockchain accomplishes peer-to-peer data sharing and stops the majority of the attackers. However, adopting blockchain for Healthcare applications is a prominent challenge due to data privacy issues such as illegal authentication, Byzantine Problems, majority attacks, high computing power, and the enormous storage required to compute healthcare data. Blockchain restrictions in the IoMT sector are solved using the proposed encrypted K-means clustering-based stellar consensus protocol (EKMC-SCP) blockchain networking method. The proposed framework performs mutual user authentication based on the elliptic curve Menezes–Qu–Vanstone-based message authentication code (ECMQV-MAC) protocol under a secure data storage using Deltoid curve-based Pallier cryptosystem (DC-PC) and a key generation mechanism using the Dixon’s method-based Blum–Goldwasser cryptosystem, (DM-BGC). The protocol provides a legal authentication for users to access the blockchain networking (BCN) and avoids large data storage in BC. Furthermore, key generation method makes the privacy of the data more robust against certain internal and external attacks. Finally, a legal user can upload healthcare data in BC, and secure data transfer is performed using EKMC-SCP in the BCN. The experimental results show that the developed framework obtains better throughput and PDR value and reduces the privacy leakages and the time overhead to generating new blocks compared to those of existing state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Qinyong Lin and Xiaorong Li and Ken Cai and Mohan Prakash and D. Paulraj},
  doi          = {10.1016/j.ins.2023.119783},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119783},
  shortjournal = {Inf. Sci.},
  title        = {Secure internet of medical things (IoMT) based on ECMQV-MAC authentication protocol and EKMC-SCP blockchain networking},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). To what extent evolutionary algorithms can benefit from a
longer search? <em>ISCI</em>, <em>654</em>, 119766. (<a
href="https://doi.org/10.1016/j.ins.2023.119766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many comparison papers Evolutionary Algorithms are stopped after a pre-defined number of function calls, which is a code-independent measure of computational time . This number of function calls is either defined by the inventors of particular benchmark problems, or set subjectively by the user for the specific problem. The question how much improvement could be achieved by Evolutionary Algorithms if they were given much more time is surprisingly rarely asked. In the present study we analyze improvements obtained by thirty Evolutionary Algorithms on four different benchmark sets, including one composed of 22 real-world problems, when the allowed number of function calls is extended ten times with respect to the values defined in the comparison criteria for the specific benchmark sets. We analyze how the prolonged search would affect the ranking of algorithms, how much improvement could be obtained by Evolutionary Algorithms in general, on what kind of problems the improvement will be achieved, and which type of algorithms would benefit most from such an extended search. We show that the improvements obtained in prolonged search are higher for real-world problems than for mathematical functions , and such improvements are mainly achieved by similar kinds of adaptive algorithms proposed relatively recently. Many metaheuristics fail to benefit from the extended search on most benchmark problems, or benefit only marginally.},
  archive      = {J_ISCI},
  author       = {Adam P. Piotrowski and Jaroslaw J. Napiorkowski and Agnieszka E. Piotrowska},
  doi          = {10.1016/j.ins.2023.119766},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119766},
  shortjournal = {Inf. Sci.},
  title        = {To what extent evolutionary algorithms can benefit from a longer search?},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Perceptual loss guided generative adversarial network for
saliency detection. <em>ISCI</em>, <em>654</em>, 119625. (<a
href="https://doi.org/10.1016/j.ins.2023.119625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we introduce a novel approach for saliency detection through the utilization of a generative adversarial network guided by perceptual loss. Achieving effective saliency detection through deep learning entails intricate challenges influenced by a multitude of factors, with the choice of loss function playing a pivotal role . Previous studies usually formulate loss functions based on pixel-level distances between predicted and ground-truth saliency maps. However, these formulations don’t explicitly exploit the perceptual attributes of objects, such as their shapes and textures, which serve as critical indicators of saliency. To tackle this deficiency, we propose an innovative loss function that capitalizes on perceptual features derived from the saliency map. Our approach has been rigorously evaluated on six benchmark datasets, demonstrating competitive performance when compared against the forefront methods in terms of both Mean Absolute Error (MAE) and F-measure. Remarkably, our experiments reveal consistent outcomes when assessing the perceptual loss using either grayscale saliency maps or saliency-masked colour images . This observation underscores the significance of shape information in shaping the perceptual saliency cues. The code is available at https://github.com/XiaoxuCai/PerGAN .},
  archive      = {J_ISCI},
  author       = {Xiaoxu Cai and Gaige Wang and Jianwen Lou and Muwei Jian and Junyu Dong and Rung-Ching Chen and Brett Stevens and Hui Yu},
  doi          = {10.1016/j.ins.2023.119625},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119625},
  shortjournal = {Inf. Sci.},
  title        = {Perceptual loss guided generative adversarial network for saliency detection},
  volume       = {654},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Color image enhancement technique based on interval-valued
intuitionistic fuzzy set. <em>ISCI</em>, <em>653</em>, 119811. (<a
href="https://doi.org/10.1016/j.ins.2023.119811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new interval-valued intuitionistic fuzzy-based algorithm is proposed to enhance low-light images. In this proposed algorithm, the low-light image is first changed to the fuzzy image by normal fuzzification . Then the above is converted to an intuitionistic fuzzy image and further to the interval-valued intuitionistic fuzzy image. After applying contrast limited adaptive histogram equalization , we derive the required image. In the experimental part, the proposed algorithm is compared with other existing algorithms including histogram equalization, contrast limited adaptive histogram equalization, histogram specification, dehazing, fractional order image enhancement, intuitionistic fuzzy, and interval-valued intuitionistic fuzzy. In terms of overall visual quality and performance metrics, the results showed that the proposed technique surpasses other current methods including entropy, absolute mean brightness error, and contrast improvement index.},
  archive      = {J_ISCI},
  author       = {J. Reegan Jebadass and P. Balasubramaniam},
  doi          = {10.1016/j.ins.2023.119811},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119811},
  shortjournal = {Inf. Sci.},
  title        = {Color image enhancement technique based on interval-valued intuitionistic fuzzy set},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid watermarking algorithm for medical images based on
digital transformation and MobileNetV2. <em>ISCI</em>, <em>653</em>,
119810. (<a href="https://doi.org/10.1016/j.ins.2023.119810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current study presents a new methodology for zero watermarking that relies on the discrete wavelet transform (DWT) and an improved MobileNetV2 convolutional neural network , along with the discrete cosine transform (DCT). This model is intended to overcome the issue of algorithm robustness in encrypted medical image watermarking . The proposed technique targets medical images inside the area of encryption and offers a unique watermarking approach to overcome the issues above. The coefficients acquired from the fully linked network layer are converted using DWT and DCT to create the medical image&#39;s feature vector. Second, MobileNetV2 is initially fed the medical image; this network has been prepared by adjusting parameters such as the convolution kernels&#39; size and the convolution modules&#39; typical architecture. Finally, the encryption of watermarks is achieved through the utilization of the logistic map system and hash function , whereby an independent party securely stores the requisite keys. The integration of a zero-watermark involves the execution of logical operations on both the encrypted watermarks and the attributes of the source image. The results of the experiment indicate that the algorithm can effectively differentiate encrypted medical images and recover the initial data from encrypted watermarked material despite conventional and geometric attacks . Compared to alternative algorithms, their superior resilience and invisibility are noteworthy.},
  archive      = {J_ISCI},
  author       = {Saqib Ali Nawaz and Jingbing Li and Uzair Aslam Bhatti and Muhammad Usman Shoukat and Dekai Li and Muhammad Ahmad Raza},
  doi          = {10.1016/j.ins.2023.119810},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119810},
  shortjournal = {Inf. Sci.},
  title        = {Hybrid watermarking algorithm for medical images based on digital transformation and MobileNetV2},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy ZE-numbers framework in group decision-making using
the BCM and CoCoSo to address sustainable urban transportation.
<em>ISCI</em>, <em>653</em>, 119809. (<a
href="https://doi.org/10.1016/j.ins.2023.119809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban transportation plays a crucial role in cities that host sports events. Mexico City, as one of the World Cup 2026 hosts, is one of the world&#39;s largest and most populous cities, with a population of over 22 million people. This city faces several challenges related to urban transportation. The purpose of this study is to develop a novel group decision-making framework for evaluating six sustainable alternatives for the management of urban transportation crises. Our proposed group decision framework develops the Base Criterion Method (BCM) and Combined Compromise Solution (CoCoSo) under the fuzzy ZE-numbers for the first time in the literature to obtain reliable decisions. Based on the opinions of decision-makers and expert votes on those opinions, the proposed approach offers a unique feature in decision sciences in that the reliability of decisions can be increased in two stages. Also, sensitive analyses were executed for each of the urban transportation alternatives based on the different states of the criteria groups. According to the findings, the optimum plan should be an investment in the Metro and electric Minibusses development to manage the urban transportation crisis in Mexico City. Also, findings show that applying the fuzzy ZE-numbers leads to more accurate and reliable results.},
  archive      = {J_ISCI},
  author       = {Gholamreza Haseli and Shabnam Rahnamay Bonab and Mostafa Hajiaghaei-Keshteli and Saeid Jafarzadeh Ghoushchi and Muhammet Deveci},
  doi          = {10.1016/j.ins.2023.119809},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119809},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy ZE-numbers framework in group decision-making using the BCM and CoCoSo to address sustainable urban transportation},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). High-dimensional m-estimation for byzantine-robust
decentralized learning. <em>ISCI</em>, <em>653</em>, 119808. (<a
href="https://doi.org/10.1016/j.ins.2023.119808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on robust sparse M -estimation over decentralized networks in the presence of Byzantine attacks. In particular, a decentralized network is modeled as an undirected graph without a central node, while a small fraction of nodes usually behave arbitrarily and send erroneous information due to system breakdowns, cyber attacks and so on. To address the Byzantine issue, some pre-determined robust aggregation rules are applied. Moreover, the gradient tracking and proximal algorithm are combined to ensure convergence and sparsity simultaneously. Theoretically, our proposed algorithms are provably robust against Byzantine attacks and achieve linear convergence rates. The finite-sample performance is studied through numerical experiments under various settings and an application to Communities and Crime Data is also presented.},
  archive      = {J_ISCI},
  author       = {Xudong Zhang and Lei Wang},
  doi          = {10.1016/j.ins.2023.119808},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119808},
  shortjournal = {Inf. Sci.},
  title        = {High-dimensional M-estimation for byzantine-robust decentralized learning},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A group consensus model with prospect theory under
probabilistic linguistic term sets. <em>ISCI</em>, <em>653</em>, 119800.
(<a href="https://doi.org/10.1016/j.ins.2023.119800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenges encountered in the realm of multi-attribute group decision-making (MAGDM) involving probabilistic linguistic term sets (PLTSs) have garnered substantial attention. Within the PLTS context, this study introduces a consensus reaching process (CRP) that iteratively refines the weights assigned to decision-makers (DMs) by leveraging the principles of prospect theory (PT). The primary goal of this iterative weight adjustment process is to enhance the overall decision-making procedure when dealing with PLTSs. To circumvent any data loss during transformation and compute the prospect values of PLTSs directly, a novel transformation formula is developed. Acknowledging the distinct cognitive levels among different DMs, the integration of multiple weights into the consensus process is characterized by its dynamic and iterative nature. Concerning the measurement of consensus, this study employs a method based on the gap between prospect values, which enhances objectivity while overcoming the limitations associated with the distance formula of PLTSs. Furthermore, the feedback mechanism incorporated into the modification process incorporates dynamic adjustment parameters that are tailored to different evaluation values, thereby preventing excessive adjustments that are either too low or too high. By utilizing the newly proposed prospect value function , this research aggregates the group evaluation value and identifies the optimal alternative. In conclusion, this paper concludes with a comparative analysis involving various counterparts, shedding light on the feasibility and validity of the proposed model.},
  archive      = {J_ISCI},
  author       = {Yu Wang and Jianming Zhan and Chao Zhang and Zeshui Xu},
  doi          = {10.1016/j.ins.2023.119800},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119800},
  shortjournal = {Inf. Sci.},
  title        = {A group consensus model with prospect theory under probabilistic linguistic term sets},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Z-relation-based multistage decision making. <em>ISCI</em>,
<em>653</em>, 119799. (<a
href="https://doi.org/10.1016/j.ins.2023.119799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multistage decision problems have attracted interest in various fields. Starting from the pioneering work of Bellman and Zadeh, a large class of comprehensive studies for fuzzy, stochastic and other settings were proposed. The main issue missed in the existing works is partial reliability of information. Indeed, partial reliability of information about states and actions is important for multistage decisions. Particularly, information about future state of a system resulting from current strategies is partially reliable due to uncertainty. To account for partial reliability aspect, Zadeh introduced the concept of a Z-number. In this paper, we use this concept to consider multistage decision making under partially reliable information. States, strategies, and goals are described by using Z-numbers. State transition matrix that describes evolution of a system in time is formed by using Z-number-based relations. This description leads to a problem of dynamic programming in Z-environment. We use Z-numbers to account for the fact that information related to state transitions is partially reliable – we are partially sure in a result of each transition. The reason behind partial reliability is complexity and uncertainty of real-world problems. A typical example and an application study are used to illustrate the approach.},
  archive      = {J_ISCI},
  author       = {Rafik A. Aliev and Witold Pedrycz and Babek G. Guirimov and Oleg H. Huseynov and Rafig R. Aliyev},
  doi          = {10.1016/j.ins.2023.119799},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119799},
  shortjournal = {Inf. Sci.},
  title        = {Z-relation-based multistage decision making},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decomposed deep multi-view subspace clustering with
self-labeling supervision. <em>ISCI</em>, <em>653</em>, 119798. (<a
href="https://doi.org/10.1016/j.ins.2023.119798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most deep multi-view subspace clustering (DMVSC) methods usually employ pipeline optimization by learning the self-expression with a deep model first and then applying spectral clustering to group multi-view data. Subsequently, end-to-end DMVSC methods have been proposed by integrating these two steps into a unified optimization framework. However, the pipeline methods may suffer from misaligned clustering accumulation due to the noise or outlying entries, and the end-to-end methods often constitute a relatively complex parameter optimization. In this paper, we propose a novel method named decomposed deep multi-view subspace clustering with self-labeling supervision (D 2 MVSC) that runs with a decomposed optimization strategy by three-stage training. Specifically, multi-scale features are extracted by autoencoder in the pre-training stage. According to the discriminative contribution of each view, consensus self-expression is learned from these features by adaptive fusion and structure supervision to generate high-quality pseudo-labels in the fine-tuning stage. Finally, the pseudo-labels are used to retrain the model in a self-labeling supervision manner for robust clustering. Exciting, the self-labeling supervision can be used as an add-on module for other DMVSC methods to improve clustering performance. Extensive experiments on six datasets verify the effectiveness and superiority of our method over other state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Jiao Wang and Bin Wu and Zhenwen Ren and Yunhui Zhou},
  doi          = {10.1016/j.ins.2023.119798},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119798},
  shortjournal = {Inf. Sci.},
  title        = {Decomposed deep multi-view subspace clustering with self-labeling supervision},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NT-DPTC: A non-negative temporal dimension preserved tensor
completion model for missing traffic data imputation. <em>ISCI</em>,
<em>653</em>, 119797. (<a
href="https://doi.org/10.1016/j.ins.2023.119797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing traffic data imputation is an important step in the intelligent transportation systems . Low rank approximation is an important method for the missing traffic data imputation, especially the low rank matrix/tensor completion. However, the low-rank matrix completion has a huge time cost and the low-rank tensor completion cannot fully extract the information and maintain non-negativity. Therefore, we propose a novel non-negative temporal dimension preserved tensor completion (NT-DPTC) model with ideas: a ) proposing a novel dimension preserved (DP) tensor decomposition method , which decomposes a tensor into three latent factor tensors to fully extract the intrinsic feature, b ) using a Sigmoid mapper for releasing non-negative constraint from the training process and increasing flexibility, c ) exploiting temporal constrains and AdamW schemes for obtaining a higher accuracy and faster convergence. Experiments on four industrial application scenarios highlight the superiority of our proposed model when compared with the existing state-of-the-art models.},
  archive      = {J_ISCI},
  author       = {Hong Chen and Mingwei Lin and Jiaqi Liu and Hengshuo Yang and Chao Zhang and Zeshui Xu},
  doi          = {10.1016/j.ins.2023.119797},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119797},
  shortjournal = {Inf. Sci.},
  title        = {NT-DPTC: A non-negative temporal dimension preserved tensor completion model for missing traffic data imputation},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). State evaluation method for complex task network models.
<em>ISCI</em>, <em>653</em>, 119796. (<a
href="https://doi.org/10.1016/j.ins.2023.119796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the assessment of non-complete states in complex task networks and establishes an online capability boundary assessment model based on real-time feature parameters. By utilizing multivariate heterogeneous state features for data mining and pattern recognition, we delve into virtual sample generation technology using an overall diffusion trend approach. This starts by examining the validity of sample data and analyzing the relevance of data acquired within the feature space . Building on this foundation, the overall diffusion trend method is applied to generate virtual sample input that aligns with the sampling distribution characteristics of avionics system equipment. To address non-complete state evaluation in complex task networks, we design a comprehensive model. This model involves constructing a system signal flow block diagram and a structural diagram depicting the available capacity of subsystems and the overall system tasks. The establishment of unknown function relationships in signal connections is achieved through a fusion of neural network and fuzzy logic systems . Finally, an intelligent optimization algorithm is employed to determine system parameters. Utilizing this neuro-fuzzy system in simulation, we attain real-time system responses and evaluate the output regarding the available capacity of system tasks.},
  archive      = {J_ISCI},
  author       = {Xiaoling Liang and Dan Bao and Zeyuan Yang},
  doi          = {10.1016/j.ins.2023.119796},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119796},
  shortjournal = {Inf. Sci.},
  title        = {State evaluation method for complex task network models},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot remaining useful life prediction based on
meta-learning with deep sparse kernel network. <em>ISCI</em>,
<em>653</em>, 119795. (<a
href="https://doi.org/10.1016/j.ins.2023.119795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting remaining useful life (RUL) of machinery is of vital importance to prognostics and health management. Reliable and accurate RUL prediction not only can reduce maintenance costs and increase machine availability but also even prevent catastrophic consequences . In reality, RUL predictions usually require numerous certain kinds of machine degradation data. However, complex operating conditions and safety issues may often result in fragmented data records generated, with very few complete samples being usable. To overcome the challenge of RUL prediction with limited data, this paper proposes a novel MetaDESK model that is based on meta-learning with deep sparse kernel network. The general idea is to train a sparse kernel with a variational posterior in a data-driven fashion, and then transfer it to a new few-shot RUL task via meta-knowledge. Specifically, we first incorporate a Gaussian Process into the model-agnostic meta-learning (MAML) framework and use variational inference to estimate latent variables as kernel features, which allows us to sample from a non-Gaussian distribution of the posterior. Then, the KL-divergence of sparse approximation is added to the kernel features as a regularization term through inference to reduce the overfitting problem. Also, to exploit the dependencies of the tasks we integrate both their shared knowledge and task-specific information into a contextual reasoning process, which is implemented by a bidirectional long short-term memory network. To evaluate our proposed model, we conduct extensive experiments using publicly available degradation data, and the results verify the model&#39;s effectiveness.},
  archive      = {J_ISCI},
  author       = {Jing Yang and Xiaomin Wang and Zhipeng Luo},
  doi          = {10.1016/j.ins.2023.119795},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119795},
  shortjournal = {Inf. Sci.},
  title        = {Few-shot remaining useful life prediction based on meta-learning with deep sparse kernel network},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic niching particle swarm optimization with an external
archive-guided mechanism for multimodal multi-objective optimization.
<em>ISCI</em>, <em>653</em>, 119794. (<a
href="https://doi.org/10.1016/j.ins.2023.119794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multi-objective optimization problems (MMOPs) contain multiple equivalent Pareto optimal sets (PSs) corresponding to the same Pareto front (PF). However, simultaneously locating well-distributed and well-converged multiple equivalent global PSs and PF remains challenging. Therefore, this paper proposes dynamic niching particle swarm optimization (PSO) with an external archive-guided (AG) mechanism, termed DNPSO-AG, for solving MMOPs. In DNPSO-AG, a clustering-based dynamic niching technique is integrated with PSO to divide the population into multiple niches. In addition, a leader updating method controls the updating of the leaders. Furthermore, a novel external archive-guided mechanism guides the evolution of multiple niches and enhances the distribution of solutions, which comprises two strategies: the adaptive division of the external archive strategy, which adaptively divides the external archive into multiple sub-archives, and the distance-based sub-archive and niche matching strategy, which assigns sub-archives to multiple niches for maintenance. The experimental results demonstrate that the proposed DNPSO-AG outperforms seven other state-of-the-art competitors on the CEC 2019 MMOP test suite in terms of the inverted generational distance (IGD) and IGD in the decision space (IGDX) metrics, with improvements of 21.3% and 9.1% over the best-performing competitor, respectively.},
  archive      = {J_ISCI},
  author       = {Yu Sun and Yuqing Chang and Shengxiang Yang and Fuli Wang},
  doi          = {10.1016/j.ins.2023.119794},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119794},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic niching particle swarm optimization with an external archive-guided mechanism for multimodal multi-objective optimization},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uninorms internal on one or more non-trivial cuts.
<em>ISCI</em>, <em>653</em>, 119793. (<a
href="https://doi.org/10.1016/j.ins.2023.119793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Each uninorm is trivially internal on the cut in the neutral element and uninorms internal on the boundary were already completely characterized. We discuss uninorms which are internal on some non-trivial cut and show that each such uninorm can be expressed as a non-trivial ordinal sum . In individual cases we discuss the structure of such conjunctive (disjunctive) uninorm and show that the corresponding ordinal sum contains uninorms, t-conorms, t-superconorms and generalized sub-uninorms (t-norms, t-subnorms and generalized super-uninorms). Moreover, we discuss the ordinal sum decomposition of uninorms with several internal cuts and show their decomposition into semigroups that have only constant internal cuts, and possibly an internal cut in the neutral element.},
  archive      = {J_ISCI},
  author       = {Andrea Mesiarová-Zemánková},
  doi          = {10.1016/j.ins.2023.119793},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119793},
  shortjournal = {Inf. Sci.},
  title        = {Uninorms internal on one or more non-trivial cuts},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Targeted mining of contiguous sequential patterns.
<em>ISCI</em>, <em>653</em>, 119791. (<a
href="https://doi.org/10.1016/j.ins.2023.119791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, sequential pattern mining (SPM) has been applied in many domains, including recommender systems , fraud detection, and other related industries. Target-oriented SPM (TSPM) has been proposed to improve the interpretability of SPM by addressing the issue that too many irrelevant or meaningless sequential patterns are often discovered, which facilitates data analysis. Nevertheless, current TSPM research does not consider contiguity to identify sequential patterns, despite the fact that it is an important feature of sequence data. Contiguity has significant implications in applications such as bioinformatics and network intrusion detection , as it can aid the detection of periodic patterns and anomalous behaviors. Therefore, this paper proposes a novel problem of target-oriented contiguous sequential pattern mining (TCSPM) and introduces two algorithms, called TCSPM and TCSPM+. TCSPM utilizes a compact data structure called sequence chain and relies on a sequence chain pruning strategy to reduce the search space . In addition, TCSPM applies a reverse matching technique to quickly search for targeted contiguous sequences . TCSPM+ is an optimized version of TCSPM that utilizes sequence segmentation operations and a query sequence pruning strategy to further improve performance. Extensive experiments on both real and synthetic datasets demonstrate that TCSPM is an efficient algorithm for discovering targeted contiguous sequential patterns (TCSPs). TCSPM+ substantially enhances the performance of TCSPM in terms of runtime, memory usage, and scalability, outperforming TCSPM by an order of magnitude on some datasets.},
  archive      = {J_ISCI},
  author       = {Kaixia Hu and Wensheng Gan and Shan Huang and Hao Peng and Philippe Fournier-Viger},
  doi          = {10.1016/j.ins.2023.119791},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119791},
  shortjournal = {Inf. Sci.},
  title        = {Targeted mining of contiguous sequential patterns},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Probability-based label enhancement for multi-dimensional
classification. <em>ISCI</em>, <em>653</em>, 119790. (<a
href="https://doi.org/10.1016/j.ins.2023.119790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-dimensional classification (MDC) assumes that each instance has multiple heterogeneous class spaces simultaneously, and each class variable describes the semantic information of instances from a specific dimension. Recent studies have proven that encoding heterogeneous class spaces into a special logical-label space and employing the label enhancement technique to learn latent real-number labels (i.e., label distributions) of instances is an effective strategy for MDC. However, the adopted label enhancement methods can result that data whose features are quite different to each other have similar label distributions. To tackle this problem, we propose a novel probability-based label enhancement approach for MDC. Specifically, manifold structures of the feature and label distribution spaces are transformed into two different probability distributions, and we expect them to be close. Subsequently, it makes label distributions of samples whose features have large differences be more differentiated. Moreover, the logical-label mapping and reconstruction terms are designed to preserve the intrinsic information from the logical-label space. Besides, an improved multi-output support vector regression is developed as the prediction model, where we introduce mean squared error to reduce the risk of model underfitting. Experimental results on ten benchmark datasets clearly validate the superiority of our method over state-of-the-art MDC baselines.},
  archive      = {J_ISCI},
  author       = {Jun Tang and Wenhui Chen and Ke Wang and Yan Zhang and Dong Liang},
  doi          = {10.1016/j.ins.2023.119790},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119790},
  shortjournal = {Inf. Sci.},
  title        = {Probability-based label enhancement for multi-dimensional classification},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SFKNN-DPC: Standard deviation weighted distance based
density peak clustering algorithm. <em>ISCI</em>, <em>653</em>, 119788.
(<a href="https://doi.org/10.1016/j.ins.2023.119788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DPC (Clustering by fast search and find of Density Peaks) algorithm and its variations typically employ Euclidean distance , overlooking the diverse contributions of individual feature to similarity and subsequent clustering. To address this limitation, the standard deviation weighted distance is proposed in this paper to enhance the Euclidean distance . This weighted distance takes into account the specific contribution of each feature to the distance (similarity) between data points . By utilizing this weighted distance, the local density ρ i ρi and distance δ i δi of point i are defined, thereby capturing the local pattern of point i to the fullest extent possible. Outliers are defined using this innovative weighted distance. The divide and conquer assignment strategy is proposed based on this proposed weighted distance and the semi-supervised learning and the mutual K-nearest neighbor assumption. Consequently, the SFKNN-DPC (Standard deviation weighted distance and Fuzzy weighted K-Nearest Neighbors based Density Peak Clustering) algorithm is proposed, aiming to effectively uncover the hidden clusters within a dataset. Extensive experiments conducted on benchmark datasets demonstrate the superiority of SFKNN-DPC over DPC, its variations, and other benchmark clustering algorithms. Moreover, statistical significance tests indicate that SFKNN-DPC exhibits notable differences when compared to its counterparts.},
  archive      = {J_ISCI},
  author       = {Juanying Xie and Xinglin Liu and Mingzhao Wang},
  doi          = {10.1016/j.ins.2023.119788},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119788},
  shortjournal = {Inf. Sci.},
  title        = {SFKNN-DPC: Standard deviation weighted distance based density peak clustering algorithm},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attention-based exploitation and exploration strategy for
multi-hop knowledge graph reasoning. <em>ISCI</em>, <em>653</em>,
119787. (<a href="https://doi.org/10.1016/j.ins.2023.119787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs (KGs) typically suffer from incompleteness. A popular approach to solve this problem is multi-hop reasoning through Reinforcement Learning (RL) framework, which is an explainable and effective model to predict missing links in KGs. However, many previous RL-based models use the scoring function of the pre-trained Knowledge Graph Embedding (KGE) methods as the reward function, which will lead to the performance of the model be limited to the KGE methods. Moreover, the agent may reason a meaningless path if it cannot distinguish the different aspect of each entity in different triples. To solve both problems, we propose a multi-hop reasoning model named Ae2KGR, by applying two novel strategies: attention-based exploitation and attention-based exploration. The attention-based exploitation strategy incorporates historical and query information with the neighborhood of the current entity, and dynamically updates the current state during reasoning process to assign different semantic information to the entity to distinguish different triples. The attention-based exploration strategy designs a novel policy network and reward function to dynamically make decisions based on the constantly changing state. Extensive experiments on three standard datasets confirm the effectiveness of our innovations, and the performance of our proposed Ae2KGR is significantly improved compared to the state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Bin Shang and Yinliang Zhao and Yifan Liu and Chenxin Wang},
  doi          = {10.1016/j.ins.2023.119787},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119787},
  shortjournal = {Inf. Sci.},
  title        = {Attention-based exploitation and exploration strategy for multi-hop knowledge graph reasoning},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RFedFW: Secure and trustable aggregation scheme for
byzantine-robust federated learning in internet of things.
<em>ISCI</em>, <em>653</em>, 119784. (<a
href="https://doi.org/10.1016/j.ins.2023.119784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a promising approach in the Internet of Things (IoT) that enables collaborative and distributed machine learning among massive IoT devices without sharing private data, thereby constructing smart IoT applications. However, traditional federated learning approaches are unable to monitor the local training process of devices. Some malicious devices can exploit the vulnerability to conduct Byzantine attacks, which may potentially lead to the failure or compromise of shared global model. In this paper, we propose a new Byzantine-robust federated learning framework called rFedFW, which aims to achieve secure and trustable federated learning in the IoT. Specifically, we propose a dual filtering mechanism to identify and discard malicious gradients. Furthermore, we design an adaptive weight adjustment scheme that dynamically reduces the aggregated weight of potentially malicious gradients, ultimately achieving robust model aggregation. Additionally, we propose a dynamic clipping method to reduce the magnitude of various gradients, and we incorporate an additive model aggregation scheme with momentum to smooth the effects of local gradients and achieve efficient model aggregation. Extensive experimental results on various datasets demonstrate the effectiveness and robustness of rFedFW.},
  archive      = {J_ISCI},
  author       = {Lina Ni and Xu Gong and Jufeng Li and Yuncan Tang and Zhuang Luan and Jinquan Zhang},
  doi          = {10.1016/j.ins.2023.119784},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119784},
  shortjournal = {Inf. Sci.},
  title        = {RFedFW: Secure and trustable aggregation scheme for byzantine-robust federated learning in internet of things},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Z-DNMASort: A double normalization-based multiple
aggregation sorting method with z-numbers for multi-criterion sorting
problems. <em>ISCI</em>, <em>653</em>, 119782. (<a
href="https://doi.org/10.1016/j.ins.2023.119782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extensive multi-criterion sorting (MCS) methods have been developed to address problems encountered in real-world scenarios. Nevertheless, these methods did not take into account the reliability of the information given by experts, and neglected the preferences of decision-makers when calculating the comprehensive performances of alternatives. To overcome these limitations, this paper proposes a double normalization-based multiple aggregation sorting method with Z-numbers (Z-DNMASort), which can depict both the reliability and uncertainty of any available information. The method considers both quantitative and qualitative criteria in forms of benefit, cost or target types in the sorting process, and also considers the reliability of information given by experts. Furthermore, this method takes into account three aggregation techniques to reflect the preferences of decision-makers when calculating the comprehensive performances of alternatives. A case study regarding battery electric vehicle (BEV) evaluation is given to validate the proposed method. The paper concludes by providing a comprehensive analysis and discourse on the proposed method.},
  archive      = {J_ISCI},
  author       = {Huchang Liao and Yue Xiao and Xingli Wu and Romualdas Bausys},
  doi          = {10.1016/j.ins.2023.119782},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119782},
  shortjournal = {Inf. Sci.},
  title        = {Z-DNMASort: A double normalization-based multiple aggregation sorting method with Z-numbers for multi-criterion sorting problems},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The challenges of modeling using fuzzy standard interval
arithmetic: A case study in electrical engineering. <em>ISCI</em>,
<em>653</em>, 119774. (<a
href="https://doi.org/10.1016/j.ins.2023.119774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the aim is to shed light on the challenges in deriving a mathematical model of dynamical systems when fuzzy standard interval arithmetic (FSIA) serves as a mathematical tool. The challenges in question are investigated through two approaches called the direct and devious approach. Specifically, in the direct approach , the challenges lie in the high complexities of deriving the fuzzy model while maintaining conformity with the laws of physics. Additionally, it is possible that the resulting fuzzy model may not have a solution. Concerning the devious approach, the primary challenge is the potential violation of the physics laws governing the system, which means that the validity of the fuzzy model is not guaranteed. Moreover, in both cases, the UBM phenomenon poses another challenge, preventing the attainment of a unique fuzzy model. As a result, it is demonstrated that FSIA and any related concepts, such as the strongly generalized Hukuhara derivative (SGH-derivative), generalized Hukuhara derivative (gH-derivative), generalized derivative, etc., mainly suffer from the catastrophe of physics laws violation (CPLV), which can be considered the most significant drawback. Furthermore, it is explained that the reason for a fuzzy differential equation under concepts such as the SGH-derivative or gH-derivative having multiple solutions is due to the CPLV. To clarify the CPLV, a simple electrical circuit with uncertain elements is examined as a case study .},
  archive      = {J_ISCI},
  author       = {Mehran Mazandarani and Jianfei Pan},
  doi          = {10.1016/j.ins.2023.119774},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119774},
  shortjournal = {Inf. Sci.},
  title        = {The challenges of modeling using fuzzy standard interval arithmetic: A case study in electrical engineering},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ambient-aware continuous aid for mountain rescue activities.
<em>ISCI</em>, <em>653</em>, 119772. (<a
href="https://doi.org/10.1016/j.ins.2023.119772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ambient-awareness in conjunction with pervasive computing is a significant challenge for system designers. It follows the necessity of gathering raw, massive and heterogeneous environmental data which we obtained, while middleware processes must merge context modelling and reasoning seamlessly. We proposed a system supporting mountain rescuers which is demanding due to the large number of environmental objects interacting, as well as high data variability. We presented complex context processing embedded in the proposed context life cycle and implemented it in a difficult mountain environment. We introduced five weather scenarios which are a basis for contextual and perceptual processing during the validation of our model. The system merges a message streaming broker for massive data transport, low and high-level processing algorithms, repositories and a logical SAT solver. It constitutes a Context-Aware-as-a-Service (CAaaS) system, offering advanced support for mountain rescue operations. The provided software model defines middleware components which act on a predicted context and transform in situ sensor data into smart decisions, and which could operate as a platform-based cloud computing model . It is an enabler yielding a synergy effect with different software components orchestration when providing pro-activeness and non-intrusiveness concerning smart decisions.},
  archive      = {J_ISCI},
  author       = {Radosław Klimek},
  doi          = {10.1016/j.ins.2023.119772},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119772},
  shortjournal = {Inf. Sci.},
  title        = {Ambient-aware continuous aid for mountain rescue activities},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient and anonymous password-hardened encryption
services. <em>ISCI</em>, <em>653</em>, 119771. (<a
href="https://doi.org/10.1016/j.ins.2023.119771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Password-based authentication and encryption schemes are commonly employed to ensure data privacy. Nevertheless, these schemes are vulnerable to brute-force attacks, as user passwords have low-entropy. Password-hardened encryption (PHE) was proposed to combat brute-force attacks by introducing an external crypto service to enforce rate limiting for user requests. However, existing PHE schemes fail to provide user anonymity and need to rely on computationally expensive cryptographic primitives (e.g. zero-knowledge proofs and exponentiations). In this paper, we introduce cross-epoch anonymity in PHE to trade off rate limiting and per-user anonymity. The user requests within the same epoch can be linked by the external crypto service to enforce rate limiting and defend against brute-force attacks, while the requests from different epochs cannot be linked to specific users, ensuring per-user anonymity. Subsequently, we propose an anonymous PHE (APHE) scheme that leverages the trusted execution environment provided by Intel SGX to achieve cross-epoch anonymity. Our scheme achieves both soundness and strong soundness without using zero-knowledge proofs and exponentiations . Sensitive operations are executed within the trusted execution environment, leading to significant performance improvements . The evaluation results demonstrate that our scheme outperforms the state-of-the-art PHE scheme with more than 12/9 times lower latencies for encryption/decryption.},
  archive      = {J_ISCI},
  author       = {Guanxiong Ha and Chunfu Jia and Xiaowei Ge and Jiawei Yuan and Hang Chen and Mingyue Li},
  doi          = {10.1016/j.ins.2023.119771},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119771},
  shortjournal = {Inf. Sci.},
  title        = {Efficient and anonymous password-hardened encryption services},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Edge propagation for link prediction in requirement-cyber
threat intelligence knowledge graph. <em>ISCI</em>, <em>653</em>,
119770. (<a href="https://doi.org/10.1016/j.ins.2023.119770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Critical information infrastructure (CII) is a critical component of national socioeconomic systems and one of the primary targets of cyberattacks. Unfortunately, CII&#39;s security administration struggles to keep up with the rapidly evolving and complex cyber threats. In this research, we combine cybersecurity threat intelligence (CTI) with management security requirements (SR) data to construct a knowledge graph (KG) named RCTI and predict new knowledge on the heterogeneous graph. In addition, we propose EGNN, a novel GNN-based model that defines the representation of edges and develop an algorithm for propagating edge information . Experiments on three public datasets and the RCTI graph show that the EGNN achieves state-of-the-art performance. Finally, we use the EGNN model to predict new links on the RCTI graph, which by manual analysis achieves a 97% connectivity rate between the CTI and SR entities. Therefore, the EGNN can effectively detect management vulnerabilities and enhance CII&#39;s cybersecurity capability in the event of cybersecurity incidents.},
  archive      = {J_ISCI},
  author       = {Yang Zhang and Jiarui Chen and Zhe Cheng and Xiong Shen and Jiancheng Qin and Yingzheng Han and Yiqin Lu},
  doi          = {10.1016/j.ins.2023.119770},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119770},
  shortjournal = {Inf. Sci.},
  title        = {Edge propagation for link prediction in requirement-cyber threat intelligence knowledge graph},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An ensemble-adaptive tree-based chain framework for
multi-target regression problems. <em>ISCI</em>, <em>653</em>, 119769.
(<a href="https://doi.org/10.1016/j.ins.2023.119769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-target regression has always been a challenging task in engineering applications . Nevertheless, it is easy to encounter problems such as low accuracy and inadequate robustness in some scenarios. To address these issues, an ensemble strategy considering correlations is proposed, named Ensemble-Adaptive Tree-based Correlation Chains. Specifically, a Follow-up Correlation Chaining strategy that quantifies the relationships among targets by arranging the L1 norms of correlations is suggested. Compared with other related strategies, it allows for the representation of these relationships through a single regressor chain. Under the proposed framework, the ensemble strategy integrates ten chains, wherein each chain adaptively updates the sample weights during training. This process involves employing the out-of-sample observations with new convergence criteria. Furthermore, the eXtreme Gradient Boosting is introduced as the base regressor to enhance the overall accuracy of the entire method. Finally, the proposed method is validated based on 25 multi-target datasets and a lightweight design of a high-speed rail bogie. The results demonstrate the superior accuracy and robustness compared to other state-of-the-art methods. In general, this study provides reliable predictions for specific scenarios and delivers practical significance in addressing relevant problems.},
  archive      = {J_ISCI},
  author       = {Hechen Wei and Xin Wang and Ziming Wen and Enying Li and Hu Wang},
  doi          = {10.1016/j.ins.2023.119769},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119769},
  shortjournal = {Inf. Sci.},
  title        = {An ensemble-adaptive tree-based chain framework for multi-target regression problems},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised multimodal graph convolutional network for
collaborative filtering. <em>ISCI</em>, <em>653</em>, 119760. (<a
href="https://doi.org/10.1016/j.ins.2023.119760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering (CF) is a central solution for capturing various user-item relationships in building recommender systems . However, when the relationships are sparsely observed, it is challenging to obtain enough signals to infer precise user preferences. Recent studies have attempted to address the sparsity issue by incorporating multimodal information (e.g., image and text) into CF models. However, existing methods mainly focus on capturing modal-specific user preference with multiple unimodal graphs, ignoring the complex nature of user behavior , which is determined by an intricate fusion of multimodal information. Therefore, we develop a Self-supervised Multimodal Graph Convolutional Network (SMGCN), which aims to learn the cross-modal user preferences over multiple modalities with an expressive multimodal fusion on a single graph. More importantly, to facilitate and enhance multimodal fusion in SMGCN, we devise two novel self-supervised learning techniques. 1) Collaborative Multimodal Alignment (CMA) uses contrastive learning to align the domain-specific multimodal semantics with the user-item relational semantics. 2) Multimodal Consistency Regularization (MCR) alleviates the sensitivity on a certain modality and increases model robustness. The experimental results demonstrate that our model consistently outperforms advanced multimodal models on three benchmark datasets.},
  archive      = {J_ISCI},
  author       = {Sungjune Kim and Seongjun Yun and Jongwuk Lee and Gyusam Chang and Wonseok Roh and Dae-Neung Sohn and Jung-Tae Lee and Hogun Park and Sangpil Kim},
  doi          = {10.1016/j.ins.2023.119760},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119760},
  shortjournal = {Inf. Sci.},
  title        = {Self-supervised multimodal graph convolutional network for collaborative filtering},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive optimization consensus mechanism for group
decision making using the shapley allocation scheme. <em>ISCI</em>,
<em>653</em>, 119752. (<a
href="https://doi.org/10.1016/j.ins.2023.119752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive consensus mechanism adopts differentiating consensus improvement strategies according to different consensus levels, which is reasonable and efficient for reaching consensus in group decision making. However, previous adaptive consensus methods adopt the feedback iteration mechanism, which has drawbacks such as time-consuming, over-consensus adjustment, and failure of consensus-reaching. Therefore, this paper studies the adaptive consensus mechanism by optimization models to avoid the above issues of the feedback iteration mechanism. In our approach, corresponding optimization models are constructed to identify non-consensus judgments, non-consensus alternatives, and non-consensus decision makers , respectively. Meanwhile, the related total minimum consensus adjustments are ascertained. Since the uniqueness of the consensus adjustment scheme cannot be ensured according to the built models, we regard it as a cost allocation problem in cooperative games, and define three types of consensus adjustment cooperative games. After that, the Shapley function, a well-known single payoff index, is adopted to allocate total consensus adjustments in different cases. Additionally, we employ the optimization model to determine the modified values of non-consensus judgments by minimizing the number of adjustment judgments. Finally, numerical study and comparison are made.},
  archive      = {J_ISCI},
  author       = {Fanyong Meng and Dengyu Zhao and Chunqiao Tan},
  doi          = {10.1016/j.ins.2023.119752},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119752},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive optimization consensus mechanism for group decision making using the shapley allocation scheme},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving two-mode algorithm via probabilistic selection for
solving satisfiability problem. <em>ISCI</em>, <em>653</em>, 119751. (<a
href="https://doi.org/10.1016/j.ins.2023.119751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The satisfiability problem (SAT) is a critically important issue in multiple branches of computer science and artificial intelligence , with its relevance in industrial applications being of particular Significance CCAnr is the current leading stochastic local search (SLS) solver for tackling crafted satisfiable instances. It uses a two-mode strategy, greedy mode and diversification mode. In the present work, we employ a probabilistic selection approach to enhance CCAnr, leading to a new algorithm called ProbCCAnr. Experiments are carried out using the random SAT benchmarks and structured SAT benchmarks including instances encoded from mathematical problems and application problems. The experiments demonstrate that ProbCCAnr significantly improves the performance of state-of-the-art SLS algorithms including CCAnr and ProbSAT, among others. Moreover, ProbCCAnr shows better performance than state of the art complete solvers.},
  archive      = {J_ISCI},
  author       = {Huimin Fu and Shaowei Cai and Guanfeng Wu and Jun Liu and Xin Yang and Yang Xu},
  doi          = {10.1016/j.ins.2023.119751},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119751},
  shortjournal = {Inf. Sci.},
  title        = {Improving two-mode algorithm via probabilistic selection for solving satisfiability problem},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BiOM: A framework for multimodal multiobjective
optimization. <em>ISCI</em>, <em>653</em>, 119750. (<a
href="https://doi.org/10.1016/j.ins.2023.119750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multiobjective evolutionary algorithms are expected to search for not only Pareto optimal front but also the corresponding multiple equivalent Pareto optimal sets . To this end, this paper designs a framework to ameliorate the performance of the existing multiobjective evolutionary algorithms (MOEAs) for solving multimodal multiobjective optimization problems (MMOPs). In this framework, an MMOP is transformed into a bi-objective optimization problem. The first objective is built by either decomposition-based method or indicator-based method in MOEAs to ensure the population convergence. A diversity indicator is another objective used to preserve the population diversity. Based on these two objectives, two diversity selection strategies are developed, which are responsible for balancing the diversity and the convergence in the decision and objective spaces , respectively, at the same time. According to the feedback information in the evolution, our framework adaptively selects one of them to pick out the promising individuals. Four variants based on our framework are built and are evaluated on 22 MMOPs benchmark functions . Six feature selection problems are also employed to test the performance of our framework. The experimental results confirm that our proposed framework performs well in all criteria.},
  archive      = {J_ISCI},
  author       = {Zhifang Wei and Weifeng Gao and Jingwei Xu and Gary G. Yen},
  doi          = {10.1016/j.ins.2023.119750},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119750},
  shortjournal = {Inf. Sci.},
  title        = {BiOM: A framework for multimodal multiobjective optimization},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Local neighbor propagation on graphs for mismatch removal.
<em>ISCI</em>, <em>653</em>, 119749. (<a
href="https://doi.org/10.1016/j.ins.2023.119749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, despite the promising progress having been achieved, most mismatch removal methods only consider the connection relationships of feature matches in a single neighborhood, and ignore their relationships between different neighborhoods, which will lead to the unavailability of local topological structure for feature matching. In this paper, we propose a novel robust Local Neighbor Propagation on Graphs based mismatch removal (LNPG) method for robust feature matching. LNPG starts from a novel neighborhood graph construction strategy, which leverages both the spatial and the residual information to preserve the local neighborhood structures of potential inliers. Subsequently, LNPG incorporates local neighbor propagation into the graph to enhance connection relationships of the data in different neighborhoods, by using the path-based similarity measurement and the adaptive graph partition . In addition, LNPG includes a novel consistency-filtering-based clustering algorithm , which introduces a reliable neighborhood consistency measure function and an effective cluster merging criterion for robust clustering. Overall, LNPG not only effectively distinguishes inliers from outliers, but also reliably classifies inliers into different transformation models between pairs of images. Extensive experiments on publicly available datasets show the superiority of our LNPG in comparison with other state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Hanlin Guo and Guobao Xiao and Lumei Su and Jiaxing Zhou and Da-Han Wang},
  doi          = {10.1016/j.ins.2023.119749},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119749},
  shortjournal = {Inf. Sci.},
  title        = {Local neighbor propagation on graphs for mismatch removal},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy-preserving federated bayesian optimization with
learnable noise. <em>ISCI</em>, <em>653</em>, 119739. (<a
href="https://doi.org/10.1016/j.ins.2023.119739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional Bayesian optimization approaches assume that all available data are located on one device, which does not consider privacy concerns since data storage and transmission may pose threats to data security . Existing differential privacy-based approaches can protect sensitive information by adding well-calibrated noise to the real objective value of the query input, which may seriously degrade the performance of Bayesian optimization. To address this issue, we propose to learn the noise level of each solution instead of the newly infilled solutions by optimizing a utility-privacy function that considers obfuscating the information of the current best solution, and striking a balance between exploration and exploitation. In this way, the real objective values and the current best solution will be protected. We further extend the proposed approach to a federated setting by considering multiple clients. Our experimental results show that the proposed algorithm can achieve very competitive optimization performance on ten test functions while being able to preserve data privacy. In addition, at the lowest level of privacy protection, the current best solution is leaked in less than 5 out of 91 rounds of surrogate updates for the proposed algorithm, which is significantly smaller than that of the algorithm under comparison.},
  archive      = {J_ISCI},
  author       = {Qiqi Liu and Yuping Yan and Yaochu Jin},
  doi          = {10.1016/j.ins.2023.119739},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119739},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-preserving federated bayesian optimization with learnable noise},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Capital equilibrium strategy for uncertain multi-model
systems. <em>ISCI</em>, <em>653</em>, 119607. (<a
href="https://doi.org/10.1016/j.ins.2023.119607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Working capital, as a core element of company operation and management, plays an important role in various aspects of the company, particularly in activities such as production, ordering, financing, etc. However, internal and external uncertainties, as well as various time cycles, constitute a complex operational environment that will severely affect the capital level of the node companies in the supply chain finance system, and thus cause serious disruptions to the system stability . Therefore, this paper aims to propose an effective capital equilibrium strategy to achieve the switching control of system capitals, thereby reducing system costs and improving system stability . Considering a two-echelon supply chain finance system, this paper designs a capital equilibrium switching strategy based on the T-S fuzzy theory to achieve the system capital equilibrium. The paper also proves the effectiveness and scientific validity of the proposed method, and compares and analyzes the differences of capital equilibrium strategies under fuzzy robust control and robust control through five numerical simulations. The research results show that fuzzy robust control can better suppress the interference of uncertainty on the switching of capital equilibrium strategy, and make the system more stable.},
  archive      = {J_ISCI},
  author       = {Yi Cui and Dongbin Hu and Xiaohong Chen and Xuanhua Xu and Zeshui Xu},
  doi          = {10.1016/j.ins.2023.119607},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119607},
  shortjournal = {Inf. Sci.},
  title        = {Capital equilibrium strategy for uncertain multi-model systems},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed secure consensus for multiagent systems based on
removing intra-cluster coupling restrictions and its application to
energy systems. <em>ISCI</em>, <em>653</em>, 119579. (<a
href="https://doi.org/10.1016/j.ins.2023.119579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cluster consensus of multiagent systems has provided analytical techniques for various industrial domains. As agents work in networked environments, their secure consensus control becomes essential desirable in response to cyber attacks . At that point, we investigate the secure cluster consensus in directed network systems under deception attacks and mixed delays. First, a control strategy for improving arbitrarily fixed topologies based on an extended state observer is proposed to ensure cluster consensus. In the framework of the proposed strategy, several criteria are derived to guarantee cluster consensus for agents. Second, different from the current works that require sufficiently strong intra-cluster coupling strength, the proposed consensus condition ensures fewer intra-cluster coupling restrictions. Third, the Halanay inequality is used to handle the mixed delays and reduce the parameters in the consensus criterion, which improves the efficiency of verifying the consensus. Finally, the simulation results on the IEEE 39-bus energy system are provided for validating the effectiveness of the proposed method, while achieving excellent tracking performance for the frequency and power deviations.},
  archive      = {J_ISCI},
  author       = {Minxue Kong and Feifei Shen and Peihao Du and Xin Peng and Weimin Zhong},
  doi          = {10.1016/j.ins.2023.119579},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119579},
  shortjournal = {Inf. Sci.},
  title        = {Distributed secure consensus for multiagent systems based on removing intra-cluster coupling restrictions and its application to energy systems},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonparametric feature impact and importance. <em>ISCI</em>,
<em>653</em>, 119563. (<a
href="https://doi.org/10.1016/j.ins.2023.119563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Practitioners use feature importance to rank and eliminate weak predictors during model development in an effort to simplify models and improve generality. Unfortunately, they also routinely conflate such feature importance measures with feature impact, the isolated effect of an explanatory variable on the response variable. This can lead to real-world consequences when importance is inappropriately interpreted as impact in applications like medicine and business. The dominant approach for computing feature importance is through interrogation of a fitted model, which works well for feature selection, but gives distorted measures of feature impact. For example, the same method applied to the same data set can yield different feature importances, depending on the model, leading us to conclude that impact should be computed directly from the data. While there are nonparametric feature selection algorithms , they typically provide feature rankings, rather than direct measures of impact or importance. They also often focus on single-variable associations with the response. In this paper, we provide mathematical definitions of feature impact and importance, derived from partial dependence curves, that operate directly on the data. We develop two methods, StratImpact and StratImp, that estimate feature impact and importance from partial dependence measures using stratification of the explanatory variables. We show that features ranked by these definitions are competitive with, and often better than, existing feature selection techniques. We validate our methods through a comparison with contemporary methods using three real data sets and a testbed of simulated data .},
  archive      = {J_ISCI},
  author       = {Terence Parr and Jeff Hamrick and James D. Wilson},
  doi          = {10.1016/j.ins.2023.119563},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119563},
  shortjournal = {Inf. Sci.},
  title        = {Nonparametric feature impact and importance},
  volume       = {653},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast and private multi-dimensional range search over
encrypted data. <em>ISCI</em>, <em>652</em>, 119773. (<a
href="https://doi.org/10.1016/j.ins.2023.119773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For businesses looking to outsource their data to remote servers, cloud-based data storage is a popular choice. It is popular due to its flexibility, cost-effectiveness, and widespread availability. However, ensuring the confidentiality of data is a critical challenge that must be addressed. As a response to this issue, searchable encryption techniques have been developed. These techniques enable search queries to be performed on encrypted data while still keeping the plaintext confidential. While most existing symmetric searchable encryption schemes are designed for one-dimensional data records or document-keyword inverted indices, this paper introduces MDRSSE, a novel symmetric searchable encryption scheme specifically tailored for multi-dimensional range search. MDRSSE stands out as one of the pioneering SSE schemes to support multi-dimensional range search efficiently, without incurring undetermined additional communication or computation costs. By employing a single round of communication between the client and server, MDRSSE enables an honest-but-curious server to respond to multi-dimensional range queries without gaining knowledge of the data records or revealing the search query. Notably, MDRSSE boasts the lowest overall search complexity compared to existing state-of-the-art symmetric searchable encryption schemes designed for multi-dimensional range search. Extensive experimental tests were conducted to validate the robustness and practicality of our proposed scheme. The results demonstrate that, for a dataset consisting of 100K records with 12 dimensions (with each leaf node holding 500 records), it takes only 2.2 seconds to generate the encrypted dataset, and the overall setup phase completes within 2.5 seconds. Furthermore, for a range query encompassing 50 nodes, the search time is less than 2 ms and 3 ms for the client and server, respectively. MDRSSE achieves semantic security under the IND-CPA assumption, all without requiring additional storage size at the server.},
  archive      = {J_ISCI},
  author       = {Shabnam Kasra Kermanshahi and Ron Steinfeld and Xun Yi and Joseph K. Liu and Surya Nepal and Junwei Lou},
  doi          = {10.1016/j.ins.2023.119773},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119773},
  shortjournal = {Inf. Sci.},
  title        = {Fast and private multi-dimensional range search over encrypted data},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An optimal pruned traversal tree-based fast minimum cut
solver in dense graph. <em>ISCI</em>, <em>652</em>, 119768. (<a
href="https://doi.org/10.1016/j.ins.2023.119768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important problem in graph theory, the minimum-cut (min-cut) problem has various applications in many related fields. Among many acceleration strategies, one commonly used strategy is preprocessing the original graph to facilitate the min-cut calculations. In this paper, an optimal pruned tree-based min-cut acceleration algorithm (PTMA) is proposed for the problem by exploiting the mapping between the cuts and pruned depth-first traversal trees , which has not yet been investigated in the existing work. In different types of dense graphs with an average degree of no less than 10, using efficient dynamic programming-based preprocessing with a time complexity of O ( M ) O(M) ( M is the total number of edges), a large number of optimal pruned depth-first traversal trees can be found, which are then used to quickly obtain accurate min-cuts of more than 99.9% node pairs. The algorithm can be used as an effective alternative to existing algorithms, and due to the inherent randomness, it is easy to fine tune the balance between overhead and precision, such as increasing the number of preprocessing passes to improve accuracy.},
  archive      = {J_ISCI},
  author       = {Wei Wei and Yuting Liu and Qinghui Zhang},
  doi          = {10.1016/j.ins.2023.119768},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119768},
  shortjournal = {Inf. Sci.},
  title        = {An optimal pruned traversal tree-based fast minimum cut solver in dense graph},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fractal-based basic probability assignment: A transient mass
function. <em>ISCI</em>, <em>652</em>, 119767. (<a
href="https://doi.org/10.1016/j.ins.2023.119767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively measuring the information content of Basic Probability Assignments (BPA) is a crucial prerequisite for addressing uncertain information within the framework of Dempster-Shafer theory. In previous research, uncertainty and dissimilarity measures for BPAs were often treated separately to counteract the impact of incomplete mutual exclusion between focal elements. In this paper, we introduce a Transient Mass Function (TMF) based on the process of pignistic probability transformation to forge a link between probabilistic and evidential information. As a transient state of BPA, the TMF not only considers the structural features of the focal element but also maintains its numerical content. Carrying out probabilistic information measures on the TMF is equivalent to performing belief information measures on the original BPA. Finally, validated by numerical simulations, TMF provides a unified and effective metric framework for evidential information.},
  archive      = {J_ISCI},
  author       = {Li Zhu and Qianli Zhou and Yong Deng and Kang Hao Cheong},
  doi          = {10.1016/j.ins.2023.119767},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119767},
  shortjournal = {Inf. Sci.},
  title        = {Fractal-based basic probability assignment: A transient mass function},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Role-aware random walk for network embedding. <em>ISCI</em>,
<em>652</em>, 119765. (<a
href="https://doi.org/10.1016/j.ins.2023.119765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding is a fundamental part of many network analysis tasks, including node classification and link prediction. The existing random walk-based embedding methods aim to learn node embedding that preserves information on either node proximity or structural similarity . However, the information on both role and community is important to network nodes. To address the shortcomings of the existing methods, this paper proposes a novel method for network embedding called the RARE, which can be used for the analysis of different types of networks and even disconnected networks. The proposed method uses the role and community information of nodes to preserve both node proximity and structural similarity in the learned node embeddings. The walks generated through the role-aware random walk can capture the role and community information of nodes. The obtained walks are input to the Skip-gram model to learn the final embedding of nodes. In addition, the RARE is extended to the CRARE that adds the sampling of high-order community members to the customized random walk so that the node’s representation can preserve more structural information of the network. The performances of the proposed methods are evaluated on multi-class node classification, link prediction, and network visualization tasks. Experimental results on different domain datasets indicate that the proposed methods outperform the baseline methods . The proposed methods can be further accelerated using parallelization in the random walk generation process. The source code : https://github.com/HeguiZhang/RARE .},
  archive      = {J_ISCI},
  author       = {Hegui Zhang and Gang Kou and Yi Peng and Boyu Zhang},
  doi          = {10.1016/j.ins.2023.119765},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119765},
  shortjournal = {Inf. Sci.},
  title        = {Role-aware random walk for network embedding},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Conditional variational autoencoder for query expansion in
ad-hoc information retrieval. <em>ISCI</em>, <em>652</em>, 119764. (<a
href="https://doi.org/10.1016/j.ins.2023.119764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Query expansion (QE) is commonly used to improve the performance of traditional information retrieval (IR) models. With the adoption of deep learning in IR research, neural QE models have emerged in recent years. Many of these models focus on learning embeddings by leveraging query-document relevance. These embedding models allow computing semantic similarities between queries and documents to generate expansion terms. However, existing models often ignore query-document interactions. This research aims to address that gap by proposing a QE model using a conditional variational autoencoder . It first maps a query-document pair into a latent space based on their interaction, then estimates an expansion model from that latent space. The proposed model is trained on relevance feedback data and generates expansions using pseudo-relevance feedback at test time. The proposed model is evaluated on three standard TREC collections for document ranking: AP and Robust 04 and GOV02, and the MS MARCO dataset for passage ranking. Results show the model outperforms state-of-the-art traditional and neural QE models. It also demonstrates higher additivity with neural matching than baselines.},
  archive      = {J_ISCI},
  author       = {Wei Ou and Van-Nam Huynh},
  doi          = {10.1016/j.ins.2023.119764},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119764},
  shortjournal = {Inf. Sci.},
  title        = {Conditional variational autoencoder for query expansion in ad-hoc information retrieval},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A random-switch-surface based neural sliding mode framework
against actuator attacks of delayed singular semi-markov jump systems.
<em>ISCI</em>, <em>652</em>, 119763. (<a
href="https://doi.org/10.1016/j.ins.2023.119763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the challenge of actuator attacks in delayed singular semi-Markov jump systems (singular S-MJSs) with uncertainties and exogenous disturbances , operating under conditions of partially unknown transition rate (PUTR) matrix and completely unknown transition rate (CUTR) matrix, respectively. The specifics of actuator attacks and the bounds of disturbances remain elusive during the controller design process. Furthermore, any information regarding unknown elements within the PUTR/CUTR matrix is unattainable. To stabilize systems against actuator attacks, we introduce a distinctive “random switch”-triggered sliding surface, referred to as the random switch surface (RSS). Additionally, H ∞ H∞ stochastic admissibility sufficient conditions are established under PUTR and CUTR matrices, respectively. Two corresponding algorithms are presented, leveraging solvable linear matrix inequalities (LMIs), to determine the gain matrices . Further, an innovative adaptive H ∞ H∞ neural sliding mode control (SMC) law is conducted, incorporating an ingenious neural network to approximate actuator attacks. It also enables real-time estimation of unavailable parameter bounds. Finally, we conduct simulations on several examples using our proposed method, as well as other comparison methods, to demonstrate the effectiveness of the proposed approach.},
  archive      = {J_ISCI},
  author       = {Qi Liu and Jianxun Li and Shuping Ma and Shen Yin and Baoping Jiang and Chunyu Yang},
  doi          = {10.1016/j.ins.2023.119763},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119763},
  shortjournal = {Inf. Sci.},
  title        = {A random-switch-surface based neural sliding mode framework against actuator attacks of delayed singular semi-markov jump systems},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-stage classification approach for AI technical service
supplier selection based on multi-stakeholder concern. <em>ISCI</em>,
<em>652</em>, 119762. (<a
href="https://doi.org/10.1016/j.ins.2023.119762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) technology, which can help supply chains improve operational efficiency and reduce production costs, has gradually been adopted by many enterprises in recent years. In general, stakeholders in the supply chain have their own requirements for AI technical services. However, most traditional service supplier selection methods rarely explicitly consider the interest demands of multi-stakeholders and coordinate them, which may lead to unsatisfactory decision results. Therefore, to support the successful implementation of AI technology in supply chain management, this paper proposes a two-stage AI technical service supplier classification method that considers the requirements of multi-stakeholders. In the first stage, we identify the opinions of stakeholders via cluster analysis and determine group coordination needs while fully considering fairness concerns. Moreover, in the second stage, we evaluate and classify AI technical service suppliers based on the group opinions of stakeholders and decision makers&#39; risk preferences. As AI technical service suppliers are mostly emerging internet enterprises, we construct a criteria system to help assess these suppliers in advance. To verify the practicability and effectiveness of our method, we conduct a case study on the automobile supply chain. Furthermore, this work can provide guidance for AI technical service suppliers to improve their enterprise construction.},
  archive      = {J_ISCI},
  author       = {Decui Liang and Wen Cao and Yinrunjie Zhang and Zeshui Xu},
  doi          = {10.1016/j.ins.2023.119762},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119762},
  shortjournal = {Inf. Sci.},
  title        = {A two-stage classification approach for AI technical service supplier selection based on multi-stakeholder concern},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interval-value based movement strategy of three-way
decisions. <em>ISCI</em>, <em>652</em>, 119761. (<a
href="https://doi.org/10.1016/j.ins.2023.119761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The trisecting, acting, and outcome comprise the three core parts of the TAO model for three-way decisions. “Acting” formulates suitable movement strategies for each region based on the results of “trisecting” so that objects can move from unfavorable regions toward favorable regions. Regarding the study of “acting”, there are mainly two movement strategies: object-based movement strategy and region-based movement strategy. However, these two methods only make movement strategies based on existing objects, so they may not be applicable to unknown new objects, namely, the generalization ability is not strong. Therefore, to develop a more generalized movement strategy that can be applied to both existing objects and new objects, we proposed a movement strategy based on interval-value. First, using interval-value to represent each flexible attribute value, a formal representation of the interval-value based movement strategy is proposed. Second, to generate movement rules from interval-value based movement strategies, we present four methods to generate four types of specific movement rules: optimistic movement rules, pessimistic movement rules, the highest frequency of global interval-value movement rules, and the highest frequency of local interval-value movement rules. Finally, the proposed model is efficient, as demonstrated by experimental data .},
  archive      = {J_ISCI},
  author       = {Yi Xu and Fan Luo},
  doi          = {10.1016/j.ins.2023.119761},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119761},
  shortjournal = {Inf. Sci.},
  title        = {Interval-value based movement strategy of three-way decisions},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A game theory based optimal allocation strategy for defense
resources of smart grid under cyber-attack. <em>ISCI</em>, <em>652</em>,
119759. (<a href="https://doi.org/10.1016/j.ins.2023.119759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A deep integration of cyber and physical systems will lead to severe risk and security challenges in the new power system . To address this problem, an optimal defense resource allocation method based on game theory is proposed to against potential cyber-attacks in smart grid proactively. Based on this method, a two-layer game model is designed to optimal resource allocation. One layer is consisted by an evolutionary game between defense nodes and attackers, and the anther layer is consisted by a noncooperative game between multiple defense nodes. Further up, the offensive and defensive evolution results for all scenarios have been discussed, then the solution to resource allocation problem among multiple nodes is formulated. Different from previous work, characteristics of the bounded rationality of the attacker are considered according to the indexes of integrity, usability and confidentiality. Meanwhile, quantum response equalization is introduced to quantify player gains. Finally, specific algorithms are employed to demonstrate the feasibility and effectiveness of the method proposed in this paper.},
  archive      = {J_ISCI},
  author       = {Hui Ge and Lei Zhao and Dong Yue and Xiangpeng Xie and Linghai Xie and Sergey Gorbachev and Iakov Korovin and Yuan Ge},
  doi          = {10.1016/j.ins.2023.119759},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119759},
  shortjournal = {Inf. Sci.},
  title        = {A game theory based optimal allocation strategy for defense resources of smart grid under cyber-attack},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parametrized linear regression for boxplot-multivalued data
applied to the brazilian electric sector. <em>ISCI</em>, <em>652</em>,
119758. (<a href="https://doi.org/10.1016/j.ins.2023.119758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symbolic boxplot data can be considered as a particular case of the numerical multi-valued variable. This kind of symbolic data is an useful exploratory tool with a simple structure for summarizing groups of numerical data . However, in the literature of symbolic data analysis it has been little explored. In this paper, we propose a new prediction method for extracting knowledge from boxplot data. A parametrized regression approach automatically extracts the best reference points from the regressor variables. These reference points are then used to build five linear regression models based on values of the boxplot: minimum (m), lower quartile (Q1), median (Q2), upper quartile (Q3) and maximum (M). A strategy based on BoxCox transformation is applied to the response variable in order to guarantee the mathematical coherence of the predictions and build the boxplot. Experimental evaluation with synthetic and real boxplot datasets illustrates the advantages of the proposed method. Moreover, the present work also focuses in the development of an application for predicting temperature data based on boxplot in the Brazilian Electric Sector.},
  archive      = {J_ISCI},
  author       = {Dailys M.A. Reyes and Leandro C. Souza and Renata M.C.R. de Souza and Adriano L.I. de Oliveira},
  doi          = {10.1016/j.ins.2023.119758},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119758},
  shortjournal = {Inf. Sci.},
  title        = {Parametrized linear regression for boxplot-multivalued data applied to the brazilian electric sector},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved quantum combination method of mass functions
based on supervised learning. <em>ISCI</em>, <em>652</em>, 119757. (<a
href="https://doi.org/10.1016/j.ins.2023.119757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Dempster-Shafer evidence theory, how to model and handle the uncertainty involved in mass functions is generally concerned by researchers. Recently, a quantum model of mass functions was proposed, in which a mass function was represented as a quantum pure state with constraints. Based on that, the authors also gave a quantum averaging operator . However, the phase parameters in the quantum model were unknown and the phase differences in the quantum averaging operator were subjectively given to 0. Considering these problems, this paper proposes an improved quantum combination method of mass functions based on supervised learning, where the optimal phase parameters are derived through supervised learning so as to acquire the phase differences in quantum averaging operator. These obtained parameters are dependent on objective data. Comparative experiments on benchmark data sets are conducted to verify the validity of the proposed method.},
  archive      = {J_ISCI},
  author       = {Siyu Xue and Xinyang Deng and Wen Jiang},
  doi          = {10.1016/j.ins.2023.119757},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119757},
  shortjournal = {Inf. Sci.},
  title        = {An improved quantum combination method of mass functions based on supervised learning},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Build interval-valued time series forecasting model with
interval cognitive map trained by principle of justifiable granularity.
<em>ISCI</em>, <em>652</em>, 119756. (<a
href="https://doi.org/10.1016/j.ins.2023.119756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the study of time series forecasting based on fuzzy cognitive maps (FCMs), the causalities between past values and future values are represented by real-valued weights in [ - 1 , 1 ] [-1,1] . However, for interval-valued time series (ITS), the causalities are affected by various uncertainties including ways of measuring and ways of intervals influencing intervals and thus involve uncertainty. Therefore, real-valued weights are no longer enough for characterizing such causalities, equipping FCMs with interval-valued weights becomes necessary and resulting in interval cognitive maps (ICMs). In this case, how to determine the interval-valued weights of an ICM becomes a crucial problem. To solve this problem, this paper first proposes the principle of justifiable granularity for interval-valued data, which is guaranteed to accumulate enough experimental evidence and effectively express the ITS, then develops a reasonable method that can optimally determine the interval-valued weights and enable the interval-valued weights having clear semantics. By means of the proposed method for determining interval-valued weights, an ICM-based ITS forecasting model is established, which can not only deal with the uncertainty of causalities between interval-valued data, but also avoid counterintuitive outputs which often appeared in existing ITS forecasting models. Experimental results show the good performance of the proposed forecasting model.},
  archive      = {J_ISCI},
  author       = {Chenxi Ouyang and Fusheng Yu and Yadong Hao and Yuqing Tang and Yanan Jiang},
  doi          = {10.1016/j.ins.2023.119756},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119756},
  shortjournal = {Inf. Sci.},
  title        = {Build interval-valued time series forecasting model with interval cognitive map trained by principle of justifiable granularity},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weak relationship indicator-based evolutionary algorithm for
multimodal multi-objective optimization. <em>ISCI</em>, <em>652</em>,
119755. (<a href="https://doi.org/10.1016/j.ins.2023.119755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multi-objective problems (MMOPs) have multiple equivalent Pareto sets (PSs) that map to the same Pareto optimal front (PF). Traditional multimodal multiobjective algorithms (MMEAs) use strong relationships to guide population convergence, but this can lead to two problems: the population may explore easier-to-search PSs and lose more difficult-to-search PSs, and it may not retain local PSs well. To address these issues, we propose a weak relationship indicator-based MMEA that includes weak convergence indicators and density evaluation indicators. The weak convergence indicator considers the relationship between an individual and its neighbors, while the density evaluation indicator considers the density information of the individual and its neighbors. This allows the population to retain solutions from different PSs during exploration. An archive based on weak convergence indicators also retains excellent solutions generated during the evolution of the population. Experimental results show that our algorithm ranked first in terms of overall score when compared with seven state-of-the-art algorithms using the Friedman Test .},
  archive      = {J_ISCI},
  author       = {Yi Xiang and Jinhua Zheng and Yaru Hu and Yuan Liu and Juan Zou and Qi Deng and Shengxiang Yang},
  doi          = {10.1016/j.ins.2023.119755},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119755},
  shortjournal = {Inf. Sci.},
  title        = {Weak relationship indicator-based evolutionary algorithm for multimodal multi-objective optimization},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed strategy for constrained resource allocation
problems of autonomous second-order nonlinear agents and its application
to smart grids. <em>ISCI</em>, <em>652</em>, 119754. (<a
href="https://doi.org/10.1016/j.ins.2023.119754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the constrained distributed resource allocation problems (DRAPs) of autonomous multi-agent systems (MASs). Unlike well-defined DRAPs, the disturbed second-order agents are taken into account. Moreover, all agents&#39; decisions are subject to both coupling and local inequalities. Because of the coexistence of disturbed second-order nonlinear dynamics and inequality constraints , existing strategies are not applicable to tackle our problem. Also, they create challenges for the strategy design, because the inequality constraints must hold at the optimal allocation (OA), while these agents are not able to control their decisions directly. By gradient descent , state feedback and internal model (IM), we exploit a distributed strategy to control all agents to carry out the distributed resource allocation tasks (DRATs). Furthermore, the strategy is rigorously analyzed. Finally, our strategy is applied to the economic dispatch problems (EDPs). Under our approach, turbine-generators can autonomously achieve the optimal generation allocation by regulating their powers, in accordance with the load demand of smart grids.},
  archive      = {J_ISCI},
  author       = {Zhenhua Deng and Jin Luo and Tao Chen},
  doi          = {10.1016/j.ins.2023.119754},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119754},
  shortjournal = {Inf. Sci.},
  title        = {Distributed strategy for constrained resource allocation problems of autonomous second-order nonlinear agents and its application to smart grids},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature selection based on fuzzy combination entropy
considering global and local feature correlation. <em>ISCI</em>,
<em>652</em>, 119753. (<a
href="https://doi.org/10.1016/j.ins.2023.119753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a commonly employed method to decrease data processing complexity by discarding unnecessary and repetitive features. An effective feature selection method can mitigate the challenges posed by high-dimensional data, save computing resources and improve learning performance. Combination entropy is a useful tool for assessing feature uncertainty, which provides an intuitive representation of the amount of information. However, classical combination entropy is difficult to be directly used for continuous features. Therefore, we propose the concept of fuzzy combination entropy. Moreover, we put forward an importance metric that comprehensively considers global feature correlation and local feature correlation. Firstly, the fuzzy combination entropy (FCE) is presented based on the fuzzy λ -similarity relation. Secondly, by combining the benefits of fuzzy rough sets and combination entropy, fuzzy combination entropy and its variants are constructed, and their related properties are also discussed. Thirdly, the concepts of global feature correlation and local feature correlation are defined and an importance metric is proposed. Finally, a feature selection method according to fuzzy combination entropy considering global feature correlation and local feature correlation (FSmFCE) is designed. According to the findings from our experiments, it is evident that our algorithm demonstrates a preference for selecting a smaller feature set, yet still achieves commendable classification performance.},
  archive      = {J_ISCI},
  author       = {Jianhua Dai and Qi Liu and Xiongtao Zou and Chucai Zhang},
  doi          = {10.1016/j.ins.2023.119753},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119753},
  shortjournal = {Inf. Sci.},
  title        = {Feature selection based on fuzzy combination entropy considering global and local feature correlation},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature relevance and redundancy coefficients for multi-view
multi-label feature selection. <em>ISCI</em>, <em>652</em>, 119747. (<a
href="https://doi.org/10.1016/j.ins.2023.119747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view and multi-label data offer a comprehensive perspective for learning models, but dimensionality poses a challenge for feature selection. Existing methods based on information theory solely focus on feature contribution to the entire label set, neglecting balanced information gain across labels and issues of feature overlap. They also miss the opportunity to exploit correlations between views, features, and labels. To address these challenges, our novel method combines feature relevance and redundancy terms. The feature relevance term uses label information coefficients to consider each label&#39;s information gain , while the feature redundancy term employs view redundancy coefficients to account for feature redundancy within and between views. This approach balances label information acquisition and reduces feature information redundancy . We evaluate our proposed method on six real-world datasets, comparing it with two existing multi-view multi-label feature selection methods and four multi-label feature selection methods. The results show that our method, RRFS, outperforms the other six methods overall.},
  archive      = {J_ISCI},
  author       = {Qingqi Han and Liang Hu and Wanfu Gao},
  doi          = {10.1016/j.ins.2023.119747},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119747},
  shortjournal = {Inf. Sci.},
  title        = {Feature relevance and redundancy coefficients for multi-view multi-label feature selection},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Granular computing-based deep learning for text
classification. <em>ISCI</em>, <em>652</em>, 119746. (<a
href="https://doi.org/10.1016/j.ins.2023.119746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Granular computing involves a comprehensive process that encompasses theories, methodologies, and techniques to solve complex problems, rather than being just an algorithm. As the volume of generated data continues to grow rapidly, data-driven problems have become increasingly complex. Although deep learning models have outperformed traditional machine learning models in solving complex problems, there is still room for enhancing their performance. In this paper, we propose a granular computing-based deep learning model, aimed at enhancing classifier accuracy in complex natural language-based problems. The proposed approach involves a new granulation method, which comprises a novel algorithm built on combinatorial concepts and ten rule-based numerical granules. By utilizing this granulation method, each granule adds a new representation and concept to the existing data. The proposed model consists of multiple models that perform learning separately in a granular view. In the final step, the model pays attention to the granulated matrices generated by various models. The proposed model is evaluated using datasets related to cyberbullying and two hate speech datasets, resulting in significant improvements in accuracy compared to state-of-the-art models.},
  archive      = {J_ISCI},
  author       = {Rashid Behzadidoost and Farnaz Mahan and Habib Izadkhah},
  doi          = {10.1016/j.ins.2023.119746},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119746},
  shortjournal = {Inf. Sci.},
  title        = {Granular computing-based deep learning for text classification},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A surrogate-assisted evolutionary algorithm with knowledge
transfer for expensive multimodal optimization problems. <em>ISCI</em>,
<em>652</em>, 119745. (<a
href="https://doi.org/10.1016/j.ins.2023.119745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a kind of common problems in practical applications, expensive multimodal optimization problems (EMMOPs) require to locate as many global optima as possible with a few costly or/and time-consuming fitness evaluations. This poses a great challenge since even capturing a single optimum is not so easy. To address this issue, this study proposes a surrogate-assisted multimodal evolutionary algorithm with knowledge transfer (SAKT-MMEA), where a modality prediction method based on global surrogate-assisted sampling (GSSMP) and a joint surrogate-assisted local search method (JSLS) are designed for efficient modality exploration and exploitation, respectively. By pre-constructing a global surrogate model, GSSMP samples and approximately evaluates adequate solutions such that the fitness landscape of an EMMOP can be well depicted and the modalities are expected to be fully detected. For each identified modality, JSLS adaptively takes a local surrogate model or a global one as the objective function to exploit the optimum while preventing it from getting trapped in a local optimum. To further enhance the exploitation efficiency, a knowledge transfer-based optimizer is developed for JSLS to collaboratively perform multiple local search on different modalities. Extensive experimental results on EMMOPs with different features demonstrate that SAKT-MMEA gains competitive edges over six state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Wenhao Du and Zhigang Ren and Jihong Wang and An Chen},
  doi          = {10.1016/j.ins.2023.119745},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119745},
  shortjournal = {Inf. Sci.},
  title        = {A surrogate-assisted evolutionary algorithm with knowledge transfer for expensive multimodal optimization problems},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel quantum belief entropy for uncertainty measure in
complex evidence theory. <em>ISCI</em>, <em>652</em>, 119744. (<a
href="https://doi.org/10.1016/j.ins.2023.119744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex evidence theory (CET), as a generalized D-S evidence theory, has the ability to express uncertainty in the complex field. CET has been applied in many information fields. One of the key issues in CET is uncertainty measurement of the complex basic belief assignment (CBBA). Previous research on uncertainty measures usually focused on classical probability theories such as belief function assignments, sets, and probability. However, in recent years, research on quantum information has provided a novel thinking direction for the measurement of uncertainty. In this paper, a novel quantum representation of CBBA is proposed based on the density matrix. In addition, a novel quantum belief entropy based on CBBA has been proposed to describe the discord part of uncertainty. In the quantum belief entropy, a concept of quantum interference is introduced to express the quantum effect of element interaction. Furthermore, some properties are analyzed and explained in the paper, and some numerical examples are given to help illustrate the novel measurement of uncertainty.},
  archive      = {J_ISCI},
  author       = {Keming Wu and Fuyuan Xiao},
  doi          = {10.1016/j.ins.2023.119744},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119744},
  shortjournal = {Inf. Sci.},
  title        = {A novel quantum belief entropy for uncertainty measure in complex evidence theory},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Delayed packing attack and countermeasure against
transaction information based applications. <em>ISCI</em>, <em>652</em>,
119742. (<a href="https://doi.org/10.1016/j.ins.2023.119742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the nature of decentralization, blockchain-based applications are gradually adopted by more and more systems in different fields to replace centralized third-party agencies. Many applications, like blockchain oracles, rely on on-chain transactions to deliver information that is used to make final decisions. There have been many methods proposed to guarantee the correctness of the final results , and most of them are in terms of the management of information providers and the application&#39;s design. However, to our notice, only a few works have discussed the security threat caused by rational mining pools that are responsible for packing transactions and information into blocks and uploading them to the blockchain . Therefore in this paper, we propose a possible delayed packing attack carried out by rational mining pools against these transaction information based applications. Game theory analysis is conducted to obtain the Nash equilibrium strategy, and the price of anarchy is calculated to depict the success probability of such an attack under different circumstances. In addition, we design a countermeasure protocol based on cryptography tools to defend against the delayed packing attack. Finally, we carry out a thorough security analysis as well as corresponding experiments to prove the security and feasibility of our countermeasure.},
  archive      = {J_ISCI},
  author       = {Jiliang Li and Yuheng Wang and Yuan Su and Zhou Su and Yuyi Wang and Weizhi Meng and Yinghua Shen},
  doi          = {10.1016/j.ins.2023.119742},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119742},
  shortjournal = {Inf. Sci.},
  title        = {Delayed packing attack and countermeasure against transaction information based applications},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Managing manipulation behavior in hydrogen refueling station
planning by a large group decision making method with hesitant fuzzy
linguistic information. <em>ISCI</em>, <em>652</em>, 119741. (<a
href="https://doi.org/10.1016/j.ins.2023.119741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The selection decision of the hydrogen refueling station construction plan involves professional knowledge in various aspects such as security management, energy storage, and environmental analysis, which requires numerous decision-makers (DMs) from different fields to participate in discussions. In real-world large group decision-making (LGDM), DMs exhibit manipulation behavior for individual interests, which is not conducive to achieving consensus and fairness of decision-making results. Consequently, this article focuses on the management of manipulation behavior and consensus feedback in LGDM with hesitant fuzzy linguistic information . Firstly, to better characterize the hesitation of DMs in the evaluation process, this article improves the primary measurement method of the hesitant fuzzy linguistic term set. Besides, to quantify the degree of manipulation by DMs, an improved manipulation function and anti-manipulation weight function are defined to manage this behavior. Furthermore, a novel consensus feedback mechanism is constructed, combining the optimization model and the trust relationship-based opinion dynamics. Finally, the performance of our proposal is explained through a practical case. And the sensitivity and comparative analyses are provided to explore the impact of manipulation behavior and the merits of our proposal.},
  archive      = {J_ISCI},
  author       = {Peide Liu and Xin Dong and Peng Wang and Runyu Du},
  doi          = {10.1016/j.ins.2023.119741},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119741},
  shortjournal = {Inf. Sci.},
  title        = {Managing manipulation behavior in hydrogen refueling station planning by a large group decision making method with hesitant fuzzy linguistic information},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical fuzzy regression tree: A new gradient boosting
approach to design a TSK fuzzy model. <em>ISCI</em>, <em>652</em>,
119740. (<a href="https://doi.org/10.1016/j.ins.2023.119740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel gradient-boosting-based ensemble system with a fuzzy regression tree (FRT) as its base component for regression tasks . FRT first initializes the rule space as a whole. In each division round, the rule space is supervised to be divided into smaller subspaces using a novel guaranteed membership division method. The consequent parameters are optimized using fuzzy weighted regularized L2 least squares . The FRT corresponding to the minimum MSE is kept as the initial model for the next division round. The above operation is repeated until the FRT reaches the maximum division rounds. Using gradient boosting to train subsequent FRTs to build hierarchical fuzzy regression tree (HFRT). The HFRT can guarantee the high accuracy while ensuring the low complexity of computation, particularly suitable for solving high-dimensional problems. HFRT performed ablation analysis experiments and compared with state-of-the-art algorithms on 28 data sets. The results confirm the effectiveness of the HFRT.},
  archive      = {J_ISCI},
  author       = {Zhen Mei and Tao Zhao and Xiangpeng Xie},
  doi          = {10.1016/j.ins.2023.119740},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119740},
  shortjournal = {Inf. Sci.},
  title        = {Hierarchical fuzzy regression tree: A new gradient boosting approach to design a TSK fuzzy model},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). DDSR: A delay differentiated services routing scheme to
reduce deployment costs for the internet of things. <em>ISCI</em>,
<em>652</em>, 119738. (<a
href="https://doi.org/10.1016/j.ins.2023.119738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-delay and low-cost communication are the main concerns of the wireless sensor-based Internet of Things (IoT), which is widely deployed in various kinds of applications. Adopting wake-up radio (WuR)-enabled wireless sensor nodes can effectively reduce delay, but the deployment costs of the network increase. In this paper, we propose a delay differentiated services routing (DDSR) scheme to reduce the deployment costs for WuR-enabled wireless sensor networks (WSNs). Urgent data prefer to select the awake non-WuR node to forward data. If there is no available awake non-WuR node to forward data at the instant, it will awaken WuR nodes alternatively to maintain a relatively low delay. However, normal data are forwarded by the awake non-WuR node to reduce the number of deployed WuR nodes. Our theoretical analysis results demonstrate that the DDSR scheme can effectively reduce the deployment costs by 93.63%–98.91% while meeting the delay requirement of forwarding urgent data and maintaining a long lifetime.},
  archive      = {J_ISCI},
  author       = {Xiaohuan Liu and Anfeng Liu and Shaobo Zhang and Tian Wang and Neal N. Xiong},
  doi          = {10.1016/j.ins.2023.119738},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119738},
  shortjournal = {Inf. Sci.},
  title        = {DDSR: A delay differentiated services routing scheme to reduce deployment costs for the internet of things},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new recurrent neural network based on direct
discretization method for solving discrete time-variant matrix inversion
with application. <em>ISCI</em>, <em>652</em>, 119729. (<a
href="https://doi.org/10.1016/j.ins.2023.119729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, many researchers have worked hard to find a better way for solving discrete time-variant problems in industrial control science and automation. For example, some researchers propose RNN models to deal with such problems. Typical discrete time-variant problems, such as discrete time-variant matrix inversion , are developed from continuous time-variant problems. In the present paper, an efficient and straightforward method is proposed to solve discrete time-variant matrix inversion, note that it can skip the solving procedures of continuous time-variant problem and solves matrix inversion directly in the discrete time-variant environment. Specifically, an innovative discrete time-variant recurrent neural network (I-DT-RNN) model for dealing with discrete time-variant matrix inversion is proposed, furthermore it is mathematically founded on the second-order Taylor expansion . The theoretical analysis results of I-DT-RNN model are also presented, which proves that the proposed I-DT-RNN model has a reasonable characteristic and also shows that the proposed I-DT-RNN model has an excellent computational performance. Moreover, in the numerical experiments part, we present three different matrices as numerical experiment examples and an application of two-link robot manipulator as an industrial example for validating the practicability of the I-DT-RNN model.},
  archive      = {J_ISCI},
  author       = {Yang Shi and Wei Chong and Wenhan Zhao and Shuai Li and Bin Li and Xiaobing Sun},
  doi          = {10.1016/j.ins.2023.119729},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119729},
  shortjournal = {Inf. Sci.},
  title        = {A new recurrent neural network based on direct discretization method for solving discrete time-variant matrix inversion with application},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consistency and consensus enhancing in group decision making
with interval-valued intuitionistic multiplicative preference relations
based on bounded confidence. <em>ISCI</em>, <em>652</em>, 119727. (<a
href="https://doi.org/10.1016/j.ins.2023.119727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a consensus and consistency enhancing method considering bound confidence for Group Decision-Making (GDM) under interval-valued intuitionistic multiplicative (IVIM) context. First, aiming at the defect that the existing consistency definitions for IVIM preference relations (IVIMPRs) violate the invariance regarding arrangement of the compared objectives’ labels, this study presents a new consistency definition for IVIMPRs. Then, based on the proposed new consistency definition for IVIMPRs, an optimization model is constructed to obtain the consistent IVIMPR. Meanwhile, a new consistency index of an IVIMPR is defined based on the distance between the IVIMPR and the set of consistent IVIMPRs. For the unacceptably consistent IVIMPR, an interactively iterative algorithm considering bounded confidence in its feedback adjustment process is presented to enhance its consistency level . As to GDM with IVIMPRs, an interactively iterative algorithm considering bounded confidence and individual consistency management in its feedback adjustment process is presented to enhance the consensus level among experts. After giving the concept of normalized interval-valued multiplicative priority weight vector , this study puts forward a new method to obtain the IVIM priority weight vector (IVIMPWV). Finally, the feasibility of the method is confirmed by a numerical example and a simulation analysis, and its superiorities are verified by some comparative analyses.},
  archive      = {J_ISCI},
  author       = {Jiu-Ying Dong and Xiao-Yun Lu and He-Cheng Li and Shu-Ping Wan and Shu-Qun Yang},
  doi          = {10.1016/j.ins.2023.119727},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119727},
  shortjournal = {Inf. Sci.},
  title        = {Consistency and consensus enhancing in group decision making with interval-valued intuitionistic multiplicative preference relations based on bounded confidence},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trust evolution based minimum adjustment consensus framework
with dynamic limited compromise behavior for probabilistic linguistic
large scale group decision-making. <em>ISCI</em>, <em>652</em>, 119724.
(<a href="https://doi.org/10.1016/j.ins.2023.119724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To eliminate discrepancies among decision makers’ (DMs’) evaluations, consensus reaching process (CRP) is important in large scale group decision-making (GDM). In CRP, trust relationship can promote the decision group to reach consensus and limited compromise behavior can preserve the original information. However, these two key factors are constant in most of existing studies, which cannot reflect the actual situations . Therefore, this paper explores trust evolution and dynamic limited compromise behavior in CRP for probabilistic linguistic large scale GDM. Firstly, a novel clustering method is proposed to cluster DMs into several subgroups. According to trust degrees among DMs in different subgroups and that in same subgroups, trust degrees among subgroups and confidence degrees of subgroups are defined, respectively. Then, trust evolution model and dynamic limited compromise behavior model are constructed. The trust degree in the next round of adjustment is related to the current trust degree and change of similarity degree, while limited compromise behavior is related to trust degree and confidence degree. Thus, the trust evolution based minimum adjustment consensus framework with dynamic limited compromise behavior is proposed. Finally, the proposed method is applied to an actual example and comparison analyses demonstrate the practicability and superiority of this method.},
  archive      = {J_ISCI},
  author       = {Wen-Chang Zou and Shu-Ping Wan and Jiu-Ying Dong},
  doi          = {10.1016/j.ins.2023.119724},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119724},
  shortjournal = {Inf. Sci.},
  title        = {Trust evolution based minimum adjustment consensus framework with dynamic limited compromise behavior for probabilistic linguistic large scale group decision-making},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A secure and privacy preserved infrastructure for VANETs
based on federated learning with local differential privacy.
<em>ISCI</em>, <em>652</em>, 119717. (<a
href="https://doi.org/10.1016/j.ins.2023.119717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in Vehicular ad-hoc Network (VANET) technology have led to a growing network of interconnected devices, including edge devices, resulting in substantial data generation. The data generated by vehicles is subsequently shared with other devices, such as Roadside Units (RSUs). However, ensuring secure data sharing poses a significant challenge due to the potential risk of data breaches. Recently, Federated Learning (FL) has garnered substantial attention in the research community, enabling data owners to collaboratively learn a shared prediction model while retaining all their training data privately. However, traditional FL-based approaches are susceptible to inference and gradient leakage attacks. This paper presents a framework for private data sharing in VANETs using FL with local differential privacy . In the first layer, vehicles apply local differential privacy techniques to their data before sharing it with the RSU. The second layer is responsible for training model parameters at the RSU and updating the trained weights with the training server. To assess our system&#39;s performance , we evaluate it based on accuracy and simulation time for both local and global parameter sharing. Additionally, we measure each client&#39;s performance by calculating accuracy measures during each iteration. The experimental results demonstrate that our framework not only ensures security against inference and gradient leakage attacks but also exhibits superior efficiency compared to its counterparts.},
  archive      = {J_ISCI},
  author       = {Hajira Batool and Adeel Anjum and Abid Khan and Stefano Izzo and Carlo Mazzocca and Gwanggil Jeon},
  doi          = {10.1016/j.ins.2023.119717},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119717},
  shortjournal = {Inf. Sci.},
  title        = {A secure and privacy preserved infrastructure for VANETs based on federated learning with local differential privacy},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed fuzzy inverse optimal fixed-time control for
uncertain multi-agent systems. <em>ISCI</em>, <em>652</em>, 119670. (<a
href="https://doi.org/10.1016/j.ins.2023.119670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an adaptive fixed-time inverse optimal control strategy for multi-agent systems with unknown dynamics. Instead of directly solving the Hamilton-Jacobi-Bellman equation to obtain the optimal control law, we prove that a meaningful performance function can be minimized by the corresponding controller, which is obtained using the backstepping technique. As a result, the complex solving process is avoided, leading to significant savings in computational resources and learning time. To handle the unknown system dynamics , fuzzy logic systems are employed. Additionally, an auxiliary Lyapunov function is defined, which allows us to deduce that the consensus tracking errors of the multi-agent system converge to a specified region within a fixed time. The efficiency of the proposed method is demonstrated through simulation results.},
  archive      = {J_ISCI},
  author       = {Zhuangbi Lin and Junhe Liu and C.L. Philip Chen and Guanyu Lai and Zongze Wu and Zhi Liu},
  doi          = {10.1016/j.ins.2023.119670},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119670},
  shortjournal = {Inf. Sci.},
  title        = {Distributed fuzzy inverse optimal fixed-time control for uncertain multi-agent systems},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised feature selection based on fuzzy related
family. <em>ISCI</em>, <em>652</em>, 119660. (<a
href="https://doi.org/10.1016/j.ins.2023.119660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current machine learning algorithms encounter challenges such as missing labels and high dimensionality . Feature selection serves as an effective dimensionality reduction technique , enhancing the efficiency and accuracy of subsequent machine learning tasks by eliminating irrelevant and redundant features. Given the difficulty in obtaining fully labeled data, partially labeled data has become a crucial target for machine learning models to address. The related family is an efficient, rough set-based feature selection approach; however, it cannot be applied to semi-supervised learning tasks. Consequently, this paper introduces a semi-supervised feature selection method based on a fuzzy related family for partially labeled data. At first, the fuzzy label values of unlabeled samples are calculated based on fuzzy similarity relationships by establishing a novel fuzzy covering system . Subsequently, a fuzzy related family is constructed by a consistent fuzzy set . Then a semi-supervised feature selection algorithm , referred to as the Semi-supervised Fuzzy Related Family (SFRF), is developed using the established feature significance measurement. Compared to existing semi-supervised feature selection algorithms, SFRF considerably enhances feature selection efficiency while preserving classification accuracy . Specifically, the average reduction efficiency across twelve datasets increased by up to 109 times.},
  archive      = {J_ISCI},
  author       = {Zhijun Guo and Yang Shen and Tian Yang and Yuan-Jiang Li and Yanfang Deng and Yuhua Qian},
  doi          = {10.1016/j.ins.2023.119660},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119660},
  shortjournal = {Inf. Sci.},
  title        = {Semi-supervised feature selection based on fuzzy related family},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EDVAE: Disentangled latent factors models in counterfactual
reasoning for individual treatment effects estimation. <em>ISCI</em>,
<em>652</em>, 119578. (<a
href="https://doi.org/10.1016/j.ins.2023.119578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating individual treatment effect (ITE) from observational data is a crucial but challenging task. Disentangled representations have been used to separate proxy variables into confounding , instrumental, and adjustment variables. However, accurately performing counterfactual reasoning based on observational data to identify ITE remains an open problem. In this paper, we revisit the problem of ITE estimation from both data and model perspectives, shedding light on previously underexplored aspects. Specifically, we investigate the impact of imbalanced data on ITE estimation, highlighting the significance of Assumption-Compliant and Method-Simplicity in handling imbalanced data. From a model perspective, we revisit disentangled representation learning from an information-theoretic standpoint and provide theoretical evidence supporting the effectiveness of the Variational Auto-Encoder (VAE) framework for achieving disentanglement. Leveraging these insights, we propose the EDVAE, a data-driven model for disentangled latent factors . EDVAE comprises three scalable components: an oversampling layer for imbalanced data, a representation layer for disentangled latent factors , and an outcome prediction layer. Experimental results on synthetic and real-world datasets underscore the effectiveness of our proposed method, showcasing its potential for addressing the intricate problem of ITE estimation from observational data. The source code is available at https://github.com/MoranCoder95/EDVAE .},
  archive      = {J_ISCI},
  author       = {Yu Liu and Jian Wang and Bing Li},
  doi          = {10.1016/j.ins.2023.119578},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119578},
  shortjournal = {Inf. Sci.},
  title        = {EDVAE: Disentangled latent factors models in counterfactual reasoning for individual treatment effects estimation},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-reservoir ESN-based prediction strategy for dynamic
multi-objective optimization. <em>ISCI</em>, <em>652</em>, 119495. (<a
href="https://doi.org/10.1016/j.ins.2023.119495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multi-objective optimization problems (DMOPs) have several conflicting and time-varying objectives or constraints. To quickly follow the dynamical Pareto optimal front (POF) of DMOPs, prediction model-based optimization algorithms have been widely studied. However, in most existing prediction-based methods, only the linear relationship of historical solutions is studied, and complex correlations among the decision variables are always ignored. To address this issue, the multi-reservoir ESN (MRESN) based predictor is designed and integrated with the multi-objective evolutionary algorithm based on decomposition (MOEA/D), which is called MRESN-MOEA/D in short. The comprehensive relationship among the previous solutions is derived using the MRESN predictor, whose multi-reservoir structure projects the inputs into the complex echo-state space and enhances the information sharing among the decision variables. To overcome the limitation caused by insufficient training solutions, the fractal interpolation technique is implemented before MRESN training. Then, the trained MRESN predictor is applied to produce the original population for the new environment. Finally, MRESN-MOEA/D is applied in both simulated benchmarks and an actual dynamical wastewater treatment system. The experiment results illustrate that the proposed algorithm outperforms other state-of-the-art methods with better convergence and diversity.},
  archive      = {J_ISCI},
  author       = {Cuili Yang and Danlei Wang and Jian Tang and Junfei Qiao and Wen Yu},
  doi          = {10.1016/j.ins.2023.119495},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {119495},
  shortjournal = {Inf. Sci.},
  title        = {Multi-reservoir ESN-based prediction strategy for dynamic multi-objective optimization},
  volume       = {652},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
