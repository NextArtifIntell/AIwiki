<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NATMI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="natmi---183">NATMI - 183</h2>
<ul>
<li><details>
<summary>
(2024a). Author correction: Predicting equilibrium distributions for
molecular systems with deep learning. <em>NATMI</em>, <em>6</em>(12),
1626. (<a href="https://doi.org/10.1038/s42256-024-00933-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Zheng, Shuxin and He, Jiyan and Liu, Chang and Shi, Yu and Lu, Ziheng and Feng, Weitao and Ju, Fusong and Wang, Jiaxi and Zhu, Jianwei and Min, Yaosen and Zhang, He and Tang, Shidi and Hao, Hongxia and Jin, Peiran and Chen, Chi and Noé, Frank and Liu, Haiguang and Liu, Tie-Yan},
  doi          = {10.1038/s42256-024-00933-4},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1626},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Author correction: Predicting equilibrium distributions for molecular systems with deep learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An interpretable RNA foundation model for exploring
functional RNA motifs in plants. <em>NATMI</em>, <em>6</em>(12),
1616–1625. (<a
href="https://doi.org/10.1038/s42256-024-00946-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex ‘language’ of plant RNA encodes a vast array of biological regulatory elements that orchestrate crucial aspects of plant growth, development and adaptation to environmental stresses. Recent advancements in foundation models (FMs) have demonstrated their unprecedented potential to decipher complex ‘language’ in biology. In this study, we introduced PlantRNA-FM, a high-performance and interpretable RNA FM specifically designed for plants. PlantRNA-FM was pretrained on an extensive dataset, integrating RNA sequences and RNA structure information from 1,124 distinct plant species. PlantRNA-FM exhibits superior performance in plant-specific downstream tasks. PlantRNA-FM achieves an F1 score of 0.974 for genic region annotation, whereas the current best-performing model achieves 0.639. Our PlantRNA-FM is empowered by our interpretable framework that facilitates the identification of biologically functional RNA sequence and structure motifs, including both RNA secondary and tertiary structure motifs across transcriptomes. Through experimental validations, we revealed translation-associated RNA motifs in plants. Our PlantRNA-FM also highlighted the importance of the position information of these functional RNA motifs in genic regions. Taken together, our PlantRNA-FM facilitates the exploration of functional RNA motifs across the complexity of transcriptomes, empowering plant scientists with capabilities for programming RNA codes in plants. Approaches are needed to explore regulatory RNA motifs in plants. An interpretable RNA foundation model is developed, trained on thousands of plant transcriptomes, which achieves superior performance in plant RNA biology tasks and enables the discovery of functional RNA sequence and structure motifs across transcriptomes.},
  archive      = {J_NATMI},
  author       = {Yu, Haopeng and Yang, Heng and Sun, Wenqing and Yan, Zongyun and Yang, Xiaofei and Zhang, Huakun and Ding, Yiliang and Li, Ke},
  doi          = {10.1038/s42256-024-00946-z},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1616-1625},
  shortjournal = {Nat. Mach. Intell.},
  title        = {An interpretable RNA foundation model for exploring functional RNA motifs in plants},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Kernel approximation using analogue in-memory computing.
<em>NATMI</em>, <em>6</em>(12), 1605–1615. (<a
href="https://doi.org/10.1038/s42256-024-00943-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel functions are vital ingredients of several machine learning (ML) algorithms but often incur substantial memory and computational costs. We introduce an approach to kernel approximation in ML algorithms suitable for mixed-signal analogue in-memory computing (AIMC) architectures. Analogue in-memory kernel approximation addresses the performance bottlenecks of conventional kernel-based methods by executing most operations in approximate kernel methods directly in memory. The IBM HERMES project chip, a state-of-the-art phase-change memory-based AIMC chip, is utilized for the hardware demonstration of kernel approximation. Experimental results show that our method maintains high accuracy, with less than a 1% drop in kernel-based ridge classification benchmarks and within 1% accuracy on the long-range arena benchmark for kernelized attention in transformer neural networks. Compared to traditional digital accelerators, our approach is estimated to deliver superior energy efficiency and lower power consumption. These findings highlight the potential of heterogeneous AIMC architectures to enhance the efficiency and scalability of ML applications. A kernel approximation method that enables linear-complexity attention computation via analogue in-memory computing (AIMC) to deliver superior energy efficiency is demonstrated on a multicore AIMC chip.},
  archive      = {J_NATMI},
  author       = {Büchel, Julian and Camposampiero, Giacomo and Vasilopoulos, Athanasios and Lammie, Corey and Le Gallo, Manuel and Rahimi, Abbas and Sebastian, Abu},
  doi          = {10.1038/s42256-024-00943-2},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1605-1615},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Kernel approximation using analogue in-memory computing},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nanobody–antigen interaction prediction with ensemble deep
learning and prompt-based protein language models. <em>NATMI</em>,
<em>6</em>(12), 1594–1604. (<a
href="https://doi.org/10.1038/s42256-024-00940-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nanobodies can provide specific binding to divergent antigens, leading to many promising therapeutic and detection applications in recent years. Traditional technologies of nanobody discovery based on alpaca immunization and phage display are very time-consuming and labour-intensive. Despite recent progress in the study of nanobodies, developing fast and accurate computational tools for nanobody–antigen interaction (NAI) prediction is urgently desirable. Here we propose an ensemble deep learning-based framework named DeepNano-seq to predict general protein–protein interaction (PPI) containing NAI from pure sequence information. Quantitative comparison results show that DeepNano-seq possesses the best cross-species generalization ability among existing PPI algorithms. Nevertheless, several of the most effective PPI methods, including DeepNano-seq, demonstrate suboptimal performance for NAI prediction due to the distinction between NAI and PPI at both the pattern and data levels. Therefore, we organize NAI data from the public database for dedicated NAI modelling. Furthermore, we enhance the prediction pipeline of DeepNano-seq by directing the model’s attention to the antigen-binding sites through a prompt-based approach to present the final DeepNano. The comprehensive evaluation demonstrates that DeepNano performs superiorly in NAI prediction and virtual screening of nanobodies. Overall, DeepNano-seq and DeepNano can offer powerful tools for nanobody discovery. Predicting nanobody–antigen interactions is crucial for advancing nanobody development in drug discovery, but it remains a challenging task. Deng et al. propose DeepNano to enhance the prediction of nanobody–antigen interactions, facilitating virtual screening of target nanobodies.},
  archive      = {J_NATMI},
  author       = {Deng, Juntao and Gu, Miao and Zhang, Pengyan and Dong, Mingyu and Liu, Tao and Zhang, Yabin and Liu, Min},
  doi          = {10.1038/s42256-024-00940-5},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1594-1604},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Nanobody–antigen interaction prediction with ensemble deep learning and prompt-based protein language models},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modulating emotional states of rats through a rat-like robot
with learned interaction patterns. <em>NATMI</em>, <em>6</em>(12),
1580–1593. (<a
href="https://doi.org/10.1038/s42256-024-00939-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots, integrated into biological systems as sociable partners, offer promising advancement in the mechanistic understanding of social behaviours. These biohybrid systems bring controllability to help elucidate the underlying biological intelligence previously inaccessible through traditional techniques. However, state-of-the-art interactive robots still struggle to convey multilevel, heterogeneous information within biological systems, making it challenging to mediate the complex interaction process effectively. Here we propose an autonomous, interactive rat-like robot that can engage with freely behaving rats by learning from the anatomical structure, dynamic motions and social interaction of rats. Imitation learning based on animal demonstration enables the robot with subtle templates of social behaviour, allowing it to capture the attention of rats and significantly arouse their interest. It also integrates visual perception, target tracking and behavioural decisions to substantially augment the interaction efficiency. We demonstrate that the robot can interact with rats for a continuous half-hour. Moreover, the robot can modulate the emotional states of rats through different interaction patterns during robot–rat social interaction. These results attest that the proposed interactive robot, with its long-term and repetitive interaction capabilities, overcomes the limitations of natural social interaction within biological systems. Such biohybrid systems capable of modulating the internal states of organisms may open the door to comprehending the ‘social’ interactions between humans and artificial intelligence. Interactive robots can be used to study animal social behaviour. Imitation learning can be used to enable a rat-like robot to learn subtle templates of social behaviour, demonstrating that it can modulate the emotional states of rats through varied interaction patterns.},
  archive      = {J_NATMI},
  author       = {Jia, Guanglu and Chen, Zhe and Zhang, Yulai and Bing, Zhenshan and Quan, Zhenzhen and Chen, Xuechao and Knoll, Alois and Huang, Qiang and Shi, Qing},
  doi          = {10.1038/s42256-024-00939-y},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1580-1593},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Modulating emotional states of rats through a rat-like robot with learned interaction patterns},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning spatiotemporal dynamics with a pretrained
generative model. <em>NATMI</em>, <em>6</em>(12), 1566–1579. (<a
href="https://doi.org/10.1038/s42256-024-00938-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing spatiotemporal dynamics with sparse sensor measurement is a challenging task that is encountered in a wide spectrum of scientific and engineering applications. The problem is particularly challenging when the number or types of sensors (for example, randomly placed) are extremely sparse. Existing end-to-end learning models ordinarily do not generalize well to unseen full-field reconstruction of spatiotemporal dynamics, especially in sparse data regimes typically seen in real-world applications. To address this challenge, here we propose a sparse-sensor-assisted score-based generative model (S3GM) to reconstruct and predict full-field spatiotemporal dynamics on the basis of sparse measurements. Instead of learning directly the mapping between input and output pairs, an unconditioned generative model is first pretrained, capturing the joint distribution of a vast group of pretraining data in a self-supervised manner, followed by a sampling process conditioned on unseen sparse measurement. The efficacy of S3GM has been verified on multiple dynamical systems with various synthetic, real-world and laboratory-test datasets (ranging from turbulent flow modelling to weather/climate forecasting). The results demonstrate the sound performance of S3GM in zero-shot reconstruction and prediction of spatiotemporal dynamics even with high levels of data sparsity and noise. We find that S3GM exhibits high accuracy, generalizability and robustness when handling different reconstruction tasks. Reconstructing and predicting spatiotemporal dynamics from sparse sensor data is challenging, especially with limited sensors. Li et al. address this by using self-supervised pretraining of a generative model, improving accuracy and generalization.},
  archive      = {J_NATMI},
  author       = {Li, Zeyu and Han, Wang and Zhang, Yue and Fu, Qingfei and Li, Jingxuan and Qin, Lizi and Dong, Ruoyu and Sun, Hao and Deng, Yue and Yang, Lijun},
  doi          = {10.1038/s42256-024-00938-z},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1566-1579},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Learning spatiotemporal dynamics with a pretrained generative model},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for predicting rate-induced tipping.
<em>NATMI</em>, <em>6</em>(12), 1556–1565. (<a
href="https://doi.org/10.1038/s42256-024-00937-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear dynamical systems exposed to changing forcing values can exhibit catastrophic transitions between distinct states. The phenomenon of critical slowing down can help anticipate such transitions if caused by a bifurcation and if the change in forcing is slow compared with the system’s internal timescale. However, in many real-world situations, these assumptions are not met and transitions can be triggered because the forcing exceeds a critical rate. For instance, the rapid pace of anthropogenic climate change compared with the internal timescales of key Earth system components, like polar ice sheets or the Atlantic Meridional Overturning Circulation, poses significant risk of rate-induced tipping. Moreover, random perturbations may cause some trajectories to cross an unstable boundary whereas others do not—even under the same forcing. Critical-slowing-down-based indicators generally cannot distinguish these cases of noise-induced tipping from no tipping. This severely limits our ability to assess the tipping risks and to predict individual trajectories. To address this, we make the first attempt to develop a deep learning framework predicting the transition probabilities of dynamical systems ahead of rate-induced transitions. Our method issues early warnings, as demonstrated on three prototypical systems for rate-induced tipping subjected to time-varying equilibrium drift and noise perturbations. Exploiting explainable artificial intelligence methods, our framework captures the fingerprints for the early detection of rate-induced tipping, even with long lead times. Our findings demonstrate the predictability of rate-induced and noise-induced tipping, advancing our ability to determine safe operating spaces for a broader class of dynamical systems than possible so far. Rate- and noise-induced transitions pose key tipping risks for ecosystems and climate subsystems, yet no predictive theory existed before. This study introduces deep learning as an effective prediction tool for these tipping events.},
  archive      = {J_NATMI},
  author       = {Huang, Yu and Bathiany, Sebastian and Ashwin, Peter and Boers, Niklas},
  doi          = {10.1038/s42256-024-00937-0},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1556-1565},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deep learning for predicting rate-induced tipping},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging ancestral sequence reconstruction for protein
representation learning. <em>NATMI</em>, <em>6</em>(12), 1542–1555. (<a
href="https://doi.org/10.1038/s42256-024-00935-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein language models (PLMs) convert amino acid sequences into the numerical representations required to train machine learning models. Many PLMs are large (&amp;gt;600 million parameters) and trained on a broad span of protein sequence space. However, these models have limitations in terms of predictive accuracy and computational cost. Here we use multiplexed ancestral sequence reconstruction to generate small but focused functional protein sequence datasets for PLM training. Compared to large PLMs, this local ancestral sequence embedding produces representations with higher predictive accuracy. We show that due to the evolutionary nature of the ancestral sequence reconstruction data, local ancestral sequence embedding produces smoother fitness landscapes, in which protein variants that are closer in fitness value become numerically closer in representation space. This work contributes to the implementation of machine learning-based protein design in real-world settings, where data are sparse and computational resources are limited. Matthews et al. present a protein sequence embedding based on data from ancestral sequences that allows machine learning to be used for tasks where training data are scarce or expensive.},
  archive      = {J_NATMI},
  author       = {Matthews, D. S. and Spence, M. A. and Mater, A. C. and Nichols, J. and Pulsford, S. B. and Sandhu, M. and Kaczmarski, J. A. and Miton, C. M. and Tokuriki, N. and Jackson, C. J.},
  doi          = {10.1038/s42256-024-00935-2},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1542-1555},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Leveraging ancestral sequence reconstruction for protein representation learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stable cox regression for survival analysis under
distribution shifts. <em>NATMI</em>, <em>6</em>(12), 1525–1541. (<a
href="https://doi.org/10.1038/s42256-024-00932-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Survival analysis aims to estimate the impact of covariates on the expected time until an event occurs, which is broadly utilized in disciplines such as life sciences and healthcare, substantially influencing decision-making and improving survival outcomes. Existing methods, usually assuming similar training and testing distributions, nevertheless face challenges with real-world varying data sources, creating unpredictable shifts that undermine their reliability. This urgently necessitates that survival analysis methods should utilize stable features across diverse cohorts for predictions, rather than relying on spurious correlations. To this end, we propose a stable Cox model with theoretical guarantees to identify stable variables, which jointly optimizes an independence-driven sample reweighting module and a weighted Cox regression model. Through extensive evaluation on simulated and real-world omics and clinical data, stable Cox not only shows strong generalization ability across diverse independent test sets but also stratifies the subtype of patients significantly with the identified biomarker panels. Survival prediction models used in healthcare usually assume that training and test data share a similar distribution, which is not true in real-world settings. Cui and colleagues develop a stable Cox regression model that can identify stable variables for predicting survival outcomes under distribution shifts.},
  archive      = {J_NATMI},
  author       = {Fan, Shaohua and Xu, Renzhe and Dong, Qian and He, Yue and Chang, Cheng and Cui, Peng},
  doi          = {10.1038/s42256-024-00932-5},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1525-1541},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Stable cox regression for survival analysis under distribution shifts},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluating generalizability of artificial intelligence
models for molecular datasets. <em>NATMI</em>, <em>6</em>(12),
1512–1524. (<a
href="https://doi.org/10.1038/s42256-024-00931-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has made rapid advances in modelling molecular sequencing data. Despite achieving high performance on benchmarks, it remains unclear to what extent deep learning models learn general principles and generalize to previously unseen sequences. Benchmarks traditionally interrogate model generalizability by generating metadata- or sequence similarity-based train and test splits of input data before assessing model performance. Here we show that this approach mischaracterizes model generalizability by failing to consider the full spectrum of cross-split overlap, that is, similarity between train and test splits. We introduce SPECTRA, the spectral framework for model evaluation. Given a model and a dataset, SPECTRA plots model performance as a function of decreasing cross-split overlap and reports the area under this curve as a measure of generalizability. We use SPECTRA with 18 sequencing datasets and phenotypes ranging from antibiotic resistance in tuberculosis to protein–ligand binding and evaluate the generalizability of 19 state-of-the-art deep learning models, including large language models, graph neural networks, diffusion models and convolutional neural networks. We show that sequence similarity- and metadata-based splits provide an incomplete assessment of model generalizability. Using SPECTRA, we find that as cross-split overlap decreases, deep learning models consistently show reduced performance, varying by task and model. Although no model consistently achieved the highest performance across all tasks, deep learning models can, in some cases, generalize to previously unseen sequences on specific tasks. SPECTRA advances our understanding of how foundation models generalize in biological applications. Ektefaie and colleagues introduce the spectral framework for models evaluation (SPECTRA) to measure the generalizability of machine learning models for molecular sequences.},
  archive      = {J_NATMI},
  author       = {Ektefaie, Yasha and Shen, Andrew and Bykova, Daria and Marin, Maximillian G. and Zitnik, Marinka and Farhat, Maha},
  doi          = {10.1038/s42256-024-00931-6},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1512-1524},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Evaluating generalizability of artificial intelligence models for molecular datasets},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal language and graph learning of adsorption
configuration in catalysis. <em>NATMI</em>, <em>6</em>(12), 1501–1511.
(<a href="https://doi.org/10.1038/s42256-024-00930-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adsorption energy is a reactivity descriptor that must be accurately predicted for effective machine learning application in catalyst screening. This process involves finding the lowest energy among different adsorption configurations on a catalytic surface, which often have very similar energies. Although graph neural networks have shown great success in computing the energy of catalyst systems, they rely heavily on atomic spatial coordinates. By contrast, transformer-based language models can directly use human-readable text inputs, potentially bypassing the need for detailed atomic positions or topology; however, these language models often struggle with accurately predicting the energy of adsorption configurations. Our study improves the predictive language model by aligning its latent space with well-established graph neural networks through a self-supervised process called graph-assisted pretraining. This method reduces the mean absolute error of energy prediction for adsorption configurations by 7.4–9.8%, redirecting the model’s attention towards adsorption configuration. Building on this, we propose using generative large language models to create text inputs for the predictive model without relying on exact atomic positions. This demonstrates a potential use case of language models in energy prediction without detailed geometric information. Ock and colleagues explore predictive and generative language models for improving adsorption energy prediction in catalysis without relying on exact atomic positions. The method involves aligning a language model’s latent space with graph neural networks using graph-assisted pretraining.},
  archive      = {J_NATMI},
  author       = {Ock, Janghoon and Badrinarayanan, Srivathsan and Magar, Rishikesh and Antony, Akshay and Barati Farimani, Amir},
  doi          = {10.1038/s42256-024-00930-7},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1501-1511},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Multimodal language and graph learning of adsorption configuration in catalysis},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reshaping the discovery of self-assembling peptides with
generative AI guided by hybrid deep learning. <em>NATMI</em>,
<em>6</em>(12), 1487–1500. (<a
href="https://doi.org/10.1038/s42256-024-00928-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supramolecular peptide-based materials have great potential for revolutionizing fields like nanotechnology and medicine. However, deciphering the intricate sequence-to-assembly pathway, essential for their real-life applications, remains a challenging endeavour. Their discovery relies primarily on empirical approaches that require substantial financial resources, impeding their disruptive potential. Consequently, despite the multitude of characterized self-assembling peptides and their demonstrated advantages, only a few peptide materials have found their way to the market. Machine learning trained on experimentally verified data presents a promising tool for quickly identifying sequences with a high propensity to self-assemble, thereby focusing resource expenditures on the most promising candidates. Here we introduce a framework that implements an accurate classifier in a metaheuristic-based generative model to navigate the search through the peptide sequence space of challenging size. For this purpose, we trained five recurrent neural networks among which the hybrid model that uses sequential information on aggregation propensity and specific physicochemical properties achieved a superior performance with 81.9% accuracy and 0.865 F1 score. Molecular dynamics simulations and experimental validation have confirmed the generative model to be 80–95% accurate in the discovery of self-assembling peptides, outperforming the current state-of-the-art models. The proposed modular framework efficiently complements human intuition in the exploration of self-assembling peptides and presents an important step in the development of intelligent laboratories for accelerated material discovery. A generative model guided by a machine-learning-based classifier capable of assessing unexplored regions of the peptide space in the search for new self-assembling sequences.},
  archive      = {J_NATMI},
  author       = {Njirjak, Marko and Žužić, Lucija and Babić, Marko and Janković, Patrizia and Otović, Erik and Kalafatovic, Daniela and Mauša, Goran},
  doi          = {10.1038/s42256-024-00928-1},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1487-1500},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reshaping the discovery of self-assembling peptides with generative AI guided by hybrid deep learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning for practical quantum error mitigation.
<em>NATMI</em>, <em>6</em>(12), 1478–1486. (<a
href="https://doi.org/10.1038/s42256-024-00927-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computers have progressed towards outperforming classical supercomputers, but quantum errors remain the primary obstacle. In the past few years, the field of quantum error mitigation has provided strategies for overcoming errors in near-term devices, enabling improved accuracy at the cost of additional run time. Through experiments on state-of-the-art quantum computers using up to 100 qubits, we demonstrate that without sacrificing accuracy, machine learning for quantum error mitigation (ML-QEM) drastically reduces the cost of mitigation. We benchmarked ML-QEM using a variety of machine learning models—linear regression, random forest, multilayer perceptron and graph neural networks—on diverse classes of quantum circuits, over increasingly complex device noise profiles, under interpolation and extrapolation, and in both numerics and experiments. These tests employed the popular digital zero-noise extrapolation method as an added reference. Finally, we propose a path towards scalable mitigation using ML-QEM to mimic traditional mitigation methods with superior runtime efficiency. Our results show that classical machine learning can extend the reach and practicality of quantum error mitigation by reducing its overhead and highlight its broader potential for practical quantum computations. Quantum error mitigation improves the accuracy of quantum computers at a computational overhead. Liao et al. demonstrate that classical machine learning models can deliver accuracy comparable to that of conventional techniques while reducing quantum computational costs.},
  archive      = {J_NATMI},
  author       = {Liao, Haoran and Wang, Derek S. and Sitdikov, Iskandar and Salcedo, Ciro and Seif, Alireza and Minev, Zlatko K.},
  doi          = {10.1038/s42256-024-00927-2},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1478-1486},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Machine learning for practical quantum error mitigation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contextual feature extraction hierarchies converge in large
language models and the brain. <em>NATMI</em>, <em>6</em>(12),
1467–1477. (<a
href="https://doi.org/10.1038/s42256-024-00925-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in artificial intelligence have sparked interest in the parallels between large language models (LLMs) and human neural processing, particularly in language comprehension. Although previous research has demonstrated similarities between LLM representations and neural responses, the computational principles driving this convergence—especially as LLMs evolve—remain elusive. Here we used intracranial electroencephalography recordings from neurosurgical patients listening to speech to investigate the alignment between high-performance LLMs and the language-processing mechanisms of the brain. We examined a diverse selection of LLMs with similar parameter sizes and found that as their performance on benchmark tasks improves, they not only become more brain-like, reflected in better neural response predictions from model embeddings, but they also align more closely with the hierarchical feature extraction pathways of the brain, using fewer layers for the same encoding. Additionally, we identified commonalities in the hierarchical processing mechanisms of high-performing LLMs, revealing their convergence towards similar language-processing strategies. Finally, we demonstrate the critical role of contextual information in both LLM performance and brain alignment. These findings reveal converging aspects of language processing in the brain and LLMs, offering new directions for developing models that better align with human cognitive processing. Why brain-like feature extraction emerges in large language models (LLMs) remains elusive. Mischler, Li and colleagues demonstrate that high-performing LLMs not only predict neural responses more accurately than other LLMs but also align more closely with the hierarchical language processing pathway in the brain, revealing parallels between these models and human cognitive mechanisms.},
  archive      = {J_NATMI},
  author       = {Mischler, Gavin and Li, Yinghao Aaron and Bickel, Stephan and Mehta, Ashesh D. and Mesgarani, Nima},
  doi          = {10.1038/s42256-024-00925-4},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1467-1477},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Contextual feature extraction hierarchies converge in large language models and the brain},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reusability report: Exploring the utility of variational
graph encoders for predicting molecular toxicity in drug design.
<em>NATMI</em>, <em>6</em>(12), 1457–1466. (<a
href="https://doi.org/10.1038/s42256-024-00923-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational graph encoders effectively combine graph convolutional networks with variational autoencoders, and have been widely employed for biomedical graph-structured data. Lam and colleagues developed a framework based on the variational graph encoder, NYAN, to facilitate the prediction of molecular properties in computer-assisted drug design. In NYAN, the low-dimensional latent variables derived from the variational graph autoencoder are leveraged as a universal molecular representation, yielding remarkable performance and versatility throughout the drug discovery process. In this study we assess the reusability of NYAN and investigate its applicability within the context of specific chemical toxicity prediction. The prediction accuracy—based on NYAN latent representations and other popular molecular feature representations—is benchmarked across a broad spectrum of toxicity datasets, and the adaptation of NYAN latent representation to other surrogate models is also explored. NYAN, equipped with common surrogate models, shows competitive or better performance in toxicity prediction compared with other state-of-the-art molecular property prediction methods. We also devise a multi-task learning strategy with feature enhancement and consensus inference by leveraging the low dimensionality and feature diversity of NYAN latent space, further boosting the multi-endpoint acute toxicity estimation. The analysis delves into the adaptability of the generic graph variational model, showcasing its aptitude for tailored tasks within the realm of drug discovery. Ruijiang Li et al. assess the reproducibility of a variational graph encoder-based framework and examines its reusability for chemical toxicity prediction. It explores how a generalist model can function as a specialist model with adaptation.},
  archive      = {J_NATMI},
  author       = {Li, Ruijiang and Lu, Jiang and Liu, Ziyi and Yi, Duoyun and Wan, Mengxuan and Zhang, Yixin and Zan, Peng and He, Song and Bo, Xiaochen},
  doi          = {10.1038/s42256-024-00923-6},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1457-1466},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reusability report: Exploring the utility of variational graph encoders for predicting molecular toxicity in drug design},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reply to: Limitations in odour recognition and
generalization in a neuromorphic olfactory circuit. <em>NATMI</em>,
<em>6</em>(12), 1454–1456. (<a
href="https://doi.org/10.1038/s42256-024-00951-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Moyal, Roy and Imam, Nabil and Cleland, Thomas A.},
  doi          = {10.1038/s42256-024-00951-2},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1454-1456},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reply to: Limitations in odour recognition and generalization in a neuromorphic olfactory circuit},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Limitations in odour recognition and generalization in a
neuromorphic olfactory circuit. <em>NATMI</em>, <em>6</em>(12),
1451–1453. (<a
href="https://doi.org/10.1038/s42256-024-00952-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Dennler, Nik and van Schaik, André and Schmuker, Michael},
  doi          = {10.1038/s42256-024-00952-1},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1451-1453},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Limitations in odour recognition and generalization in a neuromorphic olfactory circuit},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reply to: Deeper evaluation of a single-cell foundation
model. <em>NATMI</em>, <em>6</em>(12), 1447–1450. (<a
href="https://doi.org/10.1038/s42256-024-00948-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Yang, Fan and Wang, Fang and Huang, Longkai and Liu, Linjing and Huang, Junzhou and Yao, Jianhua},
  doi          = {10.1038/s42256-024-00948-x},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1447-1450},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reply to: Deeper evaluation of a single-cell foundation model},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deeper evaluation of a single-cell foundation model.
<em>NATMI</em>, <em>6</em>(12), 1443–1446. (<a
href="https://doi.org/10.1038/s42256-024-00949-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Boiarsky, Rebecca and Singh, Nalini M. and Buendia, Alejandro and Amini, Ava P. and Getz, Gad and Sontag, David},
  doi          = {10.1038/s42256-024-00949-w},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1443-1446},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deeper evaluation of a single-cell foundation model},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward a framework for risk mitigation of potential misuse
of artificial intelligence in biomedical research. <em>NATMI</em>,
<em>6</em>(12), 1435–1442. (<a
href="https://doi.org/10.1038/s42256-024-00926-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement of artificial intelligence (AI) in biomedical research presents considerable potential for misuse, including authoritarian surveillance, data misuse, bioweapon development, increase in inequity and abuse of privacy. We propose a multi-pronged framework for researchers to mitigate these risks, looking first to existing ethical frameworks and regulatory measures researchers can adapt to their own work, next to off-the-shelf AI solutions, then to design-specific solutions researchers can build into their AI to mitigate misuse. When researchers remain unable to address the potential for harmful misuse, and the risks outweigh potential benefits, we recommend researchers consider a different approach to answering their research question, or a new research question if the risks remain too great. We apply this framework to three different domains of AI research where misuse is likely to be problematic: (1) AI for drug and chemical discovery; (2) generative models for synthetic data; (3) ambient intelligence. The wide adoption of AI in biomedical research raises concerns about misuse risks. Trotsyuk, Waeiss et al. propose a framework that provides a starting point for researchers to consider how risks specific to their work could be mitigated, using existing ethical frameworks, regulatory measures and off-the-shelf AI solutions.},
  archive      = {J_NATMI},
  author       = {Trotsyuk, Artem A. and Waeiss, Quinn and Bhatia, Raina Talwar and Aponte, Brandon J. and Heffernan, Isabella M. L. and Madgavkar, Devika and Felder, Ryan Marshall and Lehmann, Lisa Soleymani and Palmer, Megan J. and Greely, Hank and Wald, Russell and Goetz, Lea and Trengove, Markus and Vandersluis, Robert and Lin, Herbert and Cho, Mildred K. and Altman, Russ B. and Endy, Drew and Relman, David A. and Levi, Margaret and Satz, Debra and Magnus, David},
  doi          = {10.1038/s42256-024-00926-3},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1435-1442},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Toward a framework for risk mitigation of potential misuse of artificial intelligence in biomedical research},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning at the forefront of detecting tipping points.
<em>NATMI</em>, <em>6</em>(12), 1433–1434. (<a
href="https://doi.org/10.1038/s42256-024-00957-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A deep learning-based method shows promise in issuing early warnings of rate-induced tipping, of particular interest in anticipating effects due to anthropogenic climate change.},
  archive      = {J_NATMI},
  author       = {Deb, Smita and Dutta, Partha Sharathi},
  doi          = {10.1038/s42256-024-00957-w},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1433-1434},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deep learning at the forefront of detecting tipping points},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-decoupling three-axis forces in a simple sensor.
<em>NATMI</em>, <em>6</em>(12), 1431–1432. (<a
href="https://doi.org/10.1038/s42256-024-00941-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A self-decoupling tactile sensor dramatically reduces calibration time for three-dimensional force measurement, scaling from cubic (N³) to linear (3N). This advancement facilitates robotic tactile perception in human–machine interfaces.},
  archive      = {J_NATMI},
  author       = {Yao, Kuanming and Zhuang, Qiuna},
  doi          = {10.1038/s42256-024-00941-4},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1431-1432},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Self-decoupling three-axis forces in a simple sensor},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI in biomaterials discovery: Generating self-assembling
peptides with resource-efficient deep learning. <em>NATMI</em>,
<em>6</em>(12), 1429–1430. (<a
href="https://doi.org/10.1038/s42256-024-00936-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks are efficient and capable agents for discovering new peptides with strong self-organizing capabilities.},
  archive      = {J_NATMI},
  author       = {Leng, Tianang and de la Fuente-Nunez, Cesar},
  doi          = {10.1038/s42256-024-00936-1},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1429-1430},
  shortjournal = {Nat. Mach. Intell.},
  title        = {AI in biomaterials discovery: Generating self-assembling peptides with resource-efficient deep learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Memetic robots. <em>NATMI</em>, <em>6</em>(12), 1427–1428.
(<a href="https://doi.org/10.1038/s42256-024-00959-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social learning is a powerful strategy of adaptation in nature. An interactive rat-like robot that engages in imitation learning with a freely behaving rat opens a way to study social behaviours.},
  archive      = {J_NATMI},
  author       = {Schmickl, Thomas},
  doi          = {10.1038/s42256-024-00959-8},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1427-1428},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Memetic robots},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discussions of machine versus living intelligence need more
clarity. <em>NATMI</em>, <em>6</em>(12), 1424–1426. (<a
href="https://doi.org/10.1038/s42256-024-00955-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sharp distinctions often drawn between machine and biological intelligences have not tracked advances in the fields of developmental biology and hybrid robotics. We call for conceptual clarity driven by the science of diverse intelligences in unconventional spaces and at unfamiliar scales and embodiments that blur conventional categories.},
  archive      = {J_NATMI},
  author       = {Rouleau, Nicolas and Levin, Michael},
  doi          = {10.1038/s42256-024-00955-y},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1424-1426},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Discussions of machine versus living intelligence need more clarity},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Foundation models in healthcare require rethinking
reliability. <em>NATMI</em>, <em>6</em>(12), 1421–1423. (<a
href="https://doi.org/10.1038/s42256-024-00924-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new class of AI models, called foundation models, has entered healthcare. Foundation models violate several basic principles of the standard machine learning paradigm for assessing reliability, making it necessary to rethink what guarantees are required to establish warranted trust in them.},
  archive      = {J_NATMI},
  author       = {Grote, Thomas and Freiesleben, Timo and Berens, Philipp},
  doi          = {10.1038/s42256-024-00924-5},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1421-1423},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Foundation models in healthcare require rethinking reliability},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LLM-based agentic systems in medicine and healthcare.
<em>NATMI</em>, <em>6</em>(12), 1418–1420. (<a
href="https://doi.org/10.1038/s42256-024-00944-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language model-based agentic systems can process input information, plan and decide, recall and reflect, interact and collaborate, leverage various tools and act. This opens up a wealth of opportunities within medicine and healthcare, ranging from clinical workflow automation to multi-agent-aided diagnosis.},
  archive      = {J_NATMI},
  author       = {Qiu, Jianing and Lam, Kyle and Li, Guohao and Acharya, Amish and Wong, Tien Yin and Darzi, Ara and Yuan, Wu and Topol, Eric J.},
  doi          = {10.1038/s42256-024-00944-1},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1418-1420},
  shortjournal = {Nat. Mach. Intell.},
  title        = {LLM-based agentic systems in medicine and healthcare},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Successful implementation of the EU AI act requires
interdisciplinary efforts. <em>NATMI</em>, <em>6</em>(12), 1415–1417.
(<a href="https://doi.org/10.1038/s42256-024-00954-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The EU Artificial Intelligence Act bans certain “subliminal techniques beyond a person’s consciousness”, but uses undefined legal terms. Interdisciplinary efforts are needed to ensure effective implementation of the legal text.},
  archive      = {J_NATMI},
  author       = {Montag, Christian and Finck, Michèle},
  doi          = {10.1038/s42256-024-00954-z},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1415-1417},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Successful implementation of the EU AI act requires interdisciplinary efforts},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards a personalized AI assistant to learn machine
learning. <em>NATMI</em>, <em>6</em>(12), 1413–1414. (<a
href="https://doi.org/10.1038/s42256-024-00953-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Wallisch, Pascal and Sheikh, Ibrahim},
  doi          = {10.1038/s42256-024-00953-0},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1413-1414},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Towards a personalized AI assistant to learn machine learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Clinical large language models with misplaced focus.
<em>NATMI</em>, <em>6</em>(12), 1411–1412. (<a
href="https://doi.org/10.1038/s42256-024-00929-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Luo, Zining and Ma, Haowei and Li, Zhiwu and Chen, Yuquan and Sun, Yixin and Hu, Aimin and Yu, Jiang and Qiao, Yang and Gu, Junxian and Li, Hongying and Peng, Xuxi and Wang, Dunrui and Liu, Ying and Liu, Zhenglong and Xie, Jiebin and Jiang, Zhen and Tian, Gang},
  doi          = {10.1038/s42256-024-00929-0},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1411-1412},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Clinical large language models with misplaced focus},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A plea for caution and guidance about using AI in genomics.
<em>NATMI</em>, <em>6</em>(12), 1409–1410. (<a
href="https://doi.org/10.1038/s42256-024-00947-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Hosseini, Mohammad and Donohue, Christopher R.},
  doi          = {10.1038/s42256-024-00947-y},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1409-1410},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A plea for caution and guidance about using AI in genomics},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Seeking clarity rather than strong opinions on intelligence.
<em>NATMI</em>, <em>6</em>(12), 1408. (<a
href="https://doi.org/10.1038/s42256-024-00968-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clear descriptions of intelligence in both living organisms and machines are essential to avoid confusion, sharpen thinking and guide interdisciplinary research. A Comment in this issue encourages researchers to answer key questions to improve clarity on the terms they use.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-024-00968-7},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1408},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Seeking clarity rather than strong opinions on intelligence},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Strategies needed to counter potential AI misuse.
<em>NATMI</em>, <em>6</em>(12), 1407. (<a
href="https://doi.org/10.1038/s42256-024-00967-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers urgently need more guidance to help them identify and mitigate potential risks when designing projects that involve AI developments.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-024-00967-8},
  journal      = {Nature Machine Intelligence},
  month        = {12},
  number       = {12},
  pages        = {1407},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Strategies needed to counter potential AI misuse},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Results from the autoPET challenge on fully automated lesion
segmentation in oncologic PET/CT imaging. <em>NATMI</em>,
<em>6</em>(11), 1396–1405. (<a
href="https://doi.org/10.1038/s42256-024-00912-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated detection of tumour lesions on positron emission tomography–computed tomography (PET/CT) image data is a clinically relevant but highly challenging task. Progress in this field has been hampered in the past owing to the lack of publicly available annotated data and limited availability of platforms for inter-institutional collaboration. Here we describe the results of the autoPET challenge, a biomedical image analysis challenge aimed to motivate research in the field of automated PET/CT image analysis. The challenge task was the automated segmentation of metabolically active tumour lesions on whole-body 18F-fluorodeoxyglucose PET/CT. Challenge participants had access to a large publicly available annotated PET/CT dataset for algorithm training. All algorithms submitted to the final challenge phase were based on deep learning methods, mostly using three-dimensional U-Net architectures. Submitted algorithms were evaluated on a private test set composed of 150 PET/CT studies from two institutions. An ensemble model of the highest-ranking algorithms achieved favourable performance compared with individual algorithms. Algorithm performance was dependent on the quality and quantity of data and on algorithm design choices, such as tailored post-processing of predicted segmentations. Future iterations of this challenge will focus on generalization and clinical translation. Automating the image analysis process for oncologic whole-body positron emission tomography–computed tomography data is a key area of interest. Gatidis et al. describe the autoPET 2022 challenge, an international competition focused on the segmentation of metabolically active tumour lesions, aiming to advance techniques in the field.},
  archive      = {J_NATMI},
  author       = {Gatidis, Sergios and Früh, Marcel and Fabritius, Matthias P. and Gu, Sijing and Nikolaou, Konstantin and Fougère, Christian La and Ye, Jin and He, Junjun and Peng, Yige and Bi, Lei and Ma, Jun and Wang, Bo and Zhang, Jia and Huang, Yukun and Heiliger, Lars and Marinov, Zdravko and Stiefelhagen, Rainer and Egger, Jan and Kleesiek, Jens and Sibille, Ludovic and Xiang, Lei and Bendazzoli, Simone and Astaraki, Mehdi and Ingrisch, Michael and Cyran, Clemens C. and Küstner, Thomas},
  doi          = {10.1038/s42256-024-00912-9},
  journal      = {Nature Machine Intelligence},
  month        = {11},
  number       = {11},
  pages        = {1396-1405},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Results from the autoPET challenge on fully automated lesion segmentation in oncologic PET/CT imaging},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient generation of protein pockets with PocketGen.
<em>NATMI</em>, <em>6</em>(11), 1382–1395. (<a
href="https://doi.org/10.1038/s42256-024-00920-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing protein-binding proteins is critical for drug discovery. However, artificial-intelligence-based design of such proteins is challenging due to the complexity of protein–ligand interactions, the flexibility of ligand molecules and amino acid side chains, and sequence–structure dependencies. We introduce PocketGen, a deep generative model that produces residue sequence and atomic structure of the protein regions in which ligand interactions occur. PocketGen promotes consistency between protein sequence and structure by using a graph transformer for structural encoding and a sequence refinement module based on a protein language model. The graph transformer captures interactions at multiple scales, including atom, residue and ligand levels. For sequence refinement, PocketGen integrates a structural adapter into the protein language model, ensuring that structure-based predictions align with sequence-based predictions. PocketGen can generate high-fidelity protein pockets with enhanced binding affinity and structural validity. It operates ten times faster than physics-based methods and achieves a 97% success rate, defined as the percentage of generated pockets with higher binding affinity than reference pockets. Additionally, it attains an amino acid recovery rate exceeding 63%. A generative model that leverages a graph transformer and protein language model to generate residue sequences and full-atom structures of protein pockets is introduced, which outperforms state-of-the-art approaches.},
  archive      = {J_NATMI},
  author       = {Zhang, Zaixi and Shen, Wan Xiang and Liu, Qi and Zitnik, Marinka},
  doi          = {10.1038/s42256-024-00920-9},
  journal      = {Nature Machine Intelligence},
  month        = {11},
  number       = {11},
  pages        = {1382-1395},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Efficient generation of protein pockets with PocketGen},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient rare event sampling with unsupervised normalizing
flows. <em>NATMI</em>, <em>6</em>(11), 1370–1381. (<a
href="https://doi.org/10.1038/s42256-024-00918-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From physics and biology to seismology and economics, the behaviour of countless systems is determined by impactful yet unlikely transitions between metastable states known as rare events, the study of which is essential for understanding and controlling the properties of these systems. Classical computational methods to sample rare events remain prohibitively inefficient and are bottlenecks for enhanced samplers that require prior data. Here we introduce a physics-informed machine learning framework, normalizing Flow enhanced Rare Event Sampler (FlowRES), which uses unsupervised normalizing flow neural networks to enhance Monte Carlo sampling of rare events by generating high-quality non-local Monte Carlo proposals. We validated FlowRES by sampling the transition path ensembles of equilibrium and non-equilibrium systems of Brownian particles, exploring increasingly complex potentials. Beyond eliminating the requirements for prior data, FlowRES features key advantages over established samplers: no collective variables need to be defined, efficiency remains constant even as events become increasingly rare and systems with multiple routes between states can be straightforwardly simulated. Sampling rare events is key to various fields of science, but current methods are inefficient. Asghar and colleagues propose a rare event sampler based on normalizing flow neural networks that requires no prior data or collective variables, works at and out of equilibrium and keeps efficiency constant as events become rarer.},
  archive      = {J_NATMI},
  author       = {Asghar, Solomon and Pei, Qing-Xiang and Volpe, Giorgio and Ni, Ran},
  doi          = {10.1038/s42256-024-00918-3},
  journal      = {Nature Machine Intelligence},
  month        = {11},
  number       = {11},
  pages        = {1370-1381},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Efficient rare event sampling with unsupervised normalizing flows},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging language model for advanced multiproperty
molecular optimization via prompt engineering. <em>NATMI</em>,
<em>6</em>(11), 1359–1369. (<a
href="https://doi.org/10.1038/s42256-024-00916-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing a candidate molecule’s physiochemical and functional properties has been a critical task in drug and material design. Although the non-trivial task of balancing multiple (potentially conflicting) optimization objectives is considered ideal for artificial intelligence, several technical challenges such as the scarcity of multiproperty-labelled training data have hindered the development of a satisfactory AI solution for a long time. Prompt-MolOpt is a tool for molecular optimization; it makes use of prompt-based embeddings, as used in large language models, to improve the transformer’s ability to optimize molecules for specific property adjustments. Notably, Prompt-MolOpt excels in working with limited multiproperty data (even under the zero-shot setting) by effectively generalizing causal relationships learned from single-property datasets. In comparative evaluations against established models such as JTNN, hierG2G and Modof, Prompt-MolOpt achieves over a 15% relative improvement in multiproperty optimization success rates compared with the leading Modof model. Furthermore, a variant of Prompt-MolOpt, named Prompt-MolOptP, can preserve the pharmacophores or any user-specified fragments under the structural transformation, further broadening its application scope. By constructing tailored optimization datasets, with the protocol introduced in this work, Prompt-MolOpt steers molecular optimization towards domain-relevant chemical spaces, enhancing the quality of the optimized molecules. Real-world tests, such as those involving blood–brain barrier permeability optimization, underscore its practical relevance. Prompt-MolOpt offers a versatile approach for multiproperty and multi-site molecular optimizations, suggesting its potential utility in chemistry research and drug and material discovery. Designing molecules in drug design is challenging as it requires optimizing multiple, potentially competing qualities. Wu and colleagues present a prompt-based molecule optimization method that can be trained from single-property data.},
  archive      = {J_NATMI},
  author       = {Wu, Zhenxing and Zhang, Odin and Wang, Xiaorui and Fu, Li and Zhao, Huifeng and Wang, Jike and Du, Hongyan and Jiang, Dejun and Deng, Yafeng and Cao, Dongsheng and Hsieh, Chang-Yu and Hou, Tingjun},
  doi          = {10.1038/s42256-024-00916-5},
  journal      = {Nature Machine Intelligence},
  month        = {11},
  number       = {11},
  pages        = {1359-1369},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Leveraging language model for advanced multiproperty molecular optimization via prompt engineering},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Epitope-anchored contrastive transfer learning for paired
CD8+ t cell receptor–antigen recognition. <em>NATMI</em>,
<em>6</em>(11), 1344–1358. (<a
href="https://doi.org/10.1038/s42256-024-00913-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the mechanisms of T cell antigen recognition that underpin adaptive immune responses is critical for developing vaccines, immunotherapies and treatments against autoimmune diseases. Despite extensive research efforts, accurate prediction of T cell receptor (TCR)–antigen binding pairs remains a great challenge due to the vast diversity and cross-reactivity of TCRs. Here we propose a deep-learning-based framework termed epitope-anchored contrastive transfer learning (EPACT) tailored to paired human CD8+ TCRs. Harnessing the pretrained representations and co-embeddings of peptide–major histocompatibility complex (pMHC) and TCR, EPACT demonstrated generalizability in predicting binding specificity for unseen epitopes and distinct TCR repertoires. Contrastive learning enabled highly precise predictions for immunodominant epitopes and interpretable analysis of epitope-specific T cells. We applied EPACT to SARS-CoV-2-responsive T cells, and the predicted binding strength aligned well with the surge in spike-specific immune responses after vaccination. We further fine-tuned EPACT on structural data to decipher the residue-level interactions involved in TCR–antigen recognition. EPACT was capable of quantifying interchain distance matrices and identifying contact residues, corroborating the presence of TCR cross-reactivity across multiple tumour-associated antigens. Together, EPACT can serve as a useful artificial intelligence approach with important potential in practical applications and contribute towards the development of TCR-based immunotherapies. Accurate prediction of T cell receptor (TCR)–antigen recognition remains a challenge. Zhang et al. propose a contrastive transfer learning model to predict TCR–pMHC binding that enables interpretable analyses of epitope-specific T cells and can decipher residue-level interactions.},
  archive      = {J_NATMI},
  author       = {Zhang, Yumeng and Wang, Zhikang and Jiang, Yunzhe and Littler, Dene R. and Gerstein, Mark and Purcell, Anthony W. and Rossjohn, Jamie and Ou, Hong-Yu and Song, Jiangning},
  doi          = {10.1038/s42256-024-00913-8},
  journal      = {Nature Machine Intelligence},
  month        = {11},
  number       = {11},
  pages        = {1344-1358},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Epitope-anchored contrastive transfer learning for paired CD8+ t cell receptor–antigen recognition},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast and generalizable micromagnetic simulation with deep
neural nets. <em>NATMI</em>, <em>6</em>(11), 1330–1343. (<a
href="https://doi.org/10.1038/s42256-024-00914-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Important progress has been made in micromagnetics, driven by its wide-ranging applications in magnetic storage design. Numerical simulation, a cornerstone of micromagnetics research, relies on first-principles rules to compute the dynamic evolution of micromagnetic systems using the renowned Landau–Lifshitz–Gilbert equation, named after Landau, Lifshitz and Gilbert. However, these simulations are often hindered by their slow speeds. Although fast Fourier transformation calculations reduce the computational complexity to O(Nlog(N)), it remains impractical for large-scale simulations. Here we introduce NeuralMAG, a deep learning approach to micromagnetic simulation. Our approach follows the Landau–Lifshitz–Gilbert iterative framework but accelerates computation of demagnetizing fields by employing a U-shaped neural network. This neural network architecture comprises an encoder that extracts aggregated spins at various scales and learns the local interaction at each scale, followed by a decoder that accumulates the local interactions at different scales to approximate the global convolution. This divide-and-accumulate scheme achieves a time complexity of O(N), notably enhancing the speed and feasibility of large-scale simulations. Unlike existing neural methods, NeuralMAG concentrates on the core computation—rather than an end-to-end approximation for a specific task—making it inherently generalizable. To validate the new approach, we trained a single model and evaluated it on two micromagnetics tasks with various sample sizes, shapes and material settings. Many physical systems involve long-range interactions, which present a considerable obstacle to large-scale simulations. Cai, Li and Wang introduce NeuralMAG, a deep learning approach to reduce complexity and accelerate micromagnetic simulations.},
  archive      = {J_NATMI},
  author       = {Cai, Yunqi and Li, Jiangnan and Wang, Dong},
  doi          = {10.1038/s42256-024-00914-7},
  journal      = {Nature Machine Intelligence},
  month        = {11},
  number       = {11},
  pages        = {1330-1343},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Fast and generalizable micromagnetic simulation with deep neural nets},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning prediction of ribosome profiling with
translatomer reveals translational regulation and interprets disease
variants. <em>NATMI</em>, <em>6</em>(11), 1314–1329. (<a
href="https://doi.org/10.1038/s42256-024-00915-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gene expression involves transcription and translation. Despite large datasets and increasingly powerful methods devoted to calculating genetic variants’ effects on transcription, discrepancy between messenger RNA and protein levels hinders the systematic interpretation of the regulatory effects of disease-associated variants. Accurate models of the sequence determinants of translation are needed to close this gap and to interpret disease-associated variants that act on translation. Here we present Translatomer, a multimodal transformer framework that predicts cell-type-specific translation from messenger RNA expression and gene sequence. We train the Translatomer on 33 tissues and cell lines, and show that the inclusion of sequence improves the prediction of ribosome profiling signal, indicating that the Translatomer captures sequence-dependent translational regulatory information. The Translatomer achieves accuracies of 0.72 to 0.80 for the de novo prediction of cell-type-specific ribosome profiling. We develop an in silico mutagenesis tool to estimate mutational effects on translation and demonstrate that variants associated with translation regulation are evolutionarily constrained, both in the human population and across species. In particular, we identify cell-type-specific translational regulatory mechanisms independent of the expression quantitative trait loci for 3,041 non-coding and synonymous variants associated with complex diseases, including Alzheimer’s disease, schizophrenia and congenital heart disease. The Translatomer accurately models the genetic underpinnings of translation, bridging the gap between messenger RNA and protein levels as well as providing valuable mechanistic insights for uninterpreted disease variants. A transformer-based approach called Translatomer is presented, which models cell-type-specific translation from messenger RNA expression and gene sequence, bridging the gap between messenger RNA and protein levels as well as providing a mechanistic insight into the genetic regulation of translation.},
  archive      = {J_NATMI},
  author       = {He, Jialin and Xiong, Lei and Shi, Shaohui and Li, Chengyu and Chen, Kexuan and Fang, Qianchen and Nan, Jiuhong and Ding, Ke and Mao, Yuanhui and Boix, Carles A. and Hu, Xinyang and Kellis, Manolis and Li, Jingyun and Xiong, Xushen},
  doi          = {10.1038/s42256-024-00915-6},
  journal      = {Nature Machine Intelligence},
  month        = {11},
  number       = {11},
  pages        = {1314-1329},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deep learning prediction of ribosome profiling with translatomer reveals translational regulation and interprets disease variants},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blending neural operators and relaxation methods in PDE
numerical solvers. <em>NATMI</em>, <em>6</em>(11), 1303–1313. (<a
href="https://doi.org/10.1038/s42256-024-00910-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks suffer from spectral bias and have difficulty representing the high-frequency components of a function, whereas relaxation methods can resolve high frequencies efficiently but stall at moderate to low frequencies. We exploit the weaknesses of the two approaches by combining them synergistically to develop a fast numerical solver of partial differential equations (PDEs) at scale. Specifically, we propose HINTS, a hybrid, iterative, numerical and transferable solver by integrating a Deep Operator Network (DeepONet) with standard relaxation methods, leading to parallel efficiency and algorithmic scalability for a wide class of PDEs, not tractable with existing monolithic solvers. HINTS balances the convergence behaviour across the spectrum of eigenmodes by utilizing the spectral bias of DeepONet, resulting in a uniform convergence rate and hence exceptional performance of the hybrid solver overall. Moreover, HINTS applies to large-scale, multidimensional systems; it is flexible with regards to discretizations, computational domain and boundary conditions; and it can also be used to precondition Krylov methods. Neural-network-based solvers for partial differential equations (PDEs) suffer from difficulties tackling high-frequency modes when learning complex functions, whereas for classical solvers it is more difficult to handle low-frequency modes. Zhang and colleagues propose a hybrid numerical PDE solver by combining a Deep Operator Network with traditional relaxation methods, leading to balanced convergence across the eigenmode spectrum for a wide range of PDEs.},
  archive      = {J_NATMI},
  author       = {Zhang, Enrui and Kahana, Adar and Kopaničáková, Alena and Turkel, Eli and Ranade, Rishikesh and Pathak, Jay and Karniadakis, George Em},
  doi          = {10.1038/s42256-024-00910-x},
  journal      = {Nature Machine Intelligence},
  month        = {11},
  number       = {11},
  pages        = {1303-1313},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Blending neural operators and relaxation methods in PDE numerical solvers},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reusability report: Annotating metabolite mass spectra with
domain-inspired chemical formula transformers. <em>NATMI</em>,
<em>6</em>(11), 1296–1302. (<a
href="https://doi.org/10.1038/s42256-024-00909-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an in-depth exploration of the Metabolite Inference with Spectrum Transformers (MIST) tool for annotating small-molecule mass spectrometry (MS) data, focusing on its reproducibility and generalizability. MIST innovates by integrating a ‘chemical formula transformer’ to process tandem MS spectra, aiming to bridge the substantial knowledge gap in untargeted MS studies, in which only a fraction of spectra are confidently annotated. Here we critically assessed the reproducibility of MIST by following the tool’s original training and testing protocols, encountering minor challenges but largely succeeding in replicating the results. We also evaluated the generalizability of MIST by applying it to an external dataset from the Critical Assessment of Small Molecule Identification 2022 challenge, showing insights into the model’s performance on previously unseen data. An ablation study further investigated the impact of various model features on database retrieval performance, suggesting that some algorithmic complexities may not significantly enhance the performance. Through rigorous evaluation, this study underscores the challenges and considerations in developing robust computational tools for MS data analysis. We advocate community-wide efforts in benchmarking, transparency and data sharing to foster advancements in metabolomics and computational biology. In this Reusability Report, Heirman and Bittremieux evaluate MIST, a tool for annotating small-molecule mass spectrometry data, focusing on reproducibility and generalizability. They call for community efforts in benchmarking, transparency and data sharing to advance metabolomics research.},
  archive      = {J_NATMI},
  author       = {Heirman, Janne and Bittremieux, Wout},
  doi          = {10.1038/s42256-024-00909-4},
  journal      = {Nature Machine Intelligence},
  month        = {11},
  number       = {11},
  pages        = {1296-1302},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reusability report: Annotating metabolite mass spectra with domain-inspired chemical formula transformers},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A soft skin with self-decoupled three-axis force-sensing
taxels. <em>NATMI</em>, <em>6</em>(11), 1284–1295. (<a
href="https://doi.org/10.1038/s42256-024-00904-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic skins integrating both normal and shear force per taxel have a wide range of applications across diverse fields, including robotics, haptics and health monitoring. Current multi-axis tactile sensors often present complexities in structure and fabrication or require an extensive calibration process, limiting their widespread applications. Here we report an electronic soft magnetic skin capable of self-decoupling three-axis forces at each taxel. We use a simple sensor structure with customizable sensitivity and measurement range, reducing the calibration complexity from known quadratic (N2) or cubic (N3) scales down to a linear (3N) scale. The three-axis self-decoupling property of the sensor is achieved by overlaying two sinusoidally magnetized flexible magnetic films with orthogonal magnetization patterns. Leveraging the self-decoupling feature and its simple structure, we demonstrate that our sensor can facilitate a diverse range of applications, such as measuring the three-dimensional force distribution in artificial knee joints, teaching robots by touch demonstration and monitoring the interaction forces between knee braces and human skin during various activities. Electronic skin with decoupled force feedback is essential in robotics. Yan et al. develop a soft magnetic skin capable of self-decoupling three-axis forces per taxel, reducing calibration complexity from quadratic or cubic scales to a linear scale.},
  archive      = {J_NATMI},
  author       = {Yan, Youcan and Zermane, Ahmed and Pan, Jia and Kheddar, Abderrahmane},
  doi          = {10.1038/s42256-024-00904-9},
  journal      = {Nature Machine Intelligence},
  month        = {11},
  number       = {11},
  pages        = {1284-1295},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A soft skin with self-decoupled three-axis force-sensing taxels},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). General-purpose foundation models for increased autonomy in
robot-assisted surgery. <em>NATMI</em>, <em>6</em>(11), 1275–1283. (<a
href="https://doi.org/10.1038/s42256-024-00917-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dominant paradigm for end-to-end robot learning focuses on optimizing task-specific objectives that solve a single robotic problem such as picking up an object or reaching a target position. However, recent work on high-capacity models in robotics has shown promise towards being trained on large collections of diverse and task-agnostic datasets of video demonstrations. These models have shown impressive levels of generalization to unseen circumstances, especially as the amount of data and the model complexity scale. Surgical robot systems that learn from data have struggled to advance as quickly as other fields of robot learning for a few reasons: there is a lack of existing large-scale open-source data to train models; it is challenging to model the soft-body deformations that these robots work with during surgery because simulation cannot match the physical and visual complexity of biological tissue; and surgical robots risk harming patients when tested in clinical trials and require more extensive safety measures. This Perspective aims to provide a path towards increasing robot autonomy in robot-assisted surgery through the development of a multi-modal, multi-task, vision–language–action model for surgical robots. Ultimately, we argue that surgical robots are uniquely positioned to benefit from general-purpose models and provide four guiding actions towards increased autonomy in robot-assisted surgery. Schmidgall et al. describe a pathway for building general-purpose machine learning models for robot-assisted surgery, including mechanisms for avoiding risk and handing over control to surgeons, and improving safety and outcomes beyond demonstration data.},
  archive      = {J_NATMI},
  author       = {Schmidgall, Samuel and Kim, Ji Woong and Kuntz, Alan and Ghazi, Ahmed Ezzat and Krieger, Axel},
  doi          = {10.1038/s42256-024-00917-4},
  journal      = {Nature Machine Intelligence},
  month        = {11},
  number       = {11},
  pages        = {1275-1283},
  shortjournal = {Nat. Mach. Intell.},
  title        = {General-purpose foundation models for increased autonomy in robot-assisted surgery},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guidelines for ethical use and acknowledgement of large
language models in academic writing. <em>NATMI</em>, <em>6</em>(11),
1272–1274. (<a
href="https://doi.org/10.1038/s42256-024-00922-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this Comment, we propose a cumulative set of three essential criteria for the ethical use of LLMs in academic writing, and present a statement that researchers can quote when submitting LLM-assisted manuscripts in order to testify to their adherence to them.},
  archive      = {J_NATMI},
  author       = {Porsdam Mann, Sebastian and Vazirani, Anuraag A. and Aboy, Mateo and Earp, Brian D. and Minssen, Timo and Cohen, I. Glenn and Savulescu, Julian},
  doi          = {10.1038/s42256-024-00922-7},
  journal      = {Nature Machine Intelligence},
  month        = {11},
  number       = {11},
  pages        = {1272-1274},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Guidelines for ethical use and acknowledgement of large language models in academic writing},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI pioneers win 2024 nobel prizes. <em>NATMI</em>,
<em>6</em>(11), 1271. (<a
href="https://doi.org/10.1038/s42256-024-00945-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 2024 Nobel prizes in physics and chemistry highlight the interdisciplinary nature and impact of AI in science.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-024-00945-0},
  journal      = {Nature Machine Intelligence},
  month        = {11},
  number       = {11},
  pages        = {1271},
  shortjournal = {Nat. Mach. Intell.},
  title        = {AI pioneers win 2024 nobel prizes},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Author correction: Integrated structure prediction of
protein–protein docking with experimental restraints using ColabDock.
<em>NATMI</em>, <em>6</em>(10), 1270. (<a
href="https://doi.org/10.1038/s42256-024-00905-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Feng, Shihao and Chen, Zhenyu and Zhang, Chengwei and Xie, Yuhao and Ovchinnikov, Sergey and Gao, Yi Qin and Liu, Sirui},
  doi          = {10.1038/s42256-024-00905-8},
  journal      = {Nature Machine Intelligence},
  month        = {10},
  number       = {10},
  pages        = {1270},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Author correction: Integrated structure prediction of protein–protein docking with experimental restraints using ColabDock},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weak baselines and reporting biases lead to overoptimism in
machine learning for fluid-related partial differential equations.
<em>NATMI</em>, <em>6</em>(10), 1256–1269. (<a
href="https://doi.org/10.1038/s42256-024-00897-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most promising applications of machine learning in computational physics is to accelerate the solution of partial differential equations (PDEs). The key objective of machine-learning-based PDE solvers is to output a sufficiently accurate solution faster than standard numerical methods, which are used as a baseline comparison. We first perform a systematic review of the ML-for-PDE-solving literature. Out of all of the articles that report using ML to solve a fluid-related PDE and claim to outperform a standard numerical method, we determine that 79% (60/76) make a comparison with a weak baseline. Second, we find evidence that reporting biases are widespread, especially outcome reporting and publication biases. We conclude that ML-for-PDE-solving research is overoptimistic: weak baselines lead to overly positive results, while reporting biases lead to under-reporting of negative results. To a large extent, these issues seem to be caused by factors similar to those of past reproducibility crises: researcher degrees of freedom and a bias towards positive results. We call for bottom-up cultural changes to minimize biased reporting as well as top-down structural reforms to reduce perverse incentives for doing so. A systematic review of machine learning approaches to solve partial differential equations related to fluid dynamics highlights concerns about reproducibility and indicates that studies in this area have reached overly optimistic conclusions.},
  archive      = {J_NATMI},
  author       = {McGreivy, Nick and Hakim, Ammar},
  doi          = {10.1038/s42256-024-00897-5},
  journal      = {Nature Machine Intelligence},
  month        = {10},
  number       = {10},
  pages        = {1256-1269},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Weak baselines and reporting biases lead to overoptimism in machine learning for fluid-related partial differential equations},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-modal deep language model for contaminant removal
from metagenome-assembled genomes. <em>NATMI</em>, <em>6</em>(10),
1245–1255. (<a
href="https://doi.org/10.1038/s42256-024-00908-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metagenome-assembled genomes (MAGs) offer valuable insights into the exploration of microbial dark matter using metagenomic sequencing data. However, there is growing concern that contamination in MAGs may substantially affect the results of downstream analysis. Current MAG decontamination tools primarily rely on marker genes and do not fully use the contextual information of genomic sequences. To overcome this limitation, we introduce Deepurify for MAG decontamination. Deepurify uses a multi-modal deep language model with contrastive learning to match microbial genomic sequences with their taxonomic lineages. It allocates contigs within a MAG to a MAG-separated tree and applies a tree traversal algorithm to partition MAGs into sub-MAGs, with the goal of maximizing the number of high- and medium-quality sub-MAGs. Here we show that Deepurify outperformed MDMclearer and MAGpurify on simulated data, CAMI datasets and real-world datasets with varying complexities. Deepurify increased the number of high-quality MAGs by 20.0% in soil, 45.1% in ocean, 45.5% in plants, 33.8% in freshwater and 28.5% in human faecal metagenomic sequencing datasets. Metagenome-assembled genomes (MAGs) provide insights into microbial dark matter, but contamination remains a concern for downstream analysis. Zou et al. develop a multi-modal deep language model that leverages microbial sequences to remove ‘unexpected’ contigs from MAGs. This approach is compatible with any contig binning tools and increases the number of high-quality bins.},
  archive      = {J_NATMI},
  author       = {Zou, Bohao and Wang, Jingjing and Ding, Yi and Zhang, Zhenmiao and Huang, Yufen and Fang, Xiaodong and Cheung, Ka Chun and See, Simon and Zhang, Lu},
  doi          = {10.1038/s42256-024-00908-5},
  journal      = {Nature Machine Intelligence},
  month        = {10},
  number       = {10},
  pages        = {1245-1255},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A multi-modal deep language model for contaminant removal from metagenome-assembled genomes},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimation of causal effects of genes on complex traits
using a bayesian-network-based framework applied to GWAS data.
<em>NATMI</em>, <em>6</em>(10), 1231–1244. (<a
href="https://doi.org/10.1038/s42256-024-00906-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deciphering the relationships between genes and complex traits can enhance our understanding of phenotypic variations and disease mechanisms. However, determining the specific roles of individual genes and quantifying their direct and indirect causal effects on complex traits remains a significant challenge. Here we present a framework (called Bayesian network genome-wide association studies (BN-GWAS)) to decipher the total and direct causal effects of individual genes. BN-GWAS leverages imputed expression profiles from GWAS and raw expression data from a reference dataset to construct a directed gene–gene–phenotype causal network. It allows gene expression and disease traits to be evaluated in different samples, significantly improving the flexibility and applicability of the approach. It can be extended to decipher the joint causal network of two or more traits, and exhibits high specificity and precision (positive predictive value), making it particularly useful for selecting genes for follow-up studies. We verified the feasibility and validity of BN-GWAS by extensive simulations and applications to 52 traits across 14 tissues in the UK Biobank, revealing insights into their genetic architectures, including the relative contributions of direct, indirect and mediating causal genes. The identified (direct) causal genes were significantly enriched for genes highlighted in the Open Targets database. Overall, BN-GWAS provides a flexible and powerful framework for elucidating the genetic basis of complex traits through a systems-level, causal inference approach. Genome-wide association studies generate extensive data, but interpreting these data remains challenging. A Bayesian-network-based method is presented that uses imputed and raw gene expression data to decipher the causal effects of individual genes.},
  archive      = {J_NATMI},
  author       = {Yin, Liangying and Feng, Yaning and Shi, Yujia and Lau, Alexandria and Qiu, Jinghong and Sham, Pak-Chung and So, Hon-Cheong},
  doi          = {10.1038/s42256-024-00906-7},
  journal      = {Nature Machine Intelligence},
  month        = {10},
  number       = {10},
  pages        = {1231-1244},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Estimation of causal effects of genes on complex traits using a bayesian-network-based framework applied to GWAS data},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sliding-attention transformer neural architecture for
predicting t cell receptor–antigen–human leucocyte antigen binding.
<em>NATMI</em>, <em>6</em>(10), 1216–1230. (<a
href="https://doi.org/10.1038/s42256-024-00901-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neoantigens are promising targets for immunotherapy by eliciting immune response and removing cancer cells with high specificity, low toxicity and ease of personalization. However, identifying effective neoantigens remains difficult because of the complex interactions among T cell receptors, antigens and human leucocyte antigen sequences. In this study, we integrate important physical and biological priors with the Transformer model and propose the physics-inspired sliding transformer (PISTE). In PISTE, the conventional, data-driven attention mechanism is replaced with physics-driven dynamics that steers the positioning of amino acid residues along the gradient field of their interactions. This allows navigating the intricate landscape of biosequence interactions intelligently, leading to improved accuracy in T cell receptor–antigen–human leucocyte antigen binding prediction and robust generalization to rare sequences. Furthermore, PISTE effectively recovers residue-level contact relationships even in the absence of three-dimensional structure training data. We applied PISTE in a multitude of immunogenic tumour types to pinpoint neoantigens and discern neoantigen-reactive T cells. In a prospective study of prostate cancer, 75% of the patients elicited immune responses through PISTE-predicted neoantigens. Predicting TCR–antigen–human leucocyte antigen binding opens the door to neoantigen identification. In this study, a physics-inspired sliding transformer (PISTE) system is used to guide the positioning of amino acid residues along the gradient field of their interactions, boosting binding prediction accuracy.},
  archive      = {J_NATMI},
  author       = {Feng, Ziyan and Chen, Jingyang and Hai, Youlong and Pang, Xuelian and Zheng, Kun and Xie, Chenglong and Zhang, Xiujuan and Li, Shengqing and Zhang, Chengjuan and Liu, Kangdong and Zhu, Lili and Hu, Xiaoyong and Li, Shiliang and Zhang, Jie and Zhang, Kai and Li, Honglin},
  doi          = {10.1038/s42256-024-00901-y},
  journal      = {Nature Machine Intelligence},
  month        = {10},
  number       = {10},
  pages        = {1216-1230},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Sliding-attention transformer neural architecture for predicting t cell receptor–antigen–human leucocyte antigen binding},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of AI-assisted microscopy frameworks through
realistic simulation with pySTED. <em>NATMI</em>, <em>6</em>(10),
1197–1215. (<a
href="https://doi.org/10.1038/s42256-024-00903-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of artificial intelligence into microscopy systems significantly enhances performance, optimizing both image acquisition and analysis phases. Development of artificial intelligence-assisted super-resolution microscopy is often limited by access to large biological datasets, as well as by difficulties to benchmark and compare approaches on heterogeneous samples. We demonstrate the benefits of a realistic stimulated emission depletion microscopy simulation platform, pySTED, for the development and deployment of artificial intelligence strategies for super-resolution microscopy. pySTED integrates theoretically and empirically validated models for photobleaching and point spread function generation in stimulated emission depletion microscopy, as well as simulating realistic point-scanning dynamics and using a deep learning model to replicate the underlying structures of real images. This simulation environment can be used for data augmentation to train deep neural networks, for the development of online optimization strategies and to train reinforcement learning models. Using pySTED as a training environment allows the reinforcement learning models to bridge the gap between simulation and reality, as showcased by its successful deployment on a real microscope system without fine tuning. Stimulated emission depletion microscopy is a super-resolution imaging technique that utilizes point scanning in fluorescence microscopy. pySTED is developed to aid in the development and benchmarking of optical microscopy experiments, testing it in both synthetic and real settings.},
  archive      = {J_NATMI},
  author       = {Bilodeau, Anthony and Michaud-Gagnon, Albert and Chabbert, Julia and Turcotte, Benoit and Heine, Jörn and Durand, Audrey and Lavoie-Cardinal, Flavie},
  doi          = {10.1038/s42256-024-00903-w},
  journal      = {Nature Machine Intelligence},
  month        = {10},
  number       = {10},
  pages        = {1197-1215},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Development of AI-assisted microscopy frameworks through realistic simulation with pySTED},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Engineering flexible machine learning systems by traversing
functionally invariant paths. <em>NATMI</em>, <em>6</em>(10), 1179–1196.
(<a href="https://doi.org/10.1038/s42256-024-00902-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contemporary machine learning algorithms train artificial neural networks by setting network weights to a single optimized configuration through gradient descent on task-specific training data. The resulting networks can achieve human-level performance on natural language processing, image analysis and agent-based tasks, but lack the flexibility and robustness characteristic of human intelligence. Here we introduce a differential geometry framework—functionally invariant paths—that provides flexible and continuous adaptation of trained neural networks so that secondary tasks can be achieved beyond the main machine learning goal, including increased network sparsification and adversarial robustness. We formulate the weight space of a neural network as a curved Riemannian manifold equipped with a metric tensor whose spectrum defines low-rank subspaces in weight space that accommodate network adaptation without loss of prior knowledge. We formalize adaptation as movement along a geodesic path in weight space while searching for networks that accommodate secondary objectives. With modest computational resources, the functionally invariant path algorithm achieves performance comparable with or exceeding state-of-the-art methods including low-rank adaptation on continual learning, sparsification and adversarial robustness tasks for large language models (bidirectional encoder representations from transformers), vision transformers (ViT and DeIT) and convolutional neural networks. Machine learning often includes secondary objectives, such as sparsity or robustness. To reach these objectives efficiently, the training of a neural network has been interpreted as the exploration of functionally invariant paths in the parameter space.},
  archive      = {J_NATMI},
  author       = {Raghavan, Guruprasad and Tharwat, Bahey and Hari, Surya Narayanan and Satani, Dhruvil and Liu, Rex and Thomson, Matt},
  doi          = {10.1038/s42256-024-00902-x},
  journal      = {Nature Machine Intelligence},
  month        = {10},
  number       = {10},
  pages        = {1179-1196},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Engineering flexible machine learning systems by traversing functionally invariant paths},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pre-training with fractional denoising to enhance molecular
property prediction. <em>NATMI</em>, <em>6</em>(10), 1169–1178. (<a
href="https://doi.org/10.1038/s42256-024-00900-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods have been considered promising for accelerating molecular screening in drug discovery and material design. Due to the limited availability of labelled data, various self-supervised molecular pre-training methods have been presented. Although many existing methods utilize common pre-training tasks in computer vision and natural language processing, they often overlook the fundamental physical principles governing molecules. In contrast, applying denoising in pre-training can be interpreted as an equivalent force learning, but the limited noise distribution introduces bias into the molecular distribution. To address this issue, we introduce a molecular pre-training framework called fractional denoising, which decouples noise design from the constraints imposed by force learning equivalence. In this way, the noise becomes customizable, allowing for incorporating chemical priors to substantially improve the molecular distribution modelling. Experiments demonstrate that our framework consistently outperforms existing methods, establishing state-of-the-art results across force prediction, quantum chemical properties and binding affinity tasks. The refined noise design enhances force accuracy and sampling coverage, which contribute to the creation of physically consistent molecular representations, ultimately leading to superior predictive performance. Denoising methods introduce useful priors in pre-training methods for molecular property prediction, but chemically unaware noise can lead to inaccurate predictions in downstream tasks. A molecular pre-training framework that uses fractional denoising to improve molecular distribution modelling is proposed, resulting in better predictions in various property prediction tasks.},
  archive      = {J_NATMI},
  author       = {Ni, Yuyan and Feng, Shikun and Hong, Xin and Sun, Yuancheng and Ma, Wei-Ying and Ma, Zhi-Ming and Ye, Qiwei and Lan, Yanyan},
  doi          = {10.1038/s42256-024-00900-z},
  journal      = {Nature Machine Intelligence},
  month        = {10},
  number       = {10},
  pages        = {1169-1178},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Pre-training with fractional denoising to enhance molecular property prediction},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Poisoning medical knowledge using large language models.
<em>NATMI</em>, <em>6</em>(10), 1156–1168. (<a
href="https://doi.org/10.1038/s42256-024-00899-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomedical knowledge graphs (KGs) constructed from medical literature have been widely used to validate biomedical discoveries and generate new hypotheses. Recently, large language models (LLMs) have demonstrated a strong ability to generate human-like text data. Although most of these text data have been useful, LLM might also be used to generate malicious content. Here, we investigate whether it is possible that a malicious actor can use an LLM to generate a malicious paper that poisons medical KGs and further affects downstream biomedical applications. As a proof of concept, we develop Scorpius, a conditional text-generation model that generates a malicious paper abstract conditioned on a promoted drug and a target disease. The goal is to fool the medical KG constructed from a mixture of this malicious abstract and millions of real papers so that KG consumers will misidentify this promoted drug as relevant to the target disease. We evaluated Scorpius on a KG constructed from 3,818,528 papers and found that Scorpius can increase the relevance of 71.3% drug–disease pairs from the top 1,000 to the top ten by adding only one malicious abstract. Moreover, the generation of Scorpius achieves better perplexity than ChatGPT, suggesting that such malicious abstracts cannot be efficiently detected by humans. Collectively, Scorpius demonstrates the possibility of poisoning medical KGs and manipulating downstream applications using LLMs, indicating the importance of accountable and trustworthy medical knowledge discovery in the era of LLMs. With increasing reliance on public data sources, researchers are concerned whether low-quality or even adversarial data could have detrimental effects on medical models. Yang et al. developed Scorpius, a malicious text generator, to investigate whether large language models can mislead medical knowledge graphs. They show that a single generated paper abstract can mislead a medical reasoning system that has read millions of papers.},
  archive      = {J_NATMI},
  author       = {Yang, Junwei and Xu, Hanwen and Mirzoyan, Srbuhi and Chen, Tong and Liu, Zixuan and Liu, Zequn and Ju, Wei and Liu, Luchen and Xiao, Zhiping and Zhang, Ming and Wang, Sheng},
  doi          = {10.1038/s42256-024-00899-3},
  journal      = {Nature Machine Intelligence},
  month        = {10},
  number       = {10},
  pages        = {1156-1168},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Poisoning medical knowledge using large language models},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Soft robotic shorts improve outdoor walking efficiency in
older adults. <em>NATMI</em>, <em>6</em>(10), 1145–1155. (<a
href="https://doi.org/10.1038/s42256-024-00894-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Peoples&#39; walking efficiency declines as they grow older, posing constraints on mobility, and affecting independence and quality of life. Although wearable assistive technologies are recognized as a potential solution for age-related movement challenges, few have proven effective for older adults, predominantly within controlled laboratory experiments. Here we present WalkON, a pair of soft robotic shorts designed to enhance walking efficiency for older individuals by assisting hip flexion. The system features a compact and lightweight tendon-driven design, using a controller based on natural leg movements to autonomously assist leg propagation. To assess WalkON&#39;s impact on daily walking, we initially conducted a technology assessment with young adults on a demanding outdoor uphill 500 m hiking trail. We then validated our findings with a group of older adults walking on a flat outdoor 400 m track. WalkON considerably reduced the metabolic cost of transport by 17.79% for young adults during uphill walking. At the same time, participants reported high perceived control over their voluntary movements (a self-reported mean score of 6.20 out of 7 on a Likert scale). Similarly, older adults reduced their metabolic cost by 10.48% when using WalkON during level ground walking, while retaining a strong sense of movement control (mean score of 6.09 out of 7). These findings emphasize the potential of wearable assistive devices to improve efficiency in outdoor walking, suggesting promising implications for promoting physical well-being and advancing mobility, particularly during the later stages of life. Walking efficiency declines in older adults. To address this challenge, Tricomi and colleagues present a pair of lightweight, soft robotic shorts that enhance walking efficiency for older adults by assisting leg mobility. This method improves energy efficiency on outdoor tracks while maintaining the users’ natural movement control.},
  archive      = {J_NATMI},
  author       = {Tricomi, Enrica and Missiroli, Francesco and Xiloyannis, Michele and Lotti, Nicola and Zhang, Xiaohui and Stefanakis, Marios and Theisen, Maximilian and Bauer, Jürgen and Becker, Clemens and Masia, Lorenzo},
  doi          = {10.1038/s42256-024-00894-8},
  journal      = {Nature Machine Intelligence},
  month        = {10},
  number       = {10},
  pages        = {1145-1155},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Soft robotic shorts improve outdoor walking efficiency in older adults},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse learned kernels for interpretable and efficient
medical time series processing. <em>NATMI</em>, <em>6</em>(10),
1132–1144. (<a
href="https://doi.org/10.1038/s42256-024-00898-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid, reliable and accurate interpretation of medical time series signals is crucial for high-stakes clinical decision-making. Deep learning methods offered unprecedented performance in medical signal processing but at a cost: they were compute intensive and lacked interpretability. We propose sparse mixture of learned kernels (SMoLK), an interpretable architecture for medical time series processing. SMoLK learns a set of lightweight flexible kernels that form a single-layer sparse neural network, providing not only interpretability but also efficiency, robustness and generalization to unseen data distributions. We introduce parameter reduction techniques to reduce the size of SMoLK networks and maintain performance. We test SMoLK on two important tasks common to many consumer wearables: photoplethysmography artefact detection and atrial fibrillation detection from single-lead electrocardiograms. We find that SMoLK matches the performance of models orders of magnitude larger. It is particularly suited for real-time applications using low-power devices, and its interpretability benefits high-stakes situations. Deep learning excels in medical signal processing but lacks interpretability. An efficient, interpretable architecture that matches the performance of larger models at orders of magnitude fewer parameters in tasks common to wearable devices has been proposed.},
  archive      = {J_NATMI},
  author       = {Chen, Sully F. and Guo, Zhicheng and Ding, Cheng and Hu, Xiao and Rudin, Cynthia},
  doi          = {10.1038/s42256-024-00898-4},
  journal      = {Nature Machine Intelligence},
  month        = {10},
  number       = {10},
  pages        = {1132-1144},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Sparse learned kernels for interpretable and efficient medical time series processing},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning for data-centric epidemic forecasting.
<em>NATMI</em>, <em>6</em>(10), 1122–1131. (<a
href="https://doi.org/10.1038/s42256-024-00895-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic emphasized the importance of epidemic forecasting for decision makers in multiple domains, ranging from public health to the economy. Forecasting epidemic progression is a non-trivial task due to multiple confounding factors, such as human behaviour, pathogen dynamics and environmental conditions. However, the surge in research interest and initiatives from public health and funding agencies has fuelled the availability of new data sources that capture previously unobservable aspects of disease spread, paving the way for a spate of ‘data-centred’ computational solutions that show promise for enhancing our forecasting capabilities. Here we discuss various methodological and practical advances and introduce a conceptual framework to navigate through them. First we list relevant datasets, such as symptomatic online surveys, retail and commerce, mobility and genomics data. Next we consider methods, focusing on recent data-driven statistical and deep learning-based methods, as well as hybrid models that combine domain knowledge of mechanistic models with the flexibility of statistical approaches. We also discuss experiences and challenges that arise in the real-world deployment of these forecasting systems, including decision-making informed by forecasts. Finally, we highlight some challenges and open problems found across the forecasting pipeline to enable robust future pandemic preparedness. Forecasting epidemic progression is a complex task influenced by various factors, including human behaviour, pathogen dynamics and environmental conditions. Rodríguez, Kamarthi and colleagues provide a review of machine learning methods for epidemic forecasting from a data-centric computational perspective.},
  archive      = {J_NATMI},
  author       = {Rodríguez, Alexander and Kamarthi, Harshavardhan and Agarwal, Pulak and Ho, Javen and Patel, Mira and Sapre, Suchet and Prakash, B. Aditya},
  doi          = {10.1038/s42256-024-00895-7},
  journal      = {Nature Machine Intelligence},
  month        = {10},
  number       = {10},
  pages        = {1122-1131},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Machine learning for data-centric epidemic forecasting},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A call for an industry-led initiative to critically assess
machine learning for real-world drug discovery. <em>NATMI</em>,
<em>6</em>(10), 1120–1121. (<a
href="https://doi.org/10.1038/s42256-024-00911-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Wognum, Cas and Ash, Jeremy R. and Aldeghi, Matteo and Rodríguez-Pérez, Raquel and Fang, Cheng and Cheng, Alan C. and Price, Daniel J. and Clevert, Djork-Arné and Engkvist, Ola and Walters, W. Patrick},
  doi          = {10.1038/s42256-024-00911-w},
  journal      = {Nature Machine Intelligence},
  month        = {10},
  number       = {10},
  pages        = {1120-1121},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A call for an industry-led initiative to critically assess machine learning for real-world drug discovery},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pick your AI poison. <em>NATMI</em>, <em>6</em>(10), 1119.
(<a href="https://doi.org/10.1038/s42256-024-00921-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distinguishing between real and fabricated facts has long been a societal challenge. As the Internet becomes increasingly littered with AI-generated content, the need for curation and safeguarding of high-quality data and information is more crucial than ever.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-024-00921-8},
  journal      = {Nature Machine Intelligence},
  month        = {10},
  number       = {10},
  pages        = {1119},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Pick your AI poison},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An end-to-end recurrent compressed sensing method to
denoise, detect and demix calcium imaging data. <em>NATMI</em>,
<em>6</em>(9), 1106–1118. (<a
href="https://doi.org/10.1038/s42256-024-00892-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-photon calcium imaging provides large-scale recordings of neuronal activities at cellular resolution. A robust, automated and high-speed pipeline to simultaneously segment the spatial footprints of neurons and extract their temporal activity traces while decontaminating them from background, noise and overlapping neurons is highly desirable to analyse calcium imaging data. Here we demonstrate DeepCaImX, an end-to-end deep learning method based on an iterative shrinkage-thresholding algorithm and a long short-term memory neural network to achieve the above goals altogether at a very high speed and without any manually tuned hyperparameter. DeepCaImX is a multi-task, multi-class and multi-label segmentation method composed of a compressed sensing-inspired neural network with a recurrent layer and fully connected layers. The neural network can simultaneously generate accurate neuronal footprints and extract clean neuronal activity traces from calcium imaging data. We trained the neural network with simulated datasets and benchmarked it against existing state-of-the-art methods with in vivo experimental data. DeepCaImX outperforms existing methods in the quality of segmentation and temporal trace extraction as well as processing speed. DeepCaImX is highly scalable and will benefit the analysis of mesoscale calcium imaging. Extracting time traces and spatial footprints of single neurons from population calcium imaging data presents challenges. Zhang et al. introduce a deep learning method that efficiently segments neuronal footprints and extracts activity traces from these data. The method surpasses existing approaches in both quality and speed, providing a robust tool for large-scale neuronal circuit analysis.},
  archive      = {J_NATMI},
  author       = {Zhang, Kangning and Tang, Sean and Zhu, Vivian and Barchini, Majd and Yang, Weijian},
  doi          = {10.1038/s42256-024-00892-w},
  journal      = {Nature Machine Intelligence},
  month        = {9},
  number       = {9},
  pages        = {1106-1118},
  shortjournal = {Nat. Mach. Intell.},
  title        = {An end-to-end recurrent compressed sensing method to denoise, detect and demix calcium imaging data},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning motif-based graphs for drug–drug interaction
prediction via local–global self-attention. <em>NATMI</em>,
<em>6</em>(9), 1094–1105. (<a
href="https://doi.org/10.1038/s42256-024-00888-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unexpected drug–drug interactions (DDIs) are important issues for both pharmaceutical research and clinical applications due to the high risk of causing severe adverse drug reactions or drug withdrawals. Many deep learning models have achieved high performance in DDI prediction, but model interpretability to reveal the underlying causes of DDIs has not been extensively explored. Here we propose MeTDDI—a deep learning framework with local–global self-attention and co-attention to learn motif-based graphs for DDI prediction. MeTDDI achieved competitive performance compared with state-of-the-art models. Regarding interpretability, we conducted extensive assessments on 73 drugs with 13,786 DDIs and MeTDDI can precisely explain the structural mechanisms for 5,602 DDIs involving 58 drugs. Besides, MeTDDI shows potential to explain complex DDI mechanisms and mitigate DDI risks. To summarize, MeTDDI provides a new perspective on exploring DDI mechanisms, which will benefit both drug discovery and polypharmacy for safer therapies for patients. A transformer-based approach that predicts drug–drug interactions in polypharmacy has been shown, which also identifies perpetrator drugs and the chemical mechanisms causing the interactions. The method could facilitate high-throughput optimization of drug combinations and mitigate adverse drug–drug interaction risks.},
  archive      = {J_NATMI},
  author       = {Zhong, Yi and Li, Gaozheng and Yang, Ji and Zheng, Houbing and Yu, Yongqiang and Zhang, Jiheng and Luo, Heng and Wang, Biao and Weng, Zuquan},
  doi          = {10.1038/s42256-024-00888-6},
  journal      = {Nature Machine Intelligence},
  month        = {9},
  number       = {9},
  pages        = {1094-1105},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Learning motif-based graphs for drug–drug interaction prediction via local–global self-attention},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerating histopathology workflows with generative
AI-based virtually multiplexed tumour profiling. <em>NATMI</em>,
<em>6</em>(9), 1077–1093. (<a
href="https://doi.org/10.1038/s42256-024-00889-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the spatial heterogeneity of tumours and its links to disease initiation and progression is a cornerstone of cancer biology. Presently, histopathology workflows heavily rely on hematoxylin and eosin and serial immunohistochemistry staining, a cumbersome, tissue-exhaustive process that results in non-aligned tissue images. We propose the VirtualMultiplexer, a generative artificial intelligence toolkit that effectively synthesizes multiplexed immunohistochemistry images for several antibody markers (namely AR, NKX3.1, CD44, CD146, p53 and ERG) from only an input hematoxylin and eosin image. The VirtualMultiplexer captures biologically relevant staining patterns across tissue scales without requiring consecutive tissue sections, image registration or extensive expert annotations. Thorough qualitative and quantitative assessment indicates that the VirtualMultiplexer achieves rapid, robust and precise generation of virtually multiplexed imaging datasets of high staining quality that are indistinguishable from the real ones. The VirtualMultiplexer is successfully transferred across tissue scales and patient cohorts with no need for model fine-tuning. Crucially, the virtually multiplexed images enabled training a graph transformer that simultaneously learns from the joint spatial distribution of several proteins to predict clinically relevant endpoints. We observe that this multiplexed learning scheme was able to greatly improve clinical prediction, as corroborated across several downstream tasks, independent patient cohorts and cancer types. Our results showcase the clinical relevance of artificial intelligence-assisted multiplexed tumour imaging, accelerating histopathology workflows and cancer biology. VirtualMultiplexer is a generative AI tool that produces realistic multiplexed immunohistochemistry images from tissue biopsies. The generated images could be used to improve clinical predictions, enhancing histopathology workflows and accelerating cancer research.},
  archive      = {J_NATMI},
  author       = {Pati, Pushpak and Karkampouna, Sofia and Bonollo, Francesco and Compérat, Eva and Radić, Martina and Spahn, Martin and Martinelli, Adriano and Wartenberg, Martin and Kruithof-de Julio, Marianna and Rapsomaniki, Marianna},
  doi          = {10.1038/s42256-024-00889-5},
  journal      = {Nature Machine Intelligence},
  month        = {9},
  number       = {9},
  pages        = {1077-1093},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Accelerating histopathology workflows with generative AI-based virtually multiplexed tumour profiling},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Zero-shot transfer of protein sequence likelihood models to
thermostability prediction. <em>NATMI</em>, <em>6</em>(9), 1063–1076.
(<a href="https://doi.org/10.1038/s42256-024-00887-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein sequence likelihood models (PSLMs) are an emerging class of self-supervised deep learning algorithms that learn probability distributions over amino acid identities conditioned on structural or evolutionary context. Recently, PSLMs have demonstrated impressive performance in predicting the relative fitness of variant sequences without any task-specific training, but their potential to address a central goal of protein engineering—enhancing stability—remains underexplored. Here we comprehensively analyse the capacity for zero-shot transfer of eight PSLMs towards prediction of relative thermostability for variants of hundreds of heterogeneous proteins across several quantitative datasets. PSLMs are compared with popular task-specific stability models, and we show that some PSLMs have competitive performance when the appropriate statistics are considered. We highlight relative strengths and weaknesses of PSLMs and examine their complementarity with task-specific models, specifically focusing our analyses on stability-engineering applications. Our results indicate that all PSLMs can appreciably augment the predictions of existing methods by integrating insights from their disparate training objectives, suggesting a path forward in the stagnating field of computational stability prediction. Stabilization of proteins is a key task in protein engineering; however, current methods to predict mutant stability face a number of limitations. Reeves and Kalyaanamoorthy study the performance of self-supervised protein sequence likelihood models for stability prediction and find that combining them with task-specific supervised models can lead to appreciable practical gains.},
  archive      = {J_NATMI},
  author       = {Reeves, Shawn and Kalyaanamoorthy, Subha},
  doi          = {10.1038/s42256-024-00887-7},
  journal      = {Nature Machine Intelligence},
  month        = {9},
  number       = {9},
  pages        = {1063-1076},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Zero-shot transfer of protein sequence likelihood models to thermostability prediction},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning integral operators via neural integral equations.
<em>NATMI</em>, <em>6</em>(9), 1046–1062. (<a
href="https://doi.org/10.1038/s42256-024-00886-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear operators with long-distance spatiotemporal dependencies are fundamental in modelling complex systems across sciences; yet, learning these non-local operators remains challenging in machine learning. Integral equations, which model such non-local systems, have wide-ranging applications in physics, chemistry, biology and engineering. We introduce the neural integral equation, a method for learning unknown integral operators from data using an integral equation solver. To improve scalability and model capacity, we also present the attentional neural integral equation, which replaces the integral with self-attention. Both models are grounded in the theory of second-kind integral equations, where the indeterminate appears both inside and outside the integral operator. We provide a theoretical analysis showing how self-attention can approximate integral operators under mild regularity assumptions, further deepening previously reported connections between transformers and integration, as well as deriving corresponding approximation results for integral operators. Through numerical benchmarks on synthetic and real-world data, including Lotka–Volterra, Navier–Stokes and Burgers’ equations, as well as brain dynamics and integral equations, we showcase the models’ capabilities and their ability to derive interpretable dynamics embeddings. Our experiments demonstrate that attentional neural integral equations outperform existing methods, especially for longer time intervals and higher-dimensional problems. Our work addresses a critical gap in machine learning for non-local operators and offers a powerful tool for studying unknown complex systems with long-range dependencies. Integral equations are used in science and engineering to model complex systems with non-local dependencies; however, existing traditional and machine-learning-based methods cannot yield accurate or efficient solutions in several complex cases. Zappala and colleagues introduce a neural-network-based method that can learn an integral operator and its dynamics from data, demonstrating higher accuracy or scalability compared with several state-of-the-art methods.},
  archive      = {J_NATMI},
  author       = {Zappala, Emanuele and Fonseca, Antonio Henrique de Oliveira and Caro, Josue Ortega and Moberly, Andrew Henry and Higley, Michael James and Cardin, Jessica and Dijk, David van},
  doi          = {10.1038/s42256-024-00886-8},
  journal      = {Nature Machine Intelligence},
  month        = {9},
  number       = {9},
  pages        = {1046-1062},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Learning integral operators via neural integral equations},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven discovery of movement-linked heterogeneity in
neurodegenerative diseases. <em>NATMI</em>, <em>6</em>(9), 1034–1045.
(<a href="https://doi.org/10.1038/s42256-024-00882-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurodegenerative diseases manifest different motor and cognitive signs and symptoms that are highly heterogeneous. Parsing these heterogeneities may lead to an improved understanding of underlying disease mechanisms; however, current methods are dependent on clinical assessments and an arbitrary choice of behavioural tests. Here we present a data-driven subtyping approach using video-captured human motion and brain functional connectivity from resting-state functional magnetic resonance imaging. We applied our framework to a cohort of individuals at different stages of Parkinson’s disease. The process mapped the data to low-dimensional measures by projecting them onto a canonical correlation space that identified three Parkinson’s disease subtypes: subtype I was characterized by motor difficulties and poor visuospatial abilities; subtype II exhibited difficulties in non-motor components of activities of daily living and motor complications (dyskinesias and motor fluctuations) and subtype III was characterized by predominant tremor symptoms. We conducted a convergent validity analysis by comparing our approach to existing and widely used approaches. The compared approaches yielded subtypes that were adequately well-clustered in the motion-brain representation space we created to delineate subtypes. Our data-driven approach, contrary to other forms of subtyping, derived biomarkers predictive of motion impairment and subtype memberships that were captured objectively by digital videos. Diagnostic strategies for neurodegenerative diseases involve various data types, related to motor and cognitive signals. Endo et al. describe a data-driven subtyping approach for Parkinson’s disease, combining motion data (from videos) and brain functional connectivity data. The method reveals clinically relevant subtypes and digital biomarkers, uncovering movement-linked heterogeneities of Parkinson’s disease.},
  archive      = {J_NATMI},
  author       = {Endo, Mark and Nerrise, Favour and Zhao, Qingyu and Sullivan, Edith V. and Fei-Fei, Li and Henderson, Victor W. and Pohl, Kilian M. and Poston, Kathleen L. and Adeli, Ehsan},
  doi          = {10.1038/s42256-024-00882-y},
  journal      = {Nature Machine Intelligence},
  month        = {9},
  number       = {9},
  pages        = {1034-1045},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Data-driven discovery of movement-linked heterogeneity in neurodegenerative diseases},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning method that identifies cellular
heterogeneity using nanoscale nuclear features. <em>NATMI</em>,
<em>6</em>(9), 1021–1033. (<a
href="https://doi.org/10.1038/s42256-024-00883-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cellular phenotypic heterogeneity is an important hallmark of many biological processes and understanding its origins remains a substantial challenge. This heterogeneity often reflects variations in the chromatin structure, influenced by factors such as viral infections and cancer, which dramatically reshape the cellular landscape. To address the challenge of identifying distinct cell states, we developed artificial intelligence of the nucleus (AINU), a deep learning method that can identify specific nuclear signatures at the nanoscale resolution. AINU can distinguish different cell states based on the spatial arrangement of core histone H3, RNA polymerase II or DNA from super-resolution microscopy images. With only a small number of images as the training data, AINU correctly identifies human somatic cells, human-induced pluripotent stem cells, very early stage infected cells transduced with DNA herpes simplex virus type 1 and even cancer cells after appropriate retraining. Finally, using AI interpretability methods, we find that the RNA polymerase II localizations in the nucleoli aid in distinguishing human-induced pluripotent stem cells from their somatic cells. Overall, AINU coupled with super-resolution microscopy of nuclear structures provides a robust tool for the precise detection of cellular heterogeneity, with considerable potential for advancing diagnostics and therapies in regenerative medicine, virology and cancer biology. Cellular phenotypic heterogeneity is a key determinant of biological functions and is challenging to identify. A deep learning method that recognizes specific nuclear signatures is discussed, which can identify cellular heterogeneity and differentiate between various cell states using a small amount of super-resolution microscopy data.},
  archive      = {J_NATMI},
  author       = {Carnevali, Davide and Zhong, Limei and González-Almela, Esther and Viana, Carlotta and Rotkevich, Mikhail and Wang, Aiping and Franco-Barranco, Daniel and Gonzalez-Marfil, Aitor and Neguembor, Maria Victoria and Castells-Garcia, Alvaro and Arganda-Carreras, Ignacio and Cosma, Maria Pia},
  doi          = {10.1038/s42256-024-00883-x},
  journal      = {Nature Machine Intelligence},
  month        = {9},
  number       = {9},
  pages        = {1021-1033},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A deep learning method that identifies cellular heterogeneity using nanoscale nuclear features},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient and scalable reinforcement learning for
large-scale network control. <em>NATMI</em>, <em>6</em>(9), 1006–1020.
(<a href="https://doi.org/10.1038/s42256-024-00879-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary challenge in the development of large-scale artificial intelligence (AI) systems lies in achieving scalable decision-making—extending the AI models while maintaining sufficient performance. Existing research indicates that distributed AI can improve scalability by decomposing complex tasks and distributing them across collaborative nodes. However, previous technologies suffered from compromised real-world applicability and scalability due to the massive requirement of communication and sampled data. Here we develop a model-based decentralized policy optimization framework, which can be efficiently deployed in multi-agent systems. By leveraging local observation through the agent-level topological decoupling of global dynamics, we prove that this decentralized mechanism achieves accurate estimations of global information. Importantly, we further introduce model learning to reinforce the optimal policy for monotonic improvement with a limited amount of sampled data. Empirical results on diverse scenarios show the superior scalability of our approach, particularly in real-world systems with hundreds of agents, thereby paving the way for scaling up AI systems. Applying large-scale AI systems to multi-agent scenarios in real-world settings is challenging. The authors propose a decentralized model-based policy optimization framework to enable scalable decision-making.},
  archive      = {J_NATMI},
  author       = {Ma, Chengdong and Li, Aming and Du, Yali and Dong, Hao and Yang, Yaodong},
  doi          = {10.1038/s42256-024-00879-7},
  journal      = {Nature Machine Intelligence},
  month        = {9},
  number       = {9},
  pages        = {1006-1020},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Efficient and scalable reinforcement learning for large-scale network control},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wing-strain-based flight control of flapping-wing drones
through reinforcement learning. <em>NATMI</em>, <em>6</em>(9), 992–1005.
(<a href="https://doi.org/10.1038/s42256-024-00893-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although drone technology has advanced rapidly, replicating the dynamic control and wind-sensing abilities of biological flight is still beyond reach. Biological studies reveal that insect wings are equipped with mechanoreceptors known as campaniform sensilla, which detect complex aerodynamic loads critical for flight agility. By leveraging robotic experiments designed to mimic these biological systems, we confirm that wing strain provides crucial information about the drone’s attitude angle, as well as the direction and velocity of the wind. We introduce a wing-strain-based flight controller that employs the aerodynamic forces exerted on a flapping drone’s wings to deduce vital flight data such as attitude and airflow without accelerometers and gyroscopic sensors. The present work spans five key experiments: initial validation of the wing strain sensor system for state information provision, control in a single degree of freedom movement environment with changing winds, control in a two degrees of freedom movement environment for gravitational attitude adjustment, a test for position control in windy conditions and a demonstration of precise flight path manipulation in a windless condition using only wing strain sensors. We have successfully demonstrated control of a flapping drone in various environments using only wing strain sensors, with the aid of a reinforcement-learning-driven flight controller. The demonstrated adaptability to environmental shifts will be beneficial across varied applications, from gust resistance to wind-assisted flight for autonomous flying robots. Inspired by mechanoreceptors on flying insects, a flapping-wing drone that makes use of strain sensors on the wings and reinforcement-learning-based flight control has been developed. The drone can fly in various unsteady environments, including in windy conditions.},
  archive      = {J_NATMI},
  author       = {Kim, Taewi and Hong, Insic and Im, Sunghoon and Rho, Seungeun and Kim, Minho and Roh, Yeonwook and Kim, Changhwan and Park, Jieun and Lim, Daseul and Lee, Doohoe and Lee, Seunggon and Lee, Jingoo and Back, Inryeol and Cho, Junggwang and Hong, Myung Rae and Kang, Sanghun and Lee, Joonho and Seo, Sungchul and Kim, Uikyum and Choi, Young-Man and Koh, Je-sung and Han, Seungyong and Kang, Daeshik},
  doi          = {10.1038/s42256-024-00893-9},
  journal      = {Nature Machine Intelligence},
  month        = {9},
  number       = {9},
  pages        = {992-1005},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Wing-strain-based flight control of flapping-wing drones through reinforcement learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Realizing full-body control of humanoid robots.
<em>NATMI</em>, <em>6</em>(9), 990–991. (<a
href="https://doi.org/10.1038/s42256-024-00891-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using deep reinforcement learning, flexible skills and behaviours emerge in humanoid robots, as demonstrated in two recent reports.},
  archive      = {J_NATMI},
  author       = {Li, Guangliang and Gomez, Randy},
  doi          = {10.1038/s42256-024-00891-x},
  journal      = {Nature Machine Intelligence},
  month        = {9},
  number       = {9},
  pages        = {990-991},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Realizing full-body control of humanoid robots},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multiscale approach for biomedical machine learning.
<em>NATMI</em>, <em>6</em>(9), 989. (<a
href="https://doi.org/10.1038/s42256-024-00907-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New multi-modal AI methods fuse different biological data types that span multiple scales, offering promising clinical utility.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-024-00907-6},
  journal      = {Nature Machine Intelligence},
  month        = {9},
  number       = {9},
  pages        = {989},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A multiscale approach for biomedical machine learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Author correction: A 5′ UTR language model for decoding
untranslated regions of mRNA and function predictions. <em>NATMI</em>,
<em>6</em>(8), 988. (<a
href="https://doi.org/10.1038/s42256-024-00890-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Chu, Yanyi and Yu, Dan and Li, Yupeng and Huang, Kaixuan and Shen, Yue and Cong, Le and Zhang, Jason and Wang, Mengdi},
  doi          = {10.1038/s42256-024-00890-y},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {988},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Author correction: A 5′ UTR language model for decoding untranslated regions of mRNA and function predictions},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A large-scale audit of dataset licensing and attribution in
AI. <em>NATMI</em>, <em>6</em>(8), 975–987. (<a
href="https://doi.org/10.1038/s42256-024-00878-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The race to train language models on vast, diverse and inconsistently documented datasets raises pressing legal and ethical concerns. To improve data transparency and understanding, we convene a multi-disciplinary effort between legal and machine learning experts to systematically audit and trace more than 1,800 text datasets. We develop tools and standards to trace the lineage of these datasets, including their source, creators, licences and subsequent use. Our landscape analysis highlights sharp divides in the composition and focus of data licenced for commercial use. Important categories including low-resource languages, creative tasks and new synthetic data all tend to be restrictively licenced. We observe frequent miscategorization of licences on popular dataset hosting sites, with licence omission rates of more than 70% and error rates of more than 50%. This highlights a crisis in misattribution and informed use of popular datasets driving many recent breakthroughs. Our analysis of data sources also explains the application of copyright law and fair use to finetuning data. As a contribution to continuing improvements in dataset transparency and responsible use, we release our audit, with an interactive user interface, the Data Provenance Explorer, to enable practitioners to trace and filter on data provenance for the most popular finetuning data collections: www.dataprovenance.org . The Data Provenance Initiative audits over 1,800 text artificial intelligence (AI) datasets, analysing trends, permissions of use and global representation. It exposes frequent errors on several major data hosting sites and offers tools for transparent and informed use of AI training data.},
  archive      = {J_NATMI},
  author       = {Longpre, Shayne and Mahari, Robert and Chen, Anthony and Obeng-Marnu, Naana and Sileo, Damien and Brannon, William and Muennighoff, Niklas and Khazam, Nathan and Kabbara, Jad and Perisetla, Kartik and Wu, Xinyi (Alexis) and Shippole, Enrico and Bollacker, Kurt and Wu, Tongshuang and Villa, Luis and Pentland, Sandy and Hooker, Sara},
  doi          = {10.1038/s42256-024-00878-8},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {975-987},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A large-scale audit of dataset licensing and attribution in AI},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A bioactivity foundation model using pairwise meta-learning.
<em>NATMI</em>, <em>6</em>(8), 962–974. (<a
href="https://doi.org/10.1038/s42256-024-00876-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bioactivity of compounds plays an important role in drug development and discovery. Existing machine learning approaches have poor generalizability in bioactivity prediction due to the small number of compounds in each assay and incompatible measurements among assays. In this paper, we propose ActFound, a bioactivity foundation model trained on 1.6 million experimentally measured bioactivities and 35,644 assays from ChEMBL. The key idea of ActFound is to use pairwise learning to learn the relative bioactivity differences between two compounds within the same assay to circumvent the incompatibility among assays. ActFound further exploits meta-learning to jointly optimize the model from all assays. On six real-world bioactivity datasets, ActFound demonstrates accurate in-domain prediction and strong generalization across assay types and molecular scaffolds. We also demonstrate that ActFound can be used as an accurate alternative to the leading physics-based computational tool FEP+(OPLS4) by achieving comparable performance when using only a few data points for fine-tuning. Our promising results indicate that ActFound could be an effective bioactivity foundation model for compound bioactivity prediction, paving the way for machine-learning-based drug development and discovery. Traditional machine learning methods for drug development struggle with bioactivity prediction due to the limited number of compounds in each assay and assay incompatibilities. Feng et al. developed ActFound, a bioactivity foundation model trained by pairwise learning and meta-learning, that improves the accuracy and generalization of bioactivity prediction.},
  archive      = {J_NATMI},
  author       = {Feng, Bin and Liu, Zequn and Huang, Nanlan and Xiao, Zhiping and Zhang, Haomiao and Mirzoyan, Srbuhi and Xu, Hanwen and Hao, Jiaran and Xu, Yinghui and Zhang, Ming and Wang, Sheng},
  doi          = {10.1038/s42256-024-00876-w},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {962-974},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A bioactivity foundation model using pairwise meta-learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning prediction of glycopeptide tandem mass spectra
powers glycoproteomics. <em>NATMI</em>, <em>6</em>(8), 950–961. (<a
href="https://doi.org/10.1038/s42256-024-00875-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein glycosylation, a post-translational modification of proteins by glycans, plays an important role in numerous physiological and pathological cellular functions. Glycoproteomics, the study of protein glycosylation on a proteome-wide scale, utilizes liquid chromatography coupled with tandem mass spectrometry (MS/MS) to get combinational information on glycosylation site, glycosylation level and glycan structure. However, current database searching methods for glycoproteomics often struggle with glycan structure determination due to the limited occurrence of structure-determining ions. Although spectral searching methods can leverage fragment intensity to facilitate the structure identification of glycopeptides, their application is hindered by difficulties in spectral library construction. In this work, we present DeepGP, a hybrid deep learning framework based on transformer and graph neural networks, for the prediction of MS/MS spectra and retention time of glycopeptides. Two graph neural network modules are employed to capture the branched glycan structure and predict glycan ion intensity, respectively. Additionally, a pretraining strategy is implemented to alleviate the insufficiency of glycoproteomics data. Testing on multiple biological datasets, DeepGP accurately predicts MS/MS spectra and retention time of glycopeptides, closely aligning with the experimental results. Comprehensive benchmarking of DeepGP on synthetic and biological datasets validates its effectiveness in distinguishing similar glycans. Based on various decoy methods, DeepGP in combination with database searching can increase glycopeptide detection sensitivity. We anticipate that DeepGP can inspire extensive future work in glycoproteomics. Glycosylation, a prevalent type of post-translational modification of proteins by glycan molecules, plays a major role in the proteome. Zong et al. present DeepGP, a hybrid deep learning framework based on transformer and graph neural network architectures that accurately predicts tandem mass spectra and retention times of glycopeptides, providing information on glycosylation and glycan structure.},
  archive      = {J_NATMI},
  author       = {Zong, Yu and Wang, Yuxin and Qiu, Xipeng and Huang, Xuanjing and Qiao, Liang},
  doi          = {10.1038/s42256-024-00875-x},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {950-961},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deep learning prediction of glycopeptide tandem mass spectra powers glycoproteomics},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On responsible machine learning datasets emphasizing
fairness, privacy and regulatory norms with examples in biometrics and
healthcare. <em>NATMI</em>, <em>6</em>(8), 936–949. (<a
href="https://doi.org/10.1038/s42256-024-00874-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) has seamlessly integrated into numerous scientific domains, catalysing unparalleled enhancements across a broad spectrum of tasks; however, its integrity and trustworthiness have emerged as notable concerns. The scientific community has focused on the development of trustworthy AI algorithms; however, machine learning and deep learning algorithms, popular in the AI community today, intrinsically rely on the quality of their training data. These algorithms are designed to detect patterns within the data, thereby learning the intended behavioural objectives. Any inadequacy in the data has the potential to translate directly into algorithms. In this study we discuss the importance of responsible machine learning datasets through the lens of fairness, privacy and regulatory compliance, and present a large audit of computer vision datasets. Despite the ubiquity of fairness and privacy challenges across diverse data domains, current regulatory frameworks primarily address human-centric data concerns. We therefore focus our discussion on biometric and healthcare datasets, although the principles we outline are broadly applicable across various domains. The audit is conducted through evaluation of the proposed responsible rubric. After surveying over 100 datasets, our detailed analysis of 60 distinct datasets highlights a universal susceptibility to fairness, privacy and regulatory compliance issues. This finding emphasizes the urgent need for revising dataset creation methodologies within the scientific community, especially in light of global advancements in data protection legislation. We assert that our study is critically relevant in the contemporary AI context, offering insights and recommendations that are both timely and essential for the ongoing evolution of AI technologies. There are pervasive concerns related to fairness, privacy and regulatory compliance in machine learning applications in healthcare, necessitating a reevaluation of dataset creation practices. Mittal et al. examine various computer vision datasets, providing insights to foster responsible AI development.},
  archive      = {J_NATMI},
  author       = {Mittal, Surbhi and Thakral, Kartik and Singh, Richa and Vatsa, Mayank and Glaser, Tamar and Canton Ferrer, Cristian and Hassner, Tal},
  doi          = {10.1038/s42256-024-00874-y},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {936-949},
  shortjournal = {Nat. Mach. Intell.},
  title        = {On responsible machine learning datasets emphasizing fairness, privacy and regulatory norms with examples in biometrics and healthcare},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Integrated structure prediction of protein–protein docking
with experimental restraints using ColabDock. <em>NATMI</em>,
<em>6</em>(8), 924–935. (<a
href="https://doi.org/10.1038/s42256-024-00873-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein complex structure prediction plays important roles in various applications, such as drug discovery and antibody design. However, due to limited prediction accuracy, there are frequent inconsistencies between the predictions and the experiments. Here we present ColabDock, a general framework adapting deep learning structure prediction models to integrate experimental restraints of different forms and sources without further large-scale retraining or fine tuning. With a generation–prediction architecture and trained ranking model, ColabDock outperforms HADDOCK and ClusPro using AlphaFold2 as the structure prediction model, not only in complex structure predictions with simulated residue and surface restraints but also in those assisted by nuclear magnetic resonance chemical shift perturbation as well as covalent labelling. It also assists antibody–antigen interface prediction with emulated interface scan restraints, which could be obtained by experiments such as deep mutational scanning. As a unified framework, we hope that ColabDock can help to bridge the gap between experimental and computational protein science. Despite rapid developments in predicting the complex structures of proteins, there are still inconsistencies between predictions and experiments. Feng et al. developed ColabDock, a general framework for deep learning models that integrates various experimental restraints and improves complex interface prediction, including antibody–antigen interactions.},
  archive      = {J_NATMI},
  author       = {Feng, Shihao and Chen, Zhenyu and Zhang, Chengwei and Xie, Yuhao and Ovchinnikov, Sergey and Gao, Yi Qin and Liu, Sirui},
  doi          = {10.1038/s42256-024-00873-z},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {924-935},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Integrated structure prediction of protein–protein docking with experimental restraints using ColabDock},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DNA language model GROVER learns sequence context in the
human genome. <em>NATMI</em>, <em>6</em>(8), 911–923. (<a
href="https://doi.org/10.1038/s42256-024-00872-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep-learning models that learn a sense of language on DNA have achieved a high level of performance on genome biological tasks. Genome sequences follow rules similar to natural language but are distinct in the absence of a concept of words. We established byte-pair encoding on the human genome and trained a foundation language model called GROVER (Genome Rules Obtained Via Extracted Representations) with the vocabulary selected via a custom task, next-k-mer prediction. The defined dictionary of tokens in the human genome carries best the information content for GROVER. Analysing learned representations, we observed that trained token embeddings primarily encode information related to frequency, sequence content and length. Some tokens are primarily localized in repeats, whereas the majority widely distribute over the genome. GROVER also learns context and lexical ambiguity. Average trained embeddings of genomic regions relate to functional genomics annotation and thus indicate learning of these structures purely from the contextual relationships of tokens. This highlights the extent of information content encoded by the sequence that can be grasped by GROVER. On fine-tuning tasks addressing genome biology with questions of genome element identification and protein–DNA binding, GROVER exceeds other models’ performance. GROVER learns sequence context, a sense for structure and language rules. Extracting this knowledge can be used to compose a grammar book for the code of life. Genomes can be modelled with language approaches by treating nucleotide bases A, C, G and T like text, but there is no natural concept of what the words would be and whether there is even a ‘language’ to be learned this way. Sanabria et al. have developed a language model called GROVER that learns with a ‘vocabulary’ of genome sequences with byte-pair encoding, a method from text compression, and shows good performance on genome biological tasks.},
  archive      = {J_NATMI},
  author       = {Sanabria, Melissa and Hirsch, Jonas and Joubert, Pierre M. and Poetsch, Anna R.},
  doi          = {10.1038/s42256-024-00872-0},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {911-923},
  shortjournal = {Nat. Mach. Intell.},
  title        = {DNA language model GROVER learns sequence context in the human genome},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised learning of topological non-abelian braiding in
non-hermitian bands. <em>NATMI</em>, <em>6</em>(8), 904–910. (<a
href="https://doi.org/10.1038/s42256-024-00871-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The topological classification of energy bands has laid the foundation for the discovery of various topological phases of matter in recent decades. While previous work focused on real-energy bands in Hermitian systems, recent studies have shifted attention to the intriguing topology of complex-energy, or non-Hermitian, bands, freeing them from the constraint of energy conservation. For example, the spectral winding of complex-energy bands can give rise to unique topological structures such as braids, holding substantial promise for advancing quantum computing. However, discussions of complex-energy braids have been predominantly limited to the Abelian braid group $${{\mathbb{B}}}_{2}$$ owing to its relative simplicity. Identifying topological non-Abelian braiding remains challenging, as it lacks a universally applicable topological invariant for characterization. Here we present a machine learning algorithm for the unsupervised identification of non-Abelian braiding within multiple complex-energy bands. We demonstrate that the results are consistent with Artin’s well-known topological equivalence conditions in braiding. Inspired by these findings, we introduce a winding matrix as a topological invariant for characterizing braiding topology. The winding matrix also reveals the bulk-edge correspondence of non-Hermitian bands with non-Abelian braiding. Finally, we extend our approach to identify non-Abelian braiding topology in two-dimensional and three-dimensional exceptional semimetals and address the unknotting problem in an unsupervised manner. The topological classification of complex-energy bands has uncovered various topological phases beyond Hermitian systems. Long and colleagues exploit unsupervised learning to fully identify the non-Abelian braiding topology of non-Hermitian bands.},
  archive      = {J_NATMI},
  author       = {Long, Yang and Xue, Haoran and Zhang, Baile},
  doi          = {10.1038/s42256-024-00871-1},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {904-910},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Unsupervised learning of topological non-abelian braiding in non-hermitian bands},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). High-resolution real-space reconstruction of cryo-EM
structures using a neural field network. <em>NATMI</em>, <em>6</em>(8),
892–903. (<a href="https://doi.org/10.1038/s42256-024-00870-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The elucidation of three-dimensional (3D) structures is crucial for unravelling the protein function and illuminating mechanisms in structural biology. Cryogenic electron microscopy (cryo-EM) single-particle analysis provides direct measurements to determine the structures of macromolecules. However, the main challenge is reconstructing high-resolution 3D structures from extremely noisy and randomly oriented two-dimensional projection images. Most existing methods involve the optimization of multiple two-dimensional slices in the Fourier domain but ignore the anisotropy among these slices, thereby limiting the reconstruction of high-frequency structures. In this paper, we propose a cryo-EM neural field reconstruction network using 3D spatial-domain optimization that learns a directional isotropic representation of the cryo-EM structure by mapping the spatial coordinates to the corresponding density values. We qualitatively and quantitatively evaluate the cryo-EM neural field reconstruction network on four datasets. The cryo-EM neural field reconstruction network improves the directional isotropy and 3D density resolution beyond the limits of existing algorithms in homogeneous reconstruction and resolves the missing elements of SARS-CoV-2 in heterogeneous reconstruction. Elucidating three-dimensional structures is crucial for unravelling the macromolecule function in structural biology. This study presents a cryogenic electron microscopy neural field reconstruction network using real-space optimization, enhancing the resolution in cryogenic electron microscopy reconstruction.},
  archive      = {J_NATMI},
  author       = {Huang, Yue and Zhu, Chengguang and Yang, Xiaokang and Liu, Manhua},
  doi          = {10.1038/s42256-024-00870-2},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {892-903},
  shortjournal = {Nat. Mach. Intell.},
  title        = {High-resolution real-space reconstruction of cryo-EM structures using a neural field network},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A transformer-based weakly supervised computational
pathology method for clinical-grade diagnosis and molecular marker
discovery of gliomas. <em>NATMI</em>, <em>6</em>(8), 876–891. (<a
href="https://doi.org/10.1038/s42256-024-00868-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex diagnostic criteria for gliomas pose great challenges for making accurate diagnoses with computational pathology methods. There are no in-depth analyses of the accuracy, reliability and auxiliary capability of present approaches from a clinical perspective. Previous studies have overlooked the exploration of molecular and morphological correlations. To overcome these limitations, we propose ROAM, a multiple-instance learning model based on large regions of interest and a pyramid transformer. ROAM enlarges regions of interest to facilitate the consideration of tissue contexts. It utilizes the pyramid transformer to model both intrascale and interscale correlations of morphological features and leverages class-specific multiple-instance learning based on attention to extract slide-level visual representations that can be used to diagnose gliomas. Through comprehensive experiments on both in-house and external glioma datasets, we demonstrate that ROAM can automatically capture key morphological features consistent with the experience of pathologists and thus provide accurate, reliable and adaptable clinical-grade diagnoses of gliomas. Moreover, ROAM has clinical value for auxiliary diagnoses and could pave the way for the study of molecular and morphological correlations. ROAM, based on large regions of interest and a pyramid transformer, can automatically capture key morphological features consistent with the experience of pathologists to provide accurate, reliable and adaptable clinical-grade diagnoses of gliomas while advancing the discovery of molecular and morphological markers related to glioma diagnosis.},
  archive      = {J_NATMI},
  author       = {Jiang, Rui and Yin, Xiaoxu and Yang, Pengshuai and Cheng, Lingchao and Hu, Juan and Yang, Jiao and Wang, Ying and Fu, Xiaodan and Shang, Li and Li, Liling and Lin, Wei and Zhou, Huan and Chen, Fufeng and Zhang, Xuegong and Hu, Zhongliang and Lv, Hairong},
  doi          = {10.1038/s42256-024-00868-w},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {876-891},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A transformer-based weakly supervised computational pathology method for clinical-grade diagnosis and molecular marker discovery of gliomas},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An interpretable deep learning framework for genome-informed
precision oncology. <em>NATMI</em>, <em>6</em>(8), 864–875. (<a
href="https://doi.org/10.1038/s42256-024-00866-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancers result from aberrations in cellular signalling systems, typically resulting from driver somatic genome alterations (SGAs) in individual tumours. Precision oncology requires understanding the cellular state and selecting medications that induce vulnerability in cancer cells under such conditions. To this end, we developed a computational framework consisting of two components: (1) a representation-learning component, which learns a representation of the cellular signalling systems when perturbed by SGAs and uses a biologically motivated and interpretable deep learning model, and (2) a drug-response prediction component, which predicts drug responses by leveraging the information of the cellular state of the cancer cells derived by the first component. Our cell-state-oriented framework notably improves the accuracy of predictions of drug responses compared to models using SGAs directly in cell lines. Moreover, our model performs well with real patient data. Importantly, our framework enables the prediction of responses to chemotherapy agents based on SGAs, thus expanding genome-informed precision oncology beyond molecularly targeted drugs. Precision oncology requires analysis of genomic alterations in cancer cells. Ren et al. develop an interpretable artificial intelligence framework that transforms somatic genomic alterations into representations of cellular signalling systems and accurately predicts cells’ responses to anticancer drugs.},
  archive      = {J_NATMI},
  author       = {Ren, Shuangxia and Cooper, Gregory F. and Chen, Lujia and Lu, Xinghua},
  doi          = {10.1038/s42256-024-00866-y},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {864-875},
  shortjournal = {Nat. Mach. Intell.},
  title        = {An interpretable deep learning framework for genome-informed precision oncology},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Factuality challenges in the era of large language models
and opportunities for fact-checking. <em>NATMI</em>, <em>6</em>(8),
852–863. (<a href="https://doi.org/10.1038/s42256-024-00881-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of tools based on large language models (LLMs), such as OpenAI’s ChatGPT and Google’s Gemini, has garnered immense public attention owing to their advanced natural language generation capabilities. These remarkably natural-sounding tools have the potential to be highly useful for various tasks. However, they also tend to produce false, erroneous or misleading content—commonly referred to as hallucinations. Moreover, LLMs can be misused to generate convincing, yet false, content and profiles on a large scale, posing a substantial societal challenge by potentially deceiving users and spreading inaccurate information. This makes fact-checking increasingly important. Despite their issues with factual accuracy, LLMs have shown proficiency in various subtasks that support fact-checking, which is essential to ensure factually accurate responses. In light of these concerns, we explore issues related to factuality in LLMs and their impact on fact-checking. We identify key challenges, imminent threats and possible solutions to these factuality issues. We also thoroughly examine these challenges, existing solutions and potential prospects for fact-checking. By analysing the factuality constraints within LLMs and their impact on fact-checking, we aim to contribute to a path towards maintaining accuracy at a time of confluence of generative artificial intelligence and misinformation. Large language models (LLMs) present challenges, including a tendency to produce false or misleading content and the potential to create misinformation or disinformation. Augenstein and colleagues explore issues related to factuality in LLMs and their impact on fact-checking.},
  archive      = {J_NATMI},
  author       = {Augenstein, Isabelle and Baldwin, Timothy and Cha, Meeyoung and Chakraborty, Tanmoy and Ciampaglia, Giovanni Luca and Corney, David and DiResta, Renee and Ferrara, Emilio and Hale, Scott and Halevy, Alon and Hovy, Eduard and Ji, Heng and Menczer, Filippo and Miguez, Ruben and Nakov, Preslav and Scheufele, Dietram and Sharma, Shivam and Zagni, Giovanni},
  doi          = {10.1038/s42256-024-00881-z},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {852-863},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Factuality challenges in the era of large language models and opportunities for fact-checking},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cognitive maps from predictive vision. <em>NATMI</em>,
<em>6</em>(8), 850–851. (<a
href="https://doi.org/10.1038/s42256-024-00885-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constructing spatial maps from sensory inputs is challenging in both neuroscience and artificial intelligence. A recent study demonstrates that a self-attention neural network using predictive coding can generate an environmental map in its latent space as an agent that navigates the environment.},
  archive      = {J_NATMI},
  author       = {von Ebers, Margaret C. and Wei, Xue-Xin},
  doi          = {10.1038/s42256-024-00885-9},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {850-851},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Cognitive maps from predictive vision},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A step forward in tracing and documenting dataset
provenance. <em>NATMI</em>, <em>6</em>(8), 848–849. (<a
href="https://doi.org/10.1038/s42256-024-00884-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training data are crucial for advancements in artificial intelligence, but many questions remain regarding the provenance of training datasets, license enforcement and creator consent. Mahari et al. provide a set of tools for tracing, documenting and sharing AI training data and highlight the importance for developers to engage with metadata of datasets.},
  archive      = {J_NATMI},
  author       = {Vincent, Nicholas},
  doi          = {10.1038/s42256-024-00884-w},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {848-849},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A step forward in tracing and documenting dataset provenance},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advanced AI assistants that act on our behalf may not be
ethically or legally feasible. <em>NATMI</em>, <em>6</em>(8), 846–847.
(<a href="https://doi.org/10.1038/s42256-024-00877-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Milano, Silvia and Nyholm, Sven},
  doi          = {10.1038/s42256-024-00877-9},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {846-847},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Advanced AI assistants that act on our behalf may not be ethically or legally feasible},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). What is in your LLM-based framework? <em>NATMI</em>,
<em>6</em>(8), 845. (<a
href="https://doi.org/10.1038/s42256-024-00896-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To maintain high standards in clarity and reproducibility, authors need to clearly mention and describe the use of GPT-4 and other large language models in their work.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-024-00896-6},
  journal      = {Nature Machine Intelligence},
  month        = {8},
  number       = {8},
  pages        = {845},
  shortjournal = {Nat. Mach. Intell.},
  title        = {What is in your LLM-based framework?},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Partial-convolution-implemented generative adversarial
network for global oceanic data assimilation. <em>NATMI</em>,
<em>6</em>(7), 834–843. (<a
href="https://doi.org/10.1038/s42256-024-00867-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The oceanic data assimilation (DA) system has been developed to optimally combine numerical-model predictions with actual measurements from the ocean to create the best estimates of current ocean conditions and their uncertainties, improving our ability to forecast and understand the global climate variations. We developed DeepDA, a global oceanic DA system using deep learning, by integrating a partial convolutional neural network and a generative adversarial network. Partial convolution serves as an observation operator, mapping irregular observational data onto gridded fields, while generative adversarial network incorporates observational information from previous time frames. Our observing system simulation experiments, using simulated observations for the DA, revealed that DeepDA markedly reduces analysis error of the oceanic temperature, outperforming both background and observed values. DeepDA’s real-case global temperature reanalysis spanning from 1981 to 2020 accurately reconstructs observed global climatological temperature fields, along with their seasonal cycles, major oceanic temperature variabilities and global warming trend. Developed solely with a long-term control simulation, DeepDA lowers technical hurdles in creating global ocean reanalysis datasets using multiple numerical models’ physical constraints, thereby diminishing systematic uncertainties in estimating global oceanic states over decades with these models. Data assimilation (DA) techniques are commonly used to assess global Earth system variability but require considerable computational resources and struggle to handle sparse observational data. Ham and colleagues introduce a partial convolution and generative adversarial network-based global oceanic DA system and successfully reconstruct the observed global temperature in a real case study with smaller computational costs than traditional DA systems.},
  archive      = {J_NATMI},
  author       = {Ham, Yoo-Geun and Joo, Yong-Sik and Kim, Jeong-Hwan and Lee, Jeong-Gil},
  doi          = {10.1038/s42256-024-00867-x},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {834-843},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Partial-convolution-implemented generative adversarial network for global oceanic data assimilation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated construction of cognitive maps with visual
predictive coding. <em>NATMI</em>, <em>6</em>(7), 820–833. (<a
href="https://doi.org/10.1038/s42256-024-00863-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans construct internal cognitive maps of their environment directly from sensory inputs without access to a system of explicit coordinates or distance measurements. Although machine learning algorithms like simultaneous localization and mapping utilize specialized inference procedures to identify visual features and construct spatial maps from visual and odometry data, the general nature of cognitive maps in the brain suggests a unified mapping algorithmic strategy that can generalize to auditory, tactile and linguistic inputs. Here we demonstrate that predictive coding provides a natural and versatile neural network algorithm for constructing spatial maps using sensory data. We introduce a framework in which an agent navigates a virtual environment while engaging in visual predictive coding using a self-attention-equipped convolutional neural network. While learning a next-image prediction task, the agent automatically constructs an internal representation of the environment that quantitatively reflects spatial distances. The internal map enables the agent to pinpoint its location relative to landmarks using only visual information.The predictive coding network generates a vectorized encoding of the environment that supports vector navigation, where individual latent space units delineate localized, overlapping neighbourhoods in the environment. Broadly, our work introduces predictive coding as a unified algorithmic framework for constructing cognitive maps that can naturally extend to the mapping of auditory, sensorimotor and linguistic inputs. Constructing spatial maps from sensory inputs is challenging in both neuroscience and artificial intelligence. Gornet and Thomson show that as an agent navigates an environment, a self-attention neural network using predictive coding can recover the environment’s map in its latent space.},
  archive      = {J_NATMI},
  author       = {Gornet, James and Thomson, Matt},
  doi          = {10.1038/s42256-024-00863-1},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {820-833},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Automated construction of cognitive maps with visual predictive coding},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Realistic morphology-preserving generative modelling of the
brain. <em>NATMI</em>, <em>6</em>(7), 811–819. (<a
href="https://doi.org/10.1038/s42256-024-00864-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical imaging research is often limited by data scarcity and availability. Governance, privacy concerns and the cost of acquisition all restrict access to medical imaging data, which, compounded by the data-hungry nature of deep learning algorithms, limits progress in the field of healthcare AI. Generative models have recently been used to synthesize photorealistic natural images, presenting a potential solution to the data scarcity problem. But are current generative models synthesizing morphologically correct samples? In this work we present a three-dimensional generative model of the human brain that is trained at the necessary scale to generate diverse, realistic-looking, high-resolution and morphologically preserving samples and conditioned on patient characteristics (for example, age and pathology). We show that the synthetic samples generated by the model preserve biological and disease phenotypes and are realistic enough to permit use downstream in well-established image analysis tools. While the proposed model has broad future applicability, such as anomaly detection and learning under limited data, its generative capabilities can be used to directly mitigate data scarcity, limited data availability and algorithmic fairness. Medical imaging research is limited by data availability. To address this challenge, Tudosiu and colleagues develop a 3D generative model of the human brain that can generate high-resolution morphologically correct brains conditioned on patient characteristics.},
  archive      = {J_NATMI},
  author       = {Tudosiu, Petru-Daniel and Pinaya, Walter H. L. and Ferreira Da Costa, Pedro and Dafflon, Jessica and Patel, Ashay and Borges, Pedro and Fernandez, Virginia and Graham, Mark S. and Gray, Robert J. and Nachev, Parashkev and Ourselin, Sebastien and Cardoso, M. Jorge},
  doi          = {10.1038/s42256-024-00864-0},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {811-819},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Realistic morphology-preserving generative modelling of the brain},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiscale topology-enabled structure-to-sequence
transformer for protein–ligand interaction predictions. <em>NATMI</em>,
<em>6</em>(7), 799–810. (<a
href="https://doi.org/10.1038/s42256-024-00855-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the success of pretrained natural language processing (NLP) models in various fields, their application in computational biology has been hindered by their reliance on biological sequences, which ignores vital three-dimensional (3D) structural information incompatible with the sequential architecture of NLP models. Here we present a topological transformer (TopoFormer), which is built by integrating NLP models and a multiscale topology technique, the persistent topological hyperdigraph Laplacian (PTHL), which systematically converts intricate 3D protein–ligand complexes at various spatial scales into an NLP-admissible sequence of topological invariants and homotopic shapes. PTHL systematically transforms intricate 3D protein–ligand complexes into NLP-compatible sequences of topological invariants and shapes, capturing essential interactions across spatial scales. TopoFormer gives rise to exemplary scoring accuracy and excellent performance in ranking, docking and screening tasks in several benchmark datasets. This approach can be utilized to convert general high-dimensional structured data into NLP-compatible sequences, paving the way for broader NLP based research. Transformers show much promise for applications in computational biology, but they rely on sequences, and a challenge is to incorporate 3D structural information. TopoFormer, proposed by Dong Chen et al., combines transformers with a mathematical multiscale topology technique to model 3D protein–ligand complexes, substantially enhancing performance in a range of prediction tasks of interest to drug discovery.},
  archive      = {J_NATMI},
  author       = {Chen, Dong and Liu, Jian and Wei, Guo-Wei},
  doi          = {10.1038/s42256-024-00855-1},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {799-810},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Multiscale topology-enabled structure-to-sequence transformer for protein–ligand interaction predictions},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lifelike agility and play in quadrupedal robots using
reinforcement learning and generative pre-trained models.
<em>NATMI</em>, <em>6</em>(7), 787–798. (<a
href="https://doi.org/10.1038/s42256-024-00861-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge from animals and humans inspires robotic innovations. Numerous efforts have been made to achieve agile locomotion in quadrupedal robots through classical controllers or reinforcement learning approaches. These methods usually rely on physical models or handcrafted rewards to accurately describe the specific system, rather than on a generalized understanding like animals do. Here we propose a hierarchical framework to construct primitive-, environmental- and strategic-level knowledge that are all pre-trainable, reusable and enrichable for legged robots. The primitive module summarizes knowledge from animal motion data, where, inspired by large pre-trained models in language and image understanding, we introduce deep generative models to produce motor control signals stimulating legged robots to act like real animals. Then, we shape various traversing capabilities at a higher level to align with the environment by reusing the primitive module. Finally, a strategic module is trained focusing on complex downstream tasks by reusing the knowledge from previous levels. We apply the trained hierarchical controllers to the MAX robot, a quadrupedal robot developed in-house, to mimic animals, traverse complex obstacles and play in a designed challenging multi-agent chase tag game, where lifelike agility and strategy emerge in the robots. A key challenge in robotics is leveraging pre-training as a form of knowledge to generate movements. The authors propose a general learning framework for reusing pre-trained knowledge across different perception and task levels. The deployed robots exhibit lifelike agility and sophisticated game-playing strategies.},
  archive      = {J_NATMI},
  author       = {Han, Lei and Zhu, Qingxu and Sheng, Jiapeng and Zhang, Chong and Li, Tingguang and Zhang, Yizheng and Zhang, He and Liu, Yuzhen and Zhou, Cheng and Zhao, Rui and Li, Jie and Zhang, Yufeng and Wang, Rui and Chi, Wanchao and Li, Xiong and Zhu, Yonghui and Xiang, Lingzhu and Teng, Xiao and Zhang, Zhengyou},
  doi          = {10.1038/s42256-024-00861-3},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {787-798},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Lifelike agility and play in quadrupedal robots using reinforcement learning and generative pre-trained models},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Direct conformational sampling from peptide energy
landscapes through hypernetwork-conditioned diffusion. <em>NATMI</em>,
<em>6</em>(7), 775–786. (<a
href="https://doi.org/10.1038/s42256-024-00860-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning approaches have spurred substantial advances in the single-state prediction of biomolecular structures. The function of biomolecules is, however, dependent on the range of conformations they can assume. This is especially true for peptides, a highly flexible class of molecules that are involved in numerous biological processes and are of high interest as therapeutics. Here we introduce PepFlow, a transferable generative model that enables direct all-atom sampling from the allowable conformational space of input peptides. We train the model in a diffusion framework and subsequently use an equivalent flow to perform conformational sampling. To overcome the prohibitive cost of generalized all-atom modelling, we modularize the generation process and integrate a hypernetwork to predict sequence-specific network parameters. PepFlow accurately predicts peptide structures and effectively recapitulates experimental peptide ensembles at a fraction of the running time of traditional approaches. PepFlow can also be used to sample conformations that satisfy constraints such as macrocyclization. Modelling the different structures a peptide can assume is integral to understanding their function. The authors introduce PepFlow, a sequence-conditioned deep learning model that is shown to accurately and efficiently generate peptide conformations.},
  archive      = {J_NATMI},
  author       = {Abdin, Osama and Kim, Philip M.},
  doi          = {10.1038/s42256-024-00860-4},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {775-786},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Direct conformational sampling from peptide energy landscapes through hypernetwork-conditioned diffusion},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reconciling privacy and accuracy in AI for medical imaging.
<em>NATMI</em>, <em>6</em>(7), 764–774. (<a
href="https://doi.org/10.1038/s42256-024-00858-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) models are vulnerable to information leakage of their training data, which can be highly sensitive, for example, in medical imaging. Privacy-enhancing technologies, such as differential privacy (DP), aim to circumvent these susceptibilities. DP is the strongest possible protection for training models while bounding the risks of inferring the inclusion of training samples or reconstructing the original data. DP achieves this by setting a quantifiable privacy budget. Although a lower budget decreases the risk of information leakage, it typically also reduces the performance of such models. This imposes a trade-off between robust performance and stringent privacy. Additionally, the interpretation of a privacy budget remains abstract and challenging to contextualize. Here we contrast the performance of artificial intelligence models at various privacy budgets against both theoretical risk bounds and empirical success of reconstruction attacks. We show that using very large privacy budgets can render reconstruction attacks impossible, while drops in performance are negligible. We thus conclude that not using DP at all is negligent when applying artificial intelligence models to sensitive data. We deem our results to lay a foundation for further debates on striking a balance between privacy risks and model performance. Ziller and colleagues present a balanced investigation of the trade-off between privacy and performance when training artificially intelligent models for medical imaging analysis tasks. The authors evaluate the use of differential privacy in realistic threat scenarios, leading to their conclusion to promote the use of differential privacy, but implementing it in a manner that also retains performance.},
  archive      = {J_NATMI},
  author       = {Ziller, Alexander and Mueller, Tamara T. and Stieger, Simon and Feiner, Leonhard F. and Brandt, Johannes and Braren, Rickmer and Rueckert, Daniel and Kaissis, Georgios},
  doi          = {10.1038/s42256-024-00858-y},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {764-774},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reconciling privacy and accuracy in AI for medical imaging},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Molecular set representation learning. <em>NATMI</em>,
<em>6</em>(7), 754–763. (<a
href="https://doi.org/10.1038/s42256-024-00856-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational representation of molecules can take many forms, including graphs, string encodings of graphs, binary vectors or learned embeddings in the form of real-valued vectors. These representations are then used in downstream classification and regression tasks using a wide range of machine learning models. However, existing models come with limitations, such as the requirement for clearly defined chemical bonds, which often do not represent the true underlying nature of a molecule. Here we propose a framework for molecular machine learning tasks based on set representation learning. We show that learning on sets of atom invariants alone reaches the performance of state-of-the-art graph-based models on the most-used chemical benchmark datasets and that introducing a set representation layer into graph neural networks can surpass the performance of established methods in the domains of chemistry, biology and material science. We introduce specialized set representation-based neural network architectures for reaction-yield and protein–ligand binding-affinity prediction. Overall, we show that the technique we denote molecular set representation learning is both an alternative and an extension to graph neural network architectures for machine learning tasks on molecules, molecule complexes and chemical reactions. Machine learning methods for molecule predictions use various representations of molecules such as in the form of strings or graphs. As an extension of graph representation learning, Probst and colleagues propose to represent a molecule as a set of atoms, to better capture the underlying chemical nature, and demonstrate improved performance in a range of machine learning tasks.},
  archive      = {J_NATMI},
  author       = {Boulougouri, Maria and Vandergheynst, Pierre and Probst, Daniel},
  doi          = {10.1038/s42256-024-00856-0},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {754-763},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Molecular set representation learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Systematic analysis of 32,111 AI model cards characterizes
documentation practice in AI. <em>NATMI</em>, <em>6</em>(7), 744–753.
(<a href="https://doi.org/10.1038/s42256-024-00857-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid proliferation of AI models has underscored the importance of thorough documentation, which enables users to understand, trust and effectively use these models in various applications. Although developers are encouraged to produce model cards, it’s not clear how much or what information these cards contain. In this study we conduct a comprehensive analysis of 32,111 AI model documentations on Hugging Face, a leading platform for distributing and deploying AI models. Our investigation sheds light on the prevailing model card documentation practices. Most AI models with a substantial number of downloads provide model cards, although with uneven informativeness. We find that sections addressing environmental impact, limitations and evaluation exhibit the lowest filled-out rates, whereas the training section is the one most consistently filled-out. We analyse the content of each section to characterize practitioners’ priorities. Interestingly, there are considerable discussions of data, sometimes with equal or even greater emphasis than the model itself. Our study provides a systematic assessment of community norms and practices surroinding model documentation through large-scale data science and linguistic analysis. As the number of AI models has rapidly grown, there is an increased focus on improving the documentation through model cards. Liang et al. explore questions around adoption practices and the type of information provided in model cards through a large-scale analysis of 32,111 model card documentation from 74,970 models.},
  archive      = {J_NATMI},
  author       = {Liang, Weixin and Rajani, Nazneen and Yang, Xinyu and Ozoani, Ezinwanne and Wu, Eric and Chen, Yiqun and Smith, Daniel Scott and Zou, James},
  doi          = {10.1038/s42256-024-00857-z},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {744-753},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Systematic analysis of 32,111 AI model cards characterizes documentation practice in AI},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shielding sensitive medical imaging data. <em>NATMI</em>,
<em>6</em>(7), 742–743. (<a
href="https://doi.org/10.1038/s42256-024-00865-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy offers protection in medical image processing but is traditionally thought to hinder accuracy. A recent study offers a reality check on the relationship between privacy measures and the ability of an artificial intelligence (AI) model to accurately analyse medical images.},
  archive      = {J_NATMI},
  author       = {Liu, Gaoyang and Wang, Chen and Xia, Tian},
  doi          = {10.1038/s42256-024-00865-z},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {742-743},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Shielding sensitive medical imaging data},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The need for reproducible research in soft robotics.
<em>NATMI</em>, <em>6</em>(7), 740–741. (<a
href="https://doi.org/10.1038/s42256-024-00869-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Baines, Robert and Shah, Dylan and Marvel, Jeremy and Case, Jennifer and Spielberg, Andrew},
  doi          = {10.1038/s42256-024-00869-9},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {740-741},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The need for reproducible research in soft robotics},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A question of trust for AI research in medicine.
<em>NATMI</em>, <em>6</em>(7), 739. (<a
href="https://doi.org/10.1038/s42256-024-00880-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical research is one of the most impactful areas for machine learning applications, but access to large and diverse health datasets is needed for models to be useful. Winning trust from patients by demonstrating that data are handled securely and effectively is key.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-024-00880-0},
  journal      = {Nature Machine Intelligence},
  month        = {7},
  number       = {7},
  pages        = {739},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A question of trust for AI research in medicine},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discovering neural policies to drive behaviour by
integrating deep reinforcement learning agents with biological neural
networks. <em>NATMI</em>, <em>6</em>(6), 726–738. (<a
href="https://doi.org/10.1038/s42256-024-00854-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (RL) has been successful in a variety of domains but has not yet been directly used to learn biological tasks by interacting with a living nervous system. As proof of principle, we show how to create such a hybrid system trained on a target-finding task. Using optogenetics, we interfaced the nervous system of the nematode Caenorhabditis elegans with a deep RL agent. Agents adapted to strikingly different sites of neural integration and learned site-specific activations to guide animals towards a target, including in cases where agents interfaced with sets of neurons with previously uncharacterized responses to optogenetic modulation. Agents were analysed by plotting their learned policies to understand how different sets of neurons were used to guide movement. Further, the animal and agent generalized to new environments using the same learned policies in food-search tasks, showing that the system achieved cooperative computation rather than the agent acting as a controller for a soft robot. Our system demonstrates that deep RL is a viable tool both for learning how neural circuits can produce goal-directed behaviour and for improving biologically relevant behaviour in a flexible way. Deep reinforcement learning (RL) has been successful in many fields but has not been used to directly improve behaviours by interfacing with living nervous systems. Li et al. present a framework that integrates deep RL agents with the nervous system of the nematode Caenorhabditis elegans. Their study shows that trained agents can assist animals in biologically relevant tasks and can be studied after training to map out effective neural policies.},
  archive      = {J_NATMI},
  author       = {Li, Chenguang and Kreiman, Gabriel and Ramanathan, Sharad},
  doi          = {10.1038/s42256-024-00854-2},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {726-738},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Discovering neural policies to drive behaviour by integrating deep reinforcement learning agents with biological neural networks},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Coordinate-based neural representations for computational
adaptive optics in widefield microscopy. <em>NATMI</em>, <em>6</em>(6),
714–725. (<a href="https://doi.org/10.1038/s42256-024-00853-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Widefield microscopy is widely used for non-invasive imaging of biological structures at subcellular resolution. When applied to a complex specimen, its image quality is degraded by sample-induced optical aberration. Adaptive optics can correct wavefront distortion and restore diffraction-limited resolution but require wavefront sensing and corrective devices, increasing system complexity and cost. Here we describe a self-supervised machine learning algorithm, CoCoA, that performs joint wavefront estimation and three-dimensional structural information extraction from a single-input three-dimensional image stack without the need for external training datasets. We implemented CoCoA for widefield imaging of mouse brain tissues and validated its performance with direct-wavefront-sensing-based adaptive optics. Importantly, we systematically explored and quantitatively characterized the limiting factors of CoCoA’s performance. Using CoCoA, we demonstrated in vivo widefield mouse brain imaging using machine learning-based adaptive optics. Incorporating coordinate-based neural representations and a forward physics model, the self-supervised scheme of CoCoA should be applicable to microscopy modalities in general. Adaptive optics (AO) corrects aberrations and restores resolution but requires specialized hardware. Kang et al. introduce a self-supervised AO method (CoCoA) for widefield microscopy, achieving in vivo mouse brain imaging without wavefront sensors.},
  archive      = {J_NATMI},
  author       = {Kang, Iksung and Zhang, Qinrong and Yu, Stella X. and Ji, Na},
  doi          = {10.1038/s42256-024-00853-3},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {714-725},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Coordinate-based neural representations for computational adaptive optics in widefield microscopy},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interpreting cis-regulatory mechanisms from genomic deep
neural networks using surrogate models. <em>NATMI</em>, <em>6</em>(6),
701–713. (<a href="https://doi.org/10.1038/s42256-024-00851-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have greatly advanced the ability to predict genome function from sequence. However, elucidating underlying biological mechanisms from genomic DNNs remains challenging. Existing interpretability methods, such as attribution maps, have their origins in non-biological machine learning applications and therefore have the potential to be improved by incorporating domain-specific interpretation strategies. Here we introduce SQUID (Surrogate Quantitative Interpretability for Deepnets), a genomic DNN interpretability framework based on domain-specific surrogate modelling. SQUID approximates genomic DNNs in user-specified regions of sequence space using surrogate models—simpler quantitative models that have inherently interpretable mathematical forms. SQUID leverages domain knowledge to model cis-regulatory mechanisms in genomic DNNs, in particular by removing the confounding effects that nonlinearities and heteroscedastic noise in functional genomics data can have on model interpretation. Benchmarking analysis on multiple genomic DNNs shows that SQUID, when compared to established interpretability methods, identifies motifs that are more consistent across genomic loci and yields improved single-nucleotide variant-effect predictions. SQUID also supports surrogate models that quantify epistatic interactions within and between cis-regulatory elements, as well as global explanations of cis-regulatory mechanisms across sequence contexts. SQUID thus advances the ability to mechanistically interpret genomic DNNs. The intersection of genomics and deep learning shows promise for real impact on healthcare and biological research, but the lack of interpretability in terms of biological mechanisms is limiting utility and further development. As a potential solution, Koo et al. present SQUID, an interpretability framework built using domain-specific genomic surrogate models.},
  archive      = {J_NATMI},
  author       = {Seitz, Evan E. and McCandlish, David M. and Kinney, Justin B. and Koo, Peter K.},
  doi          = {10.1038/s42256-024-00851-5},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {701-713},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Interpreting cis-regulatory mechanisms from genomic deep neural networks using surrogate models},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generic protein–ligand interaction scoring by integrating
physical prior knowledge and data augmentation modelling.
<em>NATMI</em>, <em>6</em>(6), 688–700. (<a
href="https://doi.org/10.1038/s42256-024-00849-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing robust methods for evaluating protein–ligand interactions has been a long-standing problem. Data-driven methods may memorize ligand and protein training data rather than learning protein–ligand interactions. Here we show a scoring approach called EquiScore, which utilizes a heterogeneous graph neural network to integrate physical prior knowledge and characterize protein–ligand interactions in equivariant geometric space. EquiScore is trained based on a new dataset constructed with multiple data augmentation strategies and a stringent redundancy-removal scheme. On two large external test sets, EquiScore consistently achieved top-ranking performance compared to 21 other methods. When EquiScore is used alongside different docking methods, it can effectively enhance the screening ability of these docking methods. EquiScore also showed good performance on the activity-ranking task of a series of structural analogues, indicating its potential to guide lead compound optimization. Finally, we investigated different levels of interpretability of EquiScore, which may provide more insights into structure-based drug design. Machine learning can improve scoring methods to evaluate protein–ligand interactions, but achieving good generalization is an outstanding challenge. Cao et al. introduce EquiScore, which is based on a graph neural network that integrates physical knowledge and is shown to have robust capabilities when applied to unseen protein targets.},
  archive      = {J_NATMI},
  author       = {Cao, Duanhua and Chen, Geng and Jiang, Jiaxin and Yu, Jie and Zhang, Runze and Chen, Mingan and Zhang, Wei and Chen, Lifan and Zhong, Feisheng and Zhang, Yingying and Lu, Chenghao and Li, Xutong and Luo, Xiaomin and Zhang, Sulin and Zheng, Mingyue},
  doi          = {10.1038/s42256-024-00849-z},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {688-700},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Generic protein–ligand interaction scoring by integrating physical prior knowledge and data augmentation modelling},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Physicochemical graph neural network for learning
protein–ligand interaction fingerprints from sequence data.
<em>NATMI</em>, <em>6</em>(6), 673–687. (<a
href="https://doi.org/10.1038/s42256-024-00847-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In drug discovery, determining the binding affinity and functional effects of small-molecule ligands on proteins is critical. Current computational methods can predict these protein–ligand interaction properties but often lose accuracy without high-resolution protein structures and falter in predicting functional effects. Here we introduce PSICHIC (PhySIcoCHemICal graph neural network), a framework incorporating physicochemical constraints to decode interaction fingerprints directly from sequence data alone. This enables PSICHIC to attain capabilities in decoding mechanisms underlying protein–ligand interactions, achieving state-of-the-art accuracy and interpretability. Trained on identical protein–ligand pairs without structural data, PSICHIC matched and even surpassed leading structure-based methods in binding-affinity prediction. In an experimental library screening for adenosine A1 receptor agonists, PSICHIC discerned functional effects effectively, ranking the sole novel agonist within the top three. PSICHIC’s interpretable fingerprints identified protein residues and ligand atoms involved in interactions, and helped in unveiling selectivity determinants of protein–ligand interaction. We foresee PSICHIC reshaping virtual screening and deepening our understanding of protein–ligand interactions. Predicting the binding affinity between small-molecule ligands and proteins is a key task in drug discovery; however, sequence-based methods are often less accurate than structure-based ones. Koh et al. develop a graph neural network using physicochemical constraints that discovers interactions between small molecules and proteins directly from sequence data and that can achieve state-of-the-art performance without the need for costly, experimental 3D structures.},
  archive      = {J_NATMI},
  author       = {Koh, Huan Yee and Nguyen, Anh T. N. and Pan, Shirui and May, Lauren T. and Webb, Geoffrey I.},
  doi          = {10.1038/s42256-024-00847-1},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {673-687},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Physicochemical graph neural network for learning protein–ligand interaction fingerprints from sequence data},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed constrained combinatorial optimization
leveraging hypergraph neural networks. <em>NATMI</em>, <em>6</em>(6),
664–672. (<a href="https://doi.org/10.1038/s42256-024-00833-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scalable addressing of high-dimensional constrained combinatorial optimization problems is a challenge that arises in several science and engineering disciplines. Recent work introduced novel applications of graph neural networks for solving quadratic-cost combinatorial optimization problems. However, effective utilization of models such as graph neural networks to address general problems with higher-order constraints is an unresolved challenge. This paper presents a framework, HypOp, that advances the state of the art for solving combinatorial optimization problems in several aspects: (1) it generalizes the prior results to higher-order constrained problems with arbitrary cost functions by leveraging hypergraph neural networks; (2) it enables scalability to larger problems by introducing a new distributed and parallel training architecture; (3) it demonstrates generalizability across different problem formulations by transferring knowledge within the same hypergraph; (4) it substantially boosts the solution accuracy compared with the prior art by suggesting a fine-tuning step using simulated annealing; and (5) it shows remarkable progress on numerous benchmark examples, including hypergraph MaxCut, satisfiability and resource allocation problems, with notable run-time improvements using a combination of fine-tuning and distributed training techniques. We showcase the application of HypOp in scientific discovery by solving a hypergraph MaxCut problem on a National Drug Code drug-substance hypergraph. Through extensive experimentation on various optimization problems, HypOp demonstrates superiority over existing unsupervised-learning-based solvers and generic optimization methods. Bolstering the broad and deep applicability of graph neural networks, Heydaribeni et al. introduce HypOp, a framework that uses hypergraph neural networks to solve general constrained combinatorial optimization problems. The presented method scales and generalizes well, improves accuracy and outperforms existing solvers on various benchmarking examples.},
  archive      = {J_NATMI},
  author       = {Heydaribeni, Nasimeh and Zhan, Xinrui and Zhang, Ruisi and Eliassi-Rad, Tina and Koushanfar, Farinaz},
  doi          = {10.1038/s42256-024-00833-7},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {664-672},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Distributed constrained combinatorial optimization leveraging hypergraph neural networks},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visual odometry with neuromorphic resonator networks.
<em>NATMI</em>, <em>6</em>(6), 653–663. (<a
href="https://doi.org/10.1038/s42256-024-00846-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual odometry (VO) is a method used to estimate self-motion of a mobile robot using visual sensors. Unlike odometry based on integrating differential measurements that can accumulate errors, such as inertial sensors or wheel encoders, VO is not compromised by drift. However, image-based VO is computationally demanding, limiting its application in use cases with low-latency, low-memory and low-energy requirements. Neuromorphic hardware offers low-power solutions to many vision and artificial intelligence problems, but designing such solutions is complicated and often has to be assembled from scratch. Here we propose the use of vector symbolic architecture (VSA) as an abstraction layer to design algorithms compatible with neuromorphic hardware. Building from a VSA model for scene analysis, described in our companion paper, we present a modular neuromorphic algorithm that achieves state-of-the-art performance on two-dimensional VO tasks. Specifically, the proposed algorithm stores and updates a working memory of the presented visual environment. Based on this working memory, a resonator network estimates the changing location and orientation of the camera. We experimentally validate the neuromorphic VSA-based approach to VO with two benchmarks: one based on an event-camera dataset and the other in a dynamic scene with a robotic task. Visual odometry, or self-motion estimation, is a fundamental task in robotics. Renner, Supic and colleagues introduce a neuromorphic algorithm for visual odometry that leverages hyperdimensional computing and hierarchical resonators. The approach estimates a robot’s motion from event-based vision, a step towards low-power machine vision for robotics.},
  archive      = {J_NATMI},
  author       = {Renner, Alpha and Supic, Lazar and Danielescu, Andreea and Indiveri, Giacomo and Frady, E. Paxon and Sommer, Friedrich T. and Sandamirskaya, Yulia},
  doi          = {10.1038/s42256-024-00846-2},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {653-663},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Visual odometry with neuromorphic resonator networks},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neuromorphic visual scene understanding with resonator
networks. <em>NATMI</em>, <em>6</em>(6), 641–652. (<a
href="https://doi.org/10.1038/s42256-024-00848-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analysing a visual scene by inferring the configuration of a generative model is widely considered the most flexible and generalizable approach to scene understanding. Yet, one major problem is the computational challenge of the inference procedure, involving a combinatorial search across object identities and poses. Here we propose a neuromorphic solution exploiting three key concepts: (1) a computational framework based on vector symbolic architectures (VSAs) with complex-valued vectors, (2) the design of hierarchical resonator networks to factorize the non-commutative transforms translation and rotation in visual scenes and (3) the design of a multi-compartment spiking phasor neuron model for implementing complex-valued resonator networks on neuromorphic hardware. The VSA framework uses vector binding operations to form a generative image model in which binding acts as the equivariant operation for geometric transformations. A scene can therefore be described as a sum of vector products, which can then be efficiently factorized by a resonator network to infer objects and their poses. The hierarchical resonator network features a partitioned architecture in which vector binding is equivariant for horizontal and vertical translation within one partition and for rotation and scaling within the other partition. The spiking neuron model allows mapping the resonator network onto efficient and low-power neuromorphic hardware. Our approach is demonstrated on synthetic scenes composed of simple two-dimensional shapes undergoing rigid geometric transformations and colour changes. A companion paper demonstrates the same approach in real-world application scenarios for machine vision and robotics. The inference procedure for analysing a visual scene presents a computational challenge. Renner, Supic and colleagues develop a neural network model, the hierarchical resonator, to determine the generative factors of variation of objects in simple scenes. The resonator was implemented on neuromorphic hardware, using a spike-timing code for complex numbers.},
  archive      = {J_NATMI},
  author       = {Renner, Alpha and Supic, Lazar and Danielescu, Andreea and Indiveri, Giacomo and Olshausen, Bruno A. and Sandamirskaya, Yulia and Sommer, Friedrich T. and Frady, E. Paxon},
  doi          = {10.1038/s42256-024-00848-0},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {641-652},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Neuromorphic visual scene understanding with resonator networks},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Laplace neural operator for solving differential equations.
<em>NATMI</em>, <em>6</em>(6), 631–640. (<a
href="https://doi.org/10.1038/s42256-024-00844-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural operators map multiple functions to different functions, possibly in different spaces, unlike standard neural networks. Hence, neural operators allow the solution of parametric ordinary differential equations (ODEs) and partial differential equations (PDEs) for a distribution of boundary or initial conditions and excitations, but can also be used for system identification as well as designing various components of digital twins. We introduce the Laplace neural operator (LNO), which incorporates the pole–residue relationship between input–output spaces, leading to better interpretability and generalization for certain classes of problems. The LNO is capable of processing non-periodic signals and transient responses resulting from simultaneously zero and non-zero initial conditions, which makes it achieve better approximation accuracy over other neural operators for extrapolation circumstances in solving several ODEs and PDEs. We also highlight the LNO’s good interpolation ability, from a low-resolution input to high-resolution outputs at arbitrary locations within the domain. To demonstrate the scalability of LNO, we conduct large-scale simulations of Rossby waves around the globe, employing millions of degrees of freedom. Taken together, our findings show that a pretrained LNO model offers an effective real-time solution for general ODEs and PDEs at scale and is an efficient alternative to existing neural operators. Neural operators are powerful neural networks that approximate nonlinear dynamical systems and their responses. Cao and colleagues introduce the Laplace neural operator, a scalable approach that can effectively deal with non-periodic signals and transient responses and can outperform existing neural operators on certain classes of ODE and PDE problems.},
  archive      = {J_NATMI},
  author       = {Cao, Qianying and Goswami, Somdatta and Karniadakis, George Em},
  doi          = {10.1038/s42256-024-00844-4},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {631-640},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Laplace neural operator for solving differential equations},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning efficient backprojections across cortical
hierarchies in real time. <em>NATMI</em>, <em>6</em>(6), 619–630. (<a
href="https://doi.org/10.1038/s42256-024-00845-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Models of sensory processing and learning in the cortex need to efficiently assign credit to synapses in all areas. In deep learning, a known solution is error backpropagation, which requires biologically implausible weight transport from feed-forwards to feedback paths. We introduce phaseless alignment learning, a bio-plausible method to learn efficient feedback weights in layered cortical hierarchies. This is achieved by exploiting the noise naturally found in biophysical systems as an additional carrier of information. In our dynamical system, all weights are learned simultaneously with always-on plasticity and using only information locally available to the synapses. Our method is completely phase-free (no forwards and backwards passes or phased learning) and allows for efficient error propagation across multi-layer cortical hierarchies, while maintaining biologically plausible signal transport and learning. Our method is applicable to a wide class of models and improves on previously known biologically plausible ways of credit assignment: compared to random synaptic feedback, it can solve complex tasks with fewer neurons and learn more useful latent representations. We demonstrate this on various classification tasks using a cortical microcircuit model with prospective coding. The credit assignment problem involves assigning credit to synapses in a neural network so that weights are updated appropriately and the circuit learns. Max et al. developed an efficient solution to the weight transport problem in networks of biophysical neurons. The method exploits noise as an information carrier and enables networks to learn to solve a task efficiently.},
  archive      = {J_NATMI},
  author       = {Max, Kevin and Kriener, Laura and Pineda García, Garibaldi and Nowotny, Thomas and Jaras, Ismael and Senn, Walter and Petrovici, Mihai A.},
  doi          = {10.1038/s42256-024-00845-3},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {619-630},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Learning efficient backprojections across cortical hierarchies in real time},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning for micro- and nanorobots. <em>NATMI</em>,
<em>6</em>(6), 605–618. (<a
href="https://doi.org/10.1038/s42256-024-00859-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) has revolutionized robotics by enhancing perception, adaptability, decision-making and more, enabling robots to work in complex scenarios beyond the capabilities of traditional approaches. However, the downsizing of robots to micro- and nanoscales introduces new challenges. For example, complexities in the actuation and locomotion of micro- and nanorobots defy traditional modelling methods, while control and navigation are complicated by strong environmental disruptions, and tracking in vivo encounters substantial noise interference. Recently, ML has also been shown to offer a promising avenue to tackle these complexities. Here we discuss how ML advances many crucial aspects of micro- and nanorobots, that is, in their design, actuation, locomotion, planning, tracking and navigation. Any application that can benefit from these fundamental advancements will be a potential beneficiary of this field, including micromanipulation, targeted delivery and therapy, bio-sensing, diagnosis and so on. This Review aims to provide an accessible and comprehensive survey for readers to quickly appreciate recent exciting accomplishments in ML for micro- and nanorobots. We also discuss potential issues and prospects of this burgeoning research direction. We hope this Review can foster interdisciplinary collaborations across robotics, computer science, material science and allied disciplines, to develop ML techniques that surmount fundamental challenges and further expand the application horizons of micro- and nanorobotics in biomedicine. Machine learning approaches in micro- and nanorobotics promise to overcome challenges encountered by applying traditional control methods at the microscopic scale. Lidong Yang et al. review this emerging area in robotics and discuss machine learning developments in design, actuation, locomotion, planning, tracking and navigation of microrobots.},
  archive      = {J_NATMI},
  author       = {Yang, Lidong and Jiang, Jialin and Ji, Fengtong and Li, Yangmin and Yung, Kai-Leung and Ferreira, Antoine and Zhang, Li},
  doi          = {10.1038/s42256-024-00859-x},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {605-618},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Machine learning for micro- and nanorobots},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning-aided generative molecular design.
<em>NATMI</em>, <em>6</em>(6), 589–604. (<a
href="https://doi.org/10.1038/s42256-024-00843-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has provided a means to accelerate early-stage drug discovery by combining molecule generation and filtering steps in a single architecture that leverages the experience and design preferences of medicinal chemists. However, designing machine learning models that can achieve this on the fly to the satisfaction of medicinal chemists remains a challenge owing to the enormous search space. Researchers have addressed de novo design of molecules by decomposing the problem into a series of tasks determined by design criteria. Here we provide a comprehensive overview of the current state of the art in molecular design using machine learning models as well as important design decisions, such as the choice of molecular representations, generative methods and optimization strategies. Subsequently, we present a collection of practical applications in which the reviewed methodologies have been experimentally validated, encompassing both academic and industrial efforts. Finally, we draw attention to the theoretical, computational and empirical challenges in deploying generative machine learning and highlight future opportunities to better align such approaches to achieve realistic drug discovery end points. Data-driven generative methods have the potential to greatly facilitate molecular design tasks for drug design.},
  archive      = {J_NATMI},
  author       = {Du, Yuanqi and Jamasb, Arian R. and Guo, Jeff and Fu, Tianfan and Harris, Charles and Wang, Yingheng and Duan, Chenru and Liò, Pietro and Schwaller, Philippe and Blundell, Tom L.},
  doi          = {10.1038/s42256-024-00843-5},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {589-604},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Machine learning-aided generative molecular design},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Challenges, evaluation and opportunities for open-world
learning. <em>NATMI</em>, <em>6</em>(6), 580–588. (<a
href="https://doi.org/10.1038/s42256-024-00852-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Environmental changes can profoundly impact the performance of artificial intelligence systems operating in the real world, with effects ranging from overt catastrophic failures to non-robust behaviours that do not take changing context into account. Here we argue that designing machine intelligence that can operate in open worlds, including detecting, characterizing and adapting to structurally unexpected environmental changes, is a critical goal on the path to building systems that can solve complex and relatively under-determined problems. We present and distinguish between three forms of open-world learning (OWL)—weak, semi-strong and strong—and argue that a fully developed OWL system should be antifragile, rather than merely robust. An antifragile system, an example of which is the immune system, is not only robust to adverse events, but adapts to them quickly and becomes better at handling them in subsequent encounters. We also argue that, because OWL approaches must be capable of handling the unexpected, their practical evaluation can pose an interesting conceptual problem. AI systems operating in the real world unavoidably encounter unexpected environmental changes and need a built-in robustness and capability to learn fast, making use of advances such as lifelong and few-shot learning. Kejriwal et al. discuss three categories of such open-world learning and discuss applications such as self-driving cars and robotic inspection.},
  archive      = {J_NATMI},
  author       = {Kejriwal, Mayank and Kildebeck, Eric and Steininger, Robert and Shrivastava, Abhinav},
  doi          = {10.1038/s42256-024-00852-4},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {580-588},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Challenges, evaluation and opportunities for open-world learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Will generative AI transform robotics? <em>NATMI</em>,
<em>6</em>(6), 579. (<a
href="https://doi.org/10.1038/s42256-024-00862-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current wave of excitement about applying large vision–language models and generative AI to robotics, expectations are running high, but conquering real-world complexities remains challenging for robots.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-024-00862-2},
  journal      = {Nature Machine Intelligence},
  month        = {6},
  number       = {6},
  pages        = {579},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Will generative AI transform robotics?},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient learning of accurate surrogates for simulations of
complex systems. <em>NATMI</em>, <em>6</em>(5), 568–577. (<a
href="https://doi.org/10.1038/s42256-024-00839-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning methods are increasingly deployed to construct surrogate models for complex physical systems at a reduced computational cost. However, the predictive capability of these surrogates degrades in the presence of noisy, sparse or dynamic data. We introduce an online learning method empowered by optimizer-driven sampling that has two advantages over current approaches: it ensures that all local extrema (including endpoints) of the model response surface are included in the training data, and it employs a continuous validation and update process in which surrogates undergo retraining when their performance falls below a validity threshold. We find, using benchmark functions, that optimizer-directed sampling generally outperforms traditional sampling methods in terms of accuracy around local extrema even when the scoring metric is biased towards assessing overall accuracy. Finally, the application to dense nuclear matter demonstrates that highly accurate surrogates for a nuclear equation-of-state model can be reliably autogenerated from expensive calculations using few model evaluations. Machine learning-based surrogate models are important to model complex systems at a reduced computational cost; however, they must often be re-evaluated and adapted for validity on future data. Diaw and colleagues propose an online training method leveraging optimizer-directed sampling to produce surrogate models that can be applied to any future data and demonstrate the approach on a dense nuclear-matter equation of state containing a phase transition.},
  archive      = {J_NATMI},
  author       = {Diaw, A. and McKerns, M. and Sagert, I. and Stanton, L. G. and Murillo, M. S.},
  doi          = {10.1038/s42256-024-00839-1},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {568-577},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Efficient learning of accurate surrogates for simulations of complex systems},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Predicting equilibrium distributions for molecular systems
with deep learning. <em>NATMI</em>, <em>6</em>(5), 558–567. (<a
href="https://doi.org/10.1038/s42256-024-00837-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in deep learning have greatly improved structure prediction of molecules. However, many macroscopic observations that are important for real-world applications are not functions of a single molecular structure but rather determined from the equilibrium distribution of structures. Conventional methods for obtaining these distributions, such as molecular dynamics simulation, are computationally expensive and often intractable. Here we introduce a deep learning framework, called Distributional Graphormer (DiG), in an attempt to predict the equilibrium distribution of molecular systems. Inspired by the annealing process in thermodynamics, DiG uses deep neural networks to transform a simple distribution towards the equilibrium distribution, conditioned on a descriptor of a molecular system such as a chemical graph or a protein sequence. This framework enables the efficient generation of diverse conformations and provides estimations of state densities, orders of magnitude faster than conventional methods. We demonstrate applications of DiG on several molecular tasks, including protein conformation sampling, ligand structure sampling, catalyst–adsorbate sampling and property-guided structure generation. DiG presents a substantial advancement in methodology for statistically understanding molecular systems, opening up new research opportunities in the molecular sciences. Methods for predicting molecular structure predictions have so far focused on only the most probable conformation, but molecular structures are dynamic and can change when performing their biological functions, for example. Zheng et al. use a graph transformer approach to learn the equilibrium distribution of molecular systems and show that this can be helpful for a number of downstream tasks, including protein structure prediction, ligand docking and molecular design.},
  archive      = {J_NATMI},
  author       = {Zheng, Shuxin and He, Jiyan and Liu, Chang and Shi, Yu and Lu, Ziheng and Feng, Weitao and Ju, Fusong and Wang, Jiaxi and Zhu, Jianwei and Min, Yaosen and Zhang, He and Tang, Shidi and Hao, Hongxia and Jin, Peiran and Chen, Chi and Noé, Frank and Liu, Haiguang and Liu, Tie-Yan},
  doi          = {10.1038/s42256-024-00837-3},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {558-567},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Predicting equilibrium distributions for molecular systems with deep learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-purpose RNA language modelling with motif-aware
pretraining and type-guided fine-tuning. <em>NATMI</em>, <em>6</em>(5),
548–557. (<a href="https://doi.org/10.1038/s42256-024-00836-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pretrained language models have shown promise in analysing nucleotide sequences, yet a versatile model excelling across diverse tasks with a single pretrained weight set remains elusive. Here we introduce RNAErnie, an RNA-focused pretrained model built upon the transformer architecture, employing two simple yet effective strategies. First, RNAErnie enhances pretraining by incorporating RNA motifs as biological priors and introducing motif-level random masking in addition to masked language modelling at base/subsequence levels. It also tokenizes RNA types (for example, miRNA, lnRNA) as stop words, appending them to sequences during pretraining. Second, subject to out-of-distribution tasks with RNA sequences not seen during the pretraining phase, RNAErnie proposes a type-guided fine-tuning strategy that first predicts possible RNA types using an RNA sequence and then appends the predicted type to the tail of sequence to refine feature embedding in a post hoc way. Our extensive evaluation across seven datasets and five tasks demonstrates the superiority of RNAErnie in both supervised and unsupervised learning. It surpasses baselines with up to 1.8% higher accuracy in classification, 2.2% greater accuracy in interaction prediction and 3.3% improved F1 score in structure prediction, showcasing its robustness and adaptability with a unified pretrained foundation. Despite the existence of various pretrained language models for nucleotide sequence analysis, achieving good performance on a broad range of downstream tasks using a single model is challenging. Wang and colleagues develop a pretrained language model specifically optimized for RNA sequence analysis and show that it can outperform state-of-the-art methods in a diverse set of downstream tasks.},
  archive      = {J_NATMI},
  author       = {Wang, Ning and Bian, Jiang and Li, Yuchen and Li, Xuhong and Mumtaz, Shahid and Kong, Linghe and Xiong, Haoyi},
  doi          = {10.1038/s42256-024-00836-4},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {548-557},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Multi-purpose RNA language modelling with motif-aware pretraining and type-guided fine-tuning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accurate and robust protein sequence design with
CarbonDesign. <em>NATMI</em>, <em>6</em>(5), 536–547. (<a
href="https://doi.org/10.1038/s42256-024-00838-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein sequence design is critically important for protein engineering. Despite recent advancements in deep learning-based methods, achieving accurate and robust sequence design remains a challenge. Here we present CarbonDesign, an approach that draws inspiration from successful ingredients of AlphaFold and which has been developed specifically for protein sequence design. At its core, CarbonDesign introduces Inverseformer, which learns representations from backbone structures and an amortized Markov random fields model for sequence decoding. Moreover, we incorporate other essential AlphaFold concepts into CarbonDesign: an end-to-end network recycling technique to leverage evolutionary constraints from protein language models and a multitask learning technique for generating side-chain structures alongside designed sequences. CarbonDesign outperforms other methods on independent test sets including the 15th Critical Assessment of protein Structure Prediction (CASP15) dataset, the Continuous Automated Model Evaluation (CAMEO) dataset and de novo proteins from RFDiffusion. Furthermore, it supports zero-shot prediction of the functional effects of sequence variants, making it a promising tool for applications in bioengineering. Deep learning has led to great advances in predicting protein structure from sequences. Ren and colleagues present here a method for the inverse problem of finding a sequence that results in a desired protein structure, which is inspired by various components of AlphaFold combined with Markov random fields to decode sequences more efficiently.},
  archive      = {J_NATMI},
  author       = {Ren, Milong and Yu, Chungong and Bu, Dongbo and Zhang, Haicang},
  doi          = {10.1038/s42256-024-00838-2},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {536-547},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Accurate and robust protein sequence design with CarbonDesign},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Augmenting large language models with chemistry tools.
<em>NATMI</em>, <em>6</em>(5), 525–535. (<a
href="https://doi.org/10.1038/s42256-024-00832-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have shown strong performance in tasks across domains but struggle with chemistry-related problems. These models also lack access to external knowledge sources, limiting their usefulness in scientific applications. We introduce ChemCrow, an LLM chemistry agent designed to accomplish tasks across organic synthesis, drug discovery and materials design. By integrating 18 expert-designed tools and using GPT-4 as the LLM, ChemCrow augments the LLM performance in chemistry, and new capabilities emerge. Our agent autonomously planned and executed the syntheses of an insect repellent and three organocatalysts and guided the discovery of a novel chromophore. Our evaluation, including both LLM and expert assessments, demonstrates ChemCrow’s effectiveness in automating a diverse set of chemical tasks. Our work not only aids expert chemists and lowers barriers for non-experts but also fosters scientific advancement by bridging the gap between experimental and computational chemistry. Large language models can be queried to perform chain-of-thought reasoning on text descriptions of data or computational tools, which can enable flexible and autonomous workflows. Bran et al. developed ChemCrow, a GPT-4-based agent that has access to computational chemistry tools and a robotic chemistry platform, which can autonomously solve tasks for designing or synthesizing chemicals such as drugs or materials.},
  archive      = {J_NATMI},
  author       = {M. Bran, Andres and Cox, Sam and Schilter, Oliver and Baldassari, Carlo and White, Andrew D. and Schwaller, Philippe},
  doi          = {10.1038/s42256-024-00832-8},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {525-535},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Augmenting large language models with chemistry tools},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantum circuit synthesis with diffusion models.
<em>NATMI</em>, <em>6</em>(5), 515–524. (<a
href="https://doi.org/10.1038/s42256-024-00831-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing has recently emerged as a transformative technology. Yet, its promised advantages rely on efficiently translating quantum operations into viable physical realizations. Here we use generative machine learning models, specifically denoising diffusion models (DMs), to facilitate this transformation. Leveraging text conditioning, we steer the model to produce desired quantum operations within gate-based quantum circuits. Notably, DMs allow to sidestep during training the exponential overhead inherent in the classical simulation of quantum dynamics—a consistent bottleneck in preceding machine learning techniques. We demonstrate the model’s capabilities across two tasks: entanglement generation and unitary compilation. The model excels at generating new circuits and supports typical DM extensions such as masking and editing to, for instance, align the circuit generation to the constraints of the targeted quantum device. Given their flexibility and generalization abilities, we envision DMs as pivotal in quantum circuit synthesis, both enhancing practical applications and providing insights into theoretical quantum computation. Achieving the promised advantages of quantum computing relies on translating quantum operations into physical realizations. Fürrutter and colleagues use diffusion models to create quantum circuits that are based on user specifications and tailored to experimental constraints.},
  archive      = {J_NATMI},
  author       = {Fürrutter, Florian and Muñoz-Gil, Gorka and Briegel, Hans J.},
  doi          = {10.1038/s42256-024-00831-9},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {515-524},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Quantum circuit synthesis with diffusion models},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maximum diffusion reinforcement learning. <em>NATMI</em>,
<em>6</em>(5), 504–514. (<a
href="https://doi.org/10.1038/s42256-024-00829-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots and animals both experience the world through their bodies and senses. Their embodiment constrains their experiences, ensuring that they unfold continuously in space and time. As a result, the experiences of embodied agents are intrinsically correlated. Correlations create fundamental challenges for machine learning, as most techniques rely on the assumption that data are independent and identically distributed. In reinforcement learning, where data are directly collected from an agent’s sequential experiences, violations of this assumption are often unavoidable. Here we derive a method that overcomes this issue by exploiting the statistical mechanics of ergodic processes, which we term maximum diffusion reinforcement learning. By decorrelating agent experiences, our approach provably enables single-shot learning in continuous deployments over the course of individual task attempts. Moreover, we prove our approach generalizes well-known maximum entropy techniques and robustly exceeds state-of-the-art performance across popular benchmarks. Our results at the nexus of physics, learning and control form a foundation for transparent and reliable decision-making in embodied reinforcement learning agents. The central assumption in machine learning that data are independent and identically distributed does not hold in many reinforcement learning settings, as experiences of reinforcement learning agents are sequential and intrinsically correlated in time. Berrueta and colleagues use the mathematical theory of ergodic processes to develop a reinforcement framework that can decorrelate agent experiences and is capable of learning in single-shot deployments.},
  archive      = {J_NATMI},
  author       = {Berrueta, Thomas A. and Pinosky, Allison and Murphey, Todd D.},
  doi          = {10.1038/s42256-024-00829-3},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {504-514},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Maximum diffusion reinforcement learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diving into deep learning. <em>NATMI</em>, <em>6</em>(5),
502–503. (<a href="https://doi.org/10.1038/s42256-024-00840-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Wang, Ge},
  doi          = {10.1038/s42256-024-00840-8},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {502-503},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Diving into deep learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Back to basics to open the black box. <em>NATMI</em>,
<em>6</em>(5), 498–501. (<a
href="https://doi.org/10.1038/s42256-024-00842-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most research efforts in machine learning focus on performance and are detached from an explanation of the behaviour of the model. We call for going back to basics of machine learning methods, with more focus on the development of a basic understanding grounded in statistical theory.},
  archive      = {J_NATMI},
  author       = {Marcondes, Diego and Simonis, Adilson and Barrera, Junior},
  doi          = {10.1038/s42256-024-00842-6},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {498-501},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Back to basics to open the black box},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Does it matter if empathic AI has no empathy?
<em>NATMI</em>, <em>6</em>(5), 496–497. (<a
href="https://doi.org/10.1038/s42256-024-00841-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Shteynberg, Garriy and Halpern, Jodi and Sadovnik, Amir and Garthoff, Jon and Perry, Anat and Hay, Jessica and Montemayor, Carlos and Olson, Michael A. and Hulsey, Tim L. and Fairweather, Abrol},
  doi          = {10.1038/s42256-024-00841-7},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {496-497},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Does it matter if empathic AI has no empathy?},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Empathic AI can’t get under the skin. <em>NATMI</em>,
<em>6</em>(5), 495. (<a
href="https://doi.org/10.1038/s42256-024-00850-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized LLMs built with the capacity for emulating empathy are right around the corner. The effects on individual users needs careful consideration.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-024-00850-6},
  journal      = {Nature Machine Intelligence},
  month        = {5},
  number       = {5},
  pages        = {495},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Empathic AI can’t get under the skin},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Publisher correction: The curious case of the test set
AUROC. <em>NATMI</em>, <em>6</em>(4), 494. (<a
href="https://doi.org/10.1038/s42256-024-00834-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Roberts, Michael and Hazan, Alon and Dittmer, Sören and Rudd, James H. F. and Schönlieb, Carola-Bibiane},
  doi          = {10.1038/s42256-024-00834-6},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {494},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Publisher correction: The curious case of the test set AUROC},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Author correction: A soft robot that adapts to environments
through shape change. <em>NATMI</em>, <em>6</em>(4), 493. (<a
href="https://doi.org/10.1038/s42256-024-00814-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Shah, Dylan S. and Powers, Joshua P. and Tilton, Liana G. and Kriegman, Sam and Bongard, Josh and Kramer-Bottiglio, Rebecca},
  doi          = {10.1038/s42256-024-00814-w},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {493},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Author correction: A soft robot that adapts to environments through shape change},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The synergy complement control approach for seamless
limb-driven prostheses. <em>NATMI</em>, <em>6</em>(4), 481–492. (<a
href="https://doi.org/10.1038/s42256-024-00825-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Limb-driven control allows for direct control by using residual limb movements rather than unnatural and complex muscle activation. Existing limb-driven methods simultaneously learn a variety of possible motions, ranging from a residual limb to entire arm motions, from human templates by relying on linear or nonlinear regression techniques. However, the map between a low-dimensional residual limb movement and high-dimensional total limb movement is highly underdetermined. Therefore, this complex, high-dimensional coordination problem cannot be accurately solved by treating it as a data-driven black box problem. Here we address this challenge by introducing the residual limb-driven control framework synergy complement control. Firstly, the residual limb drives a one-dimensional phase variable to simultaneously control the multiple joints of the prosthesis. Secondly, the resulting prosthesis motion naturally complements the movement of the residual limb by its synergy components. Furthermore, our framework adds information on contextual tasks and goals and allows for seamless transitions between these. Experimental validation was conducted using subjects with preserved arms employing an exo-prosthesis setup, and studies involving participants with and without limb differences in a virtual reality setup. The findings affirm that the restoration of lost coordinated synergy capabilities is reliably achieved through the utilization of synergy complement control with the prosthesis. Current limb-driven methods often result in suboptimal prosthetic motions. Kühn and colleagues develop a framework called synergy complement control (SCC) that advances prosthetics by learning ‘cyborg’ limb-driven control, ensuring natural coordination. Validated in diverse trials, SCC offers reliable and intuitive enhancement for limb functionality.},
  archive      = {J_NATMI},
  author       = {Kühn, Johannes and Hu, Tingli and Tödtheide, Alexander and Pozo Fortunić, Edmundo and Jensen, Elisabeth and Haddadin, Sami},
  doi          = {10.1038/s42256-024-00825-7},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {481-492},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The synergy complement control approach for seamless limb-driven prostheses},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A neural speech decoding framework leveraging deep learning
and speech synthesis. <em>NATMI</em>, <em>6</em>(4), 467–480. (<a
href="https://doi.org/10.1038/s42256-024-00824-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decoding human speech from neural signals is essential for brain–computer interface (BCI) technologies that aim to restore speech in populations with neurological deficits. However, it remains a highly challenging task, compounded by the scarce availability of neural signals with corresponding speech, data complexity and high dimensionality. Here we present a novel deep learning-based neural speech decoding framework that includes an ECoG decoder that translates electrocorticographic (ECoG) signals from the cortex into interpretable speech parameters and a novel differentiable speech synthesizer that maps speech parameters to spectrograms. We have developed a companion speech-to-speech auto-encoder consisting of a speech encoder and the same speech synthesizer to generate reference speech parameters to facilitate the ECoG decoder training. This framework generates natural-sounding speech and is highly reproducible across a cohort of 48 participants. Our experimental results show that our models can decode speech with high correlation, even when limited to only causal operations, which is necessary for adoption by real-time neural prostheses. Finally, we successfully decode speech in participants with either left or right hemisphere coverage, which could lead to speech prostheses in patients with deficits resulting from left hemisphere damage. Recent research has focused on restoring speech in populations with neurological deficits. Chen, Wang et al. develop a framework for decoding speech from neural signals, which could lead to innovative speech prostheses.},
  archive      = {J_NATMI},
  author       = {Chen, Xupeng and Wang, Ran and Khalilian-Gourtani, Amirhossein and Yu, Leyao and Dugan, Patricia and Friedman, Daniel and Doyle, Werner and Devinsky, Orrin and Wang, Yao and Flinker, Adeen},
  doi          = {10.1038/s42256-024-00824-8},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {467-480},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A neural speech decoding framework leveraging deep learning and speech synthesis},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reusability report: Uncovering associations in biomedical
bipartite networks via a bilinear attention network with domain
adaptation. <em>NATMI</em>, <em>6</em>(4), 461–466. (<a
href="https://doi.org/10.1038/s42256-024-00822-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional domain adversarial learning presents a promising approach for enhancing the generalizability of deep learning-based methods. Inspired by the efficacy of conditional domain adversarial networks, Bai and colleagues introduced DrugBAN, a methodology designed to explicitly learn pairwise local interactions between drugs and targets. DrugBAN leverages drug molecular graphs and target protein sequences, employing conditional domain adversarial networks to improve the ability to adapt to out-of-distribution data and thereby ensuring superior prediction accuracy for new drug–target pairs. Here we examine the reusability of DrugBAN and extend the evaluation of its generalizability across a wider range of biomedical contexts beyond the original datasets. Various clustering-based strategies are implemented to resplit the source and target domains to assess the robustness of DrugBAN. We also apply this cross-domain adaptation technique to the prediction of cell line–drug responses and mutation–drug associations. The analysis serves as a stepping-off point to better understand and establish a general template applicable to link prediction tasks in biomedical bipartite networks. In early 2023, Bai and colleagues presented DrugBAN, an interpretable method for drug–target prediction. In this Reusability Report, Xu and colleagues reproduce the original findings and provide a careful exploration of cross-domain adaptability.},
  archive      = {J_NATMI},
  author       = {Xu, Tao and Shi, Haoyuan and Gao, Wanling and Wang, Xiaosong and Yue, Zhenyu},
  doi          = {10.1038/s42256-024-00822-w},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {461-466},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reusability report: Uncovering associations in biomedical bipartite networks via a bilinear attention network with domain adaptation},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A 5′ UTR language model for decoding untranslated regions
of mRNA and function predictions. <em>NATMI</em>, <em>6</em>(4),
449–460. (<a href="https://doi.org/10.1038/s42256-024-00823-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 5′ untranslated region (UTR), a regulatory region at the beginning of a messenger RNA (mRNA) molecule, plays a crucial role in regulating the translation process and affects the protein expression level. Language models have showcased their effectiveness in decoding the functions of protein and genome sequences. Here, we introduce a language model for 5′ UTR, which we refer to as the UTR-LM. The UTR-LM is pretrained on endogenous 5′ UTRs from multiple species and is further augmented with supervised information including secondary structure and minimum free energy. We fine-tuned the UTR-LM in a variety of downstream tasks. The model outperformed the best known benchmark by up to 5% for predicting the mean ribosome loading, and by up to 8% for predicting the translation efficiency and the mRNA expression level. The model was also applied to identifying unannotated internal ribosome entry sites within the untranslated region and improved the area under the precision–recall curve from 0.37 to 0.52 compared to the best baseline. Further, we designed a library of 211 new 5′ UTRs with high predicted values of translation efficiency and evaluated them via a wet-laboratory assay. Experiment results confirmed that our top designs achieved a 32.5% increase in protein production level relative to well-established 5′ UTRs optimized for therapeutics. The 5′ untranslated region is a critical regulatory region of mRNA, influencing gene expression regulation and translation. Chu, Yu and colleagues develop a language model for analysing untranslated regions of mRNA. The model, pretrained on data from diverse species, enhances the prediction of mRNA translation activities and has implications for new vaccine design.},
  archive      = {J_NATMI},
  author       = {Chu, Yanyi and Yu, Dan and Li, Yupeng and Huang, Kaixuan and Shen, Yue and Cong, Le and Zhang, Jason and Wang, Mengdi},
  doi          = {10.1038/s42256-024-00823-9},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {449-460},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A 5′ UTR language model for decoding untranslated regions of mRNA and function predictions},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Invalid SMILES are beneficial rather than detrimental to
chemical language models. <em>NATMI</em>, <em>6</em>(4), 437–448. (<a
href="https://doi.org/10.1038/s42256-024-00821-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative machine learning models have attracted intense interest for their ability to sample novel molecules with desired chemical or biological properties. Among these, language models trained on SMILES (Simplified Molecular-Input Line-Entry System) representations have been subject to the most extensive experimental validation and have been widely adopted. However, these models have what is perceived to be a major limitation: some fraction of the SMILES strings that they generate are invalid, meaning that they cannot be decoded to a chemical structure. This perceived shortcoming has motivated a remarkably broad spectrum of work designed to mitigate the generation of invalid SMILES or correct them post hoc. Here I provide causal evidence that the ability to produce invalid outputs is not harmful but is instead beneficial to chemical language models. I show that the generation of invalid outputs provides a self-corrective mechanism that filters low-likelihood samples from the language model output. Conversely, enforcing valid outputs produces structural biases in the generated molecules, impairing distribution learning and limiting generalization to unseen chemical space. Together, these results refute the prevailing assumption that invalid SMILES are a shortcoming of chemical language models and reframe them as a feature, not a bug. Generative models for chemical structures are often trained to create output in the common SMILES notation. Michael Skinnider shows that training models with the goal of avoiding the generation of incorrect SMILES strings is detrimental to learning other chemical properties and that allowing models to generate incorrect molecules, which can be easily removed post hoc, leads to better performing models.},
  archive      = {J_NATMI},
  author       = {Skinnider, Michael A.},
  doi          = {10.1038/s42256-024-00821-x},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {437-448},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Invalid SMILES are beneficial rather than detrimental to chemical language models},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Geometry-enhanced pretraining on interatomic potentials.
<em>NATMI</em>, <em>6</em>(4), 428–436. (<a
href="https://doi.org/10.1038/s42256-024-00818-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning interatomic potentials (MLIPs) describe the interactions between atoms in materials and molecules by learning them from a reference database generated by ab initio calculations. MLIPs can accurately and efficiently predict such interactions and have been applied to various fields of physical science. However, high-performance MLIPs rely on a large amount of labelled data, which are costly to obtain by ab initio calculations. Here we propose a geometric structure learning framework that leverages unlabelled configurations to improve the performance of MLIPs. Our framework consists of two stages: first, using classical molecular dynamics simulations to generate unlabelled configurations of the target molecular system; and second, applying geometry-enhanced self-supervised learning techniques, including masking, denoising and contrastive learning, to capture structural information. We evaluate our framework on various benchmarks ranging from small molecule datasets to complex periodic molecular systems with more types of elements. We show that our method significantly improves the accuracy and generalization of MLIPs with only a few additional computational costs and is compatible with different invariant or equivariant graph neural network architectures. Our method enhances MLIPs and advances the simulations of molecular systems. Using machine learning methods to model interatomic potentials enables molecular dynamics simulations with ab initio level accuracy at a relatively low computational cost, but requires a large number of labelled training data obtained through expensive ab initio computations. Cui and colleagues propose a geometric learning framework that leverages self-supervised learning pretraining to enhance existing machine learning based interatomic potential models at a negligible additional computational cost.},
  archive      = {J_NATMI},
  author       = {Cui, Taoyong and Tang, Chenyu and Su, Mao and Zhang, Shufei and Li, Yuqiang and Bai, Lei and Dong, Yuhan and Gong, Xingao and Ouyang, Wanli},
  doi          = {10.1038/s42256-024-00818-6},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {428-436},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Geometry-enhanced pretraining on interatomic potentials},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Equivariant 3D-conditional diffusion model for molecular
linker design. <em>NATMI</em>, <em>6</em>(4), 417–427. (<a
href="https://doi.org/10.1038/s42256-024-00815-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fragment-based drug discovery has been an effective paradigm in early-stage drug development. An open challenge in this area is designing linkers between disconnected molecular fragments of interest to obtain chemically relevant candidate drug molecules. In this work, we propose DiffLinker, an E(3)-equivariant three-dimensional conditional diffusion model for molecular linker design. Given a set of disconnected fragments, our model places missing atoms in between and designs a molecule incorporating all the initial fragments. Unlike previous approaches that are only able to connect pairs of molecular fragments, our method can link an arbitrary number of fragments. Additionally, the model automatically determines the number of atoms in the linker and its attachment points to the input fragments. We demonstrate that DiffLinker outperforms other methods on the standard datasets, generating more diverse and synthetically accessible molecules. We experimentally test our method in real-world applications, showing that it can successfully generate valid linkers conditioned on target protein pockets. Fragment-based molecular design uses chemical motifs and combines them into bio-active compounds. While this approach has grown in capability, molecular linker methods are restricted to linking fragments one by one, which makes the search for effective combinations harder. Igashov and colleagues use a conditional diffusion model to link multiple fragments in a one-shot generative process.},
  archive      = {J_NATMI},
  author       = {Igashov, Ilia and Stärk, Hannes and Vignac, Clément and Schneuing, Arne and Satorras, Victor Garcia and Frossard, Pascal and Welling, Max and Bronstein, Michael and Correia, Bruno},
  doi          = {10.1038/s42256-024-00815-9},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {417-427},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Equivariant 3D-conditional diffusion model for molecular linker design},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tandem mass spectrum prediction for small molecules using
graph transformers. <em>NATMI</em>, <em>6</em>(4), 404–416. (<a
href="https://doi.org/10.1038/s42256-024-00816-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tandem mass spectra capture fragmentation patterns that provide key structural information about molecules. Although mass spectrometry is applied in many areas, the vast majority of small molecules lack experimental reference spectra. For over 70 years, spectrum prediction has remained a key challenge in the field. Existing deep learning methods do not leverage global structure in the molecule, potentially resulting in difficulties when generalizing to new data. In this work we propose the MassFormer model for accurately predicting tandem mass spectra. MassFormer uses a graph transformer architecture to model long-distance relationships between atoms in the molecule. The transformer module is initialized with parameters obtained through a chemical pretraining task, then fine-tuned on spectral data. MassFormer outperforms competing approaches for spectrum prediction on multiple datasets and accurately models the effects of collision energy. Gradient-based attribution methods reveal that MassFormer can identify compositional relationships between peaks in the spectrum. When applied to spectrum identification problems, MassFormer generally surpasses the performance of existing prediction-based methods. Identifying compounds in tandem mass spectrometry requires extensive databases of known compounds or computational methods to simulate spectra for samples not found in databases. Simulating tandem mass spectra is still challenging, and long-range connections in particular are difficult to model for graph neural networks. Young and colleagues use a graph transformer model to learn patterns of long-distance relations between atoms and molecules.},
  archive      = {J_NATMI},
  author       = {Young, Adamo and Röst, Hannes and Wang, Bo},
  doi          = {10.1038/s42256-024-00816-8},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {404-416},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Tandem mass spectrum prediction for small molecules using graph transformers},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synthetic lagrangian turbulence by generative diffusion
models. <em>NATMI</em>, <em>6</em>(4), 393–403. (<a
href="https://doi.org/10.1038/s42256-024-00810-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lagrangian turbulence lies at the core of numerous applied and fundamental problems related to the physics of dispersion and mixing in engineering, biofluids, the atmosphere, oceans and astrophysics. Despite exceptional theoretical, numerical and experimental efforts conducted over the past 30 years, no existing models are capable of faithfully reproducing statistical and topological properties exhibited by particle trajectories in turbulence. We propose a machine learning approach, based on a state-of-the-art diffusion model, to generate single-particle trajectories in three-dimensional turbulence at high Reynolds numbers, thereby bypassing the need for direct numerical simulations or experiments to obtain reliable Lagrangian data. Our model demonstrates the ability to reproduce most statistical benchmarks across time scales, including the fat-tail distribution for velocity increments, the anomalous power law and the increased intermittency around the dissipative scale. Slight deviations are observed below the dissipative scale, particularly in the acceleration and flatness statistics. Surprisingly, the model exhibits strong generalizability for extreme events, producing events of higher intensity and rarity that still match the realistic statistics. This paves the way for producing synthetic high-quality datasets for pretraining various downstream applications of Lagrangian turbulence. Modelling the statistical and geometrical properties of particle trajectories in turbulent flows is key to many scientific and technological applications. Li and colleagues introduce a data-driven diffusion model that can generate high-Reynolds-number Lagrangian turbulence trajectories with statistical properties consistent with those of the training set and even generalize to rare, intense events unseen during training.},
  archive      = {J_NATMI},
  author       = {Li, T. and Biferale, L. and Bonaccorso, F. and Scarpolini, M. A. and Buzzicotti, M.},
  doi          = {10.1038/s42256-024-00810-0},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {393-403},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Synthetic lagrangian turbulence by generative diffusion models},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The benefits, risks and bounds of personalizing the
alignment of large language models to individuals. <em>NATMI</em>,
<em>6</em>(4), 383–392. (<a
href="https://doi.org/10.1038/s42256-024-00820-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) undergo ‘alignment’ so that they better reflect human values or preferences, and are safer or more useful. However, alignment is intrinsically difficult because the hundreds of millions of people who now interact with LLMs have different preferences for language and conversational norms, operate under disparate value systems and hold diverse political beliefs. Typically, few developers or researchers dictate alignment norms, risking the exclusion or under-representation of various groups. Personalization is a new frontier in LLM development, whereby models are tailored to individuals. In principle, this could minimize cultural hegemony, enhance usefulness and broaden access. However, unbounded personalization poses risks such as large-scale profiling, privacy infringement, bias reinforcement and exploitation of the vulnerable. Defining the bounds of responsible and socially acceptable personalization is a non-trivial task beset with normative challenges. This article explores ‘personalized alignment’, whereby LLMs adapt to user-specific data, and highlights recent shifts in the LLM ecosystem towards a greater degree of personalization. Our main contribution explores the potential impact of personalized LLMs via a taxonomy of risks and benefits for individuals and society at large. We lastly discuss a key open question: what are appropriate bounds of personalization and who decides? Answering this normative question enables users to benefit from personalized alignment while safeguarding against harmful impacts for individuals and society. Tailoring the alignment of large language models (LLMs) to individuals is a new frontier in generative AI, but unbounded personalization can bring potential harm, such as large-scale profiling, privacy infringement and bias reinforcement. Kirk et al. develop a taxonomy for risks and benefits of personalized LLMs and discuss the need for normative decisions on what are acceptable bounds of personalization.},
  archive      = {J_NATMI},
  author       = {Kirk, Hannah Rose and Vidgen, Bertie and Röttger, Paul and Hale, Scott A.},
  doi          = {10.1038/s42256-024-00820-y},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {383-392},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The benefits, risks and bounds of personalizing the alignment of large language models to individuals},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligence tackles the nature–nurture debate.
<em>NATMI</em>, <em>6</em>(4), 381–382. (<a
href="https://doi.org/10.1038/s42256-024-00828-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A classic question in cognitive science is whether learning requires innate, domain-specific inductive biases to solve visual tasks. A recent study trained machine-learning systems on the first-person visual experiences of children to show that visual knowledge can be learned in the absence of innate inductive biases about objects or space.},
  archive      = {J_NATMI},
  author       = {Wood, Justin N.},
  doi          = {10.1038/s42256-024-00828-4},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {381-382},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Artificial intelligence tackles the nature–nurture debate},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dangers of speech technology for workplace diversity.
<em>NATMI</em>, <em>6</em>(4), 377–380. (<a
href="https://doi.org/10.1038/s42256-024-00827-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech technology offers many applications to enhance employee productivity and efficiency. Yet new dangers arise for marginalized groups, potentially jeopardizing organizational efforts to promote workplace diversity. Our analysis delves into three critical risks of speech technology and offers guidance for mitigating these risks responsibly.},
  archive      = {J_NATMI},
  author       = {Teodorescu, Mike Horia Mihail and Geiger, Mingang K. and Morse, Lily},
  doi          = {10.1038/s42256-024-00827-5},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {377-380},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Dangers of speech technology for workplace diversity},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). The curious case of the test set AUROC. <em>NATMI</em>,
<em>6</em>(4), 373–376. (<a
href="https://doi.org/10.1038/s42256-024-00817-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The area under the receiver operating characteristic curve (AUROC) of the test set is used throughout machine learning (ML) for assessing a model’s performance. However, when concordance is not the only ambition, this gives only a partial insight into performance, masking distribution shifts of model outputs and model instability.},
  archive      = {J_NATMI},
  author       = {Roberts, Michael and Hazan, Alon and Dittmer, Sören and Rudd, James H. F. and Schönlieb, Carola-Bibiane},
  doi          = {10.1038/s42256-024-00817-7},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {373-376},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The curious case of the test set AUROC},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated learning is not a cure-all for data ethics.
<em>NATMI</em>, <em>6</em>(4), 370–372. (<a
href="https://doi.org/10.1038/s42256-024-00813-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although federated learning is often seen as a promising solution to allow AI innovation while addressing privacy concerns, we argue that this technology does not fix all underlying data ethics concerns. Benefiting from federated learning in digital health requires acknowledgement of its limitations.},
  archive      = {J_NATMI},
  author       = {Bak, Marieke and Madai, Vince I. and Celi, Leo Anthony and Kaissis, Georgios A. and Cornet, Ronald and Maris, Menno and Rueckert, Daniel and Buyx, Alena and McLennan, Stuart},
  doi          = {10.1038/s42256-024-00813-x},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {370-372},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Federated learning is not a cure-all for data ethics},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The rewards of reusable machine learning code.
<em>NATMI</em>, <em>6</em>(4), 369. (<a
href="https://doi.org/10.1038/s42256-024-00835-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research papers can make a long-lasting impact when the code and software tools supporting the findings are made readily available and can be reused and built on. Our reusability reports explore and highlight examples of good code sharing practices.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-024-00835-5},
  journal      = {Nature Machine Intelligence},
  month        = {4},
  number       = {4},
  pages        = {369},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The rewards of reusable machine learning code},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Author correction: A challenge for rounded evaluation of
recommender systems. <em>NATMI</em>, <em>6</em>(3), 368. (<a
href="https://doi.org/10.1038/s42256-024-00819-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Tagliabue, Jacopo and Bianchi, Federico and Schnabel, Tobias and Attanasio, Giuseppe and Greco, Ciro and de Souza Moreira, Gabriel and Chia, Patrick John},
  doi          = {10.1038/s42256-024-00819-5},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {368},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Author correction: A challenge for rounded evaluation of recommender systems},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Foundation model for cancer imaging biomarkers.
<em>NATMI</em>, <em>6</em>(3), 354–367. (<a
href="https://doi.org/10.1038/s42256-024-00807-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation models in deep learning are characterized by a single large-scale model trained on vast amounts of data serving as the foundation for various downstream tasks. Foundation models are generally trained using self-supervised learning and excel in reducing the demand for training samples in downstream applications. This is especially important in medicine, where large labelled datasets are often scarce. Here, we developed a foundation model for cancer imaging biomarker discovery by training a convolutional encoder through self-supervised learning using a comprehensive dataset of 11,467 radiographic lesions. The foundation model was evaluated in distinct and clinically relevant applications of cancer imaging-based biomarkers. We found that it facilitated better and more efficient learning of imaging biomarkers and yielded task-specific models that significantly outperformed conventional supervised and other state-of-the-art pretrained implementations on downstream tasks, especially when training dataset sizes were very limited. Furthermore, the foundation model was more stable to input variations and showed strong associations with underlying biology. Our results demonstrate the tremendous potential of foundation models in discovering new imaging biomarkers that may extend to other clinical use cases and can accelerate the widespread translation of imaging biomarkers into clinical settings. Foundation models have transformed artificial intelligence by training on vast amounts of broad unlabelled data. Pai et al. present a foundation model leading to more accurate, efficient and robust cancer imaging biomarkers, especially in use cases with small training datasets.},
  archive      = {J_NATMI},
  author       = {Pai, Suraj and Bontempi, Dennis and Hadzic, Ibrahim and Prudente, Vasco and Sokač, Mateo and Chaunzwa, Tafadzwa L. and Bernatz, Simon and Hosny, Ahmed and Mak, Raymond H. and Birkbak, Nicolai J. and Aerts, Hugo J. W. L.},
  doi          = {10.1038/s42256-024-00807-9},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {354-367},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Foundation model for cancer imaging biomarkers},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generative AI for designing and validating easily
synthesizable and structurally novel antibiotics. <em>NATMI</em>,
<em>6</em>(3), 338–353. (<a
href="https://doi.org/10.1038/s42256-024-00809-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of pan-resistant bacteria is creating an urgent need for structurally novel antibiotics. Artificial intelligence methods can discover new antibiotics, but existing methods have notable limitations. Property prediction models, which evaluate molecules one-by-one for a given property, scale poorly to large chemical spaces. Generative models, which directly design molecules, rapidly explore vast chemical spaces but generate molecules that are challenging to synthesize. Here we introduce SyntheMol, a generative model that designs new compounds, which are easy to synthesize, from a chemical space of nearly 30 billion molecules. We apply SyntheMol to design molecules that inhibit the growth of Acinetobacter baumannii, a burdensome Gram-negative bacterial pathogen. We synthesize 58 generated molecules and experimentally validate them, with six structurally novel molecules demonstrating antibacterial activity against A. baumannii and several other phylogenetically diverse bacterial pathogens. This demonstrates the potential of generative artificial intelligence to design structurally novel, synthesizable and effective small-molecule antibiotic candidates from vast chemical spaces, with empirical validation. AI methods can discover new antibiotics but existing methods have limitations. Swanson et al. develop a generative AI model that learns to design molecules that are easy to synthesize. The authors apply the model to design and validate novel antibiotics against the bacterial pathogen Acinetobacter baumannii.},
  archive      = {J_NATMI},
  author       = {Swanson, Kyle and Liu, Gary and Catacutan, Denise B. and Arnold, Autumn and Zou, James and Stokes, Jonathan M.},
  doi          = {10.1038/s42256-024-00809-7},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {338-353},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Generative AI for designing and validating easily synthesizable and structurally novel antibiotics},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PocketFlow is a data-and-knowledge-driven structure-based
molecular generative model. <em>NATMI</em>, <em>6</em>(3), 326–337. (<a
href="https://doi.org/10.1038/s42256-024-00808-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based molecular generation has extensive applications in many fields, particularly drug discovery. However, the majority of current deep generative models are ligand-based and do not consider chemical knowledge in the molecular generation process, often resulting in a relatively low success rate. We herein propose a structure-based molecular generative framework with chemical knowledge explicitly considered (named PocketFlow), which generates novel ligand molecules inside protein binding pockets. In various computational evaluations, PocketFlow showed state-of-the-art performance, with generated molecules being 100% chemically valid and highly drug-like. Ablation experiments prove the critical role of chemical knowledge in ensuring the validity and drug-likeness of the generated molecules. We applied PocketFlow to two new target proteins that are related to epigenetic regulation, HAT1 and YTHDC1, and successfully obtained wet-lab validated bioactive compounds. The binding modes of the active compounds with target proteins are close to those predicted by molecular docking and further confirmed by the X-ray crystal structure. All the results suggest that PocketFlow is a useful deep generative model, capable of generating innovative bioactive molecules from scratch given a protein binding pocket. Deep learning generative approaches have been used in recent years to discover new molecules with drug-like properties. To improve the performance of such approaches, Yang et al. add chemical binding knowledge to a deep generative framework and demonstrate, including by wet-lab verification, that the method can find valid molecules that successfully bind to target proteins.},
  archive      = {J_NATMI},
  author       = {Jiang, Yuanyuan and Zhang, Guo and You, Jing and Zhang, Hailin and Yao, Rui and Xie, Huanzhang and Zhang, Liyun and Xia, Ziyi and Dai, Mengzhe and Wu, Yunjie and Li, Linli and Yang, Shengyong},
  doi          = {10.1038/s42256-024-00808-8},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {326-337},
  shortjournal = {Nat. Mach. Intell.},
  title        = {PocketFlow is a data-and-knowledge-driven structure-based molecular generative model},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generating mutants of monotone affinity towards stronger
protein complexes through adversarial learning. <em>NATMI</em>,
<em>6</em>(3), 315–325. (<a
href="https://doi.org/10.1038/s42256-024-00803-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite breakthroughs achieved in protein sequence-to-structure and function-to-sequence predictions, the affinity-to-mutation prediction problem remains unsolved. Such a problem is of exponential complexity deemed to find a mutated protein or protein complex having a guaranteed binding-affinity change. Here we introduce an adversarial learning-based mutation method that creates optimal amino acid substitutions and changes the mutant’s affinity change significantly in a preset direction. The key aspect in our method is the adversarial training process that dynamically labels the real side of the protein data and generates fake pseudo-data accordingly to construct a deep learning architecture for guiding the mutation. The method is sufficiently flexible to generate both single- and multipointed mutations at the adversarial learning step to mimic the natural circumstances of protein evolution. Compared with random mutants, our mutated sequences have in silico exhibited more than one order of change in magnitude of binding free energy change towards stronger complexes in the case study of Novavax–angiotensin-converting enzyme-related carboxypeptidase vaccine construct optimization. We also applied the method iteratively each time, using the output as the input sequence of the next iteration, to generate paths and a landscape of mutants with affinity-increasing monotonicity to understand SARS-CoV-2 Omicron’s spike evolution. With these steps taken for effective generation of protein mutants of monotone affinity, our method will provide potential benefits to many other applications including protein bioengineering, drug design, antibody reformulation and therapeutic protein medication. Mutations can increase or decrease a protein’s ability to bind to other proteins, but modelling multiple mutations becomes computationally intractable. Lan and colleagues propose an adversarial deep learning architecture to guide the choice of mutations to optimize binding affinities.},
  archive      = {J_NATMI},
  author       = {Lan, Tian and Su, Shuquan and Ping, Pengyao and Hutvagner, Gyorgy and Liu, Tao and Pan, Yi and Li, Jinyan},
  doi          = {10.1038/s42256-024-00803-z},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {315-325},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Generating mutants of monotone affinity towards stronger protein complexes through adversarial learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reusability report: Leveraging supervised learning to
uncover phenotype-relevant biology from single-cell RNA sequencing data.
<em>NATMI</em>, <em>6</em>(3), 307–314. (<a
href="https://doi.org/10.1038/s42256-024-00804-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in single-cell transcriptome sequencing and computational analysis methods have improved our understanding of cellular heterogeneity. However, associating different cell subsets with phenotypes remains challenging. Recently, Ren et al. introduced PENCIL, a supervised learning framework incorporating gene selection to discern phenotype-relevant cells. To assess PENCIL’s reproducibility and transferability, we conducted a comprehensive evaluation across 12 single-cell RNA sequencing datasets representing four distinct phenotypes. We identified a few caveats with the original version of PENCIL, such as sensitivity to input perturbation, the correction of which contributed to PENCIL’s enhanced reproducibility. We highlight that boosting PENCIL’s cell subsets identification with gene set variation analysis creates a cytotoxic T cell immunotherapy response signature (CyTIR) predictive of immune checkpoint blockade response in skin cancer across multiple datasets, with an area under curve &amp;gt;0.75 and accuracy &amp;gt;0.71. Overall, our assessments enhance PENCIL’s reproducibility and utility, further extending its potential for identifying phenotype-relevant cell subsets in diverse biomedical applications. This Reusability Report examines a recently published deep learning method PENCIL by Ren et al. for identifying phenotype populations in single-cell data. Cao et al. reproduce here the main results, analyse the sensitivity of the method to model parameters and describe how the method can be used to create a signature for immunotherapy response markers.},
  archive      = {J_NATMI},
  author       = {Cao, Yingying and Chang, Tian-Gen and Sahni, Sahil and Ruppin, Eytan},
  doi          = {10.1038/s42256-024-00804-y},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {307-314},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reusability report: Leveraging supervised learning to uncover phenotype-relevant biology from single-cell RNA sequencing data},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised ensemble-based phenotyping enhances
discoverability of genes related to left-ventricular morphology.
<em>NATMI</em>, <em>6</em>(3), 291–306. (<a
href="https://doi.org/10.1038/s42256-024-00801-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent genome-wide association studies have successfully identified associations between genetic variants and simple cardiac morphological parameters derived from cardiac magnetic resonance images. However, the emergence of large databases, including genetic data linked to cardiac magnetic resonance facilitates the investigation of more nuanced patterns of cardiac shape variability than those studied so far. Here we propose a framework for gene discovery coined unsupervised phenotype ensembles. The unsupervised phenotype ensemble builds a redundant yet highly expressive representation by pooling a set of phenotypes learnt in an unsupervised manner, using deep learning models trained with different hyperparameters. These phenotypes are then analysed via genome-wide association studies, retaining only highly confident and stable associations across the ensemble. We applied our approach to the UK Biobank database to extract geometric features of the left ventricle from image-derived three-dimensional meshes. We demonstrate that our approach greatly improves the discoverability of genes that influence left ventricle shape, identifying 49 loci with study-wide significance and 25 with suggestive significance. We argue that our approach would enable more extensive discovery of gene associations with image-derived phenotypes for other organs or image modalities. Genome-wide association studies allow connecting genomic information with complex traits. Rodrigo Bonazzola et al. develop a framework consisting of several deep learning tools to improve the discoverability of genes that influence specific geometric features of the heart.},
  archive      = {J_NATMI},
  author       = {Bonazzola, Rodrigo and Ferrante, Enzo and Ravikumar, Nishant and Xia, Yan and Keavney, Bernard and Plein, Sven and Syeda-Mahmood, Tanveer and Frangi, Alejandro F.},
  doi          = {10.1038/s42256-024-00801-1},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {291-306},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Unsupervised ensemble-based phenotyping enhances discoverability of genes related to left-ventricular morphology},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reusability report: Unpaired deep-learning approaches for
holographic image reconstruction. <em>NATMI</em>, <em>6</em>(3),
284–290. (<a href="https://doi.org/10.1038/s42256-024-00798-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep-learning methods using unpaired datasets hold great potential for image reconstruction, especially in biomedical imaging where obtaining paired datasets is often difficult due to practical concerns. A recent study by Lee et al. (Nature Machine Intelligence 2023) has introduced a parameterized physical model (referred to as FMGAN) using the unpaired approach for adaptive holographic imaging, which replaces the forward generator network with a physical model parameterized on the propagation distance of the probing light. FMGAN has demonstrated its capability to reconstruct the complex phase and amplitude of objects, as well as the propagation distance, even in scenarios where the object-to-sensor distance exceeds the range of the training data. We performed additional experiments to comprehensively assess FMGAN’s capabilities and limitations. As in the original paper, we compared FMGAN to two state-of-the-art unpaired methods, CycleGAN and PhaseGAN, and evaluated their robustness and adaptability under diverse conditions. Our findings highlight FMGAN’s reproducibility and generalizability when dealing with both in-distribution and out-of-distribution data, corroborating the results reported by the original authors. We also extended FMGAN with explicit forward models describing the response of specific optical systems, which improved performance when dealing with non-perfect systems. However, we observed that FMGAN encounters difficulties when explicit forward models are unavailable. In such scenarios, PhaseGAN outperformed FMGAN. A parameterized physical model that uses unpaired datasets for adaptive holographic imaging was published in Nature Machine Intelligence in 2023. Zhang and colleagues evaluate its performance and extend it to non-perfect optical systems by integrating specific optical response functions.},
  archive      = {J_NATMI},
  author       = {Zhang, Yuhe and Ritschel, Tobias and Villanueva-Perez, Pablo},
  doi          = {10.1038/s42256-024-00798-7},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {284-290},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reusability report: Unpaired deep-learning approaches for holographic image reconstruction},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning high-level visual representations from a child’s
perspective without strong inductive biases. <em>NATMI</em>,
<em>6</em>(3), 271–283. (<a
href="https://doi.org/10.1038/s42256-024-00802-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Young children develop sophisticated internal models of the world based on their visual experience. Can such models be learned from a child’s visual experience without strong inductive biases? To investigate this, we train state-of-the-art neural networks on a realistic proxy of a child’s visual experience without any explicit supervision or domain-specific inductive biases. Specifically, we train both embedding models and generative models on 200 hours of headcam video from a single child collected over two years and comprehensively evaluate their performance in downstream tasks using various reference models as yardsticks. On average, the best embedding models perform at a respectable 70% of a high-performance ImageNet-trained model, despite substantial differences in training data. They also learn broad semantic categories and object localization capabilities without explicit supervision, but they are less object-centric than models trained on all of ImageNet. Generative models trained with the same data successfully extrapolate simple properties of partially masked objects, like their rough outline, texture, colour or orientation, but struggle with finer object details. We replicate our experiments with two other children and find remarkably consistent results. Broadly useful high-level visual representations are thus robustly learnable from a sample of a child’s visual experience without strong inductive biases. Visual representations are thought to develop from visual experience and inductive biases. Orhan and Lake show that modern machine learning algorithms can learn visual knowledge from a few hundred hours of longitudinal headcam recordings collected from young children during the course of early development, without strong inductive biases.},
  archive      = {J_NATMI},
  author       = {Orhan, A. Emin and Lake, Brenden M.},
  doi          = {10.1038/s42256-024-00802-0},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {271-283},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Learning high-level visual representations from a child’s perspective without strong inductive biases},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Challenges and opportunities in translating ethical AI
principles into practice for children. <em>NATMI</em>, <em>6</em>(3),
265–270. (<a href="https://doi.org/10.1038/s42256-024-00805-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI systems are becoming increasingly pervasive within children’s devices, apps and services. The concern over a world where AI systems are deployed unchecked has raised burning questions about the impact, governance and accountability of these technologies. Although recent effort on AI ethics has converged into growing consensus on a set of high-level ethical AI principles, engagement with children’s issues is still limited, and even less is known about how to effectively apply them in practice for children. This Perspective first maps the current global landscape of existing ethics guidelines for AI and analyses their correlation with children. We then critically assess the strategies and recommendations proposed by current AI ethics initiatives, identifying the critical challenges in translating such ethical AI principles into practice for children. Finally, we tentatively map out several suggestions regarding embedding ethics into the development and governance of AI for children. As the impacts of AI on everyday life increase, guidelines are needed to ensure ethical deployment and use of this technology. This is even more pressing for technology that interacts with groups that need special protection, such as children. In this Perspective Wang et al. survey the existing AI ethics guidelines with a focus on children’s issues, and provide suggestions for further development.},
  archive      = {J_NATMI},
  author       = {Wang, Ge and Zhao, Jun and Van Kleek, Max and Shadbolt, Nigel},
  doi          = {10.1038/s42256-024-00805-x},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {265-270},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Challenges and opportunities in translating ethical AI principles into practice for children},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A collective AI via lifelong learning and sharing at the
edge. <em>NATMI</em>, <em>6</em>(3), 251–264. (<a
href="https://doi.org/10.1038/s42256-024-00800-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One vision of a future artificial intelligence (AI) is where many separate units can learn independently over a lifetime and share their knowledge with each other. The synergy between lifelong learning and sharing has the potential to create a society of AI systems, as each individual unit can contribute to and benefit from the collective knowledge. Essential to this vision are the abilities to learn multiple skills incrementally during a lifetime, to exchange knowledge among units via a common language, to use both local data and communication to learn, and to rely on edge devices to host the necessary decentralized computation and data. The result is a network of agents that can quickly respond to and learn new tasks, that collectively hold more knowledge than a single agent and that can extend current knowledge in more diverse ways than a single agent. Open research questions include when and what knowledge should be shared to maximize both the rate of learning and the long-term learning performance. Here we review recent machine learning advances converging towards creating a collective machine-learned intelligence. We propose that the convergence of such scientific and technological advances will lead to the emergence of new types of scalable, resilient and sustainable AI systems. An emerging research area in AI is developing multi-agent capabilities with collections of interacting AI systems. Andrea Soltoggio and colleagues develop a vision for combining such approaches with current edge computing technology and lifelong learning advances. The envisioned network of AI agents could quickly learn new tasks in open-ended applications, with individual AI agents independently learning and contributing to and benefiting from collective knowledge.},
  archive      = {J_NATMI},
  author       = {Soltoggio, Andrea and Ben-Iwhiwhu, Eseoghene and Braverman, Vladimir and Eaton, Eric and Epstein, Benjamin and Ge, Yunhao and Halperin, Lucy and How, Jonathan and Itti, Laurent and Jacobs, Michael A. and Kantharaju, Pavan and Le, Long and Lee, Steven and Liu, Xinran and Monteiro, Sildomar T. and Musliner, David and Nath, Saptarshi and Panda, Priyadarshini and Peridis, Christos and Pirsiavash, Hamed and Parekh, Vishwa and Roy, Kaushik and Shperberg, Shahaf and Siegelmann, Hava T. and Stone, Peter and Vedder, Kyle and Wu, Jingfeng and Yang, Lin and Zheng, Guangyao and Kolouri, Soheil},
  doi          = {10.1038/s42256-024-00800-2},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {251-264},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A collective AI via lifelong learning and sharing at the edge},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Connecting molecular properties with plain language.
<em>NATMI</em>, <em>6</em>(3), 249–250. (<a
href="https://doi.org/10.1038/s42256-024-00812-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI tools such as ChatGPT can provide responses to queries on any topic, but can such large language models accurately ‘write’ molecules as output to our specification? Results now show that models trained on general text can be tweaked with small amounts of chemical data to predict molecular properties, or to design molecules based on a target feature.},
  archive      = {J_NATMI},
  author       = {Hocky, Glen M.},
  doi          = {10.1038/s42256-024-00812-y},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {249-250},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Connecting molecular properties with plain language},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The democratization of global AI governance and the role of
tech companies. <em>NATMI</em>, <em>6</em>(3), 246–248. (<a
href="https://doi.org/10.1038/s42256-024-00811-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Can non-state multinational tech companies counteract the potential democratic deficit in the emerging global governance of AI? We argue that although they may strengthen core values of democracy such as accountability and transparency, they currently lack the right kind of authority to democratize global AI governance.},
  archive      = {J_NATMI},
  author       = {Erman, Eva and Furendal, Markus},
  doi          = {10.1038/s42256-024-00811-z},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {246-248},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The democratization of global AI governance and the role of tech companies},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The new NeuroAI. <em>NATMI</em>, <em>6</em>(3), 245. (<a
href="https://doi.org/10.1038/s42256-024-00826-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After several decades of developments in AI, has the inspiration that can be drawn from neuroscience been exhausted? Recent initiatives make the case for taking a fresh look at the intersection between the two fields.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-024-00826-6},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {245},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The new NeuroAI},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lessons from a challenge on forecasting epileptic seizures
from non-cerebral signals. <em>NATMI</em>, <em>6</em>(2), 243–244. (<a
href="https://doi.org/10.1038/s42256-024-00799-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The “My Seizure Gauge” competition explored the challenge of forecasting epileptic seizures using non-invasive wearable devices without an electroencephalogram. The organizers and the winning team reflect on their experiences.},
  archive      = {J_NATMI},
  author       = {Schlegel, Kenny and Kleyko, Denis and Brinkmann, Benjamin H. and Nurse, Ewan S. and Gayler, Ross W. and Neubert, Peer},
  doi          = {10.1038/s42256-024-00799-6},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {243-244},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Lessons from a challenge on forecasting epileptic seizures from non-cerebral signals},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Audio-based AI classifiers show no evidence of improved
COVID-19 screening over simple symptoms checkers. <em>NATMI</em>,
<em>6</em>(2), 229–242. (<a
href="https://doi.org/10.1038/s42256-023-00773-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent work has reported that respiratory audio-trained AI classifiers can accurately predict SARS-CoV-2 infection status. However, it has not yet been determined whether such model performance is driven by latent audio biomarkers with true causal links to SARS-CoV-2 infection or by confounding effects, such as recruitment bias, present in observational studies. Here we undertake a large-scale study of audio-based AI classifiers as part of the UK government’s pandemic response. We collect a dataset of audio recordings from 67,842 individuals, with linked metadata, of whom 23,514 had positive polymerase chain reaction tests for SARS-CoV-2. In an unadjusted analysis, similar to that in previous works, AI classifiers predict SARS-CoV-2 infection status with high accuracy (ROC–AUC = 0.846 [0.838–0.854]). However, after matching on measured confounders, such as self-reported symptoms, performance is much weaker (ROC–AUC = 0.619 [0.594–0.644]). Upon quantifying the utility of audio-based classifiers in practical settings, we find them to be outperformed by predictions on the basis of user-reported symptoms. We make best-practice recommendations for handling recruitment bias, and for assessing audio-based classifiers by their utility in relevant practical settings. Our work provides insights into the value of AI audio analysis and the importance of study design and treatment of confounders in AI-enabled diagnostics. AI-enabled diagnostic applications in healthcare can be powerful, but study design is very important to avoid subtle issues of bias in the dataset and evaluation. Coppock et al. demonstrate how an AI-based classifier for diagnosing SARS-Cov-2 infection from audio recordings can seem to make predictions with high accuracy but shows much lower performance after taking into account confounders, providing insights in study design and replicability in AI-based audio analysis.},
  archive      = {J_NATMI},
  author       = {Coppock, Harry and Nicholson, George and Kiskin, Ivan and Koutra, Vasiliki and Baker, Kieran and Budd, Jobie and Payne, Richard and Karoune, Emma and Hurley, David and Titcomb, Alexander and Egglestone, Sabrina and Tendero Cañadas, Ana and Butler, Lorraine and Jersakova, Radka and Mellor, Jonathon and Patel, Selina and Thornley, Tracey and Diggle, Peter and Richardson, Sylvia and Packham, Josef and Schuller, Björn W. and Pigoli, Davide and Gilmour, Steven and Roberts, Stephen and Holmes, Chris},
  doi          = {10.1038/s42256-023-00773-8},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {229-242},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Audio-based AI classifiers show no evidence of improved COVID-19 screening over simple symptoms checkers},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Protein function prediction as approximate semantic
entailment. <em>NATMI</em>, <em>6</em>(2), 220–228. (<a
href="https://doi.org/10.1038/s42256-024-00795-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Gene Ontology (GO) is a formal, axiomatic theory with over 100,000 axioms that describe the molecular functions, biological processes and cellular locations of proteins in three subontologies. Predicting the functions of proteins using the GO requires both learning and reasoning capabilities in order to maintain consistency and exploit the background knowledge in the GO. Many methods have been developed to automatically predict protein functions, but effectively exploiting all the axioms in the GO for knowledge-enhanced learning has remained a challenge. We have developed DeepGO-SE, a method that predicts GO functions from protein sequences using a pretrained large language model. DeepGO-SE generates multiple approximate models of GO, and a neural network predicts the truth values of statements about protein functions in these approximate models. We aggregate the truth values over multiple models so that DeepGO-SE approximates semantic entailment when predicting protein functions. We show, using several benchmarks, that the approach effectively exploits background knowledge in the GO and improves protein function prediction compared to state-of-the-art methods. Deep learning language models have proved useful for both natural language and protein modelling. Similar to semantics in natural language, protein functions are complex and depend on the context of their environment, rather than on the similarity of sequences. Kulmanov and colleagues present an approach to frame function prediction as semantic entailment using a neuro-symbolic model to augment a large protein language model.},
  archive      = {J_NATMI},
  author       = {Kulmanov, Maxat and Guzmán-Vega, Francisco J. and Duek Roggli, Paula and Lane, Lydie and Arold, Stefan T. and Hoehndorf, Robert},
  doi          = {10.1038/s42256-024-00795-w},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {220-228},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Protein function prediction as approximate semantic entailment},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A computational framework for neural network-based
variational monte carlo with forward laplacian. <em>NATMI</em>,
<em>6</em>(2), 209–219. (<a
href="https://doi.org/10.1038/s42256-024-00794-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network-based variational Monte Carlo (NN-VMC) has emerged as a promising cutting-edge technique of ab initio quantum chemistry. However, the high computational cost of existing approaches hinders their applications in realistic chemistry problems. Here we report a development of NN-VMC that achieves a remarkable speed-up rate, thereby greatly extending the applicability of NN-VMC to larger systems. Our key design is a computational framework named Forward Laplacian, which computes the Laplacian associated with neural networks, the bottleneck of NN-VMC, through an efficient forward propagation process. We then demonstrate that Forward Laplacian can further facilitate more developments of acceleration methods across various aspects, including optimization for sparse derivative matrix and efficient network design. Empirically, our approach enables NN-VMC to investigate a broader range of systems, providing valuable references to other ab initio methods. The results demonstrate a great potential in applying deep learning methods to solve general quantum mechanical problems. Realistic quantum mechanical simulations are computationally costly to perform but can be approximated using neural network models. Li and colleagues propose a forward propagation method in lieu of traditional backpropagation to speed up these neural network-based approaches.},
  archive      = {J_NATMI},
  author       = {Li, Ruichen and Ye, Haotian and Jiang, Du and Wen, Xuelan and Wang, Chuwei and Li, Zhe and Li, Xiang and He, Di and Chen, Ji and Ren, Weiluo and Wang, Liwei},
  doi          = {10.1038/s42256-024-00794-x},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {209-219},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A computational framework for neural network-based variational monte carlo with forward laplacian},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). State-specific protein–ligand complex structure prediction
with a multiscale deep generative model. <em>NATMI</em>, <em>6</em>(2),
195–208. (<a href="https://doi.org/10.1038/s42256-024-00792-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The binding complexes formed by proteins and small molecule ligands are ubiquitous and critical to life. Despite recent advancements in protein structure prediction, existing algorithms are so far unable to systematically predict the binding ligand structures along with their regulatory effects on protein folding. To address this discrepancy, we present NeuralPLexer, a computational approach that can directly predict protein–ligand complex structures solely using protein sequence and ligand molecular graph inputs. NeuralPLexer adopts a deep generative model to sample the three-dimensional structures of the binding complex and their conformational changes at an atomistic resolution. The model is based on a diffusion process that incorporates essential biophysical constraints and a multiscale geometric deep learning system to iteratively sample residue-level contact maps and all heavy-atom coordinates in a hierarchical manner. NeuralPLexer achieves state-of-the-art performance compared with all existing methods on benchmarks for both protein–ligand blind docking and flexible binding-site structure recovery. Moreover, owing to its specificity in sampling both ligand-free-state and ligand-bound-state ensembles, NeuralPLexer consistently outperforms AlphaFold2 in terms of global protein structure accuracy on both representative structure pairs with large conformational changes and recently determined ligand-binding proteins. NeuralPLexer predictions align with structure determination experiments for important targets in enzyme engineering and drug discovery, suggesting its potential for accelerating the design of functional proteins and small molecules at the proteome scale. Great advances in protein structure prediction have been made with recent deep learning-based methods, but proteins interact with their environment and can change shape drastically when binding to ligand molecules. To predict the 3D structure of these combined protein–ligand complexes, Qiao et al. developed a generative diffusion model with biophysical constraints and geometric deep learning.},
  archive      = {J_NATMI},
  author       = {Qiao, Zhuoran and Nie, Weili and Vahdat, Arash and Miller, Thomas F. and Anandkumar, Animashree},
  doi          = {10.1038/s42256-024-00792-z},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {195-208},
  shortjournal = {Nat. Mach. Intell.},
  title        = {State-specific protein–ligand complex structure prediction with a multiscale deep generative model},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mitigating allocative tradeoffs and harms in an
environmental justice data tool. <em>NATMI</em>, <em>6</em>(2), 187–194.
(<a href="https://doi.org/10.1038/s42256-024-00793-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighbourhood-level screening algorithms are increasingly being deployed to inform policy decisions. However, their potential for harm remains unclear: algorithmic decision-making has broadly fallen under scrutiny for disproportionate harm to marginalized groups, yet opaque methodology and proprietary data limit the generalizability of algorithmic audits. Here we leverage publicly available data to fully reproduce and audit a large-scale algorithm known as CalEnviroScreen, designed to promote environmental justice and guide public funding by identifying disadvantaged neighbourhoods. We observe the model to be both highly sensitive to subjective model specifications and financially consequential, estimating the effect of its positive designations as a 104% (62–145%) increase in funding, equivalent to US$2.08 billion (US$1.56–2.41 billion) over four years. We further observe allocative tradeoffs and susceptibility to manipulation, raising ethical concerns. We recommend incorporating technical strategies to mitigate allocative harm and accountability mechanisms to prevent misuse. Algorithmic decisions have a history of harming already marginalized populations. In an effort to combat these discriminative patterns, data-driven methods are used to comprehend these patterns, and recently also to identify disadvantaged communities to allocate resources. Huynh et al. analyse one of these tools and show a concerning sensitivity to input parameters that can lead to unintentional biases with substantial financial consequences.},
  archive      = {J_NATMI},
  author       = {Huynh, Benjamin Q. and Chin, Elizabeth T. and Koenecke, Allison and Ouyang, Derek and Ho, Daniel E. and Kiang, Mathew V. and Rehkopf, David H.},
  doi          = {10.1038/s42256-024-00793-y},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {187-194},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Mitigating allocative tradeoffs and harms in an environmental justice data tool},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weak signal extraction enabled by deep neural network
denoising of diffraction data. <em>NATMI</em>, <em>6</em>(2), 180–186.
(<a href="https://doi.org/10.1038/s42256-024-00790-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The removal or cancellation of noise has wide-spread applications in imaging and acoustics. In applications in everyday life, such as image restoration, denoising may even include generative aspects, which are unfaithful to the ground truth. For scientific use, however, denoising must reproduce the ground truth accurately. Denoising scientific data is further challenged by unknown noise profiles. In fact, such data will often include noise from multiple distinct sources, which substantially reduces the applicability of simulation-based approaches. Here we show how scientific data can be denoised by using a deep convolutional neural network such that weak signals appear with quantitative accuracy. In particular, we study X-ray diffraction and resonant X-ray scattering data recorded on crystalline materials. We demonstrate that weak signals stemming from charge ordering, insignificant in the noisy data, become visible and accurate in the denoised data. This success is enabled by supervised training of a deep neural network with pairs of measured low- and high-noise data. We additionally show that using artificial noise does not yield such quantitatively accurate results. Our approach thus illustrates a practical strategy for noise filtering that can be applied to challenging acquisition problems. Denoising low-counting statistics data in the presence of multiple, unknown noise profiles is a challenging task in scientific applications where high accuracy is required. Oppliger and colleagues train a deep convolutional neural network on pairs of experimental low- and high-noise X-ray diffraction data and demonstrate better performance on experimental noise filtering compared with the case of training on artificial data pairs.},
  archive      = {J_NATMI},
  author       = {Oppliger, Jens and Denner, M. Michael and Küspert, Julia and Frison, Ruggero and Wang, Qisi and Morawietz, Alexander and Ivashko, Oleh and Dippel, Ann-Christin and Zimmermann, Martin von and Biało, Izabela and Martinelli, Leonardo and Fauqué, Benoît and Choi, Jaewon and Garcia-Fernandez, Mirian and Zhou, Ke-Jin and Christensen, Niels Bech and Kurosawa, Tohru and Momono, Naoki and Oda, Migaku and Natterer, Fabian D. and Fischer, Mark H. and Neupert, Titus and Chang, Johan},
  doi          = {10.1038/s42256-024-00790-1},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {180-186},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Weak signal extraction enabled by deep neural network denoising of diffraction data},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Codon language embeddings provide strong signals for use in
protein engineering. <em>NATMI</em>, <em>6</em>(2), 170–179. (<a
href="https://doi.org/10.1038/s42256-024-00791-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein representations from deep language models have yielded state-of-the-art performance across many tasks in computational protein engineering. In recent years, progress has primarily focused on parameter count, with recent models’ capacities surpassing the size of the very datasets they were trained on. Here we propose an alternative direction. We show that large language models trained on codons, instead of amino acid sequences, provide high-quality representations that outperform comparable state-of-the-art models across a variety of tasks. In some tasks, such as species recognition, prediction of protein and transcript abundance or melting point estimation, we show that a language model trained on codons outperforms every other published protein language model, including some that contain over 50 times more parameters. These results indicate that, in addition to commonly studied scale and model complexity, the information content of biological data provides an orthogonal direction to improve the power of machine learning in biology. Machine learning methods have made great advances in modelling protein sequences for a variety of downstream tasks. The representation used as input for these models has been primarily the sequence of amino acids. Outeiral and Deane show that using codon sequences instead can improve protein representations and lead to model performance.},
  archive      = {J_NATMI},
  author       = {Outeiral, Carlos and Deane, Charlotte M.},
  doi          = {10.1038/s42256-024-00791-0},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {170-179},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Codon language embeddings provide strong signals for use in protein engineering},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging large language models for predictive chemistry.
<em>NATMI</em>, <em>6</em>(2), 161–169. (<a
href="https://doi.org/10.1038/s42256-023-00788-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has transformed many fields and has recently found applications in chemistry and materials science. The small datasets commonly found in chemistry sparked the development of sophisticated machine learning approaches that incorporate chemical knowledge for each application and, therefore, require specialized expertise to develop. Here we show that GPT-3, a large language model trained on vast amounts of text extracted from the Internet, can easily be adapted to solve various tasks in chemistry and materials science by fine-tuning it to answer chemical questions in natural language with the correct answer. We compared this approach with dedicated machine learning models for many applications spanning the properties of molecules and materials to the yield of chemical reactions. Surprisingly, our fine-tuned version of GPT-3 can perform comparably to or even outperform conventional machine learning techniques, in particular in the low-data limit. In addition, we can perform inverse design by simply inverting the questions. The ease of use and high performance, especially for small datasets, can impact the fundamental approach to using machine learning in the chemical and material sciences. In addition to a literature search, querying a pre-trained large language model might become a routine way to bootstrap a project by leveraging the collective knowledge encoded in these foundation models, or to provide a baseline for predictive tasks. Machine learning techniques are widely employed in chemical science, but are application specific and their development requires dedicated expertise. Jablonka and colleagues fine-tune the GPT-3 model and show that it can provide surprisingly accurate answers to a wide range of chemical questions.},
  archive      = {J_NATMI},
  author       = {Jablonka, Kevin Maik and Schwaller, Philippe and Ortega-Guerrero, Andres and Smit, Berend},
  doi          = {10.1038/s42256-023-00788-1},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {161-169},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Leveraging large language models for predictive chemistry},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Variational autoencoder for design of synthetic viral vector
serotypes. <em>NATMI</em>, <em>6</em>(2), 147–160. (<a
href="https://doi.org/10.1038/s42256-023-00787-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent, rapid advances in deep generative models for protein design have focused on small proteins with lots of data. Such models perform poorly on large proteins with limited natural sequences, for instance, the capsid protein of adenoviruses and adeno-associated virus, which are common delivery vehicles for gene therapy. Generating synthetic viral vector serotypes could overcome the potent pre-existing immune responses that most gene therapy recipients exhibit—a consequence of previous environmental exposure. We present a variational autoencoder (ProteinVAE) that can generate synthetic viral vector serotypes without epitopes for pre-existing neutralizing antibodies. A pre-trained protein language model was incorporated into the encoder to improve data efficiency, and deconvolution-based upsampling was used for decoding to avoid degenerate repetition seen in long protein sequence generation. ProteinVAE is a compact generative model with just 12.4 million parameters and was efficiently trained on the limited natural sequences. Viral protein sequences generated were used to produce structures with thermodynamic stability and viral assembly capability indistinguishable from natural vector counterparts. ProteinVAE can be used to generate a broad range of synthetic serotype sequences without epitopes for pre-existing neutralizing antibodies in the human population, effectively addressing one of the major challenges of gene therapy. It could be used more broadly to generate different types of viral vector, and any large, therapeutically valuable proteins, where available data are sparse. Recent years have seen many advances in deep learning models for protein design, usually involving a large amount of training data. Focusing on potential clinical impact, Garton et al. develop a variational autoencoder approach trained on sparse data of natural sequences of adenoviruses to generate large proteins that can be used as viral vectors in gene therapy.},
  archive      = {J_NATMI},
  author       = {Lyu, Suyue and Sowlati-Hashjin, Shahin and Garton, Michael},
  doi          = {10.1038/s42256-023-00787-2},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {147-160},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Variational autoencoder for design of synthetic viral vector serotypes},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A causal perspective on dataset bias in machine learning for
medical imaging. <em>NATMI</em>, <em>6</em>(2), 138–146. (<a
href="https://doi.org/10.1038/s42256-024-00797-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As machine learning methods gain prominence within clinical decision-making, the need to address fairness concerns becomes increasingly urgent. Despite considerable work dedicated to detecting and ameliorating algorithmic bias, today’s methods are deficient, with potentially harmful consequences. Our causal Perspective sheds new light on algorithmic bias, highlighting how different sources of dataset bias may seem indistinguishable yet require substantially different mitigation strategies. We introduce three families of causal bias mechanisms stemming from disparities in prevalence, presentation and annotation. Our causal analysis underscores how current mitigation methods tackle only a narrow and often unrealistic subset of scenarios. We provide a practical three-step framework for reasoning about fairness in medical imaging, supporting the development of safe and equitable predictive models. Machine learning algorithms play important roles in medical imaging analysis but can be affected by biases in training data. Jones and colleagues discuss how causal reasoning can be used to better understand and tackle algorithmic bias in medical imaging analysis.},
  archive      = {J_NATMI},
  author       = {Jones, Charles and Castro, Daniel C. and De Sousa Ribeiro, Fabio and Oktay, Ozan and McCradden, Melissa and Glocker, Ben},
  doi          = {10.1038/s42256-024-00797-8},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {138-146},
  shortjournal = {Nat. Mach. Intell.},
  title        = {A causal perspective on dataset bias in machine learning for medical imaging},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural multi-task learning in drug design. <em>NATMI</em>,
<em>6</em>(2), 124–137. (<a
href="https://doi.org/10.1038/s42256-023-00785-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning (MTL) is a machine learning paradigm that aims to enhance the generalization of predictive models by leveraging shared information across multiple tasks. The recent breakthroughs achieved by deep neural network models in various domains have sparked hope for similar advances in the chemical sciences. In this Perspective, we provide insights into the current state and future potential of neural MTL models applied to computer-assisted drug design. In the context of drug discovery, one prominent application of MTL is protein–ligand binding affinity prediction, in which individual proteins are considered tasks. Here we introduce the fundamental principles of MTL and propose a framework for categorizing MTL models on the basis of their architecture. This framework enables us to present a comprehensive overview and comparison of a selection of MTL models that have been successfully utilized in drug design. Subsequently, we delve into the current challenges associated with the applications of MTL. One of the key challenges lies in defining suitable representations of the molecular entities under investigation and the respective machine learning tasks. Training a machine learning model with multiple tasks can create more-useful representations and achieve better performance than training models for each task separately. In this Perspective, Allenspach et al. summarize and compare multi-task learning methods for computer-aided drug design.},
  archive      = {J_NATMI},
  author       = {Allenspach, Stephan and Hiss, Jan A. and Schneider, Gisbert},
  doi          = {10.1038/s42256-023-00785-4},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {124-137},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Neural multi-task learning in drug design},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). What comparing deep neural networks can teach us about human
vision. <em>NATMI</em>, <em>6</em>(2), 122–123. (<a
href="https://doi.org/10.1038/s42256-024-00789-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent work has demonstrated important parallels between human visual representations and those found in deep neural networks. A new study comparing functional MRI data to deep neural network models highlights factors that may determine this similarity.},
  archive      = {J_NATMI},
  author       = {Seeliger, Katja and Hebart, Martin N.},
  doi          = {10.1038/s42256-024-00789-8},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {122-123},
  shortjournal = {Nat. Mach. Intell.},
  title        = {What comparing deep neural networks can teach us about human vision},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI protein shake-up. <em>NATMI</em>, <em>6</em>(2), 121. (<a
href="https://doi.org/10.1038/s42256-024-00806-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most successful areas for deep learning in scientific discovery has been protein predictions and engineering. We take a closer look at four studies in this issue that advance protein science with innovative deep learning approaches.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-024-00806-w},
  journal      = {Nature Machine Intelligence},
  month        = {2},
  number       = {2},
  pages        = {121},
  shortjournal = {Nat. Mach. Intell.},
  title        = {AI protein shake-up},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Publisher correction: Reconstructing growth and dynamic
trajectories from single-cell transcriptomics data. <em>NATMI</em>,
<em>6</em>(1), 119. (<a
href="https://doi.org/10.1038/s42256-023-00786-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Sha, Yutong and Qiu, Yuchi and Zhou, Peijie and Nie, Qing},
  doi          = {10.1038/s42256-023-00786-3},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {119},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Publisher correction: Reconstructing growth and dynamic trajectories from single-cell transcriptomics data},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Capturing complex hand movements and object interactions
using machine learning-powered stretchable smart textile gloves.
<em>NATMI</em>, <em>6</em>(1), 106–118. (<a
href="https://doi.org/10.1038/s42256-023-00780-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate real-time tracking of dexterous hand movements has numerous applications in human–computer interaction, the metaverse, robotics and tele-health. Capturing realistic hand movements is challenging because of the large number of articulations and degrees of freedom. Here we report accurate and dynamic tracking of articulated hand and finger movements using stretchable, washable smart gloves with embedded helical sensor yarns and inertial measurement units. The sensor yarns have a high dynamic range, responding to strains as low as 0.005% and as high as 155%, and show stability during extensive use and washing cycles. We use multi-stage machine learning to report average joint-angle estimation root mean square errors of 1.21° and 1.45° for intra- and inter-participant cross-validation, respectively, matching the accuracy of costly motion-capture cameras without occlusion or field-of-view limitations. We report a data augmentation technique that enhances robustness to noise and variations of sensors. We demonstrate accurate tracking of dexterous hand movements during object interactions, opening new avenues of applications, including accurate typing on a mock paper keyboard, recognition of complex dynamic and static gestures adapted from American Sign Language, and object identification. Accurate real-time tracking of dexterous hand movements and interactions has applications in human–computer interaction, the metaverse, robotics and tele-health. Capturing realistic hand movements is challenging due to the large number of articulations and degrees of freedom. Tashakori and colleagues report accurate and dynamic tracking of articulated hand and finger movements using machine-learning powered stretchable, washable smart gloves.},
  archive      = {J_NATMI},
  author       = {Tashakori, Arvin and Jiang, Zenan and Servati, Amir and Soltanian, Saeid and Narayana, Harishkumar and Le, Katherine and Nakayama, Caroline and Yang, Chieh-ling and Wang, Z. Jane and Eng, Janice J. and Servati, Peyman},
  doi          = {10.1038/s42256-023-00780-9},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {106-118},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Capturing complex hand movements and object interactions using machine learning-powered stretchable smart textile gloves},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Autonomous 3D positional control of a magnetic microrobot
using reinforcement learning. <em>NATMI</em>, <em>6</em>(1), 92–105. (<a
href="https://doi.org/10.1038/s42256-023-00779-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic microrobots have shown promise in the field of biomedical engineering, facilitating precise drug delivery, non-invasive diagnosis and cell-based therapy. Current techniques for controlling the motion of such microrobots rely on the assumption of homogenous magnetic fields and are significantly influenced by a microrobot’s properties and surrounding environment. These strategies lack a sense of generality and adaptability when changing the environment or microrobot and exhibit a moderate delay due to independent control of the electromagnetic actuation system and microrobot’s position. To address these issues, we propose a machine learning-based positional control of magnetic microrobots via gradient fields generated by electromagnetic coils. We use reinforcement learning and a gradual training approach to control the three-dimensional position of a microrobot within a defined working area by directly managing the coil currents. We develop a simulation environment for initial exploration to reduce the overall training time. After simulation training, the learning process is transferred to a physical electromagnetic actuation system that reflects real-world intricacies. We compare our method to conventional proportional-integral-derivative control; our system is more accurate and efficient. The proposed method was combined with path planning algorithms to allow fully autonomous control. The presented approach is an alternative to complex mathematical models, which are sensitive to variations in microrobot design, the environment and the nonlinearity of magnetic systems. Magnetic microrobots are of considerable interest for non-invasive biomedical applications but it is challenging to develop a general strategy for controlling microrobot positions, for varying configurations and environments. Choi et al. develop a reinforcement learning control method, training the model in a simulation environment for initial exploration after which the learning process is transferred to a physical electromagnetic actuation system.},
  archive      = {J_NATMI},
  author       = {Abbasi, Sarmad Ahmad and Ahmed, Awais and Noh, Seungmin and Gharamaleki, Nader Latifi and Kim, Seonhyoung and Chowdhury, A. M. Masum Bulbul and Kim, Jin-young and Pané, Salvador and Nelson, Bradley J. and Choi, Hongsoo},
  doi          = {10.1038/s42256-023-00779-2},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {92-105},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Autonomous 3D positional control of a magnetic microrobot using reinforcement learning},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assessing antibody and nanobody nativeness for hit selection
and humanization with AbNatiV. <em>NATMI</em>, <em>6</em>(1), 74–91. (<a
href="https://doi.org/10.1038/s42256-023-00778-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monoclonal antibodies have emerged as key therapeutics. In particular, nanobodies, small, single-domain antibodies that are naturally expressed in camelids, are rapidly gaining momentum following the approval of the first nanobody drug in 2019. Nonetheless, the development of these biologics as therapeutics remains a challenge. Despite the availability of established in vitro directed-evolution technologies that are relatively fast and cheap to deploy, the gold standard for generating therapeutic antibodies remains discovery from animal immunization or patients. Immune-system-derived antibodies tend to have favourable properties in vivo, including long half-life, low reactivity with self-antigens and low toxicity. Here we present AbNatiV, a deep learning tool for assessing the nativeness of antibodies and nanobodies, that is, their likelihood of belonging to the distribution of immune-system-derived human antibodies or camelid nanobodies. AbNatiV is a multipurpose tool that accurately predicts the nativeness of Fv sequences from any source, including synthetic libraries and computational design. It provides an interpretable score that predicts the likelihood of immunogenicity, and a residue-level profile that can guide the engineering of antibodies and nanobodies indistinguishable from immune-system-derived ones. We further introduce an automated humanization pipeline, which we applied to two nanobodies. Laboratory experiments show that AbNatiV-humanized nanobodies retain binding and stability at par or better than their wild type, unlike nanobodies that are humanized using conventional structural and residue-frequency analysis. We make AbNatiV available as downloadable software and as a webserver. Designing antibodies and assessing their biophysical properties for potential therapeutic development is challenging with current computational methods. Ramon et al. have developed a deep learning approach called AbNatiV, based on a vector-quantized variational encoder that accurately assesses the nativeness of antibodies and nanobodies, which are small single-domain antibodies that have recently attracted considerable interest.},
  archive      = {J_NATMI},
  author       = {Ramon, Aubin and Ali, Montader and Atkinson, Misha and Saturnino, Alessio and Didi, Kieran and Visentin, Cristina and Ricagno, Stefano and Xu, Xing and Greenig, Matthew and Sormanni, Pietro},
  doi          = {10.1038/s42256-023-00778-3},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {74-91},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Assessing antibody and nanobody nativeness for hit selection and humanization with AbNatiV},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generation of 3D molecules in pockets via a language model.
<em>NATMI</em>, <em>6</em>(1), 62–73. (<a
href="https://doi.org/10.1038/s42256-023-00775-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models for molecules based on sequential line notation (for example, the simplified molecular-input line-entry system) or graph representation have attracted an increasing interest in the field of structure-based drug design, but they struggle to capture important three-dimensional (3D) spatial interactions and often produce undesirable molecular structures. To address these challenges, we introduce Lingo3DMol, a pocket-based 3D molecule generation method that combines language models and geometric deep learning technology. A new molecular representation, the fragment-based simplified molecular-input line-entry system with local and global coordinates, was developed to assist the model in learning molecular topologies and atomic spatial positions. Additionally, we trained a separate non-covalent interaction predictor to provide essential binding pattern information for the generative model. Lingo3DMol can efficiently traverse drug-like chemical spaces, preventing the formation of unusual structures. The Directory of Useful Decoys-Enhanced dataset was used for evaluation. Lingo3DMol outperformed state-of-the-art methods in terms of drug likeness, synthetic accessibility, pocket binding mode and molecule generation speed. Drug design has recently seen immense improvements in computational methods, but models can still struggle generalizing across binding pockets. Feng and colleagues combine a language model with geometric deep learning to provide efficient generation of potential new drugs.},
  archive      = {J_NATMI},
  author       = {Feng, Wei and Wang, Lvwei and Lin, Zaiyun and Zhu, Yanhao and Wang, Han and Dong, Jianqiang and Bai, Rong and Wang, Huting and Zhou, Jielong and Peng, Wei and Huang, Bo and Zhou, Wenbiao},
  doi          = {10.1038/s42256-023-00775-6},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {62-73},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Generation of 3D molecules in pockets via a language model},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-animal 3D social pose estimation, identification and
behaviour embedding with a few-shot learning framework. <em>NATMI</em>,
<em>6</em>(1), 48–61. (<a
href="https://doi.org/10.1038/s42256-023-00776-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quantification of animal social behaviour is an essential step to reveal brain functions and psychiatric disorders during interaction phases. While deep learning-based approaches have enabled precise pose estimation, identification and behavioural classification of multi-animals, their application is challenged by the lack of well-annotated datasets. Here we show a computational framework, the Social Behavior Atlas (SBeA) used to overcome the problem caused by the limited datasets. SBeA uses a much smaller number of labelled frames for multi-animal three-dimensional pose estimation, achieves label-free identification recognition and successfully applies unsupervised dynamic learning to social behaviour classification. SBeA is validated to uncover previously overlooked social behaviour phenotypes of autism spectrum disorder knockout mice. Our results also demonstrate that the SBeA can achieve high performance across various species using existing customized datasets. These findings highlight the potential of SBeA for quantifying subtle social behaviours in the fields of neuroscience and ecology. Multi-animal behaviour quantification is pivotal for deciphering animal social behaviours and has broad applications in neuroscience and ecology. Han and colleagues develop a few-shot learning framework for multi-animal 3D pose estimation, identity recognition and social behaviour classification.},
  archive      = {J_NATMI},
  author       = {Han, Yaning and Chen, Ke and Wang, Yunke and Liu, Wenhao and Wang, Zhouwei and Wang, Xiaojing and Han, Chuanliang and Liao, Jiahui and Huang, Kang and Cai, Shengyuan and Huang, Yiting and Wang, Nan and Li, Jinxiu and Song, Yangwangzi and Li, Jing and Wang, Guo-Dong and Wang, Liping and Zhang, Yaping and Wei, Pengfei},
  doi          = {10.1038/s42256-023-00776-5},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {48-61},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Multi-animal 3D social pose estimation, identification and behaviour embedding with a few-shot learning framework},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inversion dynamics of class manifolds in deep learning
reveals tradeoffs underlying generalization. <em>NATMI</em>,
<em>6</em>(1), 40–47. (<a
href="https://doi.org/10.1038/s42256-023-00772-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve near-zero training error in a classification problem, the layers of a feed-forward network have to disentangle the manifolds of data points with different labels to facilitate the discrimination. However, excessive class separation can lead to overfitting because good generalization requires learning invariant features, which involve some level of entanglement. We report on numerical experiments showing how the optimization dynamics finds representations that balance these opposing tendencies with a non-monotonic trend. After a fast segregation phase, a slower rearrangement (conserved across datasets and architectures) increases the class entanglement. The training error at the inversion is stable under subsampling and across network initializations and optimizers, which characterizes it as a property solely of the data structure and (very weakly) of the architecture. The inversion is the manifestation of tradeoffs elicited by well-defined and maximally stable elements of the training set called ‘stragglers’, which are particularly influential for generalization. Feed-forward neural networks have become powerful tools in machine learning, but their behaviour during optimization is still not well understood. Ciceri and colleagues find that during optimization, class representations first separate and then rejoin, prompted by specific elements of the training set.},
  archive      = {J_NATMI},
  author       = {Ciceri, Simone and Cassani, Lorenzo and Osella, Matteo and Rotondo, Pietro and Valle, Filippo and Gherardi, Marco},
  doi          = {10.1038/s42256-023-00772-9},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {40-47},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Inversion dynamics of class manifolds in deep learning reveals tradeoffs underlying generalization},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Reconstructing growth and dynamic trajectories from
single-cell transcriptomics data. <em>NATMI</em>, <em>6</em>(1), 25–39.
(<a href="https://doi.org/10.1038/s42256-023-00763-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series single-cell RNA sequencing (scRNA-seq) datasets provide unprecedented opportunities to learn dynamic processes of cellular systems. Due to the destructive nature of sequencing, it remains challenging to link the scRNA-seq snapshots sampled at different time points. Here we present TIGON, a dynamic, unbalanced optimal transport algorithm that reconstructs dynamic trajectories and population growth simultaneously as well as the underlying gene regulatory network from multiple snapshots. To tackle the high-dimensional optimal transport problem, we introduce a deep learning method using a dimensionless formulation based on the Wasserstein–Fisher–Rao (WFR) distance. TIGON is evaluated on simulated data and compared with existing methods for its robustness and accuracy in predicting cell state transition and cell population growth. Using three scRNA-seq datasets, we show the importance of growth in the temporal inference, TIGON’s capability in reconstructing gene expression at unmeasured time points and its applications to temporal gene regulatory networks and cell–cell communication inference. Single-cell transcriptomics has provided a powerful approach to investigate cellular properties at unprecedented resolution. Sha et al. have developed an optimal transport-based algorithm called TIGON that can connect transcriptomic snapshots from different time points to obtain collective dynamical information, including cell population growth and the underlying gene regulatory network.},
  archive      = {J_NATMI},
  author       = {Sha, Yutong and Qiu, Yuchi and Zhou, Peijie and Nie, Qing},
  doi          = {10.1038/s42256-023-00763-w},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {25-39},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Reconstructing growth and dynamic trajectories from single-cell transcriptomics data},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving generalization of machine learning-identified
biomarkers using causal modelling with examples from immune receptor
diagnostics. <em>NATMI</em>, <em>6</em>(1), 15–24. (<a
href="https://doi.org/10.1038/s42256-023-00781-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning is increasingly used to discover diagnostic and prognostic biomarkers from high-dimensional molecular data. However, a variety of factors related to experimental design may affect the ability to learn generalizable and clinically applicable diagnostics. Here we argue that a causal perspective improves the identification of these challenges and formalizes their relation to the robustness and generalization of machine learning-based diagnostics. To make for a concrete discussion, we focus on a specific, recently established high-dimensional biomarker—adaptive immune receptor repertoires (AIRRs). Through simulations, we illustrate how major biological and experimental factors of the AIRR domain may influence the learned biomarkers. In conclusion, we argue that causal modelling improves machine learning-based biomarker robustness by identifying stable relations between variables and guiding the adjustment of the relations and variables that vary between populations. Machine learning is increasingly applied for disease diagnostics due to its ability to discover differentiating features in data. However, the clinical applicability of these models remains a challenge. Pavlović et al. provide an overview of the challenges in using machine learning for biomarker discovery and suggest a causal perspective as a solution.},
  archive      = {J_NATMI},
  author       = {Pavlović, Milena and Al Hajj, Ghadi S. and Kanduri, Chakravarthi and Pensar, Johan and Wood, Mollie E. and Sollid, Ludvig M. and Greiff, Victor and Sandve, Geir K.},
  doi          = {10.1038/s42256-023-00781-8},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {15-24},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Improving generalization of machine learning-identified biomarkers using causal modelling with examples from immune receptor diagnostics},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Catching up with missing particles. <em>NATMI</em>,
<em>6</em>(1), 13–14. (<a
href="https://doi.org/10.1038/s42256-023-00770-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The implementation of particle-tracking techniques with deep neural networks is a promising way to determine particle motion within complex flow structures. A graph neural network-enhanced method enables accurate particle tracking by significantly reducing the number of lost trajectories.},
  archive      = {J_NATMI},
  author       = {Atis, Séverine and Agostini, Lionel},
  doi          = {10.1038/s42256-023-00770-x},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {13-14},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Catching up with missing particles},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anniversary AI reflections. <em>NATMI</em>, <em>6</em>(1),
6–12. (<a href="https://doi.org/10.1038/s42256-023-00784-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For our fifth anniversary, we reconnected with authors of recent Comments and Perspectives in Nature Machine Intelligence and asked them how the topic they wrote about developed. We also wanted to know what other topics in AI they found exciting, surprising or worrying, and what their hopes and expectations are for AI in 2024—and the next five years. A recurring theme is the ongoing developments in large language models and generative AI, their transformative effect on the scientific process and concerns about ethical implications.},
  archive      = {J_NATMI},
  author       = {Ferruz, Noelia and Zitnik, Marinka and Oudeyer, Pierre-Yves and Hine, Emmie and Sengupta, Nandana and Shi, Yiyu and Mincu, Diana and Mann, Sebastian Porsdam and Das, Payel and Stella, Francesco},
  doi          = {10.1038/s42256-023-00784-5},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {6-12},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Anniversary AI reflections},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The dangers of using proprietary LLMs for research.
<em>NATMI</em>, <em>6</em>(1), 4–5. (<a
href="https://doi.org/10.1038/s42256-023-00783-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Ollion, Étienne and Shen, Rubing and Macanovic, Ana and Chatelain, Arnault},
  doi          = {10.1038/s42256-023-00783-6},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {4-5},
  shortjournal = {Nat. Mach. Intell.},
  title        = {The dangers of using proprietary LLMs for research},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guidelines for study protocols describing predefined
validations of prediction models in medical deep learning and beyond.
<em>NATMI</em>, <em>6</em>(1), 2–3. (<a
href="https://doi.org/10.1038/s42256-023-00774-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NATMI},
  author       = {Kleppe, Andreas and Skrede, Ole-Johan and Liestøl, Knut and Kerr, David J. and Danielsen, Håvard E.},
  doi          = {10.1038/s42256-023-00774-7},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {2-3},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Guidelines for study protocols describing predefined validations of prediction models in medical deep learning and beyond},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Is it five already? <em>NATMI</em>, <em>6</em>(1), 1. (<a
href="https://doi.org/10.1038/s42256-024-00796-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We reflect on five years of Nature Machine Intelligence and on providing a venue for discussions in AI.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-024-00796-9},
  journal      = {Nature Machine Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Is it five already?},
  volume       = {6},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
