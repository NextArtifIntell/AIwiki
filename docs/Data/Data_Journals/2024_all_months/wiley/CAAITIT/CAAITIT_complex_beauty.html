<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CAAITIT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="caaitit---107">CAAITIT - 107</h2>
<ul>
<li><details>
<summary>
(2024). Explore human parsing modality for action recognition.
<em>CAAITIT</em>, <em>9</em>(6), 1623–1633. (<a
href="https://doi.org/10.1049/cit2.12366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal-based action recognition methods have achieved high success using pose and RGB modality. However, skeletons sequences lack appearance depiction and RGB images suffer irrelevant noise due to modality limitations. To address this, the authors introduce human parsing feature map as a novel modality, since it can selectively retain effective semantic features of the body parts while filtering out most irrelevant noise. The authors propose a new dual-branch framework called ensemble human parsing and pose network (EPP-Net), which is the first to leverage both skeletons and human parsing modalities for action recognition. The first human pose branch feeds robust skeletons in the graph convolutional network to model pose features, while the second human parsing branch also leverages depictive parsing feature maps to model parsing features via convolutional backbones. The two high-level features will be effectively combined through a late fusion strategy for better action recognition. Extensive experiments on NTU RGB + D and NTU RGB + D 120 benchmarks consistently verify the effectiveness of our proposed EPP-Net, which outperforms the existing action recognition methods. Our code is available at https://github.com/liujf69/EPP-Net-Action .},
  archive      = {J_CAAITIT},
  author       = {Jinfu Liu and Runwei Ding and Yuhang Wen and Nan Dai and Fanyang Meng and Fang-Lue Zhang and Shen Zhao and Mengyuan Liu},
  doi          = {10.1049/cit2.12366},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1623-1633},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Explore human parsing modality for action recognition},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian network structure learning by dynamic programming
algorithm based on node block sequence constraints. <em>CAAITIT</em>,
<em>9</em>(6), 1605–1622. (<a
href="https://doi.org/10.1049/cit2.12363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of dynamic programming (DP) algorithms to learn Bayesian network structures is limited by their high space complexity and difficulty in learning the structure of large-scale networks. Therefore, this study proposes a DP algorithm based on node block sequence constraints. The proposed algorithm constrains the traversal process of the parent graph by using the M-sequence matrix to considerably reduce the time consumption and space complexity by pruning the traversal process of the order graph using the node block sequence. Experimental results show that compared with existing DP algorithms, the proposed algorithm can obtain learning results more efficiently with less than 1% loss of accuracy, and can be used for learning larger-scale networks.},
  archive      = {J_CAAITIT},
  author       = {Chuchao He and Ruohai Di and Bo Li and Evgeny Neretin},
  doi          = {10.1049/cit2.12363},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1605-1622},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Bayesian network structure learning by dynamic programming algorithm based on node block sequence constraints},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inferring causal protein signalling networks from
single-cell data based on parallel discrete artificial bee colony
algorithm. <em>CAAITIT</em>, <em>9</em>(6), 1587–1604. (<a
href="https://doi.org/10.1049/cit2.12344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring causal protein signalling networks from human immune system cell data is a promising approach to unravel the underlying tissue signalling biology and dysfunction in diseased cells, which has attracted considerable attention within the bioinformatics field. Recently, Bayesian network (BN) techniques have gained significant popularity in inferring causal protein signalling networks from multiparameter single-cell data. However, current BN methods may exhibit high computational complexity and ignore interactions among protein signalling molecules from different single cells. A novel BN method is presented for learning causal protein signalling networks based on parallel discrete artificial bee colony (PDABC), named PDABC. Specifically, PDABC is a score-based BN method that utilises the parallel artificial bee colony to search for the global optimal causal protein signalling networks with the highest discrete K2 metric. The experimental results on several simulated datasets, as well as a previously published multi-parameter fluorescence-activated cell sorter dataset, indicate that PDABC surpasses the existing state-of-the-art methods in terms of performance and computational efficiency.},
  archive      = {J_CAAITIT},
  author       = {Jinduo Liu and Jihao Zhai and Junzhong Ji},
  doi          = {10.1049/cit2.12344},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1587-1604},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Inferring causal protein signalling networks from single-cell data based on parallel discrete artificial bee colony algorithm},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-omics graph convolutional networks for digestive
system tumour classification and early-late stage diagnosis.
<em>CAAITIT</em>, <em>9</em>(6), 1572–1586. (<a
href="https://doi.org/10.1049/cit2.12395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of digestive system tumours (DST) poses a significant challenge in the global crusade against cancer. These neoplasms constitute 20% of all documented cancer diagnoses and contribute to 22.5% of cancer-related fatalities. The accurate diagnosis of DST is paramount for vigilant patient monitoring and the judicious selection of optimal treatments. Addressing this challenge, the authors introduce a novel methodology, denominated as the Multi-omics Graph Transformer Convolutional Network (MGTCN). This innovative approach aims to discern various DST tumour types and proficiently discern between early-late stage tumours, ensuring a high degree of accuracy. The MGTCN model incorporates the Graph Transformer Layer framework to meticulously transform the multi-omics adjacency matrix, thereby illuminating potential associations among diverse samples. A rigorous experimental evaluation was undertaken on the DST dataset from The Cancer Genome Atlas to scrutinise the efficacy of the MGTCN model. The outcomes unequivocally underscore the efficiency and precision of MGTCN in diagnosing diverse DST tumour types and successfully discriminating between early-late stage DST cases. The source code for this groundbreaking study is readily accessible for download at https://github.com/bigone1/MGTCN .},
  archive      = {J_CAAITIT},
  author       = {Lin Zhou and Zhengzhi Zhu and Hongbo Gao and Chunyu Wang and Muhammad Attique Khan and Mati Ullah and Siffat Ullah Khan},
  doi          = {10.1049/cit2.12395},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1572-1586},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Multi-omics graph convolutional networks for digestive system tumour classification and early-late stage diagnosis},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Norm-based zeroing neural dynamics for time-variant
non-linear equations. <em>CAAITIT</em>, <em>9</em>(6), 1561–1571. (<a
href="https://doi.org/10.1049/cit2.12360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zeroing neural dynamic (ZND) model is widely deployed for time-variant non-linear equations (TVNE). Various element-wise non-linear activation functions and integration operations are investigated to enhance the convergence performance and robustness in most proposed ZND models for solving TVNE, leading to a huge cost of hardware implementation and model complexity. To overcome these problems, the authors develop a new norm-based ZND (NBZND) model with strong robustness for solving TVNE, not applying element-wise non-linear activated functions but introducing a two-norm operation to achieve finite-time convergence. Moreover, the authors develop a discrete-time NBZND model for the potential deployment of the model on digital computers. Rigorous theoretical analysis for the NBZND is provided. Simulation results substantiate the advantages of the NBZND model for solving TVNE.},
  archive      = {J_CAAITIT},
  author       = {Linyan Dai and Hanyi Xu and Yinyan Zhang and Bolin Liao},
  doi          = {10.1049/cit2.12360},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1561-1571},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Norm-based zeroing neural dynamics for time-variant non-linear equations},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RailPC: A large-scale railway point cloud semantic
segmentation dataset. <em>CAAITIT</em>, <em>9</em>(6), 1548–1560. (<a
href="https://doi.org/10.1049/cit2.12349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation in the context of 3D point clouds for the railway environment holds a significant economic value, but its development is severely hindered by the lack of suitable and specific datasets. Additionally, the models trained on existing urban road point cloud datasets demonstrate poor generalisation on railway data due to a large domain gap caused by non-overlapping special/rare categories, for example, rail track, track bed etc. To harness the potential of supervised learning methods in the domain of 3D railway semantic segmentation, we introduce RailPC, a new point cloud benchmark. RailPC provides a large-scale dataset with rich annotations for semantic segmentation in the railway environment. Notably, RailPC contains twice the number of annotated points compared to the largest available mobile laser scanning (MLS) point cloud dataset and is the first railway-specific 3D dataset for semantic segmentation. It covers a total of nearly 25 km railway in two different scenes (urban and mountain), with 3 billion points that are finely labelled as 16 most typical classes with respect to railway, and the data acquisition process is completed in China by MLS systems. Through extensive experimentation, we evaluate the performance of advanced scene understanding methods on the annotated dataset and present a synthetic analysis of semantic segmentation results. Based on our findings, we establish some critical challenges towards railway-scale point cloud semantic segmentation. The dataset is available at https://github.com/NNU-GISA/GISA-RailPC , and we will continuously update it based on community feedback.},
  archive      = {J_CAAITIT},
  author       = {Tengping Jiang and Shiwei Li and Qinyu Zhang and Guangshuai Wang and Zequn Zhang and Fankun Zeng and Peng An and Xin Jin and Shan Liu and Yongjun Wang},
  doi          = {10.1049/cit2.12349},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1548-1560},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {RailPC: A large-scale railway point cloud semantic segmentation dataset},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DRRN: Differential rectification &amp; refinement network
for ischemic infarct segmentation. <em>CAAITIT</em>, <em>9</em>(6),
1534–1547. (<a href="https://doi.org/10.1049/cit2.12350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of infarct tissue in ischemic stroke is essential to determine the extent of injury and assess the risk and choose optimal treatment for this life-threatening disease. With the prior knowledge that asymmetric analysis of anatomical structures can provide discriminative information, plenty of symmetry-based approaches have emerged to detect abnormalities in brain images. However, the inevitable non-pathological noise has not been fully alleviated and weakened, leading to unsatisfactory results. A novel differential rectification and refinement network (DRRN) for the automatic segmentation of ischemic strokes is proposed. Specifically, a differential feature perception encoder (DFPE) is developed to fully exploit and propagate the bilateral quasi-symmetry of healthy brains. In DFPE, an erasure-rectification (ER) module is devised to rectify pseudo-lesion features caused by non-pathological noise through utilising discriminant features within the symmetric neighbourhood of the original image. And a differential-attention (DA) mechanism is also integrated to fully perceive the differences in cross-axial features and estimate the similarity of long-range spatial context information. In addition, a crisscross differential feature reinforce module embedded with multiple boundary enhancement attention modules is designed to effectively integrate multi-scale features and refine textual details and margins of the infarct area. Experimental results on the public ATLAS and Kaggle dataset demonstrate the effectiveness of DRRN over state-of-the-arts.},
  archive      = {J_CAAITIT},
  author       = {Wenxue Zhou and Wenming Yang and Qingmin Liao},
  doi          = {10.1049/cit2.12350},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1534-1547},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {DRRN: Differential rectification &amp; refinement network for ischemic infarct segmentation},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MSO-DETR: Metric space optimization for few-shot object
detection. <em>CAAITIT</em>, <em>9</em>(6), 1515–1533. (<a
href="https://doi.org/10.1049/cit2.12342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the metric-based meta-learning detection model, the distribution of training samples in the metric space has great influence on the detection performance, and this influence is usually ignored by traditional meta-detectors. In addition, the design of metric space might be interfered with by the background noise of training samples. To tackle these issues, we propose a metric space optimisation method based on hyperbolic geometry attention and class-agnostic activation maps. First, the geometric properties of hyperbolic spaces to establish a structured metric space are used. A variety of feature samples of different classes are embedded into the hyperbolic space with extremely low distortion. This metric space is more suitable for representing tree-like structures between categories for image scene analysis. Meanwhile, a novel similarity measure function based on Poincaré distance is proposed to evaluate the distance of various types of objects in the feature space. In addition, the class-agnostic activation maps (CCAMs) are employed to re-calibrate the weight of foreground feature information and suppress background information. Finally, the decoder processes the high-level feature information as the decoding of the query object and detects objects by predicting their locations and corresponding task encodings. Experimental evaluation is conducted on Pascal VOC and MS COCO datasets. The experiment results show that the effectiveness of the authors’ method surpasses the performance baseline of the excellent few-shot detection models.},
  archive      = {J_CAAITIT},
  author       = {Haifeng Sima and Manyang Wang and Lanlan Liu and Yudong Zhang and Junding Sun},
  doi          = {10.1049/cit2.12342},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1515-1533},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {MSO-DETR: Metric space optimization for few-shot object detection},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sequential selection and calibration of video frames for 3D
outdoor scene reconstruction. <em>CAAITIT</em>, <em>9</em>(6),
1500–1514. (<a href="https://doi.org/10.1049/cit2.12338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D scene understanding and reconstruction aims to obtain a concise scene representation from images and reconstruct the complete scene, including the scene layout, objects bounding boxes and shapes. Existing holistic scene understanding methods primarily recover scenes from single images, with a focus on indoor scenes. Due to the complexity of real-world, the information provided by a single image is limited, resulting in issues such as object occlusion and omission. Furthermore, captured data from outdoor scenes exhibits characteristics of sparsity, strong temporal dependencies and a lack of annotations. Consequently, the task of understanding and reconstructing outdoor scenes is highly challenging. The authors propose a sparse multi-view images-based 3D scene reconstruction framework (SMSR). It divides the scene reconstruction task into three stages: initial prediction, refinement, and fusion stage. The first two stages extract 3D scene representations from each viewpoint, while the final stage involves selection, calibration and fusion of object positions and orientations across different viewpoints. SMSR effectively address the issue of object omission by utilizing small-scale sequential scene information. Experimental results on the general outdoor scene dataset UrbanScene3D-Art Sci and our proprietary dataset Software College Aerial Time-series Images, demonstrate that SMSR achieves superior performance in the scene understanding and reconstruction.},
  archive      = {J_CAAITIT},
  author       = {Weilin Sun and Manyi Li and Peng Li and Xiao Cao and Xiangxu Meng and Lei Meng},
  doi          = {10.1049/cit2.12338},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1500-1514},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Sequential selection and calibration of video frames for 3D outdoor scene reconstruction},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 4D foetal cardiac ultrasound image detection based on deep
learning with weakly supervised localisation for rapid diagnosis of
evolving hypoplastic left heart syndrome. <em>CAAITIT</em>,
<em>9</em>(6), 1485–1499. (<a
href="https://doi.org/10.1049/cit2.12354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypoplastic left heart syndrome (HLHS) is a rare, complex, and incredibly foetal congenital heart disease. To decrease neonatal mortality, evolving HLHS (eHLHS) in pregnant women should be critically diagnosed as soon as possible. However, diagnosis is currently heavily dependent on skilled medical professionals using foetal cardiac ultrasound images, making it difficult to rapidly and easily examine for this disease. Herein, the authors propose a cost-effective deep learning framework for rapid diagnosis of eHLHS (RDeH), which we have named RDeH-Net. Briefly, the framework implements a coarse-to-fine two-stage detection approach, with a structure classification network for 4D human foetal cardiac ultrasound images from various spatial and temporal domains, and a fine detection module with weakly-supervised localisation for high-precision nidus localisation and physician assistance. The experiments extensively compare the authors’ network with other state-of-the-art methods on a 4D human foetal cardiac ultrasound image dataset and show two main benefits: (1) it achieved superior average accuracy of 99.37% on three categories of foetal ultrasound images from different cases; (2) it demonstrates visually fine detection performance with weakly supervised localisation. This framework could be used to accelerate the diagnosis of eHLHS, and hence significantly lessen reliance on experienced medical physicians.},
  archive      = {J_CAAITIT},
  author       = {Gang Wang and Weisheng Li and Mingliang Zhou and Haobo Zhu and Guang Yang and Choon Hwai Yap},
  doi          = {10.1049/cit2.12354},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1485-1499},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {4D foetal cardiac ultrasound image detection based on deep learning with weakly supervised localisation for rapid diagnosis of evolving hypoplastic left heart syndrome},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis of anomalous behaviour in network systems using
deep reinforcement learning with convolutional neural network
architecture. <em>CAAITIT</em>, <em>9</em>(6), 1467–1484. (<a
href="https://doi.org/10.1049/cit2.12359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To gain access to networks, various intrusion attack types have been developed and enhanced. The increasing importance of computer networks in daily life is a result of our growing dependence on them. Given this, it is glaringly obvious that algorithmic tools with strong detection performance and dependability are required for a variety of attack types. The objective is to develop a system for intrusion detection based on deep reinforcement learning. On the basis of the Markov decision procedure, the developed system can construct patterns appropriate for classification purposes based on extensive amounts of informative records. Deep Q-Learning (DQL), Soft DQL, Double DQL, and Soft double DQL are examined from two perspectives. An evaluation of the authors’ methods using UNSW-NB15 data demonstrates their superiority regarding accuracy, precision, recall, and F1 score. The validity of the model trained on the UNSW-NB15 dataset was also checked using the BoT-IoT and ToN-IoT datasets, yielding competitive results.},
  archive      = {J_CAAITIT},
  author       = {Mohammad Hossein Modirrousta and Parisa Forghani Arani and Reza Kazemi and Mahdi Aliyari-Shoorehdeli},
  doi          = {10.1049/cit2.12359},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1467-1484},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Analysis of anomalous behaviour in network systems using deep reinforcement learning with convolutional neural network architecture},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). OSFS-vague: Online streaming feature selection algorithm
based on vague set. <em>CAAITIT</em>, <em>9</em>(6), 1451–1466. (<a
href="https://doi.org/10.1049/cit2.12327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online streaming feature selection (OSFS), as an online learning manner to handle streaming features, is critical in addressing high-dimensional data. In real big data-related applications, the patterns and distributions of streaming features constantly change over time due to dynamic data generation environments. However, existing OSFS methods rely on presented and fixed hyperparameters, which undoubtedly lead to poor selection performance when encountering dynamic features. To make up for the existing shortcomings, the authors propose a novel OSFS algorithm based on vague set, named OSFS-Vague. Its main idea is to combine uncertainty and three-way decision theories to improve feature selection from the traditional dichotomous method to the trichotomous method. OSFS-Vague also improves the calculation method of correlation between features and labels. Moreover, OSFS-Vague uses the distance correlation coefficient to classify streaming features into relevant features, weakly redundant features, and redundant features. Finally, the relevant features and weakly redundant features are filtered for an optimal feature set. To evaluate the proposed OSFS-Vague, extensive empirical experiments have been conducted on 11 datasets. The results demonstrate that OSFS-Vague outperforms six state-of-the-art OSFS algorithms in terms of selection accuracy and computational efficiency.},
  archive      = {J_CAAITIT},
  author       = {Jie Yang and Zhijun Wang and Guoyin Wang and Yanmin Liu and Yi He and Di Wu},
  doi          = {10.1049/cit2.12327},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1451-1466},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {OSFS-vague: Online streaming feature selection algorithm based on vague set},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integer wavelet transform-based secret image sharing using
rook polynomial and hamming code with authentication. <em>CAAITIT</em>,
<em>9</em>(6), 1435–1450. (<a
href="https://doi.org/10.1049/cit2.12357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective way to securely transfer secret images, secret image sharing (SIS) has been a noteworthy area of research. Basically in a SIS scheme, a secret image is shared via shadows and could be reconstructed by having the required number of them. A major downside of this method is its noise-like shadows, which draw the malicious users&#39; attention. In order to overcome this problem, SIS schemes with meaningful shadows are introduced in which the shadows are first hidden in innocent-looking cover images and then shared. In most of these schemes, the cover image cannot be recovered without distortion, which makes them useless in case of utilising critical cover images such as military or medical images. Also, embedding the secret data in Least significant bits of the cover image, in many of these schemes, makes them very fragile to steganlysis. A reversible IWT-based SIS scheme using Rook polynomial and Hamming code with authentication is proposed. In order to make the scheme robust to steganalysis, the shadow image is embedded in coefficients of Integer wavelet transform of the cover image. Using Rook polynomial makes the scheme more secure and moreover makes authentication very easy and with no need to share private key to participants. Also, utilising Hamming code lets us embed data with much less required modifications on the cover image which results in high-quality stego images.},
  archive      = {J_CAAITIT},
  author       = {Sara Charoghchi and Zahra Saeidi and Samaneh Mashhadi},
  doi          = {10.1049/cit2.12357},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1435-1450},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Integer wavelet transform-based secret image sharing using rook polynomial and hamming code with authentication},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic mapping to investigate the application of
machine learning techniques in requirement engineering activities.
<em>CAAITIT</em>, <em>9</em>(6), 1412–1434. (<a
href="https://doi.org/10.1049/cit2.12348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few years, the application and usage of Machine Learning (ML) techniques have increased exponentially due to continuously increasing the size of data and computing capacity. Despite the popularity of ML techniques, only a few research studies have focused on the application of ML especially supervised learning techniques in Requirement Engineering (RE) activities to solve the problems that occur in RE activities. The authors focus on the systematic mapping of past work to investigate those studies that focused on the application of supervised learning techniques in RE activities between the period of 2002–2023. The authors aim to investigate the research trends, main RE activities, ML algorithms, and data sources that were studied during this period. Forty-five research studies were selected based on our exclusion and inclusion criteria. The results show that the scientific community used 57 algorithms. Among those algorithms, researchers mostly used the five following ML algorithms in RE activities: Decision Tree, Support Vector Machine, Naïve Bayes, K-nearest neighbour Classifier, and Random Forest. The results show that researchers used these algorithms in eight major RE activities. Those activities are requirements analysis, failure prediction, effort estimation, quality, traceability, business rules identification, content classification, and detection of problems in requirements written in natural language. Our selected research studies used 32 private and 41 public data sources. The most popular data sources that were detected in selected studies are the Metric Data Programme from NASA, Predictor Models in Software Engineering, and iTrust Electronic Health Care System.},
  archive      = {J_CAAITIT},
  author       = {Shoaib Hassan and Qianmu Li and Khursheed Aurangzeb and Affan Yasin and Javed Ali Khan and Muhammad Shahid Anwar},
  doi          = {10.1049/cit2.12348},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1412-1434},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A systematic mapping to investigate the application of machine learning techniques in requirement engineering activities},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SACNN-IDS: A self-attention convolutional neural network for
intrusion detection in industrial internet of things. <em>CAAITIT</em>,
<em>9</em>(6), 1398–1411. (<a
href="https://doi.org/10.1049/cit2.12352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial Internet of Things (IIoT) is a pervasive network of interlinked smart devices that provide a variety of intelligent computing services in industrial environments. Several IIoT nodes operate confidential data (such as medical, transportation, military, etc.) which are reachable targets for hostile intruders due to their openness and varied structure. Intrusion Detection Systems (IDS) based on Machine Learning (ML) and Deep Learning (DL) techniques have got significant attention. However, existing ML and DL-based IDS still face a number of obstacles that must be overcome. For instance, the existing DL approaches necessitate a substantial quantity of data for effective performance, which is not feasible to run on low-power and low-memory devices. Imbalanced and fewer data potentially lead to low performance on existing IDS. This paper proposes a self-attention convolutional neural network (SACNN) architecture for the detection of malicious activity in IIoT networks and an appropriate feature extraction method to extract the most significant features. The proposed architecture has a self-attention layer to calculate the input attention and convolutional neural network (CNN) layers to process the assigned attention features for prediction. The performance evaluation of the proposed SACNN architecture has been done with the Edge-IIoTset and X-IIoTID datasets. These datasets encompassed the behaviours of contemporary IIoT communication protocols, the operations of state-of-the-art devices, various attack types, and diverse attack scenarios.},
  archive      = {J_CAAITIT},
  author       = {Mimonah Al Qathrady and Safi Ullah and Mohammed S. Alshehri and Jawad Ahmad and Sultan Almakdi and Samar M. Alqhtani and Muazzam A. Khan and Baraq Ghaleb},
  doi          = {10.1049/cit2.12352},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1398-1411},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {SACNN-IDS: A self-attention convolutional neural network for intrusion detection in industrial internet of things},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dual benchmarking study of facial forgery and facial
forensics. <em>CAAITIT</em>, <em>9</em>(6), 1377–1397. (<a
href="https://doi.org/10.1049/cit2.12362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, visual facial forgery has reached a level of sophistication that humans cannot identify fraud, which poses a significant threat to information security. A wide range of malicious applications have emerged, such as deepfake, fake news, defamation or blackmailing of celebrities, impersonation of politicians in political warfare, and the spreading of rumours to attract views. As a result, a rich body of visual forensic techniques has been proposed in an attempt to stop this dangerous trend. However, there is no comprehensive, fair, and unified performance evaluation to enlighten the community on best performing methods. The authors present a systematic benchmark beyond traditional surveys that provides in-depth insights into facial forgery and facial forensics, grounding on robustness tests such as contrast, brightness, noise, resolution, missing information, and compression. The authors also provide a practical guideline of the benchmarking results, to determine the characteristics of the methods that serve as a comparative reference in this never-ending war between measures and countermeasures. The authors’ source code is open to the public.},
  archive      = {J_CAAITIT},
  author       = {Minh Tam Pham and Thanh Trung Huynh and Thanh Tam Nguyen and Thanh Toan Nguyen and Thanh Thi Nguyen and Jun Jo and Hongzhi Yin and Quoc Viet Hung Nguyen},
  doi          = {10.1049/cit2.12362},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1377-1397},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A dual benchmarking study of facial forgery and facial forensics},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimisation of sparse deep autoencoders for dynamic network
embedding. <em>CAAITIT</em>, <em>9</em>(6), 1361–1376. (<a
href="https://doi.org/10.1049/cit2.12367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding (NE) tries to learn the potential properties of complex networks represented in a low-dimensional feature space. However, the existing deep learning-based NE methods are time-consuming as they need to train a dense architecture for deep neural networks with extensive unknown weight parameters. A sparse deep autoencoder (called SPDNE) for dynamic NE is proposed, aiming to learn the network structures while preserving the node evolution with a low computational complexity. SPDNE tries to use an optimal sparse architecture to replace the fully connected architecture in the deep autoencoder while maintaining the performance of these models in the dynamic NE. Then, an adaptive simulated algorithm to find the optimal sparse architecture for the deep autoencoder is proposed. The performance of SPDNE over three dynamical NE models (i.e. sparse architecture-based deep autoencoder method, DynGEM, and ElvDNE) is evaluated on three well-known benchmark networks and five real-world networks. The experimental results demonstrate that SPDNE can reduce about 70% of weight parameters of the architecture for the deep autoencoder during the training process while preserving the performance of these dynamical NE models. The results also show that SPDNE achieves the highest accuracy on 72 out of 96 edge prediction and network reconstruction tasks compared with the state-of-the-art dynamical NE algorithms.},
  archive      = {J_CAAITIT},
  author       = {Huimei Tang and Yutao Zhang and Lijia Ma and Qiuzhen Lin and Liping Huang and Jianqiang Li and Maoguo Gong},
  doi          = {10.1049/cit2.12367},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1361-1376},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Optimisation of sparse deep autoencoders for dynamic network embedding},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel myocarditis detection combining deep reinforcement
learning and an improved differential evolution algorithm.
<em>CAAITIT</em>, <em>9</em>(6), 1347–1360. (<a
href="https://doi.org/10.1049/cit2.12289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Myocarditis is a serious cardiovascular ailment that can lead to severe consequences if not promptly treated. It is triggered by viral infections and presents symptoms such as chest pain and heart dysfunction. Early detection is crucial for successful treatment, and cardiac magnetic resonance imaging (CMR) is a valuable tool for identifying this condition. However, the detection of myocarditis using CMR images can be challenging due to low contrast, variable noise, and the presence of multiple high CMR slices per patient. To overcome these challenges, the approach proposed incorporates advanced techniques such as convolutional neural networks (CNNs), an improved differential evolution (DE) algorithm for pre-training, and a reinforcement learning (RL)-based model for training. Developing this method presented a significant challenge due to the imbalanced classification of the Z-Alizadeh Sani myocarditis dataset from Omid Hospital in Tehran. To address this, the training process is framed as a sequential decision-making process, where the agent receives higher rewards/penalties for correctly/incorrectly classifying the minority/majority class. Additionally, the authors suggest an enhanced DE algorithm to initiate the backpropagation (BP) process, overcoming the initialisation sensitivity issue of gradient-based methods like back-propagation during the training phase. The effectiveness of the proposed model in diagnosing myocarditis is demonstrated through experimental results based on standard performance metrics. Overall, this method shows promise in expediting the triage of CMR images for automatic screening, facilitating early detection and successful treatment of myocarditis.},
  archive      = {J_CAAITIT},
  author       = {Jing Yang and Touseef Sadiq and Jiale Xiong and Muhammad Awais and Uzair Aslam Bhatti and Roohallah Alizadehsani and Juan Manuel Gorriz},
  doi          = {10.1049/cit2.12289},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {12},
  number       = {6},
  pages        = {1347-1360},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A novel myocarditis detection combining deep reinforcement learning and an improved differential evolution algorithm},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BTSC: Binary tree structure convolution layers for building
interpretable decision-making deep CNN. <em>CAAITIT</em>, <em>9</em>(5),
1331–1345. (<a href="https://doi.org/10.1049/cit2.12328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep convolution neural network (DCNN) has achieved great success in computer vision field, such models are considered to lack interpretability in decision-making. One of fundamental issues is that its decision mechanism is considered to be a “black-box” operation. The authors design the binary tree structure convolution (BTSC) module and control the activation level of particular neurons to build the interpretable DCNN model. First, the authors design a BTSC module, in which each parent node generates two independent child layers, and then integrate them into a normal DCNN model. The main advantages of the BTSC are as follows: 1) child nodes of the different parent nodes do not interfere with each other; 2) parent and child nodes can inherit knowledge. Second, considering the activation level of neurons, the authors design an information coding objective to guide neural nodes to learn the particular information coding that is expected. Through the experiments, the authors can verify that: 1) the decision-making made by both the ResNet and DenseNet models can be explained well based on the &quot;decision information flow path&quot; (known as the decision-path ) formed in the BTSC module; 2) the decision-path can reasonably interpret the decision reversal mechanism (Robustness mechanism) of the DCNN model; 3) the credibility of decision-making can be measured by the matching degree between the actual and expected decision-path .},
  archive      = {J_CAAITIT},
  author       = {Yuqi Wang and Dawei Dai and Da Liu and Shuyin Xia and Guoyin Wang},
  doi          = {10.1049/cit2.12328},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1331-1345},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {BTSC: Binary tree structure convolution layers for building interpretable decision-making deep CNN},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian attention-based user behaviour modelling for
click-through rate prediction. <em>CAAITIT</em>, <em>9</em>(5),
1320–1330. (<a href="https://doi.org/10.1049/cit2.12343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploiting the hierarchical dependence behind user behaviour is critical for click-through rate (CRT) prediction in recommender systems. Existing methods apply attention mechanisms to obtain the weights of items; however, the authors argue that deterministic attention mechanisms cannot capture the hierarchical dependence between user behaviours because they treat each user behaviour as an independent individual and cannot accurately express users&#39; flexible and changeable interests. To tackle this issue, the authors introduce the Bayesian attention to the CTR prediction model, which treats attention weights as data-dependent local random variables and learns their distribution by approximating their posterior distribution. Specifically, the prior knowledge is constructed into the attention weight distribution, and then the posterior inference is utilised to capture the implicit and flexible user intentions. Extensive experiments on public datasets demonstrate that our algorithm outperforms state-of-the-art algorithms. Empirical evidence shows that random attention weights can predict user intentions better than deterministic ones.},
  archive      = {J_CAAITIT},
  author       = {Yihao Zhang and Mian Chen and Ruizhen Chen and Chu Zhao and Meng Yuan and Zhu Sun},
  doi          = {10.1049/cit2.12343},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1320-1330},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Bayesian attention-based user behaviour modelling for click-through rate prediction},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Join multiple riemannian manifold representation and
multi-kernel non-redundancy for image clustering. <em>CAAITIT</em>,
<em>9</em>(5), 1305–1319. (<a
href="https://doi.org/10.1049/cit2.12347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image clustering has received significant attention due to the growing importance of image recognition. Researchers have explored Riemannian manifold clustering, which is capable of capturing the non-linear shapes found in real-world datasets. However, the complexity of image data poses substantial challenges for modelling and feature extraction. Traditional methods such as covariance matrices and linear subspace have shown promise in image modelling, and they are still in their early stages and suffer from certain limitations. However, these include the uncertainty of representing data using only one Riemannian manifold, limited feature extraction capacity of single kernel functions, and resulting incomplete data representation and redundancy. To overcome these limitations, the authors propose a novel approach called join multiple Riemannian manifold representation and multi-kernel non-redundancy for image clustering (MRMNR-MKC). It combines covariance matrices with linear subspace to represent data and applies multiple kernel functions to map the non-linear structural data into a reproducing kernel Hilbert space, enabling linear model analysis for image clustering. Additionally, the authors use matrix-induced regularisation to improve the clustering kernel selection process by reducing redundancy and assigning lower weights to identical kernels. Finally, the authors also conducted numerous experiments to evaluate the performance of our approach, confirming its superiority to state-of-the-art methods on three benchmark datasets.},
  archive      = {J_CAAITIT},
  author       = {Mengyuan Zhang and Jinglei Liu},
  doi          = {10.1049/cit2.12347},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1305-1319},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Join multiple riemannian manifold representation and multi-kernel non-redundancy for image clustering},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Residual multimodal transformer for expression-EEG fusion
continuous emotion recognition. <em>CAAITIT</em>, <em>9</em>(5),
1290–1304. (<a href="https://doi.org/10.1049/cit2.12346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous emotion recognition is to predict emotion states through affective information and more focus on the continuous variation of emotion. Fusion of electroencephalography (EEG) and facial expressions videos has been used in this field, while there are with some limitations in current researches, such as hand-engineered features, simple approaches to integration. Hence, a new continuous emotion recognition model is proposed based on the fusion of EEG and facial expressions videos named residual multimodal Transformer (RMMT). Firstly, the Resnet50 and temporal convolutional network (TCN) are utilised to extract spatiotemporal features from videos, and the TCN is also applied to process the computed EEG frequency power to acquire spatiotemporal features of EEG. Then, a multimodal Transformer is used to fuse the spatiotemporal features from the two modalities. Furthermore, a residual connection is introduced to fuse shallow features with deep features which is verified to be effective for continuous emotion recognition through experiments. Inspired by knowledge distillation, the authors incorporate feature-level loss into the loss function to further enhance the network performance. Experimental results show that the RMMT reaches a superior performance over other methods for the MAHNOB-HCI dataset. Ablation studies on the residual connection and loss function in the RMMT demonstrate that both of them is functional.},
  archive      = {J_CAAITIT},
  author       = {Xiaofang Jin and Jieyu Xiao and Libiao Jin and Xinruo Zhang},
  doi          = {10.1049/cit2.12346},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1290-1304},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Residual multimodal transformer for expression-EEG fusion continuous emotion recognition},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving diversity of speech-driven gesture generation with
memory networks as dynamic dictionaries. <em>CAAITIT</em>,
<em>9</em>(5), 1275–1289. (<a
href="https://doi.org/10.1049/cit2.12321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating co-speech gestures for interactive digital humans remains challenging because of the indeterministic nature of the problem. The authors observe that gestures generated from speech audio or text by existing neural methods often contain less movement shift than expected, which can be viewed as slow or dull. Thus, a new generative model coupled with memory networks as dynamic dictionaries for speech-driven gesture generation with improved diversity is proposed. More specifically, the dictionary network dynamically stores connections between text and pose features in a list of key-value pairs as the memory for the pose generation network to look up; the pose generation network then merges the matching pose features and input audio features for generating the final pose sequences. To make the improvements more accurately measurable, a new objective evaluation metric for gesture diversity that can remove the influence of low-quality motions is also proposed and tested. Quantitative and qualitative experiments demonstrate that the proposed architecture succeeds in generating gestures with improved diversity.},
  archive      = {J_CAAITIT},
  author       = {Zeyu Zhao and Nan Gao and Zhi Zeng and Guixuan Zhang and Jie Liu and Shuwu Zhang},
  doi          = {10.1049/cit2.12321},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1275-1289},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Improving diversity of speech-driven gesture generation with memory networks as dynamic dictionaries},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MH-HMR: Human mesh recovery from monocular images via
multi-hypothesis learning. <em>CAAITIT</em>, <em>9</em>(5), 1263–1274.
(<a href="https://doi.org/10.1049/cit2.12337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recovering 3D human meshes from monocular images is an inherently ill-posed and challenging task due to depth ambiguity, joint occlusion, and truncation. However, most existing approaches do not model such uncertainties, typically yielding a single reconstruction for one input. In contrast, the ambiguity of the reconstruction is embraced and the problem is considered as an inverse problem for which multiple feasible solutions exist. To address these issues, the authors propose a multi-hypothesis approach, multi-hypothesis human mesh recovery (MH-HMR), to efficiently model the multi-hypothesis representation and build strong relationships among the hypothetical features. Specifically, the task is decomposed into three stages: (1) generating a reasonable set of initial recovery results (i.e., multiple hypotheses) given a single colour image; (2) modelling intra-hypothesis refinement to enhance every single-hypothesis feature; and (3) establishing inter-hypothesis communication and regressing the final human meshes. Meanwhile, the authors take further advantage of multiple hypotheses and the recovery process to achieve human mesh recovery from multiple uncalibrated views. Compared with state-of-the-art methods, the MH-HMR approach achieves superior performance and recovers more accurate human meshes on challenging benchmark datasets, such as Human3.6M and 3DPW, while demonstrating the effectiveness across a variety of settings. The code will be publicly available at https://cic.tju.edu.cn/faculty/likun/projects/MH-HMR .},
  archive      = {J_CAAITIT},
  author       = {Haibiao Xuan and Jinsong Zhang and Yu-Kun Lai and Kun Li},
  doi          = {10.1049/cit2.12337},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1263-1274},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {MH-HMR: Human mesh recovery from monocular images via multi-hypothesis learning},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Support vector machine with discriminative low-rank
embedding. <em>CAAITIT</em>, <em>9</em>(5), 1249–1262. (<a
href="https://doi.org/10.1049/cit2.12329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machine (SVM) is a binary classifier widely used in machine learning. However, neglecting the latent data structure in previous SVM can limit the performance of SVM and its extensions. To address this issue, the authors propose a novel SVM with discriminative low-rank embedding (LRSVM) that finds a discriminative latent low-rank subspace more suitable for SVM classification. The extension models of LRSVM are introduced by imposing different orthogonality constraints to prevent computational inaccuracies. A detailed derivation of the authors’ iterative algorithms are given that is essentially for solving the SVM on the low-rank subspace. Additionally, some theorems and properties of the proposed models are presented by the authors. It is worth mentioning that the subproblems of the proposed algorithms are equivalent to the standard or the weighted linear discriminant analysis (LDA) problems. This indicates that the projection subspaces obtained by the authors’ algorithms are more suitable for SVM classification compared to those from the LDA method. The convergence analysis for the authors proposed algorithms are also provided. Furthermore, the authors conduct experiments on various machine learning data sets to evaluate the algorithms. The experiment results show that the authors’ algorithms perform significantly better than other algorithms, which indicates their superior abilities on classification tasks.},
  archive      = {J_CAAITIT},
  author       = {Guangfei Liang and Zhihui Lai and Heng Kong},
  doi          = {10.1049/cit2.12329},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1249-1262},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Support vector machine with discriminative low-rank embedding},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective interval type-2 fuzzy linear programming
problem with vagueness in coefficient. <em>CAAITIT</em>, <em>9</em>(5),
1229–1248. (<a href="https://doi.org/10.1049/cit2.12336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most widely used fuzzy linear programming models is the multi-objective interval type-2 fuzzy linear programming (IT2FLP) model, which is of particular importance due to the simultaneous integration of multiple criteria and objectives in a single problem, the fuzzy nature of this type of problems, and thus, its closer similarity to real-world problems. So far, many studies have been done for the IT2FLP problem with uncertainties of the vagueness type. However, not enough studies have been done regarding the multi-objective interval type-2 fuzzy linear programming (MOIT2FLP) problem with uncertainties of the vagueness type. As an innovation, this study investigates the MOIT2FLP problem with vagueness-type uncertainties, which are represented by membership functions (MFs) in the problem. Depending on the localisation of vagueness in the problem, that is, vagueness in the objective function vector, vagueness in the technological coefficients, vagueness in the resources vector, and any possible combination of them, various problems may arise. Furthermore, to solve problems with MOIT2FLP, first, using the weighted sum method as an efficient and effective method, each of the MOIT2FLP problems is converted into a single-objective problem. In this research, these types of problems are introduced, their MFs are stated, and different solution methods are suggested. For each of the proposed methods, the authors have provided an example and presented the results in the corresponding tables.},
  archive      = {J_CAAITIT},
  author       = {Shokouh Sargolzaei and Hassan Mishmast Nehi},
  doi          = {10.1049/cit2.12336},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1229-1248},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Multi-objective interval type-2 fuzzy linear programming problem with vagueness in coefficient},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Medical knowledge graph question answering for drug-drug
interaction prediction based on multi-hop machine reading comprehension.
<em>CAAITIT</em>, <em>9</em>(5), 1217–1228. (<a
href="https://doi.org/10.1049/cit2.12332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug-drug interaction (DDI) prediction is a crucial issue in molecular biology. Traditional methods of observing drug-drug interactions through medical experiments require significant resources and labour. The authors present a Medical Knowledge Graph Question Answering ( MedKGQA ) model, dubbed MedKGQA , that predicts DDI by employing machine reading comprehension (MRC) from closed-domain literature and constructing a knowledge graph of “drug-protein” triplets from open-domain documents. The model vectorises the drug-protein target attributes in the graph using entity embeddings and establishes directed connections between drug and protein entities based on the metabolic interaction pathways of protein targets in the human body. This aligns multiple external knowledge and applies it to learn the graph neural network. Without bells and whistles, the proposed model achieved a 4.5% improvement in terms of DDI prediction accuracy compared to previous state-of-the-art models on the QA ngaroo M ed H op dataset. Experimental results demonstrate the efficiency and effectiveness of the model and verify the feasibility of integrating external knowledge in MRC tasks.},
  archive      = {J_CAAITIT},
  author       = {Peng Gao and Feng Gao and Jian-Cheng Ni and Yu Wang and Fei Wang and Qiquan Zhang},
  doi          = {10.1049/cit2.12332},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1217-1228},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Medical knowledge graph question answering for drug-drug interaction prediction based on multi-hop machine reading comprehension},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 3D shape knowledge graph for cross-domain 3D shape
retrieval. <em>CAAITIT</em>, <em>9</em>(5), 1199–1216. (<a
href="https://doi.org/10.1049/cit2.12326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The surge in 3D modelling has led to a pronounced research emphasis on the field of 3D shape retrieval. Numerous contemporary approaches have been put forth to tackle this intricate challenge. Nevertheless, effectively addressing the intricacies of cross-modal 3D shape retrieval remains a formidable undertaking, owing to inherent modality-based disparities. The authors present an innovative notion—termed “geometric words”—which functions as elemental constituents for representing entities through combinations. To establish the knowledge graph, the authors employ geometric words as nodes, connecting them via shape categories and geometry attributes. Subsequently, a unique graph embedding method for knowledge acquisition is devised. Finally, an effective similarity measure is introduced for retrieval purposes. Importantly, each 3D or 2D entity can anchor its geometric terms within the knowledge graph, thereby serving as a link between cross-domain data. As a result, the authors’ approach facilitates multiple cross-domain 3D shape retrieval tasks. The authors evaluate the proposed method&#39;s performance on the ModelNet40 and ShapeNetCore55 datasets, encompassing scenarios related to 3D shape retrieval and cross-domain retrieval. Furthermore, the authors employ the established cross-modal dataset (MI3DOR) to assess cross-modal 3D shape retrieval. The resulting experimental outcomes, in conjunction with comparisons against state-of-the-art techniques, clearly highlight the superiority of our approach.},
  archive      = {J_CAAITIT},
  author       = {Rihao Chang and Yongtao Ma and Tong Hao and Weijie Wang and Weizhi Nie},
  doi          = {10.1049/cit2.12326},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1199-1216},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {3D shape knowledge graph for cross-domain 3D shape retrieval},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction and optimisation of gasoline quality in petroleum
refining: The use of machine learning model as a surrogate in
optimisation framework. <em>CAAITIT</em>, <em>9</em>(5), 1185–1198. (<a
href="https://doi.org/10.1049/cit2.12324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hardware-based sensing frameworks such as cooperative fuel research engines are conventionally used to monitor research octane number (RON) in the petroleum refining industry. Machine learning techniques are employed to predict the RON of integrated naphtha reforming and isomerisation processes. A dynamic Aspen HYSYS model was used to generate data by introducing artificial uncertainties in the range of ±5% in process conditions, such as temperature, flow rates, etc. The generated data was used to train support vector machines (SVM), Gaussian process regression (GPR), artificial neural networks (ANN), regression trees (RT), and ensemble trees (ET). Hyperparameter tuning was performed to enhance the prediction capabilities of GPR, ANN, SVM, ET and RT models. Performance analysis of the models indicates that GPR, ANN, and SVM with R 2 values of 0.99, 0.978, and 0.979 and RMSE values of 0.108, 0.262, and 0.258, respectively performed better than the remaining models and had the prediction capability to capture the RON dependence on predictor variables. ET and RT had an R 2 value of 0.94 and 0.89, respectively. The GPR model was used as a surrogate model for fitness function evaluations in two optimisation frameworks based on genetic algorithm and particle swarm method. Optimal parameter values found by the optimisation methodology increased the RON value by 3.52%. The proposed methodology of surrogate-based optimisation will provide a platform for plant-level implementation to realise the concept of industry 4.0 in the refinery.},
  archive      = {J_CAAITIT},
  author       = {Husnain Saghir and Iftikhar Ahmad and Manabu Kano and Hakan Caliskan and Hiki Hong},
  doi          = {10.1049/cit2.12324},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1185-1198},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Prediction and optimisation of gasoline quality in petroleum refining: The use of machine learning model as a surrogate in optimisation framework},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Causal inference for out-of-distribution recognition via
sample balancing. <em>CAAITIT</em>, <em>9</em>(5), 1172–1184. (<a
href="https://doi.org/10.1049/cit2.12311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification algorithms are commonly based on the Independent and Identically Distribution (i.i.d.) assumption, but in practice, the Out-Of-Distribution (OOD) problem widely exists, that is, the contexts of images in the model predicting are usually unseen during training. In this case, existing models trained under the i.i.d. assumption are limiting generalisation. Causal inference is an important method to learn the causal associations which are invariant across different environments, thus improving the generalisation ability of the model. However, existing methods usually require partitioning of the environment to learn invariant features, which mostly have imbalance problems due to the lack of constraints. In this paper, we propose a balanced causal learning framework (BCL), starting from how to divide the dataset in a balanced way and the balance of training after the division, which automatically generates fine-grained balanced data partitions in an unsupervised manner and balances the training difficulty of different classes, thereby enhancing the generalisation ability of models in different environments. Experiments on the OOD datasets NICO and NICO++ demonstrate that BCL achieves stable predictions on OOD data, and we also find that models using BCL focus more accurately on the foreground of images compared with the existing causal inference method, which effectively improves the generalisation ability.},
  archive      = {J_CAAITIT},
  author       = {Yuqing Wang and Xiangxian Li and Yannan Liu and Xiao Cao and Xiangxu Meng and Lei Meng},
  doi          = {10.1049/cit2.12311},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1172-1184},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Causal inference for out-of-distribution recognition via sample balancing},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Elite-guided equilibrium optimiser based on information
enhancement: Algorithm and mobile edge computing applications.
<em>CAAITIT</em>, <em>9</em>(5), 1126–1171. (<a
href="https://doi.org/10.1049/cit2.12316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Equilibrium Optimiser (EO) has been demonstrated to be one of the metaheuristic algorithms that can effectively solve global optimisation problems. Balancing the paradox between exploration and exploitation operations while enhancing the ability to jump out of the local optimum are two key points to be addressed in EO research. To alleviate these limitations, an EO variant named adaptive elite-guided Equilibrium Optimiser (AEEO) is introduced. Specifically, the adaptive elite-guided search mechanism enhances the balance between exploration and exploitation. The modified mutualism phase reinforces the information interaction among particles and local optima avoidance. The cooperation of these two mechanisms boosts the overall performance of the basic EO. The AEEO is subjected to competitive experiments with state-of-the-art algorithms and modified algorithms on 23 classical benchmark functions and IEE CEC 2017 function test suite. Experimental results demonstrate that AEEO outperforms several well-performing EO variants, DE variants, PSO variants, SSA variants, and GWO variants in terms of convergence speed and accuracy. In addition, the AEEO algorithm is used for the edge server (ES) placement problem in mobile edge computing (MEC) environments. The experimental results show that the author’s approach outperforms the representative approaches compared in terms of access latency and deployment cost.},
  archive      = {J_CAAITIT},
  author       = {Zong-Shan Wang and Shi-Jin Li and Hong-Wei Ding and Gaurav Dhiman and Peng Hou and Ai-Shan Li and Peng Hu and Zhi-Jun Yang and Jie Wang},
  doi          = {10.1049/cit2.12316},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1126-1171},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Elite-guided equilibrium optimiser based on information enhancement: Algorithm and mobile edge computing applications},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lexicon-based fine-tuning of multilingual language models
for low-resource language sentiment analysis. <em>CAAITIT</em>,
<em>9</em>(5), 1116–1125. (<a
href="https://doi.org/10.1049/cit2.12333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-trained multilingual language models (PMLMs) such as mBERT and XLM-R have shown good cross-lingual transferability. However, they are not specifically trained to capture cross-lingual signals concerning sentiment words. This poses a disadvantage for low-resource languages (LRLs) that are under-represented in these models. To better fine-tune these models for sentiment classification in LRLs, a novel intermediate task fine-tuning (ITFT) technique based on a sentiment lexicon of a high-resource language (HRL) is introduced. The authors experiment with LRLs Sinhala, Tamil and Bengali for a 3-class sentiment classification task and show that this method outperforms vanilla fine-tuning of the PMLM. It also outperforms or is on-par with basic ITFT that relies on an HRL sentiment classification dataset.},
  archive      = {J_CAAITIT},
  author       = {Vinura Dhananjaya and Surangika Ranathunga and Sanath Jayasena},
  doi          = {10.1049/cit2.12333},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1116-1125},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Lexicon-based fine-tuning of multilingual language models for low-resource language sentiment analysis},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A self-learning human-machine cooperative control method
based on driver intention recognition. <em>CAAITIT</em>, <em>9</em>(5),
1101–1115. (<a href="https://doi.org/10.1049/cit2.12313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-machine cooperative control has become an important area of intelligent driving, where driver intention recognition and dynamic control authority allocation are key factors for improving the performance of cooperative decision-making and control. In this paper, an online learning method is proposed for human-machine cooperative control, which introduces a priority control parameter in the reward function to achieve optimal allocation of control authority under different driver intentions and driving safety conditions. Firstly, a two-layer LSTM-based sequence prediction algorithm is proposed to recognise the driver&#39;s lane change (LC) intention for human-machine cooperative steering control. Secondly, an online reinforcement learning method is developed for optimising the steering authority to reduce driver workload and improve driving safety. The driver-in-the-loop simulation results show that our method can accurately predict the driver&#39;s LC intention in cooperative driving and effectively compensate for the driver&#39;s non-optimal driving actions. The experimental results on a real intelligent vehicle further demonstrate the online optimisation capability of the proposed RL-based control authority allocation algorithm and its effectiveness in improving driving safety.},
  archive      = {J_CAAITIT},
  author       = {Yan Jiang and Yuyan Ding and Xinglong Zhang and Xin Xu and Junwen Huang},
  doi          = {10.1049/cit2.12313},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1101-1115},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A self-learning human-machine cooperative control method based on driver intention recognition},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fault-tolerant and scalable boosting method over
vertically partitioned data. <em>CAAITIT</em>, <em>9</em>(5), 1092–1100.
(<a href="https://doi.org/10.1049/cit2.12339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vertical federated learning (VFL) can learn a common machine learning model over vertically partitioned datasets. However, VFL are faced with these thorny problems: (1) both the training and prediction are very vulnerable to stragglers; (2) most VFL methods can only support a specific machine learning model. Suppose that VFL incorporates the features of centralised learning, then the above issues can be alleviated. With that in mind, this paper proposes a new VFL scheme, called FedBoost, which makes private parties upload the compressed partial order relations to the honest but curious server before training and prediction. The server can build a machine learning model and predict samples on the union of coded data. The theoretical analysis indicates that the absence of any private party will not affect the training and prediction as long as a round of communication is achieved. Our scheme can support canonical tree-based models such as Tree Boosting methods and Random Forests. The experimental results also demonstrate the availability of our scheme.},
  archive      = {J_CAAITIT},
  author       = {Hai Jiang and Songtao Shang and Peng Liu and Tong Yi},
  doi          = {10.1049/cit2.12339},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1092-1100},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A fault-tolerant and scalable boosting method over vertically partitioned data},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Edge-guided representation learning for underwater object
detection. <em>CAAITIT</em>, <em>9</em>(5), 1078–1091. (<a
href="https://doi.org/10.1049/cit2.12325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater object detection (UOD) is crucial for marine economic development, environmental protection, and the planet&#39;s sustainable development. The main challenges of this task arise from low-contrast, small objects, and mimicry of aquatic organisms. The key to addressing these challenges is to focus the model on obtaining more discriminative information. The authors observe that the edges of underwater objects are highly unique and can be distinguished from low-contrast or mimicry environments based on their edges. Motivated by this observation, an Edge-guided Representation Learning Network, termed ERL-Net is proposed, that aims to achieve discriminative representation learning and aggregation under the guidance of edge cues. Firstly, an edge-guided attention module is introduced to model the explicit boundary information, which generates more discriminative features. Secondly, a hierarchical feature aggregation module is proposed to aggregate the multi-scale discriminative features by regrouping them into three levels, effectively aggregating global and local information for locating and recognising underwater objects. Finally, a wide and asymmetric receptive field block is proposed to enable features to have a wider receptive field, allowing the model to focus on smaller object information. Comprehensive experiments on three challenging underwater datasets show that our method achieves superior performance on the UOD task.},
  archive      = {J_CAAITIT},
  author       = {Linhui Dai and Hong Liu and Pinhao Song and Hao Tang and Runwei Ding and Shengquan Li},
  doi          = {10.1049/cit2.12325},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1078-1091},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Edge-guided representation learning for underwater object detection},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning in crowd counting: A survey. <em>CAAITIT</em>,
<em>9</em>(5), 1043–1077. (<a
href="https://doi.org/10.1049/cit2.12241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counting high-density objects quickly and accurately is a popular area of research. Crowd counting has significant social and economic value and is a major focus in artificial intelligence. Despite many advancements in this field, many of them are not widely known, especially in terms of research data. The authors proposed a three-tier standardised dataset taxonomy (TSDT). The Taxonomy divides datasets into small-scale, large-scale and hyper-scale, according to different application scenarios. This theory can help researchers make more efficient use of datasets and improve the performance of AI algorithms in specific fields. Additionally, the authors proposed a new evaluation index for the clarity of the dataset: average pixel occupied by each object (APO). This new evaluation index is more suitable for evaluating the clarity of the dataset in the object counting task than the image resolution. Moreover, the authors classified the crowd counting methods from a data-driven perspective: multi-scale networks, single-column networks, multi-column networks, multi-task networks, attention networks and weak-supervised networks and introduced the classic crowd counting methods of each class. The authors classified the existing 36 datasets according to the theory of three-tier standardised dataset taxonomy and discussed and evaluated these datasets. The authors evaluated the performance of more than 100 methods in the past five years on different levels of popular datasets. Recently, progress in research on small-scale datasets has slowed down. There are few new datasets and algorithms on small-scale datasets. The studies focused on large or hyper-scale datasets appear to be reaching a saturation point. The combined use of multiple approaches began to be a major research direction. The authors discussed the theoretical and practical challenges of crowd counting from the perspective of data, algorithms and computing resources. The field of crowd counting is moving towards combining multiple methods and requires fresh, targeted datasets. Despite advancements, the field still faces challenges such as handling real-world scenarios and processing large crowds in real-time. Researchers are exploring transfer learning to overcome the limitations of small datasets. The development of effective algorithms for crowd counting remains a challenging and important task in computer vision and AI, with many opportunities for future research.},
  archive      = {J_CAAITIT},
  author       = {Lijia Deng and Qinghua Zhou and Shuihua Wang and Juan Manuel Górriz and Yudong Zhang},
  doi          = {10.1049/cit2.12241},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1043-1077},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Deep learning in crowd counting: A survey},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UKF-MOT: An unscented kalman filter-based 3D multi-object
tracker. <em>CAAITIT</em>, <em>9</em>(4), 1031–1041. (<a
href="https://doi.org/10.1049/cit2.12315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-object tracking in autonomous driving is a non-linear problem. To better address the tracking problem, this paper leveraged an unscented Kalman filter to predict the object&#39;s state. In the association stage, the Mahalanobis distance was employed as an affinity metric, and a Non-minimum Suppression method was designed for matching. With the detections fed into the tracker and continuous ‘predicting-matching’ steps, the states of each object at different time steps were described as their own continuous trajectories. We conducted extensive experiments to evaluate tracking accuracy on three challenging datasets (KITTI, nuScenes and Waymo). The experimental results demonstrated that our method effectively achieved multi-object tracking with satisfactory accuracy and real-time efficiency.},
  archive      = {J_CAAITIT},
  author       = {Meng Liu and Jianwei Niu and Yu Liu},
  doi          = {10.1049/cit2.12315},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1031-1041},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {UKF-MOT: An unscented kalman filter-based 3D multi-object tracker},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mutual information oriented deep skill chaining for
multi-agent reinforcement learning. <em>CAAITIT</em>, <em>9</em>(4),
1014–1030. (<a href="https://doi.org/10.1049/cit2.12322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent reinforcement learning relies on reward signals to guide the policy networks of individual agents. However, in high-dimensional continuous spaces, the non-stationary environment can provide outdated experiences that hinder convergence, resulting in ineffective training performance for multi-agent systems. To tackle this issue, a novel reinforcement learning scheme, Mutual Information Oriented Deep Skill Chaining (MioDSC), is proposed that generates an optimised cooperative policy by incorporating intrinsic rewards based on mutual information to improve exploration efficiency. These rewards encourage agents to diversify their learning process by engaging in actions that increase the mutual information between their actions and the environment state. In addition, MioDSC can generate cooperative policies using the options framework, allowing agents to learn and reuse complex action sequences and accelerating the convergence speed of multi-agent learning. MioDSC was evaluated in the multi-agent particle environment and the StarCraft multi-agent challenge at varying difficulty levels. The experimental results demonstrate that MioDSC outperforms state-of-the-art methods and is robust across various multi-agent system tasks with high stability.},
  archive      = {J_CAAITIT},
  author       = {Zaipeng Xie and Cheng Ji and Chentai Qiao and WenZhan Song and Zewen Li and Yufeng Zhang and Yujing Zhang},
  doi          = {10.1049/cit2.12322},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1014-1030},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Mutual information oriented deep skill chaining for multi-agent reinforcement learning},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Noise-tolerant matched filter scheme supplemented with
neural dynamics algorithm for sea island extraction. <em>CAAITIT</em>,
<em>9</em>(4), 996–1013. (<a
href="https://doi.org/10.1049/cit2.12323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving high-precision extraction of sea islands from high-resolution satellite remote sensing images is crucial for effective resource development and sustainable management. Unfortunately, achieving such accuracy for sea island extraction presents significant challenges due to the presence of extensive background interference. A more widely applicable noise-tolerant matched filter (NTMF) scheme is proposed for sea island extraction based on the MF scheme. The NTMF scheme effectively suppresses the background interference, leading to more accurate and robust sea island extraction. To further enhance the accuracy and robustness of the NTMF scheme, a neural dynamics algorithm is supplemented that adds an error integration feedback term to counter noise interference during internal computer operations in practical applications. Several comparative experiments were conducted on various remote sensing images of sea islands under different noisy working conditions to demonstrate the superiority of the proposed neural dynamics algorithm-assisted NTMF scheme. These experiments confirm the advantages of using the NTMF scheme for sea island extraction with the assistance of neural dynamics algorithm.},
  archive      = {J_CAAITIT},
  author       = {Yiyu Chen and Dongyang Fu and Difeng Wang and Haoen Huang and Yang Si and Shangfeng Du},
  doi          = {10.1049/cit2.12323},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {996-1013},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Noise-tolerant matched filter scheme supplemented with neural dynamics algorithm for sea island extraction},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tjong: A transformer-based mahjong AI via hierarchical
decision-making and fan backward. <em>CAAITIT</em>, <em>9</em>(4),
982–995. (<a href="https://doi.org/10.1049/cit2.12298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mahjong, a complex game with hidden information and sparse rewards, poses significant challenges. Existing Mahjong AIs require substantial hardware resources and extensive datasets to enhance AI capabilities. The authors propose a transformer-based Mahjong AI (Tjong) via hierarchical decision-making. By utilising self-attention mechanisms, Tjong effectively captures tile patterns and game dynamics, and it decouples the decision process into two distinct stages: action decision and tile decision. This design reduces decision complexity considerably. Additionally, a fan backward technique is proposed to address the sparse rewards by allocating reversed rewards for actions based on winning hands. Tjong consists of 15M parameters and is trained using approximately 0.5 M data over 7 days of supervised learning on a single server with 2 GPUs. The action decision achieved an accuracy of 94.63%, while the claim decision attained 98.55% and the discard decision reached 81.51%. In a tournament format, Tjong outperformed AIs (CNN, MLP, RNN, ResNet, VIT), achieving scores up to 230% higher than its opponents. Furthermore, after 3 days of reinforcement learning training, it ranked within the top 1% on the leaderboard on the Botzone platform.},
  archive      = {J_CAAITIT},
  author       = {Xiali Li and Bo Liu and Zhi Wei and Zhaoqi Wang and Licheng Wu},
  doi          = {10.1049/cit2.12298},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {982-995},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Tjong: A transformer-based mahjong AI via hierarchical decision-making and fan backward},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Implicit policy constraint for offline reinforcement
learning. <em>CAAITIT</em>, <em>9</em>(4), 973–981. (<a
href="https://doi.org/10.1049/cit2.12304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning (RL) aims to learn policies entirely from passively collected datasets, making it a data-driven decision method. One of the main challenges in offline RL is the distribution shift problem, which causes the algorithm to visit out-of-distribution (OOD) samples. The distribution shift can be mitigated by constraining the divergence between the target policy and the behaviour policy. However, this method can overly constrain the target policy and impair the algorithm&#39;s performance, as it does not directly distinguish between in-distribution and OOD samples. In addition, it is difficult to learn and represent multi-modal behaviour policy when the datasets are collected by several different behaviour policies. To overcome these drawbacks, the authors address the distribution shift problem by implicit policy constraints with energy-based models (EBMs) rather than explicitly modelling the behaviour policy. The EBM is powerful for representing complex multi-modal distributions as well as the ability to distinguish in-distribution samples and OODs. Experimental results show that their method significantly outperforms the explicit policy constraint method and other baselines. In addition, the learnt energy model can be used to indicate OOD visits and alert the possible failure.},
  archive      = {J_CAAITIT},
  author       = {Zhiyong Peng and Yadong Liu and Changlin Han and Zongtan Zhou},
  doi          = {10.1049/cit2.12304},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {973-981},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Implicit policy constraint for offline reinforcement learning},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GP-FMLNet: A feature matrix learning network enhanced by
glyph and phonetic information for chinese sentiment analysis.
<em>CAAITIT</em>, <em>9</em>(4), 960–972. (<a
href="https://doi.org/10.1049/cit2.12300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is a fine-grained analysis task that aims to identify the sentiment polarity of a specified sentence. Existing methods in Chinese sentiment analysis tasks only consider sentiment features from a single pole and scale and thus cannot fully exploit and utilise sentiment feature information, making their performance less than ideal. To resolve the problem, the authors propose a new method, GP-FMLNet, that integrates both glyph and phonetic information and design a novel feature matrix learning process for phonetic features with which to model words that have the same pinyin information but different glyph information. Our method solves the problem of misspelling words influencing sentiment polarity prediction results. Specifically, the authors iteratively mine character, glyph, and pinyin features from the input comments sentences. Then, the authors use soft attention and matrix compound modules to model the phonetic features, which empowers their model to keep on zeroing in on the dynamic-setting words in various positions and to dispense with the impacts of the deceptive-setting ones. Experiments on six public datasets prove that the proposed model fully utilises the glyph and phonetic information and improves on the performance of existing Chinese sentiment analysis algorithms.},
  archive      = {J_CAAITIT},
  author       = {Jing Li and Dezheng Zhang and Yonghong Xie and Aziguli Wulamu and Yao Zhang},
  doi          = {10.1049/cit2.12300},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {960-972},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {GP-FMLNet: A feature matrix learning network enhanced by glyph and phonetic information for chinese sentiment analysis},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DPT-tracker: Dual pooling transformer for efficient visual
tracking. <em>CAAITIT</em>, <em>9</em>(4), 948–959. (<a
href="https://doi.org/10.1049/cit2.12296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer tracking always takes paired template and search images as encoder input and conduct feature extraction and target-search feature correlation by self and/or cross attention operations, thus the model complexity will grow quadratically with the number of input images. To alleviate the burden of this tracking paradigm and facilitate practical deployment of Transformer-based trackers, we propose a dual pooling transformer tracking framework, dubbed as DPT, which consists of three components: a simple yet efficient spatiotemporal attention model (SAM), a mutual correlation pooling Transformer (MCPT) and a multiscale aggregation pooling Transformer (MAPT). SAM is designed to gracefully aggregates temporal dynamics and spatial appearance information of multi-frame templates along space-time dimensions. MCPT aims to capture multi-scale pooled and correlated contextual features, which is followed by MAPT that aggregates multi-scale features into a unified feature representation for tracking prediction. DPT tracker achieves AUC score of 69.5 on LaSOT and precision score of 82.8 on TrackingNet while maintaining a shorter sequence length of attention tokens, fewer parameters and FLOPs compared to existing state-of-the-art (SOTA) Transformer tracking methods. Extensive experiments demonstrate that DPT tracker yields a strong real-time tracking baseline with a good trade-off between tracking performance and inference efficiency.},
  archive      = {J_CAAITIT},
  author       = {Yang Fang and Bailian Xie and Uswah Khairuddin and Zijian Min and Bingbing Jiang and Weisheng Li},
  doi          = {10.1049/cit2.12296},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {948-959},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {DPT-tracker: Dual pooling transformer for efficient visual tracking},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vision based intelligent traffic light management system
using faster r-CNN. <em>CAAITIT</em>, <em>9</em>(4), 932–947. (<a
href="https://doi.org/10.1049/cit2.12309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transportation systems primarily depend on vehicular flow on roads. Developed countries have shifted towards automated signal control, which manages and updates signal synchronisation automatically. In contrast, traffic in underdeveloped countries is mainly governed by manual traffic light systems. These existing manual systems lead to numerous issues, wasting substantial resources such as time, energy, and fuel, as they cannot make real-time decisions. In this work, we propose an algorithm to determine traffic signal durations based on real-time vehicle density, obtained from live closed circuit television camera feeds adjacent to traffic signals. The algorithm automates the traffic light system, making decisions based on vehicle density and employing Faster R-CNN for vehicle detection. Additionally, we have created a local dataset from live streams of Punjab Safe City cameras in collaboration with the local police authority. The proposed algorithm achieves a class accuracy of 96.6% and a vehicle detection accuracy of 95.7%. Across both day and night modes, our proposed method maintains an average precision, recall, F 1 score, and vehicle detection accuracy of 0.94, 0.98, 0.96 and 0.95, respectively. Our proposed work surpasses all evaluation metrics compared to state-of-the-art methodologies.},
  archive      = {J_CAAITIT},
  author       = {Syed Konain Abbas and Muhammad Usman Ghani Khan and Jia Zhu and Raheem Sarwar and Naif R. Aljohani and Ibrahim A. Hameed and Muhammad Umair Hassan},
  doi          = {10.1049/cit2.12309},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {932-947},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Vision based intelligent traffic light management system using faster R-CNN},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conditional selection with CNN augmented transformer for
multimodal affective analysis. <em>CAAITIT</em>, <em>9</em>(4), 917–931.
(<a href="https://doi.org/10.1049/cit2.12320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention mechanism has been a successful method for multimodal affective analysis in recent years. Despite the advances, several significant challenges remain in fusing language and its nonverbal context information. One is to generate sparse attention coefficients associated with acoustic and visual modalities, which helps locate critical emotional semantics. The other is fusing complementary cross-modal representation to construct optimal salient feature combinations of multiple modalities. A Conditional Transformer Fusion Network is proposed to handle these problems. Firstly, the authors equip the transformer module with CNN layers to enhance the detection of subtle signal patterns in nonverbal sequences. Secondly, sentiment words are utilised as context conditions to guide the computation of cross-modal attention. As a result, the located nonverbal features are not only salient but also complementary to sentiment words directly. Experimental results show that the authors’ method achieves state-of-the-art performance on several multimodal affective analysis datasets.},
  archive      = {J_CAAITIT},
  author       = {Jianwen Wang and Shiping Wang and Shunxin Xiao and Renjie Lin and Mianxiong Dong and Wenzhong Guo},
  doi          = {10.1049/cit2.12320},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {917-931},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Conditional selection with CNN augmented transformer for multimodal affective analysis},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transfer force perception skills to robot-assisted
laminectomy via imitation learning from human demonstrations.
<em>CAAITIT</em>, <em>9</em>(4), 903–916. (<a
href="https://doi.org/10.1049/cit2.12331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A comparative study of two force perception skill learning approaches for robot-assisted spinal surgery, the impedance model method and the imitation learning (IL) method, is presented. The impedance model method develops separate models for the surgeon and patient, incorporating spring-damper and bone-grinding models. Expert surgeons&#39; feature parameters are collected and mapped using support vector regression and image navigation techniques. The imitation learning approach utilises long short-term memory networks (LSTM) and addresses accurate data labelling challenges with custom models. Experimental results demonstrate skill recognition rates of 63.61%–74.62% for the impedance model approach, relying on manual feature extraction. Conversely, the imitation learning approach achieves a force perception recognition rate of 91.06%, outperforming the impedance model on curved bone surfaces. The findings demonstrate the potential of imitation learning to enhance skill acquisition in robot-assisted spinal surgery by eliminating the laborious process of manual feature extraction.},
  archive      = {J_CAAITIT},
  author       = {Meng Li and Xiaozhi Qi and Xiaoguang Han and Ying Hu and Bing Li and Yu Zhao and Jianwei Zhang},
  doi          = {10.1049/cit2.12331},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {903-916},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Transfer force perception skills to robot-assisted laminectomy via imitation learning from human demonstrations},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Safety control strategy of spinal lamina cutting based on
force and cutting depth signals. <em>CAAITIT</em>, <em>9</em>(4),
894–902. (<a href="https://doi.org/10.1049/cit2.12341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laminectomy is one of the most common posterior spinal operations. Since the lamina is adjacent to important tissues such as nerves, once damaged, it can cause serious complications and even lead to paralysis. In order to prevent the above injuries and complications, ultrasonic bone scalpel and surgical robots have been introduced into spinal laminectomy, and many scholars have studied the recognition method of the bone tissue status. Currently, almost all methods to achieve recognition of bone tissue are based on sensor signals collected by high-precision sensors installed at the end of surgical robots. However, the previous methods could not accurately identify the state of spinal bone tissue. Innovatively, the identification of bone tissue status was regarded as a time series classification task, and the classification algorithm LSTM-FCN was used to process fusion signals composed of force and cutting depth signals, thus achieving an accurate classification of the lamina bone tissue status. In addition, it was verified that the accuracy of the proposed method could reach 98.85% in identifying the state of porcine spinal laminectomy. And the maximum penetration distance can be controlled within 0.6 mm, which is safe and can be used in practice.},
  archive      = {J_CAAITIT},
  author       = {Jian Zhang and Yonghong Zhang and Shanshan Liu and Xuquan Ji and Sizhuo Liu and Zhuofu Li and Baoduo Geng and Weishi Li and Tianmiao Wang},
  doi          = {10.1049/cit2.12341},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {894-902},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Safety control strategy of spinal lamina cutting based on force and cutting depth signals},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DeepGCN based on variable multi-graph and multimodal data
for ASD diagnosis. <em>CAAITIT</em>, <em>9</em>(4), 879–893. (<a
href="https://doi.org/10.1049/cit2.12340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnosing individuals with autism spectrum disorder (ASD) accurately faces great challenges in clinical practice, primarily due to the data&#39;s high heterogeneity and limited sample size. To tackle this issue, the authors constructed a deep graph convolutional network (GCN) based on variable multi-graph and multimodal data (VMM-DGCN) for ASD diagnosis. Firstly, the functional connectivity matrix was constructed to extract primary features. Then, the authors constructed a variable multi-graph construction strategy to capture the multi-scale feature representations of each subject by utilising convolutional filters with varying kernel sizes. Furthermore, the authors brought the non-imaging information into the feature representation at each scale and constructed multiple population graphs based on multimodal data by fully considering the correlation between subjects. After extracting the deeper features of population graphs using the deep GCN(DeepGCN), the authors fused the node features of multiple subgraphs to perform node classification tasks for typical control and ASD patients. The proposed algorithm was evaluated on the Autism Brain Imaging Data Exchange I (ABIDE I) dataset, achieving an accuracy of 91.62% and an area under the curve value of 95.74%. These results demonstrated its outstanding performance compared to other ASD diagnostic algorithms.},
  archive      = {J_CAAITIT},
  author       = {Shuaiqi Liu and Siqi Wang and Chaolei Sun and Bing Li and Shuihua Wang and Fei Li},
  doi          = {10.1049/cit2.12340},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {879-893},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {DeepGCN based on variable multi-graph and multimodal data for ASD diagnosis},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GAN-MD: A myocarditis detection using multi-channel
convolutional neural networks and generative adversarial network-based
data augmentation. <em>CAAITIT</em>, <em>9</em>(4), 866–878. (<a
href="https://doi.org/10.1049/cit2.12307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Myocarditis is a significant public health concern because of its potential to cause heart failure and sudden death. The standard invasive diagnostic method, endomyocardial biopsy, is typically reserved for cases with severe complications, limiting its widespread use. Conversely, non-invasive cardiac magnetic resonance (CMR) imaging presents a promising alternative for detecting and monitoring myocarditis, because of its high signal contrast that reveals myocardial involvement. To assist medical professionals via artificial intelligence, the authors introduce generative adversarial networks - multi discriminator (GAN-MD), a deep learning model that uses binary classification to diagnose myocarditis from CMR images. Their approach employs a series of convolutional neural networks (CNNs) that extract and combine feature vectors for accurate diagnosis. The authors suggest a novel technique for improving the classification precision of CNNs. Using generative adversarial networks (GANs) to create synthetic images for data augmentation, the authors address challenges such as mode collapse and unstable training. Incorporating a reconstruction loss into the GAN loss function requires the generator to produce images reflecting the discriminator features, thus enhancing the generated images&#39; quality to more accurately replicate authentic data patterns. Moreover, combining this loss function with other regularisation methods, such as gradient penalty, has proven to further improve the performance of diverse GAN models. A significant challenge in myocarditis diagnosis is the imbalance of classification, where one class dominates over the other. To mitigate this, the authors introduce a focal loss-based training method that effectively trains the model on the minority class samples. The GAN-MD approach, evaluated on the Z-Alizadeh Sani myocarditis dataset, achieves superior results (F-measure 86.2%; geometric mean 91.0%) compared with other deep learning models and traditional machine learning methods.},
  archive      = {J_CAAITIT},
  author       = {Hengame Ahmadi Golilarz and Alireza Azadbar and Roohallah Alizadehsani and Juan Manuel Gorriz},
  doi          = {10.1049/cit2.12307},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {866-878},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {GAN-MD: A myocarditis detection using multi-channel convolutional neural networks and generative adversarial network-based data augmentation},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved organs at risk segmentation based on modified u-net
with self-attention and consistency regularisation. <em>CAAITIT</em>,
<em>9</em>(4), 850–865. (<a
href="https://doi.org/10.1049/cit2.12303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is one of the leading causes of death in the world, with radiotherapy as one of the treatment options. Radiotherapy planning starts with delineating the affected area from healthy organs, called organs at risk (OAR). A new approach to automatic OAR segmentation in the chest cavity in Computed Tomography (CT) images is presented. The proposed approach is based on the modified U-Net architecture with the ResNet-34 encoder, which is the baseline adopted in this work. The new two-branch CS-SA U-Net architecture is proposed, which consists of two parallel U-Net models in which self-attention blocks with cosine similarity as query-key similarity function (CS-SA) blocks are inserted between the encoder and decoder, which enabled the use of consistency regularisation. The proposed solution demonstrates state-of-the-art performance for the problem of OAR segmentation in CT images on the publicly available SegTHOR benchmark dataset in terms of a Dice coefficient (oesophagus—0.8714, heart—0.9516, trachea—0.9286, aorta—0.9510) and Hausdorff distance (oesophagus—0.2541, heart—0.1514, trachea—0.1722, aorta—0.1114) and significantly outperforms the baseline. The current approach is demonstrated to be viable for improving the quality of OAR segmentation for radiotherapy planning.},
  archive      = {J_CAAITIT},
  author       = {Maksym Manko and Anton Popov and Juan Manuel Gorriz and Javier Ramirez},
  doi          = {10.1049/cit2.12303},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {850-865},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Improved organs at risk segmentation based on modified U-net with self-attention and consistency regularisation},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Image super-resolution via dynamic network.
<em>CAAITIT</em>, <em>9</em>(4), 837–849. (<a
href="https://doi.org/10.1049/cit2.12297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks depend on deep network architectures to extract accurate information for image super-resolution. However, obtained information of these convolutional neural networks cannot completely express predicted high-quality images for complex scenes. A dynamic network for image super-resolution (DSRNet) is presented, which contains a residual enhancement block, wide enhancement block, feature refinement block and construction block. The residual enhancement block is composed of a residual enhanced architecture to facilitate hierarchical features for image super-resolution. To enhance robustness of obtained super-resolution model for complex scenes, a wide enhancement block achieves a dynamic architecture to learn more robust information to enhance applicability of an obtained super-resolution model for varying scenes. To prevent interference of components in a wide enhancement block, a refinement block utilises a stacked architecture to accurately learn obtained features. Also, a residual learning operation is embedded in the refinement block to prevent long-term dependency problem. Finally, a construction block is responsible for reconstructing high-quality images. Designed heterogeneous architecture can not only facilitate richer structural information, but also be lightweight, which is suitable for mobile digital devices. Experimental results show that our method is more competitive in terms of performance, recovering time of image super-resolution and complexity. The code of DSRNet can be obtained at https://github.com/hellloxiaotian/DSRNet .},
  archive      = {J_CAAITIT},
  author       = {Chunwei Tian and Xuanyu Zhang and Qi Zhang and Mingming Yang and Zhaojie Ju},
  doi          = {10.1049/cit2.12297},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {837-849},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Image super-resolution via dynamic network},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel medical image data protection scheme for smart
healthcare system. <em>CAAITIT</em>, <em>9</em>(4), 821–836. (<a
href="https://doi.org/10.1049/cit2.12292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Multimedia Things (IoMT) refers to a network of interconnected multimedia devices that communicate with each other over the Internet. Recently, smart healthcare has emerged as a significant application of the IoMT, particularly in the context of knowledge-based learning systems. Smart healthcare systems leverage knowledge-based learning to become more context-aware, adaptable, and auditable while maintaining the ability to learn from historical data. In smart healthcare systems, devices capture images, such as X-rays, Magnetic Resonance Imaging. The security and integrity of these images are crucial for the databases used in knowledge-based learning systems to foster structured decision-making and enhance the learning abilities of AI. Moreover, in knowledge-driven systems, the storage and transmission of HD medical images exert a burden on the limited bandwidth of the communication channel, leading to data transmission delays. To address the security and latency concerns, this paper presents a lightweight medical image encryption scheme utilising bit-plane decomposition and chaos theory. The results of the experiment yield entropy, energy, and correlation values of 7.999, 0.0156, and 0.0001, respectively. This validates the effectiveness of the encryption system proposed in this paper, which offers high-quality encryption, a large key space, key sensitivity, and resistance to statistical attacks.},
  archive      = {J_CAAITIT},
  author       = {Mujeeb Ur Rehman and Arslan Shafique and Muhammad Shahbaz Khan and Maha Driss and Wadii Boulila and Yazeed Yasin Ghadi and Suresh Babu Changalasetty and Majed Alhaisoni and Jawad Ahmad},
  doi          = {10.1049/cit2.12292},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {821-836},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A novel medical image data protection scheme for smart healthcare system},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge-based deep learning system for classifying
alzheimer’s disease for multi-task learning. <em>CAAITIT</em>,
<em>9</em>(4), 805–820. (<a
href="https://doi.org/10.1049/cit2.12291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has recently become a viable approach for classifying Alzheimer&#39;s disease (AD) in medical imaging. However, existing models struggle to efficiently extract features from medical images and may squander additional information resources for illness classification. To address these issues, a deep three-dimensional convolutional neural network incorporating multi-task learning and attention mechanisms is proposed. An upgraded primary C3D network is utilised to create rougher low-level feature maps. It introduces a new convolution block that focuses on the structural aspects of the magnetic resonance imaging image and another block that extracts attention weights unique to certain pixel positions in the feature map and multiplies them with the feature map output. Then, several fully connected layers are used to achieve multi-task learning, generating three outputs, including the primary classification task. The other two outputs employ backpropagation during training to improve the primary classification job. Experimental findings show that the authors’ proposed method outperforms current approaches for classifying AD, achieving enhanced classification accuracy and other indicators on the Alzheimer&#39;s disease Neuroimaging Initiative dataset. The authors demonstrate promise for future disease classification studies.},
  archive      = {J_CAAITIT},
  author       = {Amol Dattatray Dhaygude and Gaurav Kumar Ameta and Ihtiram Raza Khan and Pavitar Parkash Singh and Renato R. Maaliw and Natrayan Lakshmaiya and Mohammad Shabaz and Muhammad Attique Khan and Hany S. Hussein and Hammam Alshazly},
  doi          = {10.1049/cit2.12291},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {805-820},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Knowledge-based deep learning system for classifying alzheimer&#39;s disease for multi-task learning},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning fusion model for accurate classification of
brain tumours in magnetic resonance images. <em>CAAITIT</em>,
<em>9</em>(4), 790–804. (<a
href="https://doi.org/10.1049/cit2.12276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting brain tumours is complex due to the natural variation in their location, shape, and intensity in images. While having accurate detection and segmentation of brain tumours would be beneficial, current methods still need to solve this problem despite the numerous available approaches. Precise analysis of Magnetic Resonance Imaging (MRI) is crucial for detecting, segmenting, and classifying brain tumours in medical diagnostics. Magnetic Resonance Imaging is a vital component in medical diagnosis, and it requires precise, efficient, careful, efficient, and reliable image analysis techniques. The authors developed a Deep Learning (DL) fusion model to classify brain tumours reliably. Deep Learning models require large amounts of training data to achieve good results, so the researchers utilised data augmentation techniques to increase the dataset size for training models. VGG16, ResNet50, and convolutional deep belief networks networks extracted deep features from MRI images. Softmax was used as the classifier, and the training set was supplemented with intentionally created MRI images of brain tumours in addition to the genuine ones. The features of two DL models were combined in the proposed model to generate a fusion model, which significantly increased classification accuracy. An openly accessible dataset from the internet was used to test the model&#39;s performance, and the experimental results showed that the proposed fusion model achieved a classification accuracy of 98.98%. Finally, the results were compared with existing methods, and the proposed model outperformed them significantly.},
  archive      = {J_CAAITIT},
  author       = {Nechirvan Asaad Zebari and Chira Nadheef Mohammed and Dilovan Asaad Zebari and Mazin Abed Mohammed and Diyar Qader Zeebaree and Haydar Abdulameer Marhoon and Karrar Hameed Abdulkareem and Seifedine Kadry and Wattana Viriyasitavat and Jan Nedoma and Radek Martinek},
  doi          = {10.1049/cit2.12276},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {790-804},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A deep learning fusion model for accurate classification of brain tumours in magnetic resonance images},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic adaptive spatio–temporal graph network for COVID-19
forecasting. <em>CAAITIT</em>, <em>9</em>(3), 769–786. (<a
href="https://doi.org/10.1049/cit2.12238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Appropriately characterising the mixed space–time relations of the contagion process caused by hybrid space and time factors remains the primary challenge in COVID-19 forecasting. However, in previous deep learning models for epidemic forecasting, spatial and temporal variations are captured separately. A unified model is developed to cover all spatio–temporal relations. However, this measure is insufficient for modelling the complex spatio–temporal relations of infectious disease transmission. A dynamic adaptive spatio–temporal graph network (DASTGN) is proposed based on attention mechanisms to improve prediction accuracy. In DASTGN, complex spatio–temporal relations are depicted by adaptively fusing the mixed space–time effects and dynamic space–time dependency structure. This dual-scale model considers the time-specific, space-specific, and direct effects of the propagation process at the fine-grained level. Furthermore, the model characterises impacts from various space–time neighbour blocks under time-varying interventions at the coarse-grained level. The performance comparisons on the three COVID-19 datasets reveal that DASTGN achieves state-of-the-art results with a maximum improvement of 17.092% in the root mean-square error and 11.563% in the mean absolute error. Experimental results indicate that the mechanisms of designing DASTGN can effectively detect some spreading characteristics of COVID-19. The spatio–temporal weight matrices learned in each proposed module reveal diffusion patterns in various scenarios. In conclusion, DASTGN has successfully captured the dynamic spatio–temporal variations of COVID-19, and considering multiple dynamic space–time relationships is essential in epidemic forecasting.},
  archive      = {J_CAAITIT},
  author       = {Xiaojun Pu and Jiaqi Zhu and Yunkun Wu and Chang Leng and Zitong Bo and Hongan Wang},
  doi          = {10.1049/cit2.12238},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {769-786},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Dynamic adaptive spatio–temporal graph network for COVID-19 forecasting},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UDT: U-shaped deformable transformer for subarachnoid
haemorrhage image segmentation. <em>CAAITIT</em>, <em>9</em>(3),
756–768. (<a href="https://doi.org/10.1049/cit2.12302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subarachnoid haemorrhage (SAH), mostly caused by the rupture of intracranial aneurysm, is a common disease with a high fatality rate. SAH lesions are generally diffusely distributed, showing a variety of scales with irregular edges. The complex characteristics of lesions make SAH segmentation a challenging task. To cope with these difficulties, a u-shaped deformable transformer (UDT) is proposed for SAH segmentation. Specifically, first, a multi-scale deformable attention (MSDA) module is exploited to model the diffuseness and scale-variant characteristics of SAH lesions, where the MSDA module can fuse features in different scales and adjust the attention field of each element dynamically to generate discriminative multi-scale features. Second, the cross deformable attention-based skip connection (CDASC) module is designed to model the irregular edge characteristic of SAH lesions, where the CDASC module can utilise the spatial details from encoder features to refine the spatial information of decoder features. Third, the MSDA and CDASC modules are embedded into the backbone Res-UNet to construct the proposed UDT. Extensive experiments are conducted on the self-built SAH-CT dataset and two public medical datasets (GlaS and MoNuSeg). Experimental results show that the presented UDT achieves the state-of-the-art performance.},
  archive      = {J_CAAITIT},
  author       = {Wei Xie and Lianghao Jin and Shiqi Hua and Hao Sun and Bo Sun and Zhigang Tu and Jun Liu},
  doi          = {10.1049/cit2.12302},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {756-768},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {UDT: U-shaped deformable transformer for subarachnoid haemorrhage image segmentation},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Position-aware pushing and grasping synergy with deep
reinforcement learning in clutter. <em>CAAITIT</em>, <em>9</em>(3),
738–755. (<a href="https://doi.org/10.1049/cit2.12264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The positional information of objects is crucial to enable robots to perform grasping and pushing manipulations in clutter. To effectively perform grasping and pushing manipulations, robots need to perceive the position information of objects, including the coordinates and spatial relationship between objects (e.g., proximity, adjacency). The authors propose an end-to-end position-aware deep Q-learning framework to achieve efficient collaborative pushing and grasping in clutter. Specifically, a pair of conjugate pushing and grasping attention modules are proposed to capture the position information of objects and generate high-quality affordance maps of operating positions with features of pushing and grasping operations. In addition, the authors propose an object isolation metric and clutter metric based on instance segmentation to measure the spatial relationships between objects in cluttered environments. To further enhance the perception capacity of position information of the objects, the authors associate the change in the object isolation metric and clutter metric in cluttered environment before and after performing the action with reward function. A series of experiments are carried out in simulation and real-world which indicate that the method improves sample efficiency, task completion rate, grasping success rate and action efficiency compared to state-of-the-art end-to-end methods. Noted that the authors’ system can be robustly applied to real-world use and extended to novel objects. Supplementary material is available at https://youtu.be/NhG\_k5v3NnM}{https://youtu.be/NhG\_k5v3NnM .},
  archive      = {J_CAAITIT},
  author       = {Min Zhao and Guoyu Zuo and Shuangyue Yu and Daoxiong Gong and Zihao Wang and Ouattara Sie},
  doi          = {10.1049/cit2.12264},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {738-755},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Position-aware pushing and grasping synergy with deep reinforcement learning in clutter},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural dynamics for improving optimiser in deep learning
with noise considered. <em>CAAITIT</em>, <em>9</em>(3), 722–737. (<a
href="https://doi.org/10.1049/cit2.12263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As deep learning evolves, neural network structures become increasingly sophisticated, bringing a series of new optimisation challenges. For example, deep neural networks (DNNs) are vulnerable to a variety of attacks. Training neural networks under privacy constraints is a method to alleviate privacy leakage, and one way to do this is to add noise to the gradient. However, the existing optimisers suffer from weak convergence in the presence of increased noise during training, which leads to a low robustness of the optimiser. To stabilise and improve the convergence of DNNs, the authors propose a neural dynamics (ND) optimiser, which is inspired by the zeroing neural dynamics originated from zeroing neural networks. The authors first analyse the relationship between DNNs and control systems. Then, the authors construct the ND optimiser to update network parameters. Moreover, the proposed ND optimiser alleviates the non-convergence problem that may be suffered by adding noise to the gradient from different scenarios. Furthermore, experiments are conducted on different neural network structures, including ResNet18, ResNet34, Inception-v3, MobileNet, and long and short-term memory network. Comparative results using CIFAR, YouTube Faces, and R8 datasets demonstrate that the ND optimiser improves the accuracy and stability of DNNs under noise-free and noise-polluted conditions. The source code is publicly available at https://github.com/LongJin-lab/ND .},
  archive      = {J_CAAITIT},
  author       = {Dan Su and Predrag S. Stanimirović and Ling Bo Han and Long Jin},
  doi          = {10.1049/cit2.12263},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {722-737},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Neural dynamics for improving optimiser in deep learning with noise considered},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Construction personnel dress code detection based on YOLO
framework. <em>CAAITIT</em>, <em>9</em>(3), 709–721. (<a
href="https://doi.org/10.1049/cit2.12312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is important for construction personnel to observe the dress code, such as the correct wearing of safety helmets and reflective vests is conducive to protecting the workers&#39; lives and safety of construction. A YOLO network-based detection algorithm is proposed for the construction personnel dress code (YOLO-CPDC). Firstly, Multi-Head Self-Attention (MHSA) is introduced into the backbone network to build a hybrid backbone, called Convolution MHSA Network (CMNet). The CMNet gives the model a global field of view and enhances the detection capability of the model for small and obscured targets. Secondly, an efficient and lightweight convolution module is designed. It is named Ghost Shuffle Attention-Conv-BN-SiLU (GSA-CBS) and is used in the neck network. The GSANeck network reduces the model size without affecting the performance. Finally, the SIoU is used in the loss function and Soft NMS is used for post-processing. Experimental results on the self-constructed dataset show that YOLO-CPDC algorithm has higher detection accuracy than current methods. YOLO-CPDC achieves a mAP50 of 93.6%. Compared with the YOLOv5s, the number of parameters of our model is reduced by 18% and the mAP50 is improved by 1.1%. Overall, this research effectively meets the actual demand of dress code detection in construction scenes.},
  archive      = {J_CAAITIT},
  author       = {Yunkai Lyu and Xiaobing Yang and Ai Guan and Jingwen Wang and Leni Dai},
  doi          = {10.1049/cit2.12312},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {709-721},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Construction personnel dress code detection based on YOLO framework},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weakly supervised point cloud segmentation via deep
morphological semantic information embedding. <em>CAAITIT</em>,
<em>9</em>(3), 695–708. (<a
href="https://doi.org/10.1049/cit2.12239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmenting the semantic regions of point clouds is a crucial step for intelligent agents to understand 3D scenes. Weakly supervised point cloud segmentation is highly desirable because entirely labelling point clouds is highly time-consuming and costly. For the low-costing labelling of 3D point clouds, the scene-level label is one of the most effortless label strategies. However, due to the limitation of classifier discriminative capability and the orderless and structurless nature of the point cloud data, existing scene-level method is hard to transfer the semantic information, which usually leads to the under-activated or over-activated issues. To this end, a local semantic embedding network is introduced to learn local structural patterns and semantic propagation. Specifically, the proposed network contains graph convolution-based dilation and erosion embedding modules to implement ‘inside-out’ and ‘outside-in’ semantic information dissemination pathways. Therefore, the proposed weakly supervised learning framework could achieve the mutual propagation of semantic information in the foreground and background. Comprehensive experiments on the widely used ScanNet benchmark demonstrate the superior capacity of the proposed approach when compared to the current alternatives and baseline models.},
  archive      = {J_CAAITIT},
  author       = {Wenhao Xue and Yang Yang and Lei Li and Zhongling Huang and Xinggang Wang and Junwei Han and Dingwen Zhang},
  doi          = {10.1049/cit2.12239},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {695-708},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Weakly supervised point cloud segmentation via deep morphological semantic information embedding},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RGB-guided hyperspectral image super-resolution with deep
progressive learning. <em>CAAITIT</em>, <em>9</em>(3), 679–694. (<a
href="https://doi.org/10.1049/cit2.12256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to hardware limitations, existing hyperspectral (HS) camera often suffer from low spatial/temporal resolution. Recently, it has been prevalent to super-resolve a low resolution (LR) HS image into a high resolution (HR) HS image with a HR RGB (or multispectral) image guidance. Previous approaches for this guided super-resolution task often model the intrinsic characteristic of the desired HR HS image using hand-crafted priors. Recently, researchers pay more attention to deep learning methods with direct supervised or unsupervised learning, which exploit deep prior only from training dataset or testing data. In this article, an efficient convolutional neural network-based method is presented to progressively super-resolve HS image with RGB image guidance. Specifically, a progressive HS image super-resolution network is proposed, which progressively super-resolve the LR HS image with pixel shuffled HR RGB image guidance. Then, the super-resolution network is progressively trained with supervised pre-training and unsupervised adaption, where supervised pre-training learns the general prior on training data and unsupervised adaptation generalises the general prior to specific prior for variant testing scenes. The proposed method can effectively exploit prior from training dataset and testing HS and RGB images with spectral-spatial constraint. It has a good generalisation capability, especially for blind HS image super-resolution. Comprehensive experimental results show that the proposed deep progressive learning method outperforms the existing state-of-the-art methods for HS image super-resolution in non-blind and blind cases.},
  archive      = {J_CAAITIT},
  author       = {Tao Zhang and Ying Fu and Liwei Huang and Siyuan Li and Shaodi You and Chenggang Yan},
  doi          = {10.1049/cit2.12256},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {679-694},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {RGB-guided hyperspectral image super-resolution with deep progressive learning},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Precise region semantics-assisted GAN for pose-guided person
image generation. <em>CAAITIT</em>, <em>9</em>(3), 665–678. (<a
href="https://doi.org/10.1049/cit2.12255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating a realistic person&#39;s image from one source pose conditioned on another different target pose is a promising computer vision task. The previous mainstream methods mainly focus on exploring the transformation relationship between the keypoint-based source pose and the target pose, but rarely investigate the region-based human semantic information. Some current methods that adopt the parsing map neither consider the precise local pose-semantic matching issues nor the correspondence between two different poses. In this study, a Region Semantics-Assisted Generative Adversarial Network (RSA-GAN) is proposed for the pose-guided person image generation task. In particular, a regional pose-guided semantic fusion module is first developed to solve the imprecise match issue between the semantic parsing map from a certain source image and the corresponding keypoints in the source pose. To well align the style of the human in the source image with the target pose, a pose correspondence guided style injection module is designed to learn the correspondence between the source pose and the target pose. In addition, one gated depth-wise convolutional cross-attention based style integration module is proposed to distribute the well-aligned coarse style information together with the precisely matched pose-guided semantic information towards the target pose. The experimental results indicate that the proposed RSA-GAN achieves a 23% reduction in LPIPS compared to the method without using the semantic maps and a 6.9% reduction in FID for the method with semantic maps, respectively, and also shows higher realistic qualitative results.},
  archive      = {J_CAAITIT},
  author       = {Ji Liu and Zhenyu Weng and Yuesheng Zhu},
  doi          = {10.1049/cit2.12255},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {665-678},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Precise region semantics-assisted GAN for pose-guided person image generation},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-granularity feature enhancement network for maritime
ship detection. <em>CAAITIT</em>, <em>9</em>(3), 649–664. (<a
href="https://doi.org/10.1049/cit2.12310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the characteristics of high resolution and rich texture information, visible light images are widely used for maritime ship detection. However, these images are susceptible to sea fog and ships of different sizes, which can result in missed detections and false alarms, ultimately resulting in lower detection accuracy. To address these issues, a novel multi-granularity feature enhancement network, MFENet, which includes a three-way dehazing module (3WDM) and a multi-granularity feature enhancement module (MFEM) is proposed. The 3WDM eliminates sea fog interference by using an image clarity automatic classification algorithm based on three-way decisions and FFA-Net to obtain clear image samples. Additionally, the MFEM improves the accuracy of detecting ships of different sizes by utilising an improved super-resolution reconstruction convolutional neural network to enhance the resolution and semantic representation capability of the feature maps from YOLOv7. Experimental results demonstrate that MFENet surpasses the other 15 competing models in terms of the mean Average Precision metric on two benchmark datasets, achieving 96.28% on the McShips dataset and 97.71% on the SeaShips dataset.},
  archive      = {J_CAAITIT},
  author       = {Li Ying and Duoqian Miao and Zhifei Zhang and Hongyun Zhang and Witold Pedrycz},
  doi          = {10.1049/cit2.12310},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {649-664},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Multi-granularity feature enhancement network for maritime ship detection},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Underwater image clarifying based on human visual colour
constancy using double-opponency. <em>CAAITIT</em>, <em>9</em>(3),
632–648. (<a href="https://doi.org/10.1049/cit2.12260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater images are often with biased colours and reduced contrast because of the absorption and scattering effects when light propagates in water. Such images with degradation cannot meet the needs of underwater operations. The main problem in classic underwater image restoration or enhancement methods is that they consume long calculation time, and often, the colour or contrast of the result images is still unsatisfied. Instead of using the complicated physical model of underwater imaging degradation, we propose a new method to deal with underwater images by imitating the colour constancy mechanism of human vision using double-opponency. Firstly, the original image is converted to the LMS space. Then the signals are linearly combined, and Gaussian convolutions are performed to imitate the function of receptive fields (RFs). Next, two RFs with different sizes work together to constitute the double-opponency response. Finally, the underwater light is estimated to correct the colours in the image. Further contrast stretching on the luminance is optional. Experiments show that the proposed method can obtain clarified underwater images with higher quality than before, and it spends significantly less time cost compared to other previously published typical methods.},
  archive      = {J_CAAITIT},
  author       = {Bin Kong and Jing Qian and Pinhao Song and Jing Yang and Amir Hussain},
  doi          = {10.1049/cit2.12260},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {632-648},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Underwater image clarifying based on human visual colour constancy using double-opponency},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rethinking multi-spatial information for transferable
adversarial attacks on speaker recognition systems. <em>CAAITIT</em>,
<em>9</em>(3), 620–631. (<a
href="https://doi.org/10.1049/cit2.12295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks have been posing significant security concerns to intelligent systems, such as speaker recognition systems (SRSs). Most attacks assume the neural networks in the systems are known beforehand, while black-box attacks are proposed without such information to meet practical situations. Existing black-box attacks improve transferability by integrating multiple models or training on multiple datasets, but these methods are costly. Motivated by the optimisation strategy with spatial information on the perturbed paths and samples, we propose a Dual Spatial Momentum Iterative Fast Gradient Sign Method (DS-MI-FGSM) to improve the transferability of black-box attacks against SRSs. Specifically, DS-MI-FGSM only needs a single data and one model as the input; by extending to the data and model neighbouring spaces, it generates adversarial examples against the integrating models. To reduce the risk of overfitting, DS-MI-FGSM also introduces gradient masking to improve transferability. The authors conduct extensive experiments regarding the speaker recognition task, and the results demonstrate the effectiveness of their method, which can achieve up to 92% attack success rate on the victim model in black-box scenarios with only one known model.},
  archive      = {J_CAAITIT},
  author       = {Junjian Zhang and Hao Tan and Le Wang and Yaguan Qian and Zhaoquan Gu},
  doi          = {10.1049/cit2.12295},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {620-631},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Rethinking multi-spatial information for transferable adversarial attacks on speaker recognition systems},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heterogeneous decentralised machine unlearning with seed
model distillation. <em>CAAITIT</em>, <em>9</em>(3), 608–619. (<a
href="https://doi.org/10.1049/cit2.12281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As some recent information security legislation endowed users with unconditional rights to be forgotten by any trained machine learning model, personalised IoT service providers have to put unlearning functionality into their consideration. The most straightforward method to unlearn users&#39; contribution is to retrain the model from the initial state, which is not realistic in high throughput applications with frequent unlearning requests. Though some machine unlearning frameworks have been proposed to speed up the retraining process, they fail to match decentralised learning scenarios. A decentralised unlearning framework called heterogeneous decentralised unlearning framework with seed (HDUS) is designed, which uses distilled seed models to construct erasable ensembles for all clients. Moreover, the framework is compatible with heterogeneous on-device models, representing stronger scalability in real-world applications. Extensive experiments on three real-world datasets show that our HDUS achieves state-of-the-art performance.},
  archive      = {J_CAAITIT},
  author       = {Guanhua Ye and Tong Chen and Quoc Viet Hung Nguyen and Hongzhi Yin},
  doi          = {10.1049/cit2.12281},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {608-619},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Heterogeneous decentralised machine unlearning with seed model distillation},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). An intelligent prediction model of epidemic characters
based on multi-feature. <em>CAAITIT</em>, <em>9</em>(3), 595–607. (<a
href="https://doi.org/10.1049/cit2.12294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The epidemic characters of Omicron ( e . g . large-scale transmission) are significantly different from the initial variants of COVID-19. The data generated by large-scale transmission is important to predict the trend of epidemic characters. However, the results of current prediction models are inaccurate since they are not closely combined with the actual situation of Omicron transmission. In consequence, these inaccurate results have negative impacts on the process of the manufacturing and the service industry, for example, the production of masks and the recovery of the tourism industry. The authors have studied the epidemic characters in two ways, that is, investigation and prediction. First, a large amount of data is collected by utilising the Baidu index and conduct questionnaire survey concerning epidemic characters. Second, the β -SEIDR model is established, where the population is classified as Susceptible, Exposed, Infected, Dead and β -Recovered persons, to intelligently predict the epidemic characters of COVID-19. Note that β -Recovered persons denote that the Recovered persons may become Susceptible persons with probability β . The simulation results show that the model can accurately predict the epidemic characters.},
  archive      = {J_CAAITIT},
  author       = {Xiaoying Wang and Chunmei Li and Yilei Wang and Lin Yin and Qilin Zhou and Rui Zheng and Qingwu Wu and Yuqi Zhou and Min Dai},
  doi          = {10.1049/cit2.12294},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {595-607},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {An intelligent prediction model of epidemic characters based on multi-feature},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A topic-controllable keywords-to-text generator with
knowledge base network. <em>CAAITIT</em>, <em>9</em>(3), 585–594. (<a
href="https://doi.org/10.1049/cit2.12280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the introduction of more recent deep learning models such as encoder-decoder, text generation frameworks have gained a lot of popularity. In Natural Language Generation (NLG), controlling the information and style of the output produced is a crucial and challenging task. The purpose of this paper is to develop informative and controllable text using social media language by incorporating topic knowledge into a keyword-to-text framework. A novel Topic-Controllable Key-to-Text (TC-K2T) generator that focuses on the issues of ignoring unordered keywords and utilising subject-controlled information from previous research is presented. TC-K2T is built on the framework of conditional language encoders. In order to guide the model to produce an informative and controllable language, the generator first inputs unordered keywords and uses subjects to simulate prior human knowledge. Using an additional probability term, the model increases the likelihood of topic words appearing in the generated text to bias the overall distribution. The proposed TC-K2T can produce more informative and controllable senescence, outperforming state-of-the-art models, according to empirical research on automatic evaluation metrics and human annotations.},
  archive      = {J_CAAITIT},
  author       = {Li He and Kaize Shi and Dingxian Wang and Xianzhi Wang and Guandong Xu},
  doi          = {10.1049/cit2.12280},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {585-594},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A topic-controllable keywords-to-text generator with knowledge base network},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ada-FFL: Adaptive computing fairness federated learning.
<em>CAAITIT</em>, <em>9</em>(3), 573–584. (<a
href="https://doi.org/10.1049/cit2.12232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the scale of federated learning expands, solving the Non-IID data problem of federated learning has become a key challenge of interest. Most existing solutions generally aim to solve the overall performance improvement of all clients; however, the overall performance improvement often sacrifices the performance of certain clients, such as clients with less data. Ignoring fairness may greatly reduce the willingness of some clients to participate in federated learning. In order to solve the above problem, the authors propose Ada-FFL, an adaptive fairness federated aggregation learning algorithm, which can dynamically adjust the fairness coefficient according to the update of the local models, ensuring the convergence performance of the global model and the fairness between federated learning clients. By integrating coarse-grained and fine-grained equity solutions, the authors evaluate the deviation of local models by considering both global equity and individual equity, then the weight ratio will be dynamically allocated for each client based on the evaluated deviation value, which can ensure that the update differences of local models are fully considered in each round of training. Finally, by combining a regularisation term to limit the local model update to be closer to the global model, the sensitivity of the model to input perturbations can be reduced, and the generalisation ability of the global model can be improved. Through numerous experiments on several federal data sets, the authors show that our method has more advantages in convergence effect and fairness than the existing baselines.},
  archive      = {J_CAAITIT},
  author       = {Yue Cong and Jing Qiu and Kun Zhang and Zhongyang Fang and Chengliang Gao and Shen Su and Zhihong Tian},
  doi          = {10.1049/cit2.12232},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {573-584},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Ada-FFL: Adaptive computing fairness federated learning},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards trustworthy multi-modal motion prediction: Holistic
evaluation and interpretability of outputs. <em>CAAITIT</em>,
<em>9</em>(3), 557–572. (<a
href="https://doi.org/10.1049/cit2.12244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the motion of other road agents enables autonomous vehicles to perform safe and efficient path planning. This task is very complex, as the behaviour of road agents depends on many factors and the number of possible future trajectories can be considerable (multi-modal). Most prior approaches proposed to address multi-modal motion prediction are based on complex machine learning systems that have limited interpretability. Moreover, the metrics used in current benchmarks do not evaluate all aspects of the problem, such as the diversity and admissibility of the output. The authors aim to advance towards the design of trustworthy motion prediction systems, based on some of the requirements for the design of Trustworthy Artificial Intelligence. The focus is on evaluation criteria, robustness, and interpretability of outputs. First, the evaluation metrics are comprehensively analysed, the main gaps of current benchmarks are identified, and a new holistic evaluation framework is proposed. Then, a method for the assessment of spatial and temporal robustness is introduced by simulating noise in the perception system. To enhance the interpretability of the outputs and generate more balanced results in the proposed evaluation framework, an intent prediction layer that can be attached to multi-modal motion prediction models is proposed. The effectiveness of this approach is assessed through a survey that explores different elements in the visualisation of the multi-modal trajectories and intentions. The proposed approach and findings make a significant contribution to the development of trustworthy motion prediction systems for autonomous vehicles, advancing the field towards greater safety and reliability.},
  archive      = {J_CAAITIT},
  author       = {Sandra Carrasco Limeros and Sylwia Majchrowska and Joakim Johnander and Christoffer Petersson and Miguel Ángel Sotelo and David Fernández Llorca},
  doi          = {10.1049/cit2.12244},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {557-572},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Towards trustworthy multi-modal motion prediction: Holistic evaluation and interpretability of outputs},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trustworthy semi-supervised anomaly detection for
online-to-offline logistics business in merchant identification.
<em>CAAITIT</em>, <em>9</em>(3), 544–556. (<a
href="https://doi.org/10.1049/cit2.12301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of online-to-offline (O2O) e-commerce business has brought tremendous opportunities to the logistics industry. In the online-to-offline logistics business, it is essential to detect anomaly merchants with fraudulent shipping behaviours, such as sending other merchants&#39; packages for profit with their low discounts. This can help reduce the financial losses of platforms and ensure a healthy environment. Existing anomaly detection studies have mainly focused on online fraud behaviour detection, such as fraudulent purchase and comment behaviours in e-commerce. However, these methods are not suitable for anomaly merchant detection in logistics due to the more complex online and offline operation of package-sending behaviours and the interpretable requirements of offline deployment in logistics. MultiDet, a semi-supervised multi-view fusion-based Anomaly Detection framework in online-to-offline logistics is proposed, which consists of a basic version SemiDet and an attention-enhanced multi-view fusion model. In SemiDet, pair-wise data augmentation is first conducted to promote model robustness and address the challenge of limited labelled anomaly instances. Then, SemiDet calculates the anomaly scoring of each merchant with an auto-encoder framework. Considering the multi-relationships among logistics merchants, a multi-view attention fusion-based anomaly detection network is further designed to capture merchants&#39; mutual influences and improve the anomaly merchant detection performance. A post-hoc perturbation-based interpretation model is designed to output the importance of different views and ensure the trustworthiness of end-to-end anomaly detection. The framework based on an eight-month real-world dataset collected from one of the largest logistics platforms in China is evaluated, involving 6128 merchants and 16 million historical order consignor records in Beijing. Experimental results show that the proposed model outperforms other baselines in both AUC-ROC and AUC-PR metrics.},
  archive      = {J_CAAITIT},
  author       = {Yong Li and Shuhang Wang and Shijie Xu and Jiao Yin},
  doi          = {10.1049/cit2.12301},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {544-556},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Trustworthy semi-supervised anomaly detection for online-to-offline logistics business in merchant identification},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A versatile humanoid robot platform for dexterous
manipulation and human–robot collaboration. <em>CAAITIT</em>,
<em>9</em>(2), 526–540. (<a
href="https://doi.org/10.1049/cit2.12214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humanoid robots have attracted much attention by virtue of their compatibility with human environments. However, biped humanoids with immense promise still cannot function steadily and reliably in real-world settings in the current state. Hence, rationally combining a humanoid robot with different stable mobile platforms is a favoured solution for diverse scenarios. Here, a new versatile humanoid robot platform, aiming to provide a generic solution that can be flexibly deployed in diverse scenarios, for example, indoors and fields is presented. Versatile humanoid robot platform incorporates multimodal perception, and extensible interfaces on hardware and software, allowing it to be rapidly integrated with different mobile platforms and end-effectors, only through easy-to-assemble interfaces. Additionally, the platform has achieved impressive integration, lightness, dexterity, and strength in its class, with human-like size and rich perception, targeted to have human-intelligent manipulation skills for human-engineered environments. Overall, this article elaborates on the reasoning behind the design choices, and outlines each subsystem. Lastly, the essential performance of the platform is successfully demonstrated in a set of experiments with precise and dexterous manipulation, and human–robot collaboration requirements.},
  archive      = {J_CAAITIT},
  author       = {Xin Shu and Fenglei Ni and Xinyang Fan and Shuai Yang and Changyuan Liu and Baoxu Tu and Yiwei Liu and Hong Liu},
  doi          = {10.1049/cit2.12214},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {526-540},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A versatile humanoid robot platform for dexterous manipulation and human–robot collaboration},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An artificial systems, computational experiments and
parallel execution-based surface electromyogram-driven anti-disturbance
zeroing neurodynamic strategy for upper limb human-robot interaction
control. <em>CAAITIT</em>, <em>9</em>(2), 511–525. (<a
href="https://doi.org/10.1049/cit2.12221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, intelligent robots are extensively applied in the field of the industry and intelligent rehabilitation, wherein the human-robot interaction (HRI) control strategy is a momentous part that needs to be ameliorated. Specially, the efficacy and robustness of the HRI control algorithm in the presence of unknown external disturbances deserve to be addressed. To deal with these urgent issues, in this study, artificial systems, computational experiments and a parallel execution intelligent control framework are constructed for the HRI control. The upper limb-robotic exoskeleton system is re-modelled as an artificial system. Depending on surface electromyogram-based subject&#39;s active motion intention in the practical system, a non-convex function activated anti-disturbance zeroing neurodynamic (NC-ADZND) controller is devised in the artificial system for parallel interaction and HRI control with the practical system. Furthermore, the linear activation function-based zeroing neurodynamic (LAF-ZND) controller and proportional-derivative (posterior deltoid (PD)) controller are presented and compared. Theoretical results substantiate the global convergence and robustness of the proposed controller in the presence of different external disturbances. In addition, the simulation results verify that the NC-ADZND controller is better than the LAF-ZND and the PD controllers in respect of convergence order and anti-disturbance characteristics.},
  archive      = {J_CAAITIT},
  author       = {Yongbai Liu and Keping Liu and Gang Wang and Jiliang Zhang and Yao Chou and Zhongbo Sun},
  doi          = {10.1049/cit2.12221},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {511-525},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {An artificial systems, computational experiments and parallel execution-based surface electromyogram-driven anti-disturbance zeroing neurodynamic strategy for upper limb human-robot interaction control},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-feature-based intelligent redundancy elimination
scheme for cloud-assisted health systems. <em>CAAITIT</em>,
<em>9</em>(2), 491–510. (<a
href="https://doi.org/10.1049/cit2.12211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Redundancy elimination techniques are extensively investigated to reduce storage overheads for cloud-assisted health systems. Deduplication eliminates the redundancy of duplicate blocks by storing one physical instance referenced by multiple duplicates. Delta compression is usually regarded as a complementary technique to deduplication to further remove the redundancy of similar blocks, but our observations indicate that this is disobedient when data have sparse duplicate blocks. In addition, there are many overlapped deltas in the resemblance detection process of post-deduplication delta compression, which hinders the efficiency of delta compression and the index phase of resemblance detection inquires abundant non-similar blocks, resulting in inefficient system throughput. Therefore, a multi-feature-based redundancy elimination scheme, called MFRE, is proposed to solve these problems. The similarity feature and temporal locality feature are excavated to assist redundancy elimination where the similarity feature well expresses the duplicate attribute. Then, similarity-based dynamic post-deduplication delta compression and temporal locality-based dynamic delta compression discover more similar base blocks to minimise overlapped deltas and improve compression ratios. Moreover, the clustering method based on block-relationship and the feature index strategy based on bloom filters reduce IO overheads and improve system throughput. Experiments demonstrate that the proposed method, compared to the state-of-the-art method, improves the compression ratio and system throughput by 9.68% and 50%, respectively.},
  archive      = {J_CAAITIT},
  author       = {Ling Xiao and Beiji Zou and Xiaoyan Kui and Chengzhang Zhu and Wensheng Zhang and Xuebing Yang and Bob Zhang},
  doi          = {10.1049/cit2.12211},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {491-510},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A multi-feature-based intelligent redundancy elimination scheme for cloud-assisted health systems},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two kinds of average approximation accuracy.
<em>CAAITIT</em>, <em>9</em>(2), 481–490. (<a
href="https://doi.org/10.1049/cit2.12222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set theory places great importance on approximation accuracy, which is used to gauge how well a rough set model describes a target concept. However, traditional approximation accuracy has limitations since it varies with changes in the target concept and cannot evaluate the overall descriptive ability of a rough set model. To overcome this, two types of average approximation accuracy that objectively assess a rough set model’s ability to approximate all information granules is proposed. The first is the relative average approximation accuracy, which is based on all sets in the universe and has several basic properties. The second is the absolute average approximation accuracy, which is based on undefinable sets and has yielded significant conclusions. We also explore the relationship between these two types of average approximation accuracy. Finally, the average approximation accuracy has practical applications in addressing missing attribute values in incomplete information tables.},
  archive      = {J_CAAITIT},
  author       = {Qingzhao Kong and Wanting Wang and Dongxiao Zhang and Wenbin Zhang},
  doi          = {10.1049/cit2.12222},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {481-490},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Two kinds of average approximation accuracy},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Geometric prior guided hybrid deep neural network for facial
beauty analysis. <em>CAAITIT</em>, <em>9</em>(2), 467–480. (<a
href="https://doi.org/10.1049/cit2.12197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial beauty analysis is an important topic in human society. It may be used as a guidance for face beautification applications such as cosmetic surgery. Deep neural networks (DNNs) have recently been adopted for facial beauty analysis and have achieved remarkable performance. However, most existing DNN-based models regard facial beauty analysis as a normal classification task. They ignore important prior knowledge in traditional machine learning models which illustrate the significant contribution of the geometric features in facial beauty analysis. To be specific, landmarks of the whole face and facial organs are introduced to extract geometric features to make the decision. Inspired by this, we introduce a novel dual-branch network for facial beauty analysis: one branch takes the Swin Transformer as the backbone to model the full face and global patterns, and another branch focuses on the masked facial organs with the residual network to model the local patterns of certain facial parts. Additionally, the designed multi-scale feature fusion module can further facilitate our network to learn complementary semantic information between the two branches. In model optimisation, we propose a hybrid loss function, where especially geometric regulation is introduced by regressing the facial landmarks and it can force the extracted features to convey facial geometric features. Experiments performed on the SCUT-FBP5500 dataset and the SCUT-FBP dataset demonstrate that our model outperforms the state-of-the-art convolutional neural networks models, which proves the effectiveness of the proposed geometric regularisation and dual-branch structure with the hybrid network. To the best of our knowledge, this is the first study to introduce a Vision Transformer into the facial beauty analysis task.},
  archive      = {J_CAAITIT},
  author       = {Tianhao Peng and Mu Li and Fangmei Chen and Yong Xu and David Zhang},
  doi          = {10.1049/cit2.12197},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {467-480},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Geometric prior guided hybrid deep neural network for facial beauty analysis},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generative adversarial networks based motion learning
towards robotic calligraphy synthesis. <em>CAAITIT</em>, <em>9</em>(2),
452–466. (<a href="https://doi.org/10.1049/cit2.12198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot calligraphy visually reflects the motion capability of robotic manipulators. While traditional researches mainly focus on image generation and the writing of simple calligraphic strokes or characters, this article presents a generative adversarial network (GAN)-based motion learning method for robotic calligraphy synthesis (Gan2CS) that can enhance the efficiency in writing complex calligraphy words and reproducing classic calligraphy works. The key technologies in the proposed approach include: (1) adopting the GAN to learn the motion parameters from the robot writing operation; (2) converting the learnt motion data into the style font and realising the transition from static calligraphy images to dynamic writing demonstration; (3) reproducing high-precision calligraphy works by synthesising the writing motion data hierarchically. In this study, the motion trajectories of sample calligraphy images are firstly extracted and converted into the robot module. The robot performs the writing with motion planning, and the writing motion parameters of calligraphy strokes are learnt with GANs. Then the motion data of basic strokes is synthesised based on the hierarchical process of ‘stroke-radical-part-character’. And the robot re-writes the synthesised characters whose similarity with the original calligraphy characters is evaluated. Regular calligraphy characters have been tested in the experiments for method validation and the results validated that the robot can actualise the robotic calligraphy synthesis of writing motion data with GAN.},
  archive      = {J_CAAITIT},
  author       = {Xiaoming Wang and Yilong Yang and Weiru Wang and Yuanhua Zhou and Yongfeng Yin and Zhiguo Gong},
  doi          = {10.1049/cit2.12198},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {452-466},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Generative adversarial networks based motion learning towards robotic calligraphy synthesis},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attention-based network embedding with higher-order weights
and node attributes. <em>CAAITIT</em>, <em>9</em>(2), 440–451. (<a
href="https://doi.org/10.1049/cit2.12215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding aspires to learn a low-dimensional vector of each node in networks, which can apply to diverse data mining tasks. In real-life, many networks include rich attributes and temporal information. However, most existing embedding approaches ignore either temporal information or network attributes. A self-attention based architecture using higher-order weights and node attributes for both static and temporal attributed network embedding is presented in this article. A random walk sampling algorithm based on higher-order weights and node attributes to capture network topological features is presented. For static attributed networks, the algorithm incorporates first-order to k -order weights, and node attribute similarities into one weighted graph to preserve topological features of networks. For temporal attribute networks, the algorithm incorporates previous snapshots of networks containing first-order to k -order weights, and nodes attribute similarities into one weighted graph. In addition, the algorithm utilises a damping factor to ensure that the more recent snapshots allocate a greater weight. Attribute features are then incorporated into topological features. Next, the authors adopt the most advanced architecture, Self-Attention Networks, to learn node representations. Experimental results on node classification of static attributed networks and link prediction of temporal attributed networks reveal that our proposed approach is competitive against diverse state-of-the-art baseline approaches.},
  archive      = {J_CAAITIT},
  author       = {Xian Mo and Binyuan Wan and Rui Tang and Junkai Ding and Guangdi Liu},
  doi          = {10.1049/cit2.12215},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {440-451},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Attention-based network embedding with higher-order weights and node attributes},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep reinforcement learning using least-squares truncated
temporal-difference. <em>CAAITIT</em>, <em>9</em>(2), 425–439. (<a
href="https://doi.org/10.1049/cit2.12202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Policy evaluation (PE) is a critical sub-problem in reinforcement learning, which estimates the value function for a given policy and can be used for policy improvement. However, there still exist some limitations in current PE methods, such as low sample efficiency and local convergence, especially on complex tasks. In this study, a novel PE algorithm called Least-Squares Truncated Temporal-Difference learning (LST 2 D) is proposed. In LST 2 D, an adaptive truncation mechanism is designed, which effectively takes advantage of the fast convergence property of Least-Squares Temporal Difference learning and the asymptotic convergence property of Temporal Difference learning (TD). Then, two feature pre-training methods are utilised to improve the approximation ability of LST 2 D. Furthermore, an Actor-Critic algorithm based on LST 2 D and pre-trained feature representations (ACLPF) is proposed, where LST 2 D is integrated into the critic network to improve learning-prediction efficiency. Comprehensive simulation studies were conducted on four robotic tasks, and the corresponding results illustrate the effectiveness of LST 2 D. The proposed ACLPF algorithm outperformed DQN, ACER and PPO in terms of sample efficiency and stability, which demonstrated that LST 2 D can be applied to online learning control problems by incorporating it into the actor-critic architecture.},
  archive      = {J_CAAITIT},
  author       = {Junkai Ren and Yixing Lan and Xin Xu and Yichuan Zhang and Qiang Fang and Yujun Zeng},
  doi          = {10.1049/cit2.12202},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {425-439},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Deep reinforcement learning using least-squares truncated temporal-difference},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An object detection approach with residual feature fusion
and second-order term attention mechanism. <em>CAAITIT</em>,
<em>9</em>(2), 411–424. (<a
href="https://doi.org/10.1049/cit2.12236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatically detecting and locating remote occlusion small objects from the images of complex traffic environments is a valuable and challenging research. Since the boundary box location is not sufficiently accurate and it is difficult to distinguish overlapping and occluded objects, the authors propose a network model with a second-order term attention mechanism and occlusion loss. First, the backbone network is built on CSPDarkNet53. Then a method is designed for the feature extraction network based on an item-wise attention mechanism, which uses the filtered weighted feature vector to replace the original residual fusion and adds a second-order term to reduce the information loss in the process of fusion and accelerate the convergence of the model. Finally, an objected occlusion regression loss function is studied to reduce the problems of missed detections caused by dense objects. Sufficient experimental results demonstrate that the authors’ method achieved state-of-the-art performance without reducing the detection speed. The mAP@ .5 of the method is 85.8% on the Foggy_cityscapes dataset and the mAP@ .5 of the method is 97.8% on the KITTI dataset.},
  archive      = {J_CAAITIT},
  author       = {Cuijin Li and Zhong Qu and Shengye Wang},
  doi          = {10.1049/cit2.12236},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {411-424},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {An object detection approach with residual feature fusion and second-order term attention mechanism},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A verifiable essential secret image sharing scheme based on
HLRs (VESIS-(t, s, k, n)). <em>CAAITIT</em>, <em>9</em>(2), 388–410. (<a
href="https://doi.org/10.1049/cit2.12271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In traditional secret image sharing schemes, a secret image is shared among shareholders who have the same position. But if the shareholders have two different positions, essential and non-essential, it is necessary to use essential secret image sharing schemes. In this article, a verifiable essential secret image sharing scheme based on HLRs is proposed. Shareholder&#39;s share consists of two parts. The first part is produced by the shareholders, which prevents the fraud of dealers. The second part is a shadow image that is produced by using HLRs and the first part of share. The verification of the first part of the shares is done for the first time by using multilinear and bilinear maps. Also, for verifying shadow images, Bloom Filters are used for the first time. The proposed scheme is more efficient than similar schemes, and for the first part of the shares, has formal security.},
  archive      = {J_CAAITIT},
  author       = {Massoud Hadian Dehkordi and Seyed Taghi Farahi and Samaneh Mashhadi},
  doi          = {10.1049/cit2.12271},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {388-410},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A verifiable essential secret image sharing scheme based on HLRs (VESIS-(t, s, k, n))},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale cross-domain alignment for person image
generation. <em>CAAITIT</em>, <em>9</em>(2), 374–387. (<a
href="https://doi.org/10.1049/cit2.12224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person image generation aims to generate images that maintain the original human appearance in different target poses. Recent works have revealed that the critical element in achieving this task is the alignment of appearance domain and pose domain. Previous alignment methods, such as appearance flow warping, correspondence learning and cross attention, often encounter challenges when it comes to producing fine texture details. These approaches suffer from limitations in accurately estimating appearance flows due to the lack of global receptive field. Alternatively, they can only perform cross-domain alignment on high-level feature maps with small spatial dimensions since the computational complexity increases quadratically with larger feature sizes. In this article, the significance of multi-scale alignment, in both low-level and high-level domains, for ensuring reliable cross-domain alignment of appearance and pose is demonstrated. To this end, a novel and effective method, named Multi-scale Cross-domain Alignment (MCA) is proposed. Firstly, MCA adopts global context aggregation transformer to model multi-scale interaction between pose and appearance inputs, which employs pair-wise window-based cross attention. Furthermore, leveraging the integrated global source information for each target position, MCA applies flexible flow prediction head and point correlation to effectively conduct warping and fusing for final transformed person image generation. Our proposed MCA achieves superior performance on two popular datasets than other methods, which verifies the effectiveness of our approach.},
  archive      = {J_CAAITIT},
  author       = {Liyuan Ma and Tingwei Gao and Haibin Shen and Kejie Huang},
  doi          = {10.1049/cit2.12224},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {374-387},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Multi-scale cross-domain alignment for person image generation},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Car-following strategy of intelligent connected vehicle
using extended disturbance observer adjusted by reinforcement learning.
<em>CAAITIT</em>, <em>9</em>(2), 365–373. (<a
href="https://doi.org/10.1049/cit2.12252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disturbance observer-based control method has achieved good results in the car-following scenario of intelligent and connected vehicle (ICV). However, the gain of conventional extended disturbance observer (EDO)-based control method is usually set manually rather than adjusted adaptively according to real time traffic conditions, thus declining the car-following performance. To solve this problem, a car-following strategy of ICV using EDO adjusted by reinforcement learning is proposed. Different from the conventional method, the gain of proposed strategy can be adjusted by reinforcement learning to improve its estimation accuracy. Since the “equivalent disturbance” can be compensated by EDO to a great extent, the disturbance rejection ability of the car-following method will be improved significantly. Both Lyapunov approach and numerical simulations are carried out to verify the effectiveness of the proposed method.},
  archive      = {J_CAAITIT},
  author       = {Ruidong Yan and Penghui Li and Hongbo Gao and Jin Huang and Chengbo Wang},
  doi          = {10.1049/cit2.12252},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {365-373},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Car-following strategy of intelligent connected vehicle using extended disturbance observer adjusted by reinforcement learning},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 3D reconstruction and defect pattern recognition of bonding
wire based on stereo vision. <em>CAAITIT</em>, <em>9</em>(2), 348–364.
(<a href="https://doi.org/10.1049/cit2.12240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-destructive detection of wire bonding defects in integrated circuits (IC) is critical for ensuring product quality after packaging. Image-processing-based methods do not provide a detailed evaluation of the three-dimensional defects of the bonding wire. Therefore, a method of 3D reconstruction and pattern recognition of wire defects based on stereo vision, which can achieve non-destructive detection of bonding wire defects is proposed. The contour features of bonding wires and other electronic components in the depth image is analysed to complete the 3D reconstruction of the bonding wires. Especially to filter the noisy point cloud and obtain an accurate point cloud of the bonding wire surface, a point cloud segmentation method based on spatial surface feature detection (SFD) was proposed. SFD can extract more distinct features from the bonding wire surface during the point cloud segmentation process. Furthermore, in the defect detection process, a directional discretisation descriptor with multiple local normal vectors is designed for defect pattern recognition of bonding wires. The descriptor combines local and global features of wire and can describe the spatial variation trends and structural features of wires. The experimental results show that the method can complete the 3D reconstruction and defect pattern recognition of bonding wires, and the average accuracy of defect recognition is 96.47%, which meets the production requirements of bonding wire defect detection.},
  archive      = {J_CAAITIT},
  author       = {Naigong Yu and Hongzheng Li and Qiao Xu and Ouattara Sie and Essaf Firdaous},
  doi          = {10.1049/cit2.12240},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {348-364},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {3D reconstruction and defect pattern recognition of bonding wire based on stereo vision},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rule acquisition of three-way semi-concept lattices in
formal decision context. <em>CAAITIT</em>, <em>9</em>(2), 333–347. (<a
href="https://doi.org/10.1049/cit2.12248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way concept analysis is an important tool for information processing, and rule acquisition is one of the research hotspots of three-way concept analysis. However, compared with three-way concept lattices, three-way semi-concept lattices have three-way operators with weaker constraints, which can generate more concepts. In this article, the problem of rule acquisition for three-way semi-concept lattices is discussed in general. The authors construct the finer relation of three-way semi-concept lattices, and propose a method of rule acquisition for three-way semi-concept lattices. The authors also discuss the set of decision rules and the relationships of decision rules among object-induced three-way semi-concept lattices, object-induced three-way concept lattices, classical concept lattices and semi-concept lattices. Finally, examples are provided to illustrate the validity of our conclusions.},
  archive      = {J_CAAITIT},
  author       = {Jie Zhao and Renxia Wan and Duoqian Miao and Boyang Zhang},
  doi          = {10.1049/cit2.12248},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {333-347},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Rule acquisition of three-way semi-concept lattices in formal decision context},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mixed-decomposed convolutional network: A lightweight yet
efficient convolutional neural network for ocular disease recognition.
<em>CAAITIT</em>, <em>9</em>(2), 319–332. (<a
href="https://doi.org/10.1049/cit2.12246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eye health has become a global health concern and attracted broad attention. Over the years, researchers have proposed many state-of-the-art convolutional neural networks (CNNs) to assist ophthalmologists in diagnosing ocular diseases efficiently and precisely. However, most existing methods were dedicated to constructing sophisticated CNNs, inevitably ignoring the trade-off between performance and model complexity. To alleviate this paradox, this paper proposes a lightweight yet efficient network architecture, mixed-decomposed convolutional network (MDNet), to recognise ocular diseases. In MDNet, we introduce a novel mixed-decomposed depthwise convolution method, which takes advantage of depthwise convolution and depthwise dilated convolution operations to capture low-resolution and high-resolution patterns by using fewer computations and fewer parameters. We conduct extensive experiments on the clinical anterior segment optical coherence tomography (AS-OCT), LAG, University of California San Diego, and CIFAR-100 datasets. The results show our MDNet achieves a better trade-off between the performance and model complexity than efficient CNNs including MobileNets and MixNets. Specifically, our MDNet outperforms MobileNets by 2.5% of accuracy by using 22% fewer parameters and 30% fewer computations on the AS-OCT dataset.},
  archive      = {J_CAAITIT},
  author       = {Xiaoqing Zhang and Xiao Wu and Zunjie Xiao and Lingxi Hu and Zhongxi Qiu and Qingyang Sun and Risa Higashita and Jiang Liu},
  doi          = {10.1049/cit2.12246},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {319-332},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Mixed-decomposed convolutional network: A lightweight yet efficient convolutional neural network for ocular disease recognition},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning feature alignment and dual correlation for few-shot
image classification. <em>CAAITIT</em>, <em>9</em>(2), 303–318. (<a
href="https://doi.org/10.1049/cit2.12273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot image classification is the task of classifying novel classes using extremely limited labelled samples. To perform classification using the limited samples, one solution is to learn the feature alignment (FA) information between the labelled and unlabelled sample features. Most FA methods use the feature mean as the class prototype and calculate the correlation between prototype and unlabelled features to learn an alignment strategy. However, mean prototypes tend to degenerate informative features because spatial features at the same position may not be equally important for the final classification, leading to inaccurate correlation calculations. Therefore, the authors propose an effective intraclass FA strategy that aggregates semantically similar spatial features from an adaptive reference prototype in low-dimensional feature space to obtain an informative prototype feature map for precise correlation computation. Moreover, a dual correlation module to learn the hard and soft correlations was developed by the authors. This module combines the correlation information between the prototype and unlabelled features in both the original and learnable feature spaces, aiming to produce a comprehensive cross-correlation between the prototypes and unlabelled features. Using both FA and cross-attention modules, our model can maintain informative class features and capture important shared features for classification. Experimental results on three few-shot classification benchmarks show that the proposed method outperformed related methods and resulted in a 3% performance boost in the 1-shot setting by inserting the proposed module into the related methods.},
  archive      = {J_CAAITIT},
  author       = {Xilang Huang and Seon Han Choi},
  doi          = {10.1049/cit2.12273},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {303-318},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Learning feature alignment and dual correlation for few-shot image classification},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning and human-machine trust in healthcare: A
systematic survey. <em>CAAITIT</em>, <em>9</em>(2), 286–302. (<a
href="https://doi.org/10.1049/cit2.12268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As human-machine interaction (HMI) in healthcare continues to evolve, the issue of trust in HMI in healthcare has been raised and explored. It is critical for the development and safety of healthcare that humans have proper trust in medical machines. Intelligent machines that have applied machine learning (ML) technologies continue to penetrate deeper into the medical environment, which also places higher demands on intelligent healthcare. In order to make machines play a role in HMI in healthcare more effectively and make human-machine cooperation more harmonious, the authors need to build good human-machine trust (HMT) in healthcare. This article provides a systematic overview of the prominent research on ML and HMT in healthcare. In addition, this study explores and analyses ML and three important factors that influence HMT in healthcare, and then proposes a HMT model in healthcare. Finally, general trends are summarised and issues to consider addressing in future research on HMT in healthcare are identified.},
  archive      = {J_CAAITIT},
  author       = {Han Lin and Jiatong Han and Pingping Wu and Jiangyan Wang and Juan Tu and Hao Tang and Liuning Zhu},
  doi          = {10.1049/cit2.12268},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {286-302},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Machine learning and human-machine trust in healthcare: A systematic survey},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cloud-based video streaming services: Trends, challenges,
and opportunities. <em>CAAITIT</em>, <em>9</em>(2), 265–285. (<a
href="https://doi.org/10.1049/cit2.12299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing has drastically changed the delivery and consumption of live streaming content. The designs, challenges, and possible uses of cloud computing for live streaming are studied. A comprehensive overview of the technical and business issues surrounding cloud-based live streaming is provided, including the benefits of cloud computing, the various live streaming architectures, and the challenges that live streaming service providers face in delivering high-quality, real-time services. The different techniques used to improve the performance of video streaming, such as adaptive bit-rate streaming, multicast distribution, and edge computing are discussed and the necessity of low-latency and high-quality video transmission in cloud-based live streaming is underlined. Issues such as improving user experience and live streaming service performance using cutting-edge technology, like artificial intelligence and machine learning are discussed. In addition, the legal and regulatory implications of cloud-based live streaming, including issues with network neutrality, data privacy, and content moderation are addressed. The future of cloud computing for live streaming is examined in the section that follows, and it looks at the most likely new developments in terms of trends and technology. For technology vendors, live streaming service providers, and regulators, the findings have major policy-relevant implications. Suggestions on how stakeholders should address these concerns and take advantage of the potential presented by this rapidly evolving sector, as well as insights into the key challenges and opportunities associated with cloud-based live streaming are provided.},
  archive      = {J_CAAITIT},
  author       = {Tajinder Kumar and Purushottam Sharma and Jaswinder Tanwar and Hisham Alsghier and Shashi Bhushan and Hesham Alhumyani and Vivek Sharma and Ahmed I. Alutaibi},
  doi          = {10.1049/cit2.12299},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {265-285},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Cloud-based video streaming services: Trends, challenges, and opportunities},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DeepOCL: A deep neural network for object constraint
language generation from unrestricted nature language. <em>CAAITIT</em>,
<em>9</em>(1), 250–263. (<a
href="https://doi.org/10.1049/cit2.12207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object Constraint Language (OCL) is one kind of lightweight formal specification, which is widely used for software verification and validation in NASA and Object Management Group projects. Although OCL provides a simple expressive syntax, it is hard for the developers to write correctly due to lacking knowledge of the mathematical foundations of the first-order logic, which is approximately half accurate at the first stage of development. A deep neural network named DeepOCL is proposed, which takes the unrestricted natural language as inputs and automatically outputs the best-scored OCL candidates without requiring a domain conceptual model that is compulsively required in existing rule-based generation approaches. To demonstrate the validity of our proposed approach, ablation experiments were conducted on a new sentence-aligned dataset named OCLPairs. The experiments show that the proposed DeepOCL can achieve state of the art for OCL statement generation, scored 74.30 on BLEU, and greatly outperformed experienced developers by 35.19%. The proposed approach is the first deep learning approach to generate the OCL expression from the natural language. It can be further developed as a CASE tool for the software industry.},
  archive      = {J_CAAITIT},
  author       = {Yilong Yang and Yibo Liu and Tianshu Bao and Weiru Wang and Nan Niu and Yongfeng Yin},
  doi          = {10.1049/cit2.12207},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {250-263},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {DeepOCL: A deep neural network for object constraint language generation from unrestricted nature language},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Local saliency consistency-based label inference for weakly
supervised salient object detection using scribble annotations.
<em>CAAITIT</em>, <em>9</em>(1), 239–249. (<a
href="https://doi.org/10.1049/cit2.12210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, weak supervision has received growing attention in the field of salient object detection due to the convenience of labelling. However, there is a large performance gap between weakly supervised and fully supervised salient object detectors because the scribble annotation can only provide very limited foreground/background information. Therefore, an intuitive idea is to infer annotations that cover more complete object and background regions for training. To this end, a label inference strategy is proposed based on the assumption that pixels with similar colours and close positions should have consistent labels. Specifically, k-means clustering algorithm was first performed on both colours and coordinates of original annotations, and then assigned the same labels to points having similar colours with colour cluster centres and near coordinate cluster centres. Next, the same annotations for pixels with similar colours within each kernel neighbourhood was set further. Extensive experiments on six benchmarks demonstrate that our method can significantly improve the performance and achieve the state-of-the-art results.},
  archive      = {J_CAAITIT},
  author       = {Shuo Zhao and Peng Cui and Jing Shen and Haibo Liu},
  doi          = {10.1049/cit2.12210},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {239-249},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Local saliency consistency-based label inference for weakly supervised salient object detection using scribble annotations},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A privacy-preserving method for publishing data with
multiple sensitive attributes. <em>CAAITIT</em>, <em>9</em>(1), 222–238.
(<a href="https://doi.org/10.1049/cit2.12199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The overgeneralisation may happen because most studies on data publishing for multiple sensitive attributes (SAs) have not considered the personalised privacy requirement. Furthermore, sensitive information disclosure may also be caused by these personalised requirements. To address the matter, this article develops a personalised data publishing method for multiple SAs. According to the requirements of individuals, the new method partitions SAs values into two categories: private values and public values, and breaks the association between them for privacy guarantees. For the private values, this paper takes the process of anonymisation, while the public values are released without this process. An algorithm is designed to achieve the privacy mode, where the selectivity is determined by the sensitive value frequency and undesirable objects. The experimental results show that the proposed method can provide more information utility when compared with previous methods. The theoretic analyses and experiments also indicate that the privacy can be guaranteed even though the public values are known to an adversary. The overgeneralisation and privacy breach caused by the personalised requirement can be avoided by the new method.},
  archive      = {J_CAAITIT},
  author       = {Tong Yi and Minyong Shi and Wenqian Shang and Haibin Zhu},
  doi          = {10.1049/cit2.12199},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {222-238},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A privacy-preserving method for publishing data with multiple sensitive attributes},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-modal knowledge graph inference via media convergence
and logic rule. <em>CAAITIT</em>, <em>9</em>(1), 211–221. (<a
href="https://doi.org/10.1049/cit2.12217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Media convergence works by processing information from different modalities and applying them to different domains. It is difficult for the conventional knowledge graph to utilise multi-media features because the introduction of a large amount of information from other modalities reduces the effectiveness of representation learning and makes knowledge graph inference less effective. To address the issue, an inference method based on Media Convergence and Rule-guided Joint Inference model (MCRJI) has been proposed. The authors not only converge multi-media features of entities but also introduce logic rules to improve the accuracy and interpretability of link prediction. First, a multi-headed self-attention approach is used to obtain the attention of different media features of entities during semantic synthesis. Second, logic rules of different lengths are mined from knowledge graph to learn new entity representations. Finally, knowledge graph inference is performed based on representing entities that converge multi-media features. Numerous experimental results show that MCRJI outperforms other advanced baselines in using multi-media features and knowledge graph inference, demonstrating that MCRJI provides an excellent approach for knowledge graph inference with converged multi-media features.},
  archive      = {J_CAAITIT},
  author       = {Feng Lin and Dongmei Li and Wenbin Zhang and Dongsheng Shi and Yuanzhou Jiao and Qianzhong Chen and Yiying Lin and Wentao Zhu},
  doi          = {10.1049/cit2.12217},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {211-221},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Multi-modal knowledge graph inference via media convergence and logic rule},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Double integral-enhanced zeroing neural network with linear
noise rejection for time-varying matrix inverse. <em>CAAITIT</em>,
<em>9</em>(1), 197–210. (<a
href="https://doi.org/10.1049/cit2.12161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In engineering fields, time-varying matrix inversion (TVMI) issue is often encountered. Zeroing neural network (ZNN) has been extensively employed to resolve the TVMI problem. Nevertheless, the original ZNN (OZNN) and the integral-enhanced ZNN (IEZNN) usually fail to deal with the TVMI problem under unbounded noises, such as linear noises. Therefore, a neural network model that can handle the TVMI under linear noise interference is urgently needed. This paper develops a double integral-enhanced ZNN (DIEZNN) model based on a novel integral-type design formula with inherent linear-noise tolerance. Moreover, its convergence and robustness are verified by derivation strictly. For comparison and verification, the OZNN and the IEZNN models are adopted to resolve the TVMI under multiple identical noise environments. The experiments proved that the DIEZNN model has excellent advantages in solving TVMI problems under linear noises. In general, the DIEZNN model is an innovative work and is proposed for the first time. Satisfyingly, the errors of DIEZNN are always less than 1 × 10 −3 under linear noises, whereas the error norms of OZNN and IEZNN models are not convergent to zero. In addition, these models are applied to the control of the controllable permanent magnet synchronous motor chaotic system to indicate the superiority of the DIEZNN.},
  archive      = {J_CAAITIT},
  author       = {Bolin Liao and Luyang Han and Xinwei Cao and Shuai Li and Jianfeng Li},
  doi          = {10.1049/cit2.12161},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {197-210},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Double integral-enhanced zeroing neural network with linear noise rejection for time-varying matrix inverse},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep koopman operator-based modelling approach for
long-term prediction of dynamics with pixel-level measurements.
<em>CAAITIT</em>, <em>9</em>(1), 178–196. (<a
href="https://doi.org/10.1049/cit2.12149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although previous studies have made some clear leap in learning latent dynamics from high-dimensional representations, the performances in terms of accuracy and inference time of long-term model prediction still need to be improved. In this study, a deep convolutional network based on the Koopman operator (CKNet) is proposed to model non-linear systems with pixel-level measurements for long-term prediction. CKNet adopts an autoencoder network architecture, consisting of an encoder to generate latent states and a linear dynamical model (i.e., the Koopman operator) which evolves in the latent state space spanned by the encoder. The decoder is used to recover images from latent states. According to a multi-step ahead prediction loss function, the system matrices for approximating the Koopman operator are trained synchronously with the autoencoder in a mini-batch manner. In this manner, gradients can be synchronously transmitted to both the system matrices and the autoencoder to help the encoder self-adaptively tune the latent state space in the training process, and the resulting model is time-invariant in the latent space. Therefore, the proposed CKNet has the advantages of less inference time and high accuracy for long-term prediction. Experiments are performed on OpenAI Gym and Mujoco environments, including two and four non-linear forced dynamical systems with continuous action spaces. The experimental results show that CKNet has strong long-term prediction capabilities with sufficient precision.},
  archive      = {J_CAAITIT},
  author       = {Yongqian Xiao and Zixin Tang and Xin Xu and Xinglong Zhang and Yifei Shi},
  doi          = {10.1049/cit2.12149},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {178-196},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A deep koopman operator-based modelling approach for long-term prediction of dynamics with pixel-level measurements},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Noise-tolerate and adaptive coefficient zeroing neural
network for solving dynamic matrix square root. <em>CAAITIT</em>,
<em>9</em>(1), 167–177. (<a
href="https://doi.org/10.1049/cit2.12183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The solving of dynamic matrix square root (DMSR) problems is frequently encountered in many scientific and engineering fields. Although the original zeroing neural network is powerful for solving the DMSR, it cannot vanish the influence of the noise perturbations, and its constant-coefficient design scheme cannot accelerate the convergence speed. Therefore, a noise-tolerate and adaptive coefficient zeroing neural network (NTACZNN) is raised to enhance the robust noise immunity performance and accelerate the convergence speed simultaneously. Then, the global convergence and robustness of the proposed NTACZNN are theoretically analysed under an ideal environment and noise-perturbed circumstances. Furthermore, some illustrative simulation examples are designed and performed in order to substantiate the efficacy and advantage of the NTACZNN for the DMSR problem solution. Compared with some existing ZNNs, the proposed NTACZNN possesses advanced performance in terms of noise tolerance, solution accuracy, and convergence rate.},
  archive      = {J_CAAITIT},
  author       = {Xiuchun Xiao and Chengze Jiang and Qixiang Mei and Yudong Zhang},
  doi          = {10.1049/cit2.12183},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {167-177},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Noise-tolerate and adaptive coefficient zeroing neural network for solving dynamic matrix square root},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep convolutional neural network for diabetic retinopathy
detection via mining local and long-range dependence. <em>CAAITIT</em>,
<em>9</em>(1), 153–166. (<a
href="https://doi.org/10.1049/cit2.12155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR), the main cause of irreversible blindness, is one of the most common complications of diabetes. At present, deep convolutional neural networks have achieved promising performance in automatic DR detection tasks. The convolution operation of methods is a local cross-correlation operation, whose receptive field determines the size of the local neighbourhood for processing. However, for retinal fundus photographs, there is not only the local information but also long-distance dependence between the lesion features (e.g. hemorrhages and exudates) scattered throughout the whole image. The proposed method incorporates correlations between long-range patches into the deep learning framework to improve DR detection. Patch-wise relationships are used to enhance the local patch features since lesions of DR usually appear as plaques. The Long-Range unit in the proposed network with a residual structure can be flexibly embedded into other trained networks. Extensive experimental results demonstrate that the proposed approach can achieve higher accuracy than existing state-of-the-art models on Messidor and EyePACS datasets.},
  archive      = {J_CAAITIT},
  author       = {Xiaoling Luo and Wei Wang and Yong Xu and Zhihui Lai and Xiaopeng Jin and Bob Zhang and David Zhang},
  doi          = {10.1049/cit2.12155},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {153-166},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A deep convolutional neural network for diabetic retinopathy detection via mining local and long-range dependence},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Audio–visual keyword transformer for unconstrained
sentence-level keyword spotting. <em>CAAITIT</em>, <em>9</em>(1),
142–152. (<a href="https://doi.org/10.1049/cit2.12212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most effective methods to improve the accuracy and robustness of speech tasks, the audio–visual fusion approach has recently been introduced into the field of Keyword Spotting (KWS). However, existing audio–visual keyword spotting models are limited to detecting isolated words, while keyword spotting for unconstrained speech is still a challenging problem. To this end, an Audio–Visual Keyword Transformer (AVKT) network is proposed to spot keywords in unconstrained video clips. The authors present a transformer classifier with learnable CLS tokens to extract distinctive keyword features from the variable-length audio and visual inputs. The outputs of audio and visual branches are combined in a decision fusion module. As humans can easily notice whether a keyword appears in a sentence or not, our AVKT network can detect whether a video clip with a spoken sentence contains a pre-specified keyword. Moreover, the position of the keyword is localised in the attention map without additional position labels. Experimental results on the LRS2-KWS dataset and our newly collected PKU-KWS dataset show that the accuracy of AVKT exceeded 99% in clean scenes and 85% in extremely noisy conditions. The code is available at https://github.com/jialeren/AVKT .},
  archive      = {J_CAAITIT},
  author       = {Yidi Li and Jiale Ren and Yawei Wang and Guoquan Wang and Xia Li and Hong Liu},
  doi          = {10.1049/cit2.12212},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {142-152},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Audio–visual keyword transformer for unconstrained sentence-level keyword spotting},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hyperspectral image super resolution using deep internal and
self-supervised learning. <em>CAAITIT</em>, <em>9</em>(1), 128–141. (<a
href="https://doi.org/10.1049/cit2.12285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By automatically learning the priors embedded in images with powerful modelling capabilities, deep learning-based algorithms have recently made considerable progress in reconstructing the high-resolution hyperspectral (HR-HS) image. With previously collected large-amount of external data, these methods are intuitively realised under the full supervision of the ground-truth data. Thus, the database construction in merging the low-resolution (LR) HS (LR-HS) and HR multispectral (MS) or RGB image research paradigm, commonly named as HSI SR, requires collecting corresponding training triplets: HR-MS (RGB), LR-HS and HR-HS image simultaneously, and often faces difficulties in reality. The learned models with the training datasets collected simultaneously under controlled conditions may significantly degrade the HSI super-resolved performance to the real images captured under diverse environments. To handle the above-mentioned limitations, the authors propose to leverage the deep internal and self-supervised learning to solve the HSI SR problem. The authors advocate that it is possible to train a specific CNN model at test time, called as deep internal learning (DIL), by on-line preparing the training triplet samples from the observed LR-HS/HR-MS (or RGB) images and the down-sampled LR-HS version. However, the number of the training triplets extracted solely from the transformed data of the observation itself is extremely few particularly for the HSI SR tasks with large spatial upscale factors, which would result in limited reconstruction performance. To solve this problem, the authors further exploit deep self-supervised learning (DSL) by considering the observations as the unlabelled training samples. Specifically, the degradation modules inside the network were elaborated to realise the spatial and spectral down-sampling procedures for transforming the generated HR-HS estimation to the high-resolution RGB/LR-HS approximation, and then the reconstruction errors of the observations were formulated for measuring the network modelling performance. By consolidating the DIL and DSL into a unified deep framework, the authors construct a more robust HSI SR method without any prior training and have great potential of flexible adaptation to different settings per observation. To verify the effectiveness of the proposed approach, extensive experiments have been conducted on two benchmark HS datasets, including the CAVE and Harvard datasets, and demonstrate the great performance gain of the proposed method over the state-of-the-art methods.},
  archive      = {J_CAAITIT},
  author       = {Zhe Liu and Xian-Hua Han},
  doi          = {10.1049/cit2.12285},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {128-141},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Hyperspectral image super resolution using deep internal and self-supervised learning},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Sparse representation scheme with enhanced medium pixel
intensity for face recognition. <em>CAAITIT</em>, <em>9</em>(1),
116–127. (<a href="https://doi.org/10.1049/cit2.12247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse representation is an effective data classification algorithm that depends on the known training samples to categorise the test sample. It has been widely used in various image classification tasks. Sparseness in sparse representation means that only a few of instances selected from all training samples can effectively convey the essential class-specific information of the test sample, which is very important for classification. For deformable images such as human faces, pixels at the same location of different images of the same subject usually have different intensities. Therefore, extracting features and correctly classifying such deformable objects is very hard. Moreover, the lighting, attitude and occlusion cause more difficulty. Considering the problems and challenges listed above, a novel image representation and classification algorithm is proposed. First, the authors’ algorithm generates virtual samples by a non-linear variation method. This method can effectively extract the low-frequency information of space-domain features of the original image, which is very useful for representing deformable objects. The combination of the original and virtual samples is more beneficial to improve the classification performance and robustness of the algorithm. Thereby, the authors’ algorithm calculates the expression coefficients of the original and virtual samples separately using the sparse representation principle and obtains the final score by a designed efficient score fusion scheme. The weighting coefficients in the score fusion scheme are set entirely automatically. Finally, the algorithm classifies the samples based on the final scores. The experimental results show that our method performs better classification than conventional sparse representation algorithms.},
  archive      = {J_CAAITIT},
  author       = {Xuexue Zhang and Yongjun Zhang and Zewei Wang and Wei Long and Weihao Gao and Bob Zhang},
  doi          = {10.1049/cit2.12247},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {116-127},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Sparse representation scheme with enhanced medium pixel intensity for face recognition},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Image enhancement with intensity transformation on embedding
space. <em>CAAITIT</em>, <em>9</em>(1), 101–115. (<a
href="https://doi.org/10.1049/cit2.12279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, an image enhancement approach, which learns the global transformation function using deep neural networks, has gained attention. However, many existing methods based on this approach have a limitation: their transformation functions are too simple to imitate complex colour transformations between low-quality images and manually retouched high-quality images. In order to address this limitation, a simple yet effective approach for image enhancement is proposed. The proposed algorithm based on the channel-wise intensity transformation is designed. However, this transformation is applied to the learnt embedding space instead of specific colour spaces and then return enhanced features to colours. To this end, the authors define the continuous intensity transformation (CIT) to describe the mapping between input and output intensities on the embedding space. Then, the enhancement network is developed, which produces multi-scale feature maps from input images, derives the set of transformation functions, and performs the CIT to obtain enhanced images. Extensive experiments on the MIT-Adobe 5K dataset demonstrate that the authors’ approach improves the performance of conventional intensity transforms on colour space metrics. Specifically, the authors achieved a 3.8% improvement in peak signal-to-noise ratio, a 1.8% improvement in structual similarity index measure, and a 27.5% improvement in learned perceptual image patch similarity. Also, the authors’ algorithm outperforms state-of-the-art alternatives on three image enhancement datasets: MIT-Adobe 5K, Low-Light, and Google HDR+.},
  archive      = {J_CAAITIT},
  author       = {Hanul Kim and Yeji Jeon and Yeong Jun Koh},
  doi          = {10.1049/cit2.12279},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {101-115},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Image enhancement with intensity transformation on embedding space},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic segmentation via pixel-to-center similarity
calculation. <em>CAAITIT</em>, <em>9</em>(1), 87–100. (<a
href="https://doi.org/10.1049/cit2.12245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the fully convolutional network has achieved great success in semantic segmentation, lots of works have been proposed to extract discriminative pixel representations. However, the authors observe that existing methods still suffer from two typical challenges: (i) The intra-class feature variation between different scenes may be large, leading to the difficulty in maintaining the consistency between same-class pixels from different scenes; (ii) The inter-class feature distinction in the same scene could be small, resulting in the limited performance to distinguish different classes in each scene. The authors first rethink semantic segmentation from a perspective of similarity between pixels and class centers. Each weight vector of the segmentation head represents its corresponding semantic class in the whole dataset, which can be regarded as the embedding of the class center. Thus, the pixel-wise classification amounts to computing similarity in the final feature space between pixels and the class centers. Under this novel view, the authors propose a Class Center Similarity (CCS) layer to address the above-mentioned challenges by generating adaptive class centers conditioned on each scenes and supervising the similarities between class centers. The CCS layer utilises the Adaptive Class Center Module to generate class centers conditioned on each scene, which adapt the large intra-class variation between different scenes. Specially designed Class Distance Loss (CD Loss) is introduced to control both inter-class and intra-class distances based on the predicted center-to-center and pixel-to-center similarity. Finally, the CCS layer outputs the processed pixel-to-center similarity as the segmentation prediction. Extensive experiments demonstrate that our model performs favourably against the state-of-the-art methods.},
  archive      = {J_CAAITIT},
  author       = {Dongyue Wu and Zilin Guo and Aoyan Li and Changqian Yu and Nong Sang and Changxin Gao},
  doi          = {10.1049/cit2.12245},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {87-100},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Semantic segmentation via pixel-to-center similarity calculation},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extraction of intersecting palm-vein and palmprint features
for cancellable identity verification. <em>CAAITIT</em>, <em>9</em>(1),
69–86. (<a href="https://doi.org/10.1049/cit2.12277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel method based on the cross-modality intersecting features of the palm-vein and the palmprint is proposed for identity verification. Capitalising on the unique geometrical relationship between the two biometric modalities, the cross-modality intersecting points provides a stable set of features for identity verification. To facilitate flexibility in template changes, a template transformation is proposed. While maintaining non-invertibility, the template transformation allows transformation sizes beyond that offered by the conventional means. Extensive experiments using three public palm databases are conducted to verify the effectiveness the proposed system for identity recognition.},
  archive      = {J_CAAITIT},
  author       = {Jaekwon Lee and Beom-Seok Oh and Kar-Ann Toh},
  doi          = {10.1049/cit2.12277},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {69-86},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Extraction of intersecting palm-vein and palmprint features for cancellable identity verification},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning to represent 2D human face with mathematical model.
<em>CAAITIT</em>, <em>9</em>(1), 54–68. (<a
href="https://doi.org/10.1049/cit2.12284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to represent a human face pattern? While it is presented in a continuous way in human visual system, computers often store and process it in a discrete manner with 2D arrays of pixels. The authors attempt to learn a continuous surface representation for face image with explicit function. First, an explicit model (EmFace) for human face representation is proposed in the form of a finite sum of mathematical terms, where each term is an analytic function element. Further, to estimate the unknown parameters of EmFace, a novel neural network, EmNet, is designed with an encoder-decoder structure and trained from massive face images, where the encoder is defined by a deep convolutional neural network and the decoder is an explicit mathematical expression of EmFace. The authors demonstrate that our EmFace represents face image more accurate than the comparison method, with an average mean square error of 0.000888, 0.000936, 0.000953 on LFW, IARPA Janus Benchmark-B, and IJB-C datasets. Visualisation results show that, EmFace has a higher representation performance on faces with various expressions, postures, and other factors. Furthermore, EmFace achieves reasonable performance on several face image processing tasks, including face image restoration, denoising, and transformation.},
  archive      = {J_CAAITIT},
  author       = {Liping Zhang and Weijun Li and Linjun Sun and Lina Yu and Xin Ning and Xiaoli Dong},
  doi          = {10.1049/cit2.12284},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {54-68},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Learning to represent 2D human face with mathematical model},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust zero-watermarking algorithm based on discrete wavelet
transform and daisy descriptors for encrypted medical image.
<em>CAAITIT</em>, <em>9</em>(1), 40–53. (<a
href="https://doi.org/10.1049/cit2.12282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the intricate network environment, the secure transmission of medical images faces challenges such as information leakage and malicious tampering, significantly impacting the accuracy of disease diagnoses by medical professionals. To address this problem, the authors propose a robust feature watermarking algorithm for encrypted medical images based on multi-stage discrete wavelet transform (DWT), Daisy descriptor, and discrete cosine transform (DCT). The algorithm initially encrypts the original medical image through DWT-DCT and Logistic mapping. Subsequently, a 3-stage DWT transformation is applied to the encrypted medical image, with the centre point of the LL3 sub-band within its low-frequency component serving as the sampling point. The Daisy descriptor matrix for this point is then computed. Finally, a DCT transformation is performed on the Daisy descriptor matrix, and the low-frequency portion is processed using the perceptual hashing algorithm to generate a 32-bit binary feature vector for the medical image. This scheme utilises cryptographic knowledge and zero-watermarking technique to embed watermarks without modifying medical images and can extract the watermark from test images without the original image, which meets the basic requirements of medical image watermarking. The embedding and extraction of watermarks are accomplished in a mere 0.160 and 0.411s, respectively, with minimal computational overhead. Simulation results demonstrate the robustness of the algorithm against both conventional attacks and geometric attacks, with a notable performance in resisting rotation attacks.},
  archive      = {J_CAAITIT},
  author       = {Yiyi Yuan and Jingbing Li and Jing Liu and Uzair Aslam Bhatti and Zilong Liu and Yen-wei Chen},
  doi          = {10.1049/cit2.12282},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {40-53},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Robust zero-watermarking algorithm based on discrete wavelet transform and daisy descriptors for encrypted medical image},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transfer learning from t1-weighted to t2-weighted magnetic
resonance sequences for brain image segmentation. <em>CAAITIT</em>,
<em>9</em>(1), 26–39. (<a
href="https://doi.org/10.1049/cit2.12270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance (MR) imaging is a widely employed medical imaging technique that produces detailed anatomical images of the human body. The segmentation of MR images plays a crucial role in medical image analysis, as it enables accurate diagnosis, treatment planning, and monitoring of various diseases and conditions. Due to the lack of sufficient medical images, it is challenging to achieve an accurate segmentation, especially with the application of deep learning networks. The aim of this work is to study transfer learning from T1-weighted (T1-w) to T2-weighted (T2-w) MR sequences to enhance bone segmentation with minimal required computation resources. With the use of an excitation-based convolutional neural networks, four transfer learning mechanisms are proposed: transfer learning without fine tuning, open fine tuning, conservative fine tuning, and hybrid transfer learning. Moreover, a multi-parametric segmentation model is proposed using T2-w MR as an intensity-based augmentation technique. The novelty of this work emerges in the hybrid transfer learning approach that overcomes the overfitting issue and preserves the features of both modalities with minimal computation time and resources. The segmentation results are evaluated using 14 clinical 3D brain MR and CT images. The results reveal that hybrid transfer learning is superior for bone segmentation in terms of performance and computation time with DSCs of 0.5393 ± 0.0007. Although T2-w-based augmentation has no significant impact on the performance of T1-w MR segmentation, it helps in improving T2-w MR segmentation and developing a multi-sequences segmentation model.},
  archive      = {J_CAAITIT},
  author       = {Imene Mecheter and Maysam Abbod and Habib Zaidi and Abbes Amira},
  doi          = {10.1049/cit2.12270},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {26-39},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Transfer learning from t1-weighted to t2-weighted magnetic resonance sequences for brain image segmentation},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature extraction and learning approaches for cancellable
biometrics: A survey. <em>CAAITIT</em>, <em>9</em>(1), 4–25. (<a
href="https://doi.org/10.1049/cit2.12283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric recognition is a widely used technology for user authentication. In the application of this technology, biometric security and recognition accuracy are two important issues that should be considered. In terms of biometric security, cancellable biometrics is an effective technique for protecting biometric data. Regarding recognition accuracy, feature representation plays a significant role in the performance and reliability of cancellable biometric systems. How to design good feature representations for cancellable biometrics is a challenging topic that has attracted a great deal of attention from the computer vision community, especially from researchers of cancellable biometrics. Feature extraction and learning in cancellable biometrics is to find suitable feature representations with a view to achieving satisfactory recognition performance, while the privacy of biometric data is protected. This survey informs the progress, trend and challenges of feature extraction and learning for cancellable biometrics, thus shedding light on the latest developments and future research of this area.},
  archive      = {J_CAAITIT},
  author       = {Wencheng Yang and Song Wang and Jiankun Hu and Xiaohui Tao and Yan Li},
  doi          = {10.1049/cit2.12283},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {4-25},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Feature extraction and learning approaches for cancellable biometrics: A survey},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
