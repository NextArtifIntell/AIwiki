<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aim---59">AIM - 59</h2>
<ul>
<li><details>
<summary>
(2024). Deceptively simple: An outsider’s perspective on natural
language processing. <em>AIM</em>, <em>45</em>(4), 569–582. (<a
href="https://doi.org/10.1002/aaai.12204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article highlights a collection of ideas with an underlying deceptive simplicity that addresses several practical challenges in computational social science and generative AI safety. These ideas lead to (1) an interpretable and quantifiable framework for political polarization; (2) a language identifier robust to noisy social media text settings; (3) a cross-lingual semantic sampler that harnesses code-switching; and (4) a bias audit framework that uncovers shocking racism, antisemitism, misogyny, and other biases in a wide suite of large language models.},
  archive      = {J_AIM},
  author       = {Ashiqur R. KhudaBukhsh},
  doi          = {10.1002/aaai.12204},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {569-582},
  shortjournal = {AI Mag.},
  title        = {Deceptively simple: An outsider&#39;s perspective on natural language processing},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning representations for robust human–robot interaction.
<em>AIM</em>, <em>45</em>(4), 561–568. (<a
href="https://doi.org/10.1002/aaai.12197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article summarizes the author&#39;s presentation in the New Faculty Highlight at the Thirty-Eighth AAAI Conference on Artificial Intelligence. It discusses the desired properties of representations for enabling robust human–robot interaction. Examples from the author&#39;s work are presented to show how to build these properties into models for performing tasks with natural language guidance and engaging in social interactions with other agents.},
  archive      = {J_AIM},
  author       = {Yen-Ling Kuo},
  doi          = {10.1002/aaai.12197},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {561-568},
  shortjournal = {AI Mag.},
  title        = {Learning representations for robust human–robot interaction},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-efficient graph learning: Problems, progress, and
prospects. <em>AIM</em>, <em>45</em>(4), 549–560. (<a
href="https://doi.org/10.1002/aaai.12200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-structured data, ranging from social networks to financial transaction networks, from citation networks to gene regulatory networks, have been widely used for modeling a myriad of real-world systems. As a prevailing model architecture to model graph-structured data, graph neural networks (GNNs) have drawn much attention in both academic and industrial communities in the past decades. Despite their success in different graph learning tasks, existing methods usually rely on learning from “big” data, requiring a large amount of labeled data for model training. However, it is common that real-world graphs are associated with “small” labeled data as data annotation and labeling on graphs is always time and resource-consuming. Therefore, it is imperative to investigate graph machine learning (graph ML) with low-cost human supervision for low-resource settings where limited or even no labeled data is available. This paper investigates a new research field—data-efficient graph learning, which aims to push forward the performance boundary of graph ML models with different kinds of low-cost supervision signals. Specifically, we outline the fundamental research problems, review the current progress, and discuss the future prospects of data-efficient graph learning, aiming to illuminate the path for subsequent research in this field.},
  archive      = {J_AIM},
  author       = {Kaize Ding and Yixin Liu and Chuxu Zhang and Jianling Wang},
  doi          = {10.1002/aaai.12200},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {549-560},
  shortjournal = {AI Mag.},
  title        = {Data-efficient graph learning: Problems, progress, and prospects},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of out-of-distribution generalization for graph
machine learning from a causal view. <em>AIM</em>, <em>45</em>(4),
537–548. (<a href="https://doi.org/10.1002/aaai.12202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph machine learning (GML) has been successfully applied across a wide range of tasks. Nonetheless, GML faces significant challenges in generalizing over out-of-distribution (OOD) data, which raises concerns about its wider applicability. Recent advancements have underscored the crucial role of causality-driven approaches in overcoming these generalization challenges. Distinct from traditional GML methods that primarily rely on statistical dependencies, causality-focused strategies delve into the underlying causal mechanisms of data generation and model prediction, thus significantly improving the generalization of GML across different environments. This paper offers a thorough review of recent progress in causality-involved GML generalization. We elucidate the fundamental concepts of employing causality to enhance graph model generalization and categorize the various approaches, providing detailed descriptions of their methodologies and the connections among them. Furthermore, we explore the incorporation of causality in other related important areas of trustworthy GML, such as explanation, fairness, and robustness. Concluding with a discussion on potential future research directions, this review seeks to articulate the continuing development and future potential of causality in enhancing the trustworthiness of GML.},
  archive      = {J_AIM},
  author       = {Jing Ma},
  doi          = {10.1002/aaai.12202},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {537-548},
  shortjournal = {AI Mag.},
  title        = {A survey of out-of-distribution generalization for graph machine learning from a causal view},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging AI to improve health information access in the
world’s largest maternal mobile health program. <em>AIM</em>,
<em>45</em>(4), 526–536. (<a
href="https://doi.org/10.1002/aaai.12206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harnessing the wide-spread availability of cell phones, many nonprofits have launched mobile health (mHealth) programs to deliver information via voice or text to beneficiaries in underserved communities, with maternal and infant health being a key area of such mHealth programs. Unfortunately, dwindling listenership is a major challenge, requiring targeted interventions using limited resources. This paper focuses on Kilkari, the world&#39;s largest mHealth program for maternal and child care – with over 3 million active subscribers at a time – launched by India&#39;s Ministry of Health and Family Welfare (MoHFW) and run by the non-profit ARMMAN. We present a system called CHAHAK that aims to reduce automated dropouts as well as boost engagement with the program through the strategic allocation of interventions to beneficiaries. Past work in a similar domain has focused on a much smaller scale mHealth program and used markovian restless multiarmed bandits to optimize a single limited intervention resource. However, this paper demonstrates the challenges in adopting a markovian approach in Kilkari; therefore, CHAHAK instead relies on non-markovian time-series restless bandits and optimizes multiple interventions to improve listenership. We use real Kilkari data from the Odisha state in India to show CHAHAK&#39;s effectiveness in harnessing multiple interventions to boost listenership, benefiting marginalized communities. When deployed CHAHAK will assist the largest maternal mHealth program to date.},
  archive      = {J_AIM},
  author       = {Shresth Verma and Arshika Lalan and Paula Rodriguez Diaz and Panayiotis Danassis and Amrita Mahale and Kumar Madhu Sudan and Aparna Hegde and Milind Tambe and Aparna Taneja},
  doi          = {10.1002/aaai.12206},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {526-536},
  shortjournal = {AI Mag.},
  title        = {Leveraging AI to improve health information access in the world&#39;s largest maternal mobile health program},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The virtual driving instructor: Multi-agent system
collaborating via knowledge graph for scalable driver education.
<em>AIM</em>, <em>45</em>(4), 514–525. (<a
href="https://doi.org/10.1002/aaai.12201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces the design, development, and deployment of a virtual driving instructor (VDI) for enhanced driver education. The VDI provides personalized, real-time feedback to students in a driving simulator, addressing some of the limitations of traditional driver instruction. Employing a hybrid AI system, the VDI combines rule-based agents, learning-based agents, knowledge graphs, and Bayesian networks to assess and monitor student performance in a comprehensive manner. Implemented in multiple simulators at a driving school in Norway, the system aims to leverage AI and driving simulation to improve both the learning experience and the efficiency of instruction. Initial feedback from students has been largely positive, highlighting the effectiveness of this integration while also pointing to areas for further improvement. This marks a significant stride in infusing technology into driver education, offering a scalable and efficient approach to instruction.},
  archive      = {J_AIM},
  author       = {Johannes Rehm and Irina Reshodko and Stian Zimmermann Børresen and Odd Erik Gundersen},
  doi          = {10.1002/aaai.12201},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {514-525},
  shortjournal = {AI Mag.},
  title        = {The virtual driving instructor: Multi-agent system collaborating via knowledge graph for scalable driver education},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A submodular optimization approach to trustworthy loan
approval automation. <em>AIM</em>, <em>45</em>(4), 502–513. (<a
href="https://doi.org/10.1002/aaai.12195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of finance, the underwriting process is an essential step in evaluating every loan application. During this stage, the borrowers&#39; creditworthiness and ability to repay the loan are assessed to ultimately decide whether to approve the loan application. One of the core components of underwriting is credit scoring, in which the probability of default is estimated. As such, there has been significant progress in enhancing the predictive accuracy of credit scoring models through the use of machine learning, but there still exists a need to ultimately construct an approval rule that takes into consideration additional criteria beyond the score itself. This construction process is traditionally done manually to ensure that the approval rule remains interpretable to humans. In this paper, we outline an automated system for optimizing a rule-based system for approving loan applications, which has been deployed at Hyundai Capital Services (HCS). The main challenge lays in creating a high-quality rule base that is simultaneously simple enough to be interpretable by risk analysts as well as customers, since the approval decision should be easily understandable. We addressed this challenge through principled submodular optimization. The deployment of our system has led to a 14% annual growth in the volume of loan services at HCS, while maintaining the target bad rate, and has resulted in the approval of customers who might have otherwise been rejected.},
  archive      = {J_AIM},
  author       = {Kyungsik Lee and Hana Yoo and Sumin Shin and Wooyoung Kim and Yeonung Baek and Hyunjin Kang and Jaehyun Kim and Kee-Eung Kim},
  doi          = {10.1002/aaai.12195},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {502-513},
  shortjournal = {AI Mag.},
  title        = {A submodular optimization approach to trustworthy loan approval automation},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fusing remote and social sensing data for flood impact
mapping. <em>AIM</em>, <em>45</em>(4), 486–501. (<a
href="https://doi.org/10.1002/aaai.12196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The absence of comprehensive situational awareness information poses a significant challenge for humanitarian organizations during their response efforts. We present Flood Insights, an end-to-end system, that ingests data from multiple nontraditional data sources such as remote sensing, social sensing, and geospatial data. We employ state-of-the-art natural language processing and computer vision models to identify flood exposure, ground-level damage and flood reports, and most importantly, urgent needs of affected people. We deploy and test the system during a recent real-world catastrophe, the 2022 Pakistan floods, to surface critical situational and damage information at the district level. We validated the system&#39;s effectiveness through various statistical analyses using official ground-truth data, showcasing its strong performance and explanatory power of integrating multiple data sources. Moreover, the system was commended by the United Nations Development Programme stationed in Pakistan, as well as local authorities, for pinpointing hard-hit districts and enhancing disaster response.},
  archive      = {J_AIM},
  author       = {Zainab Akhtar and Umair Qazi and Aya El-Sakka and Rizwan Sadiq and Ferda Ofli and Muhammad Imran},
  doi          = {10.1002/aaai.12196},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {486-501},
  shortjournal = {AI Mag.},
  title        = {Fusing remote and social sensing data for flood impact mapping},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DCV2I: Leveraging deep vision models to support geographers’
visual interpretation in dune segmentation. <em>AIM</em>,
<em>45</em>(4), 472–485. (<a
href="https://doi.org/10.1002/aaai.12199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual interpretation is extremely important in human geography as the primary technique for geographers to use photograph data in identifying, classifying, and quantifying geographic and topological objects or regions. However, it is also time-consuming and requires overwhelming manual effort from professional geographers. This paper describes our interdisciplinary team&#39;s efforts in integrating computer vision models with geographers&#39; visual image interpretation process to reduce their workload in interpreting images. Focusing on the dune segmentation task, we proposed an approach called DCV 2 ⁢ I ${\bf DCV}^2{\bf I}$ featuring a deep dune segmentation model to identify dunes and label their ranges in an automated way. By developing a tool to connect our model with ArcGIS—one of the most popular workbenches for visual interpretation, geographers can further refine the automatically generated dune segmentation on images without learning any CV or deep learning techniques. Our approach thus realized a noninvasive change to geographers&#39; visual interpretation routines, reducing their manual efforts while incurring minimal interruptions to their work routines and tools they are familiar with. Deployment with a leading Chinese geography research institution demonstrated the potential of in supporting geographers in researching and solving drylands desertification.},
  archive      = {J_AIM},
  author       = {Anqi Lu and Zifeng Wu and Zheng Jiang and Wei Wang and Eerdun Hasi and Yi Wang},
  doi          = {10.1002/aaai.12199},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {472-485},
  shortjournal = {AI Mag.},
  title        = {DCV2I: Leveraging deep vision models to support geographers&#39; visual interpretation in dune segmentation},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-assisted research collaboration with open data for fair
and effective response to call for proposals. <em>AIM</em>,
<em>45</em>(4), 457–471. (<a
href="https://doi.org/10.1002/aaai.12203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building teams and promoting collaboration are two very common business activities. An example of these are seen in the TeamingForFunding problem, where research institutions and researchers are interested to identify collaborative opportunities when applying to funding agencies in response to latter&#39;s calls for proposals. We describe a novel deployed system to recommend teams using a variety of Artificial Intelligence (AI) methods, such that (1) each team achieves the highest possible skill coverage that is demanded by the opportunity, and (2) the workload of distributing the opportunities is balanced among the candidate members. We address these questions by extracting skills latent in open data of proposal calls (demand) and researcher profiles (supply), normalizing them using taxonomies, and creating efficient algorithms that match demand to supply. We create teams to maximize goodness along a novel metric balancing short- and long-term objectives. We evaluate our system in two diverse settings in US and India of researchers and proposal calls, at two different time instants about 1 year apart (total 4 settings), to establish generality of our approach, and deploy it at a major US university. We validate the effectiveness of our algorithms (1) quantitatively, by evaluating the recommended teams using a goodness score and find that more informed methods lead to recommendations of smaller number of teams and higher goodness, and (2) qualitatively, by conducting a large-scale user study at a college-wide level, and demonstrate that users overall found the tool very useful and relevant.},
  archive      = {J_AIM},
  author       = {Siva Likitha Valluru and Michael Widener and Biplav Srivastava and Sriraam Natarajan and Sugata Gangopadhyay},
  doi          = {10.1002/aaai.12203},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {457-471},
  shortjournal = {AI Mag.},
  title        = {AI-assisted research collaboration with open data for fair and effective response to call for proposals},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Framework to enable and test conversational assistant for
APIs and RPAs. <em>AIM</em>, <em>45</em>(4), 443–456. (<a
href="https://doi.org/10.1002/aaai.12198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of business automation, conversational assistants are emerging as the primary method for making automation software accessible to users in various business sectors. Access to automation primarily occurs through application programming interface (APIs) and robotic process automation (RPAs). To effectively convert APIs and RPAs into chatbots on a larger scale, it is crucial to establish an automated process for generating data and training models that can recognize user intentions, identify questions for conversational slot filling, and provide recommendations for subsequent actions. In this paper, we present a technique for enhancing and generating natural language conversational artifacts from API specifications using large language models (LLMs). The goal is to utilize LLMs in the “build” phase to assist humans in creating skills for digital assistants. As a result, the system does not need to rely on LLMs during conversations with business users, leading to efficient deployment. Along with enabling digital assistants, our system employs LLMs as proxies to simulate human interaction and automatically evaluate the digital assistant&#39;s performance. Experimental results highlight the effectiveness of our proposed approach. Our system is deployed in the IBM Watson Orchestrate product for general availability.},
  archive      = {J_AIM},
  author       = {Jayachandu Bandlamudi and Kushal Mukherjee and Prerna Agarwal and Ritwik Chaudhuri and Rakesh Pimplikar and Sampath Dechu and Alex Straley and Anbumunee Ponniah and Renuka Sindhgatta},
  doi          = {10.1002/aaai.12198},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {443-456},
  shortjournal = {AI Mag.},
  title        = {Framework to enable and test conversational assistant for APIs and RPAs},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Introduction to the special issue on innovative applications
of artificial intelligence (IAAI 2024). <em>AIM</em>, <em>45</em>(4),
440–442. (<a href="https://doi.org/10.1002/aaai.12205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This special issue of AI Magazine covers select applications from the Innovative Applications of Artificial Intelligence (IAAI) conference held in 2024 in Vancouver, Canada. The articles address a broad range of very challenging issues and contain great lessons for AI researchers and application developers.},
  archive      = {J_AIM},
  author       = {Alexander Wong and Yuhao Chen and Jan Seyler},
  doi          = {10.1002/aaai.12205},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {440-442},
  shortjournal = {AI Mag.},
  title        = {Introduction to the special issue on innovative applications of artificial intelligence (IAAI 2024)},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards robust visual understanding: A paradigm shift in
computer vision from recognition to reasoning. <em>AIM</em>,
<em>45</em>(3), 429–435. (<a
href="https://doi.org/10.1002/aaai.12194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Models that learn from data are widely and rapidly being deployed today for real-world use, but they suffer from unforeseen failures that limit their reliability. These failures often have several causes such as distribution shift; adversarial attacks; calibration errors; scarcity of data and/or ground-truth labels; noisy, corrupted, or partial data; and limitations of evaluation metrics. But many failures also occur because many modern AI tasks require reasoning beyond pattern matching and such reasoning abilities are difficult to formulate as data-based input–output function fitting. The reliability problem has become increasingly important under the new paradigm of semantic “multimodal” learning. In this article, I will discuss findings from our work to provide avenues for the development of robust and reliable computer vision systems, particularly by leveraging the interactions between vision and language. This article expands upon the invited talk at AAAI 2024 and covers three thematic areas: robustness of visual recognition systems, open-domain reliability for visual reasoning, and challenges and opportunities associated with generative models in vision.},
  archive      = {J_AIM},
  author       = {Tejas Gokhale},
  doi          = {10.1002/aaai.12194},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {429-435},
  shortjournal = {AI Mag.},
  title        = {Towards robust visual understanding: A paradigm shift in computer vision from recognition to reasoning},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards smooth mobile robot deployments in dynamic human
environments. <em>AIM</em>, <em>45</em>(3), 419–428. (<a
href="https://doi.org/10.1002/aaai.12192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been great interest in deploying autonomous mobile robots in airports, malls, and hospitals to complete a range of tasks such as delivery, cleaning, and patrolling. The rich context of these environments gives rise to highly unstructured motion that is challenging for robots to anticipate and adapt to. This results in uncomfortable and unsafe human–robot encounters, poor robot performance, and even catastrophic failures that hinder robot acceptance. Such observations have motivated my work on social robot navigation, the problem of enabling robots to navigate in human environments while accounting for human safety and comfort. In this article, I highlight prior work on expanding the classical autonomy stack with mathematical models and algorithms designed to contribute towards smoother mobile robot deployments in complex environments.},
  archive      = {J_AIM},
  author       = {Christoforos Mavrogiannis},
  doi          = {10.1002/aaai.12192},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {419-428},
  shortjournal = {AI Mag.},
  title        = {Towards smooth mobile robot deployments in dynamic human environments},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fair and optimal prediction via post-processing.
<em>AIM</em>, <em>45</em>(3), 411–418. (<a
href="https://doi.org/10.1002/aaai.12191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of machine learning algorithms and the increasing computational resources available, artificial intelligence has achieved great success in many application domains. However, the success of machine learning has also raised concerns about the fairness of the learned models. For instance, the learned models can perpetuate and even exacerbate the potential bias and discrimination in the training data. This issue has become a major obstacle to the deployment of machine learning systems in high-stakes domains, for example, criminal judgment, medical testing, online advertising, hiring process, and so forth. To mitigate the potential bias exhibited by machine learning models, fairness criteria can be integrated into the training process to ensure fair treatment across all demographics, but it often comes at the expense of model performance. Understanding such tradeoffs, therefore, is crucial to the design of optimal and fair algorithms. My research focuses on characterizing the inherent tradeoff between fairness and accuracy in machine learning, and developing algorithms that can achieve both fairness and optimality. In this article, I will discuss our recent work on designing post-processing algorithms for fair classification, which can be applied to a wide range of fairness criteria, including statistical parity, equal opportunity, and equalized odds, under both attribute-aware and attribute-blind settings, and is particularly suited to large-scale foundation models where retraining is expensive or even infeasible. I will also discuss the connections between our work and other related research on trustworthy machine learning, including the connections between algorithmic fairness and differential privacy as well as adversarial robustness.},
  archive      = {J_AIM},
  author       = {Han Zhao},
  doi          = {10.1002/aaai.12191},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {411-418},
  shortjournal = {AI Mag.},
  title        = {Fair and optimal prediction via post-processing},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effective knowledge representation and utilization for
sustainable collaborative learning across heterogeneous systems.
<em>AIM</em>, <em>45</em>(3), 404–410. (<a
href="https://doi.org/10.1002/aaai.12193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasingly decentralized and private nature of data in our digital society has motivated the development of collaborative intelligent systems that enable knowledge aggregation among data owners. However, collaborative learning has only been investigated in simple settings. For example, clients are often assumed to train solution models de novo , disregarding all prior expertise. The learned model is typically represented in task-specific forms that are not generalizable to unseen, emerging scenarios. Finally, a universal model representation is enforced among collaborators, ignoring their local compute constraints or input representations. These limitations hampers the practicality of prior collaborative systems in learning scenarios with limited task data that demand constant knowledge adaptation and transfer across information silos, tasks, and learning models, as well as the utilization of prior solution expertise. Furthermore, prior collaborative learning frameworks are not sustainable on a macro scale where participants desire fairness allocation of benefits (e.g., access to the combined model) based on their costs of participation (e.g., overhead of model sharing and training synchronization, risk of information breaches, etc.). This necessitates a new perspective of collaborative learning where the server not only aggregates but also conducts valuation of the participant&#39;s contribution, and distribute aggregated information to individuals in commensurate to their contribution. To substantiate the above vision, we propose a new research agenda on developing effective and sustainable collaborative learning frameworks across heterogeneous systems, featuring three novel computational capabilities on knowledge organization: model expression, comprehension, and valuation.},
  archive      = {J_AIM},
  author       = {Trong Nghia Hoang},
  doi          = {10.1002/aaai.12193},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {404-410},
  shortjournal = {AI Mag.},
  title        = {Effective knowledge representation and utilization for sustainable collaborative learning across heterogeneous systems},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward the confident deployment of real-world reinforcement
learning agents. <em>AIM</em>, <em>45</em>(3), 396–403. (<a
href="https://doi.org/10.1002/aaai.12190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent learning agents must be able to learn from experience so as to accomplish tasks that require more ability than could be initially programmed. Reinforcement learning (RL) has emerged as a potentially powerful class of solution methods to create agents that learn from trial-and-error interaction with the world. Despite many prominent success stories, a number of challenges often stand between the use of RL in real-world problems. As part of the AAAI New Faculty Highlight Program, in this article, I will describe the work that my group is doing at the University of Wisconsin—Madison with the intent to remove barriers to the use of RL in practice. Specifically, I will describe recent work that aims to give practitioners confidence in learned behaviors, methods to increase the data efficiency of RL, and work on “challenge” domains that stress RL algorithms beyond current testbeds.},
  archive      = {J_AIM},
  author       = {Josiah P. Hanna},
  doi          = {10.1002/aaai.12190},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {396-403},
  shortjournal = {AI Mag.},
  title        = {Toward the confident deployment of real-world reinforcement learning agents},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI fairness in practice: Paradigm, challenges, and
prospects. <em>AIM</em>, <em>45</em>(3), 386–395. (<a
href="https://doi.org/10.1002/aaai.12189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding and correcting algorithmic bias in artificial intelligence (AI) has become increasingly important, leading to a surge in research on AI fairness within both the AI community and broader society. Traditionally, this research operates within the constrained supervised learning paradigm, assuming the presence of class labels, independent and identically distributed (IID) data, and batch-based learning necessitating the simultaneous availability of all training data. However, in practice, class labels may be absent due to censoring, data is often represented using non-IID graph structures that capture connections among individual units, and data can arrive and evolve over time. These prevalent real-world data representations limit the applicability of existing fairness literature, which typically addresses fairness in static and tabular supervised learning settings. This paper reviews recent advances in AI fairness aimed at bridging these gaps for practical deployment in real-world scenarios. Additionally, opportunities are envisioned by highlighting the limitations and significant potential for real applications.},
  archive      = {J_AIM},
  author       = {Wenbin Zhang},
  doi          = {10.1002/aaai.12189},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {386-395},
  shortjournal = {AI Mag.},
  title        = {AI fairness in practice: Paradigm, challenges, and prospects},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient and robust sequential decision making algorithms.
<em>AIM</em>, <em>45</em>(3), 376–385. (<a
href="https://doi.org/10.1002/aaai.12186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential decision-making involves making informed decisions based on continuous interactions with a complex environment. This process is ubiquitous in various applications, including recommendation systems and clinical treatment design. My research has concentrated on addressing two pivotal challenges in sequential decision-making: (1) How can we design algorithms that efficiently learn the optimal decision strategy with minimal interactions and limited sample data? (2) How can we ensure robustness in decision-making algorithms when faced with distributional shifts due to environmental changes and the sim-to-real gap? This paper summarizes and expands upon the talk I presented at the AAAI 2024 New Faculty Highlights program, detailing how my research aims to tackle these challenges.},
  archive      = {J_AIM},
  author       = {Pan Xu},
  doi          = {10.1002/aaai.12186},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {376-385},
  shortjournal = {AI Mag.},
  title        = {Efficient and robust sequential decision making algorithms},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Better environments for better AI. <em>AIM</em>,
<em>45</em>(3), 369–375. (<a
href="https://doi.org/10.1002/aaai.12187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most AI research focuses exclusively on the AI agent itself, that is, given some input, what are the improvements to the agent&#39;s reasoning that will yield the best possible output? In my research, I take a novel approach to increasing the capabilities of AI agents via the use of AI to design the environments in which they are intended to act. My methods identify the inherent capabilities and limitations of AI agents and find the best way to modify their environment in order to maximize performance. With this agenda in mind, I describe here several research projects that vary in their objective, in the AI methodologies that are applied for finding optimal designs, and in the real-world applications to which they correspond. I also discuss how the different projects fit within my overarching objective of using AI to promote effective multi-agent collaboration and to enhance the way robots and machines interact with humans.},
  archive      = {J_AIM},
  author       = {Sarah Keren},
  doi          = {10.1002/aaai.12187},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {369-375},
  shortjournal = {AI Mag.},
  title        = {Better environments for better AI},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combating misinformation in the age of LLMs: Opportunities
and challenges. <em>AIM</em>, <em>45</em>(3), 354–368. (<a
href="https://doi.org/10.1002/aaai.12188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Misinformation such as fake news and rumors is a serious threat for information ecosystems and public trust. The emergence of large language models (LLMs) has great potential to reshape the landscape of combating misinformation. Generally, LLMs can be a double-edged sword in the fight. On the one hand, LLMs bring promising opportunities for combating misinformation due to their profound world knowledge and strong reasoning abilities. Thus, one emerging question is: can we utilize LLMs to combat misinformation? On the other hand, the critical challenge is that LLMs can be easily leveraged to generate deceptive misinformation at scale. Then, another important question is: how to combat LLM-generated misinformation? In this paper, we first systematically review the history of combating misinformation before the advent of LLMs. Then we illustrate the current efforts and present an outlook for these two fundamental questions, respectively. The goal of this survey paper is to facilitate the progress of utilizing LLMs for fighting misinformation and call for interdisciplinary efforts from different stakeholders for combating LLM-generated misinformation.},
  archive      = {J_AIM},
  author       = {Canyu Chen and Kai Shu},
  doi          = {10.1002/aaai.12188},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {354-368},
  shortjournal = {AI Mag.},
  title        = {Combating misinformation in the age of LLMs: Opportunities and challenges},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Food information engineering. <em>AIM</em>, <em>45</em>(3),
338–353. (<a href="https://doi.org/10.1002/aaai.12185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food information engineering relies on statistical and AI techniques (e.g., symbolic, connectionist, and neurosymbolic AI) for collecting, storing, processing, diffusing, and putting food information in a form exploitable by humans and machines. Food information is collected manually and automatically. Once collected, food information is organized using tabular data representation schema, symbolic, connectionist or neurosymbolic AI techniques. Once collected, processed, and stored, food information is diffused to different stakeholders using appropriate formats. Even if neurosymbolic AI has shown promising results in many domains, we found that this approach is rarely used in the domain of food information engineering. This paper aims to serve as a good reference for food information engineering researchers. Unlike existing reviews on the subject, we cover all the aspects of food information engineering and we linked the paper to online resources built using Open Research Knowledge Graph. These resources are composed of templates, comparison tables of research contributions and smart reviews. All these resources are organized in the “Food Information Engineering” observatory and will be continually updated with new research contributions.},
  archive      = {J_AIM},
  author       = {Azanzi Jiomekong and Allard Oelen and Soren Auer and Lorenz Anna-Lena and Vogt Lars},
  doi          = {10.1002/aaai.12185},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {338-353},
  shortjournal = {AI Mag.},
  title        = {Food information engineering},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Implementation of the EU AI act calls for interdisciplinary
governance. <em>AIM</em>, <em>45</em>(3), 333–337. (<a
href="https://doi.org/10.1002/aaai.12183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The European Union Parliament passed the EU AI Act in 2024, which is an important milestone towards the world&#39;s first comprehensive AI law to formally take effect. Although this is a significant achievement, the real work begins with putting these rules into action, a journey filled with challenges and opportunities. This perspective article reviews recent interdisciplinary research aimed at facilitating the implementation of the prohibited AI practices outlined in the EU AI Act. It also explores the necessary future efforts to effectively enforce the banning of those prohibited practices across the EU market and the challenges associated with such enforcement. Addressing these future tasks and challenges calls for the establishment of an interdisciplinary governance framework. This framework may contain a workflow that can identify the necessary expertise and coordinate experts’ collaboration at different stages of AI governance. Additionally, it involves developing and implementing a set of compliance and ethical safeguards to ensure effective management and supervision of AI practices.},
  archive      = {J_AIM},
  author       = {Huixin Zhong},
  doi          = {10.1002/aaai.12183},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {333-337},
  shortjournal = {AI Mag.},
  title        = {Implementation of the EU AI act calls for interdisciplinary governance},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). In search of verifiability: Explanations rarely enable
complementary performance in AI-advised decision making. <em>AIM</em>,
<em>45</em>(3), 317–332. (<a
href="https://doi.org/10.1002/aaai.12182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current literature on AI-advised decision making—involving explainable AI systems advising human decision makers—presents a series of inconclusive and confounding results. To synthesize these findings, we propose a simple theory that elucidates the frequent failure of AI explanations to engender appropriate reliance and complementary decision making performance. In contrast to other common desiderata, for example, interpretability or spelling out the AI&#39;s reasoning process, we argue that explanations are only useful to the extent that they allow a human decision maker to verify the correctness of the AI&#39;s prediction . Prior studies find in many decision making contexts that AI explanations do not facilitate such verification. Moreover, most tasks fundamentally do not allow easy verification, regardless of explanation method, limiting the potential benefit of any type of explanation. We also compare the objective of complementary performance with that of appropriate reliance, decomposing the latter into the notions of outcome-graded and strategy-graded reliance.},
  archive      = {J_AIM},
  author       = {Raymond Fok and Daniel S. Weld},
  doi          = {10.1002/aaai.12182},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {317-332},
  shortjournal = {AI Mag.},
  title        = {In search of verifiability: Explanations rarely enable complementary performance in AI-advised decision making},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). XAI is in trouble. <em>AIM</em>, <em>45</em>(3), 300–316.
(<a href="https://doi.org/10.1002/aaai.12184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers focusing on how artificial intelligence (AI) methods explain their decisions often discuss controversies and limitations. Some even assert that most publications offer little to no valuable contributions. In this article, we substantiate the claim that explainable AI (XAI) is in trouble by describing and illustrating four problems: the disagreements on the scope of XAI, the lack of definitional cohesion, precision, and adoption, the issues with motivations for XAI research, and limited and inconsistent evaluations. As we delve into their potential underlying sources, our analysis finds these problems seem to originate from AI researchers succumbing to the pitfalls of interdisciplinarity or from insufficient scientific rigor. Analyzing these potential factors, we discuss the literature at times coming across unexplored research questions. Hoping to alleviate existing problems, we make recommendations on precautions against the challenges of interdisciplinarity and propose directions in support of scientific rigor.},
  archive      = {J_AIM},
  author       = {Rosina O Weber and Adam J Johs and Prateek Goel and João Marques Silva},
  doi          = {10.1002/aaai.12184},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {300-316},
  shortjournal = {AI Mag.},
  title        = {XAI is in trouble},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The 2023 international planning competition. <em>AIM</em>,
<em>45</em>(2), 280–296. (<a
href="https://doi.org/10.1002/aaai.12169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present an overview of the 2023 International Planning Competition. It featured five distinct tracks designed to assess cutting-edge methods and explore the frontiers of planning within these settings: the classical (deterministic) track, the numeric track, the Hierarchical Task Networks (HTN) track, the learning track, and the probabilistic and reinforcement learning track. Each of these tracks evaluated planning methodologies through one or more subtracks, with the goal of pushing the boundaries of current planner performance. To achieve this objective, the competition introduced a combination of well-established challenges and entirely novel ones. Within this article, each track offers an exploration of its historical context, justifies its relevance within the planning landscape, discusses emerging domains and trends, elucidates the evaluation methodology, and ultimately presents the results.},
  archive      = {J_AIM},
  author       = {Ayal Taitler and Ron Alford and Joan Espasa and Gregor Behnke and Daniel Fišer and Michael Gimelfarb and Florian Pommerening and Scott Sanner and Enrico Scala and Dominik Schreiber and Javier Segovia-Aguas and Jendrik Seipp},
  doi          = {10.1002/aaai.12169},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {280-296},
  shortjournal = {AI Mag.},
  title        = {The 2023 international planning competition},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improve robustness of machine learning via efficient
optimization and conformal prediction. <em>AIM</em>, <em>45</em>(2),
270–279. (<a href="https://doi.org/10.1002/aaai.12173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advance of machine learning (ML) systems in real-world scenarios usually expects safe deployment in high-stake applications (e.g., medical diagnosis) for critical decision-making process. To this end, provable robustness of ML is usually required to measure and understand how reliable the deployed ML system is and how trustworthy their predictions can be. Many studies have been done to enhance the robustness in recent years from different angles, such as variance-regularized robust objective functions and conformal prediction (CP) for uncertainty quantification on testing data. Although these tools provably improve the robustness of ML model, there is still an inevitable gap to integrate them into an end-to-end deployment. For example, robust objectives usually require carefully designed optimization algorithms, while CP treats ML models as black boxes. This paper is a brief introduction to our recent research focusing on filling this gap. Specifically, for learning robust objectives, we designed sample-efficient stochastic optimization algorithms that achieves the optimal (or faster compared to existing algorithms) convergence rates. Moreover, for CP-based uncertainty quantification, we established a framework to analyze the expected prediction set size (smaller size means more efficiency) of CP methods in both standard and adversarial settings. This paper elaborates the key challenges and our exploration towards efficient algorithms with details of background methods, notions for robustness measure, concepts of algorithmic efficiency, our proposed algorithms and results. All of them further motivate our future research on risk-aware ML that can be critical for AI–human collaborative systems. The future work mainly targets designing conformal robust objectives and their efficient optimization algorithms.},
  archive      = {J_AIM},
  author       = {Yan Yan},
  doi          = {10.1002/aaai.12173},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {270-279},
  shortjournal = {AI Mag.},
  title        = {Improve robustness of machine learning via efficient optimization and conformal prediction},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI and agents. <em>AIM</em>, <em>45</em>(2), 267–269. (<a
href="https://doi.org/10.1002/aaai.12170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Earlier this year, OpenAI released their GPTs framework, allowing users to set up Large Language Model (LLM)-based personas, orchestrate them into a workflow and even offering their AI apps within an app store. This is the latest, and maybe the easiest to set up, in a string of agent-based LLM orchestration platforms in the past year, harkening a new age of agent-based engineering. But, like most breakthroughs, this one is also rooted in many years of research, and the reason the world is paying attention to it now is that, thanks to Generative AI and Large Language Models, we finally have artificial agents that are useful enough to scale to more serious problems.},
  archive      = {J_AIM},
  author       = {Babak Hodjat},
  doi          = {10.1002/aaai.12170},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {267-269},
  shortjournal = {AI Mag.},
  title        = {AI and agents},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Engineering AI for provable retention of objectives over
time. <em>AIM</em>, <em>45</em>(2), 256–266. (<a
href="https://doi.org/10.1002/aaai.12167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I argue that ensuring artificial intelligence (AI) retains alignment with human values over time is critical yet understudied. Most research focuses on static alignment, neglecting crucial retention dynamics enabling stability during learning and autonomy. This paper elucidates limitations constraining provable retention, arguing key gaps include formalizing dynamics, transparency of advanced systems, participatory scaling, and risks of uncontrolled recursive self-improvement. I synthesize technical and ethical perspectives into a conceptual framework grounded in control theory and philosophy to analyze dynamics. I argue priorities should shift towards capability modulation, participatory design, and advanced modeling to verify enduring alignment. Overall, I argue that realizing AI safely aligned throughout its lifetime necessitates translating principles into formal methods, demonstrations, and systems integrating technical and humanistic rigor.},
  archive      = {J_AIM},
  author       = {Adeniyi Fasoro},
  doi          = {10.1002/aaai.12167},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {256-266},
  shortjournal = {AI Mag.},
  title        = {Engineering AI for provable retention of objectives over time},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The business of news in the AI economy. <em>AIM</em>,
<em>45</em>(2), 246–255. (<a
href="https://doi.org/10.1002/aaai.12172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers the impact of AI on the economy and financing of journalism organizations. AI has structural implications on the news media beyond the practice of journalism and the management of news as a process. AI also shifts the premises of competition, competitive advantage, mergers and acquisitions, and IT capabilities in the news industries. Not least, it fundamentally challenges journalism&#39;s traditional business model. Considered hereunder is the two-sided market model, journalism&#39;s traditional platform function, its network effects, and its public good characteristics. The aim of the article is, thus, to reconceptualize core economic features of the news industries in the context of AI to provide a vocabulary with which to assess the economic future of journalism in a data-driven platform economy.},
  archive      = {J_AIM},
  author       = {Helle Sjøvaag},
  doi          = {10.1002/aaai.12172},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {246-255},
  shortjournal = {AI Mag.},
  title        = {The business of news in the AI economy},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring the impact of automated correction of
misinformation in social media. <em>AIM</em>, <em>45</em>(2), 227–245.
(<a href="https://doi.org/10.1002/aaai.12180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correcting misinformation is a complex task, influenced by various psychological, social, and technical factors. Most research evaluation methods for identifying effective correction approaches tend to rely on either crowdsourcing, questionnaires, lab-based simulations, or hypothetical scenarios. However, the translation of these methods and findings into real-world settings, where individuals willingly and freely disseminate misinformation, remains largely unexplored. Consequently, we lack a comprehensive understanding of how individuals who share misinformation in natural online environments would respond to corrective interventions. In this study, we explore the effectiveness of corrective messaging on 3898 users who shared misinformation on Twitter/X over 2 years. We designed and deployed a bot to automatically identify individuals who share misinformation and subsequently alert them to related fact-checks in various message formats. Our analysis shows that only a small minority of users react positively to the corrective messages, with most users either ignoring them or reacting negatively. Nevertheless, we also found that more active users were proportionally more likely to react positively to corrections and we observed that different message tones made particular user groups more likely to react to the bot.},
  archive      = {J_AIM},
  author       = {Grégoire Burel and Mohammadali Tavakoli and Harith Alani},
  doi          = {10.1002/aaai.12180},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {227-245},
  shortjournal = {AI Mag.},
  title        = {Exploring the impact of automated correction of misinformation in social media},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Measuring the benefit of increased transparency and control
in news recommendation. <em>AIM</em>, <em>45</em>(2), 212–226. (<a
href="https://doi.org/10.1002/aaai.12171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized news experiences powered by recommender systems permeate our lives and have the potential to influence not only our opinions, but also our decisions. At the same time, the content and viewpoints contained within news recommendations are driven by multiple factors, including both personalization and editorial selection. Explanations could help users gain a better understanding of the factors contributing to the news items selected for them to read. Indeed, recent works show that explanations are essential for users of news recommenders to understand their consumption preferences and set intentions in line with their goals, such as goals for knowledge development and increased diversity of content or viewpoints. We give examples of such works on explanation and interactive interface interventions which have been effective in influencing readers&#39; consumption intentions and behaviors in news recommendations. However, the state-of-the-art in news recommender systems currently fall short in terms of evaluating such interventions in live systems, limiting our ability to measure their true impact on user behavior and opinions. To help understand the true benefit of these interfaces, we therefore call for improving the realism of studies for news.},
  archive      = {J_AIM},
  author       = {Nava Tintarev and Bart P. Knijnenburg and Martijn C. Willemsen},
  doi          = {10.1002/aaai.12171},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {212-226},
  shortjournal = {AI Mag.},
  title        = {Measuring the benefit of increased transparency and control in news recommendation},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transforming the value chain of local journalism with
artificial intelligence. <em>AIM</em>, <em>45</em>(2), 200–211. (<a
href="https://doi.org/10.1002/aaai.12174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With their advertising and audience revenues in decline, local news organizations have been experiencing comparatively high degrees of disruption in recent years. Artificial Intelligence (AI) offers opportunities for local news organizations to better cope with the economic challenges they face. However, local news organizations need to carefully prioritize where AI will create the most value. After all, they serve customers in the audience and advertising markets, with external effects on society. At the same time, they are limited by scarce resources, which constrains the implementation of AI. Therefore, based on Porter&#39;s value chain, this article pursues two goals. First, drawing on previous research, we provide a systematic overview of activities for which local news organizations see the biggest potential of AI to create value. Moreover, we highlight promising AI use cases based on benchmarking with national news organizations. Second, we discuss local news organizations’ challenges in implementing AI and how they might overcome such obstacles.},
  archive      = {J_AIM},
  author       = {Bartosz Wilczek and Mario Haim and Neil Thurman},
  doi          = {10.1002/aaai.12174},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {200-211},
  shortjournal = {AI Mag.},
  title        = {Transforming the value chain of local journalism with artificial intelligence},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new era of AI-assisted journalism at bloomberg.
<em>AIM</em>, <em>45</em>(2), 187–199. (<a
href="https://doi.org/10.1002/aaai.12181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) is impacting and has the potential to upend entire business models and structures. The adoption of such new technologies to support newsgathering processes is established practice for newsrooms. For AI specifically, we are seeing a new era of AI-assisted journalism emerge with trust in the AI-driven analyses and accuracy of results as core tenets. In Part I of this position paper, we discuss the contributions of six recently published research papers co-authored by Bloomberg&#39;s Artificial Intelligence Engineering team that show the intricacies of training AI models for reliable newsgathering processes. The papers investigate (a) the creation of models for updated headline generation, showing that headline generation models benefit from access to the past state of the article, (b) sequentially controlled text generation, which is a novel task and we show that in general, more structured awareness results in higher control accuracy and grammatical coherence, (c) chart summarization, which looks into identifying the key message and generating sentences that describe salient information in the multimodal documents, (d) a semistructured natural language inference task to develop a framework for data augmentation for tabular inference, (e) the introduction of a human-annotated dataset (ENTSUM) for controllable summarization with a focus on named entities as the aspect to control, and (f) a novel defense mechanism against adversarial attacks (ATINTER). We also examine Bloomberg&#39;s research work, building its own internal, not-for-commercial-use large language model, BloombergGPT, and training it with the goal of demonstrating support for a wide range of tasks within the financial industry. In Part II, we analyze the evolution of automation tasks in the Bloomberg newsroom that led to the creation of Bloomberg&#39;s News Innovation Lab. Technology-assisted content creation has been a reality at Bloomberg News for nearly a decade and has evolved from rules-based headline generation from structured files to the constant exploration of potential ways to assist story creation and storytelling in the financial domain. The Lab now oversees the operation of hundreds of software bots that create semi- and fully automated stories of financial relevance, providing journalists with depth in terms of data and analysis, speed in terms of reacting to breaking news, and transparency to corners of the financial world where data investigation is a gigantic undertaking. The Lab recently introduced new tools that provide journalists with the ability to explore automation on demand while it continues to experiment with ways to assist story production. In Part III, we conceptually discuss the transformative impact that generative AI can have in any newsroom, along with considerations about the technology&#39;s shortcomings in its current state of development. As with any revolutionary new technology, as well as with exciting research opportunities, part of the challenge is balancing any potential positive and negative impacts on society. We offer our principles and guidelines used to inform our approach to experimenting with the new generative AI technologies. Bloomberg News’ style guide reminds us that our “journalism is aimed at possibly the most sophisticated audience in the world, for whom accuracy is essential.”},
  archive      = {J_AIM},
  author       = {Claudia Quinonez and Edgar Meij},
  doi          = {10.1002/aaai.12181},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {187-199},
  shortjournal = {AI Mag.},
  title        = {A new era of AI-assisted journalism at bloomberg},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Audiences, automation, and AI: From structured news to
language models. <em>AIM</em>, <em>45</em>(2), 174–186. (<a
href="https://doi.org/10.1002/aaai.12168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The appearance of large language models (LLMs) and other forms of generative AI portend a new era of disruption and innovation for the news industry, this time focused on the production and consumption of news rather than on its distribution. Large news organizations, however, may be surprisingly well-prepared for at least some of this disruption because of earlier innovation work on automating workflows for personalized content and formats using structured techniques. This article reviews this work and uses examples from the British Broadcasting Corporation (BBC) and other large news providers to show how LLMs have recently been successfully applied to addressing significant barriers to the deployment of structured approaches in production, and how innovation using structured techniques has more generally framed significant editorial and product challenges that might now be more readily addressed using generative AI. Using the BBC&#39;s next-generation authoring and publishing stack as an example, the article also discusses how earlier innovation work has influenced the design of flexible infrastructure that can accommodate uncertainty in audience behavior and editorial workflows – capabilities that are likely to be well suited to the fast-approaching AI-mediated news ecosystem.},
  archive      = {J_AIM},
  author       = {David Caswell},
  doi          = {10.1002/aaai.12168},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {174-186},
  shortjournal = {AI Mag.},
  title        = {Audiences, automation, and AI: From structured news to language models},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generative AI: An AI paradigm shift in the making?
<em>AIM</em>, <em>45</em>(1), 165–167. (<a
href="https://doi.org/10.1002/aaai.12155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is sometimes difficult to evaluate progress in Generative AI, that is, image generation and large language models. This may be because they represent a paradigm shift in AI, and the traditional ways of developing, evaluating, understanding, and deploying AI systems no longer apply. Instead, we need to develop new such approaches, possibly by extending those currently in use in cognitive neuroscience and psychology. In this manner, a new AI paradigm can be created, providing a significant leap in AI research and practice.},
  archive      = {J_AIM},
  author       = {Risto Miikkulainen},
  doi          = {10.1002/aaai.12155},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {165-167},
  shortjournal = {AI Mag.},
  title        = {Generative AI: An AI paradigm shift in the making?},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Physical scene understanding. <em>AIM</em>, <em>45</em>(1),
156–164. (<a href="https://doi.org/10.1002/aaai.12148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current AI systems still fail to match the flexibility, robustness, and generalizability of human intelligence: how even a young child can manipulate objects to achieve goals of their own invention or in cooperation, or can learn the essentials of a complex new task within minutes. We need AI with such embodied intelligence: transforming raw sensory inputs to rapidly build a rich understanding of the world for seeing, finding, and constructing things, achieving goals, and communicating with others. This problem of physical scene understanding is challenging because it requires a holistic interpretation of scenes, objects, and humans, including their geometry, physics, functionality, semantics, and modes of interaction, building upon studies across vision, learning, graphics, robotics, and AI. My research aims to address this problem by integrating bottom-up recognition models, deep networks, and inference algorithms with top-down structured graphical models, simulation engines, and probabilistic programs.},
  archive      = {J_AIM},
  author       = {Jiajun Wu},
  doi          = {10.1002/aaai.12148},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {156-164},
  shortjournal = {AI Mag.},
  title        = {Physical scene understanding},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Building trustworthy NeuroSymbolic AI systems: Consistency,
reliability, explainability, and safety. <em>AIM</em>, <em>45</em>(1),
139–155. (<a href="https://doi.org/10.1002/aaai.12149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainability and Safety engender trust. These require a model to exhibit consistency and reliability. To achieve these, it is necessary to use and analyze data and knowledge with statistical and symbolic AI methods relevant to the AI application––neither alone will do. Consequently, we argue and seek to demonstrate that the NeuroSymbolic AI approach is better suited for making AI a trusted AI system. We present the CREST framework that shows how C onsistency, R eliability, user-level E xplainability, and S afety are built on NeuroSymbolic methods that use data and knowledge to support requirements for critical applications such as health and well-being. This article focuses on Large Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs have garnered substantial attention from researchers due to their versatility in handling a broad array of natural language processing (NLP) scenarios. As examples, ChatGPT and Google&#39;s MedPaLM have emerged as highly promising platforms for providing information in general and health-related queries, respectively. Nevertheless, these models remain black boxes despite incorporating human feedback and instruction-guided tuning. For instance, ChatGPT can generate unsafe responses despite instituting safety guardrails. CREST presents a plausible approach harnessing procedural and graph-based knowledge within a NeuroSymbolic framework to shed light on the challenges associated with LLMs.},
  archive      = {J_AIM},
  author       = {Manas Gaur and Amit Sheth},
  doi          = {10.1002/aaai.12149},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {139-155},
  shortjournal = {AI Mag.},
  title        = {Building trustworthy NeuroSymbolic AI systems: Consistency, reliability, explainability, and safety},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prosocial dynamics in multiagent systems. <em>AIM</em>,
<em>45</em>(1), 131–138. (<a
href="https://doi.org/10.1002/aaai.12143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meeting today&#39;s major scientific and societal challenges requires understanding dynamics of prosociality in complex adaptive systems. Artificial intelligence (AI) is intimately connected with these challenges, both as an application domain and as a source of new computational techniques: On the one hand, AI suggests new algorithmic recommendations and interaction paradigms, offering novel possibilities to engineer cooperation and alleviate conflict in multiagent (hybrid) systems; on the other hand, new learning algorithms provide improved techniques to simulate sophisticated agents and increasingly realistic environments. In various settings, prosocial actions are socially desirable yet individually costly, thereby introducing a social dilemma of cooperation. How can AI enable cooperation in such domains? How to understand long-term dynamics in adaptive populations subject to such cooperation dilemmas? How to design cooperation incentives in multiagent learning systems? These are questions that I have been exploring and that I discussed during the New Faculty Highlights program at AAAI 2023. This paper summarizes and extends that talk.},
  archive      = {J_AIM},
  author       = {Fernando P. Santos},
  doi          = {10.1002/aaai.12143},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {131-138},
  shortjournal = {AI Mag.},
  title        = {Prosocial dynamics in multiagent systems},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-CARING: National AI institute for collaborative
assistance and responsive interaction for networked groups.
<em>AIM</em>, <em>45</em>(1), 124–130. (<a
href="https://doi.org/10.1002/aaai.12162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over 13 million Americans aged 65 and older are currently living with a diagnosis of mild cognitive impairment (MCI), a common precursor to dementia. These individuals largely rely on a network of informal caregivers—family, friends, and community members—who work together with professional healthcare and social service providers to provide care and support in home settings. The AI-CARING Institute contributes foundational AI research focused on developing personalized collaborative AI systems that improve the quality of life and independence of aging adults living at home.},
  archive      = {J_AIM},
  author       = {Sonia Chernova and Elizabeth Mynatt and Agata Rozga and Reid Simmons and Holly Yanco},
  doi          = {10.1002/aaai.12162},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {124-130},
  shortjournal = {AI Mag.},
  title        = {AI-CARING: National AI institute for collaborative assistance and responsive interaction for networked groups},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Molecule maker lab institute: Accelerating, advancing, and
democratizing molecular innovation. <em>AIM</em>, <em>45</em>(1),
117–123. (<a href="https://doi.org/10.1002/aaai.12154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many of the greatest challenges facing society today likely have molecular solutions that await discovery. However, the process of identifying and manufacturing such molecules has remained slow and highly specialist dependent. Interfacing the fields of artificial intelligence (AI) and synthetic organic chemistry has the potential to powerfully address both limitations. The Molecule Maker Lab Institute (MMLI) brings together a team of chemists, engineers, and AI-experts from the University of Illinois Urbana-Champaign (UIUC), Pennsylvania State University, and the Rochester Institute of Technology, with the goal of accelerating the discovery, synthesis and manufacture of complex organic molecules. Advanced AI and machine learning (ML) methods are deployed in four key thrusts: (1) AI-enabled synthesis planning, (2) AI-enabled catalyst development, (3) AI-enabled molecule manufacturing, and (4) AI-enabled molecule discovery. The MMLI&#39;s new AI-enabled synthesis platform integrates chemical and enzymatic catalysis with literature mining and ML to predict the best way to make new molecules with desirable biological and material properties. The MMLI is transforming chemical synthesis and generating use-inspired AI advances. Simultaneously, the MMLI is also acting as a training ground for the next generation of scientists with combined expertise in chemistry and AI. Outreach efforts aimed toward high school students and the public are being used to show how AI-enabled tools can help to make chemical synthesis accessible to nonexperts.},
  archive      = {J_AIM},
  author       = {Martin D. Burke and Scott E. Denmark and Ying Diao and Jiawei Han and Rachel Switzky and Huimin Zhao},
  doi          = {10.1002/aaai.12154},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {117-123},
  shortjournal = {AI Mag.},
  title        = {Molecule maker lab institute: Accelerating, advancing, and democratizing molecular innovation},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Institute for artificial intelligence and fundamental
interactions (IAIFI): Infusing physics intelligence into artificial
intelligence. <em>AIM</em>, <em>45</em>(1), 111–116. (<a
href="https://doi.org/10.1002/aaai.12150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The NSF AI Institute for Artificial Intelligence and Fundamental Interactions (IAIFI, pronounced /aI-faI/) is one of the inaugural NSF AI research institutes ( https://iaifi.org ). The IAIFI is enabling physics discoveries and advancing foundational AI through the development of novel AI approaches that incorporate first principles from fundamental physics. By combining state-of-the-art research with early career talent and a growing AI + physics community in the Boston area and beyond, the IAIFI is enabling researchers to develop AI technologies to tackle some of the most challenging problems in physics, and transfer these technologies to the broader AI community. Since trustworthy AI is as important for physics discovery as it is for other applications of AI in society, IAIFI researchers are applying physics principles to develop more robust AI tools and to illuminate existing AI technologies. To cultivate human intelligence, the IAIFI promotes training, education, and public engagement at the intersection of physics and AI. In these ways, the IAIFI is fusing deep learning with deep thinking to gain a deeper understanding of our universe and AI.},
  archive      = {J_AIM},
  author       = {Jesse Thaler and Mike Williams and Marisa LaFleur},
  doi          = {10.1002/aaai.12150},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {111-116},
  shortjournal = {AI Mag.},
  title        = {Institute for artificial intelligence and fundamental interactions (IAIFI): Infusing physics intelligence into artificial intelligence},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI2ES: The NSF AI institute for research on trustworthy AI
for weather, climate, and coastal oceanography. <em>AIM</em>,
<em>45</em>(1), 105–110. (<a
href="https://doi.org/10.1002/aaai.12160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The NSF AI Institute for Research on Trustworthy AI in Weather, Climate, and Coastal Oceanography (AI2ES) focuses on creating trustworthy AI for a variety of environmental and Earth science phenomena. AI2ES includes leading experts from AI, atmospheric and ocean science, risk communication, and education, who work synergistically to develop and test trustworthy AI methods that transform our understanding and prediction of the environment. Trust is a social phenomenon, and our integration of risk communication research across AI2ES activities provides an empirical foundation for developing user-informed, trustworthy AI. AI2ES also features activities to broaden participation and for workforce development that are fully integrated with AI2ES research on trustworthy AI, environmental science, and risk communication.},
  archive      = {J_AIM},
  author       = {Amy McGovern and Imme Ebert-Uphoff and Elizabeth A. Barnes and Ann Bostrom and Mariana G. Cains and Phillip Davis and Julie L. Demuth and Dimitrios I. Diochnos and Andrew H. Fagg and Philippe Tissot and John K. Williams and Christopher D. Wirz},
  doi          = {10.1002/aaai.12160},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {105-110},
  shortjournal = {AI Mag.},
  title        = {AI2ES: The NSF AI institute for research on trustworthy AI for weather, climate, and coastal oceanography},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AgAID institute—AI for agricultural labor and decision
support. <em>AIM</em>, <em>45</em>(1), 99–104. (<a
href="https://doi.org/10.1002/aaai.12156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The AgAID Institute is a National AI Research Institute focused on developing AI solutions for specialty crop agriculture. Specialty crops include a variety of fruits and vegetables, nut trees, grapes, berries, and different types of horticultural crops. In the United States, the specialty crop industry accounts for a multibillion dollar industry with over 300 crops grown just along the U.S. west coast. Specialty crop agriculture presents several unique challenges: they are labor-intensive, are easily impacted by weather extremities, and are grown mostly on irrigated lands and hence are dependent on water. The AgAID Institute aims to develop AI solutions to address these challenges, particularly in the face of workforce shortages, water scarcity, and extreme weather events. Addressing this host of challenges requires advancing foundational AI research, including spatio-temporal system modeling, robot sensing and control, multiscale site-specific decision support, and designing effective human–AI workflows. This article provides examples of current AgAID efforts and points to open directions to be explored.},
  archive      = {J_AIM},
  author       = {Alan Fern and Margaret Burnett and Joseph Davidson and Janardhan Rao Doppa and Paola Pesantez-Cabrera and Ananth Kalyanaraman},
  doi          = {10.1002/aaai.12156},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {99-104},
  shortjournal = {AI Mag.},
  title        = {AgAID Institute—AI for agricultural labor and decision support},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AIIRA: AI institute for resilient agriculture. <em>AIM</em>,
<em>45</em>(1), 94–98. (<a
href="https://doi.org/10.1002/aaai.12151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AIIRA seeks to transform agriculture by creating a new AI-driven framework for modeling plants at various agronomically relevant scales. We accomplish this by designing and deploying AI-driven predictive models that fuse diverse data with siloed domain knowledge. AIIRA &#39;s vision, illustrated in Figure 1, consists of four technical thrusts with cross-cutting education, training, and outreach activities. Our activities are focused on theory, algorithms, and tools for the principled creation of goal-oriented AI tools deployed at plant and field scales. Our use-inspired AI developments are tightly integrated with USDA-relevant challenges in crop improvement and sustainable crop production. Our strong social science focus ensures sustained AI adoption across the ag value chain. Our cyberinfrastructure (CI) efforts ensure cohesive, sustainable, and extensible CI to reproducibly share and manage data assets and analysis workflows to a diverse spectrum of the Ag community. Taken together, this will ensure long-term payoffs in AI and agriculture. AIIRA has established a new field of Cyber Agricultural Systems at the intersection of plant science, agronomics, and AI. Our signature activities build the workforce for this new field through formal and informal educational activities. Through these activities, AIIRA creates accessible pathways for underrepresented groups, especially Native Americans and women.},
  archive      = {J_AIM},
  author       = {Baskar Ganapathysubramanian and Jessica M. P. Bell and George Kantor and Nirav Merchant and Soumik Sarkar and Patrick S. Schnable and Michelle Segovia and Arti Singh and Asheesh K. Singh},
  doi          = {10.1002/aaai.12151},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {94-98},
  shortjournal = {AI Mag.},
  title        = {AIIRA: AI institute for resilient agriculture},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The AIFS institute: Building a better food system through
AI. <em>AIM</em>, <em>45</em>(1), 89–93. (<a
href="https://doi.org/10.1002/aaai.12164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our food system is complex, multifaceted, and in need of an upgrade. Population growth, climate change, and socioeconomic disparities are some of the challenges that create a systemic threat to its sustainability and capacity to address the needs of an evolving planet. The mission of the AI Institute of Next Generation Food Systems (AIFS) is to leverage the latest advances in AI to help create a more sustainable, efficient, nutritious, safe, and resilient food system. Instead of using AI in isolation, AIFS views it as the connective tissue that can bring together interconnected solutions from farm to fork. From guiding molecular breeding and building autonomous robots for precision agriculture, to predicting pathogen outbreaks and recommending personalized diets, AIFS projects aspire to pave the way for infrastructure and systems that empower practitioners to build the food system of the next generation. Workforce education, outreach, and ethical considerations related to the emergence of AI solutions in this sector are an integral part of AIFS with several collaborative activities aiming to foster an open dialogue and bringing closer students, trainees, teachers, producers, farmers, workers, policy makers, and other professionals.},
  archive      = {J_AIM},
  author       = {Ilias Tagkopoulos and Mason J. Earles and Danielle G. Lemay and Xin Liu and Nitin Nitin and Aaron D. Smith and Tarek I. Zohdi and Stephen F. Brown},
  doi          = {10.1002/aaai.12164},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {89-93},
  shortjournal = {AI Mag.},
  title        = {The AIFS institute: Building a better food system through AI},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AIFARMS: Artificial intelligence for future agricultural
resilience, management, and sustainability. <em>AIM</em>,
<em>45</em>(1), 83–88. (<a
href="https://doi.org/10.1002/aaai.12152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The AIFARMS Artificial Intelligence for Future Agricultural Resilience, Management, and Sustainability national AI institute brings together over 40 world-class AI and agriculture researchers, with the common mission to develop foundational advances in AI and use them to ensure that future agriculture is environmentally friendly, sustainable, affordable, and accessible to diverse farming communities. Since its establishment in 2020, AIFARMS has advanced the state of the art in autonomous farming, cover crop planting, machine learning for improved outcomes from remote sensing, dynamic estimation of yield loss from weeds, and livestock management. The institute has prioritized the creation and utilization of high-quality, openly available data sets for advancing foundational AI and tackling agricultural challenges. AIFARMS leverages a close partnership between UIUC and Tuskegee University to build programming for a skilled and diverse next-generation workforce in digital agriculture. We are expanding the reach of AIFARMS outside of the current partners to collaborate with national AI institutions and international partners.},
  archive      = {J_AIM},
  author       = {Vikram S. Adve and Jessica M. Wedow and Elizabeth A. Ainsworth and Girish Chowdhary and Angela Green-Miller and Christina Tucker},
  doi          = {10.1002/aaai.12152},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {83-88},
  shortjournal = {AI Mag.},
  title        = {AIFARMS: Artificial intelligence for future agricultural resilience, management, and sustainability},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-ALOE: AI for reskilling, upskilling, and workforce
development. <em>AIM</em>, <em>45</em>(1), 77–82. (<a
href="https://doi.org/10.1002/aaai.12157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The National AI Institute for Adult Learning and Online Education (AI-ALOE) develops AI learning and teaching assistants to enhance the proficiency of adult reskilling and upskilling, and thereby transform workforce development. The AI assistants both address known problems in online education for reskilling/upskilling and help personalize adult learning for workforce development. AI-ALOE develops new AI models and techniques for self-explanation, machine teaching, and mutual theory of mind to make the AI assistants usable, learnable, teachable, and scalable. AI-ALOE is also developing a data architecture for deploying and evaluating the AI assistants, collecting and analyzing data, and personalizing learning at scale.},
  archive      = {J_AIM},
  author       = {Ashok Goel and Chris Dede and Myk Garn and Chaohua Ou},
  doi          = {10.1002/aaai.12157},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {77-82},
  shortjournal = {AI Mag.},
  title        = {AI-ALOE: AI for reskilling, upskilling, and workforce development},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The AI institute for engaged learning. <em>AIM</em>,
<em>45</em>(1), 69–76. (<a
href="https://doi.org/10.1002/aaai.12161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The EngageAI Institute focuses on AI-driven narrative-centered learning environments that create engaging story-based problem-solving experiences to support collaborative learning. The institute&#39;s research has three complementary strands. First, the institute creates narrative-centered learning environments that generate interactive story-based problem scenarios to elicit rich communication, encourage coordination, and spark collaborative creativity. Second, the institute creates virtual embodied conversational agent technologies with multiple modalities for communication (speech, facial expression, gesture, gaze, and posture) to support student learning. Embodied conversational agents are driven by advances in natural language understanding, natural language generation, and computer vision. Third, the institute is creating an innovative multimodal learning analytics framework that analyzes parallel streams of multimodal data derived from students’ conversations, gaze, facial expressions, gesture, and posture as they interact with each other, with teachers, and with embodied conversational agents. Woven throughout the institute&#39;s activities is a strong focus on ethics, with an emphasis on creating AI-augmented learning that is deeply informed by considerations of fairness, accountability, transparency, trust, and privacy. The institute emphasizes broad participation and diverse perspectives to ensure that advances in AI-augmented learning address inequities in STEM. The institute brings together a multistate network of universities, diverse K-12 school systems, science museums, and nonprofit partners. Key to all of these endeavors is an emphasis on diversity, equity, and inclusion.},
  archive      = {J_AIM},
  author       = {James Lester and Mohit Bansal and Gautam Biswas and Cindy Hmelo-Silver and Jeremy Roschelle and Jonathan Rowe},
  doi          = {10.1002/aaai.12161},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {69-76},
  shortjournal = {AI Mag.},
  title        = {The AI institute for engaged learning},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From learning optimization to learner flourishing:
Reimagining AI in education at the institute for student-AI teaming
(iSAT). <em>AIM</em>, <em>45</em>(1), 61–68. (<a
href="https://doi.org/10.1002/aaai.12158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Institute for Student-AI Teaming (iSAT) addresses the foundational question: how to promote deep conceptual learning via rich socio-collaborative learning experiences for all students ?—a question that is ripe for AI-based facilitation and has the potential to transform classrooms. We advance research in speech, computer vision, human-agent teaming, computer-supported collaborative learning, expansive co-design, and the science of broadening participation to design and study next generation AI technologies (called AI Partners) embedded in student collaborative learning teams in coordination with teachers. Our institute ascribes to theoretical perspectives that aim to create a normative environment of widespread engagement through responsible design of technology, curriculum, and pedagogy in partnership with K–12 educators, racially diverse students, parents, and other community members.},
  archive      = {J_AIM},
  author       = {Sidney K. D&#39;Mello and Quentin Biddy and Thomas Breideband and Jeffrey Bush and Michael Chang and Arturo Cortez and Jeffrey Flanigan and Peter W. Foltz and Jamie C. Gorman and Leanne Hirshfield and Mon-Lin Monica Ko and Nikhil Krishnaswamy and Rachel Lieber and James Martin and Martha Palmer and William R. Penuel and Thomas Philip and Sadhana Puntambekar and James Pustejovsky and Jason G. Reitman and Tamara Sumner and Michael Tissenbaum and Lyn Walker and Jacob Whitehill},
  doi          = {10.1002/aaai.12158},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {61-68},
  shortjournal = {AI Mag.},
  title        = {From learning optimization to learner flourishing: Reimagining AI in education at the institute for student-AI teaming (iSAT)},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The TILOS AI institute: Integrating optimization and AI for
chip design, networks, and robotics. <em>AIM</em>, <em>45</em>(1),
54–60. (<a href="https://doi.org/10.1002/aaai.12165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization is a universal quest, reflecting the basic human need to do better . Improved optimizations of energy-efficiency, safety, robustness, and other criteria in engineered systems would bring incalculable societal benefits. But, fundamental challenges of scale and complexity keep many such real-world optimization needs beyond reach. This article describes The Institute for Learning-enabled Optimization at Scale (TILOS), an NSF AI Research Institute for Advances in Optimization that aims to overcome these challenges in three high-stakes use domains: chip design, communication networks, and contextual robotics. TILOS integrates foundational research, translation, education, and broader impacts toward a new nexus of optimization, AI, and data-driven learning. We summarize central challenges, early progress, and futures for the institute.},
  archive      = {J_AIM},
  author       = {Andrew B. Kahng and Arya Mazumdar and Jodi Reeves and Yusu Wang},
  doi          = {10.1002/aaai.12165},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {54-60},
  shortjournal = {AI Mag.},
  title        = {The TILOS AI institute: Integrating optimization and AI for chip design, networks, and robotics},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI institute in dynamic systems: Developing machine learning
and AI tools for scientific discovery, engineering design, and
data-driven control. <em>AIM</em>, <em>45</em>(1), 48–53. (<a
href="https://doi.org/10.1002/aaai.12159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mission of the AI Institute in Dynamic Systems is to develop the next generation of advanced machine learning (ML) and AI tools for controlling complex physical systems by discovering physically interpretable and physics-constrained data-driven models through optimal sensor selection and placement. The research effort is anchored by a common task framework (CTF) that evaluates the performance of ML algorithms, architectures, and optimization schemes for the diverse tasks required in engineering applications. The aim is to push beyond the boundaries of modern techniques by closing the loop between data collection, control, and modeling, creating a unique and cross-disciplinary architecture for learning physically interpretable and physics constrained models of complex dynamic systems from time series data. The CTF further supports sustainable and open-source challenge datasets, which are foundational for developing interpretable, ethical, and inclusive tools to solve problems fundamental to human safety, society, and the environment.},
  archive      = {J_AIM},
  author       = {J. Nathan Kutz and Steven L. Brunton and Krithika Manohar and Hod Lipson and Na Li},
  doi          = {10.1002/aaai.12159},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {48-53},
  shortjournal = {AI Mag.},
  title        = {AI institute in dynamic systems: Developing machine learning and AI tools for scientific discovery, engineering design, and data-driven control},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI4OPT: AI institute for advances in optimization.
<em>AIM</em>, <em>45</em>(1), 42–47. (<a
href="https://doi.org/10.1002/aaai.12146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is a short introduction to AI4OPT , the NSF AI Institute for Advances in Optimization. AI4OPT fuses AI and optimization, inspired by societal challenges in supply chains, energy systems, chip design and manufacturing, and sustainable food systems. By combining machine learning and mathematical optimization, AI4OPT strives to develop AI-assisted optimization systems that bring orders of magnitude improvements in efficiency, perform accurate uncertainty quantification, and address challenges in resiliency and sustainability. AI4OPT also applies its “teaching the teachers” philosophy to provide longitudinal educational pathways in AI for engineering.},
  archive      = {J_AIM},
  author       = {Pascal Van Hentenryck and Kevin Dalmeijer},
  doi          = {10.1002/aaai.12146},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {42-47},
  shortjournal = {AI Mag.},
  title        = {AI4OPT: AI institute for advances in optimization},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Institute for foundations of machine learning (IFML):
Advancing AI systems that will transform our world. <em>AIM</em>,
<em>45</em>(1), 35–41. (<a
href="https://doi.org/10.1002/aaai.12163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Institute for Foundations of Machine Learning (IFML) focuses on core foundational tools to power the next generation of machine learning models. Its research underpins the algorithms and data sets that make generative artificial intelligence (AI) more accurate and reliable. Headquartered at The University of Texas at Austin, IFML researchers collaborate across an ecosystem that spans University of Washington, Stanford, UCLA, Microsoft Research, the Santa Fe Institute, and Wichita State University. Over the past year, we have witnessed incredible breakthroughs in AI on topics that are at the heart of IFML&#39;s agenda, such as foundation models, LLMs, fine-tuning, and diffusion with game-changing applications influencing almost every area of science and technology. In this article, we seek to highlight seek to highlight the application of foundational machine learning research on key use-inspired topics:},
  archive      = {J_AIM},
  author       = {Adam Klivans and Alexandros G. Dimakis and Kristen Grauman and Jonathan I. Tamir and Daniel J. Diaz and Karen Davidson},
  doi          = {10.1002/aaai.12163},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {35-41},
  shortjournal = {AI Mag.},
  title        = {Institute for foundations of machine learning (IFML): Advancing AI systems that will transform our world},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-EDGE: An NSF AI institute for future edge networks and
distributed intelligence. <em>AIM</em>, <em>45</em>(1), 29–34. (<a
href="https://doi.org/10.1002/aaai.12145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper highlights the overall endeavors of the NSF AI Institute for Future Edge Networks and Distributed Intelligence (AI-EDGE) to create a research, education, knowledge transfer, and workforce development environment for developing technological leadership in next-generation edge networks (6G and beyond) and artificial intelligence (AI). The research objectives of AI-EDGE are twofold: “AI for Networks” and “Networks for AI.” The former develops new foundational AI techniques to revolutionize technologies for next-generation edge networks, while the latter develops advanced networking techniques to enhance distributed and interconnected AI capabilities at edge devices. These research investigations are conducted across eight symbiotic thrust areas that work together to address the main challenges towards those goals. Such a synergistic approach ensures a virtuous research cycle so that advances in one area will accelerate advances in the other, thereby paving the way for a new generation of networks that are not only intelligent but also efficient, secure, self-healing, and capable of solving large-scale distributed AI challenges. This paper also outlines the institute&#39;s endeavors in education and workforce development, as well as broadening participation and enforcing collaboration.},
  archive      = {J_AIM},
  author       = {Peizhong Ju and Chengzhang Li and Yingbin Liang and Ness Shroff},
  doi          = {10.1002/aaai.12145},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {29-34},
  shortjournal = {AI Mag.},
  title        = {AI-EDGE: An NSF AI institute for future edge networks and distributed intelligence},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Creating intelligent cyberinfrastructure for democratizing
AI. <em>AIM</em>, <em>45</em>(1), 22–28. (<a
href="https://doi.org/10.1002/aaai.12166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) has the potential for vast societal and economic gain; yet applications are developed in a largely ad hoc manner, lacking coherent, standardized, modular, and reusable infrastructures. The NSF-funded Intelligent CyberInfrastructure with Computational Learning in the Environment AI Institute (“ICICLE”) aims to fundamentally advance edge-to-center , AI-as-a-Service, achieved through intelligent cyberinfrastructure (CI) that spans the edge-cloud-HPC computing continuum , plug-and-play next-generation AI and intelligent CI services, and a commitment to design for broad accessibility and widespread benefit. This design is foundational to the institute&#39;s commitment to democratizing AI. The institute&#39;s CI activities are informed by three high-impact domains: animal ecology , digital agriculture , and smart foodsheds . The institute&#39;s workforce development and broadening participation in computing efforts reinforce the institute&#39;s commitment to democratizing AI . ICICLE seeks to serve as the national nexus for AI and intelligent CI , and welcomes engagement across its wide set of programs.},
  archive      = {J_AIM},
  author       = {Dhabaleswar K. Panda and Vipin Chaudhary and Eric Fosler-Lussier and Raghu Machiraju and Amit Majumdar and Beth Plale and Rajiv Ramnath and Ponnuswamy Sadayappan and Neelima Savardekar and Karen Tomko},
  doi          = {10.1002/aaai.12166},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {22-28},
  shortjournal = {AI Mag.},
  title        = {Creating intelligent cyberinfrastructure for democratizing AI},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Athena – the NSF AI institute for edge computing.
<em>AIM</em>, <em>45</em>(1), 15–21. (<a
href="https://doi.org/10.1002/aaai.12147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The National Science Foundation (NSF) Artificial Intelligence (AI) Institute for Edge Computing Leveraging Next Generation Networks (Athena) seeks to foment a transformation in modern edge computing by advancing AI foundations, computing paradigms, networked computing systems, and edge services and applications from a completely new computing perspective. Led by Duke University, Athena leverages revolutionary developments in computer systems, machine learning, networked computing systems, cyber-physical systems, and sensing. Members of Athena form a multidisciplinary team from eight universities. Athena organizes its research activities under four interrelated thrusts supporting edge computing: Foundational AI, Computer Systems, Networked Computing Systems, and Services and Applications, which constitute an ambitious and comprehensive research agenda. The research tasks of Athena will focus on developing AI-driven next-generation technologies for edge computing and new algorithmic and practical foundations of AI and evaluating the research outcomes through a combination of analytical, experimental, and empirical instruments, especially with target use-inspired research. The researchers of Athena demonstrate a cohesive effort by synergistically integrating the research outcomes from the four thrusts into three pillars: Edge Computing AI Systems, Collaborative Extended Reality (XR), and Situational Awareness and Autonomy. Athena is committed to a robust and comprehensive suite of educational and workforce development endeavors alongside its domestic and international collaboration and knowledge transfer efforts with external stakeholders that include both industry and community partnerships.},
  archive      = {J_AIM},
  author       = {Yiran Chen and Suman Banerjee and Shaundra Daily and Jeffery Krolik and Hai (Helen) Li and Daniel Limbrick and Miroslav Pajic and Rajashi Runton and Lin Zhong},
  doi          = {10.1002/aaai.12147},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {15-21},
  shortjournal = {AI Mag.},
  title        = {Athena – the NSF AI institute for edge computing},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The national artificial intelligence research institutes
program and its significance to a prosperous future. <em>AIM</em>,
<em>45</em>(1), 6–14. (<a
href="https://doi.org/10.1002/aaai.12153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The U.S. National Artificial Intelligence (AI) Research Institutes program is introduced, and its significance is discussed relative to the guiding national AI research and development strategy. The future of the program is also discussed, including, the strategic priorities guiding the potential for new AI Institutes of the future, initiatives for building a broader ecosystem to connect Institutes into a strongly interconnected network, and the building of new AI capacity and fostering partnerships in minority-serving institutions.},
  archive      = {J_AIM},
  author       = {James J. Donlon},
  doi          = {10.1002/aaai.12153},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {6-14},
  shortjournal = {AI Mag.},
  title        = {The national artificial intelligence research institutes program and its significance to a prosperous future},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Introduction to the special issue. <em>AIM</em>,
<em>45</em>(1), 4–5. (<a
href="https://doi.org/10.1002/aaai.12144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We briefly introduce this special issue and describe the scheme for the organization of the 20 articles in it.},
  archive      = {J_AIM},
  author       = {Ashok Goel and Chaohua Ou},
  doi          = {10.1002/aaai.12144},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {4-5},
  shortjournal = {AI Mag.},
  title        = {Introduction to the special issue},
  volume       = {45},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
