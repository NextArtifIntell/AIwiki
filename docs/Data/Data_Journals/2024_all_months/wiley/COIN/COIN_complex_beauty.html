<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>COIN_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="coin---122">COIN - 122</h2>
<ul>
<li><details>
<summary>
(2024). Mining user study data to judge the merit of a model for
supporting user-specific explanations of AI systems. <em>COIN</em>,
<em>40</em>(6), e70015. (<a
href="https://doi.org/10.1111/coin.70015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a model for supporting user-specific explanations of AI systems. We then discuss a user study that was conducted to gauge whether the decisions for adjusting output to users with certain characteristics was confirmed to be of value to participants. We focus on the merit of having explanations attuned to particular psychological profiles of users, and the value of having different options for the level of explanation that is offered (including allowing for no explanation, as one possibility). Following the description of the study, we present an approach for mining data from user participant responses in order to determine whether the model that was developed for varying the output to users was well-founded. While our results in this respect are preliminary, we explain how using varied machine learning methods is of value as a concrete step toward validation of specific approaches for AI explanation. We conclude with a discussion of related work and some ideas for new directions with the research, in the future.},
  archive      = {J_COIN},
  author       = {Owen Chambers and Robin Cohen and Maura R. Grossman and Liam Hebert and Elias Awad},
  doi          = {10.1111/coin.70015},
  journal      = {Computational Intelligence},
  month        = {12},
  number       = {6},
  pages        = {e70015},
  shortjournal = {Comput. Intell.},
  title        = {Mining user study data to judge the merit of a model for supporting user-specific explanations of AI systems},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A ViT-based adaptive recurrent mobilenet with attention
network for video compression and bit-rate reduction using improved
heuristic approach under versatile video coding. <em>COIN</em>,
<em>40</em>(6), e70014. (<a
href="https://doi.org/10.1111/coin.70014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video compression received attention from the communities of video processing and deep learning. Modern learning-aided mechanisms use a hybrid coding approach to reduce redundancy in pixel space across time and space, improving motion compensation accuracy. The experiments in video compression have important improvements in past years. The Versatile Video Coding (VVC) is the primary enhancing standard of video compression which is also referred to as H. 226. The VVC codec is a block-assisted hybrid codec, making it highly capable and complex. Video coding effectively compresses data while reducing compression artifacts, enhancing the quality and functionality of AI video technologies. However, the traditional models suffer from the incorrect compression of the motion and ineffective compensation frameworks of the motion leading to compression faults with a minimal trade-off of the rate distortion. This work implements an automated and effective video compression task under VVC using a deep learning approach. Motion estimation is conducted using the Motion Vector (MV) encoder-decoder model to track movements in the video. Based on these MV, the reconstruction of the frame is carried out to compensate for the motions. The residual images are obtained by using Vision Transformer-based Adaptive Recurrent MobileNet with Attention Network (ViT-ARMAN). The parameters optimization of the ViT-ARMAN is done using the Opposition-based Golden Tortoise Beetle Optimizer (OGTBO). Entropy coding is used in the training phase of the developed work to find the bit rate of residual images. Extensive experiments were conducted to demonstrate the effectiveness of the developed deep learning-based method for video compression and bit rate reduction under VVC.},
  archive      = {J_COIN},
  author       = {D. Padmapriya and Ameelia Roseline A},
  doi          = {10.1111/coin.70014},
  journal      = {Computational Intelligence},
  month        = {12},
  number       = {6},
  pages        = {e70014},
  shortjournal = {Comput. Intell.},
  title        = {A ViT-based adaptive recurrent mobilenet with attention network for video compression and bit-rate reduction using improved heuristic approach under versatile video coding},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Homomorphisms and embeddings of STRIPS planning models.
<em>COIN</em>, <em>40</em>(6), e70013. (<a
href="https://doi.org/10.1111/coin.70013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining whether two STRIPS planning instances are isomorphic is the simplest form of comparison between planning instances. It is also a particular case of the problem concerned with finding an isomorphism between a planning instance P $$ P $$ and a sub-instance of another instance P ′ $$ {P}^{\prime } $$ . One application of such a mapping is to efficiently produce a compiled form containing all solutions to P $$ P $$ from a compiled form containing all solutions to P ′ $$ {P}^{\prime } $$ . We also introduce the notion of embedding from an instance P $$ P $$ to another instance P ′ $$ {P}^{\prime } $$ , which allows us to deduce that P ′ $$ {P}^{\prime } $$ has no solution-plan if P $$ P $$ is unsolvable. In this paper, we study the complexity of these problems. We show that the first is GI-complete and can thus be solved, in theory, in quasi-polynomial time. While we prove the remaining problems to be NP-complete, we propose an algorithm to build an isomorphism when possible. We report extensive experimental trials on benchmark problems that demonstrate conclusively that applying constraint propagation in preprocessing can greatly improve the efficiency of a SAT solver.},
  archive      = {J_COIN},
  author       = {Arnaud Lequen and Martin C. Cooper and Frédéric Maris},
  doi          = {10.1111/coin.70013},
  journal      = {Computational Intelligence},
  month        = {12},
  number       = {6},
  pages        = {e70013},
  shortjournal = {Comput. Intell.},
  title        = {Homomorphisms and embeddings of STRIPS planning models},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal integration of mel spectrograms and text
transcripts for enhanced automatic speech recognition: Leveraging
extractive transformer-based approaches and late fusion strategies.
<em>COIN</em>, <em>40</em>(6), e70012. (<a
href="https://doi.org/10.1111/coin.70012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research endeavor aims to advance the field of Automatic Speech Recognition (ASR) by innovatively integrating multimodal data, specifically textual transcripts and Mel Spectrograms (2D images) obtained from raw audio. This study explores the less-explored potential of spectrograms and linguistic information in enhancing spoken word recognition accuracy. To elevate ASR performance, we propose two distinct transformer-based approaches: First, for the audio-centric approach, we leverage RegNet and ConvNeXt architectures, initially trained on a massive dataset of 14 million annotated images from ImageNet, to process Mel Spectrograms as image inputs. Second, we harness the Speech2Text transformer to decouple text transcript acquisition from raw audio. We pre-process Mel Spectrogram images, resizing them to 224 × 224 pixels to create two-dimensional audio representations. ImageNet, RegNet, and ConvNeXt individually categorize these images. The first channel generates the embeddings for visual modalities (RegNet and ConvNeXt) on 2D Mel Spectrograms. Additionally, we employ Sentence-BERT embeddings via Siamese BERT networks to transform Speech2Text transcripts into vectors. These image embeddings, along with Sentence-BERT embeddings from speech transcription, are subsequently fine-tuned within a deep dense model with five layers and batch normalization for spoken word classification. Our experiments focus on the Google Speech Command Dataset (GSCD) version 2, encompassing 35-word categories. To gauge the impact of spectrograms and linguistic features, we conducted an ablation analysis. Our novel late fusion strategy unites word embeddings and image embeddings, resulting in remarkable test accuracy rates of 95.87% for ConvNeXt, 99.95% for RegNet, and 85.93% for text transcripts across the 35-word categories, as processed by the deep dense layered model with Batch Normalization. We obtained a test accuracy of 99.96% for 35-word categories after using the late fusion of ConvNeXt + RegNet + SBERT, demonstrating superior results compared to other state-of-the-art methods.},
  archive      = {J_COIN},
  author       = {Sunakshi Mehra and Virender Ranga and Ritu Agarwal},
  doi          = {10.1111/coin.70012},
  journal      = {Computational Intelligence},
  month        = {12},
  number       = {6},
  pages        = {e70012},
  shortjournal = {Comput. Intell.},
  title        = {Multimodal integration of mel spectrograms and text transcripts for enhanced automatic speech recognition: Leveraging extractive transformer-based approaches and late fusion strategies},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Beyond words: ESC-net revolutionizes VQA by elevating visual
features and defying language priors. <em>COIN</em>, <em>40</em>(6),
e70010. (<a href="https://doi.org/10.1111/coin.70010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language prior is a pressing problem in the VQA domain where a model provides an answer favoring the most frequent related answer. There are some methods that are adopted to mitigate language prior issue, for example, ensemble approach, the balanced data approach, the modified evaluation strategy, and the modified training framework. In this article, we propose a VQA model, “Ensemble of Spatial and Channel Attention Network (ESC-Net),” to overcome the language bias problem by improving the visual features. In this work, we have used regional and global image features along with an ensemble of combined channel and spatial attention mechanisms to improve visual features. The model is a simpler and effective solution than existing methods to solve language bias. Extensive experiment show a remarkable performance improvement of 18% on the VQACP v2 dataset with a comparison to current state-of-the-art (SOTA) models.},
  archive      = {J_COIN},
  author       = {Souvik Chowdhury and Badal Soni},
  doi          = {10.1111/coin.70010},
  journal      = {Computational Intelligence},
  month        = {12},
  number       = {6},
  pages        = {e70010},
  shortjournal = {Comput. Intell.},
  title        = {Beyond words: ESC-net revolutionizes VQA by elevating visual features and defying language priors},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view self-supervised auxiliary task for few-shot
remote sensing classification. <em>COIN</em>, <em>40</em>(6), e70009.
(<a href="https://doi.org/10.1111/coin.70009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few years, the swift advancement of remote sensing technology has greatly promoted its widespread application in the agricultural field. For example, remote sensing technology is used to monitor the planting area and growth status of crops, classify crops, and detect agricultural disasters. In these applications, the accuracy of image classification is of great significance in improving the efficiency and sustainability of agricultural production. However, many of the existing studies primarily rely on contrastive self-supervised learning methods, which come with certain limitations such as complex data construction and a bias towards invariant features. To address these issues, additional techniques like knowledge distillation are often employed to optimize the learned features. In this article, we propose a novel approach to enhance feature acquisition specific to remote sensing images by introducing a classification-based self-supervised auxiliary task. This auxiliary task involves performing image transformation self-supervised learning tasks directly on the remote sensing images, thereby improving the overall capacity for feature representation. In this work, we design a texture fading reinforcement auxiliary task to reinforce texture features and color features that are useful for distinguishing similar classes of remote sensing. Different auxiliary tasks are fused to form a multi-view self-supervised auxiliary task and integrated with the main task to optimize the model training in an end-to-end manner. The experimental results on several popular few-shot remote sensing image datasets validate the effectiveness of the proposed method. The performance better than many advanced algorithms is achieved with a more concise structure.},
  archive      = {J_COIN},
  author       = {Baodi Liu and Lei Xing and Xujian Qiao and Qian Liu},
  doi          = {10.1111/coin.70009},
  journal      = {Computational Intelligence},
  month        = {12},
  number       = {6},
  pages        = {e70009},
  shortjournal = {Comput. Intell.},
  title        = {Multi-view self-supervised auxiliary task for few-shot remote sensing classification},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SDKT: Similar domain knowledge transfer for multivariate
time series classification tasks. <em>COIN</em>, <em>40</em>(6), e70008.
(<a href="https://doi.org/10.1111/coin.70008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series data classification has a wide range of applications in reality. With rapid development of deep learning, convolutional networks are widely used in this task and have achieved the current best performance. However, due to high difficulty and cost of collecting this type of data, labeled data is still scarce. In some tasks, the model shows overfitting, resulting in relatively poor classification performance. In order to improve the classification performance under such situation, we proposed a novel classification method based on transfer learning—similar domain knowledge transfer (call SDKT for short). Firstly, we designed a multivariate time series domain distance calculation method (call MTSDDC for short), which helped selecting the source domain that is most similar to target domain; Secondly, we used ResNet as a pre-trained classifier, transferred the parameters of the similar domain network to the target domain network and continue to fine-tune the parameters. To verify our method, we conducted experiments on several public datasets. Our study has also shown that the transfer effect from the source domain to the target domain is highly negatively correlated with the distance between them, with an average Pearson coefficient of −0.78. For the transfer of most similar source domain, compared to the ResNet model without transfer and the current best model, the average accuracy improvements on the datasets we used are 4.01% and 1.46% respectively.},
  archive      = {J_COIN},
  author       = {Jiaye Wen and Wenan Zhou},
  doi          = {10.1111/coin.70008},
  journal      = {Computational Intelligence},
  month        = {12},
  number       = {6},
  pages        = {e70008},
  shortjournal = {Comput. Intell.},
  title        = {SDKT: Similar domain knowledge transfer for multivariate time series classification tasks},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An automated histopathological colorectal cancer multi-class
classification system based on optimal image processing and prominent
features. <em>COIN</em>, <em>40</em>(6), e70007. (<a
href="https://doi.org/10.1111/coin.70007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal cancer (CRC) is characterized by the uncontrollable growth of cancerous cells within the rectal mucosa. In contrast, colon polyps, precancerous growths, can develop into colon cancer, causing symptoms like rectal bleeding, abdominal pain, diarrhea, weight loss, and constipation. It is the leading cause of death worldwide, and this potentially fatal cancer severely afflicts the elderly. Furthermore, early diagnosis is crucial for effective treatment, as it is often more time-consuming and laborious for experts. This study improved the accuracy of CRC multi-class classification compared to previous research utilizing diverse datasets, such as NCT-CRC-HE-100 K (100,000 images) and CRC-VAL-HE-7 K (7,180 images). Initially, we utilized various image processing techniques on the NCT-CRC-HE-100 K dataset to improve image quality and noise-freeness, followed by multiple feature extraction and selection methods to identify prominent features from a large data hub and experimenting with different approaches to select the best classifiers for these critical features. The third ensemble model (XGB-LightGBM-RF) achieved an optimum accuracy of 99.63% with 40 prominent features using univariate feature selection methods. Moreover, the third ensemble model also achieved 99.73% accuracy from the CRC-VAL-HE-7 K dataset. After combining two datasets, the third ensemble model achieved 99.27% accuracy. In addition, we trained and tested our model with two different datasets. We used 80% data from NCT-CRC-HE-100 K and 20% data from CRC-VAL-HE-7 K, respectively, for training and testing purposes, while the third ensemble model obtained 98.43% accuracy in multi-class classification. The results show that this new framework, which was created using the third ensemble model, can help experts figure out what kinds of CRC diseases people are dealing with at the very beginning of an investigation.},
  archive      = {J_COIN},
  author       = {Tasnim Jahan Tonni and Shakil Rana and Kaniz Fatema and Asif Karim and Md. Awlad Hossen Rony and Md. Zahid Hasan and Md. Saddam Hossain Mukta and Sami Azam},
  doi          = {10.1111/coin.70007},
  journal      = {Computational Intelligence},
  month        = {12},
  number       = {6},
  pages        = {e70007},
  shortjournal = {Comput. Intell.},
  title        = {An automated histopathological colorectal cancer multi-class classification system based on optimal image processing and prominent features},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AgriFusion: A low-carbon sustainable computing approach for
precision agriculture through probabilistic ensemble crop
recommendation. <em>COIN</em>, <em>40</em>(6), e70006. (<a
href="https://doi.org/10.1111/coin.70006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing crop production is essential for sustainable agriculture and food security. This study presents the AgriFusion Model, an advanced ensemble-based machine learning framework designed to enhance precision agriculture by offering highly accurate and low-carbon crop recommendations. By integrating Random Forest, Gradient Boosting, and LightGBM, the model combines their strengths to boost predictive accuracy, robustness, and energy efficiency. Trained on a comprehensive dataset of 2200 instances covering key parameters like nitrogen, phosphorus, potassium, temperature, humidity, pH, rainfall, and crop type, the model underwent rigorous preprocessing for data integrity. The RandomizedSearchCV method was employed to do hyperparameter tuning, namely improving the number of trees in the Random Forest algorithm and the learning rates in the Gradient Boosting algorithm. This ensemble approach achieves a remarkable accuracy rate of 99.48%, optimizes computer resources, lowers carbon footprint, and responds efficiently to a variety of agricultural situations. The model&#39;s performance is confirmed using metrics including cross-validation, accuracy, precision, recall, and F1 score. This demonstrates how the model might improve agricultural decision-making, make the most use of available resources, and promote ecologically responsible farming practices.},
  archive      = {J_COIN},
  author       = {T. R. Mahesh and Arastu Thakur and A. K. Velmurugan and Surbhi Bhatia Khan and Thippa Reddy Gadekallu and Saeed Alzahrani and Mohammed Alojail},
  doi          = {10.1111/coin.70006},
  journal      = {Computational Intelligence},
  month        = {12},
  number       = {6},
  pages        = {e70006},
  shortjournal = {Comput. Intell.},
  title        = {AgriFusion: A low-carbon sustainable computing approach for precision agriculture through probabilistic ensemble crop recommendation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Resan: A residual dual-attention network for abnormal
cardiac activity detection. <em>COIN</em>, <em>40</em>(6), e70005. (<a
href="https://doi.org/10.1111/coin.70005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular disease is one of the leading causes of death worldwide. Early and accurate detection of abnormal cardiac activity can be an effective way to prevent serious cardiovascular events. Electrocardiogram (ECG) and phonocardiogram (PCG) signals provide an objective evaluation of the heart&#39;s electrical and acoustic functions, enabling medical professionals to make an accurate diagnosis. Therefore, the cardiologists often use them to make a preliminary diagnosis of abnormal cardiac activity in clinical practice. For this reason, many diagnostic models have been proposed. However, these models fail to utilize the interaction information within and between the signals to aid the diagnosis of disease. To address this issue, we designed a residual dual-attention network (ResAN) for the detection of abnormal cardiac activity using synchronized ECG and PCG signals. First, ResAN uses a feature learning module with two parallel residual networks, for example, ECG-ResNet and PCG-ResNet to automatically learn the deep modal-specific features from the ECG and PCG sequences, respectively. Second, to fully utilize the available information of different modal signals, ResAN uses a dual-attention fusion module to capture the salient features of the integrated ECG and PCG features learned by the feature learning module, as well as the alternating features between them based on the attention mechanisms. Finally, these fused features are merged and fed to the classification module to detect abnormal cardiac activity. Our model achieves an accuracy of 96.1%, surpassing the performances of comparison models by 1.0% to 9.9% when using synchronized ECG and PCG signals. Furthermore, the ablation study confirmed the efficacy of the components in ResAN and also showed that ResAN performs better with synchronized ECG and PCG signals compared to using single-modal signals. Overall, ResAN provides a valid solution for the early detection of abnormal cardiac activity using ECG and PCG signals.},
  archive      = {J_COIN},
  author       = {Xuhui Wang and Yuanyuan Zhu and Fei Wu and Long Gao and Datun Qi and Xiaoyuan Jing and Chong Luo},
  doi          = {10.1111/coin.70005},
  journal      = {Computational Intelligence},
  month        = {12},
  number       = {6},
  pages        = {e70005},
  shortjournal = {Comput. Intell.},
  title        = {Resan: A residual dual-attention network for abnormal cardiac activity detection},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SHREA: A systematic hybrid resampling ensemble approach
using one class classifier. <em>COIN</em>, <em>40</em>(6), e70004. (<a
href="https://doi.org/10.1111/coin.70004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced classification and data incompleteness are two critical issues in machine learning that, despite significant research, are difficult to solve. This paper presents the Systematic Hybrid Resampling Ensemble Approach that deals with the class imbalance and incompleteness of data at a given dataset and improves classification performance. We use an oscillator-guided Factor Based Multiple Imputation Oversampling technique to balance out the minority and majority data samples, while substituting missing values in the dataset. The improved dataset is an oversampled dataset and it goes through random undersample to create majority and minority class subsets. These subsets are then trained with the classifiers using one of the One Class Classifier-based methods, that is, One Class Support Vector Machine or Local Outlier Factor. Lastly, bootstrap aggregation ensemble setups are done using majority and minority class classifiers and combining them to come up with a score-based prediction. To mimic real-life scenarios where data could be missing, we introduce random missing values on each of these imbalance datasets to create new sets from each dataset with different missing values, that is, (10%, 20%, and 30%). The proposed method is experimented with using datasets taken from the KEEL website, and the results are compared against RBG, SBG, SBT, DTE, and EUS. Experimental analysis shows that the proposed approach gives better results revealing the efficiency and significance compared to the existing methods. The proposed method Local Outlier Factor Systematic Hybrid Resampling Ensemble Approach improves by 3.46%, 5.30%, 10.51% and 9.26% in terms of Recall, AUC, f-measure and g-mean and One Class Support Vector Machine Systematic Hybrid Resampling Ensemble Approach by 4.82%, 5.95%, 11.03% and 8.80% respectively.},
  archive      = {J_COIN},
  author       = {Pranita Baro and Malaya Dutta Borah},
  doi          = {10.1111/coin.70004},
  journal      = {Computational Intelligence},
  month        = {12},
  number       = {6},
  pages        = {e70004},
  shortjournal = {Comput. Intell.},
  title        = {SHREA: A systematic hybrid resampling ensemble approach using one class classifier},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A benchmark proposal for non-generative fair adversarial
learning strategies using a fairness-utility trade-off metric.
<em>COIN</em>, <em>40</em>(5), e70003. (<a
href="https://doi.org/10.1111/coin.70003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI systems for decision-making have become increasingly popular in several areas. However, it is possible to identify biased decisions in many applications, which have become a concern for the computer science, artificial intelligence, and law communities. Therefore, researchers are proposing solutions to mitigate bias and discrimination among decision-makers. Some explored strategies are based on GANs to generate fair data. Others are based on adversarial learning to achieve fairness by encoding fairness constraints through an adversarial model. Moreover, it is usual for each proposal to assess its model with a specific metric, making comparing current approaches a complex task. Therefore, this work proposes a systematical benchmark procedure to assess the fair machine learning models. The proposed procedure comprises a fairness-utility trade-off metric ( ), the utility and fairness metrics to compose this assessment, the used datasets and preparation, and the statistical test. A previous work presents some of these definitions. The present work enriches the procedure by increasing the applied datasets and statistical guarantees when comparing the models&#39; results. We performed this benchmark evaluation for the non-generative adversarial models, analyzing the literature models from the same metric perspective. This assessment could not indicate a single model which better performs for all datasets. However, we built an understanding of how each model performs on each dataset with statistical confidence.},
  archive      = {J_COIN},
  author       = {Luiz Fernando F. P. de Lima and Danielle Rousy D. Ricarte and Clauirton A. Siebra},
  doi          = {10.1111/coin.70003},
  journal      = {Computational Intelligence},
  month        = {10},
  number       = {5},
  pages        = {e70003},
  shortjournal = {Comput. Intell.},
  title        = {A benchmark proposal for non-generative fair adversarial learning strategies using a fairness-utility trade-off metric},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synthetic image generation using deep learning: A systematic
literature review. <em>COIN</em>, <em>40</em>(5), e70002. (<a
href="https://doi.org/10.1111/coin.70002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of deep neural networks and improved computational power have brought a revolutionary transformation in the fields of computer vision and image processing. Within the realm of computer vision, there has been a significant interest in the area of synthetic image generation, which is a creative side of AI. Many researchers have introduced innovative methods to identify deep neural network-based architectures involved in image generation via different modes of input, like text, scene graph layouts and so forth to generate synthetic images. Computer-generated images have been found to contribute a lot to the training of different machine and deep-learning models. Nonetheless, we have observed an immediate need for a comprehensive and systematic literature review that encompasses a summary and critical evaluation of current primary studies&#39; approaches toward image generation. To address this, we carried out a systematic literature review on synthetic image generation approaches published from 2018 to February 2023. Moreover, we have conducted a systematic review of various datasets, approaches to image generation, performance metrics for existing methods, and a brief experimental comparison of DCGAN (deep convolutional generative adversarial network) and cGAN (conditional generative adversarial network) in the context of image generation. Additionally, we have identified applications related to image generation models with critical evaluation of the primary studies on the subject matter. Finally, we present some future research directions to further contribute to the field of image generation using deep neural networks.},
  archive      = {J_COIN},
  author       = {Aisha Zulfiqar and Sher Muhammad Daudpota and Ali Shariq Imran and Zenun Kastrati and Mohib Ullah and Suraksha Sadhwani},
  doi          = {10.1111/coin.70002},
  journal      = {Computational Intelligence},
  month        = {10},
  number       = {5},
  pages        = {e70002},
  shortjournal = {Comput. Intell.},
  title        = {Synthetic image generation using deep learning: A systematic literature review},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive synaptic adjustment mechanism to improve learning
performances of spiking neural networks. <em>COIN</em>, <em>40</em>(5),
e70001. (<a href="https://doi.org/10.1111/coin.70001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) are currently attracting researchers&#39; attention due to their efficiencies in various tasks. Spike-timing-dependent plasticity (STDP) is an unsupervised learning process that utilizes bio-plausibility based on the relative timing of pre/post-synaptic spikes of neurons. Integrated with STDP, SNNs perform well consuming less energy. However, it is hard to ensure that synaptic weights always converge to values guaranteeing accurate prediction because STDP does not change synaptic weights with supervision. To address this limitation, researchers have proposed mechanisms for inducing STDP to converge synaptic weights on the proper values referring to current synaptic weights. Thus, if the current weights fail to describe proper synaptic connections, they cannot induce STDP to update synaptic weights properly. To solve this problem, we propose an adaptive mechanism that helps STDP to converge synaptic weights directly based on input data features: Adaptive synaptic template (AST). AST leads synaptic weights to describe synaptic connections according to the data features. It prevents STDP from changing synaptic weights based on abnormal weights that fail to describe the proper synaptic connections. This is because it does not use the current synaptic weights that can disturb proper weight convergence. We integrate AST with an SNN and conduct experiments to compare it with a baseline (the SNN without AST) and benchmarks (previous works to improve STDP). Our experimental results show that the SNN using AST classifies various data sets with 6%–39% higher accuracy than the baseline and benchmarks.},
  archive      = {J_COIN},
  author       = {Hyun-Jong Lee and Jae-Han Lim},
  doi          = {10.1111/coin.70001},
  journal      = {Computational Intelligence},
  month        = {10},
  number       = {5},
  pages        = {e70001},
  shortjournal = {Comput. Intell.},
  title        = {Adaptive synaptic adjustment mechanism to improve learning performances of spiking neural networks},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient and robust 3D medical image classification
approach based on 3D CNN, time-distributed 2D CNN-BLSTM models, and mRMR
feature selection. <em>COIN</em>, <em>40</em>(5), e70000. (<a
href="https://doi.org/10.1111/coin.70000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of 3D medical imaging has been a turning point in the diagnosis of various diseases, as voxel information from adjacent slices helps radiologists better understand complex anatomical relationships. However, the interpretation of medical images by radiologists with different levels of expertise can vary and is also time-consuming. In the last decades, artificial intelligence-based computer-aided systems have provided fast and more reliable diagnostic insights with great potential for various clinical purposes. This paper proposes a significant deep learning based 3D medical image diagnosis method. The method classifies MedMNIST3D, which consists of six 3D biomedical datasets obtained from CT, MRA, and electron microscopy modalities. The proposed method concatenates 3D image features extracted from three independent networks, a 3D CNN, and two time-distributed ResNet BLSTM structures. The ultimate discriminative features are selected via the minimum redundancy maximum relevance (mRMR) feature selection method. Those features are then classified by a neural network model. Experiments adhere to the rules of the official splits and evaluation metrics of the MedMNIST3D datasets. The results reveal that the proposed approach outperforms similar studies in terms of accuracy and AUC.},
  archive      = {J_COIN},
  author       = {Enver Akbacak and Nedim Muzoğlu},
  doi          = {10.1111/coin.70000},
  journal      = {Computational Intelligence},
  month        = {10},
  number       = {5},
  pages        = {e70000},
  shortjournal = {Comput. Intell.},
  title        = {An efficient and robust 3D medical image classification approach based on 3D CNN, time-distributed 2D CNN-BLSTM models, and mRMR feature selection},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detection of aberration in human behavior using shallow
neural network over smartphone inertial sensors data. <em>COIN</em>,
<em>40</em>(5), e12699. (<a
href="https://doi.org/10.1111/coin.12699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of different Mobile Edge Computing (MEC) applications has significantly enhanced the realm of security and surveillance, with Human Activity Recognition (HAR) standing out as a crucial application. The diverse sensors found in smartphones have made it convenient for monitoring applications to gather and analyze data, rendering them valuable for HAR purposes. Moreover, MEC can be employed to automate surveillance, allowing intelligent monitoring of restricted areas to identify and respond to unwanted or suspicious activities. This research develops a system using motion sensors in smartphones to identify unusual human activities. People&#39;s smartphones were employed to monitor both suspicious and regular activities. Information was collected for various actions categorized as either suspicious or regular. When a person performs a certain action, the smartphone records a series of sensory data, analyse important patterns from the basic data, and then determines what the person is doing by combining information from different sensors. To prepare the data, information from different sensors was aligned to a shared timeline. In this study, we used a sliding window approach on synchronized data to feed sequences into LSTM and CNN models. These models, which include initial layers of LSTM and CNN, automatically find important patterns in the order of human activities. We combined SVM with the features extracted by the shallow Neural Network to make a mixed model that predicts suspicious activities. Lastly, we compared LSTM, CNN, and our new shallow mixed neural network using a new real-time dataset. The mixed model of CNN and SVM achieved an accuracy of 94.43%. Additionally, the sliding window method&#39;s effectiveness was confirmed with a 4.28% improvement in accuracy.},
  archive      = {J_COIN},
  author       = {Sakshi and M. P. S. Bhatia and Pinaki Chakraborty},
  doi          = {10.1111/coin.12699},
  journal      = {Computational Intelligence},
  month        = {10},
  number       = {5},
  pages        = {e12699},
  shortjournal = {Comput. Intell.},
  title        = {Detection of aberration in human behavior using shallow neural network over smartphone inertial sensors data},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid HAN-CNN with aspect term extraction for sentiment
analysis using product review. <em>COIN</em>, <em>40</em>(5), e12698.
(<a href="https://doi.org/10.1111/coin.12698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, an intensive sentiment analysis approach termed Hierarchical attention-convolutional neural network (HAN-CNN) has been proposed using product reviews. Firstly, the input product review is subjected to Bidirectional Encoder Representation from Transformers (BERT) tokenization, where the input data of each sentence are partitioned into little bits of words. Thereafter, Aspect Term Extraction (ATE) is carried out and feature extraction is completed utilizing some features. Finally, sentiment analysis is accomplished by the developed HAN-CNN, which is formed by combining a Hierarchical Attention Network (HAN) and a Convolutional Neural Network (CNN). Moreover, the proposed HAN-CNN achieved a greater performance with maximum accuracy, recall and F1-Score of 91.70%, 90.60% and 91.20%, respectively.},
  archive      = {J_COIN},
  author       = {P. C. D. Kalaivaani and K. Sathyarajasekaran and N. Krishnamoorthy and T. Kumaravel},
  doi          = {10.1111/coin.12698},
  journal      = {Computational Intelligence},
  month        = {10},
  number       = {5},
  pages        = {e12698},
  shortjournal = {Comput. Intell.},
  title        = {Hybrid HAN-CNN with aspect term extraction for sentiment analysis using product review},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comprehensive analysis of feature-algorithm interactions for
fall detection across age groups via machine learning. <em>COIN</em>,
<em>40</em>(5), e12697. (<a
href="https://doi.org/10.1111/coin.12697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fall detection in daily activities hinges on both feature selection and algorithm choice. This study delves into their intricate interplay using the Sisfall dataset, testing 10 machine learning algorithms on 26 features encompassing diverse falls and age groups. Individual feature analysis yields key insights. RFC with the autocorrelation feature outperformed the other classifiers, achieving 97.94% accuracy and 97.51% sensitivity (surpassing F3-SVM at 96.18% and F17-LightGBM at 95.79%). The F3-SVM exhibited exceptional specificity (98.72%) for distinguishing daily activities. Time-series features employed by SVM achieved a peak accuracy of 98.60% on unseen data, exceeding motion, basic statistical, and frequency domain features. Feature combinations further excel: the Quintuple approach, fusing top-performing features, reaches 98.69% accuracy, 98.28% sensitivity, and 99.08% specificity with the ETC, demonstrating notable sensitivity owing to its adaptability. This study underscores the crucial interplay of features and algorithms, with the Quintuple-ETC approach emerging as the most effective. Rigorous hyperparameter tuning strengthens its performance in real-world fall-detection applications. Furthermore, the study investigates algorithm transferability, training models on young participants&#39; data and applying them to the elderly—a significant challenge in machine learning. This highlights the importance of understanding the data transfer between age groups in healthcare, aging management, and medical diagnostics.},
  archive      = {J_COIN},
  author       = {Erhan Kavuncuoğlu},
  doi          = {10.1111/coin.12697},
  journal      = {Computational Intelligence},
  month        = {10},
  number       = {5},
  pages        = {e12697},
  shortjournal = {Comput. Intell.},
  title        = {Comprehensive analysis of feature-algorithm interactions for fall detection across age groups via machine learning},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TCSR: Self-attention with time and category for
session-based recommendation. <em>COIN</em>, <em>40</em>(5), e12695. (<a
href="https://doi.org/10.1111/coin.12695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation that uses sequence of items clicked by anonymous users to make recommendations has drawn the attention of many researchers, and a lot of approaches have been proposed. However, there are still problems that have not been well addressed: (1) Time information is either ignored or exploited with a fixed time span and granularity, which fails to understand the personalized interest transfer pattern of users with different clicking speeds; (2) Category information is either omitted or considered independent of the items, which defies the fact that the relationships between categories and items are helpful for the recommendation. To solve these problems, we propose a new session-based recommendation method, TCSR (self-attention with time and category for session-based recommendation). TCSR uses a non-linear normalized time embedding to perceive user interest transfer patterns on variable granularity and employs a heterogeneous SAN to make full use of both items and categories. Moreover, a cross-recommendation unit is adapted to adjust recommendations on the item and category sides. Extensive experiments on four real datasets show that TCSR significantly outperforms state-of-the-art approaches.},
  archive      = {J_COIN},
  author       = {Xiaoyan Zhu and Yu Zhang and Jiaxuan Li and Jiayin Wang and Xin Lai},
  doi          = {10.1111/coin.12695},
  journal      = {Computational Intelligence},
  month        = {10},
  number       = {5},
  pages        = {e12695},
  shortjournal = {Comput. Intell.},
  title        = {TCSR: Self-attention with time and category for session-based recommendation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modified local granger causality analysis based on
peter-clark algorithm for multivariate time series prediction on IoT
data. <em>COIN</em>, <em>40</em>(5), e12694. (<a
href="https://doi.org/10.1111/coin.12694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Climate data collected through Internet of Things (IoT) devices often contain high-dimensional, nonlinear, and auto-correlated characteristics, and general causality analysis methods obtain quantitative causality analysis results between variables based on conditional independence tests or Granger causality, and so forth. However, it is difficult to capture dynamic properties between variables of temporal distribution, which can obtain information that cannot be obtained by the mean detection method. Therefore, this paper proposed a new causality analysis method based on Peter-Clark (PC) algorithm and modified local Granger causality (MLGC) analysis method, called PC-MLGC, to reveal the causal relationships between variables and explore the dynamic properties on temporal distribution. First, the PC algorithm is applied to compute the relevant variables of each variable. Then, the results obtained in the previous stage are fed into the modified local Granger causality analysis model to explore causalities between variables. Finally, combined with the quantitative causality analysis results, the dynamic characteristic curves between variables can be obtained, and the accuracy of the causal relationship between variables can be further verified. The effectiveness of the proposed method is further demonstrated by comparing it with standard Granger causality analysis and a two-stage causal network learning method on one benchmark dataset and two real-world datasets.},
  archive      = {J_COIN},
  author       = {Fei Lv and Shuaizong Si and Xing Xiao and Weijie Ren},
  doi          = {10.1111/coin.12694},
  journal      = {Computational Intelligence},
  month        = {10},
  number       = {5},
  pages        = {e12694},
  shortjournal = {Comput. Intell.},
  title        = {Modified local granger causality analysis based on peter-clark algorithm for multivariate time series prediction on IoT data},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale learning for fine-grained traffic flow-based
travel time estimation prediction. <em>COIN</em>, <em>40</em>(5),
e12693. (<a href="https://doi.org/10.1111/coin.12693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In intelligent transportation systems (ITS), achieving accurate travel time estimation (TTE) is paramount, much like route planning. Precisely predicting travel time across different urban areas is vital, and an essential requirement for these privileges is having fine-grained knowledge of the city. In contrast to prior studies that are restricted to coarse-grained data, we broaden the scope of traffic flow forecasting to fine granularity, which provokes explicit challenges: (1) the prevalence of inter-grid transitions within fine-grained data introduces complexity in capturing spatial dependencies among grid cells on a global scale. (2) stemming from dynamic temporal dependencies. To address these challenges, we propose the multi-scaling hybrid model (MSHM) as a novel approach. Initially, a multi-directional convolutional layer is first used to acquire high-level depictions for each cell to retrieve the semantic attributes of the road network from local and global aspects. Next, we incorporate the characteristics of the road network and coarse-grained flow features to regularize the local and global spatial distribution modeling of road-relative traffic flow using an enhanced deep super-resolution (EDSR) technique. Benefiting from the EDSR method, our approach can generate high-quality fine-grained traffic flow maps. Furthermore, to continuously provide accurate TTE over time by leveraging well-designed multi-scale feature modeling, we incorporate a multi-scale feature expression of each road segment, capturing intricate details and important features at different scales to optimize the TTE. We conducted comprehensive trials on two real-world datasets, BJTaxi and NYCTaxi, aiming to achieve superior results compared to baseline methods.},
  archive      = {J_COIN},
  author       = {Zain Ul Abideen and Xiaodong Sun and Chao Sun},
  doi          = {10.1111/coin.12693},
  journal      = {Computational Intelligence},
  month        = {10},
  number       = {5},
  pages        = {e12693},
  shortjournal = {Comput. Intell.},
  title        = {Multi-scale learning for fine-grained traffic flow-based travel time estimation prediction},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ProtienCNN-BLSTM: An efficient deep neural network with
amino acid embedding-based model of protein sequence classification and
biological analysis. <em>COIN</em>, <em>40</em>(4), e12696. (<a
href="https://doi.org/10.1111/coin.12696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein sequence classification needs to be performed quickly and accurately to progress bioinformatics advancements and the production of pharmaceutical products. Extensive comparisons between large databases of known proteins and unknown sequences are necessary in traditional protein classification methods, which can be time-consuming. This labour-intensive and slow manual matching and classification method depends on functional and biological commonalities. Protein classification is one of the many fields in which deep learning has recently revolutionized. The data on proteins are organized hierarchically and sequentially, and the most advanced algorithms, such as Deep Family-based Method (DeepFam) and Protein Convolutional Neural Network (ProtCNN), have shown promising results in classifying proteins into relative groups. On the other hand, these methods frequently refuse to acknowledge this fact. We propose a novel hybrid model called ProteinCNN-BLSTM to overcome these particular challenges. To produce more accurate protein sequence classification, it combines the techniques of amino acid embedding with bidirectional long short-term memory (BLSTM) and convolutional neural networks (CNNs). The CNN component is the most effective at capturing local features, while the BLSTM component is the most capable of modeling long-term dependencies across protein sequences. Through the process of amino acid embedding, sequences of proteins are transformed into numeric vectors, which significantly improves the precision of prediction and the representation of features. Using the standard protein samples PDB-14189 and PDB-2272, we analyzed the proposed ProteinCNN-BLSTM model and the existing deep-learning models. Compared to the existing models, such as CNN, LSTM, GCNs, CNN-LSTM, RNNs, GCN-RNN, DeepFam, and ProtCNN, the proposed model performed more accurately and better than the existing models.},
  archive      = {J_COIN},
  author       = {Umesh Kumar Lilhore and Sarita Simaiya and Surjeet Dalal and Neetu Faujdar and Yogesh Kumar Sharma and K. B. V. Brahma Rao and V. V. R. Maheswara Rao and Shilpi Tomar and Ehab Ghith and Mehdi Tlija},
  doi          = {10.1111/coin.12696},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {4},
  pages        = {e12696},
  shortjournal = {Comput. Intell.},
  title        = {ProtienCNN-BLSTM: An efficient deep neural network with amino acid embedding-based model of protein sequence classification and biological analysis},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contextual classification of clinical records with
bidirectional long short-term memory (bi-LSTM) and bidirectional encoder
representations from transformers (BERT) model. <em>COIN</em>,
<em>40</em>(4), e12692. (<a
href="https://doi.org/10.1111/coin.12692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models have overcome traditional machine learning techniques for text classification domains in the field of natural language processing (NLP). Since, NLP is a branch of machine learning, used for interpreting language, classifying text of interest, and the same can be applied to analyse the medical clinical electronic health records. Medical text consists of lot of rich data which can altogether provide a good insight, by determining patterns from the clinical text data. In this paper, bidirectional-long short-term memory (Bi-LSTM), bi-LSTM attention and bidirectional encoder representations from transformers (BERT) base models are used to classify the text which are of privacy concern to a person and which should be extracted and can be tagged as sensitive. This text data which we might think not of privacy concern would majorly reveal a lot about the patient&#39;s integrity and personal life. Clinical data not only have patient demographic data but lot of hidden data which might go unseen and thus could arise privacy issues. Bi-LSTM with attention layer is also added on top to realize the importance of critical words which will be of great importance in terms of classification, we are able to achieve accuracy of about 92%. About 206,926 sentences are used out of which 80% are used for training and rest for testing we get accuracy of 90% approx. with Bi-LSTM alone. The same set of datasets is used for BERT model with accuracy of 93% approx.},
  archive      = {J_COIN},
  author       = {Jaya Zalte and Harshal Shah},
  doi          = {10.1111/coin.12692},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {4},
  pages        = {e12692},
  shortjournal = {Comput. Intell.},
  title        = {Contextual classification of clinical records with bidirectional long short-term memory (Bi-LSTM) and bidirectional encoder representations from transformers (BERT) model},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning multi-modal recurrent neural networks with target
propagation. <em>COIN</em>, <em>40</em>(4), e12691. (<a
href="https://doi.org/10.1111/coin.12691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modelling one-to-many type mappings in problems with a temporal component can be challenging. Backpropagation is not applicable to networks that perform discrete sampling and is also susceptible to gradient instabilities, especially when applied to longer sequences. In this paper, we propose two recurrent neural network architectures that leverage stochastic units and mixture models, and are trained with target propagation. We demonstrate that these networks can model complex conditional probability distributions, outperform backpropagation-trained alternatives, and do not rapidly degrade with increased time horizons. Our main contributions consist of the design and evaluation of the architectures that enable the networks to solve multi-model problems with a temporal dimension. This also includes the extension of the target propagation through time algorithm to handle stochastic neurons. The use of target propagation provides an additional computational advantage, which enables the network to handle time horizons that are substantially longer compared to networks fitted using backpropagation.},
  archive      = {J_COIN},
  author       = {Nikolay Manchev and Michael Spratling},
  doi          = {10.1111/coin.12691},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {4},
  pages        = {e12691},
  shortjournal = {Comput. Intell.},
  title        = {Learning multi-modal recurrent neural networks with target propagation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Edge reconstruction and feature enhancement-driven
architecture for blind super-resolution in medical imaging systems.
<em>COIN</em>, <em>40</em>(4), e12690. (<a
href="https://doi.org/10.1111/coin.12690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of single image super-resolution, the prevalent use of convolutional neural networks (CNN) typically assumes a simplistic bicubic downsampling model for image degradation. This assumption misaligns with the complex degradation processes encountered in medical imaging, leading to a performance gap when these algorithms are applied to real medical scenarios. Addressing this critical discrepancy, our study introduces a novel degradation comparative learning framework meticulously designed for the nuanced degradation characteristics of medical images within the Internet of Medical Things (IoMT). Unlike traditional CNN-based super-resolution approaches that homogeneously process image channels, our method acknowledges and leverages the disparity in informational content across channels. We present a blind image super-resolution technique, underpinned by edge reconstruction and an innovative image feature supplement module. This approach not only preserves but enriches texture details, crucial for the accurate analysis of medical images in the IoMT. Comparative evaluations of our model against existing blind super-resolution methods, utilizing both natural image testing datasets and medical images, demonstrate its superior performance. Notably, our approach exhibits remarkable proficiency in stably restoring various degraded super-resolution images, a critical requirement in the IoMT context. Experimental results demonstrate that our method is superior to the current state-of-the-art methods, marking a significant advancement in the field of medical image super-resolution.},
  archive      = {J_COIN},
  author       = {Yinghua Li and Yue Liu and Jian Xu and Hongyun Chu and Jinglu He and Shengchuan Zhang and Ying Liu},
  doi          = {10.1111/coin.12690},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {4},
  pages        = {e12690},
  shortjournal = {Comput. Intell.},
  title        = {Edge reconstruction and feature enhancement-driven architecture for blind super-resolution in medical imaging systems},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-class brain tumor classification system in MRI images
using cascades neural network. <em>COIN</em>, <em>40</em>(4), e12687.
(<a href="https://doi.org/10.1111/coin.12687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor segmentation from MRI is a challenging process that has positive ups and downs. The most crucial step for detection and treatment to save the patient&#39;s life is earlier diagnosis and classification of brain tumor (BT) with higher accuracy prediction. One of the deadliest cancers, malignant brain tumors is now the main cause of cancer-related death due to their extreme severity. To evaluate the tumors and help patients receive the appropriate treatment according to their classifications, it is essential to have a thorough understanding of brain diseases, such as classifying BT. In order to resolve the problem of low segmentation accuracy caused by an imbalance of model design and sample category in the process of brain tumor segmentation. In this research work, Multi-Dimensional Cascades Neural Network (MDCNet) is developed for multi-class BT classification. It is divided into two steps. In stage 1, an enhanced shallow-layer 3D locality net is used to conduct BT localization and rough segmentation on the preprocessed MRIs. It is also advised to use a unique circular inference module and parameter Dice loss to lower the uncertain probability and false positive border locations. In step 2, in order to compensate for mistakes and lost spatial information of a single view, morphological traits are investigated using a multi-view 2.5D net composed of three 2D refinement subnetworks. The suggested method outperforms the traditional model in segmentation, yielding an accuracy of 99.67%, 98.16%, and 99.76% for the three distinct datasets.},
  archive      = {J_COIN},
  author       = {A. Jayachandran and N. Anisha},
  doi          = {10.1111/coin.12687},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {4},
  pages        = {e12687},
  shortjournal = {Comput. Intell.},
  title        = {Multi-class brain tumor classification system in MRI images using cascades neural network},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Question-driven text summarization using an
extractive-abstractive framework. <em>COIN</em>, <em>40</em>(3), e12689.
(<a href="https://doi.org/10.1111/coin.12689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question-driven automatic text summarization is a popular technique to produce concise and informative answers to specific questions using a document collection. Both query-based and question-driven summarization may not produce reliable summaries nor contain relevant information if they do not take advantage of extractive and abstractive summarization mechanisms to improve performance. In this article, we propose a novel extractive and abstractive hybrid framework designed for question-driven automatic text summarization. The framework consists of complimentary modules that work together to generate an effective summary: (1) discovering appropriate non-redundant sentences as plausible answers using an open-domain multi-hop question answering system based on a convolutional neural network, multi-head attention mechanism and reasoning process; and (2) a novel paraphrasing generative adversarial network model based on transformers rewrites the extracted sentences in an abstractive setup. Experiments show this framework results in more reliable abstractive summary than competing methods. We have performed extensive experiments on public datasets, and the results show our model can outperform many question-driven and query-based baseline methods (an R1, R2, RL increase of 6%–7% for over the next highest baseline).},
  archive      = {J_COIN},
  author       = {Mahsa Abazari Kia and Aygul Garifullina and Mathias Kern and Jon Chamberlain and Shoaib Jameel},
  doi          = {10.1111/coin.12689},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12689},
  shortjournal = {Comput. Intell.},
  title        = {Question-driven text summarization using an extractive-abstractive framework},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cooperative networking and information processing system of
wireless communication UAV under the background of intelligent service.
<em>COIN</em>, <em>40</em>(3), e12688. (<a
href="https://doi.org/10.1111/coin.12688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the huge impact of the digital information age on many technical and industrial fields, a periodic fast search genetic algorithm is proposed. Based on the reconnaissance mission, this paper introduces the common allocation strategy into mission planning, and constructs the mathematical model of multi unmanned aerial vehicle (UAV) cooperative reconnaissance mission planning decision-making. The proposed periodic fast search genetic algorithm is used to solve the problem of multi UAV cooperative reconnaissance mission planning. In 2020, the industry growth rate of global UAV technology expenditure was as high as 30.6%, and the compound growth rate of UAV in China reached 63.5%, which is enough to see the great prospect of the integrated development of UAV technology and different industries. The experiment evaluates the log verification module of UAV by comparing the two data structures of Merkle tree and linear, and the time and memory overhead of storing and verifying logs, which shows the effectiveness of the log verification scheme in this paper.},
  archive      = {J_COIN},
  author       = {Zhiyong Chen},
  doi          = {10.1111/coin.12688},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12688},
  shortjournal = {Comput. Intell.},
  title        = {Cooperative networking and information processing system of wireless communication UAV under the background of intelligent service},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Video text rediscovery: Predicting and tracking text across
complex scenes. <em>COIN</em>, <em>40</em>(3), e12686. (<a
href="https://doi.org/10.1111/coin.12686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic texts in scene videos provide valuable insights and semantic cues crucial for video applications. However, the movement of this text presents unique challenges, such as blur, shifts, and blockages. While efficient in tracking text, state-of-the-art systems often need help when text becomes obscured or complicated scenes. This study introduces a novel method for detecting and tracking video text, specifically designed to predict the location of obscured or occluded text in subsequent frames using a tracking-by-detection paradigm. Our approach begins with a primary detector to identify text within individual frames, thus enhancing tracking accuracy. Using the Kalman filter, Munkres algorithm, and deep visual features, we establish connections between text instances across frames. Our technique works on the concept that when text goes missing in a frame due to obstructions, we use its previous speed and location to predict its next position. Experiments conducted on the ICDAR2013 Video and ICDAR2015 Video datasets confirm our method&#39;s efficacy, matching or surpassing established methods in performance.},
  archive      = {J_COIN},
  author       = {Veronica Naosekpam and Nilkanta Sahu},
  doi          = {10.1111/coin.12686},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12686},
  shortjournal = {Comput. Intell.},
  title        = {Video text rediscovery: Predicting and tracking text across complex scenes},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MRD-GAN: Multi-representation discrimination GAN for
enhancing the diversity of the generated data. <em>COIN</em>,
<em>40</em>(3), e12685. (<a
href="https://doi.org/10.1111/coin.12685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generative adversarial network (GAN) is a highly effective member of the generative models category and is extensively employed for generating realistic samples across various domains. The fundamental concept behind GAN involves two networks, a generator and a discriminator, competing against each other. During the training process, generator and discriminator networks encounter several issues that can potentially affect the quality and diversity of the generated samples. One such critical issue is mode collapse, where the generator fails to create varied samples. To tackle this issue, this article introduces a GAN approach called the multi-representation discrimination GAN (MRD-GAN). In this approach, the discriminator supports concurrent network discrimination flows to manage different representations of the data through various transformation functions, such as dimension rescaling, brightness adjustment, and gamma correction applied to the input data of the discriminator. We use a fusion function to aggregate the output of all flows and return a consolidated loss value to update the generator&#39;s weights. Hence, the discriminator conveys diverse feedback to the generator. The proposed approach has been evaluated on four distinct benchmarks, namely CelebA, Cifar-10, Fashion-Mnist, and Mnist. The experimental results demonstrate that the proposed approach surpasses the existing state-of-the-art GAN models in terms of FID metric that measures the diversity of the generated samples. Significantly, the proposed approach demonstrates remarkable FID scores of 14.02, 30.19, 9.42, and 3.14 on the CelebA, Cifar-10, Fashion-Mnist, and Mnist datasets, respectively.},
  archive      = {J_COIN},
  author       = {Mohammed Megahed and Ammar Mohammed},
  doi          = {10.1111/coin.12685},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12685},
  shortjournal = {Comput. Intell.},
  title        = {MRD-GAN: Multi-representation discrimination GAN for enhancing the diversity of the generated data},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UReslham: Radar reflectivity inversion for smart agriculture
with spatial federated learning over geostationary satellite
observations. <em>COIN</em>, <em>40</em>(3), e12684. (<a
href="https://doi.org/10.1111/coin.12684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The frequent occurrence of severe convective weather has certain adverse effects on the smart agriculture industry. To enhance the prediction of severe convective weather, the inversion model effectively fills radar reflectivity data gaps by leveraging geostationary satellite data, offering more comprehensive and accurate support for meteorological information in smart agriculture systems. Nevertheless, collaborative cross-regional inversion driven by dispersed radar data faces challenges in efficiency, privacy, and model accuracy. To this end, we employ an U-shaped residual network with an embedded light hybrid attention mechanism and utilize a federated averaging algorithm for efficient distributed training across multiple devices which could preserve the privacy of data from different locations, thereby improving inversion performance. In addition, to address the unbalanced nature of radar data, a weighted loss function is designed to enhance the model&#39;s sensitivity to high radar reflectivity. Experimental results demonstrate that the proposed model exhibits a certain level of improvement in evaluating radar reflectivity inversion performance across different thresholds compared to other models, thus substantiating the superiority of the proposed approach.},
  archive      = {J_COIN},
  author       = {Zhengyong Jin and Xiaolong Xu and Muhammad Bilal and Songyu Wu and Huichao Lin},
  doi          = {10.1111/coin.12684},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12684},
  shortjournal = {Comput. Intell.},
  title        = {UReslham: Radar reflectivity inversion for smart agriculture with spatial federated learning over geostationary satellite observations},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BiLSTM-based thunderstorm prediction for IoT applications.
<em>COIN</em>, <em>40</em>(3), e12683. (<a
href="https://doi.org/10.1111/coin.12683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the market demand for smart devices (SDs) in the Internet of Things (IoT) era is surging, the corresponding thunderstorm protection measures have rarely attracted attention. This paper presents a thunderstorm prediction method with elevation correction, to reduce the thunderstorm damage to SDs by visually tracking thunderstorm activities. First, a self-made three-dimensional atmospheric electric field apparatus (3DAEFA) deployed in IoT is developed to collect real-time AEF data. A 3DAEFA-based localization model is established, and the localization formula after correction is derived. AEF data predicted by the bi-directional long short-term memory (BiLSTM) model are input to this formula to obtain thunderstorm point charge localization results. Then, the localization skill is evaluated. Finally, the proposed method is assessed in experiments, under single and multiple point charge conditions. There are significant reductions of at least 33.1% and 8.8% in ranging and elevation angle errors, respectively. Particularly, this post-prediction correction reduces the deviation of fitted point charge moving paths by at most 0.189 km, demonstrating excellent application effects. Comparisons with radar charts and existing methods testify that this method can effectively predict thunderstorms.},
  archive      = {J_COIN},
  author       = {Li Zhuang and Lin Zhu},
  doi          = {10.1111/coin.12683},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12683},
  shortjournal = {Comput. Intell.},
  title        = {BiLSTM-based thunderstorm prediction for IoT applications},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for personalized health monitoring and
prediction: A review. <em>COIN</em>, <em>40</em>(3), e12682. (<a
href="https://doi.org/10.1111/coin.12682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized health monitoring and prediction are indispensable in advancing healthcare delivery, particularly amidst the escalating prevalence of chronic illnesses and the aging population. Deep learning (DL) stands out as a promising avenue for crafting personalized health monitoring systems adept at forecasting health outcomes with precision and efficiency. As personal health data becomes increasingly accessible, DL-based methodologies offer a compelling strategy for enhancing healthcare provision through accurate and timely prognostications of health conditions. This article offers a comprehensive examination of recent advancements in employing DL for personalized health monitoring and prediction. It summarizes a diverse range of DL architectures and their practical implementations across various realms, such as wearable technologies, electronic health records (EHRs), and data accumulated from social media platforms. Moreover, it elucidates the obstacles encountered and outlines future directions in leveraging DL for personalized health monitoring, thereby furnishing invaluable insights into the immense potential of DL in this domain.},
  archive      = {J_COIN},
  author       = {Robertas Damaševičius and Senthil Kumar Jagatheesaperumal and Rajesh N. V. P. S. Kandala and Sadiq Hussain and Roohallah Alizadehsani and Juan M. Gorriz},
  doi          = {10.1111/coin.12682},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12682},
  shortjournal = {Comput. Intell.},
  title        = {Deep learning for personalized health monitoring and prediction: A review},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024n). Retraction: Vijaya rangan vivekanandhan, subramaniam
sakthivel, muthaiyan manikandan. Adaptive neuro fuzzy inference system
to enhance the classification performance in smart irrigation system.
Comput intell 38: 308–322, 2022 (10.1111/coin.12492). <em>COIN</em>,
<em>40</em>(3), e12681. (<a
href="https://doi.org/10.1111/coin.12681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The above article, published online on 06 December 2021 in Wiley Online Library ( wileyonlinelibrary.com ), has been retracted by agreement between the Editor-in-Chief, Diana Inkpen, and Wiley Periodicals LLC. The article was published as part of a guest-edited special issue. Following publication, it came to our attention that two of those named as Guest Editors of this issue were being impersonated and/or misrepresented by a fraudulent entity. An investigation by the publisher found that all of the articles, including this one, experienced compromised editorial handling and peer review which was not in line with the journal&#39;s ethical standards. Therefore, a decision has been made to retract this article. We did not find any evidence of misconduct by the authors. The authors have been informed of the decision to retract.},
  archive      = {J_COIN},
  doi          = {10.1111/coin.12681},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12681},
  shortjournal = {Comput. Intell.},
  title        = {Retraction: vijaya rangan vivekanandhan, subramaniam sakthivel, muthaiyan manikandan. adaptive neuro fuzzy inference system to enhance the classification performance in smart irrigation system. comput intell 38: 308–322, 2022 (10.1111/coin.12492)},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024j). Retraction: Nehru veerabatheran, prabhu venkatesan, rakesh
kumar mahendran. Denoising and segmentation of brain image by proficient
blended threshold and conserve edge scrutinize technique. Comput intell
40: e12542, 2024 (10.1111/coin.12542). <em>COIN</em>, <em>40</em>(3),
e12680. (<a href="https://doi.org/10.1111/coin.12680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The above article, published online on 12 July 2022 in Wiley Online Library ( wileyonlinelibrary.com ), has been retracted by agreement between the Editor-in-Chief, Diana Inkpen, and Wiley Periodicals LLC. The article was published as part of a guest-edited special issue. Following publication, it came to our attention that two of those named as Guest Editors of this issue were being impersonated and/or misrepresented by a fraudulent entity. An investigation by the publisher found that all of the articles, including this one, experienced compromised editorial handling and peer review which was not in line with the journal&#39;s ethical standards. Therefore, a decision has been made to retract this article. We did not find any evidence of misconduct by the authors. The authors have been informed of the decision to retract.},
  archive      = {J_COIN},
  doi          = {10.1111/coin.12680},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12680},
  shortjournal = {Comput. Intell.},
  title        = {Retraction: nehru veerabatheran, prabhu venkatesan, rakesh kumar mahendran. denoising and segmentation of brain image by proficient blended threshold and conserve edge scrutinize technique. comput intell 40: e12542, 2024 (10.1111/coin.12542)},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Retraction: Gerard deepak, arumugam santhanavijayan. QGMS:
A query growth model for personalization and diversification of semantic
search based on differential ontology semantics using artificial
intelligence. Comput intell 40: e12514, 2024 (10.1111/coin.12514).
<em>COIN</em>, <em>40</em>(3), e12679. (<a
href="https://doi.org/10.1111/coin.12679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The above article, published online on 08 March 2022 in Wiley Online Library ( wileyonlinelibrary.com ), has been retracted by agreement between the Editor-in-Chief, Diana Inkpen, and Wiley Periodicals LLC. The article was published as part of a guest-edited special issue. Following publication, it came to our attention that two of those named as Guest Editors of this issue were being impersonated and/or misrepresented by a fraudulent entity. An investigation by the publisher found that all of the articles, including this one, experienced compromised editorial handling and peer review which was not in line with the journal&#39;s ethical standards. Therefore, a decision has been made to retract this article. The authors have been informed of the decision to retract.},
  archive      = {J_COIN},
  doi          = {10.1111/coin.12679},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12679},
  shortjournal = {Comput. Intell.},
  title        = {Retraction: gerard deepak, arumugam santhanavijayan. QGMS: a query growth model for personalization and diversification of semantic search based on differential ontology semantics using artificial intelligence. comput intell 40: e12514, 2024 (10.1111/coin.12514)},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024f). Retraction: Manikam babu, thangaraju jesudas. An artificial
intelligence-based smart health system for biological cognitive
detection based on wireless telecommunication. Comput intell
38:1365–1378, 2022 (10.1111/coin.12513). <em>COIN</em>, <em>40</em>(3),
e12678. (<a href="https://doi.org/10.1111/coin.12678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The above article, published online on 08 March 2022 in Wiley Online Library (wileyonlinelibrary.com), has been retracted by agreement between the Editor-in-Chief, Diana Inkpen, and Wiley Periodicals LLC. The article was published as part of a guest-edited special issue. Following publication, it came to our attention that two of those named as Guest Editors of this issue were being impersonated and/or misrepresented by a fraudulent entity. An investigation by the publisher found that all of the articles, including this one, experienced compromised editorial handling and peer review which was not in line with the journal&#39;s ethical standards. Therefore, a decision has been made to retract this article. We did not find any evidence of misconduct by the authors. The authors have been informed of the decision to retract.},
  archive      = {J_COIN},
  doi          = {10.1111/coin.12678},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12678},
  shortjournal = {Comput. Intell.},
  title        = {Retraction: manikam babu, thangaraju jesudas. an artificial intelligence-based smart health system for biological cognitive detection based on wireless telecommunication. comput intell 38:1365–1378, 2022 (10.1111/coin.12513)},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). Retraction: K logeswaran, p suresh. High utility itemset
mining using genetic algorithm assimilated with off policy reinforcement
learning to adaptively calibrate crossover operation. Comput intell 38:
1596–1615, 2022 (10.1111/coin.12490). <em>COIN</em>, <em>40</em>(3),
e12677. (<a href="https://doi.org/10.1111/coin.12677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The above article, published online on 14 November 2021 in Wiley Online Library ( wileyonlinelibrary.com ), has been retracted by agreement between the Editor-in-Chief, Diana Inkpen, and Wiley Periodicals LLC. The article was published as part of a guest-edited special issue. Following publication, it came to our attention that two of those named as Guest Editors of this issue were being impersonated and/or misrepresented by a fraudulent entity. An investigation by the publisher found that all of the articles, including this one, experienced compromised editorial handling and peer review which was not in line with the journal&#39;s ethical standards. Therefore, a decision has been made to retract this article. We did not find any evidence of misconduct by the authors. The authors have been informed of the decision to retract.},
  archive      = {J_COIN},
  doi          = {10.1111/coin.12677},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12677},
  shortjournal = {Comput. Intell.},
  title        = {Retraction: k logeswaran, p suresh. high utility itemset mining using genetic algorithm assimilated with off policy reinforcement learning to adaptively calibrate crossover operation. comput intell 38: 1596–1615, 2022 (10.1111/coin.12490)},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024k). Retraction: Om kumar c.u, ponsy r. K. Sathia bhama.
Efficient ensemble to combat flash attacks. Comput intell 40: e12488,
2024 (10.1111/coin.12488). <em>COIN</em>, <em>40</em>(3), e12676. (<a
href="https://doi.org/10.1111/coin.12676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The above article, published online on 11 November 2021 in Wiley Online Library ( wileyonlinelibrary.com ), has been retracted by agreement between the Editor-in-Chief, Diana Inkpen, and Wiley Periodicals LLC. The article was published as part of a guest-edited special issue. Following publication, it came to our attention that two of those named as Guest Editors of this issue were being impersonated and/or misrepresented by a fraudulent entity. An investigation by the publisher found that all of the articles, including this one, experienced compromised editorial handling and peer review which was not in line with the journal&#39;s ethical standards. Therefore, a decision has been made to retract this article. We did not find any evidence of misconduct by the authors. The authors have been informed of the decision to retract.},
  archive      = {J_COIN},
  doi          = {10.1111/coin.12676},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12676},
  shortjournal = {Comput. Intell.},
  title        = {Retraction: om kumar C.U, ponsy r. k. sathia bhama. efficient ensemble to combat flash attacks. comput intell 40: e12488, 2024 (10.1111/coin.12488)},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Retraction: Ala saleh alluhaidan. Artificial intelligence
for public perception of drones as a tool for telecommunication
technologies. Comput intell 40: e12507, 2024 (10.1111/coin.12507).
<em>COIN</em>, <em>40</em>(3), e12675. (<a
href="https://doi.org/10.1111/coin.12675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The above article, published online on 17 February 2022 in Wiley Online Library ( wileyonlinelibrary.com ), has been retracted by agreement between the Editor-in-Chief, Diana Inkpen, and Wiley Periodicals LLC. The article was published as part of a guest-edited special issue. Following publication, it came to our attention that two of those named as Guest Editors of this issue were being impersonated and/or misrepresented by a fraudulent entity. An investigation by the publisher found that all of the articles, including this one, experienced compromised editorial handling and peer review which was not in line with the journal&#39;s ethical standards. Therefore, a decision has been made to retract this article. We did not find any evidence of misconduct by the authors. The authors have been informed of the decision to retract but do not agree with this decision.},
  archive      = {J_COIN},
  doi          = {10.1111/coin.12675},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12675},
  shortjournal = {Comput. Intell.},
  title        = {Retraction: ala saleh alluhaidan. artificial intelligence for public perception of drones as a tool for telecommunication technologies. comput intell 40: e12507, 2024 (10.1111/coin.12507)},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024l). Retraction: S. P. Santhoshkumar, h. Lilly beaulah,
abdulrahman saad alqahtani, p. Parthasarathy, azath mubarakali. A remote
diagnosis of parkinson’s ailment using artificial intelligence based
BPNN framework and cloud based storage architecture for securing data in
cloud environment for the application of telecommunication technologies.
Comput intell 40: e12508, 2024 (10.1111/coin.12508). <em>COIN</em>,
<em>40</em>(3), e12674. (<a
href="https://doi.org/10.1111/coin.12674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The above article, published online on 15 February 2022 in in Wiley Online Library (wileyonlinelibrary.com), has been retracted by agreement between the Editor-in-Chief, Diana Inkpen, and Wiley Periodicals LLC. The article was published as part of a guest-edited special issue. Following publication, it came to our attention that two of those named as Guest Editors of this issue were being impersonated and/or misrepresented by a fraudulent entity. An investigation by the publisher found that all of the articles, including this one, experienced compromised editorial handling and peer review which was not in line with the journal&#39;s ethical standards. Therefore, a decision has been made to retract this article. The authors have been informed of the decision to retract.},
  archive      = {J_COIN},
  doi          = {10.1111/coin.12674},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12674},
  shortjournal = {Comput. Intell.},
  title        = {Retraction: s. p. santhoshkumar, h. lilly beaulah, abdulrahman saad alqahtani, p. parthasarathy, azath mubarakali. a remote diagnosis of parkinson&#39;s ailment using artificial intelligence based BPNN framework and cloud based storage architecture for securing data in cloud environment for the application of telecommunication technologies. comput intell 40: e12508, 2024 (10.1111/coin.12508)},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024g). Retraction: Meeran sheriff, rajagopal gayathri. An enhanced
ensemble machine learning classification method to detect attention
deficit hyperactivity for various artificial intelligence and
telecommunication applications. Comput intell 38: 1327–1337, 2022
(10.1111/coin.12509). <em>COIN</em>, <em>40</em>(3), e12673. (<a
href="https://doi.org/10.1111/coin.12673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The above article, published online on 21 February 2022 in Wiley Online Library (wileyonlinelibrary.com), has been retracted by agreement between the Editor-in-Chief, Diana Inkpen, and Wiley Periodicals LLC. The article was published as part of a guest-edited special issue. Following publication, it came to our attention that two of those named as Guest Editors of this issue were being impersonated and/or misrepresented by a fraudulent entity. An investigation by the publisher found that all of the articles, including this one, experienced compromised editorial handling and peer review which was not in line with the journal&#39;s ethical standards. Therefore, a decision has been made to retract this article. We did not find any evidence of misconduct by the authors. The authors have been informed of the decision to retract.},
  archive      = {J_COIN},
  doi          = {10.1111/coin.12673},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12673},
  shortjournal = {Comput. Intell.},
  title        = {Retraction: meeran sheriff, rajagopal gayathri. an enhanced ensemble machine learning classification method to detect attention deficit hyperactivity for various artificial intelligence and telecommunication applications. comput intell 38: 1327–1337, 2022 (10.1111/coin.12509)},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024i). Retraction: Neeraj kumar, upendra kumar. Artificial
intelligence for classification and regression tree based feature
selection method for network intrusion detection system in various
telecommunication technologies. Comput intell 40: e12500, 2024
(10.1111/coin.12500). <em>COIN</em>, <em>40</em>(3), e12672. (<a
href="https://doi.org/10.1111/coin.12672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The above article, published online on 10 January 2022 in Wiley Online Library (wileyonlinelibrary.com), has been retracted by agreement between the Editor-in-Chief, Diana Inkpen, and Wiley Periodicals LLC. The article was published as part of a guest-edited special issue. Following publication, it came to our attention that two of those named as Guest Editors of this issue were being impersonated and/or misrepresented by a fraudulent entity. An investigation by the publisher found that all of the articles, including this one, experienced compromised editorial handling and peer review which was not in line with the journal&#39;s ethical standards. Therefore, a decision has been made to retract this article. The authors have been informed of the decision to retract.},
  archive      = {J_COIN},
  doi          = {10.1111/coin.12672},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12672},
  shortjournal = {Comput. Intell.},
  title        = {Retraction: neeraj kumar, upendra kumar. artificial intelligence for classification and regression tree based feature selection method for network intrusion detection system in various telecommunication technologies. comput intell 40: e12500, 2024 (10.1111/coin.12500)},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Retraction: Chinnathangam karthikraja, jayaprakasam
senthilkumar, rajadurai hariharan, gandhi usha devi, yuvaraj suresh,
vijayakumar mohanraj. An empirical intrusion detection system based on
XGBoost and bidirectional long-short term model for 5G and other
telecommunication technologies. Comput intell 38: 1216–1231, 2022
(10.1111/coin.12497). <em>COIN</em>, <em>40</em>(3), e12671. (<a
href="https://doi.org/10.1111/coin.12671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The above article, published online on 23 January 2022 in Wiley Online Library (wileyonlinelibrary.com), has been retracted by agreement between the Editor-in-Chief, Diana Inkpen, and Wiley Periodicals LLC. The article was published as part of a guest-edited special issue. Following publication, it came to our attention that two of those named as Guest Editors of this issue were being impersonated and/or misrepresented by a fraudulent entity. An investigation by the publisher found that all of the articles, including this one, experienced compromised editorial handling and peer review which was not in line with the journal&#39;s ethical standards. Therefore, a decision has been made to retract this article. We did not find any evidence of misconduct by the authors. The authors have been informed of the decision to retract but do not agree with this decision.},
  archive      = {J_COIN},
  doi          = {10.1111/coin.12671},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12671},
  shortjournal = {Comput. Intell.},
  title        = {Retraction: chinnathangam karthikraja, jayaprakasam senthilkumar, rajadurai hariharan, gandhi usha devi, yuvaraj suresh, vijayakumar mohanraj. an empirical intrusion detection system based on XGBoost and bidirectional long-short term model for 5G and other telecommunication technologies. comput intell 38: 1216–1231, 2022 (10.1111/coin.12497)},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024e). Retraction: Mahaboob john y. M., ravi g. Multi constrained
network feature approximation based secure routing for improved quality
of service in mobile ad-hoc network. Comput intell 40: e12489, 2024
(10.1111/coin.12489). <em>COIN</em>, <em>40</em>(3), e12670. (<a
href="https://doi.org/10.1111/coin.12670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The above article, published online on 21 November 2021 in Wiley Online Library (wileyonlinelibrary.com), has been retracted by agreement between the Editor-in-Chief, Diana Inkpen, and Wiley Periodicals LLC. The article was published as part of a guest-edited special issue. Following publication, it came to our attention that two of those named as Guest Editors of this issue were being impersonated and/or misrepresented by a fraudulent entity. An investigation by the publisher found that all of the articles, including this one, experienced compromised editorial handling and peer review which was not in line with the journal&#39;s ethical standards. Therefore, a decision has been made to retract this article. We did not find any evidence of misconduct by the authors. The authors have been informed of the decision to retract.},
  archive      = {J_COIN},
  doi          = {10.1111/coin.12670},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12670},
  shortjournal = {Comput. Intell.},
  title        = {Retraction: mahaboob john y. m., ravi g. multi constrained network feature approximation based secure routing for improved quality of service in mobile ad-hoc network. comput intell 40: e12489, 2024 (10.1111/coin.12489)},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024h). Retraction: Muthuramalingam sivakumar, perumal renuka,
pandian chitra, sundararajan karthikeyan. IoT incorporated deep learning
model combined with SmartBin technology for real-time solid waste
management. Comput intell 38: 323–344, 2022 (10.1111/coin.12495).
<em>COIN</em>, <em>40</em>(3), e12669. (<a
href="https://doi.org/10.1111/coin.12669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The above article, published online on 03 December 2021 in Wiley Online Library ( wileyonlinelibrary.com ), has been retracted by agreement between the Editor-in-Chief, Diana Inkpen, and Wiley Periodicals LLC. The article was published as part of a guest-edited special issue. Following publication, it came to our attention that two of those named as Guest Editors of this issue were being impersonated and/or misrepresented by a fraudulent entity. An investigation by the publisher found that all of the articles, including this one, experienced compromised editorial handling and peer review which was not in line with the journal&#39;s ethical standards. Therefore, a decision has been made to retract this article. We did not find any evidence of misconduct by the authors. The authors have been informed of the decision to retract.},
  archive      = {J_COIN},
  doi          = {10.1111/coin.12669},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12669},
  shortjournal = {Comput. Intell.},
  title        = {Retraction: muthuramalingam sivakumar, perumal renuka, pandian chitra, sundararajan karthikeyan. IoT incorporated deep learning model combined with SmartBin technology for real-time solid waste management. comput intell 38: 323–344, 2022 (10.1111/coin.12495)},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024m). Retraction: Sunita satish patil, thangamuthu senthil
kumaran. Fuzzy based rendezvous points selection for mobile data
gathering in wireless sensor network. Comput intell 40: e12486, 2024
(10.1111/coin.12486). <em>COIN</em>, <em>40</em>(3), e12668. (<a
href="https://doi.org/10.1111/coin.12668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The above article, published online on 21 October 2021 in Wiley Online Library ( wileyonlinelibrary.com ), has been retracted by agreement between the Editor-in-Chief, Diana Inkpen, and Wiley Periodicals LLC. The article was published as part of a guest-edited special issue. Following publication, it came to our attention that two of those named as Guest Editors of this issue were being impersonated and/or misrepresented by a fraudulent entity. An investigation by the publisher found that all of the articles, including this one, experienced compromised editorial handling and peer review which was not in line with the journal&#39;s ethical standards. Therefore, a decision has been made to retract this article. We did not find any evidence of misconduct by the authors. The authors have been informed of the decision to retract.},
  archive      = {J_COIN},
  doi          = {10.1111/coin.12668},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12668},
  shortjournal = {Comput. Intell.},
  title        = {Retraction: sunita satish patil, thangamuthu senthil kumaran. fuzzy based rendezvous points selection for mobile data gathering in wireless sensor network. comput intell 40: e12486, 2024 (10.1111/coin.12486)},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024o). Retraction: Vinod kumar r, kavithaa g, jayanthi d. Lifetime
maximization energy-aware routing protocol for route optimization to
improve quality of service in wireless sensor networks. Comput intell
40: e12485, 2024 (10.1111/coin.12485). <em>COIN</em>, <em>40</em>(3),
e12667. (<a href="https://doi.org/10.1111/coin.12667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The above article, published online on 06 January 2022 in Wiley Online Library ( wileyonlinelibrary.com ), has been retracted by agreement between the Editor-in-Chief, Diana Inkpen, and Wiley Periodicals LLC. The article was published as part of a guest-edited special issue. Following publication, it came to our attention that two of those named as Guest Editors of this issue were being impersonated and/or misrepresented by a fraudulent entity. An investigation by the publisher found that all of the articles, including this one, experienced compromised editorial handling and peer review which was not in line with the journal&#39;s ethical standards. Therefore, a decision has been made to retract this article. We did not find any evidence of misconduct by the authors. The authors have been informed of the decision to retract.},
  archive      = {J_COIN},
  doi          = {10.1111/coin.12667},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12667},
  shortjournal = {Comput. Intell.},
  title        = {Retraction: vinod kumar r, kavithaa g, jayanthi d. lifetime maximization energy-aware routing protocol for route optimization to improve quality of service in wireless sensor networks. comput intell 40: e12485, 2024 (10.1111/coin.12485)},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable artificial intelligence for medical imaging:
Review and experiments with infrared breast images. <em>COIN</em>,
<em>40</em>(3), e12660. (<a
href="https://doi.org/10.1111/coin.12660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a growing trend of using artificial intelligence, particularly deep learning algorithms, in medical diagnostics, revolutionizing healthcare by improving efficiency, accuracy, and patient outcomes. However, the use of artificial intelligence in medical diagnostics comes with the critical need to explain the reasoning behind artificial intelligence-based predictions and ensure transparency in decision-making. Explainable artificial intelligence has emerged as a crucial research area to address the need for transparency and interpretability in medical diagnostics. Explainable artificial intelligence techniques aim to provide insights into the decision-making process of artificial intelligence systems, enabling clinicians to understand the factors the algorithms consider in reaching their predictions. This paper presents a detailed review of saliency-based (visual) methods, such as class activation methods, which have gained popularity in medical imaging as they provide visual explanations by highlighting the regions of an image most influential in the artificial intelligence&#39;s decision. We also present the literature on non-visual methods, but the focus will be on visual methods. We also use the existing literature to experiment with infrared breast images for detecting breast cancer. Towards the end of this paper, we also propose an “attention guided Grad-CAM” that enhances the visualizations for explainable artificial intelligence. The existing literature shows that explainable artificial intelligence techniques are not explored in the context of infrared medical images and opens up a wide range of opportunities for further research to make clinical thermography into assistive technology for the medical community.},
  archive      = {J_COIN},
  author       = {Kaushik Raghavan and Sivaselvan Balasubramanian and Kamakoti Veezhinathan},
  doi          = {10.1111/coin.12660},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12660},
  shortjournal = {Comput. Intell.},
  title        = {Explainable artificial intelligence for medical imaging: Review and experiments with infrared breast images},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Masked self-supervised pre-training model for EEG-based
emotion recognition. <em>COIN</em>, <em>40</em>(3), e12659. (<a
href="https://doi.org/10.1111/coin.12659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG), as a tool capable of objectively recording brain electrical signals during emotional expression, has been extensively utilized. Current technology heavily relies on datasets, with its performance being limited by the size of the dataset and the accuracy of its annotations. At the same time, unsupervised learning and contrastive learning methods largely depend on the feature distribution within datasets, thus requiring training tailored to specific datasets for optimal results. However, the collection of EEG signals is influenced by factors such as equipment, settings, individuals, and experimental procedures, resulting in significant variability. Consequently, the effectiveness of models is heavily dependent on dataset collection efforts conducted under stringent objective conditions. To address these challenges, we introduce a novel approach: employing a self-supervised pre-training model, to process data across different datasets. This model is capable of operating effectively across multiple datasets. The model conducts self-supervised pre-training without the need for direct access to specific emotion category labels, enabling it to pre-train and extract universally useful features without predefined downstream tasks. To tackle the issue of semantic expression confusion, we employed a masked prediction model that guides the model to generate richer semantic information through learning bidirectional feature combinations in sequence. Addressing challenges such as significant differences in data distribution, we introduced adaptive clustering techniques that manage by generating pseudo-labels across multiple categories. The model is capable of enhancing the expression of hidden features in intermediate layers during the self-supervised training process, enabling it to learn common hidden features across different datasets. This study, by constructing a hybrid dataset and conducting extensive experiments, demonstrated two key findings: (1) our model performs best on multiple evaluation metrics; (2) the model can effectively integrate critical features from different datasets, significantly enhancing the accuracy of emotion recognition.},
  archive      = {J_COIN},
  author       = {Xinrong Hu and Yu Chen and Jinlin Yan and Yuan Wu and Lei Ding and Jin Xu and Jun Cheng},
  doi          = {10.1111/coin.12659},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12659},
  shortjournal = {Comput. Intell.},
  title        = {Masked self-supervised pre-training model for EEG-based emotion recognition},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application of concept drift detection and adaptive
framework for non linear time series data from cardiac surgery.
<em>COIN</em>, <em>40</em>(3), e12658. (<a
href="https://doi.org/10.1111/coin.12658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of machine learning (ML) models deployed in dynamic environments tends to decline over time due to disparities between the data used for training and the upcoming data available for prediction, which is commonly known as drift. Therefore, it is important for ML models to be capable of detecting any changes or drift in the data distribution and updating the ML model accordingly. This study presents various drift detection techniques to identify drift in the survival outcomes of patients who underwent cardiac surgery. Additionally, this study proposes several drift adaptation strategies, such as adaptive learning, incremental learning, and ensemble learning. Through a detailed analysis of the results, the study confirms the superior performance of ensemble model, achieving a minimum mean absolute error (MAE) of 10.684 and 2.827 for predicting hospital stay and ICU stay, respectively. Furthermore, the models that incorporate a drift adaptive framework exhibit superior performance compared to the models that do not include such a framework.},
  archive      = {J_COIN},
  author       = {Rajarajan Ganesan and Tarunpreet Kaur and Alisha Mittal and Mansi Sahi and Sushant Konar and Tanvir Samra and Goverdhan Dutt Puri and Shayam Kumar Singh Thingnum and Nitin Auluck},
  doi          = {10.1111/coin.12658},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12658},
  shortjournal = {Comput. Intell.},
  title        = {Application of concept drift detection and adaptive framework for non linear time series data from cardiac surgery},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust colored point cloud alignment based on l*a*b* guided
and cauchy kernel. <em>COIN</em>, <em>40</em>(3), e12657. (<a
href="https://doi.org/10.1111/coin.12657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision agriculture benefits from point set registration, which can monitor plant health and growth in real time, promote the precise application of fertilizers and pesticides, and provide technical support for achieving sustainable development of agriculture. In this work, we propose a robust point set registration method for precision agriculture based on L*a*b* color guidance, bidirectional search and Cauchy distribution. First, the L*a*b* color guidance is applied to establish accurate correspondences between agricultural RGB-D data. Second, the bidirectional nearest neighbor search strategy between point sets improves the reliability of establishing correspondences and broadens the convergence domain of the algorithm. Third, Cauchy distribution is utilized as an energy function for noise suppression, which further improves the robustness of the algorithm in dealing with complex vegetation scenes. Finally, results of ablation and simulation experiments indicate that the proposed registration algorithm can achieve more accurate and robust alignment results than other classic and state-of-the-art point cloud registration algorithms to achieve monitoring and comparison of plant growth.},
  archive      = {J_COIN},
  author       = {Teng Wan and Shaoyi Du and Qiang Zhang and Ying Qi and Chunyao Huang and Wei Zeng},
  doi          = {10.1111/coin.12657},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12657},
  shortjournal = {Comput. Intell.},
  title        = {Robust colored point cloud alignment based on l*a*b* guided and cauchy kernel},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Utilizing passage-level relevance and kernel pooling for
enhancing BERT-based document reranking. <em>COIN</em>, <em>40</em>(3),
e12656. (<a href="https://doi.org/10.1111/coin.12656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pre-trained language model (PLM) based on the Transformer encoder, namely BERT, has achieved state-of-the-art results in the field of Information Retrieval. Existing BERT-based ranking models divide documents into passages and aggregate passage-level relevance to rank the document list. However, these common score aggregation strategies cannot capture important semantic information such as document structure and have not been extensively studied. In this article, we propose a novel kernel-based score pooling system to capture document-level relevance by aggregating passage-level relevance. In particular, we propose and study several representative kernel pooling functions and several different document ranking strategies based on passage-level relevance. Our proposed framework KnBERT naturally incorporates kernel functions from the passage level into the BERT-based re-ranking method, which provides a promising avenue for building universal retrieval-then-rerank information retrieval systems. Experiments conducted on two widely used TREC Robust04 and GOV2 test datasets show that the KnBERT has made significant improvements over other BERT-based ranking approaches in terms of MAP, P@20, and NDCG@20 indicators with no extra or even less computations.},
  archive      = {J_COIN},
  author       = {Min Pan and Shuting Zhou and Teng Li and Yu Liu and Quanli Pei and Angela J. Huang and Jimmy X. Huang},
  doi          = {10.1111/coin.12656},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12656},
  shortjournal = {Comput. Intell.},
  title        = {Utilizing passage-level relevance and kernel pooling for enhancing BERT-based document reranking},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel feature integration method for named entity
recognition model in product titles. <em>COIN</em>, <em>40</em>(3),
e12654. (<a href="https://doi.org/10.1111/coin.12654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity recognition of product titles is essential for retrieving and recommending product information. Due to the irregularity of product title text, such as informal sentence structure, a large number of professional attribute words, a large number of unrelated independent entities of various combinations, the existing general named entity recognition model is limited in the e-commerce field of product title entity recognition. Most of the current studies focus on only one of the two challenges instead of considering the two challenges together. Our approach proposes NEZHA-CNN-GlobalPointer architecture with the addition of label semantic network, and uses multigranularity contextual and label semantic information to fully capture the internal structure and category information of words and texts to improve the entity recognition accuracy. Through a series of experiments, we proved the efficiency of our approach over a dataset of Chinese product titles from JD.com, improving the F1-value by 5.98%, when compared to the BERT-LSTM-CRF model on the product title corpus.},
  archive      = {J_COIN},
  author       = {Shiqi Sun and Jingyuan Li and Kun Zhang and Xinghang Sun and Jianhe Cen and Yuanzhuo Wang},
  doi          = {10.1111/coin.12654},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12654},
  shortjournal = {Comput. Intell.},
  title        = {A novel feature integration method for named entity recognition model in product titles},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Object detection for caries or pit and fissure sealing
requirement in children’s first permanent molars. <em>COIN</em>,
<em>40</em>(3), e12653. (<a
href="https://doi.org/10.1111/coin.12653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dental caries, a common oral disease, poses serious risks if untreated, necessitating effective preventive measures like pit and fissure sealing. However, the reliance on experienced dentists for pit and fissures or caries detection limits accessibility, potentially leading to missed treatment opportunities, especially among children. To bridge this gap, we leverage deep learning in object detection to develop a method for autonomously identifying caries and determining pit and fissure sealing requirements using smartphone oral photos. We test several detection models and adopt a tiling strategy to reduce information loss during image pre-processing. Our implementation achieves 72.3 mAP.5 with the YOLOXs model and tiling strategy. We enhance accessibility by deploying the pre-trained network as a WeChat applet on mobile devices, enabling in-home detection by parents or guardians. In addition, our data set of children&#39;s first permanent molars will also aid in the broader study of pediatric oral disease.},
  archive      = {J_COIN},
  author       = {Chenyao Jiang and Shiyao Zhai and Hengrui Song and Yuqing Ma and Yachen Fan and Yancheng Fang and Dongmei Yu and Canyang Zhang and Sanyang Han and Runming Wang and Yong Liu and Zhenglin Chen and Jianbo Li and Peiwu Qin},
  doi          = {10.1111/coin.12653},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12653},
  shortjournal = {Comput. Intell.},
  title        = {Object detection for caries or pit and fissure sealing requirement in children&#39;s first permanent molars},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Breast tumor detection using multi-feature block based
neural network by fusion of CT and MRI images. <em>COIN</em>,
<em>40</em>(3), e12652. (<a
href="https://doi.org/10.1111/coin.12652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiologists and clinicians must automatically examine breast and tumor locations and sizes accurately. In recent years, several neural network-based feature fusion versions have been created to improve medical image segmentation. Multi-modal image fusion photos may efficiently identify tumors. This work uses image fusion to identify computed tomography and magnetic resonance imaging alterations. A Gauss-log ratio operator is recommended for difference image production. The Gauss-log ratio and log ratio difference image complement the objective of improving the difference map through image fusion. The feature change matrix extracts edge, texture, and intensity from each picture pixel. The final change detection map classifies feature vectors as “changed” or “unchanged” which has been mapped for high-resolution or low-resolution pixels. This paper proposes a multi-feature blocks (MFB) based neural network for multi-feature fusion. This neural network modeling approach globalizes pixel spatial relationships. MFB-based feature fusion also aims to capture channel interactions between feature maps. The proposed technique outperforms state-of-the-art approaches which have been discussed in detail in experimental results section.},
  archive      = {J_COIN},
  author       = {Bersha Kumari and Amita Nandal and Arvind Dhaka},
  doi          = {10.1111/coin.12652},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12652},
  shortjournal = {Comput. Intell.},
  title        = {Breast tumor detection using multi-feature block based neural network by fusion of CT and MRI images},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cost-sensitive tree SHAP for explaining cost-sensitive
tree-based models. <em>COIN</em>, <em>40</em>(3), e12651. (<a
href="https://doi.org/10.1111/coin.12651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cost-sensitive ensemble learning as a combination of two approaches, ensemble learning and cost-sensitive learning, enables generation of cost-sensitive tree-based ensemble models using the cost-sensitive decision tree (CSDT) learning algorithm. In general, tree-based models characterize nice graphical representation that can explain a model&#39;s decision-making process. However, the depth of the tree and the number of base models in the ensemble can be a limiting factor in comprehending the model&#39;s decision for each sample. The CSDT models are widely used in finance (e.g., credit scoring and fraud detection) but lack effective explanation methods. We previously addressed this gap with cost-sensitive tree Shapley Additive Explanation Method (CSTreeSHAP), a cost-sensitive tree explanation method for the single-tree CSDT model. Here, we extend the introduced methodology to cost-sensitive ensemble models, particularly cost-sensitive random forest models. The paper details the theoretical foundation and implementation details of CSTreeSHAP for both single CSDT and ensemble models. The usefulness of the proposed method is demonstrated by providing explanations for single and ensemble CSDT models trained on well-known benchmark credit scoring datasets. Finally, we apply our methodology and analyze the stability of explanations for those models compared to the cost-insensitive tree-based models. Our analysis reveals statistically significant differences between SHAP values despite seemingly similar global feature importance plots of the models. This highlights the value of our methodology as a comprehensive tool for explaining CSDT models.},
  archive      = {J_COIN},
  author       = {Marija Kopanja and Stefan Hačko and Sanja Brdar and Miloš Savić},
  doi          = {10.1111/coin.12651},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12651},
  shortjournal = {Comput. Intell.},
  title        = {Cost-sensitive tree SHAP for explaining cost-sensitive tree-based models},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A SDN improvement scheme for multi-path QUIC transmission in
satellite networks. <em>COIN</em>, <em>40</em>(3), e12650. (<a
href="https://doi.org/10.1111/coin.12650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the development of low-earth orbit broadband satellites, the combination of multi-path transmission and software-defined networking (SDN) for satellite networks has seen rapid advancement. The integration of SDN and multi-path transmission contributes to improving the efficiency of transmission and reducing network congestion. However, the current SDN controllers do not support the multi-path QUIC protocol (MPQUIC), and the routing algorithm used in current satellite networks based on minimum hop count struggles to meet the real-time requirements for some applications. Therefore, this paper designs and implements an SDN controller that supports the MPQUIC protocol and proposes a multi-objective optimization-based routing algorithm. This algorithm selects paths with lower propagation delays and higher available bandwidth for subflow transmission to improve transmission throughput. Considering the high-speed mobility of satellite nodes and frequent link switching, this paper also designs a flow table update algorithm based on the predictability of satellite network topology. It enables proactive rerouting upon link switching, ensuring stable transmission. The performance of the proposed solution is evaluated through satellite network simulation environments. The experimental results highlight that SDN-MPQUIC significantly improves performance metrics: it reduces average completion time by 37.3% to 59.3% compared to QSMPS and by 52.8% to 72.4% compared to Disjoint for files with different sizes. Additionally, SDN-MPQUIC achieves an average throughput improvement of 81.4% compared to QSMPS and 147.8% compared to Disjoint, while demonstrating a 26.3% lower retransmission rate than QSMPS.},
  archive      = {J_COIN},
  author       = {Hongxin Ma and Meng Wang and Hao Lv and Jinyao Liu and Xiaoqiang Di and Hui Qi},
  doi          = {10.1111/coin.12650},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12650},
  shortjournal = {Comput. Intell.},
  title        = {A SDN improvement scheme for multi-path QUIC transmission in satellite networks},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Continuous identity authentication protocol against quantum
attacks in satellite integrated smart grid. <em>COIN</em>,
<em>40</em>(3), e12647. (<a
href="https://doi.org/10.1111/coin.12647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the issue of low efficiency caused by the repeated use of quantum attack resistant static identity authentication methods in a satellite integrated smart grid, this paper proposes a quantum attack resistant continuous identity authentication protocol. First, in the initial authentication stage, in order to reduce computational complexity, the key encryption mechanism in the CRYSTALS-Kyber algorithm was improved and combined with the NTRU message recovery digital signature scheme to construct a lattice based explicit AKE (Kyber NTRU. AKE), which achieved mutual authentication and negotiated shared tokens. Second, in the continuous authentication stage, incorporating quantum attack resistant tokens into the current algorithm to improve authentication efficiency. The formal analysis results indicate that compared to the weakly forward secure Kyber.AKE in the CRYSTALS-Kyber algorithm, Kyber-NTRU.AKE achieves complete forward secrecy, while the non-formal analysis results demonstrate the security of the continuous authentication phase. Through theoretical analysis and efficiency comparison with Cyber.AKE, the analysis shows that the Cyber-NTRU.AKE has higher computational and communication efficiency than Cyber.AKE.},
  archive      = {J_COIN},
  author       = {Chao Huang and Min Yang and Bo Li and Lin Yu},
  doi          = {10.1111/coin.12647},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12647},
  shortjournal = {Comput. Intell.},
  title        = {Continuous identity authentication protocol against quantum attacks in satellite integrated smart grid},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MultiCogniGraph: A multimodal data fusion and graph
convolutional network-based multi-hop reasoning method for large
equipment fault diagnosis. <em>COIN</em>, <em>40</em>(3), e12646. (<a
href="https://doi.org/10.1111/coin.12646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As industrial production escalates in scale and complexity, the rapid localization and diagnosis of equipment failures have become a core technical challenge. In response to the demand for intelligent fault diagnosis in large-scale industrial equipment, this study presents “MultiCogniGraph”—a multi-hop reasoning diagnostic method that integrates multimodal data fusion, knowledge graphs, and graph convolutional networks (GCN). This method leverages internet of things (IoT) sensor data, small-sample imagery, and expert knowledge to comprehensively characterize the equipment state and accurately detect subtle distinctions in fault patterns. Utilizing a knowledge graph to synthesize data from multiple sources and deep reasoning with GCN, “MultiCogniGraph” achieves swift and effective fault localization and diagnosis. The integration of these techniques not only enhances the efficiency and accuracy of fault diagnosis but also its interpretability, marking a new direction in the field of intelligent fault diagnostics.},
  archive      = {J_COIN},
  author       = {Sen Chen and Jian Wang},
  doi          = {10.1111/coin.12646},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12646},
  shortjournal = {Comput. Intell.},
  title        = {MultiCogniGraph: A multimodal data fusion and graph convolutional network-based multi-hop reasoning method for large equipment fault diagnosis},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GMINN: Gate-enhanced multi-space interaction neural networks
for click-through rate prediction. <em>COIN</em>, <em>40</em>(3),
e12645. (<a href="https://doi.org/10.1111/coin.12645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click-through rate (CTR) prediction is a pivotal challenge in recommendation systems. Existing models are prone to disturbances from noise and redundant features, hindering their ability to fully capture implicit and higher-order feature interactions present in sparse feature data. Moreover, conventional dual-tower models overlook the significance of layer-level feature interactions. To address these limitations, this article introduces G ate-enhanced M ulti-space I nteractive N eural N etworks (GMINN), a novel model for CTR prediction. GMINN adopts a dual-tower architecture in which a multi-space interaction layer is introduced after each layer in the dual-tower deep neural network. This layer allocates features into multiple subspaces and employs matrix multiplication to establish layer-level interactions between the dual towers. Simultaneously, a field-aware gate mechanism is proposed to extract crucial latent information from the original features. Experimental validation on publicly available datasets, Criteo and Avazu, demonstrates the superiority of the proposed GMINN model. Comparative analyses against baseline models reveal that GMINN substantially improves up to 4.09% in AUC and a maximum reduction of 7.21% in Logloss. Additionally, ablation experiments provide further validation of the effectiveness of GMINN.},
  archive      = {J_COIN},
  author       = {Xingyu Feng and Xuekang Yang and Boyun Zhou},
  doi          = {10.1111/coin.12645},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12645},
  shortjournal = {Comput. Intell.},
  title        = {GMINN: Gate-enhanced multi-space interaction neural networks for click-through rate prediction},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Low overhead vector codes with combination property and
zigzag decoding for edge-aided computing in UAV network. <em>COIN</em>,
<em>40</em>(3), e12642. (<a
href="https://doi.org/10.1111/coin.12642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Codes that possess combination property (CP) and zigzag decoding (ZD) simultaneously (CP-ZD) has broad application into edge aided distributed systems, including distributed storage, coded distributed computing (CDC), and CDC-structured distributed training. Existing CP-ZD code designs are based on scalar code, where one node stores exactly one encoded packet. The drawback is that the induced overhead is high. In order to significantly reduce the overhead, vector CP-ZD codes are designed, where vector means the number of stored encoded packets in one node is extended from one to multiple. More specifically, in detailed code construction, cyclic shift is proposed, and the shifts are carefully designed for cases that each node stores two, three, and four packets, respectively. Comparisons show that the overhead is reduced significantly.},
  archive      = {J_COIN},
  author       = {Mingjun Dai and Ronghao Huang and Jinjin Wang and Bingchun Li},
  doi          = {10.1111/coin.12642},
  journal      = {Computational Intelligence},
  month        = {6},
  number       = {3},
  pages        = {e12642},
  shortjournal = {Comput. Intell.},
  title        = {Low overhead vector codes with combination property and zigzag decoding for edge-aided computing in UAV network},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detection of multi-class lung diseases based on customized
neural network. <em>COIN</em>, <em>40</em>(2), e12649. (<a
href="https://doi.org/10.1111/coin.12649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the medical image processing domain, deep learning methodologies have outstanding performance for disease classification using digital images such as X-rays, magnetic resonance imaging (MRI), and computerized tomography (CT). However, accurate diagnosis of disease by medical personnel can be challenging in certain cases, such as the complexity of interpretation and non-availability of expert personnel, difficulty at pixel-level analysis, etc. Computer-aided diagnostic (CAD) systems with proper training have shown the potential to enhance diagnostic accuracy and efficiency. With the exponential growth of medical data, CAD systems can analyze and extract valuable information by assisting medical personnel during the disease diagnostic process. To overcome these challenges, this research introduces CX-RaysNet, a novel deep-learning framework designed for the automatic identification of various lung disease classes in digital chest X-ray images. The core novelty of the CX-RaysNet framework lies in the integration of both convolutional and group convolutional layers, along with the usage of small filter sizes and the incorporation of dropout regularization. This phenomenon helps us optimize the model&#39;s ability to distinguish minute features that reveal different lung diseases. Additionally, data augmentation techniques are implemented to augment the training and testing datasets, which enhances the model&#39;s robustness and generalizability. The performance evaluation of CX-RaysNet reveals promising results, with the proposed model achieving a multi-class classification accuracy of 97.25%. Particularly, this study represents the first attempt to optimize a model specifically for low-power embedded devices, aiming to improve the accuracy of disease detection while minimizing computational resources.},
  archive      = {J_COIN},
  author       = {Azmat Ali and Yulin Wang and Xiaochuan Shi},
  doi          = {10.1111/coin.12649},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  pages        = {e12649},
  shortjournal = {Comput. Intell.},
  title        = {Detection of multi-class lung diseases based on customized neural network},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph embedded low-light image enhancement transformer based
on federated learning for internet of vehicle under tunnel environment.
<em>COIN</em>, <em>40</em>(2), e12648. (<a
href="https://doi.org/10.1111/coin.12648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Vehicles (IoV) autonomous driving technology based on deep learning has achieved great success. However, under the tunnel environment, the computer vision-based IoV may fail due to low illumination. In order to handle this issue, this paper deploys an image enhancement module at the terminal of the IoV to alleviate the low illumination influence. The enhanced images can be submitted through IoT to the cloud server for further processing. The core algorithm of image enhancement is implemented by a dynamic graph embedded transformer network based on federated learning which can fully utilize the data resources of multiple devices in IoV and improve the generalization. Extensive comparative experiments are conducted on the publicly available dataset and the self-built dataset which is collected under the tunnel environment. Compared with other deep models, all results confirm that the proposed graph embedded Transformer model can effectively enhance the detail information of the low-light image, which can greatly improve the following tasks in IoV.},
  archive      = {J_COIN},
  author       = {Yuan Shu and Fuxi Zhu and Zhongqiu Zhang and Min Zhang and Jie Yang and Yi Wang and Jun Wang},
  doi          = {10.1111/coin.12648},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  pages        = {e12648},
  shortjournal = {Comput. Intell.},
  title        = {Graph embedded low-light image enhancement transformer based on federated learning for internet of vehicle under tunnel environment},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contour wavelet diffusion: A fast and high-quality image
generation model. <em>COIN</em>, <em>40</em>(2), e12644. (<a
href="https://doi.org/10.1111/coin.12644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models can generate high-quality images and have attracted increasing attention. However, diffusion models adopt a progressive optimization process and often have long training and inference time, which limits their application in realistic scenarios. Recently, some latent space diffusion models have partially accelerated training speed by using parameters in the feature space, but additional network structures still require a large amount of unnecessary computation. Therefore, we propose the Contour Wavelet Diffusion method to accelerate the training and inference speed. First, we introduce the contour wavelet transform to extract anisotropic low-frequency and high-frequency components from the input image, and achieve acceleration by processing these down-sampling components. Meanwhile, due to the good reconstructive properties of wavelet transforms, the quality of generated images can be maintained. Second, we propose a Batch-normalized stochastic attention module that enables the model to effectively focus on important high-frequency information, further improving the quality of image generation. Finally, we propose a balanced loss function to further improve the convergence speed of the model. Experimental results on several public datasets show that our method can significantly accelerate the training and inference speed of the diffusion model while ensuring the quality of generated images.},
  archive      = {J_COIN},
  author       = {Yaoyao Ding and Xiaoxi Zhu and Yuntao Zou},
  doi          = {10.1111/coin.12644},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  pages        = {e12644},
  shortjournal = {Comput. Intell.},
  title        = {Contour wavelet diffusion: A fast and high-quality image generation model},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel algorithm machine translation for language translation
tool. <em>COIN</em>, <em>40</em>(2), e12643. (<a
href="https://doi.org/10.1111/coin.12643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy matching techniques are the presently used methods in translating the words. Neural machine translation and statistical machine translation are the methods used in MT. In machine translator tool, the strategy employed for translation needs to handle large amount of datasets and therefore the performance in retrieving correct matching output can be affected. In order to improve the matching score of MT, the advanced techniques can be presented by modifying the existing fuzzy based translator and neural machine translator. The conventional process of modifying architectures and encoding schemes are tedious process. Similarly, the preprocessing of datasets also involves more time consumption and memory utilization. In this article, a new spider web based searching enhanced translation is presented to be employed with the neural machine translator. The proposed scheme enables deep searching of available dataset to detect the accurate matching result. In addition, the quality of translation is improved by presenting an optimal selection scheme for using the sentence matches in source augmentation. The matches retrieved using various matching scores are applied to an optimization algorithm. The source augmentation using optimal retrieved matches increases the translation quality. Further, the selection of optimal match combination helps to reduce time requirement, since it is not necessary to test all retrieved matches in finding target sentence. The performance of translation is validated by measuring the quality of translation using BLEU and METEOR scores. These two scores can be achieved for the TA-EN language pairs in different configurations of about 92% and 86%, correspondingly. The results are evaluated and compared with other available NMT methods to validate the work.},
  archive      = {J_COIN},
  author       = {K. Jayasakthi Velmurugan and G. Sumathy and K. V. Pradeep},
  doi          = {10.1111/coin.12643},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  pages        = {e12643},
  shortjournal = {Comput. Intell.},
  title        = {Novel algorithm machine translation for language translation tool},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel mixture allocation models for topic learning.
<em>COIN</em>, <em>40</em>(2), e12641. (<a
href="https://doi.org/10.1111/coin.12641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Latent Dirichlet allocation (LDA) is one of the major models used for topic modelling. A number of models have been proposed extending the basic LDA model. There has also been interesting research to replace the Dirichlet prior of LDA with other pliable distributions like generalized Dirichlet, Beta-Liouville and so forth. Owing to the proven efficiency of using generalized Dirichlet (GD) and Beta-Liouville (BL) priors in topic models, we use these versions of topic models in our paper. Furthermore, to enhance the support of respective topics, we integrate mixture components which gives rise to generalized Dirichlet mixture allocation and Beta-Liouville mixture allocation models respectively. In order to improve the modelling capabilities, we use variational inference method for estimating the parameters. Additionally, we also introduce an online variational approach to cater to specific applications involving streaming data. We evaluate our models based on its performance on applications related to text classification, image categorization and genome sequence classification using a supervised approach where the labels are used as an observed variable within the model.},
  archive      = {J_COIN},
  author       = {Kamal Maanicshah and Manar Amayri and Nizar Bouguila},
  doi          = {10.1111/coin.12641},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  pages        = {e12641},
  shortjournal = {Comput. Intell.},
  title        = {Novel mixture allocation models for topic learning},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An effective graph embedded YOLOv5 model for forest fire
detection. <em>COIN</em>, <em>40</em>(2), e12640. (<a
href="https://doi.org/10.1111/coin.12640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing YOLOv5-based framework has achieved great success in the field of target detection. However, in forest fire detection tasks, there are few high-quality forest fire images available, and the performance of the YOLO model has suffered a serious decline in detecting small-scale forest fires. Making full use of context information can effectively improve the performance of small target detection. To this end, this paper proposes a new graph-embedded YOLOv5 forest fire detection framework, which can improve the performance of small-scale forest fire detection using different scales of context information. To mine local context information, we design a spatial graph convolution operation based on the message passing neural network (MPNN) mechanism. To utilize global context information, we introduce a multi-head self-attention (MSA) module before each YOLO head. The experimental results on FLAME and our self-built fire dataset show that our proposed model improves the accuracy of small-scale forest fire detection. The proposed model achieves high performance in real-time performance by fully utilizing the advantages of the YOLOv5 framework.},
  archive      = {J_COIN},
  author       = {Hui Yuan and Zhumao Lu and Ruizhe Zhang and Jinsong Li and Shuai Wang and Jingjing Fan},
  doi          = {10.1111/coin.12640},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  pages        = {e12640},
  shortjournal = {Comput. Intell.},
  title        = {An effective graph embedded YOLOv5 model for forest fire detection},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiscale attention for few-shot image classification.
<em>COIN</em>, <em>40</em>(2), e12639. (<a
href="https://doi.org/10.1111/coin.12639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the application of traditional deep learning methods in the agricultural field using remote sensing techniques, such as crop area and growth monitoring, crop classification, and agricultural disaster monitoring, has been greatly facilitated by advancements in deep learning. The accuracy of image classification plays a crucial role in these applications. Although traditional deep learning methods have achieved significant success in remote sensing image classification, they often involve convolutional neural networks with a large number of parameters that require extensive optimization using numerous remote sensing images for training purposes. To address these challenges, we propose a novel approach called multiscale attention network (MAN) for sample-based remote sensing image classification. This method consists primarily of feature extractors and attention modules to effectively utilize different scale features through multiscale feature training during the training phase. We evaluate our proposed method on three datasets comprising agricultural remote sensing images and observe superior performance compared to existing approaches. Furthermore, we validate its generalizability by testing it on an oil well indicator diagram specifically designed for classification tasks.},
  archive      = {J_COIN},
  author       = {Tong Zhou and Changyin Dong and Junshu Song and Zhiqiang Zhang and Zhen Wang and Bo Chang and Dechun Chen},
  doi          = {10.1111/coin.12639},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  pages        = {e12639},
  shortjournal = {Comput. Intell.},
  title        = {Multiscale attention for few-shot image classification},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust fine-grained visual recognition with images based on
internet of things. <em>COIN</em>, <em>40</em>(2), e12638. (<a
href="https://doi.org/10.1111/coin.12638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Labeling fine-grained objects manually is extremely challenging, as it is not only label-intensive but also requires professional knowledge. Accordingly, robust learning methods for fine-grained recognition with web images collected from Internet of Things have drawn significant attention. However, training deep fine-grained models directly using untrusted web images is confronted by two primary obstacles: (1) label noise in web images and (2) domain variance between the online sources and test datasets. To this end, in this study, we mainly focus on addressing these two pivotal problems associated with untrusted web images. To be specific, we introduce an end-to-end network that collaboratively addresses these concerns in the process of separating trusted data from untrusted web images. To validate the efficacy of our proposed model, untrusted web images are first collected by utilizing the text category labels found within fine-grained datasets. Subsequently, we employ the designed deep model to eliminate label noise and ameliorate domain mismatch. And the chosen trusted web data are utilized for model training. Comprehensive experiments and ablation studies validate that our method consistently surpasses other state-of-the-art approaches for fine-grained recognition tasks in real-world scenarios, demonstrating a significant improvement margin (2.51% on CUB200-2011 and 2.92% on Stanford Dogs). The source code and models can be accessed at: https://github.com/Codeczh/FGVC-IoT .},
  archive      = {J_COIN},
  author       = {Zhenhuang Cai and Shuai Yan and Dan Huang},
  doi          = {10.1111/coin.12638},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  pages        = {e12638},
  shortjournal = {Comput. Intell.},
  title        = {Robust fine-grained visual recognition with images based on internet of things},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy preserving support vector machine based on federated
learning for distributed IoT-enabled data analysis. <em>COIN</em>,
<em>40</em>(2), e12636. (<a
href="https://doi.org/10.1111/coin.12636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a smart city, IoT devices are required to support monitoring of normal operations such as traffic, infrastructure, and the crowd of people. IoT-enabled systems offered by many IoT devices are expected to achieve sustainable developments from the information collected by the smart city. Indeed, artificial intelligence (AI) and machine learning (ML) are well-known methods for achieving this goal as long as the system framework and problem statement are well prepared. However, to better use AI/ML, the training data should be as global as possible, which can prevent the model from working only on local data. Such data can be obtained from different sources, but this induces the privacy issue where at least one party collects all data in the plain. The main focus of this article is on support vector machines (SVM). We aim to present a solution to the privacy issue and provide confidentiality to protect the data. We build a privacy-preserving scheme for SVM (SecretSVM) based on the framework of federated learning and distributed consensus. In this scheme, data providers self-organize and obtain training parameters of SVM without revealing their own models. Finally, experiments with real data analysis show the feasibility of potential applications in smart cities. This article is the extended version of that of Hsu et al. (Proceedings of the 15th ACM Asia Conference on Computer and Communications Security. ACM; 2020:904-906).},
  archive      = {J_COIN},
  author       = {Yu-Chi Chen and Song-Yi Hsu and Xin Xie and Saru Kumari and Sachin Kumar and Joel Rodrigues and Bander A. Alzahrani},
  doi          = {10.1111/coin.12636},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  pages        = {e12636},
  shortjournal = {Comput. Intell.},
  title        = {Privacy preserving support vector machine based on federated learning for distributed IoT-enabled data analysis},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FVCNet: Detection obstacle method based on feature visual
clustering network in power line inspection. <em>COIN</em>,
<em>40</em>(2), e12634. (<a
href="https://doi.org/10.1111/coin.12634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power line inspection is an important means to eliminate hidden dangers of power lines. It is a difficult research problem how to solve the low accuracy of power line inspection based on deep neural network (DNN) due to the problems of multi-view-shape, small-size object. In this paper, an automatic detection model based on Feature visual clustering network (FVCNet) for power line inspection is established. First, an unsupervised clustering method for power line inspection is proposed, and applied to construct a detection model which can recognize multi-view-shape objects and enhanced object features. Then, the bilinear interpolation method is used to Feature enhancement method, and the enhanced high-level semantics and low-level semantics are fused to solve the problems of small object size and single sample. In this paper, FVCNet is applied to the MS-COCO 2017 data set and self-made power line inspection data set, and the test accuracy is increased to 61.2% and 82.0%, respectively. Compared with other models, especially for the categories that are greatly affected by multi-view-shape, the test accuracy has been improved significantly.},
  archive      = {J_COIN},
  author       = {Qiu-Yu Wang and Xian-Long Lv and Shi-Kai Tang},
  doi          = {10.1111/coin.12634},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  pages        = {e12634},
  shortjournal = {Comput. Intell.},
  title        = {FVCNet: Detection obstacle method based on feature visual clustering network in power line inspection},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sentiment analysis incorporating convolutional neural
network into hidden markov model. <em>COIN</em>, <em>40</em>(2), e12633.
(<a href="https://doi.org/10.1111/coin.12633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of sentiments and mining of opinions have become more and more important in years because of the development of social media technologies. The methods that utilize natural language processing and lexicon-based sentiment analysis techniques to analyze people&#39;s opinions in texts require the proper extraction of sentiment words to ensure accuracy. The current issue is tackled with a novel perspective in this paper by introducing a hybrid sentiment analysis technique. This technique brings together Convolutional Neural Network (CNN) and Hidden Markov Models (HMMs), to accurately categorize text data and pinpoint feelings. The proposed method involves 1D convolutional-layer CNN to extract hidden features from comments and applying HMMs on a feature-sentence matrix, allowing for the utilization of word sequences in extracting opinions. The method effectively captures diverse text patterns by extracting a range of features from texts using CNN. Text patterns are learned using text HMM by calculating the probabilities between sequences of feature vectors and clustering feature vectors. The paper&#39;s experimental evaluation employs benchmark datasets such as CR, MR, Subj, and SST2, demonstrating that the proposed method surpasses existing sentiment analysis techniques and traditional HMMs. One of its strengths is to analyze a range of text patterns and identify crucial features that recognize the emotion of different pieces of a sentence. Additionally, the research findings highlight the improved performance of sentiment analysis tasks through the strategic use of zero padding in conjunction with the masking technique.},
  archive      = {J_COIN},
  author       = {Maryam Khanian Najafabadi},
  doi          = {10.1111/coin.12633},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  pages        = {e12633},
  shortjournal = {Comput. Intell.},
  title        = {Sentiment analysis incorporating convolutional neural network into hidden markov model},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid data fusion approach with twin CNN architecture for
enhancing image source identification in IoT environment. <em>COIN</em>,
<em>40</em>(2), e12631. (<a
href="https://doi.org/10.1111/coin.12631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of digital devices in internet of things (IoT) environment featuring advanced visual capabilities, the task of Image Source Identification (ISI) has become increasingly vital for legal purposes, ensuring the verification of image authenticity and integrity, as well as identifying the device responsible for capturing the original scene. Over the past few decades, researchers have employed both traditional and machine-learning methods to classify image sources. In the current landscape, data-driven approaches leveraging deep learning models have emerged as powerful tools for achieving higher accuracy and precision in source prediction. The primary focus of this research is to address the complexities arising from diverse image sources and variable quality in IoT-generated multimedia data. To achieve this, a Hybrid Data Fusion Approach is introduced, leveraging multiple sources of information to bolster the accuracy and robustness of ISI. This fusion methodology integrates diverse data streams from IoT devices, including metadata, sensor information, and contextual data, amalgamating them into a comprehensive data set for analysis. This study introduces an innovative approach to ISI through the implementation of a Twin Convolutional Neural Network Architecture (TCA) aimed at enhancing the efficacy of source classification. In TCA, the first CNN architecture, referred to as DnCNN, is employed to eliminate noise from the original data set, generating 256 × 256 patches for both training and testing. Subsequently, the second CNN architecture is employed to classify images based on features extracted from various convolutional layers using a 3 × 3 filter, thereby enhancing prediction efficiency. The proposed model demonstrates exceptional accuracy in effectively classifying image sources, showcasing its potential as a robust solution in the realm of ISI.},
  archive      = {J_COIN},
  author       = {Surjeet Singh and Vivek Kumar Sehgal},
  doi          = {10.1111/coin.12631},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  pages        = {e12631},
  shortjournal = {Comput. Intell.},
  title        = {A hybrid data fusion approach with twin CNN architecture for enhancing image source identification in IoT environment},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent IoT framework with GAN-synthesized images for
enhanced defect detection in manufacturing. <em>COIN</em>,
<em>40</em>(2), e12619. (<a
href="https://doi.org/10.1111/coin.12619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The manufacturing industry is always exploring techniques to optimize processes, increase product quality, and more accurately identify defects. The technique of deep learning is the strategy that will be used to handle the issues presented. However, the challenge of using AI in this domain is the small and imbalanced dataset for training affected by the severe shortage of defective data. Moreover, data acquisition requires significant labor, time, and resources. In response to these demands, this research presents an intelligent internet of things (IoT) framework enriched by generative adversarial network (GAN). This framework was developed in response to the needs outlined above. The framework applies the IoT for real-time data collection and communication, while GAN are utilized to synthesize high-fidelity images of manufacturing defects. The quality of the GAN-synthesized image is quantified by the average FID score of 8.312 for non-defective images and 7.459 for defective images. As evidenced by the similarity between the distributions of synthetic and real images, the proposed generative model can generate visually authentic and high-fidelity images. As demonstrated by the results of the defect detection experiments, the accuracy can be enhanced to the maximum of 96.5% by integrating the GAN-synthesized images with the real images. Concurrently, this integration reduces the occurrence of false alarms.},
  archive      = {J_COIN},
  author       = {Somrawee Aramkul and Prompong Sugunnasil},
  doi          = {10.1111/coin.12619},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  pages        = {e12619},
  shortjournal = {Comput. Intell.},
  title        = {Intelligent IoT framework with GAN-synthesized images for enhanced defect detection in manufacturing},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid approach for portfolio construction: Combing
two-stage ensemble forecasting model with portfolio optimization.
<em>COIN</em>, <em>40</em>(2), e12617. (<a
href="https://doi.org/10.1111/coin.12617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combining the stock prediction with portfolio optimization can improve the performance of the portfolio construction. In this article, we propose a novel portfolio construction approach by utilizing a two-stage ensemble model to forecast stock prices and combining the forecasting results with the portfolio optimization. To be specific, there are two phases in the approach: stock prediction and portfolio optimization. The stock prediction has two stages. In the first stage, three neural networks, that is, multilayer perceptron (MLP), gated recurrent unit (GRU), and long short-term memory (LSTM) are used to integrate the forecasting results of four individual models, that is, LSTM, GRU, deep multilayer perceptron (DMLP), and random forest (RF). In the second stage, the time-varying weight ordinary least square model (OLS) is utilized to combine the first-stage forecasting results to obtain the ultimate forecasting results, and then the stocks having a better potential return on investment are chosen. In the portfolio optimization, a diversified mean-variance with forecasting model named DMVF is proposed, in which an average predictive error term is considered to obtain excess returns, and a 2-norm cost function is introduced to diversify the portfolio. Using the historical data from the Shanghai stock exchange as the study sample, the results of the experiments indicate the DMVF model with two-stage ensemble prediction outperforms benchmarks in terms of return and return-risk characteristics.},
  archive      = {J_COIN},
  author       = {Wei Chen and Zinuo Liu and Lifen Jia},
  doi          = {10.1111/coin.12617},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  pages        = {e12617},
  shortjournal = {Comput. Intell.},
  title        = {A hybrid approach for portfolio construction: Combing two-stage ensemble forecasting model with portfolio optimization},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-modal fusion YoLo network for traffic detection.
<em>COIN</em>, <em>40</em>(2), e12615. (<a
href="https://doi.org/10.1111/coin.12615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic detection (including lane detection and traffic sign detection) is one of the key technologies to realize driving assistance system and auto drive system. However, most of the existing detection methods are designed based on single-modal visible light data, when there are dramatic changes in lighting in the scene (such as insufficient lighting in night), it is difficult for these methods to obtain good detection results. In view of multi-modal data can provide complementary discriminative information, based on the YoLoV5 model, this paper proposes a multi-modal fusion YoLoV5 network, which consists of three key components: the dual stream feature extraction module, the correlation feature extraction module, and the self-attention fusion module. Specifically, the dual stream feature extraction module is used to extract the features of each of the two modalities. Secondly, input the features learned from the dual stream feature extraction module into the correlation feature extraction module to learn the features with maximum correlation. Then, the extracted maximum correlation features are used to achieve information exchange between modalities through a self-attention mechanism, and thus obtain fused features. Finally, the fused features are inputted into the detection layer to obtain the final detection result. Experimental results on different traffic detection tasks can demonstrate the superiority of the proposed method.},
  archive      = {J_COIN},
  author       = {Xinwang Zheng and Wenjie Zheng and Chujie Xu},
  doi          = {10.1111/coin.12615},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  pages        = {e12615},
  shortjournal = {Comput. Intell.},
  title        = {A multi-modal fusion YoLo network for traffic detection},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using LSTM neural networks for cross-lingual phonetic speech
segmentation with an iterative correction procedure. <em>COIN</em>,
<em>40</em>(2), e12602. (<a
href="https://doi.org/10.1111/coin.12602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article describes experiments on speech segmentation using long short-term memory recurrent neural networks. The main part of the paper deals with multi-lingual and cross-lingual segmentation, that is, it is performed on a language different from the one on which the model was trained. The experimental data involves large Czech, English, German, and Russian speech corpora designated for speech synthesis. For optimal multi-lingual modeling, a compact phonetic alphabet was proposed by sharing and clustering phones of particular languages. Many experiments were performed exploring various experimental conditions and data combinations. We proposed a simple procedure that iteratively adapts the inaccurate default model to the new voice/language. The segmentation accuracy was evaluated by comparison with reference segmentation created by a well-tuned hidden Markov model-based framework with additional manual corrections. The resulting segmentation was also employed in a unit selection text-to-speech system. The generated speech quality was compared with the reference segmentation by a preference listening test.},
  archive      = {J_COIN},
  author       = {Zdeněk Hanzlíček and Jindřich Matoušek and Jakub Vít},
  doi          = {10.1111/coin.12602},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  pages        = {e12602},
  shortjournal = {Comput. Intell.},
  title        = {Using LSTM neural networks for cross-lingual phonetic speech segmentation with an iterative correction procedure},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction to capacitated single-allocation hub location
model for a flood relief distribution network. <em>COIN</em>,
<em>40</em>(2). (<a href="https://doi.org/10.1111/coin.12614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COIN},
  doi          = {10.1111/coin.12614},
  journal      = {Computational Intelligence},
  month        = {4},
  number       = {2},
  shortjournal = {Comput. Intell.},
  title        = {Correction to capacitated single-allocation hub location model for a flood relief distribution network},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Greedy-based user selection for federated graph neural
networks with limited communication resources. <em>COIN</em>,
<em>40</em>(1), e12637. (<a
href="https://doi.org/10.1111/coin.12637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, graph neural networks (GNNs) have attracted much attention in the field of machine learning due to their remarkable success in learning from graph-structured data. However, implementing GNNs in practice faces a critical bottleneck from the high complexity of communication and computation, which arises from the frequent exchange of graphic data during model training, especially in limited communication scenarios. To address this issue, we propose a novel framework of federated graph neural networks, where multiple mobile users collaboratively train the global model of graph neural networks in a federated way. The utilization of federated learning into the training of graph neural networks can help reduce the communication overhead of the system and protect the data privacy of local users. In addition, the federated training can help reduce the system computational complexity significantly. We further introduce a greedy-based user selection for the federated graph neural networks, where the wireless bandwidth is dynamically allocated among users to encourage more users to attend the federated training of neural networks. We perform the convergence analysis on the federated training of neural networks, in order to obtain some more insights on the impact of critical parameters on the system design. Finally, we perform the simulations on the coriolis ocean for reAnalysis (CORA) dataset and show the advantages of the proposed method in this paper.},
  archive      = {J_COIN},
  author       = {Hancong Huangfu and Zizhen Zhang},
  doi          = {10.1111/coin.12637},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12637},
  shortjournal = {Comput. Intell.},
  title        = {Greedy-based user selection for federated graph neural networks with limited communication resources},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Enhancing scene-text visual question answering with
relational reasoning, attention and dynamic vocabulary integration.
<em>COIN</em>, <em>40</em>(1), e12635. (<a
href="https://doi.org/10.1111/coin.12635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual question answering (VQA) is a challenging task in computer vision. Recently, there has been a growing interest in text-based VQA tasks, emphasizing the important role of textual information for better understanding of images. Effectively utilizing text information within the image is crucial for achieving success in this task. However, existing approaches often overlook the contextual information and neglect to utilize the relationships between scene-text tokens and image objects. They simply incorporate the scene-text tokens mined from the image into the VQA model without considering these important factors. In this paper, the proposed model initially analyzes the image to extract text and identify scene objects. It then comprehends the question and mines relationships among the question, OCRed text, and scene objects, ultimately generating an answer through relational reasoning by conducting semantic and positional attention. Our decoder with attention map loss enables prediction of complex answers and handles dynamic vocabularies, reducing decoding space. It outperforms softmax-based cross entropy loss in accuracy and efficiency by accommodating varying vocabulary sizes. We evaluated our model&#39;s performance on the TextVQA dataset and achieved an accuracy of 53.91% on the validation set and 53.98% on the test set. Moreover, on the ST-VQA dataset, our model obtained ANLS scores of 0.699 on the validation set and 0.692 on the test set.},
  archive      = {J_COIN},
  author       = {Mayank Agrawal and Anand Singh Jalal and Himanshu Sharma},
  doi          = {10.1111/coin.12635},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12635},
  shortjournal = {Comput. Intell.},
  title        = {Enhancing scene-text visual question answering with relational reasoning, attention and dynamic vocabulary integration},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligence and internet of things-enabled
decision support system for the prediction of bacterial stalk root
disease in maize crop. <em>COIN</em>, <em>40</em>(1), e12632. (<a
href="https://doi.org/10.1111/coin.12632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the Internet of Things (IoT) has been considered one of the most promising technologies to automate various daily life activities, that is, monitoring and prediction, it has become extremely useful for problem solving with the introduction and integration of artificial intelligence (AI)-enabled smart learning methodologies. Therefore, due to their overwhelming characteristics, AI-enabled IoTs have been used in different application environments, such as agriculture, where detection, prevention (if possible), and prediction of crop diseases, especially at the earliest possible stage, are desperately required. Bacterial stalk root is a common disease of tomatoes that severely affects its production and yield if necessary measures are not taken. In this article, AI and an IoT-enabled decision support system (DSS) have been developed to predict the possible occurrence of bacterial stalk root diseases through a sophisticated technological infrastructure. For this purpose, Arduino agricultural boards, preferably with necessary embedded sensors, are deployed in the agricultural field of maize crops to capture valuable data at a certain time interval and send it to a centralized module where AI-based DSS, which is trained on an equally similar data set, is implemented to thoroughly examine captured data values for the possible occurrence of the disease. Additionally, the proposed AI- and IoT-enabled DSS has been tested on benchmark data sets, that is, freely available online, along with real-time captured data sets. Both experimental and simulation results show that the proposed scheme has achieved the highest accuracy level in timely prediction of the underlined disease. Finally, maize crop plots with the proposed system have significantly increased the yield (production) ratio of crops.},
  archive      = {J_COIN},
  author       = {Shaha Al-Otaibi and Rahim Khan and Jehad Ali and Aftab Ahmed},
  doi          = {10.1111/coin.12632},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12632},
  shortjournal = {Comput. Intell.},
  title        = {Artificial intelligence and internet of things-enabled decision support system for the prediction of bacterial stalk root disease in maize crop},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy optimization with authentication and cost effective
storage in the wireless sensor IoTs using blockchain. <em>COIN</em>,
<em>40</em>(1), e12630. (<a
href="https://doi.org/10.1111/coin.12630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a hybrid blockchain-based authentication scheme is proposed that provides the mechanism to authenticate the randomly distributed sensor IoTs. These nodes are divided into three types: ordinary nodes, cluster heads and sink nodes. For authentication of these nodes in a Wireless Sensor IoTs (WSIoTs), a hybrid blockchain model is introduced. It consists of both private and public blockchains, which are used to authenticate ordinary nodes and cluster heads, respectively. Moreover, to handle the issue of cluster head failure due to inefficient energy consumption, Improved Heterogeneous Gateway-based Energy-Aware Multi-hop Routing (I-HMGEAR) protocol is proposed in combination with blockchain. It provides a mechanism to efficiently use the overall energy of the network. Besides, the processed data of subnetworks is stored on blockchain that causes the issue of increased monetary cost. To solve this issue, an external platform known as InterPlanetary File System (IPFS) is used, which distributively stores the data on different devices. The simulation results show that our proposed model outperforms existing clustering scheme in terms of network lifetime and data storage cost of the WSIoTs. Our proposed scheme increases the lifetime of the network as compared to existing trust management model, intrusion prevention and multi WSN authentication schemes by 17.5%, 24.2% and 19.6%, respectively.},
  archive      = {J_COIN},
  author       = {Turki Ali Alghamdi and Nadeem Javaid},
  doi          = {10.1111/coin.12630},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12630},
  shortjournal = {Comput. Intell.},
  title        = {Energy optimization with authentication and cost effective storage in the wireless sensor IoTs using blockchain},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). XAI-driven model for crop recommender system for use in
precision agriculture. <em>COIN</em>, <em>40</em>(1), e12629. (<a
href="https://doi.org/10.1111/coin.12629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture serves as the predominant driver of a country&#39;s economy, constituting the largest share of the nation&#39;s manpower. Most farmers are facing a problem in choosing the most appropriate crop that can yield better based on the environmental conditions and make profits for them. As a consequence of this, there will be a notable decline in their overall productivity. Precision agriculture has effectively resolved the issues encountered by farmers. Today&#39;s farmers may benefit from what&#39;s known as precision agriculture. This method takes into account local climate, soil type, and past crop yields to determine which varieties will provide the best results. The explainable artificial intelligence (XAI) technique is used with radial basis functions neural network and spider monkey optimization to classify suitable crops based on the underlying soil and environmental conditions. The XAI technology would provide assets in better transparency of the prediction model on deciding the most suitable crops for their farms, taking into account a variety of geographical and operational criteria. The proposed model is assessed using standard metrics like precision, recall, accuracy, and F1-score. In contrast to other cutting-edge approaches discussed in this study, the model has shown fair performance with approximately 12% better accuracy than the other models considered in the current study. Similarly, precision has improvised by 10%, recall by 11%, and F1-score by 10%.},
  archive      = {J_COIN},
  author       = {Parvathaneni Naga Srinivasu and Muhammad Fazal Ijaz and Marcin Woźniak},
  doi          = {10.1111/coin.12629},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12629},
  shortjournal = {Comput. Intell.},
  title        = {XAI-driven model for crop recommender system for use in precision agriculture},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A mechanism for network resource allocation and task
offloading in mobile edge computing and network engineering.
<em>COIN</em>, <em>40</em>(1), e12628. (<a
href="https://doi.org/10.1111/coin.12628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, most of the resource allocation methods in mobile edge computing allocate computing resources according to the time order in which task requests are calculated and unloaded, without considering the priority of tasks in practical applications. According to the computing requirements in such cases, a priority task-oriented resource allocation method is proposed. According to the average processing time of the task execution, the corresponding priority for task is given. The tasks with different priorities are weighted to allocate computing resources, which not only ensures that the high-priority tasks obtain sufficient computing resources, but also reduces the total time and energy consumption to complete the calculation of all tasks, thus improving the quality of service. The experimental results show that the proposed method can achieve better performance.},
  archive      = {J_COIN},
  author       = {Zhixu Shu and Kewang Zhang},
  doi          = {10.1111/coin.12628},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12628},
  shortjournal = {Comput. Intell.},
  title        = {A mechanism for network resource allocation and task offloading in mobile edge computing and network engineering},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HyperED: A hierarchy-aware network based on hyperbolic
geometry for event detection. <em>COIN</em>, <em>40</em>(1), e12627. (<a
href="https://doi.org/10.1111/coin.12627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event detection plays an essential role in the task of event extraction. It aims at identifying event trigger words in a sentence and classifying event types. Generally, multiple event types are usually well-organized with a hierarchical structure in real-world scenarios, and hierarchical correlations between event types can be used to enhance event detection performance. However, such kind of hierarchical information has received insufficient attention which can lead to misclassification between multiple event types. In addition, the most existing methods perform event detection in Euclidean space, which cannot adequately represent hierarchical relationships. To address these issues, we propose a novel event detection network HyperED which embeds the event context and types in Poincaré ball of hyperbolic geometry to help learn hierarchical features between events. Specifically, for the event detection context, we first leverage the pre-trained BERT or BiLSTM in Euclidean space to learn the semantic features of ED sentences. Meanwhile, to make full use of the dependency knowledge, a GNN-based model is applied when encoding event types to learn the correlations between events. Then we use a simple neural-based transformation to project the embeddings into the Poincaré ball to capture hierarchical features, and a distance score in hyperbolic space is computed for prediction. The experiments on MAVEN and ACE 2005 datasets indicate the effectiveness of the HyperED model and prove the natural advantages of hyperbolic spaces in expressing hierarchies in an intuitive way.},
  archive      = {J_COIN},
  author       = {Meng Zhang and Zhiwen Xie and Jin Liu and Xiao Liu and Xiao Yu and Bo Huang},
  doi          = {10.1111/coin.12627},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12627},
  shortjournal = {Comput. Intell.},
  title        = {HyperED: A hierarchy-aware network based on hyperbolic geometry for event detection},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event assigning based on hierarchical features and enhanced
association for chinese mayor’s hotline. <em>COIN</em>, <em>40</em>(1),
e12626. (<a href="https://doi.org/10.1111/coin.12626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, manual event assignment for Chinese mayor&#39;s hotline is still a problem of low efficiency. In this paper, we propose a computer-aided event assignment method based on hierarchical features and enhanced association. First, hierarchical features of hotline events are extracted to obtain event encoding vectors. Second, the fine-tuned RoBERTa2RoBERTa model is used to encode the “sanding” responsibility texts of Chinese local departments. Third, an association enhanced attention (AEA) mechanism is proposed to capture the correlation information of the “event-sanding” splicing vectors for the sake of obtaining matching results of “event-sanding,” and the matching results are input into the classifier. Finally, the assignment department for is obtained by a department selection module. Experimental results show that our method can achieve better performance compared with several baseline methods on HEAD (a dataset we construct independently). The ablation experiments also demonstrate the validity of each key module in our method.},
  archive      = {J_COIN},
  author       = {Gang Chen and Xiaomin Cheng and Jianpeng Chen and Xiangrong She and JiaQi Qin and Jian Chen},
  doi          = {10.1111/coin.12626},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12626},
  shortjournal = {Comput. Intell.},
  title        = {Event assigning based on hierarchical features and enhanced association for chinese mayor&#39;s hotline},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint optimization of UAV position and user grouping for
UAV-assisted hybrid NOMA systems. <em>COIN</em>, <em>40</em>(1), e12625.
(<a href="https://doi.org/10.1111/coin.12625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the use of unmanned aerial vehicles (UAVs) in assisting hybrid non-orthogonal multiple access (NOMA) systems to enhance spectrum efficiency and communication connectivity. A joint optimization problem is formulated for UAV positioning and user grouping to maximize the sum rate. The formulated problem exhibits non-convexity, calling for an effective solution. To address this issue, a two-stage approach is proposed. In the first stage, a particle swarm optimization algorithm is employed to optimize the UAV positions without considering user grouping. With the UAV positions optimized, a game theory-based approach is utilized in the second stage to optimize user grouping and improve the sum rate of the hybrid NOMA system. Simulation results demonstrate that the proposed two-stage method achieves solutions close to the global optimum of the original problem. By optimizing the positions of UAVs and user groups, the sum rate can be effectively improved. Additionally, optimizing the deployment of UAVs ensures better fairness in providing communication services to multiple users.},
  archive      = {J_COIN},
  author       = {Yuan Sun and Zhicheng Dong and Liuqing Yang and Donghong Cai and Weixi Zhou and Yanxia Zhou},
  doi          = {10.1111/coin.12625},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12625},
  shortjournal = {Comput. Intell.},
  title        = {Joint optimization of UAV position and user grouping for UAV-assisted hybrid NOMA systems},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Enhancing visual question answering with a two-way
co-attention mechanism and integrated multimodal features.
<em>COIN</em>, <em>40</em>(1), e12624. (<a
href="https://doi.org/10.1111/coin.12624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Visual question answering (VQA), a natural language answer is generated for a given image and a question related to that image. There is a significant growth in the VQA task by applying an efficient attention mechanism. However, current VQA models use region features or object features that are not adequate to improve the accuracy of generated answers. To deal with this issue, we have used a Two-way Co-Attention Mechanism (TCAM), which is capable enough to fuse different visual features (region, object, and concept) from diverse perspectives. These diverse features lead to different sets of answers, and also, there is an inherent relationship between these visual features. We have developed a powerful attention mechanism that uses these two critical aspects by using both bottom-up and top-down TCAM to extract discriminative feature information. We have proposed a Collective Feature Integration Module (CFIM) to combine multimodal attention features and thus capture the valuable information from these visual features by employing a TCAM. Further, we have formulated a Vertical CFIM for fusing the features belonging to the same class and a Horizontal CFIM for combining the features belonging to different types, thus balancing the influence of top-down and bottom-up co-attention. The experiments are conducted on two significant datasets, VQA 1.0 and VQA 2.0. On VQA 1.0, the overall accuracy of our proposed method is 71.23 on the test-dev set and 71.94 on the test-std set. On VQA 2.0, the overall accuracy of our proposed method is 75.89 on the test-dev set and 76.32 on the test-std set. The above overall accuracy clearly reflecting the superiority of our proposed TCAM based approach over the existing methods.},
  archive      = {J_COIN},
  author       = {Mayank Agrawal and Anand Singh Jalal and Himanshu Sharma},
  doi          = {10.1111/coin.12624},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12624},
  shortjournal = {Comput. Intell.},
  title        = {Enhancing visual question answering with a two-way co-attention mechanism and integrated multimodal features},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sentiment analysis on hindi tweets during COVID-19 pandemic.
<em>COIN</em>, <em>40</em>(1), e12622. (<a
href="https://doi.org/10.1111/coin.12622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A gap among the people has been created due to a lack of social interactions. The physical void has led to an increase in online interaction among users on social media platforms. Sentiment analysis of such interactions can help us analyze the general public psychology during the pandemic. However, the lack of data in non-English and low-resource languages like ‘Hindi’ makes it difficult to study it among native and non-English speaking masses. Here, we create a small collection of ‘Hindi’ tweets on COVID-19 during the pandemic containing 10,011 tweets for sentiment analysis, which is named as sentiment analysis for Hindi (SAFH). In this article, we describe the process of collecting, creating, annotating the corpus, and sentiment classification. The claims have been verified using different word embedding with a deep learning classifier through the proposed model. The achieved accuracy of the proposed model yields up to a permissible rate of 90.9%.},
  archive      = {J_COIN},
  author       = {Anita Saroj and Akash Thakur and Sukomal Pal},
  doi          = {10.1111/coin.12622},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12622},
  shortjournal = {Comput. Intell.},
  title        = {Sentiment analysis on hindi tweets during COVID-19 pandemic},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature redundancy removal for text classification using
correlated feature subsets. <em>COIN</em>, <em>40</em>(1), e12621. (<a
href="https://doi.org/10.1111/coin.12621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The curse of high dimensionality in text classification is a worrisome problem that requires efficient and optimal feature selection (FS) methods to improve classification accuracy and reduce learning time. Existing filter-based FS methods evaluate features independently of other related ones, which can then lead to selecting a large number of redundant features, especially in high-dimensional datasets, resulting in more learning time and less classification performance, whereas information theory-based methods aim to maximize feature dependency with the class variable and minimize its redundancy for all selected features, which gradually becomes impractical when increasing the feature space. To overcome the time complexity issue of information theory-based methods while taking into account the redundancy issue, in this article, we propose a new feature selection method for text classification termed correlation-based redundancy removal, which aims to minimize the redundancy using subsets of features having close mutual information scores without sequentially seeking already selected features. The idea is that it is not important to assess the redundancy of a dominant feature having high classification information with another irrelevant feature having low classification information and vice-versa since they are implicitly weakly correlated. Our method, tested on seven datasets using both traditional classifiers (Naive Bayes and support vector machines) and deep learning models (long short-term memory and convolutional neural networks), demonstrated strong performance by reducing redundancy and improving classification compared to ten competitive metrics.},
  archive      = {J_COIN},
  author       = {Lazhar Farek and Amira Benaidja},
  doi          = {10.1111/coin.12621},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12621},
  shortjournal = {Comput. Intell.},
  title        = {Feature redundancy removal for text classification using correlated feature subsets},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrated indoor positioning methods to optimize
computations and prediction accuracy enhancement. <em>COIN</em>,
<em>40</em>(1), e12620. (<a
href="https://doi.org/10.1111/coin.12620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indoor GPS location estimation encounters accuracy challenges from intricate building structures and diverse signal interferences. Trilateration methods utilising APs are typically employed to estimate indoor locations. Nevertheless, estimation errors from multipath effects and high power consumption of sensors employed in location estimation curtail battery life. To address this issue, research into location estimation methods utilising machine learning has been conducted. However, challenges involving the selection of the optimal access point locations and obtaining dense RSSI data have been noted. In this article presents a solution based on sparse radio maps for decreasing the expenses of collecting RSSI data while simultaneously enhancing indoor location accuracy through the integration of image data. The proposed approach integrates matrix-based RSSI indoor positioning (M-RIP) for initial location estimation and feature-based image indoor positioning (F-IIP) for position determination via image feature matching. Furthermore, extended area-based post-processing (EA-PP) is employed to augment M-RIP&#39;s precision and minimize image matching computation in F-IIP, improving overall performance. This article utilizes actual building data to validate the precision of the position estimation and efficiency of computation reduction using the proposed method.},
  archive      = {J_COIN},
  author       = {Yongho Kim and Jiha Kim and Cheolwoo You and Hyunhee Park},
  doi          = {10.1111/coin.12620},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12620},
  shortjournal = {Comput. Intell.},
  title        = {Integrated indoor positioning methods to optimize computations and prediction accuracy enhancement},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligence control for trust-based detection of
attackers in 5G social networks. <em>COIN</em>, <em>40</em>(1), e12618.
(<a href="https://doi.org/10.1111/coin.12618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a comprehensive framework designed for detecting and mitigating fake and potentially threatening user communities within 5G social networks. Leveraging geo-location data, community trust dynamics, and AI-driven community detection algorithms, this framework aims to pinpoint users posing potential harm. Including an artificial control model facilitates the selection of suitable community detection algorithms, coupled with a trust-based strategy to effectively identify and filter potential attackers. A distinctive feature of this framework lies in its ability to consider attributes that prove challenging for malicious users to emulate, such as the established trust within the community, geographical location, and adaptability to diverse attack scenarios. To validate its efficacy, we illustrate the framework using synthetic social network data, demonstrating its ability to distinguish potential malicious users from trustworthy ones.},
  archive      = {J_COIN},
  author       = {Davinder Kaur and Suleyman Uslu and Mimoza Durresi and Arjan Durresi},
  doi          = {10.1111/coin.12618},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12618},
  shortjournal = {Comput. Intell.},
  title        = {Artificial intelligence control for trust-based detection of attackers in 5G social networks},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cache-aided multiuser UAV-MEC networks for smart grid
networks: A DDPG approach. <em>COIN</em>, <em>40</em>(1), e12616. (<a
href="https://doi.org/10.1111/coin.12616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) is an important research topic in the field of wireless communication and mobile computing, as it can effectively decrease the latency and energy consumption due to the trade-off between the communication and computing, where some intensive computing tasks can be offloaded to computational access points (CAPs), especially when the wireless transmission channel is in good condition. This article studies how to intelligently allocate the computing capability and wireless bandwidth among users for a cache-aided multi-terminal multi-CAP MEC network with non-ideal channel estimation, where there are N $$ N $$ mobile terminals and M $$ M $$ CAPs in the network. Each terminal has some tasks that need to be computed in a fast and efficient way. For such a system, we first design the system by jointly considering the computing capability and wireless bandwidth allocation, where the computing and communication delay is used as the performance of metric. To optimize the system performance, we then employ deep deterministic policy gradient to learn an effective strategy on the allocation of computing capability and wireless bandwidth, in order to decrease the system delay as much as possible. Simulations are finally conducted to show the superiority of the proposed studies in this article, especially about the advantages from cache.},
  archive      = {J_COIN},
  author       = {Chun Yang and Zhe Wang and Binyu Xie},
  doi          = {10.1111/coin.12616},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12616},
  shortjournal = {Comput. Intell.},
  title        = {Cache-aided multiuser UAV-MEC networks for smart grid networks: A DDPG approach},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved secure PCA and LDA algorithms for intelligent
computing in IoT-to-cloud setting. <em>COIN</em>, <em>40</em>(1),
e12613. (<a href="https://doi.org/10.1111/coin.12613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of new technologies such as artificial intelligence and big data analysis requires the simultaneous development of cloud computing technology. The application of IoT-to-cloud setting has been fully applied in various industry sectors, such as sensor-cloud system which is composed of wireless sensor network and cloud computing technology. With the increasing amount and types of collected data, companies need to reduce the dimension of massive data in cloud servers for obtaining data analysis reports rapidly. Due to frequent cloud server data leaks, companies must adequately protect the privacy of some confidential data. To this end, we designed a dimension reduction method for ciphertext data in the sensor-cloud system based on the CKKS encryption scheme, principal component analysis (PCA) and linear discriminant analysis (LDA) dimension reduction algorithm. As data cannot be directly calculated using traditional PCA and LDA algorithm after encryption, we add some interactive operations and iterative calculations to replace some steps in traditional algorithms. Finally, we select the classification dataset IRIS which is commonly used in machine learning, and screen out the best encryption and calculation parameters, and efficiently realize the dimension reduction method of ciphertext data through a large number of experiments.},
  archive      = {J_COIN},
  author       = {Liu Jiasen and Wang Xu An and Li Guofeng and Yu Dan and Zhang Jindan},
  doi          = {10.1111/coin.12613},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12613},
  shortjournal = {Comput. Intell.},
  title        = {Improved secure PCA and LDA algorithms for intelligent computing in IoT-to-cloud setting},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Few-shot learning for word-level scene text script
identification. <em>COIN</em>, <em>40</em>(1), e12612. (<a
href="https://doi.org/10.1111/coin.12612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Script identification of text in scene images has attracted massive attention recently. However, the existing techniques primarily emphasize on scripts where data are available abundantly, such as English, European, or East Asian. Although these methods are robust in dealing with high-resource data, how these techniques will work on low-resource scripts has yet to be discovered. For example, in India, there is a disparity among the text scripts across the country&#39;s demographic. To bridge the research gap for resource-constraint script identification, we present a few-shot learning network called the TextScriptFSLNet. This network does not require huge training data while achieving state-of-the-art performance on benchmark datasets. Our proposed method acts in accordance with a -way -shot paradigm by splitting the train set as support and query set, respectively. The support set learns representative knowledge of each class and creates its prototypes. We use multi-kernel spatial attention fused 2-layer convolutional neural network and averaging technique to generate the prototype of each class. This spatial attention aids in grasping important information in an image and enriches the feature representation. To the best of our knowledge, the proposed work is the first of its kind in the scene text understanding domain. Additionally, we created a dataset called Indic-FSL2023 comprising 10 of the 22 officially recognized Indian scripts. The proposed method achieves the highest accuracy among the tested methods on the newly created Indic-FSL2023. Experiments are also conducted on MLe2e to demonstrate its versatility. Furthermore, we also showed how our proposed model performed concerning illumination changes and blur on scene text script images.},
  archive      = {J_COIN},
  author       = {Veronica Naosekpam and Nilkanta Sahu},
  doi          = {10.1111/coin.12612},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12612},
  shortjournal = {Comput. Intell.},
  title        = {Few-shot learning for word-level scene text script identification},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tripartite-structure transformer for hyperspectral image
classification. <em>COIN</em>, <em>40</em>(1), e12611. (<a
href="https://doi.org/10.1111/coin.12611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral images contain rich spatial and spectral information, which provides a strong basis for distinguishing different land-cover objects. Therefore, hyperspectral image (HSI) classification has been a hot research topic. With the advent of deep learning, convolutional neural networks (CNNs) have become a popular method for hyperspectral image classification. However, convolutional neural network (CNN) has strong local feature extraction ability but cannot deal with long-distance dependence well. Vision Transformer (ViT) is a recent development that can address this limitation, but it is not effective in extracting local features and has low computational efficiency. To overcome these drawbacks, we propose a hybrid classification network that combines the strengths of both CNN and ViT, names Spatial-Spectral Former(SSF). The shallow layer employs 3D convolution to extract local features and reduce data dimensions. The deep layer employs a spectral-spatial transformer module for global feature extraction and information enhancement in spectral and spatial dimensions. Our proposed model achieves promising results on widely used public HSI datasets compared to other deep learning methods, including CNN, ViT, and hybrid models.},
  archive      = {J_COIN},
  author       = {Liuwei Wan and Meili Zhou and Shengqin Jiang and Zongwen Bai and Haokui Zhang},
  doi          = {10.1111/coin.12611},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12611},
  shortjournal = {Comput. Intell.},
  title        = {Tripartite-structure transformer for hyperspectral image classification},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cache-aided UAV-assisted relaying networks: Performance
analysis and system optimization. <em>COIN</em>, <em>40</em>(1), e12610.
(<a href="https://doi.org/10.1111/coin.12610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of distributed multi-agent unmanned aerial vehicles (UAVs) for computing tasks in remote areas has gained significant traction in recent years due to their adaptability and capability to access hard-to-reach regions that are inaccessible to ground-based methods. However, establishing wireless communication between UAVs and ground-based data sources in remote areas presents considerable challenges, particularly when UAVs are in motion. To tackle this challenge, this article investigates a cache-aided relaying system in the presence of UAVs, wherein a ground-based decode-and-forward relay equipped with cache space is deployed to facilitate wireless communication between UAVs and a central data source. Within the scope of this system, we first analyze the probability of transmission outage, providing an analytical expression for performance evaluation. We commence with the case of a single stationary UAV, subsequently expanding to multiple stationary UAVs, and ultimately incorporating multiple dynamic UAVs. Subsequently, we enhance the system performance by minimizing the outage probability through efficient power resource allocation among users. By means of mathematical modeling and simulations, this research examines the influence of various factors, including the cache size at the relay and the working mode of the UAV, on the system performance. Finally, simulations are conducted to validate the proposed analysis.},
  archive      = {J_COIN},
  author       = {Zhe Wang and Chun Yang and Binyu Xie},
  doi          = {10.1111/coin.12610},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12610},
  shortjournal = {Comput. Intell.},
  title        = {Cache-aided UAV-assisted relaying networks: Performance analysis and system optimization},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced approach of multilabel learning for the arabic
aspect category detection of the hotel reviews. <em>COIN</em>,
<em>40</em>(1), e12609. (<a
href="https://doi.org/10.1111/coin.12609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many fields, like aspect category detection (ACD) in aspect-based sentiment analysis, it is necessary to label each instance with more than one label at the same time. This study tackles the multilabel classification problem in the ACD task for the Arabic language. For this purpose, we used Arabic hotel reviews from the SemEval-2016 dataset, comprising 13,113 annotated tuples provided for training (10,509) and testing (2,604). To extract valuable information, we first propose specific data preprocessing. Then, we suggest using the dynamic weighted loss function and a data augmentation method to fix the problem with this dataset&#39;s imbalance. Using two possible approaches, we develop new ways to find different categories of things in a review sentence. The first is based on classifier chains using machine learning models. The second is based on transfer learning using pretrained AraBERT fine-tuning for contextual representation. Our findings show that both approaches outperformed the related works for ACD on the Arabic SemEval-2016. Moreover, we observed that AraBERT fine-tuning performed much better and achieved a promising -score of .},
  archive      = {J_COIN},
  author       = {Asma Ameur and Sana Hamdi and Sadok Ben Yahia},
  doi          = {10.1111/coin.12609},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12609},
  shortjournal = {Comput. Intell.},
  title        = {Enhanced approach of multilabel learning for the arabic aspect category detection of the hotel reviews},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ResNLS: An improved model for stock price forecasting.
<em>COIN</em>, <em>40</em>(1), e12608. (<a
href="https://doi.org/10.1111/coin.12608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock prices forecasting has always been a challenging task. Although many research projects adopt machine learning and deep learning algorithms to address the problem, few of them pay attention to the varying degrees of dependencies between stock prices. In this paper we introduce a hybrid model that improves stock price prediction by emphasizing the dependencies between adjacent stock prices. The proposed model, ResNLS, is mainly composed of two neural architectures, ResNet and LSTM. ResNet serves as a feature extractor to identify dependencies between stock prices across time windows, while LSTM analyses the initial time-series data with the combination of dependencies which considered as residuals. In predicting the SSE Composite Index, our experiment reveals that when the closing price data for the previous five consecutive trading days is used as the input, the performance of the model (ResNLS-5) is optimal compared to those with other inputs. Furthermore, ResNLS-5 outperforms vanilla CNN, RNN, LSTM, and BiLSTM models in terms of prediction accuracy. It also demonstrates at least a 20% improvement over the current state-of-the-art baselines. To verify whether ResNLS-5 can help clients effectively avoid risks and earn profits in the stock market, we construct a quantitative trading framework for back testing. The experimental results show that the trading strategy based on predictions from ResNLS-5 can successfully mitigate losses during declining stock prices and generate profits in the periods of rising stock prices.},
  archive      = {J_COIN},
  author       = {Yuanzhe Jia and Ali Anaissi and Basem Suleiman},
  doi          = {10.1111/coin.12608},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12608},
  shortjournal = {Comput. Intell.},
  title        = {ResNLS: An improved model for stock price forecasting},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A joint hierarchical cross-attention graph convolutional
network for multi-modal facial expression recognition. <em>COIN</em>,
<em>40</em>(1), e12607. (<a
href="https://doi.org/10.1111/coin.12607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotional recognition in conversations (ERC) is increasingly being applied in various IoT devices. Deep learning-based multimodal ERC has achieved great success by leveraging diverse and complementary modalities. Although most existing methods try to adopt attention mechanisms to fuse different information, these methods ignore the complementarity between modalities. To this end, the joint cross-attention model is introduced to alleviate this issue. However, multi-scale feature information on different modalities is not utilized. Moreover, the context relationship plays an important role in feature extraction in the expression recognition task. In this paper, we propose a novel joint hierarchical graph convolution network (JHGCN) which exploits different layer features and context relationships for facial expression recognition based on audio-visual (A-V) information. Specifically, we adopt different deep networks to extract features from different modalities individually. For V modality, we construct V graph data based on patch embeddings which are extracted from the transformer encoder. Moreover, we embed the graph convolution which can leverage the intra-modality relationships with the transformer encoder. Then, the deep feature from different layers is fed to the hierarchical fusion module to enhance feature representation. At last, we use the joint cross-attention mechanism to exploit the complementary inter-modality relationships. To validate the proposed model, we have conducted various experiments on the AffWild2 and CMU-MOSI datasets. All results confirm that our proposed model achieves highly promising performance compared to the joint cross-attention model and other methods.},
  archive      = {J_COIN},
  author       = {Chujie Xu and Yong Du and Jingzi Wang and Wenjie Zheng and Tiejun Li and Zhansheng Yuan},
  doi          = {10.1111/coin.12607},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12607},
  shortjournal = {Comput. Intell.},
  title        = {A joint hierarchical cross-attention graph convolutional network for multi-modal facial expression recognition},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Short-term photovoltaic power forecasting using hybrid
contrastive learning and temporal convolutional network under future
meteorological information absence. <em>COIN</em>, <em>40</em>(1),
e12606. (<a href="https://doi.org/10.1111/coin.12606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photovoltaic (PV) power generation is widely utilized to satisfy the increasing energy demand due to its cleanness and inexhaustibility. Accurate PV power forecasting can improve the penetration of PV power in the grid. However, it is pretty challenging to predict PV power in short-term under precious future meteorological information absence conditions. To address this problem, this study proposes the hybrid Contrastive Learning and Temporal Convolutional Network (CL-TCN), and this forecasting approach consists of two parts, including model training and adaptive processes of forecasting models. In the model training stage, this forecasting method firstly trains 18 TCN models for 18 time points from 9:00 a.m. to 17:30 p.m. These TCN models are trained by only using historical PV power data samples, and each model is used to predict the next half-hour power output. The adaptive process of models means that, in a practical forecasting stage, PV power samples from historical data are firstly evaluated and scored by a CL based data scoring mechanism to search for the most similar data samples to current measured samples. Then these similar samples are further applied to training a single above-mentioned well-trained TCN model to improve its performance in forecasting the next half-hour PV power. The experimental results tested at the time resolution of 30 min demonstrate that the proposed approach has superior performance in forecasting accuracy not only in smooth PV power samples but also in fluctuating PV power samples. Moreover, the proposed CL based data scoring mechanism can filter useless data samples effectively accelerating the forecasting process.},
  archive      = {J_COIN},
  author       = {Xiaoyang Lu and Yandang Chen and Qibin Li and Pingping Yu},
  doi          = {10.1111/coin.12606},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12606},
  shortjournal = {Comput. Intell.},
  title        = {Short-term photovoltaic power forecasting using hybrid contrastive learning and temporal convolutional network under future meteorological information absence},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A progressive mesh simplification algorithm based on neural
implicit representation. <em>COIN</em>, <em>40</em>(1), e12605. (<a
href="https://doi.org/10.1111/coin.12605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Progressive mesh simplification (PM) algorithm aims to generate simplified mesh at any resolution for the input high-precision mesh, and only needs to be optimized or fitted once. Most of the existing PM algorithms are obtained based on heuristic mesh simplification algorithms, which leads to redundant storage space and poor practice-ability of the algorithm. In this article, a progressive mesh simplification algorithm based on neural implicit representation (NePM) is proposed, and NePM transforms algorithm process into an implicit continuous optimization problem through neural network and probabilistic model. NePM uses Gaussian mixture model to model high-precision mesh and samples the probabilistic model to obtain simplified meshes at different resolutions. In addition, the simplified mesh is optimized through multi-level neural network, preserving characteristics of the input high-precision mesh. Thus, the algorithm in this work lowers the memory usage of the PM and improves the practicability of the algorithm while ensuring the accuracy.},
  archive      = {J_COIN},
  author       = {Yihua Chen},
  doi          = {10.1111/coin.12605},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12605},
  shortjournal = {Comput. Intell.},
  title        = {A progressive mesh simplification algorithm based on neural implicit representation},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parallel accelerated computing architecture for dim target
tracking on-board. <em>COIN</em>, <em>40</em>(1), e12604. (<a
href="https://doi.org/10.1111/coin.12604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The real-time tracking process of dim targets in space is mainly achieved through the correlation and prediction of dots after the detection and calculation process. The on-board calculation of the tracking needs to be completed in milliseconds, and it needs to reach the microsecond level at high frame rates. For real-time tracking of dim targets in space, it is necessary to achieve universal tracking calculation acceleration in response to different space regions and complex backgrounds, which poses high requirements for engineering implementation architecture. This paper designs a Kalman filter calculation based on digital logic parallel acceleration architecture for real-time solution of dim target tracking on-board. A unified architecture of Vector Processing Element (VPE) was established for the calculation of Kalman filtering matrix, and an array computing structure based on VPE was designed to decompose the entire filtering process and form a parallel pipelined data stream. The prediction errors under different fixed point bit widths were analyzed and deduced, and the guidance methods for selecting the optimal bit width based on the statistical results were provided. The entire design was engineered based on Xilinx&#39;s XC7K325T, resulting in an energy efficiency improvement compared to previous designs. The single iteration calculation time does not exceed 0.7 microseconds, which can meet the current high frame rate target tracking requirements. The effectiveness of this design has been verified through simulation of random trajectory data, which is consistent with the theoretical calculation error.},
  archive      = {J_COIN},
  author       = {Jiyang Yu and Dan Huang and Wenjie Li and Xianjie Wang and Xiaolong Shi},
  doi          = {10.1111/coin.12604},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12604},
  shortjournal = {Comput. Intell.},
  title        = {Parallel accelerated computing architecture for dim target tracking on-board},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A semantically enhanced text retrieval framework with
abstractive summarization. <em>COIN</em>, <em>40</em>(1), e12603. (<a
href="https://doi.org/10.1111/coin.12603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, large pretrained language models (PLMs) have led a revolution in the information retrieval community. In most PLMs-based retrieval frameworks, the ranking performance broadly depends on the model structure and the semantic complexity of the input text. Sequence-to-sequence generative models for question answering or text generation have proven to be competitive, so we wonder whether these models can improve ranking effectiveness by enhancing input semantics. This article introduces SE-BERT, a semantically enhanced bidirectional encoder representation from transformers (BERT) based ranking framework that captures more semantic information by modifying the input text. SE-BERT utilizes a pretrained generative language model to summarize both sides of the candidate passage and concatenate them into a new input sequence, allowing BERT to acquire more semantic information within the constraints of the input sequence&#39;s length. Experimental results from two Text Retrieval Conference datasets demonstrate that our approach&#39;s effectiveness increasing as the length of the input text increases.},
  archive      = {J_COIN},
  author       = {Min Pan and Teng Li and Yu Liu and Quanli Pei and Ellen Anne Huang and Jimmy X. Huang},
  doi          = {10.1111/coin.12603},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12603},
  shortjournal = {Comput. Intell.},
  title        = {A semantically enhanced text retrieval framework with abstractive summarization},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A localization method of manipulator towards achieving more
precision control. <em>COIN</em>, <em>40</em>(1), e12600. (<a
href="https://doi.org/10.1111/coin.12600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The monocular vision system is a crucial branch of machine vision research widely used in multiple industries as a research hotspot in the field of vision. Although the monocular vision system is of simple structure and cost-effectiveness, its positioning accuracy is insufficient in some industries. This article researched the robot arm positioning method via monocular vision. First, we built a vision system model and designed the style of a cooperative target for target positioning. Second, a target feature screening method based on conditions is composed for the existence of interference. Furthermore, combining the principle of pose estimation on the PNP (Perspective-n-Point) problem with the results of the visual system calibration to realize the positioning of the target. Finally, complete the construction of the experimental platform and design accuracy evaluation experiments and positioning experiments. The experimental results show that the location measurement error range of the system in this article is below 4 mm, and the measurement error of the rotation angle is below 2 . The system can adapt to the requirements of general industrial use.},
  archive      = {J_COIN},
  author       = {Hongwei Gao and Hongyang Zhang and Yueqiu Jiang and Jian Sun and Jiahui Yu},
  doi          = {10.1111/coin.12600},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12600},
  shortjournal = {Comput. Intell.},
  title        = {A localization method of manipulator towards achieving more precision control},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retracted: Denoising and segmentation of brain image by
proficient blended threshold and conserve edge scrutinize technique.
<em>COIN</em>, <em>40</em>(1), e12542. (<a
href="https://doi.org/10.1111/coin.12542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unusual collection of mass tissue in human body is commonly refereed as tumor. The tumor when it is found in brain. These tumor cells have tendency to multiply and grow in rapid speed. The growth of tumors is generally uncontrollable in nature. Tumor in brain develops along the skull and it evolves to contact with the functioning of the brain. Brain tumor (BT) can be detected at the earlier stages with the help of MRI or CT scan techniques. These scanning techniques are proved to be efficient in detecting the tumor irrespective of its size. Brain tumor being a life-threatening disease has to be diagnosed at the earliest before it turns to be malignant. The current research work focuses in proposing an efficient image processing techniques by processing the MRI images of human brain which is affected by brain tumor. This process is carried out in two stages as image denoising and image segmentation which are helpful in detecting and localizing the tumor affected region in human brain. Initially, the MRI image is read and preprocessed by converting the input image into a grayscale image and noise removed by involving the proposed method. Later, the proposed image is segmented using sobel edge detection method and the image is enhanced using the image enhancement techniques. It is achieved by using the proficient blended thresholding (PBT) Segmentation method. The performance of the proposed methods is evaluated using PSNR (peak signal noise ratio) and RMSE (root mean square error). The proposed conserve edge scrutinize (CES) filter achieved highest PSNR value. Then segmentation is evaluated by five metrices: Sensitivity, Specificity, Dice, Jaccard, and Accuracy.},
  archive      = {J_COIN},
  author       = {Nehru Veerabatheran and Prabhu Venkatesan and Rakesh Kumar Mahendran},
  doi          = {10.1111/coin.12542},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12542},
  shortjournal = {Comput. Intell.},
  title        = {Retracted: Denoising and segmentation of brain image by proficient blended threshold and conserve edge scrutinize technique},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retracted: QGMS: A query growth model for personalization
and diversification of semantic search based on differential ontology
semantics using artificial intelligence. <em>COIN</em>, <em>40</em>(1),
e12514. (<a href="https://doi.org/10.1111/coin.12514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inclusion of collective intelligence through a semantic focused affective computing can incorporate intelligence to web search and ensure its compliance with the Web 3.0. In this article, a query growth model with inclusive and exclusive ontology semantics has been proposed for diversification of query recommendation in semantic search. The ontology semantics include query augmented ontology generation, agent-driven attractor-distractor generation to yield a merged ontology, and endowment of merged ontology by using hybridization of a series of knowledge bases. The strategy further includes the formulation of a semantic network and entity leveraging based on description logics (DLs) to improve the quality of query recommendation. A novel hierarchical entropy cognitive similarity covariance model has been proposed for yielding the most appropriate recommendable query words. The strategy also encompasses the user-click information for capturing the current user intents to improve the quality queries recommended in semantic search, and thereby incorporate personalization. Experimentations are conducted for the CHiC dataset and the Spring 2006 Query Log dataset and an average accuracy of 96.27% and 92.01%, respectively, with a very low false discovery rate of 0.06 and 0.1 for the respective datasets.},
  archive      = {J_COIN},
  author       = {Gerard Deepak and Arumugam Santhanavijayan},
  doi          = {10.1111/coin.12514},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12514},
  shortjournal = {Comput. Intell.},
  title        = {Retracted: QGMS: a query growth model for personalization and diversification of semantic search based on differential ontology semantics using artificial intelligence},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retracted: A remote diagnosis of parkinson’s ailment using
artificial intelligence based BPNN framework and cloud based storage
architecture for securing data in cloud environment for the application
of telecommunication technologies. <em>COIN</em>, <em>40</em>(1),
e12508. (<a href="https://doi.org/10.1111/coin.12508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voice signal analysis and identification of disease framework for Parkinson&#39;s disease (PD) is most required thing in the past few years. A new framework for determination and identification of PD is the world&#39;s most severe neurological disorder, was proposed in this article. It is the most dangerous infection which disables individuals&#39; discourse, and different attributes, for example feelings and sensation. In this work, we initially examined about a new approach for determining the PD. Second, we proposed cloud based storage architecture for securing data in cloud computing environment. Cloud based system for distinguishing and checking Parkinson infection will expand its significance in social insurance benefit in low asset setting and security examination. This structure guarantees effective handling of huge information in distributed computing condition and acquires business experiences. In the creating nations, where the greater part of the general population does not get appropriate social insurance benefits and are not concerned of Parkinson&#39;s sickness, not to mention recognizing and getting human services for PD, this framework can be extremely commonsense and helpful. The framework, PD affected patient can be effortlessly identified as well as analyzed by giving their voice tests over their telephones. The proposed frameworks are profited to accomplish 95.8% precision in the cloud condition for recognizing PD. It is normal that the proposed system will possibly empower social insurance benefit for PD patients, who live in remote territories.},
  archive      = {J_COIN},
  author       = {S. P. Santhoshkumar and H. Lilly Beaulah and Abdulrahman Saad Alqahtani and P. Parthasarathy and Azath Mubarakali},
  doi          = {10.1111/coin.12508},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12508},
  shortjournal = {Comput. Intell.},
  title        = {Retracted: A remote diagnosis of parkinson&#39;s ailment using artificial intelligence based BPNN framework and cloud based storage architecture for securing data in cloud environment for the application of telecommunication technologies},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retracted: Artificial intelligence for public perception of
drones as a tool for telecommunication technologies. <em>COIN</em>,
<em>40</em>(1), e12507. (<a
href="https://doi.org/10.1111/coin.12507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drones, a small aviation craft that can hold sensors and be directed to certain locations, have been explored and utilized in domains such as public safety, traffic monitoring, and healthcare. Yet, the scientific research of drone usage still in progress. This article investigates the following: (1) how the public perceives a drone as a healthcare tool, and (2) what the concerns are of public acceptance of drones in healthcare. A qualitative approach with demographic questions such as participants&#39; age, education level, current knowledge of drones, as well as willingness to learn about the technology was used. The contribution is to have an understanding of how the public perceives drones. The results can be used in enhancing public views of drones through skilled personnel and an educated workforce. In a conservative community such as Saudi Arabia, the public holds a relatively positive attitude towards drones. Respondents are aware of such technology from different sources, mainly TV news. Informants also did show a decent level of perceived beneficial usage of drones in healthcare. There are few participants who disclosed concerns of safety, security, and privacy for the usage of drones in healthcare due to a lack of knowledge about the technology. The results propose that government and industry stakeholders should invest more in increasing public awareness of technology. Media coverage will likely influence the public view and help the community move forward.},
  archive      = {J_COIN},
  author       = {Ala Saleh Alluhaidan},
  doi          = {10.1111/coin.12507},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12507},
  shortjournal = {Comput. Intell.},
  title        = {Retracted: Artificial intelligence for public perception of drones as a tool for telecommunication technologies},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retracted: Artificial intelligence for classification and
regression tree based feature selection method for network intrusion
detection system in various telecommunication technologies.
<em>COIN</em>, <em>40</em>(1), e12500. (<a
href="https://doi.org/10.1111/coin.12500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Now a days, secure data communication over computer network system is a major issue in which impact of feature reduction plays a vital role to secure network by early detection of intrusion. It not only keeps a deep impact on the performance of existing Intrusion Detection System (IDS) algorithms but also affects the computational complexity. Although lots of techniques have been offered for feature reduction by researchers and they have their own perks and quirks, but still they are several flows. To manipulate the same dataset for different classifiers and to select different number of features for the detection of attacks are not only having too much computational cost but also time consuming. The experiments have been carried out using “Python” programming language based library “Scikit-Learn” software on “Kddcup99” dataset from UCI machine learning repository as a test bed. In this article a classification and regression trees (CART) based feature selection algorithm has been proposed which offers optimum set of features. Further optimum set of features has been offered by our proposed work passed over various classifiers for training and testing to establish network intrusion detection system (NIDS). We have compared the performance accuracy of various existing machine learning (ML) based classification algorithms and obtained higher performance accuracy with lower computational cost. The proposed algorithm having optimum time complexity and accuracy in designing of IDS.},
  archive      = {J_COIN},
  author       = {Neeraj Kumar and Upendra Kumar},
  doi          = {10.1111/coin.12500},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12500},
  shortjournal = {Comput. Intell.},
  title        = {Retracted: Artificial intelligence for classification and regression tree based feature selection method for network intrusion detection system in various telecommunication technologies},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retracted: Multi constrained network feature approximation
based secure routing for improved quality of service in mobile ad-hoc
network. <em>COIN</em>, <em>40</em>(1), e12489. (<a
href="https://doi.org/10.1111/coin.12489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mobile ad-hoc network is well studied on the routing issues, and the security constraints around achieving higher quality of service (QoS) values are well analyzed. The main task is to establish the path to the target with reliable intermediate nodes based on quality parameters because of the lack of node mobility and central management. In a multi-constrained QoS issuance, more than the QoS requirements must be satisfied at the end of the application. There are several secure routing protocols available to improve the QoS of Manet by routing packets securely. However, they do not meet the performance requirements. To solve this problem, and efficient Multi-Constrained Network Feature Approximation (MCNFA) technique is proposed based on safe routing. The method first determines the list of paths between source and destination. According to that, the method approximates the congestion, latency, and hop count values for each route. According to the value obtained in approximation of various parameters, the legitimate weight is computed for all the routes towards the destination. According to the value of the legitimate weight, a single route is selected to perform data transmission. The MCNFA approach improves the routing performance and increases the throughput ratio and other QoS factors. The performance of the proposed method will be assessed using NS2 simulation. The results show that the proposed scheme can maintain a longer network lifecycle in tight scenarios suitable for delay-tolerant networking. The performance is compared with energy recognition and MCNFA technique-based energy-saving routing protocols in various QoS scenarios.},
  archive      = {J_COIN},
  author       = {Mahaboob John Y. M. and Ravi G},
  doi          = {10.1111/coin.12489},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12489},
  shortjournal = {Comput. Intell.},
  title        = {Retracted: Multi constrained network feature approximation based secure routing for improved quality of service in mobile ad-hoc network},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retracted: Efficient ensemble to combat flash attacks.
<em>COIN</em>, <em>40</em>(1), e12488. (<a
href="https://doi.org/10.1111/coin.12488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flash event generates enormous traffic and the cloud service providers use sustaining techniques like scaling and content delivery network to up their services. One of the main bottlenecks that the cloud service providers still find difficult to tackle is flash attacks. Illegitimate users send craftily designed packets to land up inside the server for wreaking havoc. As deep learning autoencoder has the potential to detect malicious traffic it has been used in this research study to develop an ensemble. Convolutional neural network is efficacious in overcoming the issue of overfitting; deep autoencoder is proficient in extracting features through dimensionality reduction. In order to obtain both these advantages it was decided to develop an ensemble keeping denoising autoencoder as the core element. The process of addressing a flash attack requires first detecting the presence of bot in malicious traffic, second studying its nature by observing its behavioral manifestations. Detection of botnet was achieved by three ensembles, namely, DAE_CNN, DAE_MLP, and DAE_XGB. But capturing its external manifested behavior is challenging, because the bot signatures are always in a state of flux. The simulated empirical study yielded an appreciable outcome. Its accuracy rate was 99.9% for all the three models and the false positive rates were 0, 0.006, and 0.001, respectively.},
  archive      = {J_COIN},
  author       = {Om Kumar C.U and Ponsy R. K. Sathia Bhama},
  doi          = {10.1111/coin.12488},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12488},
  shortjournal = {Comput. Intell.},
  title        = {Retracted: Efficient ensemble to combat flash attacks},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retracted: Fuzzy based rendezvous points selection for
mobile data gathering in wireless sensor network. <em>COIN</em>,
<em>40</em>(1), e12486. (<a
href="https://doi.org/10.1111/coin.12486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, fuzzy based rendezvous points selection (FRPS) technique for mobile data gathering in wireless sensor networks is proposed. At beginning, the importance of detected data is categorized into perilous and non-perilous based on the perseverance and time limit of data. Then two Sencars are set up: one for gathering perilous data by visiting straight to the corresponding sensors, the other one for gathering non-perilous data from other sensors. The rendezvous points (RPs) for visiting the Sencars are determined by using fuzzy decision model based on the input parameters energy level, buffer occupancy level, and current load. Based on the output of this model, each sensor is assigned a combined utility value. Then the sensors with high utility values are selected as RPs and the details are broadcast to the respective Sencars.},
  archive      = {J_COIN},
  author       = {Sunita Satish Patil and Thangamuthu Senthil Kumaran},
  doi          = {10.1111/coin.12486},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12486},
  shortjournal = {Comput. Intell.},
  title        = {Retracted: Fuzzy based rendezvous points selection for mobile data gathering in wireless sensor network},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retracted: Lifetime maximization energy-aware routing
protocol for route optimization to improve quality of service in
wireless sensor networks. <em>COIN</em>, <em>40</em>(1), e12485. (<a
href="https://doi.org/10.1111/coin.12485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks (WSNs) are part of the short-term networks, including sensitivity, computation, and Wi-Fi connectivity capability. Many routing, range management, and log transfer protocols are specifically designed for WSN. The previous method showed less efficiency in routing management. The proposed lifetime maximization energy-aware routing protocol (LTMEARP) protocol is known for its high routing efficiency, giving a higher lifetime and throughput performance. The requirement for a routing system approach is advanced with Internet service provider&#39;s protocols by recalculating the routing table after the link stage&#39;s substitution worldwide, leading to responses and connection failures by sharing important data after traffic. LTMEARP routing protocol has assured high availability routing performances during traffic conditions. LTMEARP support sends homogeneous and expanded nodes. Analyze a new approach to routing-based selection algorithms for homogeneous node WSNs. The number of connections is limited and must be adjusted using separate paths and header packets to meet the user&#39;s network access location. The results show that the LTMEARP has achieved quality without introducing excessive network access program overhead, which deals with the study of communication and the benefits and problems with the performance of each routing technology.},
  archive      = {J_COIN},
  author       = {Vinod Kumar R and Kavithaa G and Jayanthi D},
  doi          = {10.1111/coin.12485},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12485},
  shortjournal = {Comput. Intell.},
  title        = {Retracted: Lifetime maximization energy-aware routing protocol for route optimization to improve quality of service in wireless sensor networks},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automating smart internet of things devices in modern homes
using context-based fuzzy logic. <em>COIN</em>, <em>40</em>(1), e12370.
(<a href="https://doi.org/10.1111/coin.12370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) is mainly used to connect different embedded objects over the internet to make communication between them possible. With the help of IoT, devices find a way to interact, work together, and study from each other&#39;s experiences just like humans do. IoT finds its way in applications such as smart home, smart city, healthcare, agriculture, and so on. The name smart home arises due to the automation of the normal home appliances to make it smart. When the devices of the normal smart home are connected via the internet, they become a part of the IoT. The smart home should ensure the following characteristics such as security, comfort, convenience, and energy saving. The article presents a technique for IoT controlled devices in a smart home using context-based fuzzy logic. Fuzzy logic is mainly used to monitor and analyze the real-time data collected from the sensors in the smart homes from various environments. Context-based fuzzy logic uses a multivalued logic principle which differs from the normal Boolean logic, where the truth value lies between only zero and one (ie, true or false). The proposed smart home is implemented in a real case scenario where it yields an accuracy of 90.5%, response time of 6.41 milliseconds, and an F-measure of 97%.},
  archive      = {J_COIN},
  author       = {Chen Ming and Seifedine Kadry and A. Antony Dasel},
  doi          = {10.1111/coin.12370},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12370},
  shortjournal = {Comput. Intell.},
  title        = {Automating smart internet of things devices in modern homes using context-based fuzzy logic},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The importance of public support in the implementation of
green transportation in the smart cities. <em>COIN</em>, <em>40</em>(1),
e12326. (<a href="https://doi.org/10.1111/coin.12326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart cities are increasingly evolving, initializing new strategies, and programs that have a significant influence on policy making and scheduling while coexisting with urban facilities. To recognize urban planning offers to a smarter city context, it is now necessary to understand the contribution of the smart city in overall urban planning and vice versa. Currently, transportation has been seen as a connection to all aspects of life across the world. This article presents the results of a survey testing into whether the public supports the concept of green transportation in the smart cities. The green urban mobility model has been proposed to investigate urban traffic information to characterize important features of smart mobility in the smart cities. The development of intelligent transportation systems using the proposed model that makes traffic easier in the city to transport safe and more comfortable. The experimental results suggest the required factors of green transportation and realistic behavior of smart mobility.},
  archive      = {J_COIN},
  author       = {Jia Mao and Qi Sun and Xi Wang and BalaAnand Muthu and Sujatha Krishnamoorthy},
  doi          = {10.1111/coin.12326},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12326},
  shortjournal = {Comput. Intell.},
  title        = {The importance of public support in the implementation of green transportation in the smart cities},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel methodology for the development of an optimal
agricultural crop field using internet of things. <em>COIN</em>,
<em>40</em>(1), e12308. (<a
href="https://doi.org/10.1111/coin.12308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) plays a vital role in the entity sharing and minimizing the workload of the human beings in various aspects. Nowadays the term IoT is used in various fields such as health care, automobiles, industry, agriculture, and so on. Agriculture is the main source of food to whole world. There are various problems faced by the farmers in agriculture due to shortage and wastage of water and fertilizers. In this regard, an optimal IoT model has been developed and proposed to attain an effective crop field. The proposed IoT model will monitor, record temperature, and soil moisture values, which will be continuously analyzed to achieve optimal plant growth and yield. The motor will be connected to the IoT model which automatically switch on/off based on optimal threshold temperature and soil moisture content value. A novel irrigation algorithm named differential waterflow algorithm has been proposed and deployed in the proposed IoT model for the automatic usage of the motor in the field. The proposed IoT model provides a web interface to the user through the cloud storage, so that the farmer can control and monitor the system in remote. The proposed system will reduce the water consumption and will ensure the uniform water distribution to the crops through the Poisson distribution which results in increasing yield.},
  archive      = {J_COIN},
  author       = {Manikandan Ramasamy and Prasanna Santhanam and Ashwin Muniyappan and Sathish Kumar Lakshmanan and Sanjeevi Pandiyan},
  doi          = {10.1111/coin.12308},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12308},
  shortjournal = {Comput. Intell.},
  title        = {A novel methodology for the development of an optimal agricultural crop field using internet of things},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Achieving concurrency in cloud-orchestrated internet of
things for resource sharing through multiple concurrent access.
<em>COIN</em>, <em>40</em>(1), e12296. (<a
href="https://doi.org/10.1111/coin.12296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud-orchestrated Internet of Things (IoT) facilitates proper utilization of network resources and placating user demands in smart communications. Multiple concurrent access (MCA) techniques designed for cloud-assisted communication helps to achieve better resource sharing features with fault tolerance ability. A multi-objective resource allocation and sharing (RAS) for balancing MCA in cloud-orchestrated IoT is presented in this article. The RAS constraints are modeled through linear programming (LP) as an optimization approach. The constraints are resolved using genetic representations (GR) for reducing the unserviced requests and failed resource allocations. Conventional genetic stages are inherited by the LP model to solve resource allocation and access issues reducing latency. The combined LP and GR jointly resolve resource allocation and MCA stagnation in cloud network. A fair outcome of LP-GR is estimation using the metrics response latency, resource utilization, request handled, and average latency.},
  archive      = {J_COIN},
  author       = {Xuedong Xu and Wei Sun and Vivekananda G. N. and Achyut Shankar},
  doi          = {10.1111/coin.12296},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12296},
  shortjournal = {Comput. Intell.},
  title        = {Achieving concurrency in cloud-orchestrated internet of things for resource sharing through multiple concurrent access},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Season wise bike sharing demand analysis using random forest
algorithm. <em>COIN</em>, <em>40</em>(1), e12287. (<a
href="https://doi.org/10.1111/coin.12287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rental bike sharing is an urban mobility model that is affordable and ecofriendly. The public bike sharing model is widely used in several cities across the world over the past decade. Because bike use is rising constantly, understanding the system demand in prediction is important to boost the operating system readiness. This article presents a prediction model to meet user demands and efficient operations for rental bikes using Random Forest (RF), which is a homogeneous ensemble method. The approach is carried out in Seoul, South Korea to predict the hourly use of rental bikes. RF is compared with Support Vector Machine with Radial Basis Function Kernel, k -nearest neighbor and Classification and Regression Trees to verify RF supremacy in rental bike demand prediction. Performance Index measures the efficiency of RF compared to the other predictive models. Also, the variable importance analysis is performed to assess the most important characteristics during different seasons by creating a predictive model using RF for each season. The results show that the influence of variables changes depending on the seasons that suggest different operating conditions. RF models trained with yearly and seasonwise models show that bike sharing demand can be further improved by considering seasonal change.},
  archive      = {J_COIN},
  author       = {Sathishkumar V. E. and Yongyun Cho},
  doi          = {10.1111/coin.12287},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12287},
  shortjournal = {Comput. Intell.},
  title        = {Season wise bike sharing demand analysis using random forest algorithm},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluation of green and sustainable building project based
on extension matter-element theory in smart city application.
<em>COIN</em>, <em>40</em>(1), e12286. (<a
href="https://doi.org/10.1111/coin.12286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The postoccupancy performance and operation management level of green building largely determines the overall sustainability level of green buildings. It is necessary to evaluate the degree of success of green buildings in the operation stage to ensure the implementation effect of the whole life cycle. However, the current green building evaluation system is incomplete, and the research on the degree of success evaluation of green buildings is very lacking. It is necessary to establish a scientific and effective evaluation index system to evaluate the degree of success of green buildings. This article applies the extension matter-element theory and entropy method to evaluate the degree of success of green building projects, taking a green building project in Nanchang as an example, and seven experts were invited to score and evaluate the project&#39;s degree of success by calculating the relevance degree of each evaluation index. The results show that this green building&#39;s degree of success emerged as at level II, that is, the “generally successful” level, and each first-level indicator, respectively, lay at level III, level II, level II, and level II. The case study proves that the evaluation method of green building determined in this article is scientific and reliable.},
  archive      = {J_COIN},
  author       = {Ming Li and Kang Xu and Sheng Huang},
  doi          = {10.1111/coin.12286},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12286},
  shortjournal = {Comput. Intell.},
  title        = {Evaluation of green and sustainable building project based on extension matter-element theory in smart city application},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic machine learning-based heuristic energy optimization
approach on multicore architecture. <em>COIN</em>, <em>40</em>(1),
e12266. (<a href="https://doi.org/10.1111/coin.12266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present era, energy is progressively turning into the major limitation in designing multicore chips. However, power and performance are the primary segments of energy, which are contrarily correlated in multicore architectures. This research primarily focused on optimizing energy level of multicore chips using parallel workloads by utilizing either power or execution advancement based on machine learning computation on dynamic programming. To do as such, the novel dynamic machine learning-based heuristic energy optimization (DML-HEO) algorithm has been designed and developed in this research on application-specific controllers to optimize energy-level on multicore architecture. Here DML-HEO is implemented on the controller to maximize the execution inside a fixed power spending plan or to limit the expended capacity to accomplish a similar pattern execution. The controller is additionally scalable as it does not bring about critical overhead due to the increase in quantity of cores. The strategy has been assessed utilizing controllers on a full-framework test system at lab-scale analysis. The experimental results demonstrate that our proposed DML-HEO system shows improving performance than the traditional system.},
  archive      = {J_COIN},
  author       = {Yokesh B. Sundaresan and M. A. Saleem Durai},
  doi          = {10.1111/coin.12266},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {e12266},
  shortjournal = {Comput. Intell.},
  title        = {Dynamic machine learning-based heuristic energy optimization approach on multicore architecture},
  volume       = {40},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
