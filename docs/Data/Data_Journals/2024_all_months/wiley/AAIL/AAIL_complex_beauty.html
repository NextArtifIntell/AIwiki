<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AAIL_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aail---7">AAIL - 7</h2>
<ul>
<li><details>
<summary>
(2024). An application of 3D vision transformers and explainable AI
in prosthetic dentistry. <em>AAIL</em>, <em>5</em>(4), e101. (<a
href="https://doi.org/10.1002/ail2.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To create and validate a transformer-based deep neural network architecture for classifying 3D scans of teeth for computer-assisted manufacturing and dental prosthetic rehabilitation surpassing previously reported validation accuracies obtained with convolutional neural networks (CNNs). Voxel-based representation and encoding input data in a high-dimensional space forms of preprocessing were investigated using 34 3D models of teeth obtained from intraoral scanning. Independent CNNs and vision transformers (ViTs), and their combination (CNN and ViT hybrid model) were implemented to classify the 3D scans directly from standard tessellation language (.stl) files and an Explainable AI (ExAI) model was generated to qualitatively explore the deterministic patterns that influenced the outcomes of the automation process. The results demonstrate that the CNN and ViT hybrid model architecture surpasses conventional supervised CNN, achieving a consistent validation accuracy of 90% through three-fold cross-validation. This process validated our initial findings, where each instance had the opportunity to be part of the validation set, ensuring it remained unseen during training. Furthermore, employing high-dimensional encoding of input data solely with 3DCNN yields a validation accuracy of 80%. When voxel data preprocessing is utilized, ViT outperforms CNN, achieving validation accuracies of 80% and 50%, respectively. The study also highlighted the saliency map&#39;s ability to identify areas of tooth cavity preparation of restorative importance, that can theoretically enable more accurate 3D printed prosthetic outputs. The investigation introduced a CNN and ViT hybrid model for classification of 3D tooth models in digital dentistry, and it was the first to employ ExAI in the efforts to automate the process of dental computer-assisted manufacturing.},
  archive      = {J_AAIL},
  author       = {Faisal Ahmed Sifat and Md Sahadul Hasan Arian and Saif Ahmed and Taseef Hasan Farook and Nabeel Mohammed and James Dudley},
  doi          = {10.1002/ail2.101},
  journal      = {Applied AI Letters},
  month        = {12},
  number       = {4},
  pages        = {e101},
  shortjournal = {Appl. AI Lett.},
  title        = {An application of 3D vision transformers and explainable AI in prosthetic dentistry},
  volume       = {5},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Developing and deploying end-to-end machine learning systems
for social impact: A rubric and practical artificial intelligence case
studies from african contexts. <em>AAIL</em>, <em>5</em>(4), e100. (<a
href="https://doi.org/10.1002/ail2.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) and machine learning have demonstrated the potential to provide solutions to societal challenges, for example, automated crop diagnostics for smallholder farmers, environmental pollution modelling and prediction for cities and machine translation systems for languages that enable information access and communication for segments of the population who are unable to speak or write official languages, among others. Despite the potential of AI, the practical and technical issues related to its development and deployment in the African context are the least documented and understood. The development and deployment of AI for social impact systems in the developing world present new intricacies and requirements emanating from the unique technology and social ecosystems in these settings. This paper provides a rubric for developing and deploying AI systems for social impact with a focus on the African context. The rubric is derived from the analysis of a series of selected real-world case studies of AI applications in Africa. We assessed the selected AI case studies against the proposed rubric. The rubric and examples of AI applications presented in this paper are expected to contribute to the development and application of AI systems in other African contexts.},
  archive      = {J_AAIL},
  author       = {Engineer Bainomugisha and Joyce Nakatumba-Nabende},
  doi          = {10.1002/ail2.100},
  journal      = {Applied AI Letters},
  month        = {12},
  number       = {4},
  pages        = {e100},
  shortjournal = {Appl. AI Lett.},
  title        = {Developing and deploying end-to-end machine learning systems for social impact: A rubric and practical artificial intelligence case studies from african contexts},
  volume       = {5},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). History matching reservoir models with many objective
bayesian optimization. <em>AAIL</em>, <em>5</em>(4), e99. (<a
href="https://doi.org/10.1002/ail2.99">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reservoir models for predicting subsurface fluid and rock behaviors can now include upwards of billions (and potentially trillions) of grid cells and are pushing the limits of computational resources. History matching, where models are updated to match existing historical data more closely, is conducted to reduce the number of simulation runs and is one of the primary time-consuming tasks. As models get larger the number of parameters to match increases, and the number of objective functions increases, and traditional methods start to reach their limitations. To solve this, we propose the use of Bayesian optimization (BO) in a hybrid cloud framework. BO iteratively searches for an optimal solution in the simulations campaign through the refinement of a set of priors initialized with a set of simulation results. The current simulation platform implements grid management and a suite of linear solvers to perform the simulation on large scale distributed-memory systems. Our early results using the hybrid cloud implementation shown here are encouraging on tasks requiring over 100 objective functions, and we propose integrating BO as a built-in module to efficiently iterate to find an optimal history match of production data in a single package platform. This paper reports on the development of the hybrid cloud BO based history matching framework and the initial results of the application to reservoir history matching.},
  archive      = {J_AAIL},
  author       = {Steven Samoil and Clyde Fare and Kirk E. Jordan and Zhangxin Chen},
  doi          = {10.1002/ail2.99},
  journal      = {Applied AI Letters},
  month        = {12},
  number       = {4},
  pages        = {e99},
  shortjournal = {Appl. AI Lett.},
  title        = {History matching reservoir models with many objective bayesian optimization},
  volume       = {5},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fine-tuned pretrained transformer for amharic news headline
generation. <em>AAIL</em>, <em>5</em>(3), e98. (<a
href="https://doi.org/10.1002/ail2.98">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amharic is one of the under-resourced languages, making news headline generation particularly challenging due to the scarcity of high-quality linguistic datasets necessary for training effective natural language processing models. In this study, we fine-tuned the small check point of the T5v1.1 model (t5-small) to perform Amharic news headline generation with an Amharic dataset that is comprised of over 70k news articles along with their headline. Fine-tuning the model involves dataset collection from Amharic news websites, text cleaning, news article size optimization using the TF-IDF algorithm, and tokenization. In addition, a tokenizer model is developed using the byte pair encoding (BPE) algorithm prior to feeding the dataset for feature extraction and summarization. Metrics including Rouge-L, BLEU, and Meteor were used to evaluate the performance of the model and a score of 0.5, 0.24, and 0.71, respectively, was achieved on the test partition of the dataset that contains 7230 instances. The results were good relative to result of the t5 model without fine-tuning, which are 0.1, 0.03, and 0.14, respectively. A postprocessing technique using a rule-based approach was used for further improving summaries generated by the model. The addition of the postprocessing helped the system to achieve Rouge-L, BLEU, and Meteor scores of 0.72, 0.52, and 0.81, respectively. The result value is relatively better than the result achieved by the nonfine-tuned T5v1.1 model and the result of previous studies report on abstractive-based text summarization for Amharic language, which had a 0.27 Rouge-L score. This contributes a valuable insight for practical application and further improvement of the model in the future by increasing the article length, using more training data, using machine learningâ€“based adaptive postprocessing techniques, and fine-tuning other available pretrained models for text summarization.},
  archive      = {J_AAIL},
  author       = {MizanuÂ Zelalem Degu and Million Meshesha},
  doi          = {10.1002/ail2.98},
  journal      = {Applied AI Letters},
  month        = {9},
  number       = {3},
  pages        = {e98},
  shortjournal = {Appl. AI Lett.},
  title        = {Fine-tuned pretrained transformer for amharic news headline generation},
  volume       = {5},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TL-GNN: Android malware detection using transfer learning.
<em>AAIL</em>, <em>5</em>(3), e94. (<a
href="https://doi.org/10.1002/ail2.94">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malware growth has accelerated due to the widespread use of Android applications. Android smartphone attacks have increased due to the widespread use of these devices. While deep learning models offer high efficiency and accuracy, training them on large and complex datasets is computationally expensive. Hence, a method that effectively detects new malware variants at a low computational cost is required. A transfer learning method to detect Android malware is proposed in this research. Because of transferring known features from a source model that has been trained to a target model, the transfer learning approach reduces the need for new training data and minimizes the need for huge amounts of computational power. We performed many experiments on 1.2 million Android application samples for performance evaluation. In addition, we evaluated how well our framework performed in comparison with traditional deep learning and standard machine learning models. In comparison with state-of-the-art Android malware detection methods, the proposed framework offers improved classification accuracy of 98.87%, a precision of 99.55%, recall of 97.30%, F 1-measure of 99.42%, and a quicker detection rate of 5.14â€‰ms using the transfer learning strategy.},
  archive      = {J_AAIL},
  author       = {Ali Raza and ZahidÂ Hussain Qaisar and Naeem Aslam and Muhammad Faheem and MuhammadÂ Waqar Ashraf and MuhammadÂ Naman Chaudhry},
  doi          = {10.1002/ail2.94},
  journal      = {Applied AI Letters},
  month        = {9},
  number       = {3},
  pages        = {e94},
  shortjournal = {Appl. AI Lett.},
  title        = {TL-GNN: Android malware detection using transfer learning},
  volume       = {5},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Building text and speech benchmark datasets and models for
low-resourced east african languages: Experiences and lessons.
<em>AAIL</em>, <em>5</em>(2), e92. (<a
href="https://doi.org/10.1002/ail2.92">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Africa has over 2000 languages; however, those languages are not well represented in the existing natural language processing ecosystem. African languages lack essential digital resources to effectively engage in advancing language technologies. There is a need to generate high-quality natural language processing resources for low-resourced African languages. Obtaining high-quality speech and text data is expensive and tedious because it can involve manual sourcing and verification of data sources. This paper discusses the process taken to curate and annotate text and speech datasets for five East African languages: Luganda, Runyankore-Rukiga, Acholi, Lumasaba, and Swahili. We also present results obtained from baseline models for machine translation, topic modeling and classification, sentiment classification, and automatic speech recognition tasks. Finally, we discuss the experiences, challenges, and lessons learned in creating the text and speech datasets.},
  archive      = {J_AAIL},
  author       = {Joyce Nakatumba-Nabende and Claire Babirye and Peter Nabende and Jeremy Francis Tusubira and Jonathan Mukiibi and Eric Peter Wairagala and Chodrine Mutebi and Tobius Saul Bateesa and Alvin Nahabwe and Hewitt Tusiime and Andrew Katumba},
  doi          = {10.1002/ail2.92},
  journal      = {Applied AI Letters},
  month        = {4},
  number       = {2},
  pages        = {e92},
  shortjournal = {Appl. AI Lett.},
  title        = {Building text and speech benchmark datasets and models for low-resourced east african languages: Experiences and lessons},
  volume       = {5},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CMD + v for chemistry: Image to chemical structure
conversion directly done in the clipboard. <em>AAIL</em>, <em>5</em>(1),
e91. (<a href="https://doi.org/10.1002/ail2.91">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present Clipboard-to-SMILES Converter (C2SC), a macOS application that directly converts molecular structures from the clipboard. The app focuses on seamlessly converting screenshots of molecules into a desired molecular representation. It supports a wide range of molecular representations, such as SMILES, SELFIES, InChI&#39;s, IUPAC names, RDKit Mol&#39;s, and CAS numbers, allowing effortless conversion between these formats within the clipboard. C2SC automatically saves converted molecules to a local history file and displays the last 10 entries for quick access. Additionally, it incorporates several SMILES operations, including canonicalization, augmentation, as well price-searching molecules on chemical vendors for the cost-effective purchasing option. Beyond the one-click conversion from clipboard to molecular structures, the app offers continuous monitoring of the clipboard which automatically converts any supported representations or images detected into SMILES. The convenient interface, directly in the status bar, as well as availability as macOS application, makes C2SC useful for a broad community not requiring any programming expertise. Most conversions are performed locally, notably the image-to-SMILES conversion, with internet access only necessary for specific tasks like price lookups. In summary, C2SC provides a user-friendly and efficient solution for converting molecular structures directly from the clipboard, offering seamless conversions between comprehensive chemical representations and can be directly downloaded from https://github.com/O-Schilter/Clipboard-to-SMILES-Converter .},
  archive      = {J_AAIL},
  author       = {Oliver Tobias Schilter and Teodoro Laino and Philippe Schwaller},
  doi          = {10.1002/ail2.91},
  journal      = {Applied AI Letters},
  month        = {2},
  number       = {1},
  pages        = {e91},
  shortjournal = {Appl. AI Lett.},
  title        = {CMD + v for chemistry: Image to chemical structure conversion directly done in the clipboard},
  volume       = {5},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
