<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SROB_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="srob---138">SROB - 138</h2>
<ul>
<li><details>
<summary>
(2024a). A call for diversity, equity, and inclusion in robotics.
<em>SROB</em>, <em>9</em>(97), eadu7713. (<a
href="https://doi.org/10.1126/scirobotics.adu7713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotics research is rooted in a diversity of ideas, so roboticists should embrace a diverse set of people.},
  archive      = {J_SROB},
  author       = {Melisa Yashinski},
  doi          = {10.1126/scirobotics.adu7713},
  journal      = {Science Robotics},
  month        = {12},
  number       = {97},
  pages        = {eadu7713},
  shortjournal = {Sci. Robot.},
  title        = {A call for diversity, equity, and inclusion in robotics},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Erratum for the research article “restoration of grasping in
an upper limb amputee using the myokinetic prosthesis with implanted
magnets” by m. Gherardini et al. <em>SROB</em>, <em>9</em>(97),
eadu7152. (<a
href="https://doi.org/10.1126/scirobotics.adu7152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Research Article “Restoration of grasping in an upper limb amputee using the myokinetic prosthesis with implanted magnets” by M. Gherardini et al., an error in Fig. 2 caused some visual elements in (A), including the red and blue parts of the cylinders and other parts of the prosthetic socket (such as the prosthetic’s battery, in blue), to become obscured. The figure has been corrected, and the conclusions and other data in the paper are not affected.},
  archive      = {J_SROB},
  doi          = {10.1126/scirobotics.adu7152},
  journal      = {Science Robotics},
  month        = {12},
  number       = {97},
  pages        = {eadu7152},
  shortjournal = {Sci. Robot.},
  title        = {Erratum for the research article “Restoration of grasping in an upper limb amputee using the myokinetic prosthesis with implanted magnets” by m. gherardini et al.},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Even teleoperated robots are discriminated against in
science fictions. <em>SROB</em>, <em>9</em>(97), eadu6332. (<a
href="https://doi.org/10.1126/scirobotics.adu6332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robot body is not a shield from discrimination in John Scalzi’s science fiction novel Head On.},
  archive      = {J_SROB},
  author       = {Robin R. Murphy},
  doi          = {10.1126/scirobotics.adu6332},
  journal      = {Science Robotics},
  month        = {12},
  number       = {97},
  pages        = {eadu6332},
  shortjournal = {Sci. Robot.},
  title        = {Even teleoperated robots are discriminated against in science fictions},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Black in robotics: Improving community and equity in the
field of robotics. <em>SROB</em>, <em>9</em>(97), eadu2915. (<a
href="https://doi.org/10.1126/scirobotics.adu2915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Black in Robotics, a nonprofit organization, has had recent success, but it is the ongoing community participation that will sustain its efforts.},
  archive      = {J_SROB},
  author       = {Monroe Kennedy and Ayanna Howard},
  doi          = {10.1126/scirobotics.adu2915},
  journal      = {Science Robotics},
  month        = {12},
  number       = {97},
  pages        = {eadu2915},
  shortjournal = {Sci. Robot.},
  title        = {Black in robotics: Improving community and equity in the field of robotics},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The cold truth about robotics research in the united kingdom
as a caribbean woman. <em>SROB</em>, <em>9</em>(97), eadu2844. (<a
href="https://doi.org/10.1126/scirobotics.adu2844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From St. Lucia to the United Kingdom, my PhD journey highlights minorities’ challenges in academia and the need to foster diverse talent.},
  archive      = {J_SROB},
  author       = {Nikita Jasmine Greenidge},
  doi          = {10.1126/scirobotics.adu2844},
  journal      = {Science Robotics},
  month        = {12},
  number       = {97},
  pages        = {eadu2844},
  shortjournal = {Sci. Robot.},
  title        = {The cold truth about robotics research in the united kingdom as a caribbean woman},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Promoting diverse and inclusive spaces with intentionality.
<em>SROB</em>, <em>9</em>(97), eadu0906. (<a
href="https://doi.org/10.1126/scirobotics.adu0906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing spaces that foster and embrace diverse perspectives and backgrounds with intentionality benefits everyone involved.},
  archive      = {J_SROB},
  author       = {Marquise D. Bell},
  doi          = {10.1126/scirobotics.adu0906},
  journal      = {Science Robotics},
  month        = {12},
  number       = {97},
  pages        = {eadu0906},
  shortjournal = {Sci. Robot.},
  title        = {Promoting diverse and inclusive spaces with intentionality},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Overcoming the challenges that women in robotics face.
<em>SROB</em>, <em>9</em>(97), eadu0391. (<a
href="https://doi.org/10.1126/scirobotics.adu0391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotics history is still HIS story, but Women in Robotics is working hard to include HER story in the future of robotics.},
  archive      = {J_SROB},
  author       = {Andra Keay},
  doi          = {10.1126/scirobotics.adu0391},
  journal      = {Science Robotics},
  month        = {12},
  number       = {97},
  pages        = {eadu0391},
  shortjournal = {Sci. Robot.},
  title        = {Overcoming the challenges that women in robotics face},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerating the pace of innovation in robotics by fostering
diversity and inclusive leadership. <em>SROB</em>, <em>9</em>(97),
eadt1958. (<a
href="https://doi.org/10.1126/scirobotics.adt1958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diverse and inclusive teams are not merely a moral imperative but also a catalyst for scientific excellence in robotics. Drawing from literature, a comprehensive citation analysis, and expert interviews, we derive seven main benefits of diversity and inclusion and propose a leadership guide for roboticists to reap these benefits.},
  archive      = {J_SROB},
  author       = {Daniela Macari and Alex Fratzl and Ksenia Keplinger and Christoph Keplinger},
  doi          = {10.1126/scirobotics.adt1958},
  journal      = {Science Robotics},
  month        = {12},
  number       = {97},
  pages        = {eadt1958},
  shortjournal = {Sci. Robot.},
  title        = {Accelerating the pace of innovation in robotics by fostering diversity and inclusive leadership},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Imaging-guided bioresorbable acoustic hydrogel microrobots.
<em>SROB</em>, <em>9</em>(97), eadp3593. (<a
href="https://doi.org/10.1126/scirobotics.adp3593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microrobots offer several opportunities in medicine for the diagnosis and treatment of various complications. However, there are several challenges related to their efficacy and ability to be detected in real time when deployed within the body. Han et al. have now developed bioresorbable acoustic microrobots that can be propelled acoustically and magnetically to tissues of interest and used for real-time ultrasound imaging and delivery of therapeutics. The gas-filled acoustic microrobots were used in vivo in a murine bladder tumor model and demonstrated the potential to support real-time imaging and delivery of anticancer drugs to the diseased tissue, resulting in the reduction in tumor size. —Amos Matsiko Micro- and nanorobots excel in navigating the intricate and often inaccessible areas of the human body, offering immense potential for applications such as disease diagnosis, precision drug delivery, detoxification, and minimally invasive surgery. Despite their promise, practical deployment faces hurdles, including achieving stable propulsion in complex in vivo biological environments, real-time imaging and localization through deep tissue, and precise remote control for targeted therapy and ensuring high therapeutic efficacy. To overcome these obstacles, we introduce a hydrogel-based, imaging-guided, bioresorbable acoustic microrobot (BAM) designed to navigate the human body with high stability. Constructed using two-photon polymerization, a BAM comprises magnetic nanoparticles and therapeutic agents integrated into its hydrogel matrix for precision control and drug delivery. The microrobot features an optimized surface chemistry with a hydrophobic inner layer to substantially enhance microbubble retention in biofluids with multiday functionality and a hydrophilic outer layer to minimize aggregation and promote timely degradation. The dual-opening bubble-trapping cavity design enables a BAM to maintain consistent and efficient acoustic propulsion across a range of biological fluids. Under focused ultrasound stimulation, the entrapped microbubbles oscillate and enhance the contrast for real-time ultrasound imaging, facilitating precise tracking and control of BAM movement through wireless magnetic navigation. Moreover, the hydrolysis-driven biodegradability of BAMs ensures its safe dissolution after treatment, posing no risk of long-term residual harm. Thorough in vitro and in vivo experimental evidence demonstrates the promising capabilities of BAMs in biomedical applications. This approach shows promise for advancing minimally invasive medical interventions and targeted therapeutic delivery.},
  archive      = {J_SROB},
  author       = {Hong Han and Xiaotian Ma and Weiting Deng and Junhang Zhang and Songsong Tang and On Shun Pak and Lailai Zhu and Ernesto Criado-Hidalgo and Chen Gong and Emil Karshalev and Jounghyun Yoo and Ming You and Ann Liu and Canran Wang and Hao K. Shen and Payal N. Patel and Claire L. Hays and Peter J. Gunnarson and Lei Li and Yang Zhang and John O. Dabiri and Lihong V. Wang and Mikhail G. Shapiro and Di Wu and Qifa Zhou and Julia R. Greer and Wei Gao},
  doi          = {10.1126/scirobotics.adp3593},
  journal      = {Science Robotics},
  month        = {12},
  number       = {97},
  pages        = {eadp3593},
  shortjournal = {Sci. Robot.},
  title        = {Imaging-guided bioresorbable acoustic hydrogel microrobots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Counterfactual rewards promote collective transport using
individually controlled swarm microrobots. <em>SROB</em>,
<em>9</em>(97), eado5888. (<a
href="https://doi.org/10.1126/scirobotics.ado5888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarms of agents working cooperatively can perform tasks more efficiently than individual agents working independently. Microrobot swarms have been widely used for a range of applications. However, controlling individual robots within the swarm is challenging. Heuthe et al . present a control strategy for individual microrobots in a swarm that relies on multiagent reinforcement learning. The learning process rewards individual microrobots on the basis of their contribution to the collective performance. The propulsion of the individual microrobots is controlled by laser beams, and the authors demonstrate the potential of the swarm to collectively transport cargo, similarly to ants. —Amos Matsiko Swarm robots offer fascinating opportunities to perform complex tasks beyond the capabilities of individual machines. Just as a swarm of ants collectively moves large objects, similar functions can emerge within a group of robots through individual strategies based on local sensing. However, realizing collective functions with individually controlled microrobots is particularly challenging because of their micrometer size, large number of degrees of freedom, strong thermal noise relative to the propulsion speed, and complex physical coupling between neighboring microrobots. Here, we implemented multiagent reinforcement learning (MARL) to generate a control strategy for up to 200 microrobots whose motions are individually controlled by laser spots. During the learning process, we used so-called counterfactual rewards that automatically assign credit to the individual microrobots, which allows fast and unbiased training. With the help of this efficient reward scheme, swarm microrobots learn to collectively transport a large cargo object to an arbitrary position and orientation, similar to ant swarms. We show that this flexible and versatile swarm robotic system is robust to variations in group size, the presence of malfunctioning units, and environmental noise. In addition, we let the robot swarms manipulate multiple objects simultaneously in a demonstration experiment, highlighting the benefits of distributed control and independent microrobot motion. Control strategies such as ours can potentially enable complex and automated assembly of mobile micromachines, programmable drug delivery capsules, and other advanced lab-on-a-chip applications.},
  archive      = {J_SROB},
  author       = {Veit-Lorenz Heuthe and Emanuele Panizon and Hongri Gu and Clemens Bechinger},
  doi          = {10.1126/scirobotics.ado5888},
  journal      = {Science Robotics},
  month        = {12},
  number       = {97},
  pages        = {eado5888},
  shortjournal = {Sci. Robot.},
  title        = {Counterfactual rewards promote collective transport using individually controlled swarm microrobots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MOGrip: Gripper for multiobject grasping in pick-and-place
tasks using translational movements of fingers. <em>SROB</em>,
<em>9</em>(97), eado3939. (<a
href="https://doi.org/10.1126/scirobotics.ado3939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human hands are quite dexterous, possessing the ability to transfer an object from the fingertips to the palm, freeing the fingers to grasp another object. However most robotic grippers are designed to grasp either a single object or multiple objects simultaneously. Inspired by human hands, Eom et al . designed a gripper with four translational fingers and a conveyor palm with elastomeric hairs. A series of tendons allow the fingers to grasp and translate an object to the palm for storage, allowing the hand to pick up and hold multiple objects sequentially. The objects can then be individually placed in specified locations, as demonstrated in a desk-tidying task. —Melisa Yashinski Humans use their dexterous fingers and adaptable palm in various multiobject grasping strategies to efficiently move multiple objects together in various situations. Advanced manipulation skills, such as finger-to-palm translation and palm-to-finger translation, enhance the dexterity in multiobject grasping. These translational movements allow the fingers to transfer the grasped objects to the palm for storage, enabling the fingers to freely perform various pick-and-place tasks while the palm stores multiple objects. However, conventional grippers, although able to handle multiple objects simultaneously, lack this integrated functionality, which combines the palm’s storage with the fingers’ precise placement. Here, we introduce a gripper for multiobject grasping that applies translational movements of fingertips to leverage the synergistic use of fingers and the palm for enhanced pick-and-place functionality. The proposed gripper consists of four fingers and an adaptive conveyor palm. The fingers sequentially grasp and transfer objects to the palm, where the objects are stored simultaneously, allowing the gripper to move multiple objects at once. Furthermore, by reversing this process, the fingers retrieve the stored objects and place them one by one in the desired position and orientation. A finger design for simple object translating and a palm design for simultaneous object storing were proposed and validated. In addition, the time efficiency and pick-and-place capabilities of the developed gripper were demonstrated. Our work shows the potential of finger translation to enhance functionality and broaden the applicability of multiobject grasping.},
  archive      = {J_SROB},
  author       = {Jaemin Eom and Sung Yol Yu and Woongbae Kim and Chunghoon Park and Kristine Yoonseo Lee and Kyu-Jin Cho},
  doi          = {10.1126/scirobotics.ado3939},
  journal      = {Science Robotics},
  month        = {12},
  number       = {97},
  pages        = {eado3939},
  shortjournal = {Sci. Robot.},
  title        = {MOGrip: Gripper for multiobject grasping in pick-and-place tasks using translational movements of fingers},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Haptiknit: Distributed stiffness knitting for wearable
haptics. <em>SROB</em>, <em>9</em>(97), eado3887. (<a
href="https://doi.org/10.1126/scirobotics.ado3887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable haptic devices can convey artificial touch during human computer interaction, but it is difficult to achieve sufficient forces and sensation with the comfort of a soft material. By combining machine knitting and pneumatic actuation, du Pasquier et al. developed a haptic sleeve with a high-stiffness outer layer that grounds the actuation force and a lower stiffness inner layer that transfers load to the skin. The Haptiknit sleeve was tested with 32 participants who could determine the location of an inflated actuator in a two-by-eight grid with high accuracy. The sleeve was also used to convey social touch gestures by inflating the actuators in different durations and patterns. Its untethered, portable operation holds promise for applications such as teleoperation or navigation. —Melisa Yashinski Haptic devices typically rely on rigid actuators and bulky power supply systems, limiting wearability. Soft materials improve comfort, but careful distribution of stiffness is required to ground actuation forces and enable load transfer to the skin. We present Haptiknit, an approach in which soft, wearable, knit textiles with embedded pneumatic actuators enable programmable haptic display. By integrating pneumatic actuators within high- and low-stiffness machine-knit layers, each actuator can transmit 40 newtons in force with a bandwidth of 14.5 hertz. We demonstrate the concept with an adjustable sleeve for the forearm coupled to an untethered pneumatic control system that conveys a diverse array of social touch signals. We assessed the sleeve’s performance for discriminative and affective touch in a three-part user study and compared our results with those of prior electromagnetically actuated approaches. Haptiknit improves touch localization compared with vibrotactile stimulation and communicates social touch cues with fewer actuators than pneumatic textiles that do not invoke distributed stiffness. The Haptiknit sleeve resulted in similar recognition of social touch gestures compared to a voice-coil array but represented a more portable and comfortable form factor.},
  archive      = {J_SROB},
  author       = {Cosima du Pasquier and Lavender Tessmer and Ian Scholl and Liana Tilton and Tian Chen and Skylar Tibbits and Allison Okamura},
  doi          = {10.1126/scirobotics.ado3887},
  journal      = {Science Robotics},
  month        = {12},
  number       = {97},
  pages        = {eado3887},
  shortjournal = {Sci. Robot.},
  title        = {Haptiknit: Distributed stiffness knitting for wearable haptics},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Monte carlo tree search with spectral expansion for planning
with dynamical systems. <em>SROB</em>, <em>9</em>(97), eado1010. (<a
href="https://doi.org/10.1126/scirobotics.ado1010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous robots require effective decision-making processes to adapt to complex new environments. Monte Carlo tree search (MCTS) is a planning algorithm that uses real-time computation to strategically explore future decisions, but it cannot be directly applied to generate physical motions for robots. Rivière et al . have now developed Spectral Expansion Tree Search that enables real-time MCTS-based planning by computing an efficient discrete representation of the physical world. The framework was deployed on various robots that were shown to be capable of autonomously discovering optimal trajectories to avoid dynamic obstacles, traverse windy gusts, support a human driver in shared control tasks, and capture and redirect an uncontrolled agent. —Amos Matsiko The ability of a robot to plan complex behaviors with real-time computation, rather than adhering to predesigned or offline-learned routines, alleviates the need for specialized algorithms or training for each problem instance. Monte Carlo tree search is a powerful planning algorithm that strategically explores simulated future possibilities, but it requires a discrete problem representation that is irreconcilable with the continuous dynamics of the physical world. We present Spectral Expansion Tree Search (SETS), a real-time, tree-based planner that uses the spectrum of the locally linearized system to construct a low-complexity and approximately equivalent discrete representation of the continuous world. We prove that SETS converges to a bound of the globally optimal solution for continuous, deterministic, and differentiable Markov decision processes, a broad class of problems that includes underactuated nonlinear dynamics, nonconvex reward functions, and unstructured environments. We experimentally validated SETS on drone, spacecraft, and ground vehicle robots and one numerical experiment, each of which is not directly solvable with existing methods. We successfully show that SETS automatically discovers a diverse set of optimal behaviors and motion trajectories in real time.},
  archive      = {J_SROB},
  author       = {Benjamin Rivière and John Lathrop and Soon-Jo Chung},
  doi          = {10.1126/scirobotics.ado1010},
  journal      = {Science Robotics},
  month        = {12},
  number       = {97},
  pages        = {eado1010},
  shortjournal = {Sci. Robot.},
  title        = {Monte carlo tree search with spectral expansion for planning with dynamical systems},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Upgrading and extending the life cycle of soft robots with
in situ free-form liquid three-dimensional printing. <em>SROB</em>,
<em>9</em>(97), eadn4542. (<a
href="https://doi.org/10.1126/scirobotics.adn4542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the soft robotics field progresses, advancements in sensors and actuation, along with deterioration, can render earlier robot generations obsolete, reducing their usable life spans. To promote sustainability in soft robotics, Kanhere et al. developed an in situ free-form liquid three-dimensional printing strategy that enables upgrades and repairs to existing robots. A specially formulated gel was printed directly onto the robot’s surface, which served as a support medium for the direct printing of new features onto various surfaces without the need for a special container. The technique was used to upgrade a batoid-like soft robot with tactile sensors, a passive whisker array, and actuated hooks, as well as to repair skin tears and whisker damage, thereby extending the robot’s life span. —Melisa Yashinski Soft robotics hardware, with numerous applications ranging from health care to exploration of unstructured environments, suffers from limited life cycles, which lead to waste generation and poor sustainability. Soft robots combine soft or hybrid components via complex assembly and disassembly workflows, which complicate the repair of broken components, hinder upgradability, and ultimately reduce their life spans. In this work, an advanced extrusion-based additive manufacturing process, in situ free-form liquid three-dimensional printing (iFL3DP), was developed to facilitate functional upgrades and repairs in soft robots. A yield-stress hydrogel—a type of material that can maintain its shape until sufficient stress is applied—was first printed directly onto the robot surface, serving as a support for printing new components. This technique enabled the fabrication of advanced components with seamless integration onto already assembled robots. These components could combine multiple materials with intricate geometries, including overhangs and high–aspect ratio shapes, that are considerably challenging to manufacture and integrate via traditional methods such as casting. This approach was successfully applied to upgrade an existing soft robot by adding three advanced functionalities: whisker-like sensors for tactile feedback, a grasping mechanism, and a multifunctional passive whisker array. This study showcases the easy repairability of features, new and old, substantially extending the robot’s life span. This workflow has potential to enhance the sustainable development of soft robots.},
  archive      = {J_SROB},
  author       = {Elgar Kanhere and Théo Calais and Snehal Jain and Aby Raj Plamootil Mathai and Aaron Chooi and Thileepan Stalin and Vincent Sebastian Joseph and Pablo Valdivia y Alvarado},
  doi          = {10.1126/scirobotics.adn4542},
  journal      = {Science Robotics},
  month        = {12},
  number       = {97},
  pages        = {eadn4542},
  shortjournal = {Sci. Robot.},
  title        = {Upgrading and extending the life cycle of soft robots with in situ free-form liquid three-dimensional printing},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). How much initiative should a service robot have?
<em>SROB</em>, <em>9</em>(96), eadt8902. (<a
href="https://doi.org/10.1126/scirobotics.adt8902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adrian Tchaikovsky’s new novel Service Model humorously imagines a robot Jeeves coping with the end of civilization.},
  archive      = {J_SROB},
  author       = {Robin R. Murphy},
  doi          = {10.1126/scirobotics.adt8902},
  journal      = {Science Robotics},
  month        = {11},
  number       = {96},
  pages        = {eadt8902},
  shortjournal = {Sci. Robot.},
  title        = {How much initiative should a service robot have?},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Crucial hurdles to achieving human-robot harmony.
<em>SROB</em>, <em>9</em>(96), eadp2507. (<a
href="https://doi.org/10.1126/scirobotics.adp2507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Holistic consideration of the human and the robot is necessary to overcome hurdles in human-robot interaction.},
  archive      = {J_SROB},
  author       = {Keya Ghonasgi and Taylor Higgins and Meghan E. Huber and Marcia K. O’Malley},
  doi          = {10.1126/scirobotics.adp2507},
  journal      = {Science Robotics},
  month        = {11},
  number       = {96},
  pages        = {eadp2507},
  shortjournal = {Sci. Robot.},
  title        = {Crucial hurdles to achieving human-robot harmony},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reconfigurable nanomaterials folded from multicomponent
chains of DNA origami voxels. <em>SROB</em>, <em>9</em>(96), eadp2309.
(<a href="https://doi.org/10.1126/scirobotics.adp2309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of synthetic molecular structures that can self-assemble into unique complex machines is a challenge. Inspired by protein folding, Luu et al. have developed a modular system of origami voxels made from DNA nanostructures. These voxels contain internal and external connections that can be switched between various states. They can be combined to form two-dimensional and three-dimensional hierarchical assemblies and be reconfigured into new shapes. The modular system could potentially be adapted for environment-adaptive switching and reconfiguration in response to temperature and pH. —Amos Matsiko In cells, proteins rapidly self-assemble into sophisticated nanomachines. Bioinspired self-assembly approaches, such as DNA origami, have been used to achieve complex three-dimensional (3D) nanostructures and devices. However, current synthetic systems are limited by low yields in hierarchical assembly and challenges in rapid and efficient reconfiguration between diverse structures. Here, we developed a modular system of DNA origami “voxels” with programmable 3D connections. We demonstrate multifunctional pools of up to 12 unique voxels that can assemble into many shapes, prototyping 50 structures. Programmable switching of local connections between flexible and rigid states achieved rapid and reversible reconfiguration of global structures in three dimensions. Multistep assembly pathways were then explored to increase the yield. Voxels were assembled via flexible chain intermediates into rigid structures, increasing yield up to 100-fold. We envision that foldable chains of DNA origami voxels can achieve increased complexity in reconfigurable nanomaterials, providing modular components for the assembly of nanorobotic systems with future applications in synthetic biology, assembly of inorganic materials, and nanomedicine.},
  archive      = {J_SROB},
  author       = {Minh Tri Luu and Jonathan F. Berengut and Jiahe Li and Jing-Bing Chen and Jasleen Kaur Daljit Singh and Kanako Coffi Dit Glieze and Matthew Turner and Karuna Skipper and Sreelakshmi Meppat and Hannah Fowler and William Close and Jonathan P. K. Doye and Ali Abbas and Shelley F. J. Wickham},
  doi          = {10.1126/scirobotics.adp2309},
  journal      = {Science Robotics},
  month        = {11},
  number       = {96},
  pages        = {eadp2309},
  shortjournal = {Sci. Robot.},
  title        = {Reconfigurable nanomaterials folded from multicomponent chains of DNA origami voxels},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robots and animals teaming up in the wild to tackle
ecosystem challenges. <em>SROB</em>, <em>9</em>(96), eado5566. (<a
href="https://doi.org/10.1126/scirobotics.ado5566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactively teaming up animals and robots could facilitate basic scientific research and address environmental and ecological crises.},
  archive      = {J_SROB},
  author       = {Thomas Schmickl and Donato Romano},
  doi          = {10.1126/scirobotics.ado5566},
  journal      = {Science Robotics},
  month        = {11},
  number       = {96},
  pages        = {eado5566},
  shortjournal = {Sci. Robot.},
  title        = {Robots and animals teaming up in the wild to tackle ecosystem challenges},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bird-inspired reflexive morphing enables rudderless flight.
<em>SROB</em>, <em>9</em>(96), eado4535. (<a
href="https://doi.org/10.1126/scirobotics.ado4535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Birds exhibit controlled gliding flight without a vertical tail, unlike the necessary rudders on airplanes that damp Dutch roll oscillations. To accomplish rudderless flight, Chang et al . developed a bioinspired aerial robot with morphing wings and tail named PigeonBot II. The robot consists of a biomimetic skeleton and real pigeon feathers that form wings that can spread and a tail that can spread, elevate, tilt, and deviate side to side like a bird. Initial experiments in a turbulent wind tunnel showed that reflexive tail tilting and deviation combined with wing morphing enabled stable flight by damping Dutch roll. Outdoor flight tests further demonstrated that the autonomous reflexive controller provided stability to the robot during take-off, cruise, and landing. —Melisa Yashinski Gliding birds lack a vertical tail, yet they fly stably rudderless in turbulence without needing discrete flaps to steer. In contrast, nearly all airplanes need vertical tails to damp Dutch roll oscillations and to control yaw. The few exceptions that lack a vertical tail either leverage differential drag-based yaw actuators or their fixed planforms are carefully tuned for passively stable Dutch roll and proverse yaw. Biologists hypothesize that birds stabilize and control gliding flight without rudders by using their wing and tail reflexes, but no rudderless airplane has a morphing wing or tail that can change shape like a bird. Our rudderless biohybrid robot, PigeonBot II, can damp its Dutch roll instability (caused by lacking a vertical tail) and control flight by morphing its biomimetic wing and tail reflexively like a bird. The bird-inspired adaptive reflexive controller was tuned in a wind tunnel to mitigate turbulent perturbations, which enabled PigeonBot II to fly autonomously in the atmosphere with pigeon-like poses. This work is a mechanistic confirmation of how birds accomplish rudderless flight via reflex functions, and it can inspire rudderless aircraft with reduced radar signature and increased efficacy.},
  archive      = {J_SROB},
  author       = {Eric Chang and Diana D. Chin and David Lentink},
  doi          = {10.1126/scirobotics.ado4535},
  journal      = {Science Robotics},
  month        = {11},
  number       = {96},
  pages        = {eado4535},
  shortjournal = {Sci. Robot.},
  title        = {Bird-inspired reflexive morphing enables rudderless flight},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A twist of the tail in turning maneuvers of bird-inspired
drones. <em>SROB</em>, <em>9</em>(96), eado3890. (<a
href="https://doi.org/10.1126/scirobotics.ado3890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During banked turns while soaring, raptors have been observed twisting their tails without moving their wings to compensate for adverse yaw. To better understand this phenomenon, Phan and Floreano designed a raptor-inspired feathered drone with morphing wings and twisting tail. The drone, named LisRaptor, features a bioinformed skeleton frame with feather-like foam structures, wings that can morph to different wing spans, and a tail capable of twisting around the body axis. Experiments performed in an indoor wind tunnel revealed that tail twisting generated aerodynamic control forces to initiate both low-speed steady banked turns and high-speed sharp turns. —Melisa Yashinski A banked turn is a common flight maneuver observed in birds and aircraft. To initiate the turn, whereas traditional aircraft rely on the wing ailerons, most birds use a variety of asymmetric wing-morphing control techniques to roll their bodies and thus redirect the lift vector to the direction of the turn. Nevertheless, when searching for prey, soaring raptors execute steady banked turns without exhibiting observable wing movements apart from the tail twisting around the body axis. Although tail twisting can compensate for adverse yaw, functioning similarly to the vertical tail in aircraft, how raptors use only tail twisting to perform banked turns is still not well understood. Here, we developed and used a raptor-inspired feathered drone to find that the proximity of the tail to the wings causes asymmetric wing-induced flows over the twisted tail and thus lift asymmetry, resulting in both roll and yaw moments sufficient to coordinate banked turns. Moreover, twisting the tail induces a nose-up pitch moment that increases the angle of attack of the wings, thereby generating more lift to compensate for losses caused by the banking motion. Flight experiments confirm the effectiveness of tail twist to control not only low-speed steady banked turns but also high-speed sharp turns by means of coordinated tail twist and pitch with asymmetric wing shape morphing. These findings contribute to the understanding of avian flight behaviors that are difficult to study in controlled laboratory settings and provide effective control strategies for agile drones with morphing aerial surfaces.},
  archive      = {J_SROB},
  author       = {Hoang-Vu Phan and Dario Floreano},
  doi          = {10.1126/scirobotics.ado3890},
  journal      = {Science Robotics},
  month        = {11},
  number       = {96},
  pages        = {eado3890},
  shortjournal = {Sci. Robot.},
  title        = {A twist of the tail in turning maneuvers of bird-inspired drones},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Coordinated behavior of autonomous microscopic machines
through local electronic pulse coupling. <em>SROB</em>, <em>9</em>(96),
eadn8067. (<a
href="https://doi.org/10.1126/scirobotics.adn8067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In nature, coordinated behaviors occur among various groups of organisms. Achieving similar synchronization and coordination in microscopic devices and robots could open new possibilities in their functionality. Taghavi et al. demonstrated autonomous synchronization in low-power oscillating modules made from pulse-coupled complementary metal oxide semiconductor oscillators that can enable wavelike collective behaviors. The authors showed that the connected oscillators could exchange electronic pulses until the system was synchronized and that they were robust to external disturbances or individual oscillator failure. —Amos Matsiko Increasingly functional microscopic machines are poised to have massive technical influence in areas including targeted drug delivery, precise surgical interventions, and environmental remediation. Such functionalities would increase markedly if collections of these microscopic machines were able to coordinate their function to achieve cooperative emergent behaviors. Implementing such coordination, however, requires a scalable strategy for synchronization—a key stumbling block for achieving collective behaviors of multiple autonomous microscopic units. Here, we show that pulse-coupled complementary metal-oxide semiconductor oscillators offer a tangible solution for such scalable synchronization. Specifically, we designed low-power oscillating modules with attached mechanical elements that exchange electronic pulses to advance their neighbor’s phase until the entire system is synchronized with the fastest oscillator or “leader.” We showed that this strategy is amenable to different oscillator connection topologies. The cooperative behaviors were robust to disturbances that scrambled the synchronization. In addition, when connections between oscillators were severed, the resulting subgroups synchronized on their own. This advance opens the door to functionalities in microscopic robot swarms that were once considered out of reach, ranging from autonomously induced fluidic transport to drive chemical reactions to cooperative building of physical structures at the microscale.},
  archive      = {J_SROB},
  author       = {Milad Taghavi and Wei Wang and Kyubum Shim and Jinsong Zhang and Itai Cohen and Alyssa Apsel},
  doi          = {10.1126/scirobotics.adn8067},
  journal      = {Science Robotics},
  month        = {11},
  number       = {96},
  pages        = {eadn8067},
  shortjournal = {Sci. Robot.},
  title        = {Coordinated behavior of autonomous microscopic machines through local electronic pulse coupling},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-organizing nervous systems for robot swarms.
<em>SROB</em>, <em>9</em>(96), eadl5161. (<a
href="https://doi.org/10.1126/scirobotics.adl5161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deploying self-organizing robot swarms in the real world is challenging because of a number of limitations. Zhu et al. have developed self-organizing nervous systems, a robot swarm architecture whereby robots self-organize hierarchies culminating in interchangeable brains that facilitate coordination of sensing, actuation, and decision-making in temporarily centralized subswarms. The authors demonstrated the ability of this approach to facilitate ease of swarm behavior design while maintaining fault tolerance, flexibility, and scalability on real robot swarms that combine aerial and ground robots for various robot missions, as well as in simulation with up to 250 robots in a swarm. —Amos Matsiko We present the self-organizing nervous system (SoNS), a robot swarm architecture based on self-organized hierarchy. The SoNS approach enables robots to autonomously establish, maintain, and reconfigure dynamic multilevel system architectures. For example, a robot swarm consisting of n independent robots could transform into a single n –robot SoNS and then into several independent smaller SoNSs, where each SoNS uses a temporary and dynamic hierarchy. Leveraging the SoNS approach, we showed that sensing, actuation, and decision-making can be coordinated in a locally centralized way without sacrificing the benefits of scalability, flexibility, and fault tolerance, for which swarm robotics is usually studied. In several proof-of-concept robot missions—including binary decision-making and search and rescue—we demonstrated that the capabilities of the SoNS approach greatly advance the state of the art in swarm robotics. The missions were conducted with a real heterogeneous aerial-ground robot swarm, using a custom-developed quadrotor platform. We also demonstrated the scalability of the SoNS approach in swarms of up to 250 robots in a physics-based simulator and demonstrated several types of system fault tolerance in simulation and reality.},
  archive      = {J_SROB},
  author       = {Weixu Zhu and Sinan Oğuz and Mary Katherine Heinrich and Michael Allwright and Mostafa Wahby and Anders Lyhne Christensen and Emanuele Garone and Marco Dorigo},
  doi          = {10.1126/scirobotics.adl5161},
  journal      = {Science Robotics},
  month        = {11},
  number       = {96},
  pages        = {eadl5161},
  shortjournal = {Sci. Robot.},
  title        = {Self-organizing nervous systems for robot swarms},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The force has limits: Molecular motors in robotics.
<em>SROB</em>, <em>9</em>(96), eadl0842. (<a
href="https://doi.org/10.1126/scirobotics.adl0842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molecular motors generate force to individually power molecular machines or collectively drive macroscopic actuators. The force output of molecular and macroscale motors appears to be constrained by the same scaling law relating motor force and mass. Here, potential origins of these universal performance characteristics are discussed and the implications examined.},
  archive      = {J_SROB},
  author       = {Henry Hess and Parag Katira and Juan B. Rodriguez III},
  doi          = {10.1126/scirobotics.adl0842},
  journal      = {Science Robotics},
  month        = {11},
  number       = {96},
  pages        = {eadl0842},
  shortjournal = {Sci. Robot.},
  title        = {The force has limits: Molecular motors in robotics},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NeuralFeels with neural fields: Visuotactile perception for
in-hand manipulation. <em>SROB</em>, <em>9</em>(96), eadl0628. (<a
href="https://doi.org/10.1126/scirobotics.adl0628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-hand perception using neural fields to endow robots with human levels of perception and dexterity is an ongoing problem in robotics. To estimate an object’s shape during manipulation, Suresh et al. trained a neural field to represent the spatial information of an object using the information gathered from vision and touch. A multifinger robotic hand with vision-based touch sensors rotated an object to gather tactile signals, which were combined with visual data from a stationary camera and input into an online neural field. The neural field used simultaneous localization and mapping (SLAM) to output the pose and geometry of the object. The pipeline, called NeuralFeels, could achieve reconstruction of novel objects with high precision. —Melisa Yashinski To achieve human-level dexterity, robots must infer spatial awareness from multimodal sensing to reason over contact interactions. During in-hand manipulation of novel objects, such spatial awareness involves estimating the object’s pose and shape. The status quo for in-hand perception primarily uses vision and is restricted to tracking a priori known objects. Moreover, visual occlusion of objects in hand is imminent during manipulation, preventing current systems from pushing beyond tasks without occlusion. We combined vision and touch sensing on a multifingered hand to estimate an object’s pose and shape during in-hand manipulation. Our method, NeuralFeels, encodes object geometry by learning a neural field online and jointly tracks it by optimizing a pose graph problem. We studied multimodal in-hand perception in simulation and the real world, interacting with different objects via a proprioception-driven policy. Our experiments showed final reconstruction F scores of 81% and average pose drifts of 4.7 millimeters, which was further reduced to 2.3 millimeters with known object models. In addition, we observed that, under heavy visual occlusion, we could achieve improvements in tracking up to 94% compared with vision-only methods. Our results demonstrate that touch, at the very least, refines and, at the very best, disambiguates visual estimates during in-hand manipulation. We release our evaluation dataset of 70 experiments, FeelSight, as a step toward benchmarking in this domain. Our neural representation driven by multimodal sensing can serve as a perception backbone toward advancing robot dexterity.},
  archive      = {J_SROB},
  author       = {Sudharshan Suresh and Haozhi Qi and Tingfan Wu and Taosha Fan and Luis Pineda and Mike Lambeta and Jitendra Malik and Mrinal Kalakrishnan and Roberto Calandra and Michael Kaess and Joseph Ortiz and Mustafa Mukadam},
  doi          = {10.1126/scirobotics.adl0628},
  journal      = {Science Robotics},
  month        = {11},
  number       = {96},
  pages        = {eadl0628},
  shortjournal = {Sci. Robot.},
  title        = {NeuralFeels with neural fields: Visuotactile perception for in-hand manipulation},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bioinspired designer DNA NanoGripper for virus sensing and
potential inhibition. <em>SROB</em>, <em>9</em>(96), eadi2084. (<a
href="https://doi.org/10.1126/scirobotics.adi2084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent DNA nanostructures have been functionalized to detect or block viruses but have lacked the dexterity to grasp individual virus particles. Here, Zhou et al. designed and synthesized a DNA NanoGripper from a single DNA origami piece that resembles a hand with a palm and four bendable finger-like structures. The NanoGripper’s fingers can be functionalized with ssDNA or aptamers to recognize and bind to different targets such as gold nanoparticles and SARS-CoV-2. Experiments showed that the NanoGripper can successfully detect SARS-CoV-2 virions in a human saliva sample with comparable sensitivity to a PCR test and has the potential to inhibit virus infections. —Melisa Yashinski DNA has shown great biocompatibility, programmable mechanical properties, and precise structural addressability at the nanometer scale, rendering it a material for constructing versatile nanorobots for biomedical applications. Here, we present the design principle, synthesis, and characterization of a DNA nanorobotic hand, called DNA NanoGripper, that contains a palm and four bendable fingers as inspired by naturally evolved human hands, bird claws, and bacteriophages. Each NanoGripper finger consists of three phalanges connected by three rotatable joints that are bendable in response to the binding of other entities. NanoGripper functions are enabled and driven by the interactions between moieties attached to the fingers and their binding partners. We demonstrate that the NanoGripper can be engineered to effectively interact with and capture nanometer-scale objects, including gold nanoparticles, gold NanoUrchins, and SARS-CoV-2 virions. With multiple DNA aptamer nanoswitches programmed to generate a fluorescent signal that is enhanced on a photonic crystal platform, the NanoGripper functions as a highly sensitive biosensor that selectively detects intact SARS-CoV-2 virions in human saliva with a limit of detection of ~100 copies per milliliter, providing a sensitivity equal to that of reverse transcription quantitative polymerase chain reaction (RT-qPCR). Quantified by flow cytometry assays, we demonstrated that the NanoGripper-aptamer complex can effectively block viral entry into the host cells, suggesting its potential for inhibiting virus infections. The design, synthesis, and characterization of a sophisticated nanomachine that can be tailored for specific applications highlight a promising pathway toward feasible and efficient solutions to the detection and potential inhibition of virus infections.},
  archive      = {J_SROB},
  author       = {Lifeng Zhou and Yanyu Xiong and Abhisek Dwivedy and Mengxi Zheng and Laura Cooper and Skye Shepherd and Tingjie Song and Wei Hong and Linh T. P. Le and Xin Chen and Saurabh Umrao and Lijun Rong and Tong Wang and Brian T. Cunningham and Xing Wang},
  doi          = {10.1126/scirobotics.adi2084},
  journal      = {Science Robotics},
  month        = {11},
  number       = {96},
  pages        = {eadi2084},
  shortjournal = {Sci. Robot.},
  title        = {Bioinspired designer DNA NanoGripper for virus sensing and potential inhibition},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cybernetic avatars: Teleoperation technologies from in-body
monitoring to social interaction. <em>SROB</em>, <em>9</em>(96),
eadg1842. (<a
href="https://doi.org/10.1126/scirobotics.adg1842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cybernetic avatars integrate physical and virtual avatars to enhance human capabilities in diverse scales and contexts.},
  archive      = {J_SROB},
  author       = {Norihiro Hagita and Ryota Kanai and Hiroshi Ishiguro and Kouta Minamizawa and Fumihito Arai and Fumio Shimpo and Takeshi Matsumura and Yoko Yamanishi},
  doi          = {10.1126/scirobotics.adg1842},
  journal      = {Science Robotics},
  month        = {11},
  number       = {96},
  pages        = {eadg1842},
  shortjournal = {Sci. Robot.},
  title        = {Cybernetic avatars: Teleoperation technologies from in-body monitoring to social interaction},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Advancing scientific discovery with the aid of robotics.
<em>SROB</em>, <em>9</em>(95), eadt3842. (<a
href="https://doi.org/10.1126/scirobotics.adt3842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots can be powerful tools to advance basic scientific discovery.},
  archive      = {J_SROB},
  author       = {Amos Matsiko},
  doi          = {10.1126/scirobotics.adt3842},
  journal      = {Science Robotics},
  month        = {10},
  number       = {95},
  pages        = {eadt3842},
  shortjournal = {Sci. Robot.},
  title        = {Advancing scientific discovery with the aid of robotics},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024h). Ted chiang imagines a computational theory of robots.
<em>SROB</em>, <em>9</em>(95), eadt3828. (<a
href="https://doi.org/10.1126/scirobotics.adt3828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two short science fiction stories, “Exhalation” and “Seventy-Two Letters”, explore robots inside and out.},
  archive      = {J_SROB},
  author       = {Robin R. Murphy},
  doi          = {10.1126/scirobotics.adt3828},
  journal      = {Science Robotics},
  month        = {10},
  number       = {95},
  pages        = {eadt3828},
  shortjournal = {Sci. Robot.},
  title        = {Ted chiang imagines a computational theory of robots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-driven aerial robots advance whale research.
<em>SROB</em>, <em>9</em>(95), eadt1955. (<a
href="https://doi.org/10.1126/scirobotics.adt1955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aerial robots assisted with artificial intelligence improve real-time wildlife monitoring of sperm whales.},
  archive      = {J_SROB},
  author       = {Haluk Bayram},
  doi          = {10.1126/scirobotics.adt1955},
  journal      = {Science Robotics},
  month        = {10},
  number       = {95},
  pages        = {eadt1955},
  shortjournal = {Sci. Robot.},
  title        = {AI-driven aerial robots advance whale research},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Augmented dexterity: How robots can enhance human surgical
skills. <em>SROB</em>, <em>9</em>(95), eadr5247. (<a
href="https://doi.org/10.1126/scirobotics.adr5247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in AI and robotics have the potential to enhance the dexterity of human surgeons.},
  archive      = {J_SROB},
  author       = {Ken Goldberg and Gary Guthart},
  doi          = {10.1126/scirobotics.adr5247},
  journal      = {Science Robotics},
  month        = {10},
  number       = {95},
  pages        = {eadr5247},
  shortjournal = {Sci. Robot.},
  title        = {Augmented dexterity: How robots can enhance human surgical skills},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning–based framework for whale rendezvous
via autonomous sensing robots. <em>SROB</em>, <em>9</em>(95), eadn7299.
(<a href="https://doi.org/10.1126/scirobotics.adn7299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, several sperm whales have been tagged to localize and track their positions while studying their behavior in the wild. Whale sightings at the surface, known as rendezvous, are critical for connecting behavioral data with tagged whales but can easily be missed. To automate whale rendezvous, Jadhav et al . used unpiloted aerial vehicles equipped with sensing modules to detect the very high frequency beacons on whale tags and underwater hydrophones to collect acoustic signals. To reduce missed rendezvous opportunities, a reinforcement learning–based algorithm was developed to determine likely surfacing times and provide routing commands to the rendezvous robots. Field tests were successfully performed initially using a speedboat to mimic whale motions and later using only acoustic measurements of three untagged whales. —Melisa Yashinski Rendezvous with sperm whales for biological observations is made challenging by their prolonged dive patterns. Here, we propose an algorithmic framework that codevelops multiagent reinforcement learning–based routing (autonomy module) and synthetic aperture radar–based very high frequency (VHF) signal–based bearing estimation (sensing module) for maximizing rendezvous opportunities of autonomous robots with sperm whales. The sensing module is compatible with low-energy VHF tags commonly used for tracking wildlife. The autonomy module leverages in situ noisy bearing measurements of whale vocalizations, VHF tags, and whale dive behaviors to enable time-critical rendezvous of a robot team with multiple whales in simulation. We conducted experiments at sea in the native habitat of sperm whales using an “engineered whale”—a speedboat equipped with a VHF-emitting tag, emulating five distinct whale tracks, with different whale motions. The sensing module shows a median bearing error of 10.55° to the tag. Using bearing measurements to the engineered whale from an acoustic sensor and our sensing module, our autonomy module gives an aggregate rendezvous success rate of 81.31% for a 500-meter rendezvous distance using three robots in postprocessing. A second class of fielded experiments that used acoustic-only bearing measurements to three untagged sperm whales showed an aggregate rendezvous success rate of 68.68% for a 1000-meter rendezvous distance using two robots in postprocessing. We further validated these algorithms with several ablation studies using a sperm whale visual encounter dataset collected by marine biologists.},
  archive      = {J_SROB},
  author       = {Ninad Jadhav and Sushmita Bhattacharya and Daniel Vogt and Yaniv Aluma and Pernille Tonessen and Akarsh Prabhakara and Swarun Kumar and Shane Gero and Robert J. Wood and Stephanie Gil},
  doi          = {10.1126/scirobotics.adn7299},
  journal      = {Science Robotics},
  month        = {10},
  number       = {95},
  pages        = {eadn7299},
  shortjournal = {Sci. Robot.},
  title        = {Reinforcement learning–based framework for whale rendezvous via autonomous sensing robots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Autonomous tracking of honey bee behaviors over long-term
periods with cooperating robots. <em>SROB</em>, <em>9</em>(95),
eadn6848. (<a
href="https://doi.org/10.1126/scirobotics.adn6848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Honey bees are important for pollination of food crops but have recently been facing population decline largely because of environmental factors, including habitat loss. Studies have attempted to understand honey bee behavior in their native beehive environment but without success. Ulrich et al. have now developed an autonomous robotic system for the tracking and observation of honey bees continuously over a 30-day period. The system was capable of detecting key behavioral characteristics of the queen, the worker bees, and the brood and could potentially be crucial in developing strategies for the protection of the species. —Amos Matsiko Digital and mechatronic methods, paired with artificial intelligence and machine learning, are transformative technologies in behavioral science and biology. The central element of the most important pollinator species—honey bees—is the colony’s queen. Because honey bee self-regulation is complex and studying queens in their natural colony context is difficult, the behavioral strategies of these organisms have not been widely studied. We created an autonomous robotic observation and behavioral analysis system aimed at continuous observation of the queen and her interactions with worker bees and comb cells, generating behavioral datasets of exceptional length and quality. Key behavioral metrics of the queen and her social embedding within the colony were gathered using our robotic system. Data were collected continuously for 24 hours a day over a period of 30 days, demonstrating our system’s capability to extract key behavioral metrics at microscopic, mesoscopic, and macroscopic system levels. Additionally, interactions among the queen, worker bees, and brood were observed and quantified. Long-term continuous observations performed by the robot yielded large amounts of high-definition video data that are beyond the observation capabilities of humans or stationary cameras. Our robotic system can enable a deeper understanding of the innermost mechanisms of honey bees’ swarm-intelligent self-regulation. Moreover, it offers the possibility to study other social insect colonies, biocoenoses, and ecosystems in an automated manner. Social insects are keystone species in all terrestrial ecosystems; thus, developing a better understanding of their behaviors will be invaluable for the protection and even the restoration of our fragile ecosystems globally.},
  archive      = {J_SROB},
  author       = {Jiří Ulrich and Martin Stefanec and Fatemeh Rekabi-Bana and Laurenz Alexander Fedotoff and Tomáš Rouček and Bilal Yağız Gündeğer and Mahmood Saadat and Jan Blaha and Jiří Janota and Daniel Nicolas Hofstadler and Kristina Žampachů and Erhan Ege Keyvan and Babür Erdem and Erol Şahin and Hande Alemdar and Ali Emre Turgut and Farshad Arvin and Thomas Schmickl and Tomáš Krajník},
  doi          = {10.1126/scirobotics.adn6848},
  journal      = {Science Robotics},
  month        = {10},
  number       = {95},
  pages        = {eadn6848},
  shortjournal = {Sci. Robot.},
  title        = {Autonomous tracking of honey bee behaviors over long-term periods with cooperating robots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Understanding the sense of self through robotics.
<em>SROB</em>, <em>9</em>(95), eadn2733. (<a
href="https://doi.org/10.1126/scirobotics.adn2733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotics can play a useful role in the scientific understanding of the sense of self, both through the construction of embodied models of the self and through the use of robots as experimental probes to explore the human self. In both cases, the embodiment of the robot allows us to devise and test hypotheses about the nature of the self, with regard to its development, its manifestation in behavior, and the diversity of selves in humans, animals, and, potentially, machines. This paper reviews robotics research that addresses the topic of the self—the minimal self, the extended self, and disorders of the self—and highlights future directions and open challenges in understanding the self through constructing its components in artificial systems. An emerging view is that key phenomena of the self can be generated in robots with suitably configured sensor and actuator systems and a layered cognitive architecture involving networks of predictive models.},
  archive      = {J_SROB},
  author       = {Tony J. Prescott and Kai Vogeley and Agnieszka Wykowska},
  doi          = {10.1126/scirobotics.adn2733},
  journal      = {Science Robotics},
  month        = {10},
  number       = {95},
  pages        = {eadn2733},
  shortjournal = {Sci. Robot.},
  title        = {Understanding the sense of self through robotics},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Paleoinspired robotics as an experimental approach to the
history of life. <em>SROB</em>, <em>9</em>(95), eadn1125. (<a
href="https://doi.org/10.1126/scirobotics.adn1125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paleontologists must confront the challenge of studying the forms and functions of extinct species for which data from preserved fossils are extremely limited, yielding only a fragmented picture of life in deep time. In response to this hurdle, we describe the nascent field of paleoinspired robotics, an innovative method that builds upon established techniques in bioinspired robotics, enabling the exploration of the biology of ancient organisms and their evolutionary trajectories. This Review presents ways in which robotic platforms can fill gaps in existing research using the exemplars of notable transitions in vertebrate locomotion. We examine recent case studies in experimental paleontology, highlighting substantial contributions made by engineering and robotics techniques, and further assess how the efficient application of robotic technologies in close collaboration with paleontologists and biologists can offer additional insights into the study of evolution that were previously unattainable.},
  archive      = {J_SROB},
  author       = {Michael Ishida and Fidji Berio and Valentina Di Santo and Neil H. Shubin and Fumiya Iida},
  doi          = {10.1126/scirobotics.adn1125},
  journal      = {Science Robotics},
  month        = {10},
  number       = {95},
  pages        = {eadn1125},
  shortjournal = {Sci. Robot.},
  title        = {Paleoinspired robotics as an experimental approach to the history of life},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robotic manipulation of cardiomyocytes to identify gap
junction modifiers for arrhythmogenic cardiomyopathy. <em>SROB</em>,
<em>9</em>(95), eadm8233. (<a
href="https://doi.org/10.1126/scirobotics.adm8233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cardiac disease arrhythmogenic cardiomyopathy is associated with deficiencies in cell-to-cell adhesion and can result in sudden fatal arrhythmias. Researchers have attempted to study the gap junctions in cardiomyocytes but have largely relied on manual experimental techniques. Dou et al . have developed a robotic cell manipulation system capable of microinjecting cardiomyocytes, with the ability to offset the spontaneous beating of the cells. They used the robotic system to study the permeability of healthy and diseased cells and subsequently carried out a drug screen to identify potential drug targets for treating the disease, which was validated in an in vivo study showing the ability to reduce beating irregularities in mice. —Amos Matsiko Arrhythmogenic cardiomyopathy (ACM) is a leading cause of sudden cardiac death among young adults. Aberrant gap junction remodeling has been linked to disease-causative mutations in plakophilin-2 ( PKP2 ). Although gap junctions are a key therapeutic target, measurement of gap junction function in preclinical disease models is technically challenging. To quantify gap junction function with high precision and high consistency, we developed a robotic cell manipulation system with visual feedback from digital holographic microscopy for three-dimensional and label-free imaging of human induced pluripotent stem cell–derived cardiomyocytes (iPSC-CMs). The robotic system can accurately determine the dynamic height changes in the cells’ contraction and resting phases, microinject drug-treated healthy and diseased iPSC-CMs in their resting phase with constant injection depth across all cells, and deposit a membrane-impermeable dye that solely diffuses between cells through gap junctions for measuring the gap junction diffusion function. The robotic system was applied toward a targeted drug screen to identify gap junction modulators and potential therapeutics for ACM. Five compounds were found to dose-dependently enhance gap junction permeability in cardiomyocytes with PKP2 knockdown. In addition, PCO 400 (pinacidil) reduced beating irregularity in a mouse model of ACM expressing mutant PKP2 (R735X). These results highlight the utility of the robotic cell manipulation system to efficiently assess gap junction function in a relevant preclinical disease model, thus providing a technique to advance drug discovery for ACM and other gap junction–mediated diseases.},
  archive      = {J_SROB},
  author       = {Wenkun Dou and Guanqiao Shan and Qili Zhao and Manpreet Malhi and Aojun Jiang and Zhuoran Zhang and Andrés González-Guerra and Shaojie Fu and Junhui Law and Robert M. Hamilton and Juan A. Bernal and Xinyu Liu and Yu Sun and Jason T. Maynes},
  doi          = {10.1126/scirobotics.adm8233},
  journal      = {Science Robotics},
  month        = {10},
  number       = {95},
  pages        = {eadm8233},
  shortjournal = {Sci. Robot.},
  title        = {Robotic manipulation of cardiomyocytes to identify gap junction modifiers for arrhythmogenic cardiomyopathy},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). High-tech guardians: Robotics at the heart of the future
circular collider. <em>SROB</em>, <em>9</em>(95), eadm7965. (<a
href="https://doi.org/10.1126/scirobotics.adm7965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A holistic robotic concept for inspection, maintenance, and emergency interventions for the Future Circular Collider is presented.},
  archive      = {J_SROB},
  author       = {Hannes Gamper and Andreas Mueller and Mario Di Castro},
  doi          = {10.1126/scirobotics.adm7965},
  journal      = {Science Robotics},
  month        = {10},
  number       = {95},
  pages        = {eadm7965},
  shortjournal = {Sci. Robot.},
  title        = {High-tech guardians: Robotics at the heart of the future circular collider},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). High-resolution outdoor videography of insects using fast
lock-on tracking. <em>SROB</em>, <em>9</em>(95), eadm7689. (<a
href="https://doi.org/10.1126/scirobotics.adm7689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studying insects in their natural environments can provide important insight into their behavior. However, videography of flying insects, especially outdoors, is difficult because of their small size and fast motion. After tagging an insect with a distinct marker, Vo-Doan et al . developed a system called Fast Lock-On (FLO) tracking that uses a feedback system to tilt the camera’s mirror position and keep the insect in focus. Using FLO, high-speed, high-resolution videos of a honey bee and locust were successfully captured with low motion blur. The FLO system was then incorporated onto a drone enabling video collection of a marked honey bee for several minutes, unlocking the potential for tracking insects on the kilometer scale. —Melisa Yashinski Insects have important roles globally in ecology, economy, and health, yet our understanding of their behavior remains limited. Bees, for example, use vision and a tiny brain to find flowers and return home, but understanding how they perform these impressive tasks has been hampered by limitations in recording technology. Here, we present Fast Lock-On (FLO) tracking. This method moves an image sensor to remain focused on a retroreflective marker affixed to an insect. Using paraxial infrared illumination, simple image processing can localize the sensor location of the insect in a few milliseconds. When coupled with a feedback system to steer a high-magnification optical system to remain focused on the insect, a high–spatiotemporal resolution trajectory can be gathered over a large region. As the basis for several robotic systems, we show that FLO is a versatile idea that can be used in combination with other components. We demonstrate that the optical path can be split and used for recording high-speed video. Furthermore, by flying an FLO system on a quadcopter drone, we track a flying honey bee and anticipate tracking insects in the wild over kilometer scales. Such systems have the capability to provide higher-resolution information about insects behaving in natural environments and as such will be helpful in revealing the biomechanical and neuroethological mechanisms used by insects in natural settings.},
  archive      = {J_SROB},
  author       = {T. Thang Vo-Doan and Victor V. Titov and Michael J. M. Harrap and Stephan Lochner and Andrew D. Straw},
  doi          = {10.1126/scirobotics.adm7689},
  journal      = {Science Robotics},
  month        = {10},
  number       = {95},
  pages        = {eadm7689},
  shortjournal = {Sci. Robot.},
  title        = {High-resolution outdoor videography of insects using fast lock-on tracking},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transforming science labs into automated factories of
discovery. <em>SROB</em>, <em>9</em>(95), eadm6991. (<a
href="https://doi.org/10.1126/scirobotics.adm6991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laboratories in chemistry, biochemistry, and materials science are at the leading edge of technology, discovering molecules and materials to unlock capabilities in energy, catalysis, biotechnology, sustainability, electronics, and more. Yet, most modern laboratories resemble factories from generations past, with a large reliance on humans manually performing synthesis and characterization tasks. Robotics and automation can enable scientific experiments to be conducted faster, more safely, more accurately, and with greater reproducibility, allowing scientists to tackle large societal problems in domains such as health and energy on a shorter timescale. We define five levels of laboratory automation, from laboratory assistance to full automation. We also introduce robotics research challenges that arise when increasing levels of automation and when increasing the generality of tasks within the laboratory. Robots are poised to transform science labs into automated factories of discovery that accelerate scientific progress.},
  archive      = {J_SROB},
  author       = {Angelos Angelopoulos and James F. Cahoon and Ron Alterovitz},
  doi          = {10.1126/scirobotics.adm6991},
  journal      = {Science Robotics},
  month        = {10},
  number       = {95},
  pages        = {eadm6991},
  shortjournal = {Sci. Robot.},
  title        = {Transforming science labs into automated factories of discovery},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024g). Social robot for at-home cognitive monitoring.
<em>SROB</em>, <em>9</em>(94), eadt0930. (<a
href="https://doi.org/10.1126/scirobotics.adt0930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A socially assistive robot can administer in-home neuropsychological tests for cognitive monitoring of older adults.},
  archive      = {J_SROB},
  author       = {Melisa Yashinski},
  doi          = {10.1126/scirobotics.adt0930},
  journal      = {Science Robotics},
  month        = {9},
  number       = {94},
  pages        = {eadt0930},
  shortjournal = {Sci. Robot.},
  title        = {Social robot for at-home cognitive monitoring},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024i). Visual seafloor mapping with autonomous robots.
<em>SROB</em>, <em>9</em>(94), eads9444. (<a
href="https://doi.org/10.1126/scirobotics.ads9444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous robots adopt navigation-aided hierarchical reconstruction to visually map the seafloor.},
  archive      = {J_SROB},
  author       = {Amos Matsiko},
  doi          = {10.1126/scirobotics.ads9444},
  journal      = {Science Robotics},
  month        = {9},
  number       = {94},
  pages        = {eads9444},
  shortjournal = {Sci. Robot.},
  title        = {Visual seafloor mapping with autonomous robots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024e). Machine learning, robots, and abuse of power.
<em>SROB</em>, <em>9</em>(94), eads6559. (<a
href="https://doi.org/10.1126/scirobotics.ads6559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The novel Annie Bot by Sierra Greer is a machine learning take on the domestic noir genre.},
  archive      = {J_SROB},
  author       = {Robin R. Murphy},
  doi          = {10.1126/scirobotics.ads6559},
  journal      = {Science Robotics},
  month        = {9},
  number       = {94},
  pages        = {eads6559},
  shortjournal = {Sci. Robot.},
  title        = {Machine learning, robots, and abuse of power},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Float like a butterfly, swim like a biohybrid neuromuscular
robot. <em>SROB</em>, <em>9</em>(94), eads4127. (<a
href="https://doi.org/10.1126/scirobotics.ads4127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A butterfly-like robot swims using an electronic device to stimulate human-derived motor neurons and cardiac muscle cells.},
  archive      = {J_SROB},
  author       = {Nicole W. Xu},
  doi          = {10.1126/scirobotics.ads4127},
  journal      = {Science Robotics},
  month        = {9},
  number       = {94},
  pages        = {eads4127},
  shortjournal = {Sci. Robot.},
  title        = {Float like a butterfly, swim like a biohybrid neuromuscular robot},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Taking control: Steering the future of biohybrid robots.
<em>SROB</em>, <em>9</em>(94), eadr9299. (<a
href="https://doi.org/10.1126/scirobotics.adr9299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Innovations in control mechanisms for muscle-powered robots are advancing the sophistication of biohybrid machines.},
  archive      = {J_SROB},
  author       = {Maheera Bawa and Ritu Raman},
  doi          = {10.1126/scirobotics.adr9299},
  journal      = {Science Robotics},
  month        = {9},
  number       = {94},
  pages        = {eadr9299},
  shortjournal = {Sci. Robot.},
  title        = {Taking control: Steering the future of biohybrid robots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A versatile knee exoskeleton mitigates quadriceps fatigue in
lifting, lowering, and carrying tasks. <em>SROB</em>, <em>9</em>(94),
eadr8282. (<a
href="https://doi.org/10.1126/scirobotics.adr8282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fatigue among workers engaging in physically demanding tasks increases their risk of injury. In particular, fatigue-induced musculoskeletal injuries occur because of repeated lifting, lowering, and carrying activities among workers. Divekar et al . have developed an adaptive knee exoskeleton controller that provides assistance to users depending on the tasks carried out. The exoskeleton controller was capable of application-specific tuning without user calibration. It was shown to minimize quadriceps muscle fatigue among participants carrying out repetitive multiterrain lifting, lowering, and carrying tasks. —Amos Matsiko The quadriceps are particularly susceptible to fatigue during repetitive lifting, lowering, and carrying (LLC), affecting worker performance, posture, and ultimately lower-back injury risk. Although robotic exoskeletons have been developed and optimized for specific use cases like lifting-lowering, their controllers lack the versatility or customizability to target critical muscles across many fatiguing tasks. Here, we present a task-adaptive knee exoskeleton controller that automatically modulates virtual springs, dampers, and gravity and inertia compensation to assist squatting, level walking, and ramp and stairs ascent/descent. Unlike end-to-end neural networks, the controller is composed of predictable, bounded components with interpretable parameters that are amenable to data-driven optimization for biomimetic assistance and subsequent application-specific tuning, for example, maximizing quadriceps assistance over multiterrain LLC. When deployed on a backdrivable knee exoskeleton, the assistance torques holistically reduced quadriceps effort across multiterrain LLC tasks (significantly except for level walking) in 10 human users without user-specific calibration. The exoskeleton also significantly improved fatigue-induced deficits in time-based performance and posture during repetitive lifting-lowering. Last, the system facilitated seamless task transitions and garnered a high effectiveness rating postfatigue over a multiterrain circuit. These findings indicate that this versatile control framework can target critical muscles across multiple tasks, specifically mitigating quadriceps fatigue and its deleterious effects.},
  archive      = {J_SROB},
  author       = {Nikhil V. Divekar and Gray C. Thomas and Avani R. Yerva and Hannah B. Frame and Robert D. Gregg},
  doi          = {10.1126/scirobotics.adr8282},
  journal      = {Science Robotics},
  month        = {9},
  number       = {94},
  pages        = {eadr8282},
  shortjournal = {Sci. Robot.},
  title        = {A versatile knee exoskeleton mitigates quadriceps fatigue in lifting, lowering, and carrying tasks},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Restoration of grasping in an upper limb amputee using the
myokinetic prosthesis with implanted magnets. <em>SROB</em>,
<em>9</em>(94), eadp3260. (<a
href="https://doi.org/10.1126/scirobotics.adp3260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Restoration of dexterous motor control after an amputation is challenging in the field of prosthetics and often relies on transduction of electrical signals from the brain to control bionic limbs. Gherardini et al. have now developed a myokinetic interface involving the implantation of magnets within muscle groups of the residual limb of a transradial amputee and a prosthesis device controlled wirelessly. Muscle deformation due to voluntary contraction was harnessed for dexterous bionic hand control through a direct control strategy and with the aid of a pattern recognition algorithm, enabling the user to carry out functional tasks such as picking up and grasping fragile objects as well as tying shoelaces. —Amos Matsiko The loss of a hand disrupts the sophisticated neural pathways between the brain and the hand, severely affecting the level of independence of the patient and the ability to carry out daily work and social activities. Recent years have witnessed a rapid evolution of surgical techniques and technologies aimed at restoring dexterous motor functions akin to those of the human hand through bionic solutions, mainly relying on probing of electrical signals from the residual nerves and muscles. Here, we report the clinical implementation of an interface aimed at achieving this goal by exploiting muscle deformation, sensed through passive magnetic implants: the myokinetic interface. One participant with a transradial amputation received an implantation of six permanent magnets in three muscles of the residual limb. A truly self-contained myokinetic prosthetic arm embedding all hardware components and the battery within the prosthetic socket was developed. By retrieving muscle deformation caused by voluntary contraction through magnet localization, we were able to control in real time a dexterous robotic hand following both a direct control strategy and a pattern recognition approach. In just 6 weeks, the participant successfully completed a series of functional tests, achieving scores similar to those achieved when using myoelectric controllers, a standard-of-care solution, with comparable physical and mental workloads. This experience raised conceptual and technical limits of the interface, which nevertheless pave the way for further investigations in a partially unexplored field. This study also demonstrates a viable possibility for intuitively interfacing humans with robotic technologies.},
  archive      = {J_SROB},
  author       = {Marta Gherardini and Valerio Ianniciello and Federico Masiero and Flavia Paggetti and Daniele D’Accolti and Eliana La Frazia and Olimpia Mani and Stefania Dalise and Katarina Dejanovic and Noemi Fragapane and Luca Maggiani and Edoardo Ipponi and Marco Controzzi and Manuela Nicastro and Carmelo Chisari and Lorenzo Andreani and Christian Cipriani},
  doi          = {10.1126/scirobotics.adp3260},
  journal      = {Science Robotics},
  month        = {9},
  number       = {94},
  pages        = {eadp3260},
  shortjournal = {Sci. Robot.},
  title        = {Restoration of grasping in an upper limb amputee using the myokinetic prosthesis with implanted magnets},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Soft robotic artificial left ventricle simulator capable of
reproducing myocardial biomechanics. <em>SROB</em>, <em>9</em>(94),
eado4553. (<a
href="https://doi.org/10.1126/scirobotics.ado4553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiac devices and interventions are often dependent on the use of animal models and ex vivo tissue for testing and development. Moreover, surgical training for procedure-specific skills also relies on animal tissue. Davies et al. have developed a soft robotic device that can mimic the left ventricle of the heart and reproduce cardiac motion as well as physiological hemodynamic conditions. They demonstrated the ability to simulate conditions of healthy and diseased heart states, with the potential to counter the need for animal models to develop cardiac devices. —Amos Matsiko The heart’s intricate myocardial architecture has been called the Gordian knot of anatomy, an impossible tangle of intricate muscle fibers. This complexity dictates equally complex cardiac motions that are difficult to mimic in physical systems. If these motions could be generated by a robotic system, then cardiac device testing, cardiovascular disease studies, and surgical procedure training could reduce their reliance on animal models, saving time, costs, and lives. This work introduces a bioinspired soft robotic left ventricle simulator capable of reproducing the minutiae of cardiac motion while providing physiological pressures. This device uses thin-filament artificial muscles to mimic the multilayered myocardial architecture. To demonstrate the device’s ability to follow the cardiac motions observed in the literature, we used canine myocardial strain data as input signals that were subsequently applied to each artificial myocardial layer. The device’s ability to reproduce physiological volume and pressure under healthy and heart failure conditions, as well as effective simulation of a cardiac support device, were experimentally demonstrated in a left-sided mock circulation loop. This work also has the potential to deliver faithful simulated cardiac motion for preclinical device and surgical procedure testing, with the potential to simulate patient-specific myocardial architecture and motion.},
  archive      = {J_SROB},
  author       = {James Davies and Mai Thanh Thai and Bibhu Sharma and Trung Thien Hoang and Chi Cong Nguyen and Phuoc Thien Phan and Thao Nhu Anne Marie Vuong and Adrienne Ji and Kefan Zhu and Emanuele Nicotra and Yi-Chin Toh and Michael Stevens and Christopher Hayward and Hoang-Phuong Phan and Nigel Hamilton Lovell and Thanh Nho Do},
  doi          = {10.1126/scirobotics.ado4553},
  journal      = {Science Robotics},
  month        = {9},
  number       = {94},
  pages        = {eado4553},
  shortjournal = {Sci. Robot.},
  title        = {Soft robotic artificial left ventricle simulator capable of reproducing myocardial biomechanics},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wirelessly steerable bioelectronic neuromuscular robots
adapting neurocardiac junctions. <em>SROB</em>, <em>9</em>(94),
eado0051. (<a
href="https://doi.org/10.1126/scirobotics.ado0051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Typically, biohybrid machines built from cardiac muscle cells have relied on the involuntary, contractile actuation of the cells to continuously propel the robot. However, without the nervous system, this rhythmic pumping action could not be adjusted or controlled. To imbue control, Tetsuka et al. developed a biohybrid swimmer with a neurocardiac muscle junction. Acting as an artificial brain, a frequency multiplexing wireless system was used to stimulate the motor neurons, which in turn activated the cardiac muscle cells. The robot’s speed could be controlled by modulating the frequency and pulse duration of the electrical signal, and direction was altered by transmitting signals to the left and right fins independently. —Melisa Yashinski Biological motions of native muscle tissues rely on the nervous system to interface movement with the surrounding environment. The neural innervation of muscles, crucial for regulating movement, is the fundamental infrastructure for swiftly responding to changes in body tissue requirements. This study introduces a bioelectronic neuromuscular robot integrated with the motor nervous system through electrical synapses to evoke cardiac muscle activities and steer robotic motion. Serving as an artificial brain and wirelessly regulating selective neural activation to initiate robot fin motion, a wireless frequency multiplexing bioelectronic device is used to control the robot. Frequency multiplexing bioelectronics enables the control of the robot locomotion speed and direction by modulating the flapping of the robot fins through the wireless motor innervation of cardiac muscles. The robots demonstrated an average locomotion speed of ~0.52 ± 0.22 millimeters per second, fin-flapping frequency up to 2.0 hertz, and turning locomotion path curvature of ~0.11 ± 0.04 radians per millimeter. These systems will contribute to the expansion of biohybrid machines into the brain-to-motor frontier for developing autonomous biohybrid systems capable of advanced adaptive motor control and learning.},
  archive      = {J_SROB},
  author       = {Hiroyuki Tetsuka and Samuele Gobbi and Takaaki Hatanaka and Lorenzo Pirrami and Su Ryon Shin},
  doi          = {10.1126/scirobotics.ado0051},
  journal      = {Science Robotics},
  month        = {9},
  number       = {94},
  pages        = {eado0051},
  shortjournal = {Sci. Robot.},
  title        = {Wirelessly steerable bioelectronic neuromuscular robots adapting neurocardiac junctions},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stretchable arduinos embedded in soft robots. <em>SROB</em>,
<em>9</em>(94), eadn6844. (<a
href="https://doi.org/10.1126/scirobotics.adn6844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Commercial and open-source electronic circuit boards are widely used for controlling robots; however, their rigid form makes it difficult to embed them into soft robots. Here, Woodman et al. developed a generalized method for converting multilayered circuits into a soft, stretchable form. Commercial circuits were recreated by patterning biphasic liquid metal onto tacky films, and their continued operation was demonstrated during high-strain cycling. Using this method, stretchable Arduino Pro Minis were created and embedded into the body of a soft crawling robot to control locomotion, into pneumatic cubes for sensing and communicating, and into the high-strain elbow area of a wearable sleeve for tracking motion. —Melisa Yashinski To achieve real-world functionality, robots must have the ability to carry out decision-making computations. However, soft robots stretch and therefore need a solution other than rigid computers. Examples of embedding computing capacity into soft robots currently include appending rigid printed circuit boards to the robot, integrating soft logic gates, and exploiting material responses for material-embedded computation. Although promising, these approaches introduce limitations such as rigidity, tethers, or low logic gate density. The field of stretchable electronics has sought to solve these challenges, but a complete pipeline for direct integration of single-board computers, microcontrollers, and other complex circuitry into soft robots has remained elusive. We present a generalized method to translate any complex two-layer circuit into a soft, stretchable form. This enabled the creation of stretchable single-board microcontrollers (including Arduinos) and other commercial circuits (including SparkFun circuits), without design simplifications. As demonstrations of the method’s utility, we embedded highly stretchable (&gt;300% strain) Arduino Pro Minis into the bodies of multiple soft robots. This makes use of otherwise inert structural material, fulfilling the promise of the stretchable electronic field to integrate state-of-the-art computational power into robust, stretchable systems during active use.},
  archive      = {J_SROB},
  author       = {Stephanie J. Woodman and Dylan S. Shah and Melanie Landesberg and Anjali Agrawala and Rebecca Kramer-Bottiglio},
  doi          = {10.1126/scirobotics.adn6844},
  journal      = {Science Robotics},
  month        = {9},
  number       = {94},
  pages        = {eadn6844},
  shortjournal = {Sci. Robot.},
  title        = {Stretchable arduinos embedded in soft robots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hexagonal electrohydraulic modules for rapidly
reconfigurable high-speed robots. <em>SROB</em>, <em>9</em>(94),
eadl3546. (<a
href="https://doi.org/10.1126/scirobotics.adl3546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconfigurable, modular robots are an appealing approach to developing versatile systems, but because of soft actuators’ slow actuation speeds, low force output, and tethered configurations, they have mostly been limited to heavy, bulky motors. Using electrohydraulic actuation, Yoder et al . developed a hexagonal-shaped modular robot that provides high-speed and high-strain actuation. Four electrohydraulic actuators located at the junctions of a hexagonal array of stiff plates drive a rapid shape change in the hexagon from tall and narrow to wide and short. Magnets embedded in the plates allow the modules to connect in honeycomb-like lattices for multimodal actuation, such as a high-stroke muscle hanging configuration and a rolling wheel–like configuration. —Melisa Yashinski Robots made from reconfigurable modular units feature versatility, cost efficiency, and improved sustainability compared with fixed designs. Reconfigurable modules driven by soft actuators provide adaptable actuation, safe interaction, and wide design freedom, but existing soft modules would benefit from high-speed and high-strain actuation, as well as driving methods well-suited to untethered operation. Here, we introduce a class of electrically actuated robotic modules that provide high-speed (a peak contractile strain rate of 4618% per second, 15.8-hertz bandwidth, and a peak specific power of 122 watts per kilogram), high-strain (49% contraction) actuation and that use magnets for reversible mechanical and electrical connections between neighboring modules, thereby serving as building blocks for rapidly reconfigurable and highly agile robotic systems. The actuation performance of each hexagonal electrohydraulic (HEXEL) module is enabled by a synergistic combination of soft and rigid components; a hexagonal exoskeleton of rigid plates amplifies the motion produced by soft electrohydraulic actuators and provides a mechanical structure and connection platform for reconfigurable robots composed of many modules. We characterize the actuation performance of individual HEXEL modules, present a model that captures their quasi-static force-stroke behavior, and demonstrate both a high-jumping and a fast pipe-crawling robot. Using embedded magnetic connections, we arranged multiple modules into reconfigurable robots with diverse functionality, including a high-stroke muscle, a multimodal active array, a table-top active platform, and a fast-rolling robot. We further leveraged the magnetic connections for hosting untethered, snap-on driving electronics, together highlighting the promise of HEXEL modules for creating rapidly reconfigurable high-speed robots.},
  archive      = {J_SROB},
  author       = {Zachary Yoder and Ellen H. Rumley and Ingemar Schmidt and Philipp Rothemund and Christoph Keplinger},
  doi          = {10.1126/scirobotics.adl3546},
  journal      = {Science Robotics},
  month        = {9},
  number       = {94},
  pages        = {eadl3546},
  shortjournal = {Sci. Robot.},
  title        = {Hexagonal electrohydraulic modules for rapidly reconfigurable high-speed robots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Collection of microrobots for gentle cell manipulation.
<em>SROB</em>, <em>9</em>(93), eads6194. (<a
href="https://doi.org/10.1126/scirobotics.ads6194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optically actuated soft microrobotic tools were designed for cell transportation, manipulation, and cell-to-cell interactions.},
  archive      = {J_SROB},
  author       = {Melisa Yashinski},
  doi          = {10.1126/scirobotics.ads6194},
  journal      = {Science Robotics},
  month        = {8},
  number       = {93},
  pages        = {eads6194},
  shortjournal = {Sci. Robot.},
  title        = {Collection of microrobots for gentle cell manipulation},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Erratum for the research article “field deployment of
wolbachia-infected aedes aegypti using uncrewed aerial vehicle” by y.-h.
Lin et al. <em>SROB</em>, <em>9</em>(93), eads4716. (<a
href="https://doi.org/10.1126/scirobotics.ads4716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SROB},
  doi          = {10.1126/scirobotics.ads4716},
  journal      = {Science Robotics},
  month        = {8},
  number       = {93},
  pages        = {eads4716},
  shortjournal = {Sci. Robot.},
  title        = {Erratum for the research article “Field deployment of wolbachia-infected aedes aegypti using uncrewed aerial vehicle” by y.-h. lin et al.},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Bilingual speech neuroprosthesis. <em>SROB</em>,
<em>9</em>(93), eads4122. (<a
href="https://doi.org/10.1126/scirobotics.ads4122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A neuroprosthesis could decode two languages from the brain activity of a bilingual participant who was unable to articulate speech.},
  archive      = {J_SROB},
  author       = {Amos Matsiko},
  doi          = {10.1126/scirobotics.ads4122},
  journal      = {Science Robotics},
  month        = {8},
  number       = {93},
  pages        = {eads4122},
  shortjournal = {Sci. Robot.},
  title        = {Bilingual speech neuroprosthesis},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024f). Real-world exoskeletons are better than those in the movie
atlas. <em>SROB</em>, <em>9</em>(93), eadr9557. (<a
href="https://doi.org/10.1126/scirobotics.adr9557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent movie Atlas misses fundamental robotics advances in self-stabilization and human-robot interaction.},
  archive      = {J_SROB},
  author       = {Robin R. Murphy},
  doi          = {10.1126/scirobotics.adr9557},
  journal      = {Science Robotics},
  month        = {8},
  number       = {93},
  pages        = {eadr9557},
  shortjournal = {Sci. Robot.},
  title        = {Real-world exoskeletons are better than those in the movie atlas},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online tree-based planning for active spacecraft fault
estimation and collision avoidance. <em>SROB</em>, <em>9</em>(93),
eadn4722. (<a
href="https://doi.org/10.1126/scirobotics.adn4722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As autonomous systems are increasingly deployed in various real-world scenarios, the ability to safely accomplish their desired tasks is dependent on the ability to detect system failures and subsequently take the appropriate action without human intervention. Ragan et al . have developed a method—safe fault estimation via active sensing tree search—for diagnosing system faults capable of planning and acting to ensure safe robot operations. They demonstrated that the method could actively perform fault estimation on a robotic spacecraft simulator on a collision course with a model comet when thrusters are dysfunctional and showed its potential to keep the robot on a safe path. —Amos Matsiko Autonomous robots operating in uncertain or hazardous environments subject to state safety constraints must be able to identify and isolate faulty components in a time-optimal manner. When the underlying fault is ambiguous and intertwined with the robot’s state estimation, motion plans that discriminate between simultaneous actuator and sensor faults are necessary. However, the coupled fault mode and physical state uncertainty creates a constrained optimization problem that is challenging to solve with existing methods. We combined belief-space tree search, marginalized filtering, and concentration inequalities in our method, safe fault estimation via active sensing tree search (s-FEAST), a planner that actively diagnoses system faults by selecting actions that give the most informative observations while simultaneously enforcing probabilistic state constraints. We justify this approach with theoretical analysis showing s-FEAST’s convergence to optimal policies. Using our robotic spacecraft simulator, we experimentally validated s-FEAST by safely and successfully performing fault estimation while on a collision course with a model comet. These results were further validated through extensive numerical simulations demonstrating s-FEAST’s performance.},
  archive      = {J_SROB},
  author       = {James Ragan and Benjamin Riviere and Fred Y. Hadaegh and Soon-Jo Chung},
  doi          = {10.1126/scirobotics.adn4722},
  journal      = {Science Robotics},
  month        = {8},
  number       = {93},
  pages        = {eadn4722},
  shortjournal = {Sci. Robot.},
  title        = {Online tree-based planning for active spacecraft fault estimation and collision avoidance},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intrinsic sense of touch for intuitive physical human-robot
interaction. <em>SROB</em>, <em>9</em>(93), eadn4008. (<a
href="https://doi.org/10.1126/scirobotics.adn4008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tactile sensors and electronic skins are common devices that provide robots with a sense of physical interaction, but they become complex and costly when used to cover large portions of a robot. Using internal high-resolution joint-force-torque sensors, Iskandar et al . realized an intrinsic, full-body sense of touch in a robotic arm. Deep learning techniques and an artificial neural network allow the robot to sense the location, direction, and magnitude of a force applied anywhere on its surface. The robot can recognize and react to characters, such as a number drawn on its surface, and virtual buttons or sliders, providing users with an intuitive way to interact with a robot. —Melisa Yashinski The sense of touch is a property that allows humans to interact delicately with their physical environment. This article reports on a technological advancement in intuitive human-robot interaction that enables an intrinsic robotic sense of touch without the use of artificial skin or tactile instrumentation. On the basis of high-resolution joint-force-torque sensing in a redundant arrangement, we were able to let the robot sensitively feel the surrounding environment and accurately localize touch trajectories in space and time that were applied on its surface by a human. Through an intertwined combination of manifold learning techniques and artificial neural networks, the robot identified and interpreted those touch trajectories as machine-readable letters, symbols, or numbers. This opens up unexplored opportunities in terms of intuitive and flexible interaction between human and robot. Furthermore, we showed that our concept of so-called virtual buttons can be used to straightforwardly implement a tactile communication link, including switches and slider bars, which are complementary to speech, hardware buttons, and control panels. These interaction elements could be freely placed, moved, and configured in arbitrary locations on the robot structure. The intrinsic sense of touch we proposed in this work can serve as the basis for an advanced category of physical human-robot interaction that has not been possible yet, enabling a shift from conventional modalities toward adaptability, flexibility, and intuitive handling.},
  archive      = {J_SROB},
  author       = {Maged Iskandar and Alin Albu-Schäffer and Alexander Dietrich},
  doi          = {10.1126/scirobotics.adn4008},
  journal      = {Science Robotics},
  month        = {8},
  number       = {93},
  pages        = {eadn4008},
  shortjournal = {Sci. Robot.},
  title        = {Intrinsic sense of touch for intuitive physical human-robot interaction},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bistable soft jumper capable of fast response and high
takeoff velocity. <em>SROB</em>, <em>9</em>(93), eadm8484. (<a
href="https://doi.org/10.1126/scirobotics.adm8484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For jumping to be an efficient mode of locomotion, it requires a high power output and fast response time, which can be difficult to achieve in soft materials. Here, Tang et al . developed a pyramid-shaped soft jumper with a fast snap-through transition triggered by a magnetic field. Made of magnetic panels and elastomer creases, the robot rapidly transitions from the top of the pyramid pointing up to pointing down, propelling the robot upward to more than 100 times its height. By adjusting the strength, duration, and direction of the magnetic field, the robot’s movement can go from jumping to hopping, and its trajectory can be controlled, allowing it to navigate through confined spaces such as a pipeline. —Melisa Yashinski In contrast with jumping robots made from rigid materials, soft jumpers composed of compliant and elastically deformable materials exhibit superior impact resistance and mechanically robust functionality. However, recent efforts to create stimuli-responsive jumpers from soft materials were limited in their response speed, takeoff velocity, and travel distance. Here, we report a magnetic-driven, ultrafast bistable soft jumper that exhibits good jumping capability (jumping more than 108 body heights with a takeoff velocity of more than 2 meters per second) and fast response time (less than 15 milliseconds) compared with previous soft jumping robots. The snap-through transitions between bistable states form a repeatable loop that harnesses the ultrafast release of stored elastic energy. On the basis of the dynamic analysis, the multimodal locomotion of the bistable soft jumper can be realized: the interwell mode of jumping and the intrawell mode of hopping. These modes are controlled by adjusting the duration and strength of the magnetic field, which endows the bistable soft jumper with robust locomotion capabilities. In addition, it is capable of jumping omnidirectionally with tunable heights and distances. To demonstrate its capability in complex environments, a realistic pipeline with amphibious terrain was established. The jumper successfully finished a simulative task of cleansing water through a pipeline. The design principle and actuating mechanism of the bistable soft jumper can be further extended for other flexible systems.},
  archive      = {J_SROB},
  author       = {Daofan Tang and Chengqian Zhang and Chengfeng Pan and Hao Hu and Haonan Sun and Huangzhe Dai and Jianzhong Fu and Carmel Majidi and Peng Zhao},
  doi          = {10.1126/scirobotics.adm8484},
  journal      = {Science Robotics},
  month        = {8},
  number       = {93},
  pages        = {eadm8484},
  shortjournal = {Sci. Robot.},
  title        = {Bistable soft jumper capable of fast response and high takeoff velocity},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Variable-stiffness–morphing wheel inspired by the surface
tension of a liquid droplet. <em>SROB</em>, <em>9</em>(93), eadl2067.
(<a href="https://doi.org/10.1126/scirobotics.adl2067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With their speed and low cost of transport, wheels are a favorable choice of locomotion for robots. However, wheels cannot easily navigate over large obstacles, restricting their use in certain environments. Here, Lee et al. developed a wheel with adjustable stiffness that can be changed in real time, taking on a rigid, circular shape on flat ground and a soft, deformable shape for rolling over large obstacles. A smart chain structure along the outside of the wheel connects to a center hub via a spoke structure. The tension in the spokes can be adjusted to adapt the wheel stiffness, allowing the wheels to move across a variable terrain. The wheel capabilities are demonstrated in a four-wheeled vehicle and a two-wheeled wheelchair system. —Melisa Yashinski Wheels have been commonly used for locomotion in mobile robots and transportation systems because of their simple structure and energy efficiency. However, the performance of wheels in overcoming obstacles is limited compared with their advantages in driving on normal flat ground. Here, we present a variable-stiffness wheel inspired by the surface tension of a liquid droplet. In a liquid droplet, as the cohesive force of the outermost liquid molecules increases, the net force pulling the liquid molecules inward also increases. This leads to high surface tension, resulting in the liquid droplet reverting to a circular shape from its distorted shape induced by gravitational forces. Similarly, the shape and stiffness of a wheel were controlled by changing the traction force at the outermost smart chain block. As the tension of the wire spokes connected to each chain block increased, the wheel characteristics reflected those of a general circular-rigid wheel, which has an advantage in high-speed locomotion on normal flat ground. Conversely, the modulus of the wheel decreased as the tension of the wire spoke decreased, and the wheel was easily deformed according to the shape of obstacles. This makes the wheel suitable for overcoming obstacles without requiring complex control or sensing systems. On the basis of this mechanism, a wheel was applied to a two-wheeled wheelchair system weighing 120 kilograms, and the state transition between a circular high-modulus state and a deformable low-modulus state was realized in real time when the wheelchair was driven in an outdoor environment.},
  archive      = {J_SROB},
  author       = {Jae-Young Lee and Seongji Han and Munyu Kim and Yong-Sin Seo and Jongwoo Park and Dong Il Park and Chanhun Park and Hyunuk Seo and Joonho Lee and Hwi-Su Kim and Jeongae Bak and Hugo Rodrigue and Jin-Gyun Kim and Joono Cheong and Sung-Hyuk Song},
  doi          = {10.1126/scirobotics.adl2067},
  journal      = {Science Robotics},
  month        = {8},
  number       = {93},
  pages        = {eadl2067},
  shortjournal = {Sci. Robot.},
  title        = {Variable-stiffness–morphing wheel inspired by the surface tension of a liquid droplet},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sensorimotor control of robots mediated by
electrophysiological measurements of fungal mycelia. <em>SROB</em>,
<em>9</em>(93), eadk8019. (<a
href="https://doi.org/10.1126/scirobotics.adk8019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many biohybrid robots are powered by animal or plant cells, which are sensitive to specific culture procedures and limited to short life spans. In contrast, fungi can be easily cultured and are robust in extreme conditions. Taking advantage of fungal mycelia’s natural light sensitivity, Mishra et al. developed an electrical interface to both house the mycelia and measure their electrophysiological action potentials. A control model was then developed to use the rhythmic voltage spikes from the living mycelia to control the locomotion of both a soft starfish-inspired robot and a wheeled robot. Robot trajectories could be altered by stimulating the mycelia with ultraviolet light. —Melisa Yashinski Living tissues are still far from being used as practical components in biohybrid robots because of limitations in life span, sensitivity to environmental factors, and stringent culture procedures. Here, we introduce fungal mycelia as an easy-to-use and robust living component in biohybrid robots. We constructed two biohybrid robots that use the electrophysiological activity of living mycelia to control their artificial actuators. The mycelia sense their environment and issue action potential–like spiking voltages as control signals to the motors and valves of the robots that we designed and built. The paper highlights two key innovations: first, a vibration- and electromagnetic interference–shielded mycelium electrical interface that allows for stable, long-term electrophysiological bioelectric recordings during untethered, mobile operation; second, a control architecture for robots inspired by neural central pattern generators, incorporating rhythmic patterns of positive and negative spikes from the living mycelia. We used these signals to control a walking soft robot as well as a wheeled hard one. We also demonstrated the use of mycelia to respond to environmental cues by using ultraviolet light stimulation to augment the robots’ gaits.},
  archive      = {J_SROB},
  author       = {Anand Kumar Mishra and Jaeseok Kim and Hannah Baghdadi and Bruce R. Johnson and Kathie T. Hodge and Robert F. Shepherd},
  doi          = {10.1126/scirobotics.adk8019},
  journal      = {Science Robotics},
  month        = {8},
  number       = {93},
  pages        = {eadk8019},
  shortjournal = {Sci. Robot.},
  title        = {Sensorimotor control of robots mediated by electrophysiological measurements of fungal mycelia},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). High energy density picoliter-scale zinc-air microbatteries
for colloidal robotics. <em>SROB</em>, <em>9</em>(93), eade4642. (<a
href="https://doi.org/10.1126/scirobotics.ade4642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy storage at the micrometer scale is an ever-growing challenge as robots are progressively downsized. Moreover, the use of wet chemistry in battery technologies limits their potential to be scaled down beyond millimeters in size. Zhang et al . have now developed a high energy density zinc-air battery at the picoliter scale in volume. Using photolithography, 10,000 batteries could be fabricated from a single 50.8-mm wafer and released into solution. Moreover, the batteries could achieve an energy density above 760 watt-hours per liter and were capable of powering micrometer-sized devices such as colloidal robots, sensors, and memristor circuits. —Amos Matsiko The recent interest in microscopic autonomous systems, including microrobots, colloidal state machines, and smart dust, has created a need for microscale energy storage and harvesting. However, macroscopic materials for energy storage have noted incompatibilities with microfabrication techniques, creating substantial challenges to realizing microscale energy systems. Here, we photolithographically patterned a microscale zinc/platinum/SU-8 system to generate the highest energy density microbattery at the picoliter (10 −12 liter) scale. The device scavenges ambient or solution-dissolved oxygen for a zinc oxidation reaction, achieving an energy density ranging from 760 to 1070 watt-hours per liter at scales below 100 micrometers lateral and 2 micrometers thickness in size. The parallel nature of photolithography processes allows 10,000 devices per wafer to be released into solution as colloids with energy stored on board. Within a volume of only 2 picoliters each, these primary microbatteries can deliver open circuit voltages of 1.05 ± 0.12 volts, with total energies ranging from 5.5 ± 0.3 to 7.7 ± 1.0 microjoules and a maximum power near 2.7 nanowatts. We demonstrated that such systems can reliably power a micrometer-sized memristor circuit, providing access to nonvolatile memory. We also cycled power to drive the reversible bending of microscale bimorph actuators at 0.05 hertz for mechanical functions of colloidal robots. Additional capabilities, such as powering two distinct nanosensor types and a clock circuit, were also demonstrated. The high energy density, low volume, and simple configuration promise the mass fabrication and adoption of such picoliter zinc-air batteries for micrometer-scale, colloidal robotics with autonomous functions.},
  archive      = {J_SROB},
  author       = {Ge Zhang and Sungyun Yang and Jing Fan Yang and David Gonzalez-Medrano and Marc Z. Miskin and Volodymyr B. Koman and Yuwen Zeng and Sylvia Xin Li and Matthias Kuehne and Albert Tianxiang Liu and Allan M. Brooks and Mahesh Kumar and Michael S. Strano},
  doi          = {10.1126/scirobotics.ade4642},
  journal      = {Science Robotics},
  month        = {8},
  number       = {93},
  pages        = {eade4642},
  shortjournal = {Sci. Robot.},
  title        = {High energy density picoliter-scale zinc-air microbatteries for colloidal robotics},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). Robot behavior that can adapt to user interaction.
<em>SROB</em>, <em>9</em>(92), eadr9645. (<a
href="https://doi.org/10.1126/scirobotics.adr9645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neuroendocrine system responds to interaction with users and modulates robot behavior.},
  archive      = {J_SROB},
  author       = {Melisa Yashinski},
  doi          = {10.1126/scirobotics.adr9645},
  journal      = {Science Robotics},
  month        = {7},
  number       = {92},
  pages        = {eadr9645},
  shortjournal = {Sci. Robot.},
  title        = {Robot behavior that can adapt to user interaction},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024j). Web-based distributed robot localization. <em>SROB</em>,
<em>9</em>(92), eadr8263. (<a
href="https://doi.org/10.1126/scirobotics.adr8263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web-based strategy enables robots to communicate estimated locations among robot peers.},
  archive      = {J_SROB},
  author       = {Amos Matsiko},
  doi          = {10.1126/scirobotics.adr8263},
  journal      = {Science Robotics},
  month        = {7},
  number       = {92},
  pages        = {eadr8263},
  shortjournal = {Sci. Robot.},
  title        = {Web-based distributed robot localization},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Erratum for the research article “excitation of natural
spinal reflex loops in the sensory-motor control of hand prostheses” by
p. G. Sagastegui alva et al. <em>SROB</em>, <em>9</em>(92), eadr7180.
(<a href="https://doi.org/10.1126/scirobotics.adr7180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SROB},
  doi          = {10.1126/scirobotics.adr7180},
  journal      = {Science Robotics},
  month        = {7},
  number       = {92},
  pages        = {eadr7180},
  shortjournal = {Sci. Robot.},
  title        = {Erratum for the research article “Excitation of natural spinal reflex loops in the sensory-motor control of hand prostheses” by p. g. sagastegui alva et al.},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024k). Would robots really bother with a bloody uprising?
<em>SROB</em>, <em>9</em>(92), eadr2950. (<a
href="https://doi.org/10.1126/scirobotics.adr2950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the amusing 1982 novel Software , robots punish their human overlords by raising prices on longevity drugs and organ transplants.},
  archive      = {J_SROB},
  author       = {Robin R. Murphy},
  doi          = {10.1126/scirobotics.adr2950},
  journal      = {Science Robotics},
  month        = {7},
  number       = {92},
  pages        = {eadr2950},
  shortjournal = {Sci. Robot.},
  title        = {Would robots really bother with a bloody uprising?},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Virus-blocking mosquitoes take flight in the fight against
dengue. <em>SROB</em>, <em>9</em>(92), eadr0224. (<a
href="https://doi.org/10.1126/scirobotics.adr0224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drone-based mosquito releases facilitate the introduction of dengue-blocking bacteria in wild mosquito populations.},
  archive      = {J_SROB},
  author       = {Jacob E. Crawford},
  doi          = {10.1126/scirobotics.adr0224},
  journal      = {Science Robotics},
  month        = {7},
  number       = {92},
  pages        = {eadr0224},
  shortjournal = {Sci. Robot.},
  title        = {Virus-blocking mosquitoes take flight in the fight against dengue},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scale-inspired programmable robotic structures with
concurrent shape morphing and stiffness variation. <em>SROB</em>,
<em>9</em>(92), eadl0307. (<a
href="https://doi.org/10.1126/scirobotics.adl0307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Animals and plants have the ability to respond dynamically to their environments depending on the requirements for a specific task. Chen et al. have taken inspiration from the scales of pangolins to develop a soft robotic layered structure with capabilities of shape morphing and stiffness variability. The scale-inspired layered structure (SAILS) relies on negative pressure and a high frequency of actuation to morph into shapes and stiffnesses of interest. They demonstrate the potential of SAILS in the form of an amphibious robot capable of swimming and crawling, as well as a drone landing gear capable of varying its stiffness to minimize the impact of landing. —Amos Matsiko Biological organisms often have remarkable multifunctionality through intricate structures, such as concurrent shape morphing and stiffness variation in the octopus. Soft robots, which are inspired by natural creatures, usually require the integration of separate modules to achieve these various functions. As a result, the whole structure is cumbersome, and the control system is complex, often involving multiple control loops to finish a required task. Here, inspired by the scales that cover creatures like pangolins and fish, we developed a robotic structure that can vary its stiffness and change shape simultaneously in a highly integrated, compact body. The scale-inspired layered structure (SAILS) was enabled by the inversely designed programmable surface patterns of the scales. After fabrication, SAILS was inherently soft and flexible. When sealed in an elastic envelope and subjected to negative confining pressure, it transitioned to its designated shape and concurrently became stiff. SAILS could be actuated at frequencies as high as 5 hertz and achieved an apparent bending modulus change of up to 53 times between its soft and stiff states. We further demonstrated both the versatility of SAILS by developing a soft robot that is amphibious and adaptive and tunable landing systems for drones with the capacity to accommodate different loads.},
  archive      = {J_SROB},
  author       = {Tianyu Chen and Xudong Yang and Bojian Zhang and Junwei Li and Jie Pan and Yifan Wang},
  doi          = {10.1126/scirobotics.adl0307},
  journal      = {Science Robotics},
  month        = {7},
  number       = {92},
  pages        = {eadl0307},
  shortjournal = {Sci. Robot.},
  title        = {Scale-inspired programmable robotic structures with concurrent shape morphing and stiffness variation},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal soft valve enables physical responsiveness for
preemptive resilience of soft robots. <em>SROB</em>, <em>9</em>(92),
eadk9978. (<a
href="https://doi.org/10.1126/scirobotics.adk9978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fluidic soft robots are vulnerable to failure from overpressurization and damage that leads to sudden loss of pressurization. To give these robots more resilience and extend their lifetimes, Pontin and Damian developed a multimodal pneumatic soft valve designed to isolate damage and avoid catastrophic failure. The valve passively reacts to pressure differences triggered by faults. In the forward operating mode, the valve can detect a burst and autonomously isolate the damaged section, maintaining pressure in the other parts of the robot. In the reverse operating mode, the valve can detect overpressurization and release air to prevent irreversible damage. The valve capabilities were demonstrated in a five-finger soft gripper, a two-finger soft hand, and a soft crawler that remained operational after damage. —Melisa Yashinski Resilience is crucial for the self-preservation of biological systems: Humans recover from wounds thanks to an immune system that autonomously enacts a multistage response to promote healing. Similar passive mechanisms can enable pneumatic soft robots to overcome common faults such as bursts originating from punctures or overpressurization. Recent technological advancements, ranging from fault-tolerant controllers for robot reconfigurability to self-healing materials, have paved the way for robot resilience. However, these techniques require powerful processors and large datasets or external hardware. How to extend the operational life span of damaged soft robots with minimal computational and physical resources remains unclear. In this study, we demonstrated a multimodal pneumatic soft valve capable of passive resilient reactions, triggered by faults, to prevent or isolate damage in soft robots. In its forward operation mode, the valve, requiring a single supply pressure, isolated punctured soft inflatable elements from the rest of the soft robot in as fast as 21 milliseconds. In its reverse operation mode, the valve can passively protect robots against overpressurization caused by external disturbances, avoiding plastic deformations and bursts. Furthermore, the two modes combined enabled the creation of an endogenously controlled valve capable of autonomous burst isolation. We demonstrated the passive and quick response and the possibility of monolithic integration of the soft valve in grippers and crawling robots. The approach proposed in this study provides a distributed small-footprint alternative to controller-based resilience and is expected to help soft robots achieve uninterrupted long-lasting operation.},
  archive      = {J_SROB},
  author       = {Marco Pontin and Dana D. Damian},
  doi          = {10.1126/scirobotics.adk9978},
  journal      = {Science Robotics},
  month        = {7},
  number       = {92},
  pages        = {eadk9978},
  shortjournal = {Sci. Robot.},
  title        = {Multimodal soft valve enables physical responsiveness for preemptive resilience of soft robots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Field deployment of wolbachia-infected aedes aegypti using
uncrewed aerial vehicle. <em>SROB</em>, <em>9</em>(92), eadk7913. (<a
href="https://doi.org/10.1126/scirobotics.adk7913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The World Mosquito Program recently developed a technique to control dengue transmission by releasing Wolbachia -infected Aedes aegypti mosquitoes. Wolbachia bacteria act as a virus-blocking agent and are maternally transmitted to the local mosquito populations. However, scaling ground-based releases to large geographic areas poses a challenge. To address this, Lin et al . developed an automated mosquito dosing release system and incorporated it into an uncrewed aerial vehicle (UAV). This system, which includes temperature and humidity control, is designed to release 150 mosquitos per dose. Two successful field trials in Fiji demonstrated that the UAV-based release achieved similar uniformity to ground release methods and successfully established Wolbachia infections in the native population over a 2-km 2 area. —Melisa Yashinski Over the past 50 years, there has been a marked increase in diseases like dengue fever, chikungunya, and Zika. The World Mosquito Program (WMP) has developed an approach that, instead of attempting to eliminate vector species, introduces Wolbachia into native Aedes aegypti populations through the release of Wolbachia -infected mosquitoes. Using this approach, a randomized controlled study recently demonstrated a 77% reduction in dengue across a treatment area within Yogyakarta, Indonesia. Existing release methods use the ground-based release of mosquito eggs or adults that are labor-intensive, are logistically challenging to scale up, and can be restrictive in areas where staff safety is a concern. To overcome these limitations, we developed a fully automated mosquito dosing release system that released smaller cohorts of mosquitoes over a wide area and integrated it into an uncrewed aerial vehicle. We established the effectiveness of this system using an aerial mark, release, and recapture approach. We then demonstrated that using only the aerial release method, we can establish Wolbachia infection in a naive Ae. aegypti population. In both cases, the use of aerial releases demonstrated comparable outcomes to ground-based releases without the required labor or risk. These two trials demonstrated the feasibility of using an aerial release approach for large-scale mosquito releases.},
  archive      = {J_SROB},
  author       = {Ya-Hsun Lin and Dirk Albert Joubert and Sebastian Kaeser and Cameron Dowd and Jurg Germann and Anam Khalid and Jai Andrew Denton and Kate Retski and Aminiasi Tavui and Cameron Paul Simmons and Scott Leslie O’Neill and Jeremie Roger Lionel Gilles},
  doi          = {10.1126/scirobotics.adk7913},
  journal      = {Science Robotics},
  month        = {7},
  number       = {92},
  pages        = {eadk7913},
  shortjournal = {Sci. Robot.},
  title        = {Field deployment of wolbachia-infected aedes aegypti using uncrewed aerial vehicle},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bilateral back extensor exosuit for multidimensional
assistance and prevention of spinal injuries. <em>SROB</em>,
<em>9</em>(92), eadk6717. (<a
href="https://doi.org/10.1126/scirobotics.adk6717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Repetitive tasks involving lifting of objects such as in industrial settings can cause injuries to the spine and back muscles. Although wearable exoskeleton suits can be used in these settings to alleviate risks to injury, they may not provide multidimensional movement during asymmetric lifting. Kim et al. have developed an active Bilateral Back Extensor Exosuit capable of multidimensional force assistance during lifting tasks. The wearable device offers multiple degrees of freedom in range of motion and was shown to provide back muscle force assistance and to decrease compression on the spines of human participants during asymmetric and symmetric lifting tasks. —Amos Matsiko Lumbar spine injuries resulting from heavy or repetitive lifting remain a prevalent concern in workplaces. Back-support devices have been developed to mitigate these injuries by aiding workers during lifting tasks. However, existing devices often fall short in providing multidimensional force assistance for asymmetric lifting, an essential feature for practical workplace use. In addition, validation of device safety across the entire human spine has been lacking. This paper introduces the Bilateral Back Extensor Exosuit (BBEX), a robotic back-support device designed to address both functionality and safety concerns. The design of the BBEX draws inspiration from the anatomical characteristics of the human spine and back extensor muscles. Using a multi–degree-of-freedom architecture and serially connected linear actuators, the device’s components are strategically arranged to closely mimic the biomechanics of the human spine and back extensor muscles. To establish the efficacy and safety of the BBEX, a series of experiments with human participants was conducted. Eleven healthy male participants engaged in symmetric and asymmetric lifting tasks while wearing the BBEX. The results confirm the ability of the BBEX to provide effective multidimensional force assistance. Moreover, comprehensive safety validation was achieved through analyses of muscle fatigue in the upper and the lower erector spinae muscles, as well as mechanical loading on spinal joints during both lifting scenarios. By seamlessly integrating functionality inspired by human biomechanics with a focus on safety, this study offers a promising solution to address the persistent challenge of preventing lumbar spine injuries in demanding work environments.},
  archive      = {J_SROB},
  author       = {Jae In Kim and Jaeyoun Choi and Junhyung Kim and Junkyung Song and Jaebum Park and Yong-Lae Park},
  doi          = {10.1126/scirobotics.adk6717},
  journal      = {Science Robotics},
  month        = {7},
  number       = {92},
  pages        = {eadk6717},
  shortjournal = {Sci. Robot.},
  title        = {Bilateral back extensor exosuit for multidimensional assistance and prevention of spinal injuries},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Merging sociality and robotics through an evolutionary
perspective. <em>SROB</em>, <em>9</em>(92), eadk6664. (<a
href="https://doi.org/10.1126/scirobotics.adk6664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotics, using social mechanisms like hormonal modulation, may accelerate our understanding of core sociality principles.},
  archive      = {J_SROB},
  author       = {Fabiola Diana and Lola Cañamero and Ruud Hortensius and Mariska E. Kret},
  doi          = {10.1126/scirobotics.adk6664},
  journal      = {Science Robotics},
  month        = {7},
  number       = {92},
  pages        = {eadk6664},
  shortjournal = {Sci. Robot.},
  title        = {Merging sociality and robotics through an evolutionary perspective},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Crawling, climbing, perching, and flying by FiBa soft
robots. <em>SROB</em>, <em>9</em>(92), eadk4533. (<a
href="https://doi.org/10.1126/scirobotics.adk4533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many soft robots rely on external electrical or pneumatic power sources accompanied by a physical cumbersome tether limiting the robots’ range. To achieve untethered operation, Ching et al . combined a three-dimensionally printed pneumatic balloon and a curved polymer film to form a soft actuator termed film-balloon, or FiBa, actuator. These bending actuators are substantially lighter than other pneumatic actuators and can be combined with onboard pneumatic pumps, batteries, and controllers for untethered operation. The versatility of these actuators is demonstrated in various biomimetic robot designs that can crawl, climb, perch, and fly. Untethered robots capable of complex modes of locomotion could prove useful in remote operations such as rescue missions and space exploration. —Melisa Yashinski This paper introduces an approach to fabricating lightweight, untethered soft robots capable of diverse biomimetic locomotion. Untethering soft robotics from electrical or pneumatic power remains one of the prominent challenges within the field. The development of functional untethered soft robotic systems hinges heavily on mitigating their weight; however, the conventional weight of pneumatic network actuators (pneu-nets) in soft robots has hindered untethered operations. To address this challenge, we developed film-balloon (FiBa) modules that drastically reduced the weight of soft actuators. FiBa modules combine transversely curved polymer thin films and three-dimensionally printed pneumatic balloons to achieve varied locomotion modes. These lightweight FiBa modules serve as building blocks to create untethered soft robots mimicking natural movement strategies. These modules substantially reduce overall robot weight, allowing the integration of components such as pumps, valves, batteries, and control boards, thereby enabling untethered operation. FiBa modules integrated with electronic components demonstrated four bioinspired modes of locomotion, including turtle-inspired crawling, inchworm-inspired climbing, bat-inspired perching, and ladybug-inspired flying. Overall, our study offers an alternative tool for designing and customizing lightweight, untethered soft robots with advanced functionalities. The reduction of the weight of soft robots enabled by our approach opens doors to a wide range of applications, including disaster relief, space exploration, remote sensing, and search and rescue operations, where lightweight, untethered soft robotic systems are essential.},
  archive      = {J_SROB},
  author       = {Terry Ching and Joseph Zhi Wei Lee and Shane Kyi Hla Win and Luke Soe Thura Win and Danial Sufiyan and Charlotte Pei Xuan Lim and Nidhi Nagaraju and Yi-Chin Toh and Shaohui Foong and Michinao Hashimoto},
  doi          = {10.1126/scirobotics.adk4533},
  journal      = {Science Robotics},
  month        = {7},
  number       = {92},
  pages        = {eadk4533},
  shortjournal = {Sci. Robot.},
  title        = {Crawling, climbing, perching, and flying by FiBa soft robots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visual route following for tiny autonomous robots.
<em>SROB</em>, <em>9</em>(92), eadk0310. (<a
href="https://doi.org/10.1126/scirobotics.adk0310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For navigation, robots often rely either on external infrastructure or on mapping-based navigation algorithms that are generally associated with high computational demands. van Dijk et al . have now developed an insect-inspired approach for visual navigation of resource-constrained miniature drones by exploiting both visual homing and odometry. The framework was tested on a 56-g drone, which was shown to be capable of following routes in indoor environments over long distances with minimal memory requirements. This approach could substantially improve the autonomous navigation of aerial robots with constraints in computational power, energy demands, and weight. —Amos Matsiko Navigation is an essential capability for autonomous robots. In particular, visual navigation has been a major research topic in robotics because cameras are lightweight, power-efficient sensors that provide rich information on the environment. However, the main challenge of visual navigation is that it requires substantial computational power and memory for visual processing and storage of the results. As of yet, this has precluded its use on small, extremely resource-constrained robots such as lightweight drones. Inspired by the parsimony of natural intelligence, we propose an insect-inspired approach toward visual navigation that is specifically aimed at extremely resource-restricted robots. It is a route-following approach in which a robot’s outbound trajectory is stored as a collection of highly compressed panoramic images together with their spatial relationships as measured with odometry. During the inbound journey, the robot uses a combination of odometry and visual homing to return to the stored locations, with visual homing preventing the buildup of odometric drift. A main advancement of the proposed strategy is that the number of stored compressed images is minimized by spacing them apart as far as the accuracy of odometry allows. To demonstrate the suitability for small systems, we implemented the strategy on a tiny 56-gram drone. The drone could successfully follow routes up to 100 meters with a trajectory representation that consumed less than 20 bytes per meter. The presented method forms a substantial step toward the autonomous visual navigation of tiny robots, facilitating their more widespread application.},
  archive      = {J_SROB},
  author       = {Tom van Dijk and Christophe De Wagter and Guido C. H. E. de Croon},
  doi          = {10.1126/scirobotics.adk0310},
  journal      = {Science Robotics},
  month        = {7},
  number       = {92},
  pages        = {eadk0310},
  shortjournal = {Sci. Robot.},
  title        = {Visual route following for tiny autonomous robots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Upscaling the production of sterile male mosquitoes with an
automated pupa sex sorter. <em>SROB</em>, <em>9</em>(92), eadj6261. (<a
href="https://doi.org/10.1126/scirobotics.adj6261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several techniques have been developed to fight mosquito-borne diseases, including the release of sterile or incompatible male mosquitoes into the wild to reduce population growth. However, sorting mosquitoes by sex is a laborious process. Gong et al. have now developed an automated mosquito pupa sex sorter, which was tested on three mosquito species and shown to increase the production of males 17-fold when compared with a manual separation process. A field trial in Guangzhou, China showed that the process was capable of producing sufficient incompatible males without reducing their quality, which led to the suppression of wild populations of mosquitoes. —Amos Matsiko Effective mosquito population suppression has been repeatedly demonstrated in field trials through the release of male mosquitoes to induce sterile mating with wild females using the incompatible insect technique (IIT), the sterile insect technique (SIT), or their combination. However, upscaling these techniques requires a highly efficient and scalable approach for the sex separation of mass-reared mosquitoes to minimize the unintentional release of females, which can lead to either population replacement or biting nuisance, a major bottleneck up to now. Here, we report the successful development of an automated mosquito pupa sex sorter that can effectively separate large numbers of males from females for population suppression of Aedes aegypti , A. albopictus , and Culex quinquefasciatus . The male production capacity of the automated sex sorter was increased by ~17-fold compared with manual sex separation with the Fay-Morlan sorter and enabled one person to separate 16 million males per week. With ~0.5% female contamination, the produced males exhibited high flight ability and mating performance. The field trial demonstrates that the quality of A. albopictus males produced using the automated sex sorter is suitable for inducing population suppression. These results indicate that the automated sex sorter offers the potential to upscale IIT and SIT against mosquito vectors for disease control.},
  archive      = {J_SROB},
  author       = {Jun-Tao Gong and Wadaka Mamai and Xiaohua Wang and Jian Zhu and Yongjun Li and Julian Liu and Qixian Tang and Yuanhui Huang and Jixin Zhang and Jiayi Zhou and Hamidou Maiga and Nanwintoum Séverin Bimbilé Somda and Claudia Martina and Simran Singh Kotla and Thomas Wallner and Jérémy Bouyer and Zhiyong Xi},
  doi          = {10.1126/scirobotics.adj6261},
  journal      = {Science Robotics},
  month        = {7},
  number       = {92},
  pages        = {eadj6261},
  shortjournal = {Sci. Robot.},
  title        = {Upscaling the production of sterile male mosquitoes with an automated pupa sex sorter},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Erratum for the research article “fully neuromorphic vision
and control for autonomous drone flight” by f. Paredes-vallés et
al. <em>SROB</em>, <em>9</em>(91), eadr0223. (<a
href="https://doi.org/10.1126/scirobotics.adr0223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SROB},
  doi          = {10.1126/scirobotics.adr0223},
  journal      = {Science Robotics},
  month        = {6},
  number       = {91},
  pages        = {eadr0223},
  shortjournal = {Sci. Robot.},
  title        = {Erratum for the research article “Fully neuromorphic vision and control for autonomous drone flight” by f. paredes-vallés et al.},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ironies of social robotics. <em>SROB</em>, <em>9</em>(91),
eadq6387. (<a
href="https://doi.org/10.1126/scirobotics.adq6387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming for “humanlike” or “natural” interactions can make social robots and their limitations more difficult to understand.},
  archive      = {J_SROB},
  author       = {Tom Ziemke},
  doi          = {10.1126/scirobotics.adq6387},
  journal      = {Science Robotics},
  month        = {6},
  number       = {91},
  pages        = {eadq6387},
  shortjournal = {Sci. Robot.},
  title        = {Ironies of social robotics},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024l). Would you risk humanity’s survival on a robot built in two
years? <em>SROB</em>, <em>9</em>(91), eadq6361. (<a
href="https://doi.org/10.1126/scirobotics.adq6361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Project Hail Mary reflects real-world technical readiness assessment processes for robotics.},
  archive      = {J_SROB},
  author       = {Robin R. Murphy},
  doi          = {10.1126/scirobotics.adq6361},
  journal      = {Science Robotics},
  month        = {6},
  number       = {91},
  pages        = {eadq6361},
  shortjournal = {Sci. Robot.},
  title        = {Would you risk humanity’s survival on a robot built in two years?},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The future lies in a pair of tactile hands. <em>SROB</em>,
<em>9</em>(91), eadq1501. (<a
href="https://doi.org/10.1126/scirobotics.adq1501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancing robot hand dexterity with optical tactile sensing raises questions about humanoid robotics.},
  archive      = {J_SROB},
  author       = {Nathan F. Lepora},
  doi          = {10.1126/scirobotics.adq1501},
  journal      = {Science Robotics},
  month        = {6},
  number       = {91},
  pages        = {eadq1501},
  shortjournal = {Sci. Robot.},
  title        = {The future lies in a pair of tactile hands},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Biohybrid microrobots regulate colonic cytokines and the
epithelium barrier in inflammatory bowel disease. <em>SROB</em>,
<em>9</em>(91), eadl2007. (<a
href="https://doi.org/10.1126/scirobotics.adl2007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regulating cytokine activity can effectively manage inflammatory bowel disease, but traditional treatments are immunosuppressant or only target specific cytokines. By combining the robust motion of green algae with the binding abilities of macrophage membrane–coated nanoparticles, Li et al. developed a biohybrid microrobot that captured and removed a range of proinflammatory cytokines in vitro. The algae-based robots were encapsulated for protective passage through the stomach and administered to mice. In vivo studies confirmed biosafety and successful prevention and treatment of inflammatory bowel disease in a mouse model. The algae-based robots also hold potential for treatment of other cytokine-related disorders. —Melisa Yashinski Cytokines have been identified as key contributors to the development of inflammatory bowel disease (IBD), yet conventional treatments often prove inadequate and carry substantial side effects. Here, we present an innovative biohybrid robotic system, termed “algae-MΦNP-robot,” for addressing IBD by actively neutralizing colonic cytokine levels. Our approach combines moving green microalgae with macrophage membrane–coated nanoparticles (MΦNPs) to efficiently capture proinflammatory cytokines “on the fly.” The dynamic algae-MΦNP-robots outperformed static counterparts by enhancing cytokine removal through continuous movement, better distribution, and extended retention in the colon. This system is encapsulated in an oral capsule, which shields it from gastric acidity and ensures functionality upon reaching the targeted disease site. The resulting algae-MΦNP-robot capsule effectively regulated cytokine levels, facilitating the healing of damaged epithelial barriers. It showed markedly improved prevention and treatment efficacy in a mouse model of IBD and demonstrated an excellent biosafety profile. Overall, our biohybrid algae-MΦNP-robot system offers a promising and efficient solution for IBD, addressing cytokine-related inflammation effectively.},
  archive      = {J_SROB},
  author       = {Zhengxing Li and Yaou Duan and Fangyu Zhang and Hao Luan and Wei-Ting Shen and Yiyan Yu and Nianfei Xian and Zhongyuan Guo and Edward Zhang and Lu Yin and Ronnie H. Fang and Weiwei Gao and Liangfang Zhang and Joseph Wang},
  doi          = {10.1126/scirobotics.adl2007},
  journal      = {Science Robotics},
  month        = {6},
  number       = {91},
  pages        = {eadl2007},
  shortjournal = {Sci. Robot.},
  title        = {Biohybrid microrobots regulate colonic cytokines and the epithelium barrier in inflammatory bowel disease},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The role of low-cost robots in the future of spaceflight.
<em>SROB</em>, <em>9</em>(91), eadl1995. (<a
href="https://doi.org/10.1126/scirobotics.adl1995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lessons from the CubeSat and Mars Exploration programs may guide the infusion of robotics for planetary science and exploration.},
  archive      = {J_SROB},
  author       = {Paul E. Glick and J. Bob Balaram and Michael R. Davidson and Elizabeth Lyons and Michael T. Tolley},
  doi          = {10.1126/scirobotics.adl1995},
  journal      = {Science Robotics},
  month        = {6},
  number       = {91},
  pages        = {eadl1995},
  shortjournal = {Sci. Robot.},
  title        = {The role of low-cost robots in the future of spaceflight},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conductive block copolymer elastomers and psychophysical
thresholding for accurate haptic effects. <em>SROB</em>, <em>9</em>(91),
eadk3925. (<a
href="https://doi.org/10.1126/scirobotics.adk3925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most haptic devices rely on mechanical actuators to stimulate the skin but are limited in range. Alternatively, electrical stimulation of mechanosensory neurons can be perceived as a mechanical force but often requires high currents and leads to unwanted effects, such as pain. Blau et al . developed an electrotactile device made from a conductive block copolymer in a serpentine shape that exhibited microscopic conformability with the skin. When tested on human participants, the device provided stimulation at very low currents and could toggle between pressure and vibration by changing the signal frequency. Safe and reliable electrotactile stimulation is a promising development for haptic devices such as human-machine interfaces and prosthetics. —Melisa Yashinski Electrotactile stimulus is a form of sensory substitution in which an electrical signal is perceived as a mechanical sensation. The electrotactile effect could, in principle, recapitulate a range of tactile experience by selective activation of nerve endings. However, the method has been plagued by inconsistency, galvanic reactions, pain and desensitization, and unwanted stimulation of nontactile nerves. Here, we describe how a soft conductive block copolymer, a stretchable layout, and concentric electrodes, along with psychophysical thresholding, can circumvent these shortcomings. These purpose-designed materials, device layouts, and calibration techniques make it possible to generate accurate and reproducible sensations across a cohort of 10 human participants and to do so at ultralow currents (≥6 microamperes) without pain or desensitization. This material, form factor, and psychophysical approach could be useful for haptic devices and as a tool for activation of the peripheral nervous system.},
  archive      = {J_SROB},
  author       = {Rachel Blau and Abdulhameed Abdal and Nicholas Root and Alexander X. Chen and Tarek Rafeedi and Robert Ramji and Yi Qie and Taewoo Kim and Anthony Navarro and Jason Chin and Laura L. Becerra and Samuel J. Edmunds and Samantha M. Russman and Shadi A. Dayeh and David P. Fenning and Romke Rouw and Darren J. Lipomi},
  doi          = {10.1126/scirobotics.adk3925},
  journal      = {Science Robotics},
  month        = {6},
  number       = {91},
  pages        = {eadk3925},
  shortjournal = {Sci. Robot.},
  title        = {Conductive block copolymer elastomers and psychophysical thresholding for accurate haptic effects},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Soft robotic platform for progressive and reversible aortic
constriction in a small-animal model. <em>SROB</em>, <em>9</em>(91),
eadj9769. (<a
href="https://doi.org/10.1126/scirobotics.adj9769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the processes involved in heart failure due to cardiac diseases is crucial in the development of effective interventions. However, tunable physical models that can suitably replicate these processes progressively are lacking. Rosalia et al. have now used implantable soft robot actuators to develop a tunable platform that can model progressive and reversible aortic constriction in small animals. With the aid of magnetic resonance imaging, they demonstrated the hemodynamic changes due to pressure overload from aortic banding and debanding, replicating the progression and reversal of cardiac disease. —Amos Matsiko Our understanding of cardiac remodeling processes due to left ventricular pressure overload derives largely from animal models of aortic banding. However, these studies fail to enable control over both disease progression and reversal, hindering their clinical relevance. Here, we describe a method for progressive and reversible aortic banding based on an implantable expandable actuator that can be finely tuned to modulate aortic banding and debanding in a rat model. Through catheterization, imaging, and histologic studies, we demonstrate that our platform can recapitulate the hemodynamic and structural changes associated with pressure overload in a controllable manner. We leveraged soft robotics to enable noninvasive aortic debanding, demonstrating that these changes can be partly reversed because of cessation of the biomechanical stimulus. By recapitulating longitudinal disease progression and reversibility, this animal model could elucidate fundamental mechanisms of cardiac remodeling and optimize timing of intervention for pressure overload.},
  archive      = {J_SROB},
  author       = {Luca Rosalia and Sophie X. Wang and Caglar Ozturk and Wei Huang and Jean Bonnemain and Rachel Beatty and Garry P. Duffy and Christopher T. Nguyen and Ellen T. Roche},
  doi          = {10.1126/scirobotics.adj9769},
  journal      = {Science Robotics},
  month        = {6},
  number       = {91},
  pages        = {eadj9769},
  shortjournal = {Sci. Robot.},
  title        = {Soft robotic platform for progressive and reversible aortic constriction in a small-animal model},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). When performing actions with robots, attribution of
intentionality affects the sense of joint agency. <em>SROB</em>,
<em>9</em>(91), eadj3665. (<a
href="https://doi.org/10.1126/scirobotics.adj3665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sense of joint agency can emerge when humans collaborate to complete tasks. They experience a perception or feeling of shared control over joint actions and their outcomes. Navare et al . investigated whether the sense of joint agency can occur between humans and humanoid robots during collaborative tasks. They used neural and behavioral measures to show that human participants experienced this sense of joint agency, underpinned by mechanisms of joint sensorimotor processing, when a robot was presented as an intentional agent. However, a sense of joint agency was not felt when the robot was presented as a mechanical artifact. —Amos Matsiko Sense of joint agency (SoJA) is the sense of control experienced by humans when acting with others to bring about changes in the shared environment. SoJA is proposed to arise from the sensorimotor predictive processes underlying action control and monitoring. Because SoJA is a ubiquitous phenomenon occurring when we perform actions with other humans, it is of great interest and importance to understand whether—and under what conditions—SoJA occurs in collaborative tasks with humanoid robots. In this study, using behavioral measures and neural responses measured by electroencephalography (EEG), we aimed to evaluate whether SoJA occurs in joint action with the humanoid robot iCub and whether its emergence is influenced by the perceived intentionality of the robot. Behavioral results show that participants experienced SoJA with the robot partner when it was presented as an intentional agent but not when it was presented as a mechanical artifact. EEG results show that the mechanism that influences the emergence of SoJA in the condition when the robot is presented as an intentional agent is the ability to form similarly accurate predictions about the sensory consequences of our own and others’ actions, leading to similar modulatory activity over sensory processing. Together, our results shed light on the joint sensorimotor processing mechanisms underlying the emergence of SoJA in human-robot interaction and underscore the importance of attribution of intentionality to the robot in human-robot collaboration.},
  archive      = {J_SROB},
  author       = {Uma Prashant Navare and Francesca Ciardo and Kyveli Kompatsiari and Davide De Tommaso and Agnieszka Wykowska},
  doi          = {10.1126/scirobotics.adj3665},
  journal      = {Science Robotics},
  month        = {6},
  number       = {91},
  pages        = {eadj3665},
  shortjournal = {Sci. Robot.},
  title        = {When performing actions with robots, attribution of intentionality affects the sense of joint agency},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SimPLE, a visuotactile method learned in simulation to
precisely pick, localize, regrasp, and place objects. <em>SROB</em>,
<em>9</em>(91), eadi8808. (<a
href="https://doi.org/10.1126/scirobotics.adi8808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robotic manipulation, there is often a trade-off between high accuracy for a repetitive motion and reliability in an unstructured environment. To teach a robot to move objects into an organized arrangement, Bauza et al. have developed a framework called SimPLE, which stands for Simulation to Pick, Localize, and placE. Given only a model of the object, the framework generates training data by sampling grasps in simulation. The SimPLE framework was tested with a set of 15 objects of different geometries on a dual-arm robot equipped with tactile sensors and an external depth camera. Using hand-to-hand regrasps, the robot successfully relocated the objects into structured arrangements, demonstrating the possibility of transferring a model learned in simulation to a real robot. —Melisa Yashinski Existing robotic systems have a tension between generality and precision. Deployed solutions for robotic manipulation tend to fall into the paradigm of one robot solving a single task, lacking “precise generalization,” or the ability to solve many tasks without compromising on precision. This paper explores solutions for precise and general pick and place. In precise pick and place, or kitting, the robot transforms an unstructured arrangement of objects into an organized arrangement, which can facilitate further manipulation. We propose SimPLE (Simulation to Pick Localize and placE) as a solution to precise pick and place. SimPLE learns to pick, regrasp, and place objects given the object’s computer-aided design model and no prior experience. We developed three main components: task-aware grasping, visuotactile perception, and regrasp planning. Task-aware grasping computes affordances of grasps that are stable, observable, and favorable to placing. The visuotactile perception model relies on matching real observations against a set of simulated ones through supervised learning to estimate a distribution of likely object poses. Last, we computed a multistep pick-and-place plan by solving a shortest-path problem on a graph of hand-to-hand regrasps. On a dual-arm robot equipped with visuotactile sensing, SimPLE demonstrated pick and place of 15 diverse objects. The objects spanned a wide range of shapes, and SimPLE achieved successful placements into structured arrangements with 1-mm clearance more than 90% of the time for six objects and more than 80% of the time for 11 objects.},
  archive      = {J_SROB},
  author       = {Maria Bauza and Antonia Bronars and Yifan Hou and Ian Taylor and Nikhil Chavan-Dafle and Alberto Rodriguez},
  doi          = {10.1126/scirobotics.adi8808},
  journal      = {Science Robotics},
  month        = {6},
  number       = {91},
  pages        = {eadi8808},
  shortjournal = {Sci. Robot.},
  title        = {SimPLE, a visuotactile method learned in simulation to precisely pick, localize, regrasp, and place objects},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring beyond earth using space robotics. <em>SROB</em>,
<em>9</em>(91), eadi6424. (<a
href="https://doi.org/10.1126/scirobotics.adi6424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic spacecraft enable exploration of our Solar System beyond our human presence. Although spacecraft have explored every planet in the Solar System, the frontiers of space robotics are at the cutting edge of landers, rovers, and now atmospheric explorers, where robotic spacecraft must interact intimately with their environment to explore beyond the reach of flyby and orbital remote sensing. Here, we describe the tremendous growth in space robotics missions in the past 7 years, with many new entities participating in missions to the surface of the Moon, Mars, and beyond. We also describe the recent development of aerial missions to planets and moons, as exemplified by the Ingenuity helicopter on Mars and the Dragonfly mission to Titan. We focus on suborbital robotics—landers, rovers, and aerial vehicles—with associated challenges in sensing, manipulation, mobility, and system-level autonomy.},
  archive      = {J_SROB},
  author       = {Steve A. Chien and Gianfranco Visentin and Connor Basich},
  doi          = {10.1126/scirobotics.adi6424},
  journal      = {Science Robotics},
  month        = {6},
  number       = {91},
  pages        = {eadi6424},
  shortjournal = {Sci. Robot.},
  title        = {Exploring beyond earth using space robotics},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimality principles in spacecraft neural guidance and
control. <em>SROB</em>, <em>9</em>(91), eadi6421. (<a
href="https://doi.org/10.1126/scirobotics.adi6421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This Review discusses the main results obtained in training end-to-end neural architectures for guidance and control of interplanetary transfers, planetary landings, and close-proximity operations, highlighting the successful learning of optimality principles by the underlying neural models. Spacecraft and drones aimed at exploring our solar system are designed to operate in conditions where the smart use of onboard resources is vital to the success or failure of the mission. Sensorimotor actions are thus often derived from high-level, quantifiable, optimality principles assigned to each task, using consolidated tools in optimal control theory. The planned actions are derived on the ground and transferred on board, where controllers have the task of tracking the uploaded guidance profile. Here, we review recent trends based on the use of end-to-end networks, called guidance and control networks (G&amp;CNets), which allow spacecraft to depart from such an architecture and to embrace the onboard computation of optimal actions. In this way, the sensor information is transformed in real time into optimal plans, thus increasing mission autonomy and robustness. We then analyze drone racing as an ideal gym environment to test these architectures on real robotic platforms and thus increase confidence in their use in future space exploration missions. Drone racing not only shares with spacecraft missions both limited onboard computational capabilities and similar control structures induced from the optimality principle sought but also entails different levels of uncertainties and unmodeled effects and a very different dynamical timescale.},
  archive      = {J_SROB},
  author       = {Dario Izzo and Emmanuel Blazquez and Robin Ferede and Sebastien Origer and Christophe De Wagter and Guido C. H. E. de Croon},
  doi          = {10.1126/scirobotics.adi6421},
  journal      = {Science Robotics},
  month        = {6},
  number       = {91},
  pages        = {eadi6421},
  shortjournal = {Sci. Robot.},
  title        = {Optimality principles in spacecraft neural guidance and control},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A portable inflatable soft wearable robot to assist the
shoulder during industrial work. <em>SROB</em>, <em>9</em>(91),
eadi2377. (<a
href="https://doi.org/10.1126/scirobotics.adi2377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Labor-intensive industrial work involving repetitive lifting of arms has been associated with several shoulder injuries. Significant progress has been made in the development of passive exoskeletons that typically use springs to provide assistance, but the assistance level is not easily adaptable to different user motions. Zhou et al . have now developed a portable soft wearable robot to actively assist the shoulder in industrial use cases, showing the potential to reduce muscle activity during drilling and holding tasks in a laboratory setting. Use of the device by workers in an automotive industrial setting was also demonstrated. —Amos Matsiko Repetitive overhead tasks during factory work can cause shoulder injuries resulting in impaired health and productivity loss. Soft wearable upper extremity robots have the potential to be effective injury prevention tools with minimal restrictions using soft materials and active controls. We present the design and evaluation of a portable inflatable shoulder wearable robot for assisting industrial workers during shoulder-elevated tasks. The robot is worn like a shirt with integrated textile pneumatic actuators, inertial measurement units, and a portable actuation unit. It can provide up to 6.6 newton-meters of torque to support the shoulder and cycle assistance on and off at six times per minute. From human participant evaluations during simulated industrial tasks, the robot reduced agonist muscle activities (anterior, middle, and posterior deltoids and biceps brachii) by up to 40% with slight changes in joint angles of less than 7% range of motion while not increasing antagonistic muscle activity (latissimus dorsi) in current sample size. Comparison of controller parameters further highlighted that higher assistance magnitude and earlier assistance timing resulted in statistically significant muscle activity reductions. During a task circuit with dynamic transitions among the tasks, the kinematics-based controller of the robot showed robustness to misinflations (96% true negative rate and 91% true positive rate), indicating minimal disturbances to the user when assistance was not required. A preliminary evaluation of a pressure modulation profile also highlighted a trade-off between user perception and hardware demands. Finally, five automotive factory workers used the robot in a pilot manufacturing area and provided feedback.},
  archive      = {J_SROB},
  author       = {Yu Meng Zhou and Cameron J. Hohimer and Harrison T. Young and Connor M. McCann and David Pont-Esteban and Umut S. Civici and Yichu Jin and Patrick Murphy and Diana Wagner and Tazzy Cole and Nathan Phipps and Haedo Cho and Franchesco Bertacchi and Isabella Pignataro and Tommaso Proietti and Conor J. Walsh},
  doi          = {10.1126/scirobotics.adi2377},
  journal      = {Science Robotics},
  month        = {6},
  number       = {91},
  pages        = {eadi2377},
  shortjournal = {Sci. Robot.},
  title        = {A portable inflatable soft wearable robot to assist the shoulder during industrial work},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024i). What to give your robot mother on mother’s day.
<em>SROB</em>, <em>9</em>(90), eadp8107. (<a
href="https://doi.org/10.1126/scirobotics.adp8107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Jung_E , the 2023 science-fiction movie from South Korea, suggests that a novel leg-wheel hybrid for robot locomotion might be appreciated.},
  archive      = {J_SROB},
  author       = {Robin R. Murphy},
  doi          = {10.1126/scirobotics.adp8107},
  journal      = {Science Robotics},
  month        = {5},
  number       = {90},
  pages        = {eadp8107},
  shortjournal = {Sci. Robot.},
  title        = {What to give your robot mother on mother’s day},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Avian eye–inspired artificial vision takes a step forward.
<em>SROB</em>, <em>9</em>(90), eadp5682. (<a
href="https://doi.org/10.1126/scirobotics.adp5682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bioinspiration from avian eyes allows development of artificial vision systems with foveated and multispectral imaging.},
  archive      = {J_SROB},
  author       = {Qing Liu and Yihui Zhang},
  doi          = {10.1126/scirobotics.adp5682},
  journal      = {Science Robotics},
  month        = {5},
  number       = {90},
  pages        = {eadp5682},
  shortjournal = {Sci. Robot.},
  title        = {Avian eye–inspired artificial vision takes a step forward},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A guiding light for stimulating paralyzed muscles.
<em>SROB</em>, <em>9</em>(90), eado9987. (<a
href="https://doi.org/10.1126/scirobotics.ado9987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the performance of closed-loop optogenetic nerve stimulation can reproduce desired muscle activation patterns.},
  archive      = {J_SROB},
  author       = {Jordan Williams},
  doi          = {10.1126/scirobotics.ado9987},
  journal      = {Science Robotics},
  month        = {5},
  number       = {90},
  pages        = {eado9987},
  shortjournal = {Sci. Robot.},
  title        = {A guiding light for stimulating paralyzed muscles},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stereoscopic artificial compound eyes for spatiotemporal
perception in three-dimensional space. <em>SROB</em>, <em>9</em>(90),
eadl3606. (<a
href="https://doi.org/10.1126/scirobotics.adl3606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The praying mantis has an overlap in its field of view between its left and right eyes that generates binocular vision and is capable of depth perception through stereopsis. Inspired by the praying mantis, Bae et al. have developed artificial compound eyes with stereoscopic vision for spatiotemporal perception in three-dimensional space using edge computing. They adopted federated split learning to process information from both the left and right artificial eyes and showed that the system was capable of tracking object movement at a rapid temporal processing rate. —Amos Matsiko Arthropods’ eyes are effective biological vision systems for object tracking and wide field of view because of their structural uniqueness; however, unlike mammalian eyes, they can hardly acquire the depth information of a static object because of their monocular cues. Therefore, most arthropods rely on motion parallax to track the object in three-dimensional (3D) space. Uniquely, the praying mantis (Mantodea) uses both compound structured eyes and a form of stereopsis and is capable of achieving object recognition in 3D space. Here, by mimicking the vision system of the praying mantis using stereoscopically coupled artificial compound eyes, we demonstrated spatiotemporal object sensing and tracking in 3D space with a wide field of view. Furthermore, to achieve a fast response with minimal latency, data storage/transportation, and power consumption, we processed the visual information at the edge of the system using a synaptic device and a federated split learning algorithm. The designed and fabricated stereoscopic artificial compound eye provides energy-efficient and accurate spatiotemporal object sensing and optical flow tracking. It exhibits a root mean square error of 0.3 centimeter, consuming only approximately 4 millijoules for sensing and tracking. These results are more than 400 times lower than conventional complementary metal-oxide semiconductor–based imaging systems. Our biomimetic imager shows the potential of integrating nature’s unique design using hardware and software codesigned technology toward capabilities of edge computing and sensing.},
  archive      = {J_SROB},
  author       = {Byungjoon Bae and Doeon Lee and Minseong Park and Yujia Mu and Yongmin Baek and Inbo Sim and Cong Shen and Kyusang Lee},
  doi          = {10.1126/scirobotics.adl3606},
  journal      = {Science Robotics},
  month        = {5},
  number       = {90},
  pages        = {eadl3606},
  shortjournal = {Sci. Robot.},
  title        = {Stereoscopic artificial compound eyes for spatiotemporal perception in three-dimensional space},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Excitation of natural spinal reflex loops in the
sensory-motor control of hand prostheses. <em>SROB</em>, <em>9</em>(90),
eadl0085. (<a
href="https://doi.org/10.1126/scirobotics.adl0085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Restoring sensory feedback in amputees is necessary to improve prosthesis control, but several noninvasive techniques to achieve this are cognitively demanding. Sagastegui Alva et al . developed a closed-loop feedback approach to aid prosthesis control by stimulating spinal motor neurons through mechanical vibration of tendons. The system was tested with trans-radial amputees and showed the ability to improve functional motor skills, including grasping dexterity, with a prosthesis device. The study demonstrates the potential of using both voluntary and involuntary action with natural feedback loops to control prostheses. —Amos Matsiko Sensory feedback for prosthesis control is typically based on encoding sensory information in specific types of sensory stimuli that the users interpret to adjust the control of the prosthesis. However, in physiological conditions, the afferent feedback received from peripheral nerves is not only processed consciously but also modulates spinal reflex loops that contribute to the neural information driving muscles. Spinal pathways are relevant for sensory-motor integration, but they are commonly not leveraged for prosthesis control. We propose an approach to improve sensory-motor integration for prosthesis control based on modulating the excitability of spinal circuits through the vibration of tendons in a closed loop with muscle activity. We measured muscle signals in healthy participants and amputees during different motor tasks, and we closed the loop by applying vibration on tendons connected to the muscles, which modulated the excitability of motor neurons. The control signals to the prosthesis were thus the combination of voluntary control and additional spinal reflex inputs induced by tendon vibration. Results showed that closed-loop tendon vibration was able to modulate the neural drive to the muscles. When closed-loop tendon vibration was used, participants could achieve similar or better control performance in interfaces using muscle activation than without stimulation. Stimulation could even improve prosthetic grasping in amputees. Overall, our results indicate that closed-loop tendon vibration can integrate spinal reflex pathways in the myocontrol system and open the possibility of incorporating natural feedback loops in prosthesis control.},
  archive      = {J_SROB},
  author       = {Patrick G. Sagastegui Alva and Anna Boesendorfer and Oskar C. Aszmann and Jaime Ibáñez and Dario Farina},
  doi          = {10.1126/scirobotics.adl0085},
  journal      = {Science Robotics},
  month        = {5},
  number       = {90},
  pages        = {eadl0085},
  shortjournal = {Sci. Robot.},
  title        = {Excitation of natural spinal reflex loops in the sensory-motor control of hand prostheses},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Avian eye–inspired perovskite artificial vision system for
foveated and multispectral imaging. <em>SROB</em>, <em>9</em>(90),
eadk6903. (<a
href="https://doi.org/10.1126/scirobotics.adk6903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The eyes of certain bird species contain deep central foveae that can magnify a target object for motion tracking as well as four cone types corresponding to red, green, blue (RGB), and ultraviolet (UV) light. Inspired by these avian eyes, Park et al. developed an artificial vision system for foveated and multispectral imaging. The system was composed of an artificial Gaussian-shaped fovea that could magnify and focus an object similarly to a zoom lens and a vertically stacked perovskite photodetector array that could detect R, G, B, and UV light without filters. This vision system is particularly promising in uncrewed aerial vehicles for detecting target objects and their motion. —Melisa Yashinski Avian eyes have deep central foveae as a result of extensive evolution. Deep foveae efficiently refract incident light, creating a magnified image of the target object and making it easier to track object motion. These features are essential for detecting and tracking remote objects in dynamic environments. Furthermore, avian eyes respond to a wide spectrum of light, including visible and ultraviolet light, allowing them to efficiently distinguish the target object from complex backgrounds. Despite notable advances in artificial vision systems that mimic animal vision, the exceptional object detection and targeting capabilities of avian eyes via foveated and multispectral imaging remain underexplored. Here, we present an artificial vision system that capitalizes on these aspects of avian vision. We introduce an artificial fovea and vertically stacked perovskite photodetector arrays whose designs were optimized by theoretical simulations for the demonstration of foveated and multispectral imaging. The artificial vision system successfully identifies colored and mixed-color objects and detects remote objects through foveated imaging. The potential for use in uncrewed aerial vehicles that need to detect, track, and recognize distant targets in dynamic environments is also discussed. Our avian eye–inspired perovskite artificial vision system marks a notable advance in bioinspired artificial visions.},
  archive      = {J_SROB},
  author       = {Jinhong Park and Min Seok Kim and Joonsoo Kim and Sehui Chang and Mincheol Lee and Gil Ju Lee and Young Min Song and Dae-Hyeong Kim},
  doi          = {10.1126/scirobotics.adk6903},
  journal      = {Science Robotics},
  month        = {5},
  number       = {90},
  pages        = {eadk6903},
  shortjournal = {Sci. Robot.},
  title        = {Avian eye–inspired perovskite artificial vision system for foveated and multispectral imaging},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluating initial usability of a hand augmentation device
across a large and diverse sample. <em>SROB</em>, <em>9</em>(90),
eadk5183. (<a
href="https://doi.org/10.1126/scirobotics.adk5183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is often the case that diverse populations are not considered during the development of motor augmentation technology. To ensure inclusive wearability, Clode et al. explored the usability of a 3D-printed hand augmentation device called the Third Thumb across a range of demographics at the Royal Society Summer Science Exhibition. Of 596 participants, 98% were able to successfully wear, operate, and perform a task with the Third Thumb. To assess usability, participants were asked to complete one of two tasks that involved moving pegs or various foam objects. Although everyone could perform the task, performance was generally poorer among younger children, whereas younger and older adults performed similarly. Meanwhile, they found that gender or handedness did not influence performance. —Melisa Yashinski The advancement of motor augmentation and the broader domain of human-machine interaction rely on a seamless integration with users’ physical and cognitive capabilities. These considerations may markedly fluctuate among individuals on the basis of their age, form, and abilities. There is a need to develop a standard for considering these diversity needs and preferences to guide technological development, and large-scale testing can provide us with evidence for such considerations. Public engagement events provide an important opportunity to build a bidirectional discourse with potential users for the codevelopment of inclusive and accessible technologies. We exhibited the Third Thumb, a hand augmentation device, at a public engagement event and tested participants from the general public, who are often not involved in such early technological development of wearable robotic technology. We focused on wearability (fit and control), ability to successfully operate the device, and ability levels across diversity factors relevant for physical technologies (gender, handedness, and age). Our inclusive design was successful in 99.3% of our diverse sample of 596 individuals tested (age range from 3 to 96 years). Ninety-eight percent of participants were further able to successfully manipulate objects using the extra thumb during the first minute of use, with no significant influences of gender, handedness, or affinity for hobbies involving the hands. Performance was generally poorer among younger children (aged ≤11 years). Although older and younger adults performed the task comparably, we identified age costs with the older adults. Our findings offer tangible demonstration of the initial usability of the Third Thumb for a broad demographic.},
  archive      = {J_SROB},
  author       = {Dani Clode and Lucy Dowdall and Edmund da Silva and Klara Selén and Dorothy Cowie and Giulia Dominijanni and Tamar R. Makin},
  doi          = {10.1126/scirobotics.adk5183},
  journal      = {Science Robotics},
  month        = {5},
  number       = {90},
  pages        = {eadk5183},
  shortjournal = {Sci. Robot.},
  title        = {Evaluating initial usability of a hand augmentation device across a large and diverse sample},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wearable robots for the real world need vision.
<em>SROB</em>, <em>9</em>(90), eadj8812. (<a
href="https://doi.org/10.1126/scirobotics.adj8812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance wearable robots, understanding user intent and environmental perception with novel vision approaches is needed.},
  archive      = {J_SROB},
  author       = {Letizia Gionfrida and Daekyum Kim and Davide Scaramuzza and Dario Farina and Robert D. Howe},
  doi          = {10.1126/scirobotics.adj8812},
  journal      = {Science Robotics},
  month        = {5},
  number       = {90},
  pages        = {eadj8812},
  shortjournal = {Sci. Robot.},
  title        = {Wearable robots for the real world need vision},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Microsaccade-inspired event camera for robotics.
<em>SROB</em>, <em>9</em>(90), eadj8124. (<a
href="https://doi.org/10.1126/scirobotics.adj8124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event cameras are useful for sensing dynamic objects, but they are not optimized for maintaining stable and persistent texture in vision. Inspired by microsaccades, which are tiny involuntary eye movements generated during prolonged visual fixation to resolve objects, He et al. developed an enhanced event camera to address these challenges. The event camera contained a rotating wedge prism mounted in front of the aperture of the event camera to redirect light and stabilize texture. They demonstrated the ability of the enhanced event camera to acquire more information about the environment and estimate high-speed motion when compared with standard event cameras, with potential to be adopted for robot vision. —Amos Matsiko Neuromorphic vision sensors or event cameras have made the visual perception of extremely low reaction time possible, opening new avenues for high-dynamic robotics applications. These event cameras’ output is dependent on both motion and texture. However, the event camera fails to capture object edges that are parallel to the camera motion. This is a problem intrinsic to the sensor and therefore challenging to solve algorithmically. Human vision deals with perceptual fading using the active mechanism of small involuntary eye movements, the most prominent ones called microsaccades. By moving the eyes constantly and slightly during fixation, microsaccades can substantially maintain texture stability and persistence. Inspired by microsaccades, we designed an event-based perception system capable of simultaneously maintaining low reaction time and stable texture. In this design, a rotating wedge prism was mounted in front of the aperture of an event camera to redirect light and trigger events. The geometrical optics of the rotating wedge prism allows for algorithmic compensation of the additional rotational motion, resulting in a stable texture appearance and high informational output independent of external motion. The hardware device and software solution are integrated into a system, which we call artificial microsaccade–enhanced event camera (AMI-EV). Benchmark comparisons validated the superior data quality of AMI-EV recordings in scenarios where both standard cameras and event cameras fail to deliver. Various real-world experiments demonstrated the potential of the system to facilitate robotics perception both for low-level and high-level vision tasks.},
  archive      = {J_SROB},
  author       = {Botao He and Ze Wang and Yuan Zhou and Jingxi Chen and Chahat Deep Singh and Haojia Li and Yuman Gao and Shaojie Shen and Kaiwei Wang and Yanjun Cao and Chao Xu and Yiannis Aloimonos and Fei Gao and Cornelia Fermüller},
  doi          = {10.1126/scirobotics.adj8124},
  journal      = {Science Robotics},
  month        = {5},
  number       = {90},
  pages        = {eadj8124},
  shortjournal = {Sci. Robot.},
  title        = {Microsaccade-inspired event camera for robotics},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Closed-loop optogenetic neuromodulation enables
high-fidelity fatigue-resistant muscle control. <em>SROB</em>,
<em>9</em>(90), eadi8995. (<a
href="https://doi.org/10.1126/scirobotics.adi8995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrical stimulation has been widely used in neuroprostheses to control and restore muscle function. However, this approach causes poor fine-force modulation and quickly leads to fatiguing of the muscles after brief stimulation. Herrera-Arcos et al . now present a closed-loop method for neuromodulation using optogenetics that alleviates the challenges associated with electrical stimulation. A biophysical model was also developed to understand the characteristics underlying neuromuscular optogenetic stimulation. They showed that functional optogenetic stimulation supported fatigue-resistant control of muscle with higher accuracy and higher generated force in vivo than electrical stimulation, demonstrating that it may potentially be adopted for prosthesis control. —Amos Matsiko Closed-loop neuroprostheses show promise in restoring motion in individuals with neurological conditions. However, conventional activation strategies based on functional electrical stimulation (FES) fail to accurately modulate muscle force and exhibit rapid fatigue because of their unphysiological recruitment mechanism. Here, we present a closed-loop control framework that leverages physiological force modulation under functional optogenetic stimulation (FOS) to enable high-fidelity muscle control for extended periods of time (&gt;60 minutes) in vivo. We first uncovered the force modulation characteristic of FOS, showing more physiological recruitment and significantly higher modulation ranges (&gt;320%) compared with FES. Second, we developed a neuromuscular model that accurately describes the highly nonlinear dynamics of optogenetically stimulated muscle. Third, on the basis of the optogenetic model, we demonstrated real-time control of muscle force with improved performance and fatigue resistance compared with FES. This work lays the foundation for fatigue-resistant neuroprostheses and optogenetically controlled biohybrid robots with high-fidelity force modulation.},
  archive      = {J_SROB},
  author       = {Guillermo Herrera-Arcos and Hyungeun Song and Seong Ho Yeon and Omkar Ghenand and Samantha Gutierrez-Arango and Sapna Sinha and Hugh Herr},
  doi          = {10.1126/scirobotics.adi8995},
  journal      = {Science Robotics},
  month        = {5},
  number       = {90},
  pages        = {eadi8995},
  shortjournal = {Sci. Robot.},
  title        = {Closed-loop optogenetic neuromodulation enables high-fidelity fatigue-resistant muscle control},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An ultrawide field-of-view pinhole compound eye using
hemispherical nanowire array for robot vision. <em>SROB</em>,
<em>9</em>(90), eadi8666. (<a
href="https://doi.org/10.1126/scirobotics.adi8666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insects have compound eyes with wide field of view and motion-tracking capabilities that have served as inspiration for roboticists. Previous attempts that transferred a microlens array onto a curved surface have suffered from complications during the transfer process. As an alternative approach, Zhou et al. developed a lens-free compound eye by combining a 3D-printed hemispherical pinhole structure with a perovskite nanowire photodetector array. The pinhole compound eye exhibited a wide field of view and could accurately locate targets owing to the good angular selectivity and wide spectrum response in monocular and binocular configurations. To demonstrate dynamic motion tracking, the compound eye was incorporated onto a drone and successfully tracked a moving quadruped robot in real time. —Melisa Yashinski Garnering inspiration from biological compound eyes, artificial vision systems boasting a vivid range of diverse visual functional traits have come to the fore recently. However, most of these artificial systems rely on transformable electronics, which suffer from the complexity and constrained geometry of global deformation, as well as potential mismatches between optical and detector units. Here, we present a unique pinhole compound eye that combines a three-dimensionally printed honeycomb optical structure with a hemispherical, all-solid-state, high-density perovskite nanowire photodetector array. The lens-free pinhole structure can be designed and fabricated with an arbitrary layout to match the underlying image sensor. Optical simulations and imaging results matched well with each other and substantiated the key characteristics and capabilities of our system, which include an ultrawide field of view, accurate target positioning, and motion tracking function. We further demonstrate the potential of our unique compound eye for advanced robotic vision by successfully completing a moving target tracking mission.},
  archive      = {J_SROB},
  author       = {Yu Zhou and Zhibo Sun and Yucheng Ding and Zhengnan Yuan and Xiao Qiu and Yang Bryan Cao and Zhu’an Wan and Zhenghao Long and Swapnadeep Poddar and Shivam Kumar and Wenhao Ye and Chak Lam Jonathan Chan and Daquan Zhang and Beitao Ren and Qianpeng Zhang and Hoi-Sing Kwok and Mitch Guijun Li and Zhiyong Fan},
  doi          = {10.1126/scirobotics.adi8666},
  journal      = {Science Robotics},
  month        = {5},
  number       = {90},
  pages        = {eadi8666},
  shortjournal = {Sci. Robot.},
  title        = {An ultrawide field-of-view pinhole compound eye using hemispherical nanowire array for robot vision},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fully neuromorphic vision and control for autonomous drone
flight. <em>SROB</em>, <em>9</em>(90), eadi0591. (<a
href="https://doi.org/10.1126/scirobotics.adi0591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the ability of visual processing enabled by artificial neural networks, the associated hardware and large power consumption limit deployment on small flying drones. Neuromorphic hardware offers a promising alternative, but the accompanying spiking neural networks are difficult to train, and the current hardware only supports a limited number of neurons. Paredes-Vallés et al. now present a neuromorphic pipeline to control drone flight. They trained a five-layer spiking neural network to process the raw inputs from an event camera. The network first estimated ego-motion and subsequently determined low-level control commands. Real-world experiments demonstrated that the drone could control its ego-motion to land, hover, and maneuver sideways, with minimal power consumption. —Melisa Yashinski Biological sensing and processing is asynchronous and sparse, leading to low-latency and energy-efficient perception and action. In robotics, neuromorphic hardware for event-based vision and spiking neural networks promises to exhibit similar characteristics. However, robotic implementations have been limited to basic tasks with low-dimensional sensory inputs and motor actions because of the restricted network size in current embedded neuromorphic processors and the difficulties of training spiking neural networks. Here, we present a fully neuromorphic vision-to-control pipeline for controlling a flying drone. Specifically, we trained a spiking neural network that accepts raw event-based camera data and outputs low-level control actions for performing autonomous vision-based flight. The vision part of the network, consisting of five layers and 28,800 neurons, maps incoming raw events to ego-motion estimates and was trained with self-supervised learning on real event data. The control part consists of a single decoding layer and was learned with an evolutionary algorithm in a drone simulator. Robotic experiments show a successful sim-to-real transfer of the fully learned neuromorphic pipeline. The drone could accurately control its ego-motion, allowing for hovering, landing, and maneuvering sideways—even while yawing at the same time. The neuromorphic pipeline runs on board on Intel’s Loihi neuromorphic processor with an execution frequency of 200 hertz, consuming 0.94 watt of idle power and a mere additional 7 to 12 milliwatts when running the network. These results illustrate the potential of neuromorphic sensing and processing for enabling insect-sized intelligent robots.},
  archive      = {J_SROB},
  author       = {F. Paredes-Vallés and J. J. Hagenaars and J. Dupeyroux and S. Stroobants and Y. Xu and G. C. H. E. de Croon},
  doi          = {10.1126/scirobotics.adi0591},
  journal      = {Science Robotics},
  month        = {5},
  number       = {90},
  pages        = {eadi0591},
  shortjournal = {Sci. Robot.},
  title        = {Fully neuromorphic vision and control for autonomous drone flight},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Grasping objects with the aid of haptics. <em>SROB</em>,
<em>9</em>(89), eadp8528. (<a
href="https://doi.org/10.1126/scirobotics.adp8528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A smart suction cup uses haptics to supplement vision for exploration of objects in a grasping task.},
  archive      = {J_SROB},
  author       = {Amos Matsiko},
  doi          = {10.1126/scirobotics.adp8528},
  journal      = {Science Robotics},
  month        = {4},
  number       = {89},
  pages        = {eadp8528},
  shortjournal = {Sci. Robot.},
  title        = {Grasping objects with the aid of haptics},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024h). Using machine learning and robotics to discover plastic
substitutes. <em>SROB</em>, <em>9</em>(89), eadp7392. (<a
href="https://doi.org/10.1126/scirobotics.adp7392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovery of all-natural thin films with tunable properties was partially automated using robotics and machine learning.},
  archive      = {J_SROB},
  author       = {Melisa Yashinski},
  doi          = {10.1126/scirobotics.adp7392},
  journal      = {Science Robotics},
  month        = {4},
  number       = {89},
  pages        = {eadp7392},
  shortjournal = {Sci. Robot.},
  title        = {Using machine learning and robotics to discover plastic substitutes},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). Legged robots take a leap forward. <em>SROB</em>,
<em>9</em>(89), eadp3679. (<a
href="https://doi.org/10.1126/scirobotics.adp3679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legged robots take a leap forward.},
  archive      = {J_SROB},
  author       = {Amos Matsiko},
  doi          = {10.1126/scirobotics.adp3679},
  journal      = {Science Robotics},
  month        = {4},
  number       = {89},
  pages        = {eadp3679},
  shortjournal = {Sci. Robot.},
  title        = {Legged robots take a leap forward},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024g). Robot pack mules remain science fiction for now.
<em>SROB</em>, <em>9</em>(89), eadp3677. (<a
href="https://doi.org/10.1126/scirobotics.adp3677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The plot of the 2014 science-fiction movie Young Ones revolves around a robot pack mule based on the real-world BigDog.},
  archive      = {J_SROB},
  author       = {Robin R. Murphy},
  doi          = {10.1126/scirobotics.adp3677},
  journal      = {Science Robotics},
  month        = {4},
  number       = {89},
  pages        = {eadp3677},
  shortjournal = {Sci. Robot.},
  title        = {Robot pack mules remain science fiction for now},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Legged robots beyond bioinspiration. <em>SROB</em>,
<em>9</em>(89), eadp1956. (<a
href="https://doi.org/10.1126/scirobotics.adp1956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in engineering enable wheeled-legged hybrid locomotion, an achievement not feasible in biological systems.},
  archive      = {J_SROB},
  author       = {Krzysztof Walas},
  doi          = {10.1126/scirobotics.adp1956},
  journal      = {Science Robotics},
  month        = {4},
  number       = {89},
  pages        = {eadp1956},
  shortjournal = {Sci. Robot.},
  title        = {Legged robots beyond bioinspiration},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Locomotion as manipulation with ReachBot. <em>SROB</em>,
<em>9</em>(89), eadi9762. (<a
href="https://doi.org/10.1126/scirobotics.adi9762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Caves on the moon and Mars are of geological and astrobiological interest, but their rocky terrain and sparse anchor points make it impossible for traditional robots to explore. Taking inspiration from an arachnid, Chen et al . developed a robot with a small body and long extendable booms for appendages named ReachBot. The ends of the booms were equipped with grippers that can grasp rocky terrain and enable ReachBot to use manipulation for locomotion. Using onboard sensors along with a contact-before-motion planner, the robot could scan and identify graspable convex features. Field tests performed in a lava tube in the Mojave Desert (California, USA) confirmed that ReachBot could identify and grasp multiple sites, demonstrating its potential as a martian explorer. —Melisa Yashinski Caves and lava tubes on the Moon and Mars are sites of geological and astrobiological interest but consist of terrain that is inaccessible with traditional robot locomotion. To support the exploration of these sites, we present ReachBot, a robot that uses extendable booms as appendages to manipulate itself with respect to irregular rock surfaces. The booms terminate in grippers equipped with microspines and provide ReachBot with a large workspace, allowing it to achieve force closure in enclosed spaces, such as the walls of a lava tube. To propel ReachBot, we present a contact-before-motion planner for nongaited legged locomotion that uses internal force control, similar to a multifingered hand, to keep its long, slender booms in tension. Motion planning also depends on finding and executing secure grips on rock features. We used a Monte Carlo simulation to inform gripper design and predict grasp strength and variability. In addition, we used a two-step perception system to identify possible grasp locations. To validate our approach and mechanisms under realistic conditions, we deployed a single ReachBot arm and gripper in a lava tube in the Mojave Desert. The field test confirmed that ReachBot will find many targets for secure grasps with the proposed kinematic design.},
  archive      = {J_SROB},
  author       = {Tony G. Chen and Stephanie Newdick and Julia Di and Carlo Bosio and Nitin Ongole and Mathieu Lapôtre and Marco Pavone and Mark R. Cutkosky},
  doi          = {10.1126/scirobotics.adi9762},
  journal      = {Science Robotics},
  month        = {4},
  number       = {89},
  pages        = {eadi9762},
  shortjournal = {Sci. Robot.},
  title        = {Locomotion as manipulation with ReachBot},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Why animals can outrun robots. <em>SROB</em>,
<em>9</em>(89), eadi9754. (<a
href="https://doi.org/10.1126/scirobotics.adi9754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strategies for robot locomotion have often taken inspiration from animals. But robots still fall short when compared to the inherent performance of animals. Burden et al. review the literature and discuss why animals outrun robots in categories such as agility, range, and robustness. The authors highlight that, with few exceptions, engineering outperforms biology in the components critical for running, so they conclude that there must be as-yet-undiscovered principles of integration and control that give animals their advantage over robots. —Amos Matsiko Animals are much better at running than robots. The difference in performance arises in the important dimensions of agility, range, and robustness. To understand the underlying causes for this performance gap, we compare natural and artificial technologies in the five subsystems critical for running: power, frame, actuation, sensing, and control. With few exceptions, engineering technologies meet or exceed the performance of their biological counterparts. We conclude that biology’s advantage over engineering arises from better integration of subsystems, and we identify four fundamental obstacles that roboticists must overcome. Toward this goal, we highlight promising research directions that have outsized potential to help future running robots achieve animal-level performance.},
  archive      = {J_SROB},
  author       = {Samuel A. Burden and Thomas Libby and Kaushik Jayaram and Simon Sponberg and J. Maxwell Donelan},
  doi          = {10.1126/scirobotics.adi9754},
  journal      = {Science Robotics},
  month        = {4},
  number       = {89},
  pages        = {eadi9754},
  shortjournal = {Sci. Robot.},
  title        = {Why animals can outrun robots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning robust autonomous navigation and locomotion for
wheeled-legged robots. <em>SROB</em>, <em>9</em>(89), eadi9641. (<a
href="https://doi.org/10.1126/scirobotics.adi9641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Last-mile deliveries in urban areas lead to increasing traffic problems and supply chain issues. By converting to robotic deliveries, routes can move from the street to alternate pathways, but traditional legged robots lack the necessary efficiency and battery life. By augmenting a legged robot with wheels, Lee et al . used hybrid wheeled-legged locomotion to improve the cost of transport while rolling on flat surfaces yet still allowing for legged navigation over obstacles like stairs. Using various reinforcement learning techniques, the robot was trained to smoothly transition between walking and driving modes and to navigate challenging terrain and dynamic obstacles including pedestrians. The robot was tested for large-scale navigation through an autonomous trek of more than 10 kilometers in Zurich, Switzerland, and Seville, Spain. The hybrid wheeled-legged platform successfully addressed many challenges associated with robotic urban mobility. —Melisa Yashinski Autonomous wheeled-legged robots have the potential to transform logistics systems, improving operational efficiency and adaptability in urban environments. Navigating urban environments, however, poses unique challenges for robots, necessitating innovative solutions for locomotion and navigation. These challenges include the need for adaptive locomotion across varied terrains and the ability to navigate efficiently around complex dynamic obstacles. This work introduces a fully integrated system comprising adaptive locomotion control, mobility-aware local navigation planning, and large-scale path planning within the city. Using model-free reinforcement learning (RL) techniques and privileged learning, we developed a versatile locomotion controller. This controller achieves efficient and robust locomotion over various rough terrains, facilitated by smooth transitions between walking and driving modes. It is tightly integrated with a learned navigation controller through a hierarchical RL framework, enabling effective navigation through challenging terrain and various obstacles at high speed. Our controllers are integrated into a large-scale urban navigation system and validated by autonomous, kilometer-scale navigation missions conducted in Zurich, Switzerland, and Seville, Spain. These missions demonstrate the system’s robustness and adaptability, underscoring the importance of integrated control systems in achieving seamless navigation in complex environments. Our findings support the feasibility of wheeled-legged robots and hierarchical RL for autonomous navigation, with implications for last-mile delivery and beyond.},
  archive      = {J_SROB},
  author       = {Joonho Lee and Marko Bjelonic and Alexander Reske and Lorenz Wellhausen and Takahiro Miki and Marco Hutter},
  doi          = {10.1126/scirobotics.adi9641},
  journal      = {Science Robotics},
  month        = {4},
  number       = {89},
  pages        = {eadi9641},
  shortjournal = {Sci. Robot.},
  title        = {Learning robust autonomous navigation and locomotion for wheeled-legged robots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-world humanoid locomotion with reinforcement learning.
<em>SROB</em>, <em>9</em>(89), eadi9579. (<a
href="https://doi.org/10.1126/scirobotics.adi9579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability of robots to navigate adaptively and robustly in varying terrain increases their chances of success when deployed in the real world. However, stable locomotion of full-size bipedal humanoid robots creates a challenge from a controls perspective. Radosavovic et al . developed a reinforcement learning approach for controlling locomotion of a humanoid robot, Digit. They trained their model in simulation and subsequently deployed it into the real-world zero-shot and showed the potential for robust locomotion on various indoor and outdoor environments. The robot could exhibit natural and adaptive walking behaviors, including an emergent arm-swing motion, and adapt to external perturbations. —Amos Matsiko Humanoid robots that can autonomously operate in diverse environments have the potential to help address labor shortages in factories, assist elderly at home, and colonize new planets. Although classical controllers for humanoid robots have shown impressive results in a number of settings, they are challenging to generalize and adapt to new environments. Here, we present a fully learning-based approach for real-world humanoid locomotion. Our controller is a causal transformer that takes the history of proprioceptive observations and actions as input and predicts the next action. We hypothesized that the observation-action history contains useful information about the world that a powerful transformer model can use to adapt its behavior in context, without updating its weights. We trained our model with large-scale model-free reinforcement learning on an ensemble of randomized environments in simulation and deployed it to the real-world zero-shot. Our controller could walk over various outdoor terrains, was robust to external disturbances, and could adapt in context.},
  archive      = {J_SROB},
  author       = {Ilija Radosavovic and Tete Xiao and Bike Zhang and Trevor Darrell and Jitendra Malik and Koushil Sreenath},
  doi          = {10.1126/scirobotics.adi9579},
  journal      = {Science Robotics},
  month        = {4},
  number       = {89},
  pages        = {eadi9579},
  shortjournal = {Sci. Robot.},
  title        = {Real-world humanoid locomotion with reinforcement learning},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An agile monopedal hopping quadcopter with synergistic
hybrid locomotion. <em>SROB</em>, <em>9</em>(89), eadi8912. (<a
href="https://doi.org/10.1126/scirobotics.adi8912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional jumping robots are actuated in a stance phase, either by a rapid energy release mechanism or with legs driven by actuators. Previous attempts at a jumping and flying robot used these mechanisms for jump-assisted takeoff but struggled to achieve continuous hopping or adjustable jump heights. A new robot called the Hopcopter by Bai et al. combines a commercial quadcopter with a passive telescopic leg. The Hopcopter was actuated in the aerial phase, allowing for continuous hopping, high jump frequencies, and tunable jump height. Intermittent hops led to sudden increases in acceleration and enable highly agile movements such as rapid, tight turns. The robot was also modified with an aerodynamic stabilizer that interacts with air flow to stabilize the robot with only internal sensors. The combination of locomotion modes was shown to increase endurance and power efficiency, which could potentially extend travel distance and operational range for applications in surveillance and inspection. —Melisa Yashinski Nature abounds with examples of superior mobility through the fusion of aerial and ground movement. Drawing inspiration from such multimodal locomotion, we introduce a high-performance hybrid hopping and flying robot. The proposed robot seamlessly integrates a nano quadcopter with a passive telescopic leg, overcoming limitations of previous jumping mechanisms that rely on stance phase leg actuation. Based on the identified dynamics, a thrust-based control method and detachable active aerodynamic surfaces were devised for the robot to perform continuous jumps with and without position feedback. This unique design and actuation strategy enable tuning of jump height and reduced stance phase duration, leading to agile hopping locomotion. The robot recorded an average vertical hopping speed of 2.38 meters per second at a jump height of 1.63 meters. By harnessing multimodal locomotion, the robot is capable of intermittent midflight jumps that result in substantial instantaneous accelerations and rapid changes in flight direction, offering enhanced agility and versatility in complex environments. The passive leg design holds potential for direct integration with conventional rotorcraft, unlocking seamless hybrid hopping and flying locomotion.},
  archive      = {J_SROB},
  author       = {Songnan Bai and Qiqi Pan and Runze Ding and Huaiyuan Jia and Zhengbao Yang and Pakpong Chirarattananon},
  doi          = {10.1126/scirobotics.adi8912},
  journal      = {Science Robotics},
  month        = {4},
  number       = {89},
  pages        = {eadi8912},
  shortjournal = {Sci. Robot.},
  title        = {An agile monopedal hopping quadcopter with synergistic hybrid locomotion},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning agile soccer skills for a bipedal robot with deep
reinforcement learning. <em>SROB</em>, <em>9</em>(89), eadi8022. (<a
href="https://doi.org/10.1126/scirobotics.adi8022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating robust motor skills in bipedal robots in the real world is challenging because of the inability of current control methods to generalize to specific tasks. Haarnoja et al. developed a deep reinforcement learning–based framework for full-body control of humanoid robots, enabling a game of one-versus-one soccer. The robots exhibited emergent behaviors in the form of dynamic motor skills such as the ability to recover from falls and also tactics like defending the ball against an opponent. The robot movements were faster when using their framework than a scripted baseline controller and may have potential for more complex multirobot interactions. —Amos Matsiko We investigated whether deep reinforcement learning (deep RL) is able to synthesize sophisticated and safe movement skills for a low-cost, miniature humanoid robot that can be composed into complex behavioral strategies. We used deep RL to train a humanoid robot to play a simplified one-versus-one soccer game. The resulting agent exhibits robust and dynamic movement skills, such as rapid fall recovery, walking, turning, and kicking, and it transitions between them in a smooth and efficient manner. It also learned to anticipate ball movements and block opponent shots. The agent’s tactical behavior adapts to specific game contexts in a way that would be impractical to manually design. Our agent was trained in simulation and transferred to real robots zero-shot. A combination of sufficiently high-frequency control, targeted dynamics randomization, and perturbations during training enabled good-quality transfer. In experiments, the agent walked 181% faster, turned 302% faster, took 63% less time to get up, and kicked a ball 34% faster than a scripted baseline.},
  archive      = {J_SROB},
  author       = {Tuomas Haarnoja and Ben Moran and Guy Lever and Sandy H. Huang and Dhruva Tirumala and Jan Humplik and Markus Wulfmeier and Saran Tunyasuvunakool and Noah Y. Siegel and Roland Hafner and Michael Bloesch and Kristian Hartikainen and Arunkumar Byravan and Leonard Hasenclever and Yuval Tassa and Fereshteh Sadeghi and Nathan Batchelor and Federico Casarini and Stefano Saliceti and Charles Game and Neil Sreendra and Kushal Patel and Marlon Gwira and Andrea Huber and Nicole Hurley and Francesco Nori and Raia Hadsell and Nicolas Heess},
  doi          = {10.1126/scirobotics.adi8022},
  journal      = {Science Robotics},
  month        = {4},
  number       = {89},
  pages        = {eadi8022},
  shortjournal = {Sci. Robot.},
  title        = {Learning agile soccer skills for a bipedal robot with deep reinforcement learning},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024g). Restoration of motor function using magnetoelectric
metamaterials. <em>SROB</em>, <em>9</em>(88), eadp3707. (<a
href="https://doi.org/10.1126/scirobotics.adp3707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implantable magnetic materials can be used for wireless neural stimulation and restoration of motor function.},
  archive      = {J_SROB},
  author       = {Amos Matsiko},
  doi          = {10.1126/scirobotics.adp3707},
  journal      = {Science Robotics},
  month        = {3},
  number       = {88},
  pages        = {eadp3707},
  shortjournal = {Sci. Robot.},
  title        = {Restoration of motor function using magnetoelectric metamaterials},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024f). Safe radiation surveillance using uncrewed vehicles.
<em>SROB</em>, <em>9</em>(88), eadp1760. (<a
href="https://doi.org/10.1126/scirobotics.adp1760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncrewed aerial vehicles could be used to collect radiation data after a dispersal event.},
  archive      = {J_SROB},
  author       = {Melisa Yashinski},
  doi          = {10.1126/scirobotics.adp1760},
  journal      = {Science Robotics},
  month        = {3},
  number       = {88},
  pages        = {eadp1760},
  shortjournal = {Sci. Robot.},
  title        = {Safe radiation surveillance using uncrewed vehicles},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A fictional history of robotics features forgotten
real-world robots. <em>SROB</em>, <em>9</em>(88), eado7982. (<a
href="https://doi.org/10.1126/scirobotics.ado7982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The science-fiction movie The Creator uses six real-world robots from the 1950s and 1960s to show progress in AI.},
  archive      = {J_SROB},
  author       = {Robin R. Murphy},
  doi          = {10.1126/scirobotics.ado7982},
  journal      = {Science Robotics},
  month        = {3},
  number       = {88},
  pages        = {eado7982},
  shortjournal = {Sci. Robot.},
  title        = {A fictional history of robotics features forgotten real-world robots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Teaching robots the art of human social synchrony.
<em>SROB</em>, <em>9</em>(88), eado5755. (<a
href="https://doi.org/10.1126/scirobotics.ado5755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humanoid robots can now learn the art of social synchrony using neural networks.},
  archive      = {J_SROB},
  author       = {Rachael E. Jack},
  doi          = {10.1126/scirobotics.ado5755},
  journal      = {Science Robotics},
  month        = {3},
  number       = {88},
  pages        = {eado5755},
  shortjournal = {Sci. Robot.},
  title        = {Teaching robots the art of human social synchrony},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Elastic energy-recycling actuators for efficient robots.
<em>SROB</em>, <em>9</em>(88), eadj7246. (<a
href="https://doi.org/10.1126/scirobotics.adj7246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermal loss in electric motors leads to a reduction in energy efficiency of the devices they power. Springs, on the other hand, can produce torque without consuming energy, but they are challenging to control. Krimsky and Collins have developed an actuator that combines the benefits of motors and springs, having both fine torque control and efficient energy recovery. A prototype actuator was tested in a series of cyclic test cases, demonstrating the potential to reduce energy consumption by 50 to 97% and highlighting the wide-reaching implications in the development of robotic systems with low energy consumption. —Amos Matsiko Electric motors are widely used in robots but waste energy in many applications. We introduce an elastic energy-recycling actuator that maintains the versatility of motors while improving energy efficiency in cyclic tasks. The actuator comprises a motor in parallel with an array of springs that can be individually engaged and disengaged, while retaining stored energy, by pairs of low-power electroadhesive clutches. We developed a prototype actuator and tested it in five repetitive tasks with features common in robotic applications but difficult to perform efficiently. The actuator reduced power consumption by at least 50% in all cases and by 97% in the best case. Elastic energy recovery, controlled by low-power clutches, can improve the efficiency of mobile robots, assistive devices, and other engineered systems.},
  archive      = {J_SROB},
  author       = {Erez Krimsky and Steven H. Collins},
  doi          = {10.1126/scirobotics.adj7246},
  journal      = {Science Robotics},
  month        = {3},
  number       = {88},
  pages        = {eadj7246},
  shortjournal = {Sci. Robot.},
  title        = {Elastic energy-recycling actuators for efficient robots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimating human joint moments unifies exoskeleton control,
reducing user effort. <em>SROB</em>, <em>9</em>(88), eadi8852. (<a
href="https://doi.org/10.1126/scirobotics.adi8852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exoskeleton suits that personalize the assistance provided to users depending on the anatomical and environmental needs have the potential to improve user mobility. However, controllers for these suits are not optimized for all of the possible ambulation modes that the user will encounter. Molinaro et al. have now developed a unified lower limb exoskeleton control framework that relies on deep learning to adapt autonomously to user needs for a wide range of ambulatory conditions. The neural network could estimate the total hip flexion/extension moments without the need for user-specific calibration and was shown to be capable of reducing user metabolic cost. —Amos Matsiko Robotic lower-limb exoskeletons can augment human mobility, but current systems require extensive, context-specific considerations, limiting their real-world viability. Here, we present a unified exoskeleton control framework that autonomously adapts assistance on the basis of instantaneous user joint moment estimates from a temporal convolutional network (TCN). When deployed on our hip exoskeleton, the TCN achieved an average root mean square error of 0.142 newton-meters per kilogram across 35 ambulatory conditions without any user-specific calibration. Further, the unified controller significantly reduced user metabolic cost and lower-limb positive work during level-ground and incline walking compared with walking without wearing the exoskeleton. This advancement bridges the gap between in-lab exoskeleton technology and real-world human ambulation, making exoskeleton control technology viable for a broad community.},
  archive      = {J_SROB},
  author       = {Dean D. Molinaro and Inseung Kang and Aaron J. Young},
  doi          = {10.1126/scirobotics.adi8852},
  journal      = {Science Robotics},
  month        = {3},
  number       = {88},
  pages        = {eadi8852},
  shortjournal = {Sci. Robot.},
  title        = {Estimating human joint moments unifies exoskeleton control, reducing user effort},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ANYmal parkour: Learning agile navigation for quadrupedal
robots. <em>SROB</em>, <em>9</em>(88), eadi7566. (<a
href="https://doi.org/10.1126/scirobotics.adi7566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agility in legged robots that match humans and animals is not easily achievable. Moreover, the ability to perform elegant and nimble locomotion around complex obstacles with limited onboard computing makes agility even more challenging. Hoeller et al . developed a framework for training a quadrupedal robot with locomotion skills, such as jumping, climbing, crouching, and walking, for rapid navigation around an obstacle parkour course. The framework was trained in simulation and subsequently deployed in the real world on legged robots, demonstrating their ability to reach targets with speeds of up to 2 meters per second and showing potential for robot navigation on unstructured terrain where time is vital, such as in search and rescue. —Amos Matsiko Performing agile navigation with four-legged robots is a challenging task because of the highly dynamic motions, contacts with various parts of the robot, and the limited field of view of the perception sensors. Here, we propose a fully learned approach to training such robots and conquer scenarios that are reminiscent of parkour challenges. The method involves training advanced locomotion skills for several types of obstacles, such as walking, jumping, climbing, and crouching, and then using a high-level policy to select and control those skills across the terrain. Thanks to our hierarchical formulation, the navigation policy is aware of the capabilities of each skill, and it will adapt its behavior depending on the scenario at hand. In addition, a perception module was trained to reconstruct obstacles from highly occluded and noisy sensory data and endows the pipeline with scene understanding. Compared with previous attempts, our method can plan a path for challenging scenarios without expert demonstration, offline computation, a priori knowledge of the environment, or taking contacts explicitly into account. Although these modules were trained from simulated data only, our real-world experiments demonstrate successful transfer on hardware, where the robot navigated and crossed consecutive challenging obstacles with speeds of up to 2 meters per second.},
  archive      = {J_SROB},
  author       = {David Hoeller and Nikita Rudin and Dhionis Sako and Marco Hutter},
  doi          = {10.1126/scirobotics.adi7566},
  journal      = {Science Robotics},
  month        = {3},
  number       = {88},
  pages        = {eadi7566},
  shortjournal = {Sci. Robot.},
  title        = {ANYmal parkour: Learning agile navigation for quadrupedal robots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wireless flow-powered miniature robot capable of traversing
tubular structures. <em>SROB</em>, <em>9</em>(88), eadi5155. (<a
href="https://doi.org/10.1126/scirobotics.adi5155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Millimeter-scale robots that are capable of traversing through pipes for maintenance and inspection often rely on external power, but this dependence limits the robot’s operational range and environment. Conversely, pipe inspection robots with onboard powering and actuation units cannot be scaled down to the millimeter scale. As an alternate power source, Hong et al. developed a miniature robot that relies on environmental power to traverse a pipeline. The wheeled robot, equipped with an internal impeller, converts the fluid flow in the tube into mechanical energy. An external magnetic field can switch the direction the impeller rotates, enabling movement both with and against direction of flow. Flexible wheels enable the robot to traverse complex pipe shapes with changing diameter. By using flow power within the pipe, this robot can move long distances and perform for long durations. —Melisa Yashinski Wireless millimeter-scale robots capable of navigating through fluid-flowing tubular structures hold substantial potential for inspection, maintenance, or repair use in nuclear, industrial, and medical applications. However, prevalent reliance on external powering constrains these robots’ operational range and applicable environments. Alternatives with onboard powering must trade off size, functionality, and operation duration. Here, we propose a wireless millimeter-scale wheeled robot capable of using environmental flows to power and actuate its long-distance locomotion through complex pipelines. The flow-powering module can convert flow energy into mechanical energy, achieving an impeller speed of up to 9595 revolutions per minute, accompanied by an output power density of 11.7 watts per cubic meter and an efficiency of 33.7%. A miniature gearbox module can further transmit the converted mechanical energy into the robot’s locomotion system, allowing the robot to move against water flow at an average rate of up to 1.05 meters per second. The robot’s motion status (moving against/with flow or pausing) can be switched using an external magnetic field or an onboard mechanical regulator, contingent on different proposed control designs. In addition, we designed kirigami-based soft wheels for adaptive locomotion. The robot can move against flows of various substances within pipes featuring complex geometries and diverse materials. Solely powered by flow, the robot can transport cylindrical payloads with a diameter of up to 55% of the pipe’s diameter and carry devices such as an endoscopic camera for pipeline inspection, a wireless temperature sensor for environmental temperature monitoring, and a leak-stopper shell for infrastructure maintenance.},
  archive      = {J_SROB},
  author       = {Chong Hong and Yingdan Wu and Che Wang and Ziyu Ren and Chunxiang Wang and Zemin Liu and Wenqi Hu and Metin Sitti},
  doi          = {10.1126/scirobotics.adi5155},
  journal      = {Science Robotics},
  month        = {3},
  number       = {88},
  pages        = {eadi5155},
  shortjournal = {Sci. Robot.},
  title        = {Wireless flow-powered miniature robot capable of traversing tubular structures},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human-robot facial coexpression. <em>SROB</em>,
<em>9</em>(88), eadi4724. (<a
href="https://doi.org/10.1126/scirobotics.adi4724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humanoid robots are capable of mimicking human expressions by perceiving human emotions and responding after the human has finished their expression. However, a delayed smile can feel artificial and disingenuous compared with a smile occurring simultaneously with a companion’s smile. Hu et al. trained their anthropomorphic facial robot named Emo to display an anticipatory expression to match its human companion. Emo is equipped with 26 motors and flexible silicone skin to provide precise control over its facial expressions. The robot was trained with a video dataset of humans making expressions. By observing subtle changes in a human face, the robot could predict an approaching smile 839 milliseconds before the human smiled and adjust its face to smile simultaneously. —Melisa Yashinski Large language models are enabling rapid progress in robotic verbal communication, but nonverbal communication is not keeping pace. Physical humanoid robots struggle to express and communicate using facial movement, relying primarily on voice. The challenge is twofold: First, the actuation of an expressively versatile robotic face is mechanically challenging. A second challenge is knowing what expression to generate so that the robot appears natural, timely, and genuine. Here, we propose that both barriers can be alleviated by training a robot to anticipate future facial expressions and execute them simultaneously with a human. Whereas delayed facial mimicry looks disingenuous, facial coexpression feels more genuine because it requires correct inference of the human’s emotional state for timely execution. We found that a robot can learn to predict a forthcoming smile about 839 milliseconds before the human smiles and, using a learned inverse kinematic facial self-model, coexpress the smile simultaneously with the human. We demonstrated this ability using a robot face comprising 26 degrees of freedom. We believe that the ability to coexpress simultaneous facial expressions could improve human-robot interaction.},
  archive      = {J_SROB},
  author       = {Yuhang Hu and Boyuan Chen and Jiong Lin and Yunzhe Wang and Yingke Wang and Cameron Mehlman and Hod Lipson},
  doi          = {10.1126/scirobotics.adi4724},
  journal      = {Science Robotics},
  month        = {3},
  number       = {88},
  pages        = {eadi4724},
  shortjournal = {Sci. Robot.},
  title        = {Human-robot facial coexpression},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EELS: Autonomous snake-like robot with task and motion
planning capabilities for ice world exploration. <em>SROB</em>,
<em>9</em>(88), eadh8332. (<a
href="https://doi.org/10.1126/scirobotics.adh8332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is growing interest in the exploration of icy moons, such as Enceladus, which may have astrobiological implications. However, obtaining samples is challenging because of the environmental extremities on the surface or within ice vents. Vaquero et al. developed a snake-like robot named Exobiology Extant Life Surveyor (EELS) that was capable of autonomously navigating on icy surfaces. EELS has a perception head that contains a series of sensors and cameras to observe its environment, whereas the body has articulated segments for shape-changing and a screw-like outer surface to enable motility. EELS shows potential for risk-aware autonomous exploration of complex icy terrain. —Amos Matsiko Ice worlds are at the forefront of astrobiological interest because of the evidence of subsurface oceans. Enceladus in particular is unique among the icy moons because there are known vent systems that are likely connected to a subsurface ocean, through which the ocean water is ejected to space. An existing study has shown that sending small robots into the vents and directly sampling the ocean water is likely possible. To enable such a mission, NASA’s Jet Propulsion Laboratory is developing a snake-like robot called Exobiology Extant Life Surveyor (EELS) that can navigate Enceladus’ extreme surface and descend an erupting vent to capture unaltered liquid samples and potentially reach the ocean. However, navigating to and through Enceladus’ environment is challenging: Because of the limitations of existing orbital reconnaissance, there is substantial uncertainty with respect to its geometry and the physical properties of the surface/vents; communication is limited, which requires highly autonomous robots to execute the mission with limited human supervision. Here, we provide an overview of the EELS project and its development effort to create a risk-aware autonomous robot to navigate these extreme ice terrains/environments. We describe the robot’s architecture and the technical challenges to navigate and sense the icy environment safely and effectively. We focus on the challenges related to surface mobility, task and motion planning under uncertainty, and risk quantification. We provide initial results on mobility and risk-aware task and motion planning from field tests and simulated scenarios.},
  archive      = {J_SROB},
  author       = {T. S. Vaquero and G. Daddi and R. Thakker and M. Paton and A. Jasour and M. P. Strub and R. M. Swan and R. Royce and M. Gildner and P. Tosi and M. Veismann and P. Gavrilov and E. Marteau and J. Bowkett and D. Loret de Mola Lemus and Y. Nakka and B. Hockman and A. Orekhov and T. D. Hasseler and C. Leake and B. Nuernberger and P. Proença and W. Reid and W. Talbot and N. Georgiev and T. Pailevanian and A. Archanian and E. Ambrose and J. Jasper and R. Etheredge and C. Roman and D. Levine and K. Otsu and S. Yearicks and H. Melikyan and R. R. Rieber and K. Carpenter and J. Nash and A. Jain and L. Shiraishi and M. Robinson and M. Travers and H. Choset and J. Burdick and A. Gardner and M. Cable and M. Ingham and M. Ono},
  doi          = {10.1126/scirobotics.adh8332},
  journal      = {Science Robotics},
  month        = {3},
  number       = {88},
  pages        = {eadh8332},
  shortjournal = {Sci. Robot.},
  title        = {EELS: Autonomous snake-like robot with task and motion planning capabilities for ice world exploration},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Performing forceful robot manipulation tasks.
<em>SROB</em>, <em>9</em>(87), eado8051. (<a
href="https://doi.org/10.1126/scirobotics.ado8051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A planning framework enables a robot to perform forceful manipulation tasks, such as opening a push-twist medicine bottle.},
  archive      = {J_SROB},
  author       = {Melisa Yashinski},
  doi          = {10.1126/scirobotics.ado8051},
  journal      = {Science Robotics},
  month        = {2},
  number       = {87},
  pages        = {eado8051},
  shortjournal = {Sci. Robot.},
  title        = {Performing forceful robot manipulation tasks},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024h). Tracking hand movements with a smart glove. <em>SROB</em>,
<em>9</em>(87), eado6856. (<a
href="https://doi.org/10.1126/scirobotics.ado6856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic hand movements could be detected in real time using machine learning and a smart textile glove.},
  archive      = {J_SROB},
  author       = {Amos Matsiko},
  doi          = {10.1126/scirobotics.ado6856},
  journal      = {Science Robotics},
  month        = {2},
  number       = {87},
  pages        = {eado6856},
  shortjournal = {Sci. Robot.},
  title        = {Tracking hand movements with a smart glove},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024e). Magnetic robots make headway in medicine. <em>SROB</em>,
<em>9</em>(87), eado3194. (<a
href="https://doi.org/10.1126/scirobotics.ado3194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SROB},
  author       = {Amos Matsiko},
  doi          = {10.1126/scirobotics.ado3194},
  journal      = {Science Robotics},
  month        = {2},
  number       = {87},
  pages        = {eado3194},
  shortjournal = {Sci. Robot.},
  title        = {Magnetic robots make headway in medicine},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Remote magnetic navigation enables precision telesurgery.
<em>SROB</em>, <em>9</em>(87), eado3187. (<a
href="https://doi.org/10.1126/scirobotics.ado3187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical devices actuated by external magnetic fields can create opportunities for clinical adoption of precision telesurgery.},
  archive      = {J_SROB},
  author       = {Bradley J. Nelson and Bernard R. Bendok and Evelyn L. Turcotte and H. Hunt Batjer},
  doi          = {10.1126/scirobotics.ado3187},
  journal      = {Science Robotics},
  month        = {2},
  number       = {87},
  pages        = {eado3187},
  shortjournal = {Sci. Robot.},
  title        = {Remote magnetic navigation enables precision telesurgery},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Early science fiction got microbots surprisingly right.
<em>SROB</em>, <em>9</em>(87), eado1489. (<a
href="https://doi.org/10.1126/scirobotics.ado1489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since 1931, science fiction has speculated on how microbots might work and how they will change our lives.},
  archive      = {J_SROB},
  author       = {Robin R. Murphy},
  doi          = {10.1126/scirobotics.ado1489},
  journal      = {Science Robotics},
  month        = {2},
  number       = {87},
  pages        = {eado1489},
  shortjournal = {Sci. Robot.},
  title        = {Early science fiction got microbots surprisingly right},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human-scale navigation of magnetic microrobots in hepatic
arteries. <em>SROB</em>, <em>9</em>(87), eadh8702. (<a
href="https://doi.org/10.1126/scirobotics.adh8702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic microrobots can be used for selective drug delivery in arteries; however, challenges from gravity and blood flow can make it difficult to navigate them with accuracy. Li et al. developed an algorithm to determine the optimal patient position such that gravity helps, rather than hinders, targeted drug delivery in hepatic arteries. Magnetic fields generated from MRI were used to steer the microrobots through hepatic arteries to targeted liver lobes in living pigs. When the algorithm was used to determine the optimal position for the pig, the number of microrobots that reach targeted lobes increased up to 2.6-fold compared with microrobots navigated in pigs that were not repositioned. Finding the optimal patient position could improve efficiency in drug-delivery techniques that rely on an external field for navigation. —Melisa Yashinski Using external actuation sources to navigate untethered drug-eluting microrobots in the bloodstream offers great promise in improving the selectivity of drug delivery, especially in oncology, but the current field forces are difficult to maintain with enough strength inside the human body (&gt;70-centimeter-diameter range) to achieve this operation. Here, we present an algorithm to predict the optimal patient position with respect to gravity during endovascular microrobot navigation. Magnetic resonance navigation, using magnetic field gradients in clinical magnetic resonance imaging (MRI), is combined with the algorithm to improve the targeting efficiency of magnetic microrobots (MMRs). Using a dedicated microparticle injector, a high-precision MRI-compatible balloon inflation system, and a clinical MRI, MMRs were successfully steered into targeted lobes via the hepatic arteries of living pigs. The distribution ratio of the microrobots (roughly 2000 MMRs per pig) in the right liver lobe increased from 47.7 to 86.4% and increased in the left lobe from 52.2 to 84.1%. After passing through multiple vascular bifurcations, the number of MMRs reaching four different target liver lobes had a 1.7- to 2.6-fold increase in the navigation groups compared with the control group. Performing simulations on 19 patients with hepatocellular carcinoma (HCC) demonstrated that the proposed technique can meet the need for hepatic embolization in patients with HCC. Our technology offers selectable direction for actuator-based navigation of microrobots at the human scale.},
  archive      = {J_SROB},
  author       = {Ning Li and Phillip Fei and Cyril Tous and Mahdi Rezaei Adariani and Marie-Lou Hautot and Inès Ouedraogo and Amina Hadjadj and Ivan P. Dimov and Quan Zhang and Simon Lessard and Zeynab Nosrati and Courtney N. Ng and Katayoun Saatchi and Urs O. Häfeli and Charles Tremblay and Samuel Kadoury and An Tang and Sylvain Martel and Gilles Soulez},
  doi          = {10.1126/scirobotics.adh8702},
  journal      = {Science Robotics},
  month        = {2},
  number       = {87},
  pages        = {eadh8702},
  shortjournal = {Sci. Robot.},
  title        = {Human-scale navigation of magnetic microrobots in hepatic arteries},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An ingestible self-propelling device for intestinal
reanimation. <em>SROB</em>, <em>9</em>(87), eadh8170. (<a
href="https://doi.org/10.1126/scirobotics.adh8170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Postoperative ileus (POI) is the leading cause of prolonged hospital stay after abdominal surgery and is characterized by a functional paralysis of the digestive tract, leading to symptoms such as constipation, vomiting, and functional obstruction. Current treatments are mainly supportive and inefficacious and yield acute side effects. Although electrical stimulation studies have demonstrated encouraging pacing and entraining of the intestinal slow waves, no devices exist today to enable targeted intestinal reanimation. Here, we developed an ingestible self-propelling device for intestinal reanimation (INSPIRE) capable of restoring peristalsis through luminal electrical stimulation. Optimizing mechanical, material, and electrical design parameters, we validated optimal deployment, intestinal electrical luminal contact, self-propelling capability, safety, and degradation of the device in ex vivo and in vivo swine models. We compared the INSPIRE’s effect on motility in models of normal and depressed motility and chemically induced ileus. Intestinal contraction improved by 44% in anesthetized animals and up to 140% in chemically induced ileus cases. In addition, passage time decreased from, on average, 8.6 days in controls to 2.5 days with the INSPIRE device, demonstrating significant improvement in motility. Luminal electrical stimulation of the intestine via the INSPIRE efficaciously restored peristaltic activity. This noninvasive option offers a promising solution for the treatment of ileus and other motility disorders.},
  archive      = {J_SROB},
  author       = {Shriya S. Srinivasan and Julien Dosso and Hen-Wei Huang and George Selsing and Amro Alshareef and Johannes Kuosmanen and Keiko Ishida and Joshua Jenkins and Wiam Abdalla Mohammed Madani and Alison Hayward and Giovanni Traverso},
  doi          = {10.1126/scirobotics.adh8170},
  journal      = {Science Robotics},
  month        = {2},
  number       = {87},
  pages        = {eadh8170},
  shortjournal = {Sci. Robot.},
  title        = {An ingestible self-propelling device for intestinal reanimation},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Magnetic soft microfiberbots for robotic embolization.
<em>SROB</em>, <em>9</em>(87), eadh2479. (<a
href="https://doi.org/10.1126/scirobotics.adh2479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a minimally invasive treatment for aneurysms and brain tumors, surgeons typically insert a slender catheter through the femoral artery and guide it through blood vessels to deliver embolic agents. However, this method of embolization can be difficult to steer through complex vascular networks. A magnetic, soft microfiberbot was developed by Liu et al. to perform remotely controlled robotic embolization. The microfiberbot, composed of a magnetized fiber coiled into a helix shape, can conform to different vessel sizes and performs a corkscrew propulsion when subjected to an external magnetic field. The microfiberbots were used to successfully perform in vitro embolization of aneurysm and tumor in phantom blood vessels and in vivo embolization in a rabbit femoral artery. These proposed robots provide a controllable alternative to conventional catheter-based embolization. —Melisa Yashinski Cerebral aneurysms and brain tumors are leading life-threatening diseases worldwide. By deliberately occluding the target lesion to reduce the blood supply, embolization has been widely used clinically to treat cerebral aneurysms and brain tumors. Conventional embolization is usually performed by threading a catheter through blood vessels to the target lesion, which is often limited by the poor steerability of the catheter in complex neurovascular networks, especially in submillimeter regions. Here, we propose magnetic soft microfiberbots with high steerability, reliable maneuverability, and multimodal shape reconfigurability to perform robotic embolization in submillimeter regions via a remote, untethered, and magnetically controllable manner. Magnetic soft microfiberbots were fabricated by thermal drawing magnetic soft composite into microfibers, followed by magnetizing and molding procedures to endow a helical magnetic polarity. By controlling magnetic fields, magnetic soft microfiberbots exhibit reversible elongated/aggregated shape morphing and helical propulsion in flow conditions, allowing for controllable navigation through complex vasculature and robotic embolization in submillimeter regions. We performed in vitro embolization of aneurysm and tumor in neurovascular phantoms and in vivo embolization of a rabbit femoral artery model under real-time fluoroscopy. These studies demonstrate the potential clinical value of our work, paving the way for a robotic embolization scheme in robotic settings.},
  archive      = {J_SROB},
  author       = {Xurui Liu and Liu Wang and Yuanzhuo Xiang and Fan Liao and Na Li and Jiyu Li and Jiaxin Wang and Qingyang Wu and Cheng Zhou and Youzhou Yang and Yuanshi Kou and Yueying Yang and Hanchuan Tang and Ning Zhou and Chidan Wan and Zhouping Yin and Guang-Zhong Yang and Guangming Tao and Jianfeng Zang},
  doi          = {10.1126/scirobotics.adh2479},
  journal      = {Science Robotics},
  month        = {2},
  number       = {87},
  pages        = {eadh2479},
  shortjournal = {Sci. Robot.},
  title        = {Magnetic soft microfiberbots for robotic embolization},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tracking and navigation of a microswarm under laser speckle
contrast imaging for targeted delivery. <em>SROB</em>, <em>9</em>(87),
eadh1978. (<a
href="https://doi.org/10.1126/scirobotics.adh1978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro- and nanorobots have been widely proposed for various medical applications, including drug delivery and thrombolysis. However, tracking these swarms of robots in real time has been challenging, especially for imaging modalities that rely on extended exposure to ionizing radiation. Wang et al . report on the use of laser speckle contrast imaging to track a swarm of magnetic nanorobots within blood vessels in real time and guide their endovascular navigation. The authors demonstrated the potential for high contrast imaging and navigation of the swarm of nanorobots in stagnant and flowing blood environments ex vivo and in vivo. The findings offer an opportunity for improvements in targeted endovascular delivery. —Amos Matsiko Micro/nanorobotic swarms consisting of numerous tiny building blocks show great potential in biomedical applications because of their collective active delivery ability, enhanced imaging contrast, and environment-adaptive capability. However, in vivo real-time imaging and tracking of micro/nanorobotic swarms remain a challenge, considering the limited imaging size and spatial-temporal resolution of current imaging modalities. Here, we propose a strategy that enables real-time tracking and navigation of a microswarm in stagnant and flowing blood environments by using laser speckle contrast imaging (LSCI), featuring full-field imaging, high temporal-spatial resolution, and noninvasiveness. The change in dynamic convection induced by the microswarm can be quantitatively investigated by analyzing the perfusion unit (PU) distribution, offering an alternative approach to investigate the swarm behavior and its interaction with various blood environments. Both the microswarm and surrounding environment were monitored and imaged by LSCI in real time, and the images were further analyzed for simultaneous swarm tracking and navigation in the complex vascular system. Moreover, our strategy realized real-time tracking and delivery of a microswarm in vivo, showing promising potential for LSCI-guided active delivery of microswarm in the vascular system.},
  archive      = {J_SROB},
  author       = {Qinglong Wang and Qianqian Wang and Zhipeng Ning and Kai Fung Chan and Jialin Jiang and Yuqiong Wang and Lin Su and Shuai Jiang and Ben Wang and Bonaventure Yiu Ming Ip and Ho Ko and Thomas Wai Hong Leung and Philip Wai Yan Chiu and Simon Chun Ho Yu and Li Zhang},
  doi          = {10.1126/scirobotics.adh1978},
  journal      = {Science Robotics},
  month        = {2},
  number       = {87},
  pages        = {eadh1978},
  shortjournal = {Sci. Robot.},
  title        = {Tracking and navigation of a microswarm under laser speckle contrast imaging for targeted delivery},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dexterous helical magnetic robot for improved endovascular
access. <em>SROB</em>, <em>9</em>(87), eadh0298. (<a
href="https://doi.org/10.1126/scirobotics.adh0298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acute ischemic stroke can lead to long-term debilitating conditions and death, but, if patients are treated promptly, then their chances of survival and recovery increase exponentially. The challenge for clinicians is accessing the affected blood vessel in the brain. Because of the complex network and architecture of these blood vessels, there is still an unmet need for approaches that enable effective navigation of catheters to remove the blood clot. Dreyfus et al. report on a highly dexterous articulated continuum robot that is magnetically steered to improve the navigation of catheters in tortuous blood vessels. The device enabled successful endovascular navigation from the aorta to millimeter-sized cranial arteries in vivo, demonstrating its potential for atraumatic access to occluded vessels in the brain. —Amos Matsiko Treating vascular diseases in the brain requires access to the affected region inside the body. This is usually accomplished through a minimally invasive technique that involves the use of long, thin devices, such as wires and tubes, that are manually maneuvered by a clinician within the bloodstream. By pushing, pulling, and twisting, these devices are navigated through the tortuous pathways of the blood vessels. The outcome of the procedure heavily relies on the clinician’s skill and the device’s ability to navigate to the affected target region in the bloodstream, which is often inhibited by tortuous blood vessels. Sharp turns require high flexibility, but this flexibility inhibits translation of proximal insertion to distal tip advancement. We present a highly dexterous, magnetically steered continuum robot that overcomes pushability limitations through rotation. A helical protrusion on the device’s surface engages with the vessel wall and translates rotation to forward motion at every point of contact. An articulating magnetic tip allows for active steerability, enabling navigation from the aortic arch to millimeter-sized arteries of the brain. The effectiveness of the magnetic continuum robot has been demonstrated through successful navigation in models of the human vasculature and in blood vessels of a live pig.},
  archive      = {J_SROB},
  author       = {R. Dreyfus and Q. Boehler and S. Lyttle and P. Gruber and J. Lussi and C. Chautems and S. Gervasoni and J. Berberat and D. Seibold and N. Ochsenbein-Kölble and M. Reinehr and M. Weisskopf and L. Remonda and B. J. Nelson},
  doi          = {10.1126/scirobotics.adh0298},
  journal      = {Science Robotics},
  month        = {2},
  number       = {87},
  pages        = {eadh0298},
  shortjournal = {Sci. Robot.},
  title        = {Dexterous helical magnetic robot for improved endovascular access},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024f). Overcoming adversaries in multirobot navigation.
<em>SROB</em>, <em>9</em>(86), eado2404. (<a
href="https://doi.org/10.1126/scirobotics.ado2404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A path-planning algorithm allows safe navigation of robot teams in cluttered environments while in the presence of adversaries.},
  archive      = {J_SROB},
  author       = {Amos Matsiko},
  doi          = {10.1126/scirobotics.ado2404},
  journal      = {Science Robotics},
  month        = {1},
  number       = {86},
  pages        = {eado2404},
  shortjournal = {Sci. Robot.},
  title        = {Overcoming adversaries in multirobot navigation},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024e). Robots can motivate children to practice piano.
<em>SROB</em>, <em>9</em>(86), eado1003. (<a
href="https://doi.org/10.1126/scirobotics.ado1003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Children who practiced piano with a robot that initiated self-assessment showed increased motivation and improved performance.},
  archive      = {J_SROB},
  author       = {Melisa Yashinski},
  doi          = {10.1126/scirobotics.ado1003},
  journal      = {Science Robotics},
  month        = {1},
  number       = {86},
  pages        = {eado1003},
  shortjournal = {Sci. Robot.},
  title        = {Robots can motivate children to practice piano},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024j). What will robots think of us? <em>SROB</em>,
<em>9</em>(86), eadn6096. (<a
href="https://doi.org/10.1126/scirobotics.adn6096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two recent science fiction novels humorously illustrate the importance of correct robot mental models.},
  archive      = {J_SROB},
  author       = {Robin R. Murphy},
  doi          = {10.1126/scirobotics.adn6096},
  journal      = {Science Robotics},
  month        = {1},
  number       = {86},
  pages        = {eadn6096},
  shortjournal = {Sci. Robot.},
  title        = {What will robots think of us?},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robot swarms meet soft matter physics. <em>SROB</em>,
<em>9</em>(86), eadn6035. (<a
href="https://doi.org/10.1126/scirobotics.adn6035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Principles of soft matter physics can be leveraged to develop swarms of active robots with unique properties.},
  archive      = {J_SROB},
  author       = {Daniel I. Goldman and D. Zeb Rocklin},
  doi          = {10.1126/scirobotics.adn6035},
  journal      = {Science Robotics},
  month        = {1},
  number       = {86},
  pages        = {eadn6035},
  shortjournal = {Sci. Robot.},
  title        = {Robot swarms meet soft matter physics},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A growing soft robot with climbing plant–inspired adaptive
behaviors for navigation in unstructured environments. <em>SROB</em>,
<em>9</em>(86), eadi5908. (<a
href="https://doi.org/10.1126/scirobotics.adi5908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-growing robots are an emerging solution in soft robotics for navigating, exploring, and colonizing unstructured environments. However, their ability to grow and move in heterogeneous three-dimensional (3D) spaces, comparable with real-world conditions, is still developing. We present an autonomous growing robot that draws inspiration from the behavioral adaptive strategies of climbing plants to navigate unstructured environments. The robot mimics climbing plants’ apical shoot to sense and coordinate additive adaptive growth via an embedded additive manufacturing mechanism and a sensorized tip. Growth orientation, comparable with tropisms in real plants, is dictated by external stimuli, including gravity, light, and shade. These are incorporated within a vector field method to implement the preferred adaptive behavior for a given environment and task, such as growth toward light and/or against gravity. We demonstrate the robot’s ability to navigate through growth in relation to voids, potential supports, and thoroughfares in otherwise complex habitats. Adaptive twining around vertical supports can provide an escape from mechanical stress due to self-support, reduce energy expenditure for construction costs, and develop an anchorage point to support further growth and crossing gaps. The robot adapts its material printing parameters to develop a light body and fast growth to twine on supports or a tougher body to enable self-support and cross gaps. These features, typical of climbing plants, highlight a potential for adaptive robots and their on-demand manufacturing. They are especially promising for applications in exploring, monitoring, and interacting with unstructured environments or in the autonomous construction of complex infrastructures.},
  archive      = {J_SROB},
  author       = {Emanuela Del Dottore and Alessio Mondini and Nick Rowe and Barbara Mazzolai},
  doi          = {10.1126/scirobotics.adi5908},
  journal      = {Science Robotics},
  month        = {1},
  number       = {86},
  pages        = {eadi5908},
  shortjournal = {Sci. Robot.},
  title        = {A growing soft robot with climbing plant–inspired adaptive behaviors for navigation in unstructured environments},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ultralight, strong, and self-reprogrammable mechanical
metamaterials. <em>SROB</em>, <em>9</em>(86), eadi2746. (<a
href="https://doi.org/10.1126/scirobotics.adi2746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Versatile programmable materials have long been envisioned that can reconfigure themselves to adapt to changing use cases in adaptive infrastructure, space exploration, disaster response, and more. We introduce a robotic structural system as an implementation of programmable matter, with mechanical performance and scale on par with conventional high-performance materials and truss systems. Fiber-reinforced composite truss-like building blocks form strong, stiff, and lightweight lattice structures as mechanical metamaterials. Two types of mobile robots operate over the exterior surface and through the interior of the system, performing transport, placement, and reversible fastening using the intrinsic lattice periodicity for indexing and metrology. Leveraging programmable matter algorithms to achieve scalability in size and complexity, this system design enables robust collective automated assembly and reconfiguration of large structures with simple robots. We describe the system design and experimental results from a 256–unit cell assembly demonstration and lattice mechanical testing, as well as a demonstration of disassembly and reconfiguration. The assembled structural lattice material exhibits ultralight mass density (0.0103 grams per cubic centimeter) with high strength and stiffness for its weight ( 11.38 kilopascals and 1.1129 megapascals, respectively), a material performance realm appropriate for applications like space structures. With simple robots and structure, high mass-specific structural performance, and competitive throughput, this system demonstrates the potential for self-reconfiguring autonomous metamaterials for diverse applications.},
  archive      = {J_SROB},
  author       = {Christine E. Gregg and Damiana Catanoso and Olivia Irene B. Formoso and Irina Kostitsyna and Megan E. Ochalek and Taiwo J. Olatunde and In Won Park and Frank M. Sebastianelli and Elizabeth M. Taylor and Greenfield T. Trinh and Kenneth C. Cheung},
  doi          = {10.1126/scirobotics.adi2746},
  journal      = {Science Robotics},
  month        = {1},
  number       = {86},
  pages        = {eadi2746},
  shortjournal = {Sci. Robot.},
  title        = {Ultralight, strong, and self-reprogrammable mechanical metamaterials},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DTC: Deep tracking control. <em>SROB</em>, <em>9</em>(86),
eadh5401. (<a
href="https://doi.org/10.1126/scirobotics.adh5401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legged locomotion is a complex control problem that requires both accuracy and robustness to cope with real-world challenges. Legged systems have traditionally been controlled using trajectory optimization with inverse dynamics. Such hierarchical model-based methods are appealing because of intuitive cost function tuning, accurate planning, generalization, and, most importantly, the insightful understanding gained from more than one decade of extensive research. However, model mismatch and violation of assumptions are common sources of faulty operation. Simulation-based reinforcement learning, on the other hand, results in locomotion policies with unprecedented robustness and recovery skills. Yet, all learning algorithms struggle with sparse rewards emerging from environments where valid footholds are rare, such as gaps or stepping stones. In this work, we propose a hybrid control architecture that combines the advantages of both worlds to simultaneously achieve greater robustness, foot-placement accuracy, and terrain generalization. Our approach uses a model-based planner to roll out a reference motion during training. A deep neural network policy is trained in simulation, aiming to track the optimized footholds. We evaluated the accuracy of our locomotion pipeline on sparse terrains, where pure data-driven methods are prone to fail. Furthermore, we demonstrate superior robustness in the presence of slippery or deformable ground when compared with model-based counterparts. Last, we show that our proposed tracking controller generalizes across different trajectory optimization methods not seen during training. In conclusion, our work unites the predictive capabilities and optimality guarantees of online planning with the inherent robustness attributed to offline learning.},
  archive      = {J_SROB},
  author       = {Fabian Jenelten and Junzhe He and Farbod Farshidian and Marco Hutter},
  doi          = {10.1126/scirobotics.adh5401},
  journal      = {Science Robotics},
  month        = {1},
  number       = {86},
  pages        = {eadh5401},
  shortjournal = {Sci. Robot.},
  title        = {DTC: Deep tracking control},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A self-organizing robotic aggregate using solid and
liquid-like collective states. <em>SROB</em>, <em>9</em>(86), eadh4130.
(<a href="https://doi.org/10.1126/scirobotics.adh4130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing robotic systems that can change their physical form factor as well as their compliance to adapt to environmental constraints remains a major conceptual and technical challenge. To address this, we introduce the Granulobot, a modular system that blurs the distinction between soft, modular, and swarm robotics. The system consists of gear-like units that each contain a single actuator such that units can self-assemble into larger, granular aggregates using magnetic coupling. These aggregates can reconfigure dynamically and also split into subsystems that might later recombine. Aggregates can self-organize into collective states with solid- and liquid-like properties, thus displaying widely differing compliance. These states can be perturbed locally via actuators or externally via mechanical feedback from the environment to produce adaptive shape-shifting in a decentralized manner. This, in turn, can generate locomotion strategies adapted to different conditions. Aggregates can move over obstacles without using external sensors or coordinates to maintain a steady gait over different surfaces without electronic communication among units. The modular design highlights a physical, morphological form of control that advances the development of resilient robotic systems with the ability to morph and adapt to different functions and conditions.},
  archive      = {J_SROB},
  author       = {Baudouin Saintyves and Matthew Spenko and Heinrich M. Jaeger},
  doi          = {10.1126/scirobotics.adh4130},
  journal      = {Science Robotics},
  month        = {1},
  number       = {86},
  pages        = {eadh4130},
  shortjournal = {Sci. Robot.},
  title        = {A self-organizing robotic aggregate using solid and liquid-like collective states},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 3D-printed digital pneumatic logic for the control of soft
robotic actuators. <em>SROB</em>, <em>9</em>(86), eadh4060. (<a
href="https://doi.org/10.1126/scirobotics.adh4060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft robots are paving their way to catch up with the application range of metal-based machines and to occupy fields that are challenging for traditional machines. Pneumatic actuators play an important role in this development, allowing the construction of bioinspired motion systems. Pneumatic logic gates provide a powerful alternative for controlling pressure-activated soft robots, which are often controlled by metallic valves and electric circuits. Many existing approaches for fully compliant pneumatic control logic suffer from high manual effort and low pressure tolerance. In our work, we invented three-dimensional (3D) printable, pneumatic logic gates that perform Boolean operations and imitate electric circuits. Within 7 hours, a filament printer is able to produce a module that serves as an OR, AND, or NOT gate; the logic function is defined by the assigned input signals. The gate contains two alternately acting pneumatic valves, whose work principle is based on the interaction of pressurized chambers and a 3D-printed 1-millimeter tube inside. The gate design does not require any kind of support material for its hollow parts, which makes the modules ready to use directly after printing. Depending on the chosen material, the modules can operate on a pressure supply between 80 and more than 750 kilopascals. The capabilities of the invented gates were verified by implementing an electronics-free drink dispenser based on a pneumatic ring oscillator and a 1-bit memory. Their high compliance is demonstrated by driving a car over a fully flexible, 3D-printed robotic walker controlled by an integrated circuit.},
  archive      = {J_SROB},
  author       = {S. Conrad and J. Teichmann and P. Auth and N. Knorr and K. Ulrich and D. Bellin and T. Speck and F. J. Tauber},
  doi          = {10.1126/scirobotics.adh4060},
  journal      = {Science Robotics},
  month        = {1},
  number       = {86},
  pages        = {eadh4060},
  shortjournal = {Sci. Robot.},
  title        = {3D-printed digital pneumatic logic for the control of soft robotic actuators},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ICub3 avatar system: Enabling remote fully immersive
embodiment of humanoid robots. <em>SROB</em>, <em>9</em>(86), eadh3834.
(<a href="https://doi.org/10.1126/scirobotics.adh3834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an avatar system designed to facilitate the embodiment of humanoid robots by human operators, validated through iCub3, a humanoid developed at the Istituto Italiano di Tecnologia. More precisely, the paper makes two contributions: First, we present the humanoid iCub3 as a robotic avatar that integrates the latest significant improvements after about 15 years of development of the iCub series. Second, we present a versatile avatar system enabling humans to embody humanoid robots encompassing aspects such as locomotion, manipulation, voice, and facial expressions with comprehensive sensory feedback including visual, auditory, haptic, weight, and touch modalities. We validated the system by implementing several avatar architecture instances, each tailored to specific requirements. First, we evaluated the optimized architecture for verbal, nonverbal, and physical interactions with a remote recipient. This testing involved the operator in Genoa and the avatar in the Biennale di Venezia, Venice—about 290 kilometers away—thus allowing the operator to visit the Italian art exhibition remotely. Second, we evaluated the optimized architecture for recipient physical collaboration and public engagement on stage, live, at the We Make Future show, a prominent world digital innovation festival. In this instance, the operator was situated in Genoa while the avatar operated in Rimini—about 300 kilometers away—interacting with a recipient who entrusted the avatar with a payload to carry on stage before an audience of approximately 2000 spectators. Third, we present the architecture implemented by the iCub Team for the All Nippon Airways (ANA) Avatar XPrize competition.},
  archive      = {J_SROB},
  author       = {Stefano Dafarra and Ugo Pattacini and Giulio Romualdi and Lorenzo Rapetti and Riccardo Grieco and Kourosh Darvish and Gianluca Milani and Enrico Valli and Ines Sorrentino and Paolo Maria Viceconte and Alessandro Scalzo and Silvio Traversaro and Carlotta Sartore and Mohamed Elobaid and Nuno Guedelha and Connor Herron and Alexander Leonessa and Francesco Draicchio and Giorgio Metta and Marco Maggiali and Daniele Pucci},
  doi          = {10.1126/scirobotics.adh3834},
  journal      = {Science Robotics},
  month        = {1},
  number       = {86},
  pages        = {eadh3834},
  shortjournal = {Sci. Robot.},
  title        = {ICub3 avatar system: Enabling remote fully immersive embodiment of humanoid robots},
  volume       = {9},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
