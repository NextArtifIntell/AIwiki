<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AML_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aml---81">AML - 81</h2>
<ul>
<li><details>
<summary>
(2024). Modeling performance of data collection systems for
high-energy physics. <em>AML</em>, <em>2</em>(4), 046113. (<a
href="https://doi.org/10.1063/5.0232456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exponential increases in scientific experimental data are outpacing silicon technology progress, necessitating heterogeneous computing systems—particularly those utilizing machine learning (ML)—to meet future scientific computing demands. The growing importance and complexity of heterogeneous computing systems require systematic modeling to understand and predict the effective roles for ML. We present a model that addresses this need by framing the key aspects of data collection pipelines and constraints and combining them with the important vectors of technology that shape alternatives, computing metrics that allow complex alternatives to be compared. For instance, a data collection pipeline may be characterized by parameters such as sensor sampling rates and the overall relevancy of retrieved samples. Alternatives to this pipeline are enabled by development vectors including ML, parallelization, advancing CMOS, and neuromorphic computing. By calculating metrics for each alternative such as overall F1 score, power, hardware cost, and energy expended per relevant sample, our model allows alternative data collection systems to be rigorously compared. We apply this model to the Compact Muon Solenoid experiment and its planned high luminosity-large hadron collider upgrade, evaluating novel technologies for the data acquisition system (DAQ), including ML-based filtering and parallelized software. The results demonstrate that improvements to early DAQ stages significantly reduce resources required later, with a power reduction of 60% and increased relevant data retrieval per unit power (from 0.065 to 0.31 samples/kJ). However, we predict that further advances will be required in order to meet overall power and cost constraints for the DAQ.},
  archive      = {J_AML},
  author       = {Olin-Ammentorp, Wilkie and Wu, Xingfu and Chien, Andrew A.},
  doi          = {10.1063/5.0232456},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046113},
  shortjournal = {APL Mach. Learn.},
  title        = {Modeling performance of data collection systems for high-energy physics},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable learning of potentials to predict time-dependent
hartree–fock dynamics. <em>AML</em>, <em>2</em>(4), 046112. (<a
href="https://doi.org/10.1063/5.0232683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a framework to learn the time-dependent Hartree–Fock (TDHF) inter-electronic potential of a molecule from its electron density dynamics. Although the entire TDHF Hamiltonian, including the inter-electronic potential, can be computed from first principles, we use this problem as a testbed to develop strategies that can be applied to learn a priori unknown terms that arise in other methods/approaches to quantum dynamics, e.g., emerging problems such as learning exchange–correlation potentials for time-dependent density functional theory. We develop, train, and test three models of the TDHF inter-electronic potential, each parameterized by a four-index tensor of size up to 60 × 60 × 60 × 60. Two of the models preserve Hermitian symmetry, while one model preserves an eight-fold permutation symmetry that implies Hermitian symmetry. Across seven different molecular systems, we find that accounting for the deeper eight-fold symmetry leads to the best-performing model across three metrics: training efficiency, test set predictive power, and direct comparison of true and learned inter-electronic potentials. All three models, when trained on ensembles of field-free trajectories, generate accurate electron dynamics predictions even in a field-on regime that lies outside the training set. To enable our models to scale to large molecular systems, we derive expressions for Jacobian-vector products that enable iterative, matrix-free training.},
  archive      = {J_AML},
  author       = {Bhat, Harish S. and Gupta, Prachi and Isborn, Christine M.},
  doi          = {10.1063/5.0232683},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046112},
  shortjournal = {APL Mach. Learn.},
  title        = {Scalable learning of potentials to predict time-dependent Hartree–Fock dynamics},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Applications of machine learning to high temperature and
high pressure environments: A literature review. <em>AML</em>,
<em>2</em>(4), 046111. (<a
href="https://doi.org/10.1063/5.0233409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, machine learning as a new style of calculation has been developed quickly, and because it can obtain results that experiments cannot achieve, it has become a useful calculation tool in the field of high temperature and high pressure (HTHP). It can simulate and calculate the experimental results according to some calculation principles, such as first-principles, and execute prediction based on models created, such as Gaussian approximation potential, to obtain high-precision results. In addition, its simulation process is very fast, and the cost is not as expensive as that of density functional theory, so machine learning in the field of HTHP computing has aroused great research interest. The rapid development of machine learning makes it a powerful tool to predict some parameter or mechanism of materials and brings a new chance to simulate more complex experimental environments. In this paper, we review some of the most recent applications and insights into machine learning techniques in the fields of mechanics, thermology, electricity, and structural search under the demanding conditions of HTHP.},
  archive      = {J_AML},
  author       = {Wang, Hengkai and Lv, Zengtao and Kumar, Santosh and Wang, Qinglin},
  doi          = {10.1063/5.0233409},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046111},
  shortjournal = {APL Mach. Learn.},
  title        = {Applications of machine learning to high temperature and high pressure environments: A literature review},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Field-free spin–orbit torque devices for logic and neural
network applications. <em>AML</em>, <em>2</em>(4), 046110. (<a
href="https://doi.org/10.1063/5.0226135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust field-free spin–orbit torque (SOT) switching plays an essential role in realizing practical SOT-based magnetic memories and logic devices. Leveraging the strong interlayer Dzyaloshinskii–Moriya interaction, field-free SOT switching is achieved with a threshold switching current density of 5.4 × 10 10 A/m 2 . By exploiting the advantage of separated read–write paths, we demonstrate fundamental logic operations such as AND, OR, and NOT in a dual-channel SOT Hall bar device. We further explore the application of a digital SOT magnetic random access memory (MRAM) design in addressing the issue of the low ON/OFF ratio of the conventional spin-transfer torque MRAM, highlighting its potential for neural network applications. Our simulation results show that using digital SOT MRAM can achieve a classification accuracy of 92.2% for the MNIST dataset, outperforms the analog SOT MRAM case (&lt;10%), and presents remarkable improvements in power and time efficiencies compared to the SRAM case. These findings establish digital SOT MRAM as a frontrunner for edge artificial intelligence applications and offline inference.},
  archive      = {J_AML},
  author       = {Lin, Chun-Yi and Hsieh, Jui-Yu and Wang, Po-Chuan and Tsai, Chia-Chin and Pai, Chi-Feng},
  doi          = {10.1063/5.0226135},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046110},
  shortjournal = {APL Mach. Learn.},
  title        = {Field-free spin–orbit torque devices for logic and neural network applications},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). In silico design and prediction of metastable quaternary
phases in cu–ni–si–cr alloys. <em>AML</em>, <em>2</em>(4), 046109. (<a
href="https://doi.org/10.1063/5.0228936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quaternary phases formed in copper alloys are investigated through a combination of quantum-mechanical and classical computer simulations and active machine learning. Focus is given to nickel, silicon, and chromium impurities in a copper matrix. The analysis of the formation enthalpies of candidate quaternary structures leads to the prediction of two novel quaternary phases and the assessment of their stability. For the predicted two phases, machine learned atomistic potentials are developed using active learning with quantum-mechanical accuracy. The use of these potentials in atomistic simulations further elucidates the structure, temperature-dependent dynamics, and elastic behavior of the predicted quaternary phases in copper alloys. The combined in silico approach is thus proven highly efficient in both designing materials and elucidating their properties and potential combining different spatiotemporal scales. In the case of alloys, this computational scheme significantly reduces the effort in searching the huge chemical space of possible phases, enhancing the efficiency in synthesizing novel alloys with pre-defined properties.},
  archive      = {J_AML},
  author       = {Díaz Carral, Ángel and Gravelle, Simon and Fyta, Maria},
  doi          = {10.1063/5.0228936},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046109},
  shortjournal = {APL Mach. Learn.},
  title        = {In silico design and prediction of metastable quaternary phases in Cu–Ni–Si–Cr alloys},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A high-throughput and data-driven computational framework
for novel quantum materials. <em>AML</em>, <em>2</em>(4), 046108. (<a
href="https://doi.org/10.1063/5.0221823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AML},
  author       = {Kastuar, Srihari M. and Rzepa, Christopher and Rangarajan, Srinivas and Ekuma, Chinedu E.},
  doi          = {10.1063/5.0221823},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046108},
  shortjournal = {APL Mach. Learn.},
  title        = {A high-throughput and data-driven computational framework for novel quantum materials},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PICL: Physics informed contrastive learning for partial
differential equations. <em>AML</em>, <em>2</em>(4), 046107. (<a
href="https://doi.org/10.1063/5.0223651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural operators have recently grown in popularity as Partial Differential Equation (PDE) surrogate models. Learning solution functionals, rather than functions, has proven to be a powerful approach to calculate fast, accurate solutions to complex PDEs. While much work has been performed evaluating neural operator performance on a wide variety of surrogate modeling tasks, these works normally evaluate performance on a single equation at a time. In this work, we develop a novel contrastive pretraining framework utilizing generalized contrastive loss that improves neural operator generalization across multiple governing equations simultaneously. Governing equation coefficients are used to measure ground-truth similarity between systems. A combination of physics-informed system evolution and latent-space model output is anchored to input data and used in our distance function. We find that physics-informed contrastive pretraining improves accuracy for the Fourier neural operator in fixed-future and autoregressive rollout tasks for the 1D and 2D heat, Burgers’, and linear advection equations.},
  archive      = {J_AML},
  author       = {Lorsung, Cooper and Barati Farimani, Amir},
  doi          = {10.1063/5.0223651},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046107},
  shortjournal = {APL Mach. Learn.},
  title        = {PICL: Physics informed contrastive learning for partial differential equations},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Waveflow: Boundary-conditioned normalizing flows applied to
fermionic wave functions. <em>AML</em>, <em>2</em>(4), 046106. (<a
href="https://doi.org/10.1063/5.0229620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient and expressive wave function Ansatz is key to scalable solutions for complex many-body electronic structures. While Slater determinants are predominantly used for constructing antisymmetric electronic wave function Ansätze , this construction can result in limited expressiveness when the targeted wave function is highly complex. In this work, we introduce Waveflow, an innovative framework for learning many-body fermionic wave functions using boundary-conditioned normalizing flows. Instead of relying on Slater determinants, Waveflow imposes antisymmetry by defining the fundamental domain of the wave function and applying necessary boundary conditions. A key challenge in using normalizing flows for this purpose is addressing the topological mismatch between the prior and target distributions. We propose using O-spline priors and I-spline bijections to handle this mismatch, which allows for flexibility in the node number of the distribution while automatically maintaining its square-normalization property. We apply Waveflow to a one-dimensional many-electron system, where we variationally minimize the system’s energy using variational quantum Monte Carlo (VQMC). Our experiments demonstrate that Waveflow can effectively resolve topological mismatches and faithfully learn the ground-state wave function.},
  archive      = {J_AML},
  author       = {Thiede, Luca and Sun, Chong and Aspuru-Guzik, Alán},
  doi          = {10.1063/5.0229620},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046106},
  shortjournal = {APL Mach. Learn.},
  title        = {Waveflow: Boundary-conditioned normalizing flows applied to fermionic wave functions},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PhysBERT: A text embedding model for physics scientific
literature. <em>AML</em>, <em>2</em>(4), 046105. (<a
href="https://doi.org/10.1063/5.0238090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The specialized language and complex concepts in physics pose significant challenges for information extraction through Natural Language Processing (NLP). Central to effective NLP applications is the text embedding model, which converts text into dense vector representations for efficient information retrieval and semantic analysis. In this work, we introduce PhysBERT, the first physics-specific text embedding model. Pre-trained on a curated corpus of 1.2 × 10 6 arXiv physics papers and fine-tuned with supervised data, PhysBERT outperforms leading general-purpose models on physics-specific tasks, including the effectiveness in fine-tuning for specific physics subdomains.},
  archive      = {J_AML},
  author       = {Hellert, Thorsten and Montenegro, João and Pollastro, Andrea},
  doi          = {10.1063/5.0238090},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046105},
  shortjournal = {APL Mach. Learn.},
  title        = {PhysBERT: A text embedding model for physics scientific literature},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Elastic constants from charge density distribution in FCC
high-entropy alloys using CNN and DFT. <em>AML</em>, <em>2</em>(4),
046104. (<a href="https://doi.org/10.1063/5.0229105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While high-entropy alloys (HEAs) present exponentially large compositional space for alloy design, they also create enormous computational challenges to trace the compositional space, especially for the inherently expensive density functional theory calculations (DFT). Recent works have integrated machine learning into DFT to overcome these challenges. However, often these models require an intensive search of appropriate physics-based descriptors. In this paper, we employ a 3D convolutional neural network over just one descriptor, i.e., the charge density derived from DFT, to simplify and bypass the hunt for the descriptors. We show that the elastic constants of face-centered cubic multi-elemental alloys in the Ni–Cu–Au–Pd–Pt system can be predicted from charge density. In addition, using our recent PREDICT approach, we show that the model can be trained only on the charge densities of simpler binary and ternary alloys to effectively predict elastic constants in complex multi-elemental alloys, thereby further enabling easier property-tracing in the large compositional space of HEAs.},
  archive      = {J_AML},
  author       = {Mirzaee, Hossein and Soltanmohammadi, Ramin and Linton, Nathan and Fischer, Jacob and Kamrava, Serveh and Tahmasebi, Pejman and Aidhy, Dilpuneet},
  doi          = {10.1063/5.0229105},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046104},
  shortjournal = {APL Mach. Learn.},
  title        = {Elastic constants from charge density distribution in FCC high-entropy alloys using CNN and DFT},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning assisted search for fe–co–c ternary
compounds with high magnetic anisotropy. <em>AML</em>, <em>2</em>(4),
046103. (<a href="https://doi.org/10.1063/5.0208761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We employ a machine learning (ML)-guided framework to explore rare earth free magnetic materials, specifically focusing on Fe–Co–C ternary compounds for potential use in permanent magnets. Utilizing a specifically trained crystal graph convolutional neural network model, we efficiently screen a vast space of nearly a million substitutional structures to select 620 promising structures for further investigation by first-principles calculation. We predict five low-energy metastable Fe–Co–C compounds with formation energy less than 150 meV/atom above the convex hull. These compounds exhibit high magnetization ( J s &gt; 1.0 T) and significant magnetic anisotropy ( K 1 &gt; 1.0 MJ/m 3 ), making them promising candidates for permanent magnet applications. The phonon calculations indicate these compounds are dynamically stable. Our ML-guided framework demonstrates the utility of rapidly identifying novel materials with tailored magnetic properties.},
  archive      = {J_AML},
  author       = {Xia, Weiyi and Sakurai, Masahiro and Liao, Timothy and Wang, Renhai and Zhang, Chao and Sun, Huaijun and Ho, Kai-Ming and Chelikowsky, James R. and Wang, Cai-Zhuang},
  doi          = {10.1063/5.0208761},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046103},
  shortjournal = {APL Mach. Learn.},
  title        = {Machine learning assisted search for Fe–Co–C ternary compounds with high magnetic anisotropy},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing high-fidelity neural network potentials through
low-fidelity sampling. <em>AML</em>, <em>2</em>(4), 046102. (<a
href="https://doi.org/10.1063/5.0222779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficacy of neural network potentials (NNPs) critically depends on the quality of the configurational datasets used for training. Prior research using empirical potentials has shown that well-selected liquid–solid transitional configurations of a metallic system can be translated to other metallic systems. This study demonstrates that such validated configurations can be relabeled using density functional theory (DFT) calculations, thereby enhancing the development of high-fidelity NNPs. Training strategies and sampling approaches are efficiently assessed using empirical potentials and subsequently relabeled via DFT in a highly parallelized fashion for high-fidelity NNP training. Our results reveal that relying solely on energy and force for NNP training is inadequate to prevent overfitting, highlighting the necessity of incorporating stress terms into the loss functions. To optimize training involving force and stress terms, we propose employing transfer learning to fine-tune the weights, ensuring that the potential surface is smooth for these quantities composed of energy derivatives. This approach markedly improves the accuracy of elastic constants derived from simulations in both empirical potential-based NNPs and relabeled DFT-based NNPs. Overall, this study offers significant insights into leveraging empirical potentials to expedite the development of reliable and robust NNPs at the DFT level.},
  archive      = {J_AML},
  author       = {Jung, Gang Seob},
  doi          = {10.1063/5.0222779},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046102},
  shortjournal = {APL Mach. Learn.},
  title        = {Enhancing high-fidelity neural network potentials through low-fidelity sampling},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven approximations of topological insulator systems.
<em>AML</em>, <em>2</em>(4), 046101. (<a
href="https://doi.org/10.1063/5.0224309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A data-driven approach to calculating tight-binding models for discrete coupled-mode systems is presented. In particular, spectral and topological data are used to build an appropriate discrete model that accurately replicates these properties. This work is motivated by topological insulator systems that are often described by tight-binding models. The problem is formulated as the minimization of an appropriate residual (objective) function. Given bulk spectral data and a topological index (e.g., winding number), an appropriate discrete model is obtained to arbitrary precision. A nonlinear least squares method is used to determine the coefficients. The effectiveness of the scheme is highlighted against a Schrödinger equation with a periodic potential that can be described by the Su–Schrieffer–Heeger model.},
  archive      = {J_AML},
  author       = {Cole, Justin T. and Nameika, Michael J.},
  doi          = {10.1063/5.0224309},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046101},
  shortjournal = {APL Mach. Learn.},
  title        = {Data-driven approximations of topological insulator systems},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine-learning-derived thermal conductivity of
two-dimensional TiS2/MoS2 van der waals heterostructures. <em>AML</em>,
<em>2</em>(3), 036115. (<a
href="https://doi.org/10.1063/5.0205702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the thermal conductivity of two-dimensional (2D) heterostructures is challenging and cannot be adequately resolved using conventional computational approaches. To address this challenge, we propose a new and efficient approach that combines first-principles density functional theory (DFT) calculations with a machine-learning interatomic potential (MLIP) methodology to determine the thermal conductivity of a novel 2D van der Waals TiS 2 /MoS 2 heterostructure. We leverage the proposed approach to estimate the thermal conductivities of TiS 2 /MoS 2 heterostructures as well as bilayer-TiS 2 and bilayer-MoS 2 . A unique aspect of this approach is the combined implementation of the moment tensor potential for short-range (intralayer) interactions and the D3-dispersion correction scheme for long-range (interlayer) van der Waals interactions. This approach employs relatively inexpensive computational DFT-based datasets generated from ab initio molecular dynamics simulations to accurately describe the interatomic interactions in the bilayers. The thermal conductivities of the bilayers exhibit the following trend: bilayer-TiS 2 &gt; bilayer-MoS 2 &gt; the TiS 2 /MoS 2 heterostructure. In addition, this work makes the case that the 2D bilayers exhibit considerably higher thermal conductivities than bulk graphite, a common battery anode material, indicating the potential to utilize 2D heterostructures in thermal management applications and energy storage devices. Furthermore, the MLIP-based methodology provides a reliable approach for estimating the thermal conductivity of bilayers and heterostructures.},
  archive      = {J_AML},
  author       = {Nair, A. K. and Da Silva, C. M. and Amon, C. H.},
  doi          = {10.1063/5.0205702},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036115},
  shortjournal = {APL Mach. Learn.},
  title        = {Machine-learning-derived thermal conductivity of two-dimensional TiS2/MoS2 van der waals heterostructures},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-modality ghost diffraction in a complex disordered
environment using untrained neural networks. <em>AML</em>,
<em>2</em>(3), 036114. (<a
href="https://doi.org/10.1063/5.0222851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We report a dual-modality ghost diffraction (GD) system to simultaneously enable high-fidelity data transmission and high-resolution object reconstruction through complex disordered media using an untrained neural network (UNN) with only one set of realizations. The pixels of a 2D image to be transmitted are sequentially encoded into a series of random amplitude-only patterns using a UNN without labels and datasets. The series of random patterns generated is sequentially displayed to interact with an object placed in a designed optical system through complex disordered media. The realizations recorded at the receiving end are used to retrieve the transmitted data and reconstruct the object at the same time. The experimental results demonstrate that the proposed dual-modality GD system can robustly enable high-fidelity data transmission and high-resolution object reconstruction in a complex disordered environment. This could be a promising step toward the development of AI-driven compact optical systems with multiple modalities through complex disordered media.},
  archive      = {J_AML},
  author       = {Peng, Yang and Chen, Wen},
  doi          = {10.1063/5.0222851},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036114},
  shortjournal = {APL Mach. Learn.},
  title        = {Dual-modality ghost diffraction in a complex disordered environment using untrained neural networks},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dreaming of electrical waves: Generative modeling of cardiac
excitation waves using diffusion models. <em>AML</em>, <em>2</em>(3),
036113. (<a href="https://doi.org/10.1063/5.0194391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrical waves in the heart form rotating spiral or scroll waves during life-threatening arrhythmias, such as atrial or ventricular fibrillation. The wave dynamics are typically modeled using coupled partial differential equations, which describe reaction–diffusion dynamics in excitable media. More recently, data-driven generative modeling has emerged as an alternative to generate spatio-temporal patterns in physical and biological systems. Here, we explore denoising diffusion probabilistic models for the generative modeling of electrical wave patterns in cardiac tissue. We trained diffusion models with simulated electrical wave patterns to be able to generate such wave patterns in unconditional and conditional generation tasks. For instance, we explored the diffusion-based (i) parameter-specific generation, (ii) evolution, and (iii) inpainting of spiral wave dynamics, including reconstructing three-dimensional scroll wave dynamics from superficial two-dimensional measurements. Furthermore, we generated arbitrarily shaped bi-ventricular geometries and simultaneously initiated scroll wave patterns inside these geometries using diffusion. We characterized and compared the diffusion-generated solutions to solutions obtained with corresponding biophysical models and found that diffusion models learn to replicate spiral and scroll wave dynamics so well that they could be used for data-driven modeling of excitation waves in cardiac tissue. For instance, an ensemble of diffusion-generated spiral wave dynamics exhibits similar self-termination statistics as the corresponding ensemble simulated with a biophysical model. However, we also found that diffusion models produce artifacts if training data are lacking, e.g., during self-termination, and “hallucinate” wave patterns when insufficiently constrained.},
  archive      = {J_AML},
  author       = {Baranwal, Tanish and Lebert, Jan and Christoph, Jan},
  doi          = {10.1063/5.0194391},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036113},
  shortjournal = {APL Mach. Learn.},
  title        = {Dreaming of electrical waves: Generative modeling of cardiac excitation waves using diffusion models},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ionic species representations for materials informatics.
<em>AML</em>, <em>2</em>(3), 036112. (<a
href="https://doi.org/10.1063/5.0227009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional representations of the elements have become common within the field of materials informatics to build useful, structure-agnostic models for the chemistry of materials. However, the characteristics of elements change when they adopt a given oxidation state, with distinct structural preferences and physical properties. We explore several methods for developing embedding vectors of elements decorated with oxidation states. Graphs generated from 110 160 crystals are used to train representations of 84 elements that form 336 species. Clustering these learned representations of ionic species in low-dimensional space reproduces expected chemical heuristics, particularly the separation of cations from anions. We show that these representations have enhanced expressive power for property prediction tasks involving inorganic compounds. We expect that ionic representations, necessary for the description of mixed valence and complex magnetic systems, will support more powerful machine learning models for materials.},
  archive      = {J_AML},
  author       = {Onwuli, Anthony and Butler, Keith T. and Walsh, Aron},
  doi          = {10.1063/5.0227009},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036112},
  shortjournal = {APL Mach. Learn.},
  title        = {Ionic species representations for materials informatics},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A machine learning framework for quantum cascade laser
design. <em>AML</em>, <em>2</em>(3), 036111. (<a
href="https://doi.org/10.1063/5.0222812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-layer perceptron neural network was used to predict the laser transition figure of merit, a measure of the laser threshold gain, of over 900 × 10 6 Quantum Cascade (QC) laser designs using only layer thicknesses and the applied electric field as inputs. Designs were generated by randomly altering the layer thicknesses of an initial 10-layer design. Validating the predictions with our 1D Schrödinger solver, the predicted values show 5%–15% error for the laser structures, well within QC laser design variations. The algorithm (i) allowed for the identification of high figure of merit structures, (ii) recognized which layers should be altered to maximize the figure of merit at a given electric field, and (iii) increased the original design figure of merit of 94.7–141.2 eV ps Å 2 , a 1.5-fold improvement and significant for QC lasers. The computational time for laser design data collection is greatly reduced from 32 h for 27 000 designs using our 1D Schrödinger solver on a virtual machine, to 8 h for 907 × 10 6 designs using the machine learning algorithm on a laptop computer.},
  archive      = {J_AML},
  author       = {Correa Hernandez, Andres and Gmachl, Claire F.},
  doi          = {10.1063/5.0222812},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036111},
  shortjournal = {APL Mach. Learn.},
  title        = {A machine learning framework for quantum cascade laser design},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 3D–2D neural nets for phase retrieval in noisy
interferometric imaging. <em>AML</em>, <em>2</em>(3), 036110. (<a
href="https://doi.org/10.1063/5.0204212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, neural networks have been used to solve phase retrieval problems in imaging with superior accuracy and speed than traditional techniques, especially in the presence of noise. However, in the context of interferometric imaging, phase noise has been largely unaddressed by existing neural network architectures. Such noise arises naturally in an interferometer due to mechanical instabilities or atmospheric turbulence, limiting measurement acquisition times and posing a challenge in scenarios with limited light intensity, such as remote sensing. Here, we introduce a 3D–2D Phase Retrieval U-Net (PRUNe) that takes noisy and randomly phase-shifted interferograms as inputs and outputs a single 2D phase image. A 3D downsampling convolutional encoder captures correlations within and between frames to produce a 2D latent space, which is upsampled by a 2D decoder into a phase image. We test our model against a state-of-the-art singular value decomposition algorithm and find PRUNe reconstructions consistently show more accurate and smooth reconstructions, with a ×2.5–4 lower mean squared error at multiple signal-to-noise ratios for interferograms with low (&lt;1 photon/pixel) and high (∼100 photons/pixel) signal intensity. Our model presents a faster and more accurate approach to perform phase retrieval in extremely low light intensity interferometry in the presence of phase noise and will find application in other multi-frame noisy imaging techniques.},
  archive      = {J_AML},
  author       = {Proppe, Andrew H. and Thekkadath, Guillaume and England, Duncan and Bustard, Philip J. and Bouchard, Frédéric and Lundeen, Jeff S. and Sussman, Benjamin J.},
  doi          = {10.1063/5.0204212},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036110},
  shortjournal = {APL Mach. Learn.},
  title        = {3D–2D neural nets for phase retrieval in noisy interferometric imaging},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The impact of feature representation on the accuracy of
photonic neural networks. <em>AML</em>, <em>2</em>(3), 036109. (<a
href="https://doi.org/10.1063/5.0226172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photonic neural networks (PNNs) are gaining significant interest in the research community due to their potential for high parallelization, low latency, and energy efficiency. PNNs compute using light, which leads to several differences in implementation when compared to electronics, such as the need to represent input features in the photonic domain before feeding them into the network. In this encoding process, it is common to combine multiple features into a single input to reduce the number of inputs and associated devices, leading to smaller and more energy-efficient PNNs. Although this alters the network’s handling of input data, its impact on PNNs remains understudied. This paper addresses this open question, investigating the effect of commonly used encoding strategies that combine features on the performance and learning capabilities of PNNs. Here, using the concept of feature importance, we develop a mathematical methodology for analyzing feature combination. Through this methodology, we demonstrate that encoding multiple features together in a single input determines their relative importance, thus limiting the network’s ability to learn from the data. However, given some prior knowledge of the data, this can also be leveraged for higher accuracy. By selecting an optimal encoding method, we achieve up to a 12.3% improvement in the accuracy of PNNs trained on the Iris dataset compared to other encoding techniques, surpassing the performance of networks where features are not combined. These findings highlight the importance of carefully choosing the encoding to the accuracy and decision-making strategies of PNNs, particularly in size or power constrained applications.},
  archive      = {J_AML},
  author       = {Gomes de Queiroz, Mauricio and Jimenez, Paul and Cardoso, Raphael and Vidaletti Costa, Mateus and Abdalla, Mohab and O’Connor, Ian and Bosio, Alberto and Pavanello, Fabio},
  doi          = {10.1063/5.0226172},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036109},
  shortjournal = {APL Mach. Learn.},
  title        = {The impact of feature representation on the accuracy of photonic neural networks},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerating simulations of strained-film growth by deep
learning: Finite element method accuracy over long time scales.
<em>AML</em>, <em>2</em>(3), 036108. (<a
href="https://doi.org/10.1063/5.0221363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A convolutional neural network is trained on a large dataset of suitably randomized film profiles and corresponding elastic energy densities ɛ ρ ɛ ⁠ , computed by the finite element method. The trained model provides quantitative predictions of ɛ ρ ɛ for arbitrary profiles, surrogating its explicit calculation, and is used for the time integration of partial differential equations describing the evolution of strained films. The close match found between the neural network predictions and the “ground-truth” evolutions obtained by the finite element method calculation of ɛ ρ ɛ ⁠ , even after tens-of-thousands of integration time-steps, validates the approach. A substantial computational speed up without significant loss of accuracy is demonstrated, allowing for million-steps simulations of islands growth and coarsening. The intriguing possibility of extending the domain size is also discussed.},
  archive      = {J_AML},
  author       = {Lanzoni, Daniele and Rovaris, Fabrizio and Martín-Encinar, Luis and Fantasia, Andrea and Bergamaschini, Roberto and Montalenti, Francesco},
  doi          = {10.1063/5.0221363},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036108},
  shortjournal = {APL Mach. Learn.},
  title        = {Accelerating simulations of strained-film growth by deep learning: Finite element method accuracy over long time scales},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantum-tunneling deep neural network for optical illusion
recognition. <em>AML</em>, <em>2</em>(3), 036107. (<a
href="https://doi.org/10.1063/5.0225771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discovery of the quantum tunneling (QT) effect—the transmission of particles through a high potential barrier—was one of the most impressive achievements of quantum mechanics made in the 1920s. Responding to the contemporary challenges, I introduce a deep neural network (DNN) architecture that processes information using the effect of QT. I demonstrate the ability of QT-DNN to recognize optical illusions like a human. Tasking QT-DNN to simulate human perception of the Necker cube and Rubin’s vase, I provide arguments in favor of the superiority of QT-based activation functions over the activation functions optimized for modern applications in machine vision, also showing that, at the fundamental level, QT-DNN is closely related to biology-inspired DNNs and models based on the principles of quantum information processing.},
  archive      = {J_AML},
  author       = {Maksymov, Ivan S.},
  doi          = {10.1063/5.0225771},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036107},
  shortjournal = {APL Mach. Learn.},
  title        = {Quantum-tunneling deep neural network for optical illusion recognition},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sim2Real in reconstructive spectroscopy: Deep learning with
augmented device-informed data simulation. <em>AML</em>, <em>2</em>(3),
036106. (<a href="https://doi.org/10.1063/5.0209339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a deep learning (DL)-based framework, namely Sim2Real , for spectral signal reconstruction in reconstructive spectroscopy, focusing on efficient data sampling and fast inference time. The work focuses on the challenge of reconstructing real-world spectral signals in an extreme setting where only device-informed simulated data are available for training. Such device-informed simulated data are much easier to collect than real-world data but exhibit large distribution shifts from their real-world counterparts. To leverage such simulated data effectively, a hierarchical data augmentation strategy is introduced to mitigate the adverse effects of this domain shift, and a corresponding neural network for the spectral signal reconstruction with our augmented data is designed. Experiments using a real dataset measured from our spectrometer device demonstrate that Sim2Real achieves significant speed-up during the inference while attaining on-par performance with the state-of-the-art optimization-based methods.},
  archive      = {J_AML},
  author       = {Chen, Jiyi and Li, Pengyu and Wang, Yutong and Ku, Pei-Cheng and Qu, Qing},
  doi          = {10.1063/5.0209339},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036106},
  shortjournal = {APL Mach. Learn.},
  title        = {Sim2Real in reconstructive spectroscopy: Deep learning with augmented device-informed data simulation},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep-learning design of electronic metasurfaces in graphene
for quantum control and dirac electron holography. <em>AML</em>,
<em>2</em>(3), 036105. (<a
href="https://doi.org/10.1063/5.0216271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metasurfaces are sub-wavelength patterned layers for controlling waves in physical systems. In optics, metasurfaces are created by materials with different dielectric constants and are capable of unconventional functionalities. We develop a deep-learning framework for Dirac-material metasurface design for controlling electronic waves. The metasurface is a configuration of circular graphene quantum dots, each created by an electric potential. Employing deep convolutional neural networks, we show that the original scattering wave can be reconstructed with fidelity over 95%, suggesting the feasibility of Dirac electron holography. Additional applications such as plane wave generation and designing broadband and multi-functionality electronic metasurface in graphene are illustrated.},
  archive      = {J_AML},
  author       = {Han, Chen-Di and Ye, Li-Li and Lin, Zin and Kovanis, Vassilios and Lai, Ying-Cheng},
  doi          = {10.1063/5.0216271},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036105},
  shortjournal = {APL Mach. Learn.},
  title        = {Deep-learning design of electronic metasurfaces in graphene for quantum control and dirac electron holography},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Determining the density and spatial descriptors of atomic
scale defects of 2H–WSe2 with ensemble deep learning. <em>AML</em>,
<em>2</em>(3), 036104. (<a
href="https://doi.org/10.1063/5.0195116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have demonstrated atomic-scale defect characterization in scanning tunneling microscopy images of single crystal tungsten diselenide using an ensemble of U-Net-like convolutional neural networks. Coordinates, counts, densities, and spatial extents were determined from almost 16 000 defect detections, leading to the rapid identification of defect types and their densities. Our results show that analysis aided by machine learning can be used to rapidly determine the quality of transition metal dichalcogenides and provide much needed quantitative input, which may improve the synthesis process.},
  archive      = {J_AML},
  author       = {Smalley, Darian and Lough, Stephanie D. and Holtzman, Luke N. and Holbrook, Madisen and Hone, James C. and Barmak, Katayun and Ishigami, Masahiro},
  doi          = {10.1063/5.0195116},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036104},
  shortjournal = {APL Mach. Learn.},
  title        = {Determining the density and spatial descriptors of atomic scale defects of 2H–WSe2 with ensemble deep learning},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine-learning nowcasting of the atlantic meridional
overturning circulation. <em>AML</em>, <em>2</em>(3), 036103. (<a
href="https://doi.org/10.1063/5.0207539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Atlantic Meridional Overturning Circulation (AMOC) is a significant component of the global ocean system, which has so far ensured a relatively warm climate for the North Atlantic and mild conditions in regions, such as Western Europe. The AMOC is also critical for the global climate. The complexity of the dynamical system underlying the AMOC is so vast that a long-term assessment of the potential risk of AMOC collapse is extremely challenging. However, short-term prediction can lead to accurate estimates of the dynamical state of the AMOC and possibly to early warning signals for guiding policy making and control strategies toward preventing AMOC collapse in the long term. We develop a model-free, machine-learning framework to predict the AMOC dynamical state in the short term by employing five datasets: MOVE and RAPID (observational), AMOC fingerprint (proxy records), and AMOC simulated fingerprint and CESM AMOC (synthetic). We demonstrate the power of our framework in predicting the variability of the AMOC within the maximum prediction horizon of 12 or 24 months. A number of issues affecting the prediction performance are investigated.},
  archive      = {J_AML},
  author       = {Zhai, Zheng-Meng and Moradi, Mohammadamin and Panahi, Shirin and Wang, Zhi-Hua and Lai, Ying-Cheng},
  doi          = {10.1063/5.0207539},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036103},
  shortjournal = {APL Mach. Learn.},
  title        = {Machine-learning nowcasting of the atlantic meridional overturning circulation},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computational experiments with cellular-automata generated
images reveal intrinsic limitations of convolutional neural networks on
pattern recognition tasks. <em>AML</em>, <em>2</em>(3), 036102. (<a
href="https://doi.org/10.1063/5.0213905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extraordinary success of convolutional neural networks (CNNs) in various computer vision tasks has revitalized the field of artificial intelligence. The out-sized expectations created by this extraordinary success have, however, been tempered by a recognition of CNNs’ fragility. Importantly, the magnitude of the problem is unclear due to a lack of rigorous benchmark datasets. Here, we propose a solution to the benchmarking problem that reveals the extent of the vulnerabilities of CNNs and of the methods used to provide interpretability to their predictions. We employ cellular automata (CA) to generate images with rigorously controllable characteristics. CA allow for the definition of both extraordinarily simple and highly complex discrete functions and allow for the generation of boundless datasets of images without repeats. In this work, we systematically investigate the fragility and interpretability of the three popular CNN architectures using CA-generated datasets. We find a sharp transition from a learnable phase to an unlearnable phase as the latent space entropy of the discrete CA functions increases. Furthermore, we demonstrate that shortcut learning is an inherent trait of CNNs. Given a dataset with an easy-to-learn and strongly predictive pattern, CNN will consistently learn the shortcut even if the pattern occurs only on a small fraction of the image. Finally, we show that widely used attribution methods aiming to add interpretability to CNN outputs are strongly CNN-architecture specific and vary widely in their ability to identify input regions of high importance to the model. Our results provide significant insight into the limitations of both CNNs and the approaches developed to add interpretability to their predictions and raise concerns about the types of tasks that should be entrusted to them.},
  archive      = {J_AML},
  author       = {Lei, Weihua and Zanchettin, Cleber and Santos, Flávio A. O. and Nunes Amaral, Luís A.},
  doi          = {10.1063/5.0213905},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036102},
  shortjournal = {APL Mach. Learn.},
  title        = {Computational experiments with cellular-automata generated images reveal intrinsic limitations of convolutional neural networks on pattern recognition tasks},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain wall and magnetic tunnel junction hybrid for on-chip
learning in UNet architecture. <em>AML</em>, <em>2</em>(3), 036101. (<a
href="https://doi.org/10.1063/5.0214042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a spintronic device based hardware implementation of UNet for segmentation tasks. Our approach involves designing hardware for convolution, deconvolution, rectified activation function (ReLU), and max pooling layers of the UNet architecture. We designed the convolution and deconvolution layers of the network using the synaptic behavior of the domain wall MTJ. We also construct the ReLU and max pooling functions of the network utilizing the spin hall driven orthogonal current injected MTJ. To incorporate the diverse physics of spin-transport, magnetization dynamics, and CMOS elements in our UNet design, we employ a hybrid simulation setup that couples micromagnetic simulation, non-equilibrium Green’s function, and SPICE simulation along with network implementation. We evaluate our UNet design on the CamVid dataset and achieve segmentation accuracies of 83.71% on test data, on par with the software implementation with 821 mJ of energy consumption for on-chip training over 150 epochs. We further demonstrate nearly one order of magnitude (10×) improvement in the energy requirement of the network using unstable ferromagnet (Δ = 4.58) over the stable ferromagnet (Δ = 45) based ReLU and max pooling functions while maintaining similar accuracy. The hybrid architecture comprising domain wall MTJ and unstable FM-based MTJ leads to an on-chip energy consumption of 85.79 mJ during training, with a testing energy cost of 1.55 µ J.},
  archive      = {J_AML},
  author       = {Vadde, Venkatesh and Muralidharan, Bhaskaran and Sharma, Abhishek},
  doi          = {10.1063/5.0214042},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036101},
  shortjournal = {APL Mach. Learn.},
  title        = {Domain wall and magnetic tunnel junction hybrid for on-chip learning in UNet architecture},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tutorials: Physics-informed machine learning methods of
computing 1D phase-field models. <em>AML</em>, <em>2</em>(3), 031101.
(<a href="https://doi.org/10.1063/5.0205159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phase-field models are widely used to describe phase transitions and interface evolution in various scientific disciplines. In this Tutorial, we present two neural network methods for solving them. The first method is based on physics-informed neural networks (PINNs), which enforce the governing equations and boundary/initial conditions in the loss function. The second method is based on deep operator neural networks (DeepONets), which treat the neural network as an operator that maps the current state of the field variable to the next state. Both methods are demonstrated with the Allen–Cahn equation in one dimension, and the results are compared with the ground truth. This Tutorial also discusses the advantages and limitations of each method, as well as the potential extensions and improvements.},
  archive      = {J_AML},
  author       = {Li, Wei and Fang, Ruqing and Jiao, Junning and Vassilakis, Georgios N. and Zhu, Juner},
  doi          = {10.1063/5.0205159},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {031101},
  shortjournal = {APL Mach. Learn.},
  title        = {Tutorials: Physics-informed machine learning methods of computing 1D phase-field models},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Webinar recap: Fostering a new data culture with APL machine
learning. <em>AML</em>, <em>2</em>(3), 030401. (<a
href="https://doi.org/10.1063/5.0230221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AML},
  author       = {Eshraghian, Jason and Ding, Jennifer and Muilenburg, Jennifer and Mehonic, Adnan},
  doi          = {10.1063/5.0230221},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {030401},
  shortjournal = {APL Mach. Learn.},
  title        = {Webinar recap: Fostering a new data culture with APL machine learning},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Erratum: “Improved prediction for failure time of multilayer
ceramic capacitors (MLCCs): A physics-based machine learning approach”
[APL mach. Learn. 1, 036107 (2023)]. <em>AML</em>, <em>2</em>(2),
029901. (<a href="https://doi.org/10.1063/5.0221988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AML},
  author       = {Yousefian, Pedram and Sepehrinezhad, Alireza and van Duin, Adri C. T. and Randall, Clive A.},
  doi          = {10.1063/5.0221988},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {029901},
  shortjournal = {APL Mach. Learn.},
  title        = {Erratum: “Improved prediction for failure time of multilayer ceramic capacitors (MLCCs): a physics-based machine learning approach” [APL mach. learn. 1, 036107 (2023)]},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Waveform retrieval for ultrafast applications based on
convolutional neural networks. <em>AML</em>, <em>2</em>(2), 026124. (<a
href="https://doi.org/10.1063/5.0173933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric field waveforms of light carry rich information about dynamical events on a broad range of timescales. The insight that can be reached from their analysis, however, depends on the accuracy of retrieval from noisy data. In this article, we present a novel approach for waveform retrieval based on supervised deep learning. We demonstrate the performance of our model by comparison with conventional denoising approaches, including wavelet transform and Wiener filtering. The model leverages the enhanced precision obtained from the nonlinearity of deep learning. The results open a path toward an improved understanding of physical and chemical phenomena in field-resolved spectroscopy.},
  archive      = {J_AML},
  author       = {Altwaijry, Najd and Coffee, Ryan and Kling, Matthias F.},
  doi          = {10.1063/5.0173933},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026124},
  shortjournal = {APL Mach. Learn.},
  title        = {Waveform retrieval for ultrafast applications based on convolutional neural networks},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constructing coarse-grained models with physics-guided
gaussian process regression. <em>AML</em>, <em>2</em>(2), 026123. (<a
href="https://doi.org/10.1063/5.0190357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coarse-grained models describe the macroscopic mean response of a process at large scales, which derives from stochastic processes at small scales. Common examples include accounting for velocity fluctuations in a turbulent fluid flow model and cloud evolution in climate models. Most existing techniques for constructing coarse-grained models feature ill-defined parameters whose values are arbitrarily chosen (e.g., a window size), are narrow in their applicability (e.g., only applicable to time series or spatial data), or cannot readily incorporate physics information. Here, we introduce the concept of physics-guided Gaussian process regression as a machine-learning-based coarse-graining technique that is broadly applicable and amenable to input from known physics-based relationships. Using a pair of case studies derived from molecular dynamics simulations, we demonstrate the attractive properties and superior performance of physics-guided Gaussian processes for coarse-graining relative to prevalent benchmarks. The key advantage of Gaussian-process-based coarse-graining is its ability to seamlessly integrate data-driven and physics-based information.},
  archive      = {J_AML},
  author       = {Fang, Yating and Zhao, Qian Qian and Sills, Ryan B. and Ezzat, Ahmed Aziz},
  doi          = {10.1063/5.0190357},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026123},
  shortjournal = {APL Mach. Learn.},
  title        = {Constructing coarse-grained models with physics-guided gaussian process regression},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Programmable superconducting optoelectronic single-photon
synapses with integrated multi-state memory. <em>AML</em>,
<em>2</em>(2), 026122. (<a
href="https://doi.org/10.1063/5.0204469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The co-location of memory and processing is a core principle of neuromorphic computing. A local memory device for synaptic weight storage has long been recognized as an enabling element for large-scale, high-performance neuromorphic hardware. In this work, we demonstrate programmable superconducting synapses with integrated memories for use in superconducting optoelectronic neural systems. Superconducting nanowire single-photon detectors and Josephson junctions are combined into programmable synaptic circuits that exhibit single-photon sensitivity, memory cells with more than 400 internal states, leaky integration of input spike events, and 0.4 fJ programming energies (including cooling power). These results are attractive for implementing a variety of supervised and unsupervised learning algorithms and lay the foundation for a new hardware platform optimized for large-scale spiking network accelerators.},
  archive      = {J_AML},
  author       = {Primavera, Bryce A. and Khan, Saeed and Mirin, Richard P. and Nam, Sae Woo and Shainline, Jeffrey M.},
  doi          = {10.1063/5.0204469},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026122},
  shortjournal = {APL Mach. Learn.},
  title        = {Programmable superconducting optoelectronic single-photon synapses with integrated multi-state memory},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heterogeneous reinforcement learning for defending power
grids against attacks. <em>AML</em>, <em>2</em>(2), 026121. (<a
href="https://doi.org/10.1063/5.0216874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) has been employed to devise the best course of actions in defending the critical infrastructures, such as power networks against cyberattacks. Nonetheless, even in the case of the smallest power grids, the action space of RL experiences exponential growth, rendering efficient exploration by the RL agent practically unattainable. The current RL algorithms tailored to power grids are generally not suited when the state-action space size becomes large, despite trade-offs. We address the large action-space problem for power grid security by exploiting temporal graph convolutional neural networks (TGCNs) to develop a parallel but heterogeneous RL framework. In particular, we divide the action space into smaller subspaces, each explored by an RL agent. How to efficiently organize the spatiotemporal action sequences then becomes a great challenge. We invoke TGCN to meet this challenge by accurately predicting the performance of each individual RL agent in the event of an attack. The top performing agent is selected, resulting in the optimal sequence of actions. First, we investigate the action-space size comparison for IEEE 5-bus and 14-bus systems. Furthermore, we use IEEE 14-bus and IEEE 118-bus systems coupled with the Grid2Op platform to illustrate the performance and action division influence on training times and grid survival rates using both deep Q-learning and Soft Actor Critic trained agents and Grid2Op default greedy agents. Our TGCN framework provides a computationally reasonable approach for generating the best course of actions to defend cyber physical systems against attacks.},
  archive      = {J_AML},
  author       = {Moradi, Mohammadamin and Panahi, Shirin and Zhai, Zheng-Meng and Weng, Yang and Dirkman, John and Lai, Ying-Cheng},
  doi          = {10.1063/5.0216874},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026121},
  shortjournal = {APL Mach. Learn.},
  title        = {Heterogeneous reinforcement learning for defending power grids against attacks},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simulation-trained machine learning models for lorentz
transmission electron microscopy. <em>AML</em>, <em>2</em>(2), 026120.
(<a href="https://doi.org/10.1063/5.0197138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the collective behavior of complex spin textures, such as lattices of magnetic skyrmions, is of fundamental importance for exploring and controlling the emergent ordering of these spin textures and inducing phase transitions. It is also critical to understand the skyrmion–skyrmion interactions for applications such as magnetic skyrmion-enabled reservoir or neuromorphic computing. Magnetic skyrmion lattices can be studied using in situ Lorentz transmission electron microscopy (LTEM), but quantitative and statistically robust analysis of the skyrmion lattices from LTEM images can be difficult. In this work, we show that a convolutional neural network, trained on simulated data, can be applied to perform segmentation of spin textures and to extract quantitative data, such as spin texture size and location, from experimental LTEM images, which cannot be obtained manually. This includes quantitative information about skyrmion size, position, and shape, which can, in turn, be used to calculate skyrmion–skyrmion interactions and lattice ordering. We apply this approach to segmenting images of Néel skyrmion lattices so that we can accurately identify skyrmion size and deformation in both dense and sparse lattices. The model is trained using a large set of micromagnetic simulations as well as simulated LTEM images. This entirely open-source training pipeline can be applied to a wide variety of magnetic features and materials, enabling large-scale statistical studies of spin textures using LTEM.},
  archive      = {J_AML},
  author       = {McCray, Arthur R. C. and Bender, Alec and Petford-Long, Amanda and Phatak, Charudatta},
  doi          = {10.1063/5.0197138},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026120},
  shortjournal = {APL Mach. Learn.},
  title        = {Simulation-trained machine learning models for lorentz transmission electron microscopy},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). X-LoRA: Mixture of low-rank adapter experts, a flexible
framework for large language models with applications in protein
mechanics and molecular design. <em>AML</em>, <em>2</em>(2), 026119. (<a
href="https://doi.org/10.1063/5.0203126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We report a mixture of expert strategy to create fine-tuned large language models using a deep layer-wise token-level approach based on low-rank adaptation (LoRA). Starting with a set of pre-trained LoRA adapters, our gating strategy uses the hidden states to dynamically mix adapted layers, allowing the resulting X-LoRA model to draw upon different capabilities and create never-before-used deep layer-wise combinations to solve tasks. The design is inspired by the biological principles of universality and diversity, where neural network building blocks are reused in different hierarchical manifestations. Hence, the X-LoRA model can be easily implemented for any existing large language model without a need for modifications of the underlying structure. We develop a tailored X-LoRA model that offers scientific capabilities, including forward/inverse analysis tasks and enhanced reasoning capability, focused on biomaterial analysis, protein mechanics, and design. The impact of this work includes access to readily expandable and adaptable models with strong domain knowledge and the capability to integrate across areas of knowledge. Featuring experts in biology, mathematics, reasoning, bio-inspired materials, mechanics and materials, chemistry, protein biophysics, mechanics, and quantum-mechanics based molecular properties, we conduct a series of physics-focused case studies. We examine knowledge recall, protein mechanics forward/inverse tasks, protein design, adversarial agentic modeling including ontological knowledge graph construction, and molecular design. The model is capable not only of making quantitative predictions of nanomechanical properties of proteins or quantum mechanical molecular properties but also reasoning over the results and correctly predicting likely mechanisms that explain distinct molecular behaviors.},
  archive      = {J_AML},
  author       = {Buehler, Eric L. and Buehler, Markus J.},
  doi          = {10.1063/5.0203126},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026119},
  shortjournal = {APL Mach. Learn.},
  title        = {X-LoRA: Mixture of low-rank adapter experts, a flexible framework for large language models with applications in protein mechanics and molecular design},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced spectrum prediction using deep learning models with
multi-frequency supplementary inputs. <em>AML</em>, <em>2</em>(2),
026118. (<a href="https://doi.org/10.1063/5.0203931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the rapid progress of deep learning techniques has brought unprecedented transformations and innovations across various fields. While neural network-based approaches can effectively encode data and detect underlying patterns of features, the diverse formats and compositions of data in different fields pose challenges in effectively utilizing these data, especially for certain research fields in the early stages of integrating deep learning. Therefore, it is crucial to find more efficient ways to utilize existing datasets. Here, we demonstrate that the predictive accuracy of the network can be improved dramatically by simply adding supplementary multi-frequency inputs to the existing dataset in the target spectrum predicting process. This design methodology paves the way for interdisciplinary research and applications at the interface of deep learning and other fields, such as photonics, composite material design, and biological medicine.},
  archive      = {J_AML},
  author       = {Xing, Xiaohua and Ren, Yuqi and Zou, Die and Zhang, Qiankun and Mao, Bingxuan and Yao, Jianquan and Xiong, Deyi and Wu, Liang},
  doi          = {10.1063/5.0203931},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026118},
  shortjournal = {APL Mach. Learn.},
  title        = {Enhanced spectrum prediction using deep learning models with multi-frequency supplementary inputs},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cell detection with convolutional spiking neural network for
neuromorphic cytometry. <em>AML</em>, <em>2</em>(2), 026117. (<a
href="https://doi.org/10.1063/5.0199514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imaging flow cytometry (IFC) is an advanced cell-analytic technology offering rich spatial information and fluorescence intensity for multi-parametric characterization. Manual gating in cytometry data enables the classification of discrete populations from the sample based on extracted features. However, this expert-driven technique can be subjective and laborious, often presenting challenges in reproducibility and being inherently limited to bivariate analysis. Numerous AI-driven cell classifications have recently emerged to automate the process of including multivariate data with enhanced reproducibility and accuracy. Our previous work demonstrated the early development of neuromorphic imaging cytometry, evaluating its feasibility in resolving conventional frame-based imaging systems’ limitations in data redundancy, fluorescence sensitivity, and compromised throughput. Herein, we adopted a convolutional spiking neural network (SNN) combined with the YOLOv3 model (SNN-YOLO) to perform cell classification and detection on label-free samples under neuromorphic vision. Spiking techniques are inherently suitable post-processing techniques for neuromorphic vision sensing. The experiment was conducted with polystyrene-based microparticles, THP-1, and LL/2 cell lines. The network’s performance was compared with that of a traditional YOLOv3 model fed with event-generated frame data to serve as a baseline. In this work, our SNN-YOLO outperformed the YOLOv3 baseline by achieving the highest average class accuracy of 0.974, compared to 0.962 for YOLOv3. Both models reported comparable performances across other key metrics and should be further explored for future auto-gating strategies and cytometry applications.},
  archive      = {J_AML},
  author       = {Zhang, Ziyao and Yang, Haoxiang and Eshraghian, Jason K. and Li, Jiayin and Yong, Ken-Tye and Vigolo, Daniele and McGuire, Helen M. and Kavehei, Omid},
  doi          = {10.1063/5.0199514},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026117},
  shortjournal = {APL Mach. Learn.},
  title        = {Cell detection with convolutional spiking neural network for neuromorphic cytometry},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The development of thermodynamically consistent and
physics-informed equation-of-state model through machine learning.
<em>AML</em>, <em>2</em>(2), 026116. (<a
href="https://doi.org/10.1063/5.0192447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ab initio molecular dynamics (AIMD) simulations have become an important tool used in the construction of equations of state (EOS) tables for warm dense matter. Due to computational costs, only a limited number of system state conditions can be simulated, and the remaining EOS surface must be interpolated for use in radiation-hydrodynamic simulations of experiments. In this work, we develop a thermodynamically consistent EOS model that utilizes a physics-informed machine learning approach to implicitly learn the underlying Helmholtz free-energy from AIMD generated energies and pressures. The model, referred to as PIML-EOS, was trained and tested on warm dense polystyrene producing a fit within a 1% relative error for both energy and pressure and is shown to satisfy both the Maxwell and Gibbs–Duhem relations. In addition, we provide a path toward obtaining thermodynamic quantities, such as the total entropy and chemical potential (containing both ionic and electronic contributions), which are not available from current AIMD simulations.},
  archive      = {J_AML},
  author       = {Hinz, J. and Yu, Dayou and Pandey, Deep Shankar and Sapkota, Hitesh and Yu, Qi and Mihaylov, D. I. and Karasiev, V. V. and Hu, S. X.},
  doi          = {10.1063/5.0192447},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026116},
  shortjournal = {APL Mach. Learn.},
  title        = {The development of thermodynamically consistent and physics-informed equation-of-state model through machine learning},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simulating CO2 diffusivity in rigid and flexible mg-MOF-74
with machine-learning force fields. <em>AML</em>, <em>2</em>(2), 026115.
(<a href="https://doi.org/10.1063/5.0190372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flexibility of metal–organic frameworks (MOFs) affects their gas adsorption and diffusion properties. However, reliable force fields for simulating flexible MOFs are lacking. As a result, most atomistic simulations so far have been carried out assuming rigid MOFs, which inevitably overestimates the gas adsorption energy. Here, we show that this issue can be addressed by applying a machine-learning potential, trained on quantum chemistry data, to atomistic simulations. We find that inclusion of flexibility is particularly important for simulating CO 2 chemisorption in MOFs with coordinatively unsaturated metal sites. Specifically, we demonstrate that the diffusion of CO 2 in a flexible Mg-MOF-74 structure is about one order of magnitude faster than in a rigid one, challenging the rigid-MOF assumption in previous simulations.},
  archive      = {J_AML},
  author       = {Zheng, Bowen and Gu, Grace X. and Santos, Carine dos and Neumann Barros Ferreira, Rodrigo and Steiner, Mathias and Luan, Binquan},
  doi          = {10.1063/5.0190372},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026115},
  shortjournal = {APL Mach. Learn.},
  title        = {Simulating CO2 diffusivity in rigid and flexible mg-MOF-74 with machine-learning force fields},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Biological plausible algorithm for seizure detection: Toward
AI-enabled electroceuticals at the edge. <em>AML</em>, <em>2</em>(2),
026114. (<a href="https://doi.org/10.1063/5.0192875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nearly 1% of people worldwide suffer from epilepsy. Electroencephalogram (EEG)-based diagnostics and monitoring tools, such as scalp EEG, subscalp EEG, stereo EEG, or sub/epi-dural EEG recordings [also known as electrocorticography (ECoG)], are widely used in different settings as the gold standard techniques to perform seizure identification, localization, and more primarily in epilepsy or suspected epilepsy in patients. Techniques such as subscalp EEG and ECoG offer long-term brain interaction, potentially replacing traditional electroceuticals with smart closed-loop therapies. However, these systems require continuous on-device training due to real-time demands and high power consumption. Inspired by the brain architecture, biologically plausible algorithms, such as some neuromorphic computing, show promise in addressing these challenges. In our research, we utilized liquid time-constant spiking neural networks with forward propagation through time to detect seizures in scalp-EEG. We trained and validated our model on the Temple University Hospital dataset and tested its generalization on out-of-sample data from the Royal Prince Alfred Hospital (RPAH) and EPILEPSIAE datasets. Our model achieved high area under the receiver operating characteristic curve (AUROC) scores of 0.83 in both datasets. We assessed the robustness by decreasing the memory size by 90% and obtained an overall AUROC of 0.82 in the RPAH dataset and 0.83 in the EPILEPSIAE dataset. Our model showed outstanding results of 3.1 μ J power consumption per inference and a 20% firing rate during training. This allows for incorporating bio-inspired efficient algorithms for on-device training, tackling challenges such as memory, power consumption, and efficiency.},
  archive      = {J_AML},
  author       = {Herbozo Contreras, Luis Fernando and Huang, Zhaojing and Yu, Leping and Nikpour, Armin and Kavehei, Omid},
  doi          = {10.1063/5.0192875},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026114},
  shortjournal = {APL Mach. Learn.},
  title        = {Biological plausible algorithm for seizure detection: Toward AI-enabled electroceuticals at the edge},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AlGaN/GaN MOS-HEMT enabled optoelectronic artificial
synaptic devices for neuromorphic computing. <em>AML</em>,
<em>2</em>(2), 026113. (<a
href="https://doi.org/10.1063/5.0194083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial optoelectronic synaptic transistors have attracted extensive research interest as an essential component for neuromorphic computing systems and brain emulation applications. However, performance challenges still remain for synaptic devices, including low energy consumption, high integration density, and flexible modulation. Employing trapping and detrapping relaxation, a novel optically stimulated synaptic transistor enabled by the AlGaN/GaN hetero-structure metal-oxide semiconductor high-electron-mobility transistor has been successfully demonstrated in this study. Synaptic functions, including excitatory postsynaptic current (EPSC), paired-pulse facilitation index, and transition from short-term memory to long-term memory, are well mimicked and explicitly investigated. In a single EPSC event, the AlGaN/GaN synaptic transistor shows the characteristics of low energy consumption and a high signal-to-noise ratio. The EPSC of the synaptic transistor can be synergistically modulated by both optical stimulation and gate/drain bias. Moreover, utilizing a convolution neural network, hand-written digit images were used to verify the data preprocessing capability for neuromorphic computing applications.},
  archive      = {J_AML},
  author       = {Chen, Jiaxiang and Du, Haitao and Qu, Haolan and Gao, Han and Gu, Yitian and Zhu, Yitai and Ye, Wenbo and Zou, Jun and Wang, Hongzhi and Zou, Xinbo},
  doi          = {10.1063/5.0194083},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026113},
  shortjournal = {APL Mach. Learn.},
  title        = {AlGaN/GaN MOS-HEMT enabled optoelectronic artificial synaptic devices for neuromorphic computing},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cardiac abnormality detection with a tiny diagonal state
space model based on sequential liquid neural processing unit.
<em>AML</em>, <em>2</em>(2), 026112. (<a
href="https://doi.org/10.1063/5.0191574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript introduces a novel method for cardiac abnormality detection by combining the Diagonal State Space Sequence (S4D) model with the Closed-form Continuous-time neural network (CfC), yielding a highly effective, robust, generalizable, and compact solution. Our proposed S4D-CfC model is evaluated on 12- and single-lead electrocardiogram data from over 20 000 patients. The system exhibits validation results with strong average F1 score and average area under the receiver operating characteristic curve values of 0.88% and 98%, respectively. To demonstrate the tiny machine learning of our 242 KB size model, we deployed the system on relatively resource-constrained hardware to evaluate its training performance on-the-edge. Such on-device fine-tuning can enhance personalized solutions in this context, allowing the system to learn each patient’s data features. A comparison with a structured 2D convolutional long short-term memory CfC model demonstrates the S4D-CfC model’s superior performance. The proposed model’s size can be significantly reduced to 25 KB, maintaining reasonable performance on 2.5 s data, 75% shorter than the original 10 s data, making it suitable for resource-constrained hardware and minimizing latency. In summary, the S4D-CfC model represents a groundbreaking advancement in cardiac abnormality detection, offering robustness, generalization, and practicality with the potential for efficient deployment on limited-resource platforms, revolutionizing healthcare technology.},
  archive      = {J_AML},
  author       = {Huang, Zhaojing and Leung, Wing Hang and Cui, Jiashuo and Yu, Leping and Herbozo Contreras, Luis Fernando and Truong, Nhan Duy and Nikpour, Armin and Kavehei, Omid},
  doi          = {10.1063/5.0191574},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026112},
  shortjournal = {APL Mach. Learn.},
  title        = {Cardiac abnormality detection with a tiny diagonal state space model based on sequential liquid neural processing unit},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring the optimal design space of transparent perovskite
solar cells for four-terminal tandem applications through pareto front
optimization. <em>AML</em>, <em>2</em>(2), 026111. (<a
href="https://doi.org/10.1063/5.0187208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning algorithms can enhance the design and experimental processing of solar cells, resulting in increased conversion efficiency. In this study, we introduce a novel machine learning-based methodology for optimizing the Pareto front of four-terminal (4T) perovskite-copper indium selenide (CIS) tandem solar cells (TSCs). By training a neural network using the Bayesian regularization-backpropagation algorithm via Hammersley sampling, we achieve high prediction accuracy when testing with unseen data through random sampling. This surrogate model not only reduces computational costs but also potentially enhances device performance, increasing from 29.4% to 30.4% while simultaneously reducing material costs for fabrication by 50%. Comparing experimentally fabricated cells with the predicted optimal cells, the latter show a thinner front contact electrode, charge-carrier transport layer, and back contact electrode. Highly efficient perovskite cells identified from the Pareto front have a perovskite layer thickness ranging from 420 to 580 nm. Further analysis reveals the front contact electrode needs to be thin, while the back contact electrode can have a thickness ranging from 100 to 145 nm and still achieve high efficiency. The charge-carrier transport layers play a crucial role in minimizing interface recombination and ensuring unidirectional current flow. The optimal design space suggests thinner electron and hole transport layer thicknesses of 7 nm, down from 23 to 10 nm, respectively. It indicates a balanced charge-carrier extraction is crucial for an optimized perovskite cell. Overall, the presented methodology and optimized design parameters have the potential to enhance the performance of 4T perovskite/CIS TSC while reducing material fabrication costs.},
  archive      = {J_AML},
  author       = {Tan, Hu Quee and Zhao, Xinhai and Ambardekar, Akhil and Birgersson, Erik and Xue, Hansong},
  doi          = {10.1063/5.0187208},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026111},
  shortjournal = {APL Mach. Learn.},
  title        = {Exploring the optimal design space of transparent perovskite solar cells for four-terminal tandem applications through pareto front optimization},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visual explanations of machine learning model estimating
charge states in quantum dots. <em>AML</em>, <em>2</em>(2), 026110. (<a
href="https://doi.org/10.1063/5.0193621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Charge state recognition in quantum dot devices is important in the preparation of quantum bits for quantum information processing. Toward auto-tuning of larger-scale quantum devices, automatic charge state recognition by machine learning has been demonstrated. For further development of this technology, an understanding of the operation of the machine learning model, which is usually a black box, will be useful. In this study, we analyze the explainability of the machine learning model estimating charge states in quantum dots by gradient weighted class activation mapping. This technique highlights the important regions in the image for predicting the class. The model predicts the state based on the change transition lines, indicating that human-like recognition is realized. We also demonstrate improvements of the model by utilizing feedback from the mapping results. Due to the simplicity of our simulation and pre-processing methods, our approach offers scalability without significant additional simulation costs, demonstrating its suitability for future quantum dot system expansions.},
  archive      = {J_AML},
  author       = {Muto, Yui and Nakaso, Takumi and Shinozaki, Motoya and Aizawa, Takumi and Kitada, Takahito and Nakajima, Takashi and Delbecq, Matthieu R. and Yoneda, Jun and Takeda, Kenta and Noiri, Akito and Ludwig, Arne and Wieck, Andreas D. and Tarucha, Seigo and Kanemura, Atsunori and Shiga, Motoki and Otsuka, Tomohiro},
  doi          = {10.1063/5.0193621},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026110},
  shortjournal = {APL Mach. Learn.},
  title        = {Visual explanations of machine learning model estimating charge states in quantum dots},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On-device edge-learning for cardiac abnormality detection
using a bio-inspired and spiking shallow network. <em>AML</em>,
<em>2</em>(2), 026109. (<a
href="https://doi.org/10.1063/5.0191571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces on-device edge learning for cardiac abnormality detection by merging spiking 2D Convolutional Long-Short-Term Memory (ConvLSTM2D) with a bio-inspired shallow neural network, referred to as Closed-form Continuous-time (CfC), to form the sCCfC model. The model achieves an F1 score and AUROC of 0.82 and 0.91 in cardiac abnormalities detection. These results are comparable to the non-spiking ConvLSTM2D–CfC (ConvCfC) model [Huang et al. , J. Cardiovasc. Transl. Res. (published online, 2024)]. Notably, the sCCfC model demonstrates a significantly higher energy efficiency with an estimated power consumption of 4.68 μ J/Inf (per inference) on an emulated Loihi’s neuromorphic chip architecture, in contrast to ConvCfC model’s consumption of 450 μ J/Inf on a conventional processor. In addition, as a proof-of-concept, we deployed the sCCfC model on the conventional and relatively resource-constrained Radxa Zero, which is equipped with an Amlogic S905Y2 processor for on-device training , which resulted in performance improvements. After initial training of two epochs on a conventional Graphics Processing Unit, the F1 score and AUROC improved from 0.46 and 0.65 to 0.56 and 0.73, respectively, with five additional epochs of on-device training. Furthermore, when presented with a new dataset, the sCCfC model showcases strong out-of-sample generalization capabilities that can constitute a pseudo-perspective test, achieving an F1 score and AUROC of 0.71 and 0.86, respectively. The spiking sCCfC also outperforms the non-spiking ConvCfC model in robustness regarding effectively handling missing electrocardiogram (ECG) channels during inference. The model’s efficacy extends to single-lead ECG analysis, demonstrating reasonable accuracy in this context, while the focus of our work has been on the computational and memory complexities of the model.},
  archive      = {J_AML},
  author       = {Huang, Zhaojing and Leung, Wing Hang and Yu, Leping and Herbozo Contreras, Luis Fernando and Zhang, Ziyao and Truong, Nhan Duy and Nikpour, Armin and Kavehei, Omid},
  doi          = {10.1063/5.0191571},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026109},
  shortjournal = {APL Mach. Learn.},
  title        = {On-device edge-learning for cardiac abnormality detection using a bio-inspired and spiking shallow network},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised learning of shedding droplet dynamics during
steam condensation. <em>AML</em>, <em>2</em>(2), 026108. (<a
href="https://doi.org/10.1063/5.0188620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge of condensate shedding droplet dynamics provides important information for the characterization of two-phase heat and mass transfer phenomena. Detecting and segmenting the droplets during shedding requires considerable time and effort if performed manually. Here, we developed a self-supervised deep learning model for segmenting shedding droplets from a variety of dropwise and filmwise condensing surfaces. The model eliminates the need for image annotation by humans in the training step and, therefore, reduces labor significantly. The trained model achieved an average accuracy greater than 0.9 on a new unseen test dataset. After extracting the shedding droplet size and speed, we developed a data-driven model for shedding droplet dynamics based on condensation heat flux and surface properties such as wettability and tube diameter. Our results demonstrate that condensate droplet departure size is both heat flux and tube size dependent and follows different trends based on the condensation mode. The results of this work provide an annotation-free methodology for falling droplet segmentation as well as a statistical understanding of droplet dynamics during condensation.},
  archive      = {J_AML},
  author       = {Khodakarami, Siavash and Kabirzadeh, Pouya and Miljkovic, Nenad},
  doi          = {10.1063/5.0188620},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026108},
  shortjournal = {APL Mach. Learn.},
  title        = {Self-supervised learning of shedding droplet dynamics during steam condensation},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multivariate gaussian process surrogates for predicting
basic structural parameters of refractory non-dilute random alloys.
<em>AML</em>, <em>2</em>(2), 026107. (<a
href="https://doi.org/10.1063/5.0186045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Refractory non-dilute random alloys consist of two or more principal refractory metals with complex interactions that modify their basic structural properties such as lattice parameters and elastic constants. Atomistic simulations (ASs) are an effective method to compute such basic structural parameters. However, accurate predictions from ASs are computationally expensive due to the size and number of atomistic structures required. To reduce the computational burden, multivariate Gaussian process regression (MVGPR) is proposed as a surrogate model that only requires computing a small number of configurations for training. The elemental atom percentage in the hyper-spherical coordinates is demonstrated to be an effective feature for surrogate modeling. An additive approximation of the full MVGPR model is also proposed to further reduce computations. To improve surrogate accuracy, active learning is used to select a small number of alloys to simulate. Numerical studies based on AS data show the accuracy of the surrogate methodology and the additive approximation, as well as the effectiveness and robustness of the active learning for selecting new alloy designs to simulate.},
  archive      = {J_AML},
  author       = {Ruiz, Cesar and Raj, Anshu and Xu, Shuozhi},
  doi          = {10.1063/5.0186045},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026107},
  shortjournal = {APL Mach. Learn.},
  title        = {Multivariate gaussian process surrogates for predicting basic structural parameters of refractory non-dilute random alloys},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse subnetwork inference for neural network epistemic
uncertainty estimation with improved hessian approximation.
<em>AML</em>, <em>2</em>(2), 026106. (<a
href="https://doi.org/10.1063/5.0193951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite significant advances in deep neural networks across diverse domains, challenges persist in safety-critical contexts, including domain shift sensitivity and unreliable uncertainty estimation. To address these issues, this study investigates Bayesian learning for uncertainty handling in modern neural networks. However, the high-dimensional, non-convex nature of the posterior distribution poses practical limitations for epistemic uncertainty estimation. The Laplace approximation, as a cost-efficient Bayesian method, offers a practical solution by approximating the posterior as a multivariate normal distribution but faces computational bottlenecks in precise covariance matrix computation and storage. This research employs subnetwork inference, utilizing only a subset of the parameter space for Bayesian inference. In addition, a Kronecker-factored and low-rank representation is explored to reduce space complexity and computational costs. Several corrections are introduced to converge the approximated curvature to the exact Hessian matrix. Numerical results demonstrate the effectiveness and competitiveness of this method, whereas qualitative experiments highlight the impact of Hessian approximation granularity and parameter space utilization in Bayesian inference on mitigating overconfidence in predictions and obtaining high-quality uncertainty estimates.},
  archive      = {J_AML},
  author       = {Chen, Yinsong and Yu, Samson and Eshraghian, Jason K. and Lim, Chee Peng},
  doi          = {10.1063/5.0193951},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026106},
  shortjournal = {APL Mach. Learn.},
  title        = {Sparse subnetwork inference for neural network epistemic uncertainty estimation with improved hessian approximation},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Imaging in double-casing wells with convolutional neural
network based on inception module. <em>AML</em>, <em>2</em>(2), 026105.
(<a href="https://doi.org/10.1063/5.0191452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evaluation of well integrity in double-casing wells is critical for ensuring well stability, preventing oil and gas leaks, avoiding pollution, and ensuring safety throughout well development and production. However, the current predominant method of assessing cementing quality primarily focuses on single-casing wells, with limited work conducted on double-casing wells. This study introduces a novel approach for evaluating the cementing quality using the Inception module of convolutional neural networks. First, the finite-difference method is employed to generate borehole sonic data corresponding to a variety of model configurations, which are used to train a neural network that learns spatial features from the borehole sonic data to reconstruct the slowness model. By adjusting the network architecture and parameters, it is discovered that a neural network with two blocks and 4096 nodes in the fully connected layer demonstrated the best imaging results and exhibited strong anti-noise capabilities. The proposed method is validated using practical wellbore size models, demonstrating excellent results and offering a more effective means of evaluating wellbore integrity in double-casing wells. In addition, dipole acoustic logging data are used to conduct slowness model imaging of the compressional (P-) wave and shear (S-) wave in double-casing wells to verify the feasibility of cementing quality evaluation. The developed method contributes to more accurate evaluations of wellbore integrity for the oil and gas industry, leading to improved safety and environmental outcomes.},
  archive      = {J_AML},
  author       = {Zhang, Siqi and Zeng, Zhoumo and Wang, Xiaocen and Chen, Shili and Liu, Yang},
  doi          = {10.1063/5.0191452},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026105},
  shortjournal = {APL Mach. Learn.},
  title        = {Imaging in double-casing wells with convolutional neural network based on inception module},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Harnessing nonlinear conductive characteristic of TiO2/HfO2
memristor crossbar for implementing parallel vector–matrix
multiplication. <em>AML</em>, <em>2</em>(2), 026104. (<a
href="https://doi.org/10.1063/5.0195190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memristor crossbar arrays are expected to achieve highly energy-efficient neuromorphic computing via implementing parallel vector–matrix multiplication (VMM) in situ . The similarities between memristors and neural synapses offer opportunities for realizing hardware-based brain-inspired computing, such as spike neural networks. However, the nonlinear I – V characteristics of the memristors limit the implementation of parallel VMM on passive memristor crossbar arrays. In our work, we propose to utilize differential conductance as a synaptic weight to implement linear VMM operations on a passive memristor array in parallel. We fabricated a TiO 2 /HfO 2 memristor crossbar array, in which differential-conductance-based synaptic weight exhibits plasticity, nonvolatility, multi-states, and tunable ON/OFF ratio. The noise-dependent accuracy performance of VMM operations based on the proposed approach was evaluated, offering an optimization guideline. Furthermore, we demonstrated a spike neural network circuit capable of processing small spiking signals through the differential-conductance-based synapses. The experimental results showcase effective space-coded and time-coded spike pattern recognition. Importantly, our work opens up new possibilities for the development of passive memristor arrays, leading to increased energy and area efficiency in brain-inspired chips.},
  archive      = {J_AML},
  author       = {Wei, Wei and Wang, Cong and Pan, Chen and Yangdong, Xing-Jian and Yang, Zai-Zheng and Yang, Yuekun and Cheng, Bin and Liang, Shi-Jun and Miao, Feng},
  doi          = {10.1063/5.0195190},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026104},
  shortjournal = {APL Mach. Learn.},
  title        = {Harnessing nonlinear conductive characteristic of TiO2/HfO2 memristor crossbar for implementing parallel vector–matrix multiplication},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Study of the adsorption sites of high entropy alloys for CO2
reduction using graph convolutional network. <em>AML</em>,
<em>2</em>(2), 026103. (<a
href="https://doi.org/10.1063/5.0198043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon dioxide reduction is a major step toward building a cleaner and safer environment. There is a surge of interest in exploring high-entropy alloys (HEAs) as active catalysts for CO 2 reduction; however, so far, it is mainly limited to quinary HEAs. Inspired by the successful synthesis of octonary and denary HEAs, herein, the CO 2 reduction reaction (CO 2 RR) performance of an HEA composed of Ag, Au, Cu, Pd, Pt, Co, Ga, Ni, and Zn is studied by developing a high-fidelity graph neural network (GNN) framework. Within this framework, the adsorption site geometry and physics are employed through the featurization of elements. Particularly, featurization is performed using various intrinsic properties, such as electronegativity and atomic radius, to enable not only the supervised learning of CO 2 RR performance descriptors, namely, CO and H adsorption energies, but also the learning of adsorption physics and generalization to unseen metals and alloys. The developed model evaluates the adsorption strength of ∼ 3.5 and ∼ 0.4 billion possible sites for CO and H, respectively. Despite the enormous space of the AgAuCuPdPtCoGaNiZn alloy and the rather small size of the training data, the GNN framework demonstrated high accuracy and good robustness. This study paves the way for the rapid screening and intelligent synthesis of CO 2 RR-active and selective HEAs.},
  archive      = {J_AML},
  author       = {Oliaei, H. and Aluru, N. R.},
  doi          = {10.1063/5.0198043},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026103},
  shortjournal = {APL Mach. Learn.},
  title        = {Study of the adsorption sites of high entropy alloys for CO2 reduction using graph convolutional network},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computational synthesis of a new generation of 2D-based
perovskite quantum materials. <em>AML</em>, <em>2</em>(2), 026102. (<a
href="https://doi.org/10.1063/5.0189497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Perovskite-based optoelectronic devices have emerged as a promising energy source due to their potential for scalable production. This study introduces “perovskene,” a novel class of 2D materials derived from the ABC 3 -like perovskites, synthesized via a data-driven, high-throughput computational strategy. We harness machine learning and multitarget deep neural networks to systematically investigate the structure–property relations, paving the way for targeted material design and optimization in fields such as renewable energy, electronics, and catalysis. The characterization of over 1500 synthesized structures shows that more than 500 structures are stable, revealing properties such as ultra-low work function and large magnetic moment, underscoring the potential for advanced technological applications.},
  archive      = {J_AML},
  author       = {Ekuma, Chinedu E.},
  doi          = {10.1063/5.0189497},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026102},
  shortjournal = {APL Mach. Learn.},
  title        = {Computational synthesis of a new generation of 2D-based perovskite quantum materials},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simulation-free determination of microstructure
representative volume element size via fisher scores. <em>AML</em>,
<em>2</em>(2), 026101. (<a
href="https://doi.org/10.1063/5.0195232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A representative volume element (RVE) is a reasonably small unit of microstructure that can be simulated to obtain the same effective properties as the entire microstructure sample. Finite element (FE) simulation of RVEs, as opposed to much larger samples, saves computational expenses, especially in multiscale modeling. Therefore, it is desirable to have a framework that determines the RVE size prior to FE simulations. Existing methods select the RVE size based on when the FE-simulated properties of samples of increasing sizes converge with insignificant statistical variations, with the drawback being that many samples must be simulated. We propose a simulation-free alternative that determines the RVE size based only on a micrograph. The approach utilizes a machine learning model trained to implicitly characterize the stochastic nature of the input micrograph. The underlying rationale is to view RVE size as the smallest moving window size for which the stochastic nature of the microstructure within the window is stationary as the window moves across a large micrograph. For this purpose, we adapt a recently developed Fisher score-based framework for microstructure nonstationarity monitoring. Because the resulting RVE size is based solely on the micrograph and does not involve any FE simulation of specific properties, it constitutes an RVE for any property of interest that solely depends on the microstructure characteristics. Through numerical experiments of simple and complex microstructures, we validate our approach and show that our selected RVE sizes are consistent with when the chosen FE-simulated properties converge.},
  archive      = {J_AML},
  author       = {Liu, Wei and Mojumder, Satyajit and Liu, Wing Kam and Chen, Wei and Apley, Daniel W.},
  doi          = {10.1063/5.0195232},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026101},
  shortjournal = {APL Mach. Learn.},
  title        = {Simulation-free determination of microstructure representative volume element size via fisher scores},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Brain-inspired learning in artificial neural networks: A
review. <em>AML</em>, <em>2</em>(2), 021501. (<a
href="https://doi.org/10.1063/5.0186054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANNs) have emerged as an essential tool in machine learning, achieving remarkable success across diverse domains, including image and speech generation, game playing, and robotics. However, there exist fundamental differences between ANNs’ operating mechanisms and those of the biological brain, particularly concerning learning processes. This paper presents a comprehensive review of current brain-inspired learning representations in artificial neural networks. We investigate the integration of more biologically plausible mechanisms, such as synaptic plasticity, to improve these networks’ capabilities. Moreover, we delve into the potential advantages and challenges accompanying this approach. In this review, we pinpoint promising avenues for future research in this rapidly advancing field, which could bring us closer to understanding the essence of intelligence.},
  archive      = {J_AML},
  author       = {Schmidgall, Samuel and Ziaei, Rojin and Achterberg, Jascha and Kirsch, Louis and Hajiseyedrazi, S. Pardis and Eshraghian, Jason},
  doi          = {10.1063/5.0186054},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {021501},
  shortjournal = {APL Mach. Learn.},
  title        = {Brain-inspired learning in artificial neural networks: A review},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Erratum: “Learning the stable and metastable phase diagram
to accelerate the discovery of metastable phases of boron” [APL mach.
Learn. 2, 016103 (2024)]. <em>AML</em>, <em>2</em>(1), 019901. (<a
href="https://doi.org/10.1063/5.0198511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AML},
  author       = {Balasubramanian, Karthik and Banik, Suvo and Manna, Sukriti and Srinivasan, Srilok and Sankaranarayanan, Subramanian K. R. S.},
  doi          = {10.1063/5.0198511},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {019901},
  shortjournal = {APL Mach. Learn.},
  title        = {Erratum: “Learning the stable and metastable phase diagram to accelerate the discovery of metastable phases of boron” [APL mach. learn. 2, 016103 (2024)]},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerating defect predictions in semiconductors using
graph neural networks. <em>AML</em>, <em>2</em>(1), 016122. (<a
href="https://doi.org/10.1063/5.0176333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {First-principles computations reliably predict the energetics of point defects in semiconductors but are constrained by the expense of using large supercells and advanced levels of theory. Machine learning models trained on computational data, especially ones that sufficiently encode defect coordination environments, can be used to accelerate defect predictions. Here, we develop a framework for the prediction and screening of native defects and functional impurities in a chemical space of group IV, III–V, and II–VI zinc blende semiconductors, powered by crystal Graph-based Neural Networks (GNNs) trained on high-throughput density functional theory (DFT) data. Using an innovative approach of sampling partially optimized defect configurations from DFT calculations, we generate one of the largest computational defect datasets to date, containing many types of vacancies, self-interstitials, anti-site substitutions, impurity interstitials and substitutions, as well as some defect complexes. We applied three types of established GNN techniques, namely crystal graph convolutional neural network, materials graph network, and Atomistic Line Graph Neural Network (ALIGNN), to rigorously train models for predicting defect formation energy (DFE) in multiple charge states and chemical potential conditions. We find that ALIGNN yields the best DFE predictions with root mean square errors around 0.3 eV, which represents a prediction accuracy of 98% given the range of values within the dataset, improving significantly on the state-of-the-art. We further show that GNN-based defective structure optimization can take us close to DFT-optimized geometries at a fraction of the cost of full DFT. The current models are based on the semi-local generalized gradient approximation-Perdew–Burke–Ernzerhof (PBE) functional but are highly promising because of the correlation of computed energetics and defect levels with higher levels of theory and experimental data, the accuracy and necessity of discovering novel metastable and low energy defect structures at the PBE level of theory before advanced methods could be applied, and the ability to train multi-fidelity models in the future with new data from non-local functionals. The DFT-GNN models enable prediction and screening across thousands of hypothetical defects based on both unoptimized and partially optimized defective structures, helping identify electronically active defects in technologically important semiconductors.},
  archive      = {J_AML},
  author       = {Rahman, Md Habibur and Gollapalli, Prince and Manganaris, Panayotis and Yadav, Satyesh Kumar and Pilania, Ghanshyam and DeCost, Brian and Choudhary, Kamal and Mannodi-Kanakkithodi, Arun},
  doi          = {10.1063/5.0176333},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016122},
  shortjournal = {APL Mach. Learn.},
  title        = {Accelerating defect predictions in semiconductors using graph neural networks},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Autonomous convergence of STM control parameters using
bayesian optimization. <em>AML</em>, <em>2</em>(1), 016121. (<a
href="https://doi.org/10.1063/5.0185362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scanning tunneling microscopy (STM) is a widely used tool for atomic imaging of novel materials and their surface energetics. However, the optimization of the imaging conditions is a tedious process due to the extremely sensitive tip–surface interaction, thus limiting the throughput efficiency. In this paper, we deploy a machine learning (ML)-based framework to achieve optimal atomically resolved imaging conditions in real time. The experimental workflow leverages the Bayesian optimization (BO) method to rapidly improve the image quality, defined by the peak intensity in the Fourier space. The outcome of the BO prediction is incorporated into the microscope controls, i.e., the current setpoint and the tip bias, to dynamically improve the STM scan conditions. We present strategies to either selectively explore or exploit across the parameter space. As a result, suitable policies are developed for autonomous convergence of the control parameters. The ML-based framework serves as a general workflow methodology across a wide range of materials.},
  archive      = {J_AML},
  author       = {Narasimha, Ganesh and Hus, Saban and Biswas, Arpan and Vasudevan, Rama and Ziatdinov, Maxim},
  doi          = {10.1063/5.0185362},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016121},
  shortjournal = {APL Mach. Learn.},
  title        = {Autonomous convergence of STM control parameters using bayesian optimization},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VERI-d: A new dataset and method for multi-camera vehicle
re-identification of damaged cars under varying lighting conditions.
<em>AML</em>, <em>2</em>(1), 016120. (<a
href="https://doi.org/10.1063/5.0183408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle re-identification (V-ReID) is a critical task that aims to match the same vehicle across images from different camera viewpoints. The previous studies have leveraged attribute clues, such as color, model, and license plate, to enhance the V-ReID performance. However, these methods often lack effective interaction between the global–local features and the final V-ReID objective. Moreover, they do not address the challenging issues in real-world scenarios, such as high viewpoint variations, extreme illumination conditions, and car appearance changes (e.g., due to damage or wrong driving). We propose a novel framework to tackle these problems and advance the research in V-ReID, which can handle various types of car appearance changes and achieve robust V-ReID under varying lighting conditions. Our main contributions are as follows: (i) we propose a new Re-ID architecture named global–local self-attention network, which integrates local information into the feature learning process and enhances the feature representation for V-ReID and (ii) we introduce a novel damaged vehicle Re-ID dataset called VERI-D, which is the first publicly available dataset that focuses on this challenging yet practical scenario. The dataset contains both natural and synthetic images of damaged vehicles captured from multiple camera viewpoints and under different lighting conditions. (iii) We conduct extensive experiments on the VERI-D dataset and demonstrate the effectiveness of our approach in addressing the challenges associated with damaged vehicle re-identification. We also compare our method to several state-of-the-art V-ReID methods and show its superiority.},
  archive      = {J_AML},
  author       = {Liu, Shao and Agaian, Sos S.},
  doi          = {10.1063/5.0183408},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016120},
  shortjournal = {APL Mach. Learn.},
  title        = {VERI-D: A new dataset and method for multi-camera vehicle re-identification of damaged cars under varying lighting conditions},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving the mechanical properties of cantor-like alloys
with bayesian optimization. <em>AML</em>, <em>2</em>(1), 016119. (<a
href="https://doi.org/10.1063/5.0179844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The search for better compositions in high entropy alloys is a formidable challenge in materials science. Here, we demonstrate a systematic Bayesian optimization method to enhance the mechanical properties of the paradigmatic five-element Cantor alloy in silico . This method utilizes an automated loop with an online database, a Bayesian optimization algorithm, thermodynamic modeling, and molecular dynamics simulations. Starting from the equiatomic Cantor composition, our approach optimizes the relative fractions of its constituent elements, searching for better compositions while maintaining the thermodynamic phase stability. With 24 steps, we find Fe 21 Cr 20 Mn 5 Co 20 Ni 34 with a yield stress improvement of 58%, and with 72 steps, we find Fe 6 Cr 22 Mn 5 Co 32 Ni 35 where the yield stress has improved by 74%. These optimized compositions correspond to Ni-rich medium entropy alloys with enhanced mechanical properties and superior face-centered-cubic phase stability compared to the traditional equiatomic Cantor alloy. The automatic approach devised here paves the way for designing high entropy alloys with tailored properties, opening avenues for numerous potential applications.},
  archive      = {J_AML},
  author       = {Torsti, Valtteri and Mäkinen, Tero and Bonfanti, Silvia and Koivisto, Juha and Alava, Mikko J.},
  doi          = {10.1063/5.0179844},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016119},
  shortjournal = {APL Mach. Learn.},
  title        = {Improving the mechanical properties of cantor-like alloys with bayesian optimization},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Random forests for detecting weak signals and extracting
physical information: A case study of magnetic navigation. <em>AML</em>,
<em>2</em>(1), 016118. (<a
href="https://doi.org/10.1063/5.0189564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been recently demonstrated that two machine-learning architectures, reservoir computing and time-delayed feed-forward neural networks, can be exploited for detecting the Earth’s anomaly magnetic field immersed in overwhelming complex signals for magnetic navigation in a GPS-denied environment. The accuracy of the detected anomaly field corresponds to a positioning accuracy in the range of 10–40 m. To increase the accuracy and reduce the uncertainty of weak signal detection as well as to directly obtain the position information, we exploit the machine-learning model of random forests that combines the output of multiple decision trees to give optimal values of the physical quantities of interest. In particular, from time-series data gathered from the cockpit of a flying airplane during various maneuvering stages, where strong background complex signals are caused by other elements of the Earth’s magnetic field and the fields produced by the electronic systems in the cockpit, we demonstrate that the random-forest algorithm performs remarkably well in detecting the weak anomaly field and in filtering the position of the aircraft. With the aid of the conventional inertial navigation system, the positioning error can be reduced to less than 10 m. We also find that, contrary to the conventional wisdom, the classic Tolles–Lawson model for calibrating and removing the magnetic field generated by the body of the aircraft is not necessary and may even be detrimental for the success of the random-forest method.},
  archive      = {J_AML},
  author       = {Moradi, Mohammadamin and Zhai, Zheng-Meng and Nielsen, Aaron and Lai, Ying-Cheng},
  doi          = {10.1063/5.0189564},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016118},
  shortjournal = {APL Mach. Learn.},
  title        = {Random forests for detecting weak signals and extracting physical information: A case study of magnetic navigation},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning-enabled probing of irradiation-induced defects
in time-series micrographs. <em>AML</em>, <em>2</em>(1), 016117. (<a
href="https://doi.org/10.1063/5.0186046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling time-series data with convolutional neural networks (CNNs) requires building a model to learn in batches as opposed to training sequentially. Coupling CNNs with in situ or operando techniques opens the possibility of accurately segmenting dynamic reactions and mass transport phenomena to understand how materials behave under the conditions in which they are used. In this article, in situ ion irradiation transmission electron microscopy (TEM) images are used as inputs into the CNN to assess the defect generation rate, defect cluster density, and saturation of defects. We then use the output segmentation maps to correlate with conventional TEM micrographs to assess the model’s ability to detail nanoscale interactions. Next, we discuss the implications of preprocessing and hyperparameters on model variability, accuracy when expanded to other datasets, and the role of regularization when controlling model variance. Ultimately, we eliminate human bias when extrapolating physical metrics, speed up analysis time, decouple reactions that happen at 100 ms intervals, and deploy models that are both accurate and transferable to similar experiments.},
  archive      = {J_AML},
  author       = {Burns, Kory and Tadj, Kayvon and Allaparti, Tarun and Arias, Liliana and Li, Nan and Aitkaliyeva, Assel and Misra, Amit and Scott, Mary C. and Hattar, Khalid},
  doi          = {10.1063/5.0186046},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016117},
  shortjournal = {APL Mach. Learn.},
  title        = {Deep learning-enabled probing of irradiation-induced defects in time-series micrographs},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Measuring thermal profiles in high explosives using neural
networks. <em>AML</em>, <em>2</em>(1), 016116. (<a
href="https://doi.org/10.1063/5.0183886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new method for calculating the temperature profile of high explosive (HE) material using a Convolutional Neural Network (CNN). To train/test the CNN, we have developed a hybrid experiment/simulation method for collecting acoustic and temperature data. We experimentally heat cylindrical containers of HE material until detonation/deflagration, where we continuously measure the acoustic bursts through the HE using multiple acoustic transducers lined around the exterior container circumference. However, measuring the temperature profile in the HE in an experiment would require inserting a large number of thermal probes, which would disrupt the heating process. Thus, we use two thermal probes, one at the HE center and one at the wall. We then use numerical simulation of the heating process to calculate the temperature distribution and correct the simulated temperatures based on the experimental center and wall temperatures. We calculate temperature errors on the order of 15 °C, which is ∼12% of the range of temperatures in the experiment. We also investigate how the algorithm’s accuracy is affected by the number of acoustic receivers used to collect each measurement and the resolution of the temperature prediction. This work provides a means of assessing the safety status of HE material, which cannot be achieved using existing temperature measurement methods. In addition, it has implications for a range of other applications where internal temperature profile measurements would provide critical information. These applications include detecting chemical reactions, observing thermodynamic processes such as combustion, monitoring metal or plastic casting, determining the energy density in thermal storage capsules, and identifying abnormal battery operations.},
  archive      = {J_AML},
  author       = {Greenhall, J. and Zerkle, D. K. and Davis, E. S. and Broilo, R. and Pantea, C.},
  doi          = {10.1063/5.0183886},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016116},
  shortjournal = {APL Mach. Learn.},
  title        = {Measuring thermal profiles in high explosives using neural networks},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Physics-agnostic inverse design using transfer matrices.
<em>AML</em>, <em>2</em>(1), 016115. (<a
href="https://doi.org/10.1063/5.0179457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse design is an application of machine learning to device design, giving the computer maximal latitude in generating novel structures, learning from their performance, and optimizing them to suit the designer’s needs. Gradient-based optimizers, augmented by the adjoint method to efficiently compute the gradient, are particularly attractive for this approach and have proven highly successful with finite-element and finite-difference physics simulators. Here, we extend adjoint optimization to the transfer matrix method, an accurate and efficient simulator for a wide variety of quasi-1D physical phenomena. We leverage this versatility to develop a physics-agnostic inverse design framework and apply it to three distinct problems, each presenting a substantial challenge for conventional design methods: optics, designing a multivariate optical element for compressive sensing; acoustics, designing a high-performance anti-sonar submarine coating; and quantum mechanics, designing a tunable double-bandpass electron energy filter.},
  archive      = {J_AML},
  author       = {Morrison, Nathaniel and Pan, Shuaiwei and Ma, Eric Y.},
  doi          = {10.1063/5.0179457},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016115},
  shortjournal = {APL Mach. Learn.},
  title        = {Physics-agnostic inverse design using transfer matrices},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Training self-learning circuits for power-efficient
solutions. <em>AML</em>, <em>2</em>(1), 016114. (<a
href="https://doi.org/10.1063/5.0181382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the size and ubiquity of artificial intelligence and computational machine learning models grow, the energy required to train and use them is rapidly becoming economically and environmentally unsustainable. Recent laboratory prototypes of self-learning electronic circuits, such as “physical learning machines,” open the door to analog hardware that directly employs physics to learn desired functions from examples at a low energy cost. In this work, we show that this hardware platform allows for an even further reduction in energy consumption by using good initial conditions and a new learning algorithm. Using analytical calculations, simulations, and experiments, we show that a trade-off emerges when learning dynamics attempt to minimize both the error and the power consumption of the solution—greater power reductions can be achieved at the cost of decreasing solution accuracy. Finally, we demonstrate a practical procedure to weigh the relative importance of error and power minimization, improving the power efficiency given a specific tolerance to error.},
  archive      = {J_AML},
  author       = {Stern, Menachem and Dillavou, Sam and Jayaraman, Dinesh and Durian, Douglas J. and Liu, Andrea J.},
  doi          = {10.1063/5.0181382},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016114},
  shortjournal = {APL Mach. Learn.},
  title        = {Training self-learning circuits for power-efficient solutions},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contextual beamforming: Exploiting location and AI for
enhanced wireless telecommunication performance. <em>AML</em>,
<em>2</em>(1), 016113. (<a
href="https://doi.org/10.1063/5.0176422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Beamforming, an integral component of modern mobile networks, enables spatial selectivity and improves network quality. However, many beamforming techniques are iterative, introducing unwanted latency to the system. In recent times, there has been a growing interest in leveraging mobile users’ location information to expedite beamforming processes. This paper explores the concept of contextual beamforming, discussing its advantages, disadvantages, and implications. Notably, we demonstrate an impressive 53% improvement in the signal-to-interference-plus-noise ratio by implementing the adaptive beamforming maximum ratio transmission (MRT) algorithm compared to scenarios without beamforming. It further elucidates how MRT contributes to contextual beamforming. The importance of localization in implementing contextual beamforming is also examined. Additionally, the paper delves into the use of artificial intelligence (AI) schemes, including machine learning and deep learning, in implementing contextual beamforming techniques that leverage user location information. Based on the comprehensive review, the results suggest that the combination of MRT and zero-forcing techniques, alongside deep neural networks employing Bayesian optimization, represents the most promising approach for contextual beamforming. Furthermore, the study discusses the future potential of programmable switches, such as Tofino—an innovative switch developed by Barefoot Networks (now a part of Intel)—in enabling location-aware beamforming. This paper highlights the significance of contextual beamforming for improving wireless telecommunications performance. By capitalizing on location information and employing advanced AI techniques, the field can overcome challenges and unlock new possibilities for delivering reliable and efficient mobile networks.},
  archive      = {J_AML},
  author       = {Kaur, Jaspreet and Bhatti, Satyam and Tan, Kang and Popoola, Olaoluwa R. and Imran, Muhammad Ali and Ghannam, Rami and Abbasi, Qammer H. and Abbas, Hasan T.},
  doi          = {10.1063/5.0176422},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016113},
  shortjournal = {APL Mach. Learn.},
  title        = {Contextual beamforming: Exploiting location and AI for enhanced wireless telecommunication performance},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating uncertainty into deep learning models for
enhanced prediction of nanocomposite materials’ mechanical properties.
<em>AML</em>, <em>2</em>(1), 016112. (<a
href="https://doi.org/10.1063/5.0177062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a novel deep-learning framework that incorporates quantified uncertainty for predicting the mechanical properties of nanocomposite materials, specifically taking into account their morphology and composition. Due to the intricate microstructures of nanocomposites and their dynamic changes under diverse conditions, traditional methods, such as molecular dynamics simulations, often impose significant computational burdens. Our machine learning models, trained on comprehensive material datasets, provide a lower computational cost alternative, facilitating rapid exploration of design spaces and more reliable predictions. We employ both convolutional neural networks and feedforward neural networks for our predictions, training separate models for yield strength and ultimate tensile strength. Furthermore, we integrate uncertainty quantification into our models, thereby providing confidence intervals for our predictions and making them more reliable. This study paves the way for advancements in predicting the properties of nanocomposite materials and could potentially be expanded to cover a broad spectrum of materials in the future.},
  archive      = {J_AML},
  author       = {Wang, Yuheng and Lin, Guang and Yang, Shengfeng},
  doi          = {10.1063/5.0177062},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016112},
  shortjournal = {APL Mach. Learn.},
  title        = {Integrating uncertainty into deep learning models for enhanced prediction of nanocomposite materials’ mechanical properties},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predicting wind farm wake losses with deep convolutional
hierarchical encoder–decoder neural networks. <em>AML</em>,
<em>2</em>(1), 016111. (<a
href="https://doi.org/10.1063/5.0168973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind turbine wakes are the most significant factor affecting wind farm performance, decreasing energy production and increasing fatigue loads in downstream turbines. Wind farm turbine layouts are designed to minimize wake interactions using a suite of predictive models, including analytical wake models and computational fluid dynamics simulations (CFD). CFD simulations of wind farms are time-consuming and computationally expensive, which hinder their use in optimization studies that require hundreds of simulations to converge to an optimal turbine layout. In this work, we propose DeepWFLO, a deep convolutional hierarchical encoder–decoder neural network architecture, as an image-to-image surrogate model for predicting the wind velocity field for Wind Farm Layout Optimization (WFLO). We generate a dataset composed of image representations of the turbine layout and undisturbed flow field in the wind farm, as well as images of the corresponding wind velocity field, including wake effects generated with both analytical models and CFD simulations. The proposed DeepWFLO architecture is then trained and optimized through supervised learning with an application-tailored loss function that considers prediction errors in both wind velocity and energy production. Results on a commonly used test case show median velocity errors of 1.0%–8.0% for DeepWFLO networks trained with analytical and CFD data, respectively. We also propose a model-fusion strategy that uses analytical wake models to generate an additional input channel for the network, resulting in median velocity errors below 1.8%. Spearman rank correlations between predictions and data, which evidence the suitability of DeepWFLO for optimization purposes, range between 92.3% and 99.9%.},
  archive      = {J_AML},
  author       = {Romero, David A. and Hasanpoor, Saeede and Antonini, Enrico G. A. and Amon, Cristina H.},
  doi          = {10.1063/5.0168973},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016111},
  shortjournal = {APL Mach. Learn.},
  title        = {Predicting wind farm wake losses with deep convolutional hierarchical encoder–decoder neural networks},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Completeness of atomic structure representations.
<em>AML</em>, <em>2</em>(1), 016110. (<a
href="https://doi.org/10.1063/5.0160740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the challenge of obtaining a comprehensive and symmetric representation of point particle groups, such as atoms in a molecule, which is crucial in physics and theoretical chemistry. The problem has become even more important with the widespread adoption of machine-learning techniques in science, as it underpins the capacity of models to accurately reproduce physical relationships while being consistent with fundamental symmetries and conservation laws. However, some of the descriptors that are commonly used to represent point clouds— notably those based on discretized correlations of the neighbor density that power most of the existing ML models of matter at the atomic scale—are unable to distinguish between special arrangements of particles in three dimensions. This makes it impossible to machine learn their properties. Atom-density correlations are provably complete in the limit in which they simultaneously describe the mutual relationship between all atoms, which is impractical. We present a novel approach to construct descriptors of finite correlations based on the relative arrangement of particle triplets, which can be employed to create symmetry-adapted models with universal approximation capabilities, and have the resolution of the neighbor discretization as the sole convergence parameter. Our strategy is demonstrated on a class of atomic arrangements that are specifically built to defy a broad class of conventional symmetric descriptors, showing its potential for addressing their limitations.},
  archive      = {J_AML},
  author       = {Nigam, Jigyasa and Pozdnyakov, Sergey N. and Huguenin-Dumittan, Kevin K. and Ceriotti, Michele},
  doi          = {10.1063/5.0160740},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016110},
  shortjournal = {APL Mach. Learn.},
  title        = {Completeness of atomic structure representations},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Digitizing images of electrical-circuit schematics.
<em>AML</em>, <em>2</em>(1), 016109. (<a
href="https://doi.org/10.1063/5.0177755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrical-circuit schematics are a foundational tool in electrical engineering. A method that can automatically digitalize them is desirable since a knowledge base of such schematics could preserve their functional information as well as provide a database that one can mine to predict more operationally efficient electrical circuits using data analytics and machine learning. We present a workflow that contains a novel pattern-recognition methodology and a custom-trained Optical Character Recognition (OCR) model that can digitalize images of electrical-circuit schematics with minimal configuration. The pattern-recognition and OCR stages of the workflow yield 86.4% and 99.6% success rates, respectively. We also present an extendable option toward predictive circuit-design efficiencies, subject to a large database of images being available. Thereby, data gathered from our pattern-recognition workflow are used to draw network graphs, which are in turn employed to form matrix equations that contain the voltages and currents for all nodes in the circuit in terms of component values. These equations could be applied to a database of electrical-circuit schematics to predict new circuit designs or circuit modifications that offer greater operational efficiency. Alternatively, these network graphs could be converted into simulation programs with integrated circuit emphasis netlists to afford more accurate and computationally automated simulations.},
  archive      = {J_AML},
  author       = {Kelly, Charles R. and Cole, Jacqueline M.},
  doi          = {10.1063/5.0177755},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016109},
  shortjournal = {APL Mach. Learn.},
  title        = {Digitizing images of electrical-circuit schematics},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning for rapid discovery of laminar flow channel
wall modifications that enhance heat transfer. <em>AML</em>,
<em>2</em>(1), 016108. (<a
href="https://doi.org/10.1063/5.0187783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical simulation of fluid flow plays an essential role in modeling many physical phenomena, which enables technological advancements, contributes to sustainable practices, and expands our understanding of various natural and engineered systems. The calculation of heat transfer in fluid flow in simple flat channels is a relatively easy task for various simulation methods. However, once the channel geometry becomes more complex, numerical simulations become a bottleneck in optimizing wall geometries. We present a combination of accurate numerical simulations of arbitrary, flat, and non-flat channels as well as machine learning models trained on simulated data to predict the drag coefficient and Stanton number. We show that convolutional neural networks (CNNs) can accurately predict target properties at a fraction of the computational cost of numerical simulations. We use CNN models in a virtual high-throughput screening approach to explore a large number of possible, randomly generated wall architectures. Data augmentation techniques are incorporated to enforce physical invariances toward shifting and flipping, contributing to precise prediction for fluid flow and heat transfer characteristics. Moreover, we approach the interpretation of the trained model to better understand relevant channel structures and their influence on heat transfer. The general approach is not only applicable to simple flow setups as presented here but can be extended to more complex tasks, such as multiphase or even reactive unit operations in chemical engineering.},
  archive      = {J_AML},
  author       = {Koide, Yuri and Kaithakkal, Arjun J. and Schniewind, Matthias and Ladewig, Bradley P. and Stroh, Alexander and Friederich, Pascal},
  doi          = {10.1063/5.0187783},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016108},
  shortjournal = {APL Mach. Learn.},
  title        = {Machine learning for rapid discovery of laminar flow channel wall modifications that enhance heat transfer},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Noise tailoring, noise annealing, and external perturbation
injection strategies in memristive hopfield neural networks.
<em>AML</em>, <em>2</em>(1), 016107. (<a
href="https://doi.org/10.1063/5.0173662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The commercial introduction of a novel electronic device is often preceded by a lengthy material optimization phase devoted to the suppression of device noise as much as possible. The emergence of novel computing architectures, however, triggers a paradigm shift in noise engineering, demonstrating that non-suppressed but properly tailored noise can be harvested as a computational resource in probabilistic computing schemes. Such a strategy was recently realized on the hardware level in memristive Hopfield neural networks, delivering fast and highly energy efficient optimization performance. Inspired by these achievements, we perform a thorough analysis of simulated memristive Hopfield neural networks relying on realistic noise characteristics acquired on various memristive devices. These characteristics highlight the possibility of orders of magnitude variations in the noise level depending on the material choice as well as on the resistance state (and the corresponding active region volume) of the devices. Our simulations separate the effects of various device non-idealities on the operation of the Hopfield neural network by investigating the role of the programming accuracy as well as the noise-type and noise amplitude of the ON and OFF states. Relying on these results, we propose optimized noise tailoring and noise annealing strategies, comparing the impact of internal noise to the effect of external perturbation injection schemes.},
  archive      = {J_AML},
  author       = {Fehérvári, János Gergő and Balogh, Zoltán and Török, Tímea Nóra and Halbritter, András},
  doi          = {10.1063/5.0173662},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016107},
  shortjournal = {APL Mach. Learn.},
  title        = {Noise tailoring, noise annealing, and external perturbation injection strategies in memristive hopfield neural networks},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). M3ICRO: Machine learning-enabled compact photonic tensor
core based on programmable multi-operand multimode interference.
<em>AML</em>, <em>2</em>(1), 016106. (<a
href="https://doi.org/10.1063/5.0170965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photonic computing shows promise for transformative advancements in machine learning (ML) acceleration, offering ultrafast speed, massive parallelism, and high energy efficiency. However, current photonic tensor core (PTC) designs based on standard optical components hinder scalability and compute density due to their large spatial footprint. To address this, we propose an ultracompact PTC using customized programmable multi-operand multimode interference (MOMMI) devices, named M 3 ICRO . The programmable MOMMI leverages the intrinsic light propagation principle, providing a single-device programmable matrix unit beyond the conventional computing paradigm of one multiply-accumulate operation per device. To overcome the optimization difficulty of customized devices that often requires time-consuming simulation, we apply ML for optics to predict the device behavior and enable differentiable optimization flow. We thoroughly investigate the reconfigurability and matrix expressivity of our customized PTC and introduce a novel block unfolding method to fully exploit the computing capabilities of a complex-valued PTC for near-universal real-valued linear transformations. Extensive evaluations demonstrate that M 3 ICRO achieves a 3.5–8.9× smaller footprint, 1.6–4.4× higher speed, 9.9–38.5× higher compute density, 3.7–12× higher system throughput, and superior noise robustness compared to state-of-the-art coherent PTC designs. It also outperforms electronic digital A100 graphics processing unit by 34.8–403× higher throughput while maintaining close-to-digital task accuracy across various ML benchmarks.},
  archive      = {J_AML},
  author       = {Gu, Jiaqi and Zhu, Hanqing and Feng, Chenghao and Jiang, Zixuan and Chen, Ray T. and Pan, David Z.},
  doi          = {10.1063/5.0170965},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016106},
  shortjournal = {APL Mach. Learn.},
  title        = {M3ICRO: Machine learning-enabled compact photonic tensor core based on programmable multi-operand multimode interference},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction and control of spatiotemporal chaos by learning
conjugate tubular neighborhoods. <em>AML</em>, <em>2</em>(1), 016105.
(<a href="https://doi.org/10.1063/5.0181022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I present a data-driven predictive modeling tool that is applicable to high-dimensional chaotic systems with unstable periodic orbits. The basic idea is using deep neural networks to learn coordinate transformations between the trajectories in the periodic orbits’ neighborhoods and those of low-dimensional linear systems in a latent space . I argue that the resulting models are partially interpretable since their latent-space dynamics is fully understood. To illustrate the method, I apply it to the numerical solutions of the Kuramoto–Sivashinsky partial differential equation in one dimension. Besides the forward-time predictions, I also show that these models can be leveraged for control.},
  archive      = {J_AML},
  author       = {Budanur, Nazmi Burak},
  doi          = {10.1063/5.0181022},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016105},
  shortjournal = {APL Mach. Learn.},
  title        = {Prediction and control of spatiotemporal chaos by learning conjugate tubular neighborhoods},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning approach for gas sensor data regression:
Incorporating surface state model and GRU-based model. <em>AML</em>,
<em>2</em>(1), 016104. (<a
href="https://doi.org/10.1063/5.0160983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal–oxide–semiconductor (MOS) gas sensors are widely used for gas detection and monitoring. However, MOS gas sensors have always suffered from instability in the link between gas sensor data and the measured gas concentration. In this paper, we propose a novel deep learning approach that combines the surface state model and a Gated Recurrent Unit (GRU)-based regression to enhance the analysis of gas sensor data. The surface state model provides valuable insights into the microscopic surface processes underlying the conductivity response to pulse heating, while the GRU model effectively captures the temporal dependencies present in time-series data. The experimental results demonstrate that the theory guided model GRU+ β outperforms the elementary GRU algorithm in terms of accuracy and astringent speed. The incorporation of the surface state model and the parameter rate enhances the model’s accuracy and provides valuable information for learning pulse-heated regression tasks with better generalization. This research exhibits superiority of integrating domain knowledge and deep learning techniques in the field of gas sensor data analysis. The proposed approach offers a practical framework for improving the understanding and prediction of gas concentrations, facilitating better decision-making in various practical applications.},
  archive      = {J_AML},
  author       = {Zhuang, Yi and Yin, Du and Wu, Lang and Niu, Gaoqiang and Wang, Fei},
  doi          = {10.1063/5.0160983},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016104},
  shortjournal = {APL Mach. Learn.},
  title        = {A deep learning approach for gas sensor data regression: Incorporating surface state model and GRU-based model},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Learning the stable and metastable phase diagram to
accelerate the discovery of metastable phases of boron. <em>AML</em>,
<em>2</em>(1), 016103. (<a
href="https://doi.org/10.1063/5.0175994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Boron, an element of captivating chemical intricacy, has been surrounded by controversies ever since its discovery in 1808. The complexities of boron stem from its unique position between metals and insulators in the Periodic Table. Recent computational studies have shed light on some of the stable boron allotropes. However, the demand for multifunctionality necessitates the need to go beyond the stable phases into the realm of metastability and explore the potentially vast but elusive metastable phases of boron. Traditional search for stable phases of materials has focused on identifying materials with the lowest enthalpy. Here, we introduce a workflow that uses reinforcement learning coupled with decision trees, such as Monte Carlo tree search, to search for stable and metastable boron phases, with enthalpy as the objective. We discover new boron metastable phases and construct a phase diagram that locates their phase space ( T , P ) at different levels of metastability (Δ G ) from the ground state and provides useful information on the domains of relative stability of the various stable and metastable boron phases.},
  archive      = {J_AML},
  author       = {Balasubramanian, Karthik and Banik, Suvo and Manna, Sukriti and Srinivasan, Srilok and Sankaranarayanan, Subramanian K. R. S.},
  doi          = {10.1063/5.0175994},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016103},
  shortjournal = {APL Mach. Learn.},
  title        = {Learning the stable and metastable phase diagram to accelerate the discovery of metastable phases of boron},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning thermodynamically constrained equations of state
with uncertainty. <em>AML</em>, <em>2</em>(1), 016102. (<a
href="https://doi.org/10.1063/5.0165298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical simulations of high energy-density experiments require equation of state (EOS) models that relate a material’s thermodynamic state variables—specifically pressure, volume/density, energy, and temperature. EOS models are typically constructed using a semi-empirical parametric methodology, which assumes a physics-informed functional form with many tunable parameters calibrated using experimental/simulation data. Since there are inherent uncertainties in the calibration data (parametric uncertainty) and the assumed functional EOS form (model uncertainty), it is essential to perform uncertainty quantification (UQ) to improve confidence in EOS predictions. Model uncertainty is challenging for UQ studies since it requires exploring the space of all possible physically consistent functional forms. Thus, it is often neglected in favor of parametric uncertainty, which is easier to quantify without violating thermodynamic laws. This work presents a data-driven machine learning approach to constructing EOS models that naturally captures model uncertainty while satisfying the necessary thermodynamic consistency and stability constraints. We propose a novel framework based on physics-informed Gaussian process regression (GPR) that automatically captures total uncertainty in the EOS and can be jointly trained on both simulation and experimental data sources. A GPR model for the shock Hugoniot is derived, and its uncertainties are quantified using the proposed framework. We apply the proposed model to learn the EOS for the diamond solid state of carbon using both density functional theory data and experimental shock Hugoniot data to train the model and show that the prediction uncertainty is reduced by considering thermodynamic constraints.},
  archive      = {J_AML},
  author       = {Sharma, Himanshu and Gaffney, Jim A. and Tsapetis, Dimitrios and Shields, Michael D.},
  doi          = {10.1063/5.0165298},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016102},
  shortjournal = {APL Mach. Learn.},
  title        = {Learning thermodynamically constrained equations of state with uncertainty},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning based hybrid ensemble models for prediction
of organic dyes photophysical properties: Absorption wavelengths,
emission wavelengths, and quantum yields. <em>AML</em>, <em>2</em>(1),
016101. (<a href="https://doi.org/10.1063/5.0181294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fluorescent organic dyes are extensively used in the design and discovery of new materials, photovoltaic cells, light sensors, imaging applications, medicinal chemistry, drug design, energy harvesting technologies, dye and pigment industries, and pharmaceutical industries, among other things. However, designing and synthesizing new fluorescent organic dyes with desirable properties for specific applications requires knowledge of the chemical and physical properties of previously studied molecules. It is a difficult task for experimentalists to identify the photophysical properties of the required chemical molecule at negligible time and financial cost. For this purpose, machine learning-based models are a highly demanding technique for estimating photophysical properties and may be an alternative approach to density functional theory. In this study, we used 15 single models and proposed three different hybrid models to assess a dataset of 3066 organic materials for predicting photophysical properties. The performance of these models was evaluated using three evaluation parameters: mean absolute error, root mean squared error, and the coefficient of determination ( R 2 ) on the test-size data. All the proposed hybrid models achieved the highest accuracy ( R 2 ) of 97.28%, 95.19%, and 74.01% for predicting the absorption wavelengths, emission wavelengths, and quantum yields, respectively. These resultant outcomes of the proposed hybrid models are ∼1.9%, ∼2.7%, and ∼2.4% higher than the recently reported best models’ values in the same dataset for absorption wavelengths, emission wavelengths, and quantum yields, respectively. This research promotes the quick and accurate production of new fluorescent organic dyes with desirable photophysical properties for specific applications.},
  archive      = {J_AML},
  author       = {Mahato, Kapil Dev and Kumar Das, S. S. Gourab and Azad, Chandrashekhar and Kumar, Uday},
  doi          = {10.1063/5.0181294},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016101},
  shortjournal = {APL Mach. Learn.},
  title        = {Machine learning based hybrid ensemble models for prediction of organic dyes photophysical properties: Absorption wavelengths, emission wavelengths, and quantum yields},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unifying perspective on non-stationary kernels for deeper
gaussian processes. <em>AML</em>, <em>2</em>(1), 010902. (<a
href="https://doi.org/10.1063/5.0176963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Gaussian process (GP) is a popular statistical technique for stochastic function approximation and uncertainty quantification from data. GPs have been adopted into the realm of machine learning (ML) in the last two decades because of their superior prediction abilities, especially in data-sparse scenarios, and their inherent ability to provide robust uncertainty estimates. Even so, their performance highly depends on intricate customizations of the core methodology, which often leads to dissatisfaction among practitioners when standard setups and off-the-shelf software tools are being deployed. Arguably, the most important building block of a GP is the kernel function, which assumes the role of a covariance operator. Stationary kernels of the Matérn class are used in the vast majority of applied studies; poor prediction performance and unrealistic uncertainty quantification are often the consequences. Non-stationary kernels show improved performance but are rarely used due to their more complicated functional form and the associated effort and expertise needed to define and tune them optimally. In this perspective, we want to help ML practitioners make sense of some of the most common forms of non-stationarity for Gaussian processes. We show a variety of kernels in action using representative datasets, carefully study their properties, and compare their performances. Based on our findings, we propose a new kernel that combines some of the identified advantages of existing kernels.},
  archive      = {J_AML},
  author       = {Noack, Marcus M. and Luo, Hengrui and Risser, Mark D.},
  doi          = {10.1063/5.0176963},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {010902},
  shortjournal = {APL Mach. Learn.},
  title        = {A unifying perspective on non-stationary kernels for deeper gaussian processes},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). In-memory and in-sensor reservoir computing with memristive
devices. <em>AML</em>, <em>2</em>(1), 010901. (<a
href="https://doi.org/10.1063/5.0174863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the significant progress made in deep learning on digital computers, their energy consumption and computational speed still fall short of meeting the standards for brain-like computing. To address these limitations, reservoir computing (RC) has been gaining increasing attention across communities of electronic devices, computing systems, and machine learning, notably with its in-memory or in-sensor implementation on the hardware–software co-design. Hardware regarded, in-memory or in-sensor computers leverage emerging electronic and optoelectronic devices for data processing right where the data are stored or sensed. This technology dramatically reduces the energy consumption from frequent data transfers between sensing, storage, and computational units. Software regarded, RC enables real-time edge learning thanks to its brain-inspired dynamic system with massive training complexity reduction. From this perspective, we survey recent advancements in in-memory/in-sensor RC, including algorithm designs, material and device development, and downstream applications in classification and regression problems, and discuss challenges and opportunities ahead in this emerging field.},
  archive      = {J_AML},
  author       = {Lin, Ning and Chen, Jia and Zhao, Ruoyu and He, Yangu and Wong, Kwunhang and Qiu, Qinru and Wang, Zhongrui and Yang, J. Joshua},
  doi          = {10.1063/5.0174863},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {010901},
  shortjournal = {APL Mach. Learn.},
  title        = {In-memory and in-sensor reservoir computing with memristive devices},
  volume       = {2},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
